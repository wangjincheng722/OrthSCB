I0829 09:22:53.241369 916722 caffe.cpp:218] Using GPUs 1
I0829 09:22:53.277673 916722 caffe.cpp:223] GPU 1: GeForce RTX 3090
I0829 09:22:54.231506 916722 solver.cpp:44] Initializing solver from parameters: 
test_iter: 10000
test_interval: 50000
base_lr: 0.01
display: 500
max_iter: 5000000
lr_policy: "fixed"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 50000
snapshot_prefix: "weights_20210828200417/CIFAR10"
solver_mode: GPU
device_id: 1
random_seed: 831486
net: "train_test.pt"
train_state {
  level: 0
  stage: ""
}
type: "SGD"
I0829 09:22:54.231715 916722 solver.cpp:87] Creating training net from net file: train_test.pt
I0829 09:22:54.232201 916722 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: train_test.pt
I0829 09:22:54.232214 916722 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0829 09:22:54.232323 916722 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer InputData
I0829 09:22:54.232352 916722 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0829 09:22:54.232363 916722 net.cpp:51] Initializing net from parameters: 
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "InputData"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
  }
  image_data_param {
    source: "/home/jcwang/work/1.CIFAR10/train.txt"
    batch_size: 32
    shuffle: true
    is_color: true
  }
}
layer {
  name: "B0_0_ConvBNScaleReLU_Conv"
  type: "Convolution"
  bottom: "data"
  top: "B0_0_ConvBNScaleReLU_Conv"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "B0_0_ConvBNScaleReLU_BN"
  type: "BatchNorm"
  bottom: "B0_0_ConvBNScaleReLU_Conv"
  top: "B0_0_ConvBNScaleReLU_Conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.999
    eps: 0.001
  }
}
layer {
  name: "B0_0_ConvBNScaleReLU_Scale"
  type: "Scale"
  bottom: "B0_0_ConvBNScaleReLU_Conv"
  top: "B0_0_ConvBNScaleReLU_Conv"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
    l1_lambda: 0
  }
}
layer {
  name: "B0_0_ConvBNScaleReLU_ReLU"
  type: "ReLU"
  bottom: "B0_0_ConvBNScaleReLU_Conv"
  top: "B0_0_ConvBNScaleReLU_Conv"
}
layer {
  name: "B0_0_ConvBNScaleReLU_Dropout"
  type: "Dropout"
  bottom: "B0_0_ConvBNScaleReLU_Conv"
  top: "ConvBNScaleReLU"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "B0_1_SConv_SparseConv"
  type: "SparseConvolution"
  bottom: "ConvBNScaleReLU"
  top: "B0_1_SConvBlockV2_T1"
  sparse_convolution_param {
    weight_filler {
      type: "xavier"
    }
    channel_expand_multiplier: 8
  }
}
layer {
  name: "B0_1_SConv_BN"
  type: "BatchNorm"
  bottom: "B0_1_SConvBlockV2_T1"
  top: "B0_1_SConvBlockV2_T1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.999
    eps: 0.001
  }
}
layer {
  name: "B0_1_SConv_Scale"
  type: "Scale"
  bottom: "B0_1_SConvBlockV2_T1"
  top: "B0_1_SConvBlockV2_Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "B0_1_SConv_Conv1x1"
  type: "Convolution"
  bottom: "B0_1_SConvBlockV2_Scale"
  top: "B0_1_SConvBlockV2_Conv1x1"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "B0_1_SConv_ReLU"
  type: "ReLU"
  bottom: "B0_1_SConvBlockV2_Conv1x1"
  top: "B0_1_SConvBlockV2_Conv1x1"
}
layer {
  name: "B0_1_SConv_Dropout"
  type: "Dropout"
  bottom: "B0_1_SConvBlockV2_Conv1x1"
  top: "B0_1_SConvBlockV2_Dropout"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "B0_Pooling"
  type: "Pooling"
  bottom: "B0_1_SConvBlockV2_Dropout"
  top: "Pooling1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "B1_0_SConv_SparseConv"
  type: "SparseConvolution"
  bottom: "Pooling1"
  top: "B1_0_SConvBlockV2_T1"
  sparse_convolution_param {
    weight_filler {
      type: "xavier"
    }
    channel_expand_multiplier: 8
  }
}
layer {
  name: "B1_0_SConv_BN"
  type: "BatchNorm"
  bottom: "B1_0_SConvBlockV2_T1"
  top: "B1_0_SConvBlockV2_T1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.999
    eps: 0.001
  }
}
layer {
  name: "B1_0_SConv_Scale"
  type: "Scale"
  bottom: "B1_0_SConvBlockV2_T1"
  top: "B1_0_SConvBlockV2_Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "B1_0_SConv_Conv1x1"
  type: "Convolution"
  bottom: "B1_0_SConvBlockV2_Scale"
  top: "B1_0_SConvBlockV2_Conv1x1"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "B1_0_SConv_ReLU"
  type: "ReLU"
  bottom: "B1_0_SConvBlockV2_Conv1x1"
  top: "B1_0_SConvBlockV2_Conv1x1"
}
layer {
  name: "B1_0_SConv_Dropout"
  type: "Dropout"
  bottom: "B1_0_SConvBlockV2_Conv1x1"
  top: "B1_0_SConvBlockV2_Dropout"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "B1_1_SConv_SparseConv"
  type: "SparseConvolution"
  bottom: "B1_0_SConvBlockV2_Dropout"
  top: "B1_1_SConvBlockV2_T1"
  sparse_convolution_param {
    weight_filler {
      type: "xavier"
    }
    channel_expand_multiplier: 8
  }
}
layer {
  name: "B1_1_SConv_BN"
  type: "BatchNorm"
  bottom: "B1_1_SConvBlockV2_T1"
  top: "B1_1_SConvBlockV2_T1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.999
    eps: 0.001
  }
}
layer {
  name: "B1_1_SConv_Scale"
  type: "Scale"
  bottom: "B1_1_SConvBlockV2_T1"
  top: "B1_1_SConvBlockV2_Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "B1_1_SConv_Conv1x1"
  type: "Convolution"
  bottom: "B1_1_SConvBlockV2_Scale"
  top: "B1_1_SConvBlockV2_Conv1x1"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "B1_1_SConv_ReLU"
  type: "ReLU"
  bottom: "B1_1_SConvBlockV2_Conv1x1"
  top: "B1_1_SConvBlockV2_Conv1x1"
}
layer {
  name: "B1_1_SConv_Dropout"
  type: "Dropout"
  bottom: "B1_1_SConvBlockV2_Conv1x1"
  top: "B1_1_SConvBlockV2_Dropout"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "B1_Pooling"
  type: "Pooling"
  bottom: "B1_1_SConvBlockV2_Dropout"
  top: "Pooling2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "B2_0_SConv_SparseConv"
  type: "SparseConvolution"
  bottom: "Pooling2"
  top: "B2_0_SConvBlockV2_T1"
  sparse_convolution_param {
    weight_filler {
      type: "xavier"
    }
    channel_expand_multiplier: 8
  }
}
layer {
  name: "B2_0_SConv_BN"
  type: "BatchNorm"
  bottom: "B2_0_SConvBlockV2_T1"
  top: "B2_0_SConvBlockV2_T1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.999
    eps: 0.001
  }
}
layer {
  name: "B2_0_SConv_Scale"
  type: "Scale"
  bottom: "B2_0_SConvBlockV2_T1"
  top: "B2_0_SConvBlockV2_Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "B2_0_SConv_Conv1x1"
  type: "Convolution"
  bottom: "B2_0_SConvBlockV2_Scale"
  top: "B2_0_SConvBlockV2_Conv1x1"
  convolution_param {
    num_output: 192
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "B2_0_SConv_ReLU"
  type: "ReLU"
  bottom: "B2_0_SConvBlockV2_Conv1x1"
  top: "B2_0_SConvBlockV2_Conv1x1"
}
layer {
  name: "B2_0_SConv_Dropout"
  type: "Dropout"
  bottom: "B2_0_SConvBlockV2_Conv1x1"
  top: "B2_0_SConvBlockV2_Dropout"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "B2_1_SConv_SparseConv"
  type: "SparseConvolution"
  bottom: "B2_0_SConvBlockV2_Dropout"
  top: "B2_1_SConvBlockV2_T1"
  sparse_convolution_param {
    weight_filler {
      type: "xavier"
    }
    channel_expand_multiplier: 8
  }
}
layer {
  name: "B2_1_SConv_BN"
  type: "BatchNorm"
  bottom: "B2_1_SConvBlockV2_T1"
  top: "B2_1_SConvBlockV2_T1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.999
    eps: 0.001
  }
}
layer {
  name: "B2_1_SConv_Scale"
  type: "Scale"
  bottom: "B2_1_SConvBlockV2_T1"
  top: "B2_1_SConvBlockV2_Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "B2_1_SConv_Conv1x1"
  type: "Convolution"
  bottom: "B2_1_SConvBlockV2_Scale"
  top: "B2_1_SConvBlockV2_Conv1x1"
  convolution_param {
    num_output: 192
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "B2_1_SConv_ReLU"
  type: "ReLU"
  bottom: "B2_1_SConvBlockV2_Conv1x1"
  top: "B2_1_SConvBlockV2_Conv1x1"
}
layer {
  name: "B2_1_SConv_Dropout"
  type: "Dropout"
  bottom: "B2_1_SConvBlockV2_Conv1x1"
  top: "B2_1_SConvBlockV2_Dropout"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "B2_2_SConv_SparseConv"
  type: "SparseConvolution"
  bottom: "B2_1_SConvBlockV2_Dropout"
  top: "B2_2_SConvBlockV2_T1"
  sparse_convolution_param {
    weight_filler {
      type: "xavier"
    }
    channel_expand_multiplier: 8
  }
}
layer {
  name: "B2_2_SConv_BN"
  type: "BatchNorm"
  bottom: "B2_2_SConvBlockV2_T1"
  top: "B2_2_SConvBlockV2_T1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.999
    eps: 0.001
  }
}
layer {
  name: "B2_2_SConv_Scale"
  type: "Scale"
  bottom: "B2_2_SConvBlockV2_T1"
  top: "B2_2_SConvBlockV2_Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "B2_2_SConv_Conv1x1"
  type: "Convolution"
  bottom: "B2_2_SConvBlockV2_Scale"
  top: "B2_2_SConvBlockV2_Conv1x1"
  convolution_param {
    num_output: 192
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "B2_2_SConv_ReLU"
  type: "ReLU"
  bottom: "B2_2_SConvBlockV2_Conv1x1"
  top: "B2_2_SConvBlockV2_Conv1x1"
}
layer {
  name: "B2_2_SConv_Dropout"
  type: "Dropout"
  bottom: "B2_2_SConvBlockV2_Conv1x1"
  top: "B2_2_SConvBlockV2_Dropout"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "B2_Pooling"
  type: "Pooling"
  bottom: "B2_2_SConvBlockV2_Dropout"
  top: "Pooling3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "B3_0_SConv_SparseConv"
  type: "SparseConvolution"
  bottom: "Pooling3"
  top: "B3_0_SConvBlockV2_T1"
  sparse_convolution_param {
    weight_filler {
      type: "xavier"
    }
    channel_expand_multiplier: 8
  }
}
layer {
  name: "B3_0_SConv_BN"
  type: "BatchNorm"
  bottom: "B3_0_SConvBlockV2_T1"
  top: "B3_0_SConvBlockV2_T1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.999
    eps: 0.001
  }
}
layer {
  name: "B3_0_SConv_Scale"
  type: "Scale"
  bottom: "B3_0_SConvBlockV2_T1"
  top: "B3_0_SConvBlockV2_Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "B3_0_SConv_Conv1x1"
  type: "Convolution"
  bottom: "B3_0_SConvBlockV2_Scale"
  top: "B3_0_SConvBlockV2_Conv1x1"
  convolution_param {
    num_output: 192
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "B3_0_SConv_ReLU"
  type: "ReLU"
  bottom: "B3_0_SConvBlockV2_Conv1x1"
  top: "B3_0_SConvBlockV2_Conv1x1"
}
layer {
  name: "B3_0_SConv_Dropout"
  type: "Dropout"
  bottom: "B3_0_SConvBlockV2_Conv1x1"
  top: "B3_0_SConvBlockV2_Dropout"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "B3_1_SConv_SparseConv"
  type: "SparseConvolution"
  bottom: "B3_0_SConvBlockV2_Dropout"
  top: "B3_1_SConvBlockV2_T1"
  sparse_convolution_param {
    weight_filler {
      type: "xavier"
    }
    channel_expand_multiplier: 8
  }
}
layer {
  name: "B3_1_SConv_BN"
  type: "BatchNorm"
  bottom: "B3_1_SConvBlockV2_T1"
  top: "B3_1_SConvBlockV2_T1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.999
    eps: 0.001
  }
}
layer {
  name: "B3_1_SConv_Scale"
  type: "Scale"
  bottom: "B3_1_SConvBlockV2_T1"
  top: "B3_1_SConvBlockV2_Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "B3_1_SConv_Conv1x1"
  type: "Convolution"
  bottom: "B3_1_SConvBlockV2_Scale"
  top: "B3_1_SConvBlockV2_Conv1x1"
  convolution_param {
    num_output: 192
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "B3_1_SConv_ReLU"
  type: "ReLU"
  bottom: "B3_1_SConvBlockV2_Conv1x1"
  top: "B3_1_SConvBlockV2_Conv1x1"
}
layer {
  name: "B3_1_SConv_Dropout"
  type: "Dropout"
  bottom: "B3_1_SConvBlockV2_Conv1x1"
  top: "B3_1_SConvBlockV2_Dropout"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "B3_2_SConv_SparseConv"
  type: "SparseConvolution"
  bottom: "B3_1_SConvBlockV2_Dropout"
  top: "B3_2_SConvBlockV2_T1"
  sparse_convolution_param {
    weight_filler {
      type: "xavier"
    }
    channel_expand_multiplier: 8
  }
}
layer {
  name: "B3_2_SConv_BN"
  type: "BatchNorm"
  bottom: "B3_2_SConvBlockV2_T1"
  top: "B3_2_SConvBlockV2_T1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.999
    eps: 0.001
  }
}
layer {
  name: "B3_2_SConv_Scale"
  type: "Scale"
  bottom: "B3_2_SConvBlockV2_T1"
  top: "B3_2_SConvBlockV2_Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "B3_2_SConv_Conv1x1"
  type: "Convolution"
  bottom: "B3_2_SConvBlockV2_Scale"
  top: "B3_2_SConvBlockV2_Conv1x1"
  convolution_param {
    num_output: 192
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "B3_2_SConv_ReLU"
  type: "ReLU"
  bottom: "B3_2_SConvBlockV2_Conv1x1"
  top: "B3_2_SConvBlockV2_Conv1x1"
}
layer {
  name: "B3_2_SConv_Dropout"
  type: "Dropout"
  bottom: "B3_2_SConvBlockV2_Conv1x1"
  top: "B3_2_SConvBlockV2_Dropout"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "B3_Pooling"
  type: "Pooling"
  bottom: "B3_2_SConvBlockV2_Dropout"
  top: "Pooling4"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "Pooling4"
  top: "fc1"
  inner_product_param {
    num_output: 384
    bias_term: true
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "classifier"
  type: "InnerProduct"
  bottom: "fc1"
  top: "classifier"
  inner_product_param {
    num_output: 10
    bias_term: true
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "softmax_loss"
  type: "SoftmaxWithLoss"
  bottom: "classifier"
  bottom: "label"
  top: "softmax_loss"
}
I0829 09:22:54.232755 916722 layer_factory.hpp:77] Creating layer InputData
I0829 09:22:54.232805 916722 net.cpp:84] Creating Layer InputData
I0829 09:22:54.232815 916722 net.cpp:380] InputData -> data
I0829 09:22:54.232856 916722 net.cpp:380] InputData -> label
I0829 09:22:54.232877 916722 image_data_layer.cpp:38] Opening file /home/jcwang/work/1.CIFAR10/train.txt
I0829 09:22:54.241921 916722 image_data_layer.cpp:53] Shuffling data
I0829 09:22:54.242720 916722 image_data_layer.cpp:63] A total of 50005 images.
I0829 09:22:54.243888 916722 image_data_layer.cpp:90] output data size: 32,3,32,32
I0829 09:22:54.244359 916722 net.cpp:122] Setting up InputData
I0829 09:22:54.244371 916722 net.cpp:129] Top shape: 32 3 32 32 (98304)
I0829 09:22:54.244379 916722 net.cpp:129] Top shape: 32 (32)
I0829 09:22:54.244385 916722 net.cpp:137] Memory required for data: 393344
I0829 09:22:54.244390 916722 layer_factory.hpp:77] Creating layer B0_0_ConvBNScaleReLU_Conv
I0829 09:22:54.244410 916722 net.cpp:84] Creating Layer B0_0_ConvBNScaleReLU_Conv
I0829 09:22:54.244416 916722 net.cpp:406] B0_0_ConvBNScaleReLU_Conv <- data
I0829 09:22:54.244450 916722 net.cpp:380] B0_0_ConvBNScaleReLU_Conv -> B0_0_ConvBNScaleReLU_Conv
I0829 09:22:54.244707 916722 net.cpp:122] Setting up B0_0_ConvBNScaleReLU_Conv
I0829 09:22:54.244717 916722 net.cpp:129] Top shape: 32 64 32 32 (2097152)
I0829 09:22:54.244724 916722 net.cpp:137] Memory required for data: 8781952
I0829 09:22:54.244736 916722 layer_factory.hpp:77] Creating layer B0_0_ConvBNScaleReLU_BN
I0829 09:22:54.244750 916722 net.cpp:84] Creating Layer B0_0_ConvBNScaleReLU_BN
I0829 09:22:54.244755 916722 net.cpp:406] B0_0_ConvBNScaleReLU_BN <- B0_0_ConvBNScaleReLU_Conv
I0829 09:22:54.244760 916722 net.cpp:367] B0_0_ConvBNScaleReLU_BN -> B0_0_ConvBNScaleReLU_Conv (in-place)
I0829 09:22:54.244901 916722 net.cpp:122] Setting up B0_0_ConvBNScaleReLU_BN
I0829 09:22:54.244908 916722 net.cpp:129] Top shape: 32 64 32 32 (2097152)
I0829 09:22:54.244913 916722 net.cpp:137] Memory required for data: 17170560
I0829 09:22:54.244922 916722 layer_factory.hpp:77] Creating layer B0_0_ConvBNScaleReLU_Scale
I0829 09:22:54.244930 916722 net.cpp:84] Creating Layer B0_0_ConvBNScaleReLU_Scale
I0829 09:22:54.244935 916722 net.cpp:406] B0_0_ConvBNScaleReLU_Scale <- B0_0_ConvBNScaleReLU_Conv
I0829 09:22:54.244940 916722 net.cpp:367] B0_0_ConvBNScaleReLU_Scale -> B0_0_ConvBNScaleReLU_Conv (in-place)
I0829 09:22:54.244974 916722 layer_factory.hpp:77] Creating layer B0_0_ConvBNScaleReLU_Scale
I0829 09:22:54.245069 916722 net.cpp:122] Setting up B0_0_ConvBNScaleReLU_Scale
I0829 09:22:54.245076 916722 net.cpp:129] Top shape: 32 64 32 32 (2097152)
I0829 09:22:54.245082 916722 net.cpp:137] Memory required for data: 25559168
I0829 09:22:54.245090 916722 layer_factory.hpp:77] Creating layer B0_0_ConvBNScaleReLU_ReLU
I0829 09:22:54.245098 916722 net.cpp:84] Creating Layer B0_0_ConvBNScaleReLU_ReLU
I0829 09:22:54.245102 916722 net.cpp:406] B0_0_ConvBNScaleReLU_ReLU <- B0_0_ConvBNScaleReLU_Conv
I0829 09:22:54.245107 916722 net.cpp:367] B0_0_ConvBNScaleReLU_ReLU -> B0_0_ConvBNScaleReLU_Conv (in-place)
I0829 09:22:54.245115 916722 net.cpp:122] Setting up B0_0_ConvBNScaleReLU_ReLU
I0829 09:22:54.245118 916722 net.cpp:129] Top shape: 32 64 32 32 (2097152)
I0829 09:22:54.245123 916722 net.cpp:137] Memory required for data: 33947776
I0829 09:22:54.245127 916722 layer_factory.hpp:77] Creating layer B0_0_ConvBNScaleReLU_Dropout
I0829 09:22:54.245139 916722 net.cpp:84] Creating Layer B0_0_ConvBNScaleReLU_Dropout
I0829 09:22:54.245144 916722 net.cpp:406] B0_0_ConvBNScaleReLU_Dropout <- B0_0_ConvBNScaleReLU_Conv
I0829 09:22:54.245149 916722 net.cpp:380] B0_0_ConvBNScaleReLU_Dropout -> ConvBNScaleReLU
I0829 09:22:54.245182 916722 net.cpp:122] Setting up B0_0_ConvBNScaleReLU_Dropout
I0829 09:22:54.245187 916722 net.cpp:129] Top shape: 32 64 32 32 (2097152)
I0829 09:22:54.245193 916722 net.cpp:137] Memory required for data: 42336384
I0829 09:22:54.245203 916722 layer_factory.hpp:77] Creating layer B0_1_SConv_SparseConv
I0829 09:22:54.245223 916722 net.cpp:84] Creating Layer B0_1_SConv_SparseConv
I0829 09:22:54.245229 916722 net.cpp:406] B0_1_SConv_SparseConv <- ConvBNScaleReLU
I0829 09:22:54.245236 916722 net.cpp:380] B0_1_SConv_SparseConv -> B0_1_SConvBlockV2_T1
I0829 09:22:54.245357 916722 net.cpp:122] Setting up B0_1_SConv_SparseConv
I0829 09:22:54.245363 916722 net.cpp:129] Top shape: 32 512 32 32 (16777216)
I0829 09:22:54.245369 916722 net.cpp:137] Memory required for data: 109445248
I0829 09:22:54.245374 916722 layer_factory.hpp:77] Creating layer B0_1_SConv_BN
I0829 09:22:54.245383 916722 net.cpp:84] Creating Layer B0_1_SConv_BN
I0829 09:22:54.245388 916722 net.cpp:406] B0_1_SConv_BN <- B0_1_SConvBlockV2_T1
I0829 09:22:54.245395 916722 net.cpp:367] B0_1_SConv_BN -> B0_1_SConvBlockV2_T1 (in-place)
I0829 09:22:54.245512 916722 net.cpp:122] Setting up B0_1_SConv_BN
I0829 09:22:54.245519 916722 net.cpp:129] Top shape: 32 512 32 32 (16777216)
I0829 09:22:54.245524 916722 net.cpp:137] Memory required for data: 176554112
I0829 09:22:54.245532 916722 layer_factory.hpp:77] Creating layer B0_1_SConv_Scale
I0829 09:22:54.245538 916722 net.cpp:84] Creating Layer B0_1_SConv_Scale
I0829 09:22:54.245543 916722 net.cpp:406] B0_1_SConv_Scale <- B0_1_SConvBlockV2_T1
I0829 09:22:54.245548 916722 net.cpp:380] B0_1_SConv_Scale -> B0_1_SConvBlockV2_Scale
I0829 09:22:54.245580 916722 layer_factory.hpp:77] Creating layer B0_1_SConv_Scale
I0829 09:22:54.245656 916722 net.cpp:122] Setting up B0_1_SConv_Scale
I0829 09:22:54.245663 916722 net.cpp:129] Top shape: 32 512 32 32 (16777216)
I0829 09:22:54.245674 916722 net.cpp:137] Memory required for data: 243662976
I0829 09:22:54.245680 916722 layer_factory.hpp:77] Creating layer B0_1_SConv_Conv1x1
I0829 09:22:54.245692 916722 net.cpp:84] Creating Layer B0_1_SConv_Conv1x1
I0829 09:22:54.245697 916722 net.cpp:406] B0_1_SConv_Conv1x1 <- B0_1_SConvBlockV2_Scale
I0829 09:22:54.245702 916722 net.cpp:380] B0_1_SConv_Conv1x1 -> B0_1_SConvBlockV2_Conv1x1
I0829 09:22:54.245992 916722 net.cpp:122] Setting up B0_1_SConv_Conv1x1
I0829 09:22:54.246001 916722 net.cpp:129] Top shape: 32 64 32 32 (2097152)
I0829 09:22:54.246006 916722 net.cpp:137] Memory required for data: 252051584
I0829 09:22:54.246012 916722 layer_factory.hpp:77] Creating layer B0_1_SConv_ReLU
I0829 09:22:54.246021 916722 net.cpp:84] Creating Layer B0_1_SConv_ReLU
I0829 09:22:54.246026 916722 net.cpp:406] B0_1_SConv_ReLU <- B0_1_SConvBlockV2_Conv1x1
I0829 09:22:54.246030 916722 net.cpp:367] B0_1_SConv_ReLU -> B0_1_SConvBlockV2_Conv1x1 (in-place)
I0829 09:22:54.246037 916722 net.cpp:122] Setting up B0_1_SConv_ReLU
I0829 09:22:54.246040 916722 net.cpp:129] Top shape: 32 64 32 32 (2097152)
I0829 09:22:54.246045 916722 net.cpp:137] Memory required for data: 260440192
I0829 09:22:54.246050 916722 layer_factory.hpp:77] Creating layer B0_1_SConv_Dropout
I0829 09:22:54.246057 916722 net.cpp:84] Creating Layer B0_1_SConv_Dropout
I0829 09:22:54.246060 916722 net.cpp:406] B0_1_SConv_Dropout <- B0_1_SConvBlockV2_Conv1x1
I0829 09:22:54.246069 916722 net.cpp:380] B0_1_SConv_Dropout -> B0_1_SConvBlockV2_Dropout
I0829 09:22:54.246095 916722 net.cpp:122] Setting up B0_1_SConv_Dropout
I0829 09:22:54.246101 916722 net.cpp:129] Top shape: 32 64 32 32 (2097152)
I0829 09:22:54.246106 916722 net.cpp:137] Memory required for data: 268828800
I0829 09:22:54.246110 916722 layer_factory.hpp:77] Creating layer B0_Pooling
I0829 09:22:54.246117 916722 net.cpp:84] Creating Layer B0_Pooling
I0829 09:22:54.246122 916722 net.cpp:406] B0_Pooling <- B0_1_SConvBlockV2_Dropout
I0829 09:22:54.246129 916722 net.cpp:380] B0_Pooling -> Pooling1
I0829 09:22:54.246156 916722 net.cpp:122] Setting up B0_Pooling
I0829 09:22:54.246162 916722 net.cpp:129] Top shape: 32 64 16 16 (524288)
I0829 09:22:54.246167 916722 net.cpp:137] Memory required for data: 270925952
I0829 09:22:54.246171 916722 layer_factory.hpp:77] Creating layer B1_0_SConv_SparseConv
I0829 09:22:54.246182 916722 net.cpp:84] Creating Layer B1_0_SConv_SparseConv
I0829 09:22:54.246191 916722 net.cpp:406] B1_0_SConv_SparseConv <- Pooling1
I0829 09:22:54.246203 916722 net.cpp:380] B1_0_SConv_SparseConv -> B1_0_SConvBlockV2_T1
I0829 09:22:54.246299 916722 net.cpp:122] Setting up B1_0_SConv_SparseConv
I0829 09:22:54.246304 916722 net.cpp:129] Top shape: 32 512 16 16 (4194304)
I0829 09:22:54.246310 916722 net.cpp:137] Memory required for data: 287703168
I0829 09:22:54.246315 916722 layer_factory.hpp:77] Creating layer B1_0_SConv_BN
I0829 09:22:54.246322 916722 net.cpp:84] Creating Layer B1_0_SConv_BN
I0829 09:22:54.246327 916722 net.cpp:406] B1_0_SConv_BN <- B1_0_SConvBlockV2_T1
I0829 09:22:54.246333 916722 net.cpp:367] B1_0_SConv_BN -> B1_0_SConvBlockV2_T1 (in-place)
I0829 09:22:54.246412 916722 net.cpp:122] Setting up B1_0_SConv_BN
I0829 09:22:54.246417 916722 net.cpp:129] Top shape: 32 512 16 16 (4194304)
I0829 09:22:54.246423 916722 net.cpp:137] Memory required for data: 304480384
I0829 09:22:54.246430 916722 layer_factory.hpp:77] Creating layer B1_0_SConv_Scale
I0829 09:22:54.246440 916722 net.cpp:84] Creating Layer B1_0_SConv_Scale
I0829 09:22:54.246444 916722 net.cpp:406] B1_0_SConv_Scale <- B1_0_SConvBlockV2_T1
I0829 09:22:54.246450 916722 net.cpp:380] B1_0_SConv_Scale -> B1_0_SConvBlockV2_Scale
I0829 09:22:54.246474 916722 layer_factory.hpp:77] Creating layer B1_0_SConv_Scale
I0829 09:22:54.246546 916722 net.cpp:122] Setting up B1_0_SConv_Scale
I0829 09:22:54.246552 916722 net.cpp:129] Top shape: 32 512 16 16 (4194304)
I0829 09:22:54.246557 916722 net.cpp:137] Memory required for data: 321257600
I0829 09:22:54.246563 916722 layer_factory.hpp:77] Creating layer B1_0_SConv_Conv1x1
I0829 09:22:54.246573 916722 net.cpp:84] Creating Layer B1_0_SConv_Conv1x1
I0829 09:22:54.246580 916722 net.cpp:406] B1_0_SConv_Conv1x1 <- B1_0_SConvBlockV2_Scale
I0829 09:22:54.246587 916722 net.cpp:380] B1_0_SConv_Conv1x1 -> B1_0_SConvBlockV2_Conv1x1
I0829 09:22:54.247987 916722 net.cpp:122] Setting up B1_0_SConv_Conv1x1
I0829 09:22:54.248001 916722 net.cpp:129] Top shape: 32 128 16 16 (1048576)
I0829 09:22:54.248008 916722 net.cpp:137] Memory required for data: 325451904
I0829 09:22:54.248014 916722 layer_factory.hpp:77] Creating layer B1_0_SConv_ReLU
I0829 09:22:54.248023 916722 net.cpp:84] Creating Layer B1_0_SConv_ReLU
I0829 09:22:54.248028 916722 net.cpp:406] B1_0_SConv_ReLU <- B1_0_SConvBlockV2_Conv1x1
I0829 09:22:54.248034 916722 net.cpp:367] B1_0_SConv_ReLU -> B1_0_SConvBlockV2_Conv1x1 (in-place)
I0829 09:22:54.248041 916722 net.cpp:122] Setting up B1_0_SConv_ReLU
I0829 09:22:54.248045 916722 net.cpp:129] Top shape: 32 128 16 16 (1048576)
I0829 09:22:54.248050 916722 net.cpp:137] Memory required for data: 329646208
I0829 09:22:54.248054 916722 layer_factory.hpp:77] Creating layer B1_0_SConv_Dropout
I0829 09:22:54.248061 916722 net.cpp:84] Creating Layer B1_0_SConv_Dropout
I0829 09:22:54.248065 916722 net.cpp:406] B1_0_SConv_Dropout <- B1_0_SConvBlockV2_Conv1x1
I0829 09:22:54.248070 916722 net.cpp:380] B1_0_SConv_Dropout -> B1_0_SConvBlockV2_Dropout
I0829 09:22:54.248327 916722 net.cpp:122] Setting up B1_0_SConv_Dropout
I0829 09:22:54.248334 916722 net.cpp:129] Top shape: 32 128 16 16 (1048576)
I0829 09:22:54.248339 916722 net.cpp:137] Memory required for data: 333840512
I0829 09:22:54.248343 916722 layer_factory.hpp:77] Creating layer B1_1_SConv_SparseConv
I0829 09:22:54.248353 916722 net.cpp:84] Creating Layer B1_1_SConv_SparseConv
I0829 09:22:54.248358 916722 net.cpp:406] B1_1_SConv_SparseConv <- B1_0_SConvBlockV2_Dropout
I0829 09:22:54.248363 916722 net.cpp:380] B1_1_SConv_SparseConv -> B1_1_SConvBlockV2_T1
I0829 09:22:54.248500 916722 net.cpp:122] Setting up B1_1_SConv_SparseConv
I0829 09:22:54.248509 916722 net.cpp:129] Top shape: 32 1024 16 16 (8388608)
I0829 09:22:54.248515 916722 net.cpp:137] Memory required for data: 367394944
I0829 09:22:54.248520 916722 layer_factory.hpp:77] Creating layer B1_1_SConv_BN
I0829 09:22:54.248529 916722 net.cpp:84] Creating Layer B1_1_SConv_BN
I0829 09:22:54.248534 916722 net.cpp:406] B1_1_SConv_BN <- B1_1_SConvBlockV2_T1
I0829 09:22:54.248540 916722 net.cpp:367] B1_1_SConv_BN -> B1_1_SConvBlockV2_T1 (in-place)
I0829 09:22:54.248629 916722 net.cpp:122] Setting up B1_1_SConv_BN
I0829 09:22:54.248636 916722 net.cpp:129] Top shape: 32 1024 16 16 (8388608)
I0829 09:22:54.248642 916722 net.cpp:137] Memory required for data: 400949376
I0829 09:22:54.248648 916722 layer_factory.hpp:77] Creating layer B1_1_SConv_Scale
I0829 09:22:54.248654 916722 net.cpp:84] Creating Layer B1_1_SConv_Scale
I0829 09:22:54.248659 916722 net.cpp:406] B1_1_SConv_Scale <- B1_1_SConvBlockV2_T1
I0829 09:22:54.248664 916722 net.cpp:380] B1_1_SConv_Scale -> B1_1_SConvBlockV2_Scale
I0829 09:22:54.248688 916722 layer_factory.hpp:77] Creating layer B1_1_SConv_Scale
I0829 09:22:54.248742 916722 net.cpp:122] Setting up B1_1_SConv_Scale
I0829 09:22:54.248749 916722 net.cpp:129] Top shape: 32 1024 16 16 (8388608)
I0829 09:22:54.248754 916722 net.cpp:137] Memory required for data: 434503808
I0829 09:22:54.248760 916722 layer_factory.hpp:77] Creating layer B1_1_SConv_Conv1x1
I0829 09:22:54.248769 916722 net.cpp:84] Creating Layer B1_1_SConv_Conv1x1
I0829 09:22:54.248775 916722 net.cpp:406] B1_1_SConv_Conv1x1 <- B1_1_SConvBlockV2_Scale
I0829 09:22:54.248780 916722 net.cpp:380] B1_1_SConv_Conv1x1 -> B1_1_SConvBlockV2_Conv1x1
I0829 09:22:54.249527 916722 net.cpp:122] Setting up B1_1_SConv_Conv1x1
I0829 09:22:54.249536 916722 net.cpp:129] Top shape: 32 128 16 16 (1048576)
I0829 09:22:54.249541 916722 net.cpp:137] Memory required for data: 438698112
I0829 09:22:54.249547 916722 layer_factory.hpp:77] Creating layer B1_1_SConv_ReLU
I0829 09:22:54.249552 916722 net.cpp:84] Creating Layer B1_1_SConv_ReLU
I0829 09:22:54.249557 916722 net.cpp:406] B1_1_SConv_ReLU <- B1_1_SConvBlockV2_Conv1x1
I0829 09:22:54.249562 916722 net.cpp:367] B1_1_SConv_ReLU -> B1_1_SConvBlockV2_Conv1x1 (in-place)
I0829 09:22:54.249568 916722 net.cpp:122] Setting up B1_1_SConv_ReLU
I0829 09:22:54.249573 916722 net.cpp:129] Top shape: 32 128 16 16 (1048576)
I0829 09:22:54.249578 916722 net.cpp:137] Memory required for data: 442892416
I0829 09:22:54.249583 916722 layer_factory.hpp:77] Creating layer B1_1_SConv_Dropout
I0829 09:22:54.249589 916722 net.cpp:84] Creating Layer B1_1_SConv_Dropout
I0829 09:22:54.249594 916722 net.cpp:406] B1_1_SConv_Dropout <- B1_1_SConvBlockV2_Conv1x1
I0829 09:22:54.249599 916722 net.cpp:380] B1_1_SConv_Dropout -> B1_1_SConvBlockV2_Dropout
I0829 09:22:54.249632 916722 net.cpp:122] Setting up B1_1_SConv_Dropout
I0829 09:22:54.249639 916722 net.cpp:129] Top shape: 32 128 16 16 (1048576)
I0829 09:22:54.249644 916722 net.cpp:137] Memory required for data: 447086720
I0829 09:22:54.249648 916722 layer_factory.hpp:77] Creating layer B1_Pooling
I0829 09:22:54.249655 916722 net.cpp:84] Creating Layer B1_Pooling
I0829 09:22:54.249660 916722 net.cpp:406] B1_Pooling <- B1_1_SConvBlockV2_Dropout
I0829 09:22:54.249667 916722 net.cpp:380] B1_Pooling -> Pooling2
I0829 09:22:54.249687 916722 net.cpp:122] Setting up B1_Pooling
I0829 09:22:54.249693 916722 net.cpp:129] Top shape: 32 128 8 8 (262144)
I0829 09:22:54.249698 916722 net.cpp:137] Memory required for data: 448135296
I0829 09:22:54.249702 916722 layer_factory.hpp:77] Creating layer B2_0_SConv_SparseConv
I0829 09:22:54.249711 916722 net.cpp:84] Creating Layer B2_0_SConv_SparseConv
I0829 09:22:54.249716 916722 net.cpp:406] B2_0_SConv_SparseConv <- Pooling2
I0829 09:22:54.249720 916722 net.cpp:380] B2_0_SConv_SparseConv -> B2_0_SConvBlockV2_T1
I0829 09:22:54.249902 916722 net.cpp:122] Setting up B2_0_SConv_SparseConv
I0829 09:22:54.249910 916722 net.cpp:129] Top shape: 32 1024 8 8 (2097152)
I0829 09:22:54.249917 916722 net.cpp:137] Memory required for data: 456523904
I0829 09:22:54.249922 916722 layer_factory.hpp:77] Creating layer B2_0_SConv_BN
I0829 09:22:54.249928 916722 net.cpp:84] Creating Layer B2_0_SConv_BN
I0829 09:22:54.249933 916722 net.cpp:406] B2_0_SConv_BN <- B2_0_SConvBlockV2_T1
I0829 09:22:54.249941 916722 net.cpp:367] B2_0_SConv_BN -> B2_0_SConvBlockV2_T1 (in-place)
I0829 09:22:54.250025 916722 net.cpp:122] Setting up B2_0_SConv_BN
I0829 09:22:54.250033 916722 net.cpp:129] Top shape: 32 1024 8 8 (2097152)
I0829 09:22:54.250043 916722 net.cpp:137] Memory required for data: 464912512
I0829 09:22:54.250058 916722 layer_factory.hpp:77] Creating layer B2_0_SConv_Scale
I0829 09:22:54.250064 916722 net.cpp:84] Creating Layer B2_0_SConv_Scale
I0829 09:22:54.250069 916722 net.cpp:406] B2_0_SConv_Scale <- B2_0_SConvBlockV2_T1
I0829 09:22:54.250077 916722 net.cpp:380] B2_0_SConv_Scale -> B2_0_SConvBlockV2_Scale
I0829 09:22:54.250102 916722 layer_factory.hpp:77] Creating layer B2_0_SConv_Scale
I0829 09:22:54.250156 916722 net.cpp:122] Setting up B2_0_SConv_Scale
I0829 09:22:54.250164 916722 net.cpp:129] Top shape: 32 1024 8 8 (2097152)
I0829 09:22:54.250169 916722 net.cpp:137] Memory required for data: 473301120
I0829 09:22:54.250174 916722 layer_factory.hpp:77] Creating layer B2_0_SConv_Conv1x1
I0829 09:22:54.250185 916722 net.cpp:84] Creating Layer B2_0_SConv_Conv1x1
I0829 09:22:54.250191 916722 net.cpp:406] B2_0_SConv_Conv1x1 <- B2_0_SConvBlockV2_Scale
I0829 09:22:54.250196 916722 net.cpp:380] B2_0_SConv_Conv1x1 -> B2_0_SConvBlockV2_Conv1x1
I0829 09:22:54.251272 916722 net.cpp:122] Setting up B2_0_SConv_Conv1x1
I0829 09:22:54.251281 916722 net.cpp:129] Top shape: 32 192 8 8 (393216)
I0829 09:22:54.251287 916722 net.cpp:137] Memory required for data: 474873984
I0829 09:22:54.251292 916722 layer_factory.hpp:77] Creating layer B2_0_SConv_ReLU
I0829 09:22:54.251298 916722 net.cpp:84] Creating Layer B2_0_SConv_ReLU
I0829 09:22:54.251303 916722 net.cpp:406] B2_0_SConv_ReLU <- B2_0_SConvBlockV2_Conv1x1
I0829 09:22:54.251312 916722 net.cpp:367] B2_0_SConv_ReLU -> B2_0_SConvBlockV2_Conv1x1 (in-place)
I0829 09:22:54.251317 916722 net.cpp:122] Setting up B2_0_SConv_ReLU
I0829 09:22:54.251322 916722 net.cpp:129] Top shape: 32 192 8 8 (393216)
I0829 09:22:54.251327 916722 net.cpp:137] Memory required for data: 476446848
I0829 09:22:54.251332 916722 layer_factory.hpp:77] Creating layer B2_0_SConv_Dropout
I0829 09:22:54.251336 916722 net.cpp:84] Creating Layer B2_0_SConv_Dropout
I0829 09:22:54.251340 916722 net.cpp:406] B2_0_SConv_Dropout <- B2_0_SConvBlockV2_Conv1x1
I0829 09:22:54.251346 916722 net.cpp:380] B2_0_SConv_Dropout -> B2_0_SConvBlockV2_Dropout
I0829 09:22:54.251368 916722 net.cpp:122] Setting up B2_0_SConv_Dropout
I0829 09:22:54.251374 916722 net.cpp:129] Top shape: 32 192 8 8 (393216)
I0829 09:22:54.251379 916722 net.cpp:137] Memory required for data: 478019712
I0829 09:22:54.251384 916722 layer_factory.hpp:77] Creating layer B2_1_SConv_SparseConv
I0829 09:22:54.251394 916722 net.cpp:84] Creating Layer B2_1_SConv_SparseConv
I0829 09:22:54.251399 916722 net.cpp:406] B2_1_SConv_SparseConv <- B2_0_SConvBlockV2_Dropout
I0829 09:22:54.251406 916722 net.cpp:380] B2_1_SConv_SparseConv -> B2_1_SConvBlockV2_T1
I0829 09:22:54.251567 916722 net.cpp:122] Setting up B2_1_SConv_SparseConv
I0829 09:22:54.251574 916722 net.cpp:129] Top shape: 32 1536 8 8 (3145728)
I0829 09:22:54.251579 916722 net.cpp:137] Memory required for data: 490602624
I0829 09:22:54.251585 916722 layer_factory.hpp:77] Creating layer B2_1_SConv_BN
I0829 09:22:54.251591 916722 net.cpp:84] Creating Layer B2_1_SConv_BN
I0829 09:22:54.251596 916722 net.cpp:406] B2_1_SConv_BN <- B2_1_SConvBlockV2_T1
I0829 09:22:54.251602 916722 net.cpp:367] B2_1_SConv_BN -> B2_1_SConvBlockV2_T1 (in-place)
I0829 09:22:54.251682 916722 net.cpp:122] Setting up B2_1_SConv_BN
I0829 09:22:54.251688 916722 net.cpp:129] Top shape: 32 1536 8 8 (3145728)
I0829 09:22:54.251693 916722 net.cpp:137] Memory required for data: 503185536
I0829 09:22:54.251700 916722 layer_factory.hpp:77] Creating layer B2_1_SConv_Scale
I0829 09:22:54.251709 916722 net.cpp:84] Creating Layer B2_1_SConv_Scale
I0829 09:22:54.251714 916722 net.cpp:406] B2_1_SConv_Scale <- B2_1_SConvBlockV2_T1
I0829 09:22:54.251720 916722 net.cpp:380] B2_1_SConv_Scale -> B2_1_SConvBlockV2_Scale
I0829 09:22:54.251745 916722 layer_factory.hpp:77] Creating layer B2_1_SConv_Scale
I0829 09:22:54.251802 916722 net.cpp:122] Setting up B2_1_SConv_Scale
I0829 09:22:54.251808 916722 net.cpp:129] Top shape: 32 1536 8 8 (3145728)
I0829 09:22:54.251819 916722 net.cpp:137] Memory required for data: 515768448
I0829 09:22:54.251830 916722 layer_factory.hpp:77] Creating layer B2_1_SConv_Conv1x1
I0829 09:22:54.251840 916722 net.cpp:84] Creating Layer B2_1_SConv_Conv1x1
I0829 09:22:54.251845 916722 net.cpp:406] B2_1_SConv_Conv1x1 <- B2_1_SConvBlockV2_Scale
I0829 09:22:54.251852 916722 net.cpp:380] B2_1_SConv_Conv1x1 -> B2_1_SConvBlockV2_Conv1x1
I0829 09:22:54.254365 916722 net.cpp:122] Setting up B2_1_SConv_Conv1x1
I0829 09:22:54.254379 916722 net.cpp:129] Top shape: 32 192 8 8 (393216)
I0829 09:22:54.254385 916722 net.cpp:137] Memory required for data: 517341312
I0829 09:22:54.254391 916722 layer_factory.hpp:77] Creating layer B2_1_SConv_ReLU
I0829 09:22:54.254398 916722 net.cpp:84] Creating Layer B2_1_SConv_ReLU
I0829 09:22:54.254403 916722 net.cpp:406] B2_1_SConv_ReLU <- B2_1_SConvBlockV2_Conv1x1
I0829 09:22:54.254411 916722 net.cpp:367] B2_1_SConv_ReLU -> B2_1_SConvBlockV2_Conv1x1 (in-place)
I0829 09:22:54.254420 916722 net.cpp:122] Setting up B2_1_SConv_ReLU
I0829 09:22:54.254423 916722 net.cpp:129] Top shape: 32 192 8 8 (393216)
I0829 09:22:54.254428 916722 net.cpp:137] Memory required for data: 518914176
I0829 09:22:54.254433 916722 layer_factory.hpp:77] Creating layer B2_1_SConv_Dropout
I0829 09:22:54.254438 916722 net.cpp:84] Creating Layer B2_1_SConv_Dropout
I0829 09:22:54.254443 916722 net.cpp:406] B2_1_SConv_Dropout <- B2_1_SConvBlockV2_Conv1x1
I0829 09:22:54.254448 916722 net.cpp:380] B2_1_SConv_Dropout -> B2_1_SConvBlockV2_Dropout
I0829 09:22:54.254473 916722 net.cpp:122] Setting up B2_1_SConv_Dropout
I0829 09:22:54.254479 916722 net.cpp:129] Top shape: 32 192 8 8 (393216)
I0829 09:22:54.254484 916722 net.cpp:137] Memory required for data: 520487040
I0829 09:22:54.254488 916722 layer_factory.hpp:77] Creating layer B2_2_SConv_SparseConv
I0829 09:22:54.254496 916722 net.cpp:84] Creating Layer B2_2_SConv_SparseConv
I0829 09:22:54.254501 916722 net.cpp:406] B2_2_SConv_SparseConv <- B2_1_SConvBlockV2_Dropout
I0829 09:22:54.254506 916722 net.cpp:380] B2_2_SConv_SparseConv -> B2_2_SConvBlockV2_T1
I0829 09:22:54.254669 916722 net.cpp:122] Setting up B2_2_SConv_SparseConv
I0829 09:22:54.254678 916722 net.cpp:129] Top shape: 32 1536 8 8 (3145728)
I0829 09:22:54.254683 916722 net.cpp:137] Memory required for data: 533069952
I0829 09:22:54.254688 916722 layer_factory.hpp:77] Creating layer B2_2_SConv_BN
I0829 09:22:54.254698 916722 net.cpp:84] Creating Layer B2_2_SConv_BN
I0829 09:22:54.254703 916722 net.cpp:406] B2_2_SConv_BN <- B2_2_SConvBlockV2_T1
I0829 09:22:54.254710 916722 net.cpp:367] B2_2_SConv_BN -> B2_2_SConvBlockV2_T1 (in-place)
I0829 09:22:54.254788 916722 net.cpp:122] Setting up B2_2_SConv_BN
I0829 09:22:54.254794 916722 net.cpp:129] Top shape: 32 1536 8 8 (3145728)
I0829 09:22:54.254801 916722 net.cpp:137] Memory required for data: 545652864
I0829 09:22:54.254806 916722 layer_factory.hpp:77] Creating layer B2_2_SConv_Scale
I0829 09:22:54.254812 916722 net.cpp:84] Creating Layer B2_2_SConv_Scale
I0829 09:22:54.254817 916722 net.cpp:406] B2_2_SConv_Scale <- B2_2_SConvBlockV2_T1
I0829 09:22:54.254824 916722 net.cpp:380] B2_2_SConv_Scale -> B2_2_SConvBlockV2_Scale
I0829 09:22:54.254846 916722 layer_factory.hpp:77] Creating layer B2_2_SConv_Scale
I0829 09:22:54.254901 916722 net.cpp:122] Setting up B2_2_SConv_Scale
I0829 09:22:54.254909 916722 net.cpp:129] Top shape: 32 1536 8 8 (3145728)
I0829 09:22:54.254914 916722 net.cpp:137] Memory required for data: 558235776
I0829 09:22:54.254920 916722 layer_factory.hpp:77] Creating layer B2_2_SConv_Conv1x1
I0829 09:22:54.254928 916722 net.cpp:84] Creating Layer B2_2_SConv_Conv1x1
I0829 09:22:54.254932 916722 net.cpp:406] B2_2_SConv_Conv1x1 <- B2_2_SConvBlockV2_Scale
I0829 09:22:54.254940 916722 net.cpp:380] B2_2_SConv_Conv1x1 -> B2_2_SConvBlockV2_Conv1x1
I0829 09:22:54.257511 916722 net.cpp:122] Setting up B2_2_SConv_Conv1x1
I0829 09:22:54.257524 916722 net.cpp:129] Top shape: 32 192 8 8 (393216)
I0829 09:22:54.257531 916722 net.cpp:137] Memory required for data: 559808640
I0829 09:22:54.257537 916722 layer_factory.hpp:77] Creating layer B2_2_SConv_ReLU
I0829 09:22:54.257556 916722 net.cpp:84] Creating Layer B2_2_SConv_ReLU
I0829 09:22:54.257562 916722 net.cpp:406] B2_2_SConv_ReLU <- B2_2_SConvBlockV2_Conv1x1
I0829 09:22:54.257568 916722 net.cpp:367] B2_2_SConv_ReLU -> B2_2_SConvBlockV2_Conv1x1 (in-place)
I0829 09:22:54.257576 916722 net.cpp:122] Setting up B2_2_SConv_ReLU
I0829 09:22:54.257580 916722 net.cpp:129] Top shape: 32 192 8 8 (393216)
I0829 09:22:54.257586 916722 net.cpp:137] Memory required for data: 561381504
I0829 09:22:54.257589 916722 layer_factory.hpp:77] Creating layer B2_2_SConv_Dropout
I0829 09:22:54.257597 916722 net.cpp:84] Creating Layer B2_2_SConv_Dropout
I0829 09:22:54.257601 916722 net.cpp:406] B2_2_SConv_Dropout <- B2_2_SConvBlockV2_Conv1x1
I0829 09:22:54.257607 916722 net.cpp:380] B2_2_SConv_Dropout -> B2_2_SConvBlockV2_Dropout
I0829 09:22:54.257632 916722 net.cpp:122] Setting up B2_2_SConv_Dropout
I0829 09:22:54.257638 916722 net.cpp:129] Top shape: 32 192 8 8 (393216)
I0829 09:22:54.257645 916722 net.cpp:137] Memory required for data: 562954368
I0829 09:22:54.257649 916722 layer_factory.hpp:77] Creating layer B2_Pooling
I0829 09:22:54.257656 916722 net.cpp:84] Creating Layer B2_Pooling
I0829 09:22:54.257661 916722 net.cpp:406] B2_Pooling <- B2_2_SConvBlockV2_Dropout
I0829 09:22:54.257666 916722 net.cpp:380] B2_Pooling -> Pooling3
I0829 09:22:54.257689 916722 net.cpp:122] Setting up B2_Pooling
I0829 09:22:54.257695 916722 net.cpp:129] Top shape: 32 192 4 4 (98304)
I0829 09:22:54.257700 916722 net.cpp:137] Memory required for data: 563347584
I0829 09:22:54.257704 916722 layer_factory.hpp:77] Creating layer B3_0_SConv_SparseConv
I0829 09:22:54.257712 916722 net.cpp:84] Creating Layer B3_0_SConv_SparseConv
I0829 09:22:54.257717 916722 net.cpp:406] B3_0_SConv_SparseConv <- Pooling3
I0829 09:22:54.257723 916722 net.cpp:380] B3_0_SConv_SparseConv -> B3_0_SConvBlockV2_T1
I0829 09:22:54.257884 916722 net.cpp:122] Setting up B3_0_SConv_SparseConv
I0829 09:22:54.257891 916722 net.cpp:129] Top shape: 32 1536 4 4 (786432)
I0829 09:22:54.257896 916722 net.cpp:137] Memory required for data: 566493312
I0829 09:22:54.257902 916722 layer_factory.hpp:77] Creating layer B3_0_SConv_BN
I0829 09:22:54.257913 916722 net.cpp:84] Creating Layer B3_0_SConv_BN
I0829 09:22:54.257920 916722 net.cpp:406] B3_0_SConv_BN <- B3_0_SConvBlockV2_T1
I0829 09:22:54.257925 916722 net.cpp:367] B3_0_SConv_BN -> B3_0_SConvBlockV2_T1 (in-place)
I0829 09:22:54.258005 916722 net.cpp:122] Setting up B3_0_SConv_BN
I0829 09:22:54.258011 916722 net.cpp:129] Top shape: 32 1536 4 4 (786432)
I0829 09:22:54.258018 916722 net.cpp:137] Memory required for data: 569639040
I0829 09:22:54.258025 916722 layer_factory.hpp:77] Creating layer B3_0_SConv_Scale
I0829 09:22:54.258031 916722 net.cpp:84] Creating Layer B3_0_SConv_Scale
I0829 09:22:54.258036 916722 net.cpp:406] B3_0_SConv_Scale <- B3_0_SConvBlockV2_T1
I0829 09:22:54.258041 916722 net.cpp:380] B3_0_SConv_Scale -> B3_0_SConvBlockV2_Scale
I0829 09:22:54.258067 916722 layer_factory.hpp:77] Creating layer B3_0_SConv_Scale
I0829 09:22:54.258126 916722 net.cpp:122] Setting up B3_0_SConv_Scale
I0829 09:22:54.258131 916722 net.cpp:129] Top shape: 32 1536 4 4 (786432)
I0829 09:22:54.258136 916722 net.cpp:137] Memory required for data: 572784768
I0829 09:22:54.258142 916722 layer_factory.hpp:77] Creating layer B3_0_SConv_Conv1x1
I0829 09:22:54.258155 916722 net.cpp:84] Creating Layer B3_0_SConv_Conv1x1
I0829 09:22:54.258160 916722 net.cpp:406] B3_0_SConv_Conv1x1 <- B3_0_SConvBlockV2_Scale
I0829 09:22:54.258167 916722 net.cpp:380] B3_0_SConv_Conv1x1 -> B3_0_SConvBlockV2_Conv1x1
I0829 09:22:54.260654 916722 net.cpp:122] Setting up B3_0_SConv_Conv1x1
I0829 09:22:54.260668 916722 net.cpp:129] Top shape: 32 192 4 4 (98304)
I0829 09:22:54.260675 916722 net.cpp:137] Memory required for data: 573177984
I0829 09:22:54.260682 916722 layer_factory.hpp:77] Creating layer B3_0_SConv_ReLU
I0829 09:22:54.260689 916722 net.cpp:84] Creating Layer B3_0_SConv_ReLU
I0829 09:22:54.260694 916722 net.cpp:406] B3_0_SConv_ReLU <- B3_0_SConvBlockV2_Conv1x1
I0829 09:22:54.260706 916722 net.cpp:367] B3_0_SConv_ReLU -> B3_0_SConvBlockV2_Conv1x1 (in-place)
I0829 09:22:54.260721 916722 net.cpp:122] Setting up B3_0_SConv_ReLU
I0829 09:22:54.260726 916722 net.cpp:129] Top shape: 32 192 4 4 (98304)
I0829 09:22:54.260742 916722 net.cpp:137] Memory required for data: 573571200
I0829 09:22:54.260746 916722 layer_factory.hpp:77] Creating layer B3_0_SConv_Dropout
I0829 09:22:54.260754 916722 net.cpp:84] Creating Layer B3_0_SConv_Dropout
I0829 09:22:54.260758 916722 net.cpp:406] B3_0_SConv_Dropout <- B3_0_SConvBlockV2_Conv1x1
I0829 09:22:54.260764 916722 net.cpp:380] B3_0_SConv_Dropout -> B3_0_SConvBlockV2_Dropout
I0829 09:22:54.260790 916722 net.cpp:122] Setting up B3_0_SConv_Dropout
I0829 09:22:54.260797 916722 net.cpp:129] Top shape: 32 192 4 4 (98304)
I0829 09:22:54.260802 916722 net.cpp:137] Memory required for data: 573964416
I0829 09:22:54.260805 916722 layer_factory.hpp:77] Creating layer B3_1_SConv_SparseConv
I0829 09:22:54.260814 916722 net.cpp:84] Creating Layer B3_1_SConv_SparseConv
I0829 09:22:54.260818 916722 net.cpp:406] B3_1_SConv_SparseConv <- B3_0_SConvBlockV2_Dropout
I0829 09:22:54.260824 916722 net.cpp:380] B3_1_SConv_SparseConv -> B3_1_SConvBlockV2_T1
I0829 09:22:54.260985 916722 net.cpp:122] Setting up B3_1_SConv_SparseConv
I0829 09:22:54.260993 916722 net.cpp:129] Top shape: 32 1536 4 4 (786432)
I0829 09:22:54.260998 916722 net.cpp:137] Memory required for data: 577110144
I0829 09:22:54.261003 916722 layer_factory.hpp:77] Creating layer B3_1_SConv_BN
I0829 09:22:54.261013 916722 net.cpp:84] Creating Layer B3_1_SConv_BN
I0829 09:22:54.261016 916722 net.cpp:406] B3_1_SConv_BN <- B3_1_SConvBlockV2_T1
I0829 09:22:54.261023 916722 net.cpp:367] B3_1_SConv_BN -> B3_1_SConvBlockV2_T1 (in-place)
I0829 09:22:54.261101 916722 net.cpp:122] Setting up B3_1_SConv_BN
I0829 09:22:54.261107 916722 net.cpp:129] Top shape: 32 1536 4 4 (786432)
I0829 09:22:54.261112 916722 net.cpp:137] Memory required for data: 580255872
I0829 09:22:54.261129 916722 layer_factory.hpp:77] Creating layer B3_1_SConv_Scale
I0829 09:22:54.261138 916722 net.cpp:84] Creating Layer B3_1_SConv_Scale
I0829 09:22:54.261143 916722 net.cpp:406] B3_1_SConv_Scale <- B3_1_SConvBlockV2_T1
I0829 09:22:54.261148 916722 net.cpp:380] B3_1_SConv_Scale -> B3_1_SConvBlockV2_Scale
I0829 09:22:54.261175 916722 layer_factory.hpp:77] Creating layer B3_1_SConv_Scale
I0829 09:22:54.261231 916722 net.cpp:122] Setting up B3_1_SConv_Scale
I0829 09:22:54.261237 916722 net.cpp:129] Top shape: 32 1536 4 4 (786432)
I0829 09:22:54.261242 916722 net.cpp:137] Memory required for data: 583401600
I0829 09:22:54.261248 916722 layer_factory.hpp:77] Creating layer B3_1_SConv_Conv1x1
I0829 09:22:54.261260 916722 net.cpp:84] Creating Layer B3_1_SConv_Conv1x1
I0829 09:22:54.261265 916722 net.cpp:406] B3_1_SConv_Conv1x1 <- B3_1_SConvBlockV2_Scale
I0829 09:22:54.261270 916722 net.cpp:380] B3_1_SConv_Conv1x1 -> B3_1_SConvBlockV2_Conv1x1
I0829 09:22:54.263718 916722 net.cpp:122] Setting up B3_1_SConv_Conv1x1
I0829 09:22:54.263731 916722 net.cpp:129] Top shape: 32 192 4 4 (98304)
I0829 09:22:54.263737 916722 net.cpp:137] Memory required for data: 583794816
I0829 09:22:54.263743 916722 layer_factory.hpp:77] Creating layer B3_1_SConv_ReLU
I0829 09:22:54.263752 916722 net.cpp:84] Creating Layer B3_1_SConv_ReLU
I0829 09:22:54.263757 916722 net.cpp:406] B3_1_SConv_ReLU <- B3_1_SConvBlockV2_Conv1x1
I0829 09:22:54.263763 916722 net.cpp:367] B3_1_SConv_ReLU -> B3_1_SConvBlockV2_Conv1x1 (in-place)
I0829 09:22:54.263770 916722 net.cpp:122] Setting up B3_1_SConv_ReLU
I0829 09:22:54.263775 916722 net.cpp:129] Top shape: 32 192 4 4 (98304)
I0829 09:22:54.263780 916722 net.cpp:137] Memory required for data: 584188032
I0829 09:22:54.263784 916722 layer_factory.hpp:77] Creating layer B3_1_SConv_Dropout
I0829 09:22:54.263792 916722 net.cpp:84] Creating Layer B3_1_SConv_Dropout
I0829 09:22:54.263797 916722 net.cpp:406] B3_1_SConv_Dropout <- B3_1_SConvBlockV2_Conv1x1
I0829 09:22:54.263803 916722 net.cpp:380] B3_1_SConv_Dropout -> B3_1_SConvBlockV2_Dropout
I0829 09:22:54.263831 916722 net.cpp:122] Setting up B3_1_SConv_Dropout
I0829 09:22:54.263844 916722 net.cpp:129] Top shape: 32 192 4 4 (98304)
I0829 09:22:54.263849 916722 net.cpp:137] Memory required for data: 584581248
I0829 09:22:54.263854 916722 layer_factory.hpp:77] Creating layer B3_2_SConv_SparseConv
I0829 09:22:54.263860 916722 net.cpp:84] Creating Layer B3_2_SConv_SparseConv
I0829 09:22:54.263865 916722 net.cpp:406] B3_2_SConv_SparseConv <- B3_1_SConvBlockV2_Dropout
I0829 09:22:54.263872 916722 net.cpp:380] B3_2_SConv_SparseConv -> B3_2_SConvBlockV2_T1
I0829 09:22:54.264034 916722 net.cpp:122] Setting up B3_2_SConv_SparseConv
I0829 09:22:54.264041 916722 net.cpp:129] Top shape: 32 1536 4 4 (786432)
I0829 09:22:54.264047 916722 net.cpp:137] Memory required for data: 587726976
I0829 09:22:54.264052 916722 layer_factory.hpp:77] Creating layer B3_2_SConv_BN
I0829 09:22:54.264061 916722 net.cpp:84] Creating Layer B3_2_SConv_BN
I0829 09:22:54.264066 916722 net.cpp:406] B3_2_SConv_BN <- B3_2_SConvBlockV2_T1
I0829 09:22:54.264072 916722 net.cpp:367] B3_2_SConv_BN -> B3_2_SConvBlockV2_T1 (in-place)
I0829 09:22:54.264154 916722 net.cpp:122] Setting up B3_2_SConv_BN
I0829 09:22:54.264160 916722 net.cpp:129] Top shape: 32 1536 4 4 (786432)
I0829 09:22:54.264165 916722 net.cpp:137] Memory required for data: 590872704
I0829 09:22:54.264173 916722 layer_factory.hpp:77] Creating layer B3_2_SConv_Scale
I0829 09:22:54.264180 916722 net.cpp:84] Creating Layer B3_2_SConv_Scale
I0829 09:22:54.264184 916722 net.cpp:406] B3_2_SConv_Scale <- B3_2_SConvBlockV2_T1
I0829 09:22:54.264190 916722 net.cpp:380] B3_2_SConv_Scale -> B3_2_SConvBlockV2_Scale
I0829 09:22:54.264214 916722 layer_factory.hpp:77] Creating layer B3_2_SConv_Scale
I0829 09:22:54.264276 916722 net.cpp:122] Setting up B3_2_SConv_Scale
I0829 09:22:54.264283 916722 net.cpp:129] Top shape: 32 1536 4 4 (786432)
I0829 09:22:54.264288 916722 net.cpp:137] Memory required for data: 594018432
I0829 09:22:54.264294 916722 layer_factory.hpp:77] Creating layer B3_2_SConv_Conv1x1
I0829 09:22:54.264304 916722 net.cpp:84] Creating Layer B3_2_SConv_Conv1x1
I0829 09:22:54.264309 916722 net.cpp:406] B3_2_SConv_Conv1x1 <- B3_2_SConvBlockV2_Scale
I0829 09:22:54.264315 916722 net.cpp:380] B3_2_SConv_Conv1x1 -> B3_2_SConvBlockV2_Conv1x1
I0829 09:22:54.266785 916722 net.cpp:122] Setting up B3_2_SConv_Conv1x1
I0829 09:22:54.266798 916722 net.cpp:129] Top shape: 32 192 4 4 (98304)
I0829 09:22:54.266805 916722 net.cpp:137] Memory required for data: 594411648
I0829 09:22:54.266811 916722 layer_factory.hpp:77] Creating layer B3_2_SConv_ReLU
I0829 09:22:54.266819 916722 net.cpp:84] Creating Layer B3_2_SConv_ReLU
I0829 09:22:54.266824 916722 net.cpp:406] B3_2_SConv_ReLU <- B3_2_SConvBlockV2_Conv1x1
I0829 09:22:54.266829 916722 net.cpp:367] B3_2_SConv_ReLU -> B3_2_SConvBlockV2_Conv1x1 (in-place)
I0829 09:22:54.266836 916722 net.cpp:122] Setting up B3_2_SConv_ReLU
I0829 09:22:54.266841 916722 net.cpp:129] Top shape: 32 192 4 4 (98304)
I0829 09:22:54.266846 916722 net.cpp:137] Memory required for data: 594804864
I0829 09:22:54.266850 916722 layer_factory.hpp:77] Creating layer B3_2_SConv_Dropout
I0829 09:22:54.266857 916722 net.cpp:84] Creating Layer B3_2_SConv_Dropout
I0829 09:22:54.266862 916722 net.cpp:406] B3_2_SConv_Dropout <- B3_2_SConvBlockV2_Conv1x1
I0829 09:22:54.266868 916722 net.cpp:380] B3_2_SConv_Dropout -> B3_2_SConvBlockV2_Dropout
I0829 09:22:54.266892 916722 net.cpp:122] Setting up B3_2_SConv_Dropout
I0829 09:22:54.266898 916722 net.cpp:129] Top shape: 32 192 4 4 (98304)
I0829 09:22:54.266903 916722 net.cpp:137] Memory required for data: 595198080
I0829 09:22:54.266907 916722 layer_factory.hpp:77] Creating layer B3_Pooling
I0829 09:22:54.266914 916722 net.cpp:84] Creating Layer B3_Pooling
I0829 09:22:54.266919 916722 net.cpp:406] B3_Pooling <- B3_2_SConvBlockV2_Dropout
I0829 09:22:54.266924 916722 net.cpp:380] B3_Pooling -> Pooling4
I0829 09:22:54.266942 916722 net.cpp:122] Setting up B3_Pooling
I0829 09:22:54.266947 916722 net.cpp:129] Top shape: 32 192 1 1 (6144)
I0829 09:22:54.266957 916722 net.cpp:137] Memory required for data: 595222656
I0829 09:22:54.266971 916722 layer_factory.hpp:77] Creating layer fc1
I0829 09:22:54.266986 916722 net.cpp:84] Creating Layer fc1
I0829 09:22:54.266991 916722 net.cpp:406] fc1 <- Pooling4
I0829 09:22:54.266997 916722 net.cpp:380] fc1 -> fc1
I0829 09:22:54.267424 916722 net.cpp:122] Setting up fc1
I0829 09:22:54.267431 916722 net.cpp:129] Top shape: 32 384 (12288)
I0829 09:22:54.267436 916722 net.cpp:137] Memory required for data: 595271808
I0829 09:22:54.267443 916722 layer_factory.hpp:77] Creating layer classifier
I0829 09:22:54.267449 916722 net.cpp:84] Creating Layer classifier
I0829 09:22:54.267453 916722 net.cpp:406] classifier <- fc1
I0829 09:22:54.267459 916722 net.cpp:380] classifier -> classifier
I0829 09:22:54.267525 916722 net.cpp:122] Setting up classifier
I0829 09:22:54.267532 916722 net.cpp:129] Top shape: 32 10 (320)
I0829 09:22:54.267536 916722 net.cpp:137] Memory required for data: 595273088
I0829 09:22:54.267542 916722 layer_factory.hpp:77] Creating layer softmax_loss
I0829 09:22:54.267554 916722 net.cpp:84] Creating Layer softmax_loss
I0829 09:22:54.267558 916722 net.cpp:406] softmax_loss <- classifier
I0829 09:22:54.267563 916722 net.cpp:406] softmax_loss <- label
I0829 09:22:54.267572 916722 net.cpp:380] softmax_loss -> softmax_loss
I0829 09:22:54.267583 916722 layer_factory.hpp:77] Creating layer softmax_loss
I0829 09:22:54.267639 916722 net.cpp:122] Setting up softmax_loss
I0829 09:22:54.267645 916722 net.cpp:129] Top shape: (1)
I0829 09:22:54.267650 916722 net.cpp:132]     with loss weight 1
I0829 09:22:54.267666 916722 net.cpp:137] Memory required for data: 595273092
I0829 09:22:54.267671 916722 net.cpp:198] softmax_loss needs backward computation.
I0829 09:22:54.267676 916722 net.cpp:198] classifier needs backward computation.
I0829 09:22:54.267680 916722 net.cpp:198] fc1 needs backward computation.
I0829 09:22:54.267685 916722 net.cpp:198] B3_Pooling needs backward computation.
I0829 09:22:54.267689 916722 net.cpp:198] B3_2_SConv_Dropout needs backward computation.
I0829 09:22:54.267694 916722 net.cpp:198] B3_2_SConv_ReLU needs backward computation.
I0829 09:22:54.267699 916722 net.cpp:198] B3_2_SConv_Conv1x1 needs backward computation.
I0829 09:22:54.267702 916722 net.cpp:198] B3_2_SConv_Scale needs backward computation.
I0829 09:22:54.267706 916722 net.cpp:198] B3_2_SConv_BN needs backward computation.
I0829 09:22:54.267711 916722 net.cpp:198] B3_2_SConv_SparseConv needs backward computation.
I0829 09:22:54.267715 916722 net.cpp:198] B3_1_SConv_Dropout needs backward computation.
I0829 09:22:54.267719 916722 net.cpp:198] B3_1_SConv_ReLU needs backward computation.
I0829 09:22:54.267724 916722 net.cpp:198] B3_1_SConv_Conv1x1 needs backward computation.
I0829 09:22:54.267727 916722 net.cpp:198] B3_1_SConv_Scale needs backward computation.
I0829 09:22:54.267732 916722 net.cpp:198] B3_1_SConv_BN needs backward computation.
I0829 09:22:54.267736 916722 net.cpp:198] B3_1_SConv_SparseConv needs backward computation.
I0829 09:22:54.267740 916722 net.cpp:198] B3_0_SConv_Dropout needs backward computation.
I0829 09:22:54.267745 916722 net.cpp:198] B3_0_SConv_ReLU needs backward computation.
I0829 09:22:54.267750 916722 net.cpp:198] B3_0_SConv_Conv1x1 needs backward computation.
I0829 09:22:54.267753 916722 net.cpp:198] B3_0_SConv_Scale needs backward computation.
I0829 09:22:54.267757 916722 net.cpp:198] B3_0_SConv_BN needs backward computation.
I0829 09:22:54.267761 916722 net.cpp:198] B3_0_SConv_SparseConv needs backward computation.
I0829 09:22:54.267766 916722 net.cpp:198] B2_Pooling needs backward computation.
I0829 09:22:54.267771 916722 net.cpp:198] B2_2_SConv_Dropout needs backward computation.
I0829 09:22:54.267774 916722 net.cpp:198] B2_2_SConv_ReLU needs backward computation.
I0829 09:22:54.267778 916722 net.cpp:198] B2_2_SConv_Conv1x1 needs backward computation.
I0829 09:22:54.267783 916722 net.cpp:198] B2_2_SConv_Scale needs backward computation.
I0829 09:22:54.267787 916722 net.cpp:198] B2_2_SConv_BN needs backward computation.
I0829 09:22:54.267796 916722 net.cpp:198] B2_2_SConv_SparseConv needs backward computation.
I0829 09:22:54.267805 916722 net.cpp:198] B2_1_SConv_Dropout needs backward computation.
I0829 09:22:54.267810 916722 net.cpp:198] B2_1_SConv_ReLU needs backward computation.
I0829 09:22:54.267814 916722 net.cpp:198] B2_1_SConv_Conv1x1 needs backward computation.
I0829 09:22:54.267818 916722 net.cpp:198] B2_1_SConv_Scale needs backward computation.
I0829 09:22:54.267823 916722 net.cpp:198] B2_1_SConv_BN needs backward computation.
I0829 09:22:54.267827 916722 net.cpp:198] B2_1_SConv_SparseConv needs backward computation.
I0829 09:22:54.267832 916722 net.cpp:198] B2_0_SConv_Dropout needs backward computation.
I0829 09:22:54.267835 916722 net.cpp:198] B2_0_SConv_ReLU needs backward computation.
I0829 09:22:54.267839 916722 net.cpp:198] B2_0_SConv_Conv1x1 needs backward computation.
I0829 09:22:54.267844 916722 net.cpp:198] B2_0_SConv_Scale needs backward computation.
I0829 09:22:54.267848 916722 net.cpp:198] B2_0_SConv_BN needs backward computation.
I0829 09:22:54.267853 916722 net.cpp:198] B2_0_SConv_SparseConv needs backward computation.
I0829 09:22:54.267858 916722 net.cpp:198] B1_Pooling needs backward computation.
I0829 09:22:54.267861 916722 net.cpp:198] B1_1_SConv_Dropout needs backward computation.
I0829 09:22:54.267865 916722 net.cpp:198] B1_1_SConv_ReLU needs backward computation.
I0829 09:22:54.267869 916722 net.cpp:198] B1_1_SConv_Conv1x1 needs backward computation.
I0829 09:22:54.267874 916722 net.cpp:198] B1_1_SConv_Scale needs backward computation.
I0829 09:22:54.267879 916722 net.cpp:198] B1_1_SConv_BN needs backward computation.
I0829 09:22:54.267882 916722 net.cpp:198] B1_1_SConv_SparseConv needs backward computation.
I0829 09:22:54.267886 916722 net.cpp:198] B1_0_SConv_Dropout needs backward computation.
I0829 09:22:54.267890 916722 net.cpp:198] B1_0_SConv_ReLU needs backward computation.
I0829 09:22:54.267894 916722 net.cpp:198] B1_0_SConv_Conv1x1 needs backward computation.
I0829 09:22:54.267899 916722 net.cpp:198] B1_0_SConv_Scale needs backward computation.
I0829 09:22:54.267904 916722 net.cpp:198] B1_0_SConv_BN needs backward computation.
I0829 09:22:54.267907 916722 net.cpp:198] B1_0_SConv_SparseConv needs backward computation.
I0829 09:22:54.267911 916722 net.cpp:198] B0_Pooling needs backward computation.
I0829 09:22:54.267918 916722 net.cpp:198] B0_1_SConv_Dropout needs backward computation.
I0829 09:22:54.267922 916722 net.cpp:198] B0_1_SConv_ReLU needs backward computation.
I0829 09:22:54.267927 916722 net.cpp:198] B0_1_SConv_Conv1x1 needs backward computation.
I0829 09:22:54.267931 916722 net.cpp:198] B0_1_SConv_Scale needs backward computation.
I0829 09:22:54.267935 916722 net.cpp:198] B0_1_SConv_BN needs backward computation.
I0829 09:22:54.267940 916722 net.cpp:198] B0_1_SConv_SparseConv needs backward computation.
I0829 09:22:54.267944 916722 net.cpp:198] B0_0_ConvBNScaleReLU_Dropout needs backward computation.
I0829 09:22:54.267948 916722 net.cpp:198] B0_0_ConvBNScaleReLU_ReLU needs backward computation.
I0829 09:22:54.267952 916722 net.cpp:198] B0_0_ConvBNScaleReLU_Scale needs backward computation.
I0829 09:22:54.267956 916722 net.cpp:198] B0_0_ConvBNScaleReLU_BN needs backward computation.
I0829 09:22:54.267961 916722 net.cpp:198] B0_0_ConvBNScaleReLU_Conv needs backward computation.
I0829 09:22:54.267966 916722 net.cpp:200] InputData does not need backward computation.
I0829 09:22:54.267969 916722 net.cpp:242] This network produces output softmax_loss
I0829 09:22:54.268003 916722 net.cpp:255] Network initialization done.
I0829 09:22:54.268599 916722 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: train_test.pt
I0829 09:22:54.268611 916722 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0829 09:22:54.268620 916722 solver.cpp:172] Creating test net (#0) specified by net file: train_test.pt
I0829 09:22:54.268683 916722 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer InputData
I0829 09:22:54.268723 916722 net.cpp:51] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "InputData"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: true
    crop_size: 32
  }
  image_data_param {
    source: "/home/jcwang/work/1.CIFAR10/test.txt"
    batch_size: 1
    shuffle: true
    is_color: true
  }
}
layer {
  name: "B0_0_ConvBNScaleReLU_Conv"
  type: "Convolution"
  bottom: "data"
  top: "B0_0_ConvBNScaleReLU_Conv"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "B0_0_ConvBNScaleReLU_BN"
  type: "BatchNorm"
  bottom: "B0_0_ConvBNScaleReLU_Conv"
  top: "B0_0_ConvBNScaleReLU_Conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.999
    eps: 0.001
  }
}
layer {
  name: "B0_0_ConvBNScaleReLU_Scale"
  type: "Scale"
  bottom: "B0_0_ConvBNScaleReLU_Conv"
  top: "B0_0_ConvBNScaleReLU_Conv"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
    l1_lambda: 0
  }
}
layer {
  name: "B0_0_ConvBNScaleReLU_ReLU"
  type: "ReLU"
  bottom: "B0_0_ConvBNScaleReLU_Conv"
  top: "B0_0_ConvBNScaleReLU_Conv"
}
layer {
  name: "B0_0_ConvBNScaleReLU_Dropout"
  type: "Dropout"
  bottom: "B0_0_ConvBNScaleReLU_Conv"
  top: "ConvBNScaleReLU"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "B0_1_SConv_SparseConv"
  type: "SparseConvolution"
  bottom: "ConvBNScaleReLU"
  top: "B0_1_SConvBlockV2_T1"
  sparse_convolution_param {
    weight_filler {
      type: "xavier"
    }
    channel_expand_multiplier: 8
  }
}
layer {
  name: "B0_1_SConv_BN"
  type: "BatchNorm"
  bottom: "B0_1_SConvBlockV2_T1"
  top: "B0_1_SConvBlockV2_T1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.999
    eps: 0.001
  }
}
layer {
  name: "B0_1_SConv_Scale"
  type: "Scale"
  bottom: "B0_1_SConvBlockV2_T1"
  top: "B0_1_SConvBlockV2_Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "B0_1_SConv_Conv1x1"
  type: "Convolution"
  bottom: "B0_1_SConvBlockV2_Scale"
  top: "B0_1_SConvBlockV2_Conv1x1"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "B0_1_SConv_ReLU"
  type: "ReLU"
  bottom: "B0_1_SConvBlockV2_Conv1x1"
  top: "B0_1_SConvBlockV2_Conv1x1"
}
layer {
  name: "B0_1_SConv_Dropout"
  type: "Dropout"
  bottom: "B0_1_SConvBlockV2_Conv1x1"
  top: "B0_1_SConvBlockV2_Dropout"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "B0_Pooling"
  type: "Pooling"
  bottom: "B0_1_SConvBlockV2_Dropout"
  top: "Pooling1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "B1_0_SConv_SparseConv"
  type: "SparseConvolution"
  bottom: "Pooling1"
  top: "B1_0_SConvBlockV2_T1"
  sparse_convolution_param {
    weight_filler {
      type: "xavier"
    }
    channel_expand_multiplier: 8
  }
}
layer {
  name: "B1_0_SConv_BN"
  type: "BatchNorm"
  bottom: "B1_0_SConvBlockV2_T1"
  top: "B1_0_SConvBlockV2_T1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.999
    eps: 0.001
  }
}
layer {
  name: "B1_0_SConv_Scale"
  type: "Scale"
  bottom: "B1_0_SConvBlockV2_T1"
  top: "B1_0_SConvBlockV2_Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "B1_0_SConv_Conv1x1"
  type: "Convolution"
  bottom: "B1_0_SConvBlockV2_Scale"
  top: "B1_0_SConvBlockV2_Conv1x1"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "B1_0_SConv_ReLU"
  type: "ReLU"
  bottom: "B1_0_SConvBlockV2_Conv1x1"
  top: "B1_0_SConvBlockV2_Conv1x1"
}
layer {
  name: "B1_0_SConv_Dropout"
  type: "Dropout"
  bottom: "B1_0_SConvBlockV2_Conv1x1"
  top: "B1_0_SConvBlockV2_Dropout"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "B1_1_SConv_SparseConv"
  type: "SparseConvolution"
  bottom: "B1_0_SConvBlockV2_Dropout"
  top: "B1_1_SConvBlockV2_T1"
  sparse_convolution_param {
    weight_filler {
      type: "xavier"
    }
    channel_expand_multiplier: 8
  }
}
layer {
  name: "B1_1_SConv_BN"
  type: "BatchNorm"
  bottom: "B1_1_SConvBlockV2_T1"
  top: "B1_1_SConvBlockV2_T1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.999
    eps: 0.001
  }
}
layer {
  name: "B1_1_SConv_Scale"
  type: "Scale"
  bottom: "B1_1_SConvBlockV2_T1"
  top: "B1_1_SConvBlockV2_Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "B1_1_SConv_Conv1x1"
  type: "Convolution"
  bottom: "B1_1_SConvBlockV2_Scale"
  top: "B1_1_SConvBlockV2_Conv1x1"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "B1_1_SConv_ReLU"
  type: "ReLU"
  bottom: "B1_1_SConvBlockV2_Conv1x1"
  top: "B1_1_SConvBlockV2_Conv1x1"
}
layer {
  name: "B1_1_SConv_Dropout"
  type: "Dropout"
  bottom: "B1_1_SConvBlockV2_Conv1x1"
  top: "B1_1_SConvBlockV2_Dropout"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "B1_Pooling"
  type: "Pooling"
  bottom: "B1_1_SConvBlockV2_Dropout"
  top: "Pooling2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "B2_0_SConv_SparseConv"
  type: "SparseConvolution"
  bottom: "Pooling2"
  top: "B2_0_SConvBlockV2_T1"
  sparse_convolution_param {
    weight_filler {
      type: "xavier"
    }
    channel_expand_multiplier: 8
  }
}
layer {
  name: "B2_0_SConv_BN"
  type: "BatchNorm"
  bottom: "B2_0_SConvBlockV2_T1"
  top: "B2_0_SConvBlockV2_T1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.999
    eps: 0.001
  }
}
layer {
  name: "B2_0_SConv_Scale"
  type: "Scale"
  bottom: "B2_0_SConvBlockV2_T1"
  top: "B2_0_SConvBlockV2_Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "B2_0_SConv_Conv1x1"
  type: "Convolution"
  bottom: "B2_0_SConvBlockV2_Scale"
  top: "B2_0_SConvBlockV2_Conv1x1"
  convolution_param {
    num_output: 192
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "B2_0_SConv_ReLU"
  type: "ReLU"
  bottom: "B2_0_SConvBlockV2_Conv1x1"
  top: "B2_0_SConvBlockV2_Conv1x1"
}
layer {
  name: "B2_0_SConv_Dropout"
  type: "Dropout"
  bottom: "B2_0_SConvBlockV2_Conv1x1"
  top: "B2_0_SConvBlockV2_Dropout"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "B2_1_SConv_SparseConv"
  type: "SparseConvolution"
  bottom: "B2_0_SConvBlockV2_Dropout"
  top: "B2_1_SConvBlockV2_T1"
  sparse_convolution_param {
    weight_filler {
      type: "xavier"
    }
    channel_expand_multiplier: 8
  }
}
layer {
  name: "B2_1_SConv_BN"
  type: "BatchNorm"
  bottom: "B2_1_SConvBlockV2_T1"
  top: "B2_1_SConvBlockV2_T1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.999
    eps: 0.001
  }
}
layer {
  name: "B2_1_SConv_Scale"
  type: "Scale"
  bottom: "B2_1_SConvBlockV2_T1"
  top: "B2_1_SConvBlockV2_Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "B2_1_SConv_Conv1x1"
  type: "Convolution"
  bottom: "B2_1_SConvBlockV2_Scale"
  top: "B2_1_SConvBlockV2_Conv1x1"
  convolution_param {
    num_output: 192
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "B2_1_SConv_ReLU"
  type: "ReLU"
  bottom: "B2_1_SConvBlockV2_Conv1x1"
  top: "B2_1_SConvBlockV2_Conv1x1"
}
layer {
  name: "B2_1_SConv_Dropout"
  type: "Dropout"
  bottom: "B2_1_SConvBlockV2_Conv1x1"
  top: "B2_1_SConvBlockV2_Dropout"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "B2_2_SConv_SparseConv"
  type: "SparseConvolution"
  bottom: "B2_1_SConvBlockV2_Dropout"
  top: "B2_2_SConvBlockV2_T1"
  sparse_convolution_param {
    weight_filler {
      type: "xavier"
    }
    channel_expand_multiplier: 8
  }
}
layer {
  name: "B2_2_SConv_BN"
  type: "BatchNorm"
  bottom: "B2_2_SConvBlockV2_T1"
  top: "B2_2_SConvBlockV2_T1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.999
    eps: 0.001
  }
}
layer {
  name: "B2_2_SConv_Scale"
  type: "Scale"
  bottom: "B2_2_SConvBlockV2_T1"
  top: "B2_2_SConvBlockV2_Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "B2_2_SConv_Conv1x1"
  type: "Convolution"
  bottom: "B2_2_SConvBlockV2_Scale"
  top: "B2_2_SConvBlockV2_Conv1x1"
  convolution_param {
    num_output: 192
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "B2_2_SConv_ReLU"
  type: "ReLU"
  bottom: "B2_2_SConvBlockV2_Conv1x1"
  top: "B2_2_SConvBlockV2_Conv1x1"
}
layer {
  name: "B2_2_SConv_Dropout"
  type: "Dropout"
  bottom: "B2_2_SConvBlockV2_Conv1x1"
  top: "B2_2_SConvBlockV2_Dropout"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "B2_Pooling"
  type: "Pooling"
  bottom: "B2_2_SConvBlockV2_Dropout"
  top: "Pooling3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "B3_0_SConv_SparseConv"
  type: "SparseConvolution"
  bottom: "Pooling3"
  top: "B3_0_SConvBlockV2_T1"
  sparse_convolution_param {
    weight_filler {
      type: "xavier"
    }
    channel_expand_multiplier: 8
  }
}
layer {
  name: "B3_0_SConv_BN"
  type: "BatchNorm"
  bottom: "B3_0_SConvBlockV2_T1"
  top: "B3_0_SConvBlockV2_T1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.999
    eps: 0.001
  }
}
layer {
  name: "B3_0_SConv_Scale"
  type: "Scale"
  bottom: "B3_0_SConvBlockV2_T1"
  top: "B3_0_SConvBlockV2_Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "B3_0_SConv_Conv1x1"
  type: "Convolution"
  bottom: "B3_0_SConvBlockV2_Scale"
  top: "B3_0_SConvBlockV2_Conv1x1"
  convolution_param {
    num_output: 192
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "B3_0_SConv_ReLU"
  type: "ReLU"
  bottom: "B3_0_SConvBlockV2_Conv1x1"
  top: "B3_0_SConvBlockV2_Conv1x1"
}
layer {
  name: "B3_0_SConv_Dropout"
  type: "Dropout"
  bottom: "B3_0_SConvBlockV2_Conv1x1"
  top: "B3_0_SConvBlockV2_Dropout"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "B3_1_SConv_SparseConv"
  type: "SparseConvolution"
  bottom: "B3_0_SConvBlockV2_Dropout"
  top: "B3_1_SConvBlockV2_T1"
  sparse_convolution_param {
    weight_filler {
      type: "xavier"
    }
    channel_expand_multiplier: 8
  }
}
layer {
  name: "B3_1_SConv_BN"
  type: "BatchNorm"
  bottom: "B3_1_SConvBlockV2_T1"
  top: "B3_1_SConvBlockV2_T1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.999
    eps: 0.001
  }
}
layer {
  name: "B3_1_SConv_Scale"
  type: "Scale"
  bottom: "B3_1_SConvBlockV2_T1"
  top: "B3_1_SConvBlockV2_Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "B3_1_SConv_Conv1x1"
  type: "Convolution"
  bottom: "B3_1_SConvBlockV2_Scale"
  top: "B3_1_SConvBlockV2_Conv1x1"
  convolution_param {
    num_output: 192
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "B3_1_SConv_ReLU"
  type: "ReLU"
  bottom: "B3_1_SConvBlockV2_Conv1x1"
  top: "B3_1_SConvBlockV2_Conv1x1"
}
layer {
  name: "B3_1_SConv_Dropout"
  type: "Dropout"
  bottom: "B3_1_SConvBlockV2_Conv1x1"
  top: "B3_1_SConvBlockV2_Dropout"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "B3_2_SConv_SparseConv"
  type: "SparseConvolution"
  bottom: "B3_1_SConvBlockV2_Dropout"
  top: "B3_2_SConvBlockV2_T1"
  sparse_convolution_param {
    weight_filler {
      type: "xavier"
    }
    channel_expand_multiplier: 8
  }
}
layer {
  name: "B3_2_SConv_BN"
  type: "BatchNorm"
  bottom: "B3_2_SConvBlockV2_T1"
  top: "B3_2_SConvBlockV2_T1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    moving_average_fraction: 0.999
    eps: 0.001
  }
}
layer {
  name: "B3_2_SConv_Scale"
  type: "Scale"
  bottom: "B3_2_SConvBlockV2_T1"
  top: "B3_2_SConvBlockV2_Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "B3_2_SConv_Conv1x1"
  type: "Convolution"
  bottom: "B3_2_SConvBlockV2_Scale"
  top: "B3_2_SConvBlockV2_Conv1x1"
  convolution_param {
    num_output: 192
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "B3_2_SConv_ReLU"
  type: "ReLU"
  bottom: "B3_2_SConvBlockV2_Conv1x1"
  top: "B3_2_SConvBlockV2_Conv1x1"
}
layer {
  name: "B3_2_SConv_Dropout"
  type: "Dropout"
  bottom: "B3_2_SConvBlockV2_Conv1x1"
  top: "B3_2_SConvBlockV2_Dropout"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "B3_Pooling"
  type: "Pooling"
  bottom: "B3_2_SConvBlockV2_Dropout"
  top: "Pooling4"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "Pooling4"
  top: "fc1"
  inner_product_param {
    num_output: 384
    bias_term: true
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "classifier"
  type: "InnerProduct"
  bottom: "fc1"
  top: "classifier"
  inner_product_param {
    num_output: 10
    bias_term: true
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "softmax_loss"
  type: "SoftmaxWithLoss"
  bottom: "classifier"
  bottom: "label"
  top: "softmax_loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "classifier"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0829 09:22:54.269125 916722 layer_factory.hpp:77] Creating layer InputData
I0829 09:22:54.269141 916722 net.cpp:84] Creating Layer InputData
I0829 09:22:54.269147 916722 net.cpp:380] InputData -> data
I0829 09:22:54.269155 916722 net.cpp:380] InputData -> label
I0829 09:22:54.269166 916722 image_data_layer.cpp:38] Opening file /home/jcwang/work/1.CIFAR10/test.txt
I0829 09:22:54.271126 916722 image_data_layer.cpp:53] Shuffling data
I0829 09:22:54.271282 916722 image_data_layer.cpp:63] A total of 10001 images.
I0829 09:22:54.271363 916722 image_data_layer.cpp:90] output data size: 1,3,32,32
I0829 09:22:54.271579 916722 net.cpp:122] Setting up InputData
I0829 09:22:54.271589 916722 net.cpp:129] Top shape: 1 3 32 32 (3072)
I0829 09:22:54.271596 916722 net.cpp:129] Top shape: 1 (1)
I0829 09:22:54.271601 916722 net.cpp:137] Memory required for data: 12292
I0829 09:22:54.271605 916722 layer_factory.hpp:77] Creating layer label_InputData_1_split
I0829 09:22:54.271625 916722 net.cpp:84] Creating Layer label_InputData_1_split
I0829 09:22:54.271629 916722 net.cpp:406] label_InputData_1_split <- label
I0829 09:22:54.271636 916722 net.cpp:380] label_InputData_1_split -> label_InputData_1_split_0
I0829 09:22:54.271644 916722 net.cpp:380] label_InputData_1_split -> label_InputData_1_split_1
I0829 09:22:54.271669 916722 net.cpp:122] Setting up label_InputData_1_split
I0829 09:22:54.271675 916722 net.cpp:129] Top shape: 1 (1)
I0829 09:22:54.271680 916722 net.cpp:129] Top shape: 1 (1)
I0829 09:22:54.271684 916722 net.cpp:137] Memory required for data: 12300
I0829 09:22:54.271688 916722 layer_factory.hpp:77] Creating layer B0_0_ConvBNScaleReLU_Conv
I0829 09:22:54.271697 916722 net.cpp:84] Creating Layer B0_0_ConvBNScaleReLU_Conv
I0829 09:22:54.271701 916722 net.cpp:406] B0_0_ConvBNScaleReLU_Conv <- data
I0829 09:22:54.271708 916722 net.cpp:380] B0_0_ConvBNScaleReLU_Conv -> B0_0_ConvBNScaleReLU_Conv
I0829 09:22:54.271878 916722 net.cpp:122] Setting up B0_0_ConvBNScaleReLU_Conv
I0829 09:22:54.271886 916722 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0829 09:22:54.271893 916722 net.cpp:137] Memory required for data: 274444
I0829 09:22:54.271898 916722 layer_factory.hpp:77] Creating layer B0_0_ConvBNScaleReLU_BN
I0829 09:22:54.271905 916722 net.cpp:84] Creating Layer B0_0_ConvBNScaleReLU_BN
I0829 09:22:54.271910 916722 net.cpp:406] B0_0_ConvBNScaleReLU_BN <- B0_0_ConvBNScaleReLU_Conv
I0829 09:22:54.271916 916722 net.cpp:367] B0_0_ConvBNScaleReLU_BN -> B0_0_ConvBNScaleReLU_Conv (in-place)
I0829 09:22:54.271992 916722 net.cpp:122] Setting up B0_0_ConvBNScaleReLU_BN
I0829 09:22:54.271998 916722 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0829 09:22:54.272004 916722 net.cpp:137] Memory required for data: 536588
I0829 09:22:54.272012 916722 layer_factory.hpp:77] Creating layer B0_0_ConvBNScaleReLU_Scale
I0829 09:22:54.272022 916722 net.cpp:84] Creating Layer B0_0_ConvBNScaleReLU_Scale
I0829 09:22:54.272027 916722 net.cpp:406] B0_0_ConvBNScaleReLU_Scale <- B0_0_ConvBNScaleReLU_Conv
I0829 09:22:54.272033 916722 net.cpp:367] B0_0_ConvBNScaleReLU_Scale -> B0_0_ConvBNScaleReLU_Conv (in-place)
I0829 09:22:54.272059 916722 layer_factory.hpp:77] Creating layer B0_0_ConvBNScaleReLU_Scale
I0829 09:22:54.272131 916722 net.cpp:122] Setting up B0_0_ConvBNScaleReLU_Scale
I0829 09:22:54.272138 916722 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0829 09:22:54.272143 916722 net.cpp:137] Memory required for data: 798732
I0829 09:22:54.272150 916722 layer_factory.hpp:77] Creating layer B0_0_ConvBNScaleReLU_ReLU
I0829 09:22:54.272156 916722 net.cpp:84] Creating Layer B0_0_ConvBNScaleReLU_ReLU
I0829 09:22:54.272161 916722 net.cpp:406] B0_0_ConvBNScaleReLU_ReLU <- B0_0_ConvBNScaleReLU_Conv
I0829 09:22:54.272166 916722 net.cpp:367] B0_0_ConvBNScaleReLU_ReLU -> B0_0_ConvBNScaleReLU_Conv (in-place)
I0829 09:22:54.272171 916722 net.cpp:122] Setting up B0_0_ConvBNScaleReLU_ReLU
I0829 09:22:54.272176 916722 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0829 09:22:54.272181 916722 net.cpp:137] Memory required for data: 1060876
I0829 09:22:54.272186 916722 layer_factory.hpp:77] Creating layer B0_0_ConvBNScaleReLU_Dropout
I0829 09:22:54.272190 916722 net.cpp:84] Creating Layer B0_0_ConvBNScaleReLU_Dropout
I0829 09:22:54.272194 916722 net.cpp:406] B0_0_ConvBNScaleReLU_Dropout <- B0_0_ConvBNScaleReLU_Conv
I0829 09:22:54.272199 916722 net.cpp:380] B0_0_ConvBNScaleReLU_Dropout -> ConvBNScaleReLU
I0829 09:22:54.272222 916722 net.cpp:122] Setting up B0_0_ConvBNScaleReLU_Dropout
I0829 09:22:54.272228 916722 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0829 09:22:54.272233 916722 net.cpp:137] Memory required for data: 1323020
I0829 09:22:54.272238 916722 layer_factory.hpp:77] Creating layer B0_1_SConv_SparseConv
I0829 09:22:54.272243 916722 net.cpp:84] Creating Layer B0_1_SConv_SparseConv
I0829 09:22:54.272248 916722 net.cpp:406] B0_1_SConv_SparseConv <- ConvBNScaleReLU
I0829 09:22:54.272253 916722 net.cpp:380] B0_1_SConv_SparseConv -> B0_1_SConvBlockV2_T1
I0829 09:22:54.272367 916722 net.cpp:122] Setting up B0_1_SConv_SparseConv
I0829 09:22:54.272382 916722 net.cpp:129] Top shape: 1 512 32 32 (524288)
I0829 09:22:54.272387 916722 net.cpp:137] Memory required for data: 3420172
I0829 09:22:54.272392 916722 layer_factory.hpp:77] Creating layer B0_1_SConv_BN
I0829 09:22:54.272401 916722 net.cpp:84] Creating Layer B0_1_SConv_BN
I0829 09:22:54.272406 916722 net.cpp:406] B0_1_SConv_BN <- B0_1_SConvBlockV2_T1
I0829 09:22:54.272413 916722 net.cpp:367] B0_1_SConv_BN -> B0_1_SConvBlockV2_T1 (in-place)
I0829 09:22:54.272564 916722 net.cpp:122] Setting up B0_1_SConv_BN
I0829 09:22:54.272573 916722 net.cpp:129] Top shape: 1 512 32 32 (524288)
I0829 09:22:54.272579 916722 net.cpp:137] Memory required for data: 5517324
I0829 09:22:54.272591 916722 layer_factory.hpp:77] Creating layer B0_1_SConv_Scale
I0829 09:22:54.272598 916722 net.cpp:84] Creating Layer B0_1_SConv_Scale
I0829 09:22:54.272603 916722 net.cpp:406] B0_1_SConv_Scale <- B0_1_SConvBlockV2_T1
I0829 09:22:54.272609 916722 net.cpp:380] B0_1_SConv_Scale -> B0_1_SConvBlockV2_Scale
I0829 09:22:54.272640 916722 layer_factory.hpp:77] Creating layer B0_1_SConv_Scale
I0829 09:22:54.272717 916722 net.cpp:122] Setting up B0_1_SConv_Scale
I0829 09:22:54.272724 916722 net.cpp:129] Top shape: 1 512 32 32 (524288)
I0829 09:22:54.272730 916722 net.cpp:137] Memory required for data: 7614476
I0829 09:22:54.272737 916722 layer_factory.hpp:77] Creating layer B0_1_SConv_Conv1x1
I0829 09:22:54.272745 916722 net.cpp:84] Creating Layer B0_1_SConv_Conv1x1
I0829 09:22:54.272749 916722 net.cpp:406] B0_1_SConv_Conv1x1 <- B0_1_SConvBlockV2_Scale
I0829 09:22:54.272766 916722 net.cpp:380] B0_1_SConv_Conv1x1 -> B0_1_SConvBlockV2_Conv1x1
I0829 09:22:54.273082 916722 net.cpp:122] Setting up B0_1_SConv_Conv1x1
I0829 09:22:54.273089 916722 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0829 09:22:54.273094 916722 net.cpp:137] Memory required for data: 7876620
I0829 09:22:54.273100 916722 layer_factory.hpp:77] Creating layer B0_1_SConv_ReLU
I0829 09:22:54.273111 916722 net.cpp:84] Creating Layer B0_1_SConv_ReLU
I0829 09:22:54.273118 916722 net.cpp:406] B0_1_SConv_ReLU <- B0_1_SConvBlockV2_Conv1x1
I0829 09:22:54.273123 916722 net.cpp:367] B0_1_SConv_ReLU -> B0_1_SConvBlockV2_Conv1x1 (in-place)
I0829 09:22:54.273129 916722 net.cpp:122] Setting up B0_1_SConv_ReLU
I0829 09:22:54.273133 916722 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0829 09:22:54.273138 916722 net.cpp:137] Memory required for data: 8138764
I0829 09:22:54.273142 916722 layer_factory.hpp:77] Creating layer B0_1_SConv_Dropout
I0829 09:22:54.273149 916722 net.cpp:84] Creating Layer B0_1_SConv_Dropout
I0829 09:22:54.273152 916722 net.cpp:406] B0_1_SConv_Dropout <- B0_1_SConvBlockV2_Conv1x1
I0829 09:22:54.273159 916722 net.cpp:380] B0_1_SConv_Dropout -> B0_1_SConvBlockV2_Dropout
I0829 09:22:54.273183 916722 net.cpp:122] Setting up B0_1_SConv_Dropout
I0829 09:22:54.273190 916722 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0829 09:22:54.273195 916722 net.cpp:137] Memory required for data: 8400908
I0829 09:22:54.273200 916722 layer_factory.hpp:77] Creating layer B0_Pooling
I0829 09:22:54.273205 916722 net.cpp:84] Creating Layer B0_Pooling
I0829 09:22:54.273209 916722 net.cpp:406] B0_Pooling <- B0_1_SConvBlockV2_Dropout
I0829 09:22:54.273214 916722 net.cpp:380] B0_Pooling -> Pooling1
I0829 09:22:54.273233 916722 net.cpp:122] Setting up B0_Pooling
I0829 09:22:54.273239 916722 net.cpp:129] Top shape: 1 64 16 16 (16384)
I0829 09:22:54.273243 916722 net.cpp:137] Memory required for data: 8466444
I0829 09:22:54.273248 916722 layer_factory.hpp:77] Creating layer B1_0_SConv_SparseConv
I0829 09:22:54.273257 916722 net.cpp:84] Creating Layer B1_0_SConv_SparseConv
I0829 09:22:54.273262 916722 net.cpp:406] B1_0_SConv_SparseConv <- Pooling1
I0829 09:22:54.273267 916722 net.cpp:380] B1_0_SConv_SparseConv -> B1_0_SConvBlockV2_T1
I0829 09:22:54.273360 916722 net.cpp:122] Setting up B1_0_SConv_SparseConv
I0829 09:22:54.273366 916722 net.cpp:129] Top shape: 1 512 16 16 (131072)
I0829 09:22:54.273371 916722 net.cpp:137] Memory required for data: 8990732
I0829 09:22:54.273381 916722 layer_factory.hpp:77] Creating layer B1_0_SConv_BN
I0829 09:22:54.273396 916722 net.cpp:84] Creating Layer B1_0_SConv_BN
I0829 09:22:54.273401 916722 net.cpp:406] B1_0_SConv_BN <- B1_0_SConvBlockV2_T1
I0829 09:22:54.273406 916722 net.cpp:367] B1_0_SConv_BN -> B1_0_SConvBlockV2_T1 (in-place)
I0829 09:22:54.273496 916722 net.cpp:122] Setting up B1_0_SConv_BN
I0829 09:22:54.273504 916722 net.cpp:129] Top shape: 1 512 16 16 (131072)
I0829 09:22:54.273509 916722 net.cpp:137] Memory required for data: 9515020
I0829 09:22:54.273516 916722 layer_factory.hpp:77] Creating layer B1_0_SConv_Scale
I0829 09:22:54.273525 916722 net.cpp:84] Creating Layer B1_0_SConv_Scale
I0829 09:22:54.273530 916722 net.cpp:406] B1_0_SConv_Scale <- B1_0_SConvBlockV2_T1
I0829 09:22:54.273535 916722 net.cpp:380] B1_0_SConv_Scale -> B1_0_SConvBlockV2_Scale
I0829 09:22:54.273558 916722 layer_factory.hpp:77] Creating layer B1_0_SConv_Scale
I0829 09:22:54.273627 916722 net.cpp:122] Setting up B1_0_SConv_Scale
I0829 09:22:54.273633 916722 net.cpp:129] Top shape: 1 512 16 16 (131072)
I0829 09:22:54.273639 916722 net.cpp:137] Memory required for data: 10039308
I0829 09:22:54.273645 916722 layer_factory.hpp:77] Creating layer B1_0_SConv_Conv1x1
I0829 09:22:54.273654 916722 net.cpp:84] Creating Layer B1_0_SConv_Conv1x1
I0829 09:22:54.273659 916722 net.cpp:406] B1_0_SConv_Conv1x1 <- B1_0_SConvBlockV2_Scale
I0829 09:22:54.273664 916722 net.cpp:380] B1_0_SConv_Conv1x1 -> B1_0_SConvBlockV2_Conv1x1
I0829 09:22:54.274407 916722 net.cpp:122] Setting up B1_0_SConv_Conv1x1
I0829 09:22:54.274416 916722 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0829 09:22:54.274422 916722 net.cpp:137] Memory required for data: 10170380
I0829 09:22:54.274427 916722 layer_factory.hpp:77] Creating layer B1_0_SConv_ReLU
I0829 09:22:54.274435 916722 net.cpp:84] Creating Layer B1_0_SConv_ReLU
I0829 09:22:54.274441 916722 net.cpp:406] B1_0_SConv_ReLU <- B1_0_SConvBlockV2_Conv1x1
I0829 09:22:54.274446 916722 net.cpp:367] B1_0_SConv_ReLU -> B1_0_SConvBlockV2_Conv1x1 (in-place)
I0829 09:22:54.274452 916722 net.cpp:122] Setting up B1_0_SConv_ReLU
I0829 09:22:54.274456 916722 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0829 09:22:54.274461 916722 net.cpp:137] Memory required for data: 10301452
I0829 09:22:54.274466 916722 layer_factory.hpp:77] Creating layer B1_0_SConv_Dropout
I0829 09:22:54.274474 916722 net.cpp:84] Creating Layer B1_0_SConv_Dropout
I0829 09:22:54.274479 916722 net.cpp:406] B1_0_SConv_Dropout <- B1_0_SConvBlockV2_Conv1x1
I0829 09:22:54.274484 916722 net.cpp:380] B1_0_SConv_Dropout -> B1_0_SConvBlockV2_Dropout
I0829 09:22:54.274506 916722 net.cpp:122] Setting up B1_0_SConv_Dropout
I0829 09:22:54.274513 916722 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0829 09:22:54.274518 916722 net.cpp:137] Memory required for data: 10432524
I0829 09:22:54.274521 916722 layer_factory.hpp:77] Creating layer B1_1_SConv_SparseConv
I0829 09:22:54.274528 916722 net.cpp:84] Creating Layer B1_1_SConv_SparseConv
I0829 09:22:54.274533 916722 net.cpp:406] B1_1_SConv_SparseConv <- B1_0_SConvBlockV2_Dropout
I0829 09:22:54.274538 916722 net.cpp:380] B1_1_SConv_SparseConv -> B1_1_SConvBlockV2_T1
I0829 09:22:54.274672 916722 net.cpp:122] Setting up B1_1_SConv_SparseConv
I0829 09:22:54.274679 916722 net.cpp:129] Top shape: 1 1024 16 16 (262144)
I0829 09:22:54.274684 916722 net.cpp:137] Memory required for data: 11481100
I0829 09:22:54.274690 916722 layer_factory.hpp:77] Creating layer B1_1_SConv_BN
I0829 09:22:54.274696 916722 net.cpp:84] Creating Layer B1_1_SConv_BN
I0829 09:22:54.274701 916722 net.cpp:406] B1_1_SConv_BN <- B1_1_SConvBlockV2_T1
I0829 09:22:54.274708 916722 net.cpp:367] B1_1_SConv_BN -> B1_1_SConvBlockV2_T1 (in-place)
I0829 09:22:54.274791 916722 net.cpp:122] Setting up B1_1_SConv_BN
I0829 09:22:54.274797 916722 net.cpp:129] Top shape: 1 1024 16 16 (262144)
I0829 09:22:54.274802 916722 net.cpp:137] Memory required for data: 12529676
I0829 09:22:54.274809 916722 layer_factory.hpp:77] Creating layer B1_1_SConv_Scale
I0829 09:22:54.274817 916722 net.cpp:84] Creating Layer B1_1_SConv_Scale
I0829 09:22:54.274827 916722 net.cpp:406] B1_1_SConv_Scale <- B1_1_SConvBlockV2_T1
I0829 09:22:54.274839 916722 net.cpp:380] B1_1_SConv_Scale -> B1_1_SConvBlockV2_Scale
I0829 09:22:54.274865 916722 layer_factory.hpp:77] Creating layer B1_1_SConv_Scale
I0829 09:22:54.274924 916722 net.cpp:122] Setting up B1_1_SConv_Scale
I0829 09:22:54.274931 916722 net.cpp:129] Top shape: 1 1024 16 16 (262144)
I0829 09:22:54.274936 916722 net.cpp:137] Memory required for data: 13578252
I0829 09:22:54.274942 916722 layer_factory.hpp:77] Creating layer B1_1_SConv_Conv1x1
I0829 09:22:54.274951 916722 net.cpp:84] Creating Layer B1_1_SConv_Conv1x1
I0829 09:22:54.274956 916722 net.cpp:406] B1_1_SConv_Conv1x1 <- B1_1_SConvBlockV2_Scale
I0829 09:22:54.274964 916722 net.cpp:380] B1_1_SConv_Conv1x1 -> B1_1_SConvBlockV2_Conv1x1
I0829 09:22:54.275732 916722 net.cpp:122] Setting up B1_1_SConv_Conv1x1
I0829 09:22:54.275741 916722 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0829 09:22:54.275746 916722 net.cpp:137] Memory required for data: 13709324
I0829 09:22:54.275753 916722 layer_factory.hpp:77] Creating layer B1_1_SConv_ReLU
I0829 09:22:54.275758 916722 net.cpp:84] Creating Layer B1_1_SConv_ReLU
I0829 09:22:54.275763 916722 net.cpp:406] B1_1_SConv_ReLU <- B1_1_SConvBlockV2_Conv1x1
I0829 09:22:54.275772 916722 net.cpp:367] B1_1_SConv_ReLU -> B1_1_SConvBlockV2_Conv1x1 (in-place)
I0829 09:22:54.275779 916722 net.cpp:122] Setting up B1_1_SConv_ReLU
I0829 09:22:54.275784 916722 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0829 09:22:54.275787 916722 net.cpp:137] Memory required for data: 13840396
I0829 09:22:54.275792 916722 layer_factory.hpp:77] Creating layer B1_1_SConv_Dropout
I0829 09:22:54.275797 916722 net.cpp:84] Creating Layer B1_1_SConv_Dropout
I0829 09:22:54.275802 916722 net.cpp:406] B1_1_SConv_Dropout <- B1_1_SConvBlockV2_Conv1x1
I0829 09:22:54.275810 916722 net.cpp:380] B1_1_SConv_Dropout -> B1_1_SConvBlockV2_Dropout
I0829 09:22:54.275858 916722 net.cpp:122] Setting up B1_1_SConv_Dropout
I0829 09:22:54.275866 916722 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0829 09:22:54.275871 916722 net.cpp:137] Memory required for data: 13971468
I0829 09:22:54.275874 916722 layer_factory.hpp:77] Creating layer B1_Pooling
I0829 09:22:54.275882 916722 net.cpp:84] Creating Layer B1_Pooling
I0829 09:22:54.275887 916722 net.cpp:406] B1_Pooling <- B1_1_SConvBlockV2_Dropout
I0829 09:22:54.275892 916722 net.cpp:380] B1_Pooling -> Pooling2
I0829 09:22:54.275916 916722 net.cpp:122] Setting up B1_Pooling
I0829 09:22:54.275923 916722 net.cpp:129] Top shape: 1 128 8 8 (8192)
I0829 09:22:54.275928 916722 net.cpp:137] Memory required for data: 14004236
I0829 09:22:54.275933 916722 layer_factory.hpp:77] Creating layer B2_0_SConv_SparseConv
I0829 09:22:54.275940 916722 net.cpp:84] Creating Layer B2_0_SConv_SparseConv
I0829 09:22:54.275944 916722 net.cpp:406] B2_0_SConv_SparseConv <- Pooling2
I0829 09:22:54.275950 916722 net.cpp:380] B2_0_SConv_SparseConv -> B2_0_SConvBlockV2_T1
I0829 09:22:54.276093 916722 net.cpp:122] Setting up B2_0_SConv_SparseConv
I0829 09:22:54.276101 916722 net.cpp:129] Top shape: 1 1024 8 8 (65536)
I0829 09:22:54.276106 916722 net.cpp:137] Memory required for data: 14266380
I0829 09:22:54.276113 916722 layer_factory.hpp:77] Creating layer B2_0_SConv_BN
I0829 09:22:54.276118 916722 net.cpp:84] Creating Layer B2_0_SConv_BN
I0829 09:22:54.276124 916722 net.cpp:406] B2_0_SConv_BN <- B2_0_SConvBlockV2_T1
I0829 09:22:54.276129 916722 net.cpp:367] B2_0_SConv_BN -> B2_0_SConvBlockV2_T1 (in-place)
I0829 09:22:54.276249 916722 net.cpp:122] Setting up B2_0_SConv_BN
I0829 09:22:54.276255 916722 net.cpp:129] Top shape: 1 1024 8 8 (65536)
I0829 09:22:54.276262 916722 net.cpp:137] Memory required for data: 14528524
I0829 09:22:54.276270 916722 layer_factory.hpp:77] Creating layer B2_0_SConv_Scale
I0829 09:22:54.276278 916722 net.cpp:84] Creating Layer B2_0_SConv_Scale
I0829 09:22:54.276281 916722 net.cpp:406] B2_0_SConv_Scale <- B2_0_SConvBlockV2_T1
I0829 09:22:54.276288 916722 net.cpp:380] B2_0_SConv_Scale -> B2_0_SConvBlockV2_Scale
I0829 09:22:54.276319 916722 layer_factory.hpp:77] Creating layer B2_0_SConv_Scale
I0829 09:22:54.276397 916722 net.cpp:122] Setting up B2_0_SConv_Scale
I0829 09:22:54.276405 916722 net.cpp:129] Top shape: 1 1024 8 8 (65536)
I0829 09:22:54.276412 916722 net.cpp:137] Memory required for data: 14790668
I0829 09:22:54.276417 916722 layer_factory.hpp:77] Creating layer B2_0_SConv_Conv1x1
I0829 09:22:54.276449 916722 net.cpp:84] Creating Layer B2_0_SConv_Conv1x1
I0829 09:22:54.276458 916722 net.cpp:406] B2_0_SConv_Conv1x1 <- B2_0_SConvBlockV2_Scale
I0829 09:22:54.276464 916722 net.cpp:380] B2_0_SConv_Conv1x1 -> B2_0_SConvBlockV2_Conv1x1
I0829 09:22:54.277621 916722 net.cpp:122] Setting up B2_0_SConv_Conv1x1
I0829 09:22:54.277631 916722 net.cpp:129] Top shape: 1 192 8 8 (12288)
I0829 09:22:54.277637 916722 net.cpp:137] Memory required for data: 14839820
I0829 09:22:54.277642 916722 layer_factory.hpp:77] Creating layer B2_0_SConv_ReLU
I0829 09:22:54.277650 916722 net.cpp:84] Creating Layer B2_0_SConv_ReLU
I0829 09:22:54.277655 916722 net.cpp:406] B2_0_SConv_ReLU <- B2_0_SConvBlockV2_Conv1x1
I0829 09:22:54.277660 916722 net.cpp:367] B2_0_SConv_ReLU -> B2_0_SConvBlockV2_Conv1x1 (in-place)
I0829 09:22:54.277666 916722 net.cpp:122] Setting up B2_0_SConv_ReLU
I0829 09:22:54.277670 916722 net.cpp:129] Top shape: 1 192 8 8 (12288)
I0829 09:22:54.277675 916722 net.cpp:137] Memory required for data: 14888972
I0829 09:22:54.277679 916722 layer_factory.hpp:77] Creating layer B2_0_SConv_Dropout
I0829 09:22:54.277689 916722 net.cpp:84] Creating Layer B2_0_SConv_Dropout
I0829 09:22:54.277694 916722 net.cpp:406] B2_0_SConv_Dropout <- B2_0_SConvBlockV2_Conv1x1
I0829 09:22:54.277699 916722 net.cpp:380] B2_0_SConv_Dropout -> B2_0_SConvBlockV2_Dropout
I0829 09:22:54.277724 916722 net.cpp:122] Setting up B2_0_SConv_Dropout
I0829 09:22:54.277729 916722 net.cpp:129] Top shape: 1 192 8 8 (12288)
I0829 09:22:54.277734 916722 net.cpp:137] Memory required for data: 14938124
I0829 09:22:54.277738 916722 layer_factory.hpp:77] Creating layer B2_1_SConv_SparseConv
I0829 09:22:54.277747 916722 net.cpp:84] Creating Layer B2_1_SConv_SparseConv
I0829 09:22:54.277752 916722 net.cpp:406] B2_1_SConv_SparseConv <- B2_0_SConvBlockV2_Dropout
I0829 09:22:54.277758 916722 net.cpp:380] B2_1_SConv_SparseConv -> B2_1_SConvBlockV2_T1
I0829 09:22:54.277920 916722 net.cpp:122] Setting up B2_1_SConv_SparseConv
I0829 09:22:54.277926 916722 net.cpp:129] Top shape: 1 1536 8 8 (98304)
I0829 09:22:54.277931 916722 net.cpp:137] Memory required for data: 15331340
I0829 09:22:54.277936 916722 layer_factory.hpp:77] Creating layer B2_1_SConv_BN
I0829 09:22:54.277945 916722 net.cpp:84] Creating Layer B2_1_SConv_BN
I0829 09:22:54.277949 916722 net.cpp:406] B2_1_SConv_BN <- B2_1_SConvBlockV2_T1
I0829 09:22:54.277956 916722 net.cpp:367] B2_1_SConv_BN -> B2_1_SConvBlockV2_T1 (in-place)
I0829 09:22:54.278038 916722 net.cpp:122] Setting up B2_1_SConv_BN
I0829 09:22:54.278044 916722 net.cpp:129] Top shape: 1 1536 8 8 (98304)
I0829 09:22:54.278049 916722 net.cpp:137] Memory required for data: 15724556
I0829 09:22:54.278056 916722 layer_factory.hpp:77] Creating layer B2_1_SConv_Scale
I0829 09:22:54.278062 916722 net.cpp:84] Creating Layer B2_1_SConv_Scale
I0829 09:22:54.278066 916722 net.cpp:406] B2_1_SConv_Scale <- B2_1_SConvBlockV2_T1
I0829 09:22:54.278074 916722 net.cpp:380] B2_1_SConv_Scale -> B2_1_SConvBlockV2_Scale
I0829 09:22:54.278095 916722 layer_factory.hpp:77] Creating layer B2_1_SConv_Scale
I0829 09:22:54.278149 916722 net.cpp:122] Setting up B2_1_SConv_Scale
I0829 09:22:54.278157 916722 net.cpp:129] Top shape: 1 1536 8 8 (98304)
I0829 09:22:54.278162 916722 net.cpp:137] Memory required for data: 16117772
I0829 09:22:54.278168 916722 layer_factory.hpp:77] Creating layer B2_1_SConv_Conv1x1
I0829 09:22:54.278175 916722 net.cpp:84] Creating Layer B2_1_SConv_Conv1x1
I0829 09:22:54.278179 916722 net.cpp:406] B2_1_SConv_Conv1x1 <- B2_1_SConvBlockV2_Scale
I0829 09:22:54.278188 916722 net.cpp:380] B2_1_SConv_Conv1x1 -> B2_1_SConvBlockV2_Conv1x1
I0829 09:22:54.280678 916722 net.cpp:122] Setting up B2_1_SConv_Conv1x1
I0829 09:22:54.280696 916722 net.cpp:129] Top shape: 1 192 8 8 (12288)
I0829 09:22:54.280710 916722 net.cpp:137] Memory required for data: 16166924
I0829 09:22:54.280717 916722 layer_factory.hpp:77] Creating layer B2_1_SConv_ReLU
I0829 09:22:54.280725 916722 net.cpp:84] Creating Layer B2_1_SConv_ReLU
I0829 09:22:54.280730 916722 net.cpp:406] B2_1_SConv_ReLU <- B2_1_SConvBlockV2_Conv1x1
I0829 09:22:54.280736 916722 net.cpp:367] B2_1_SConv_ReLU -> B2_1_SConvBlockV2_Conv1x1 (in-place)
I0829 09:22:54.280755 916722 net.cpp:122] Setting up B2_1_SConv_ReLU
I0829 09:22:54.280758 916722 net.cpp:129] Top shape: 1 192 8 8 (12288)
I0829 09:22:54.280763 916722 net.cpp:137] Memory required for data: 16216076
I0829 09:22:54.280767 916722 layer_factory.hpp:77] Creating layer B2_1_SConv_Dropout
I0829 09:22:54.280776 916722 net.cpp:84] Creating Layer B2_1_SConv_Dropout
I0829 09:22:54.280779 916722 net.cpp:406] B2_1_SConv_Dropout <- B2_1_SConvBlockV2_Conv1x1
I0829 09:22:54.280786 916722 net.cpp:380] B2_1_SConv_Dropout -> B2_1_SConvBlockV2_Dropout
I0829 09:22:54.280812 916722 net.cpp:122] Setting up B2_1_SConv_Dropout
I0829 09:22:54.280817 916722 net.cpp:129] Top shape: 1 192 8 8 (12288)
I0829 09:22:54.280822 916722 net.cpp:137] Memory required for data: 16265228
I0829 09:22:54.280826 916722 layer_factory.hpp:77] Creating layer B2_2_SConv_SparseConv
I0829 09:22:54.280834 916722 net.cpp:84] Creating Layer B2_2_SConv_SparseConv
I0829 09:22:54.280839 916722 net.cpp:406] B2_2_SConv_SparseConv <- B2_1_SConvBlockV2_Dropout
I0829 09:22:54.280844 916722 net.cpp:380] B2_2_SConv_SparseConv -> B2_2_SConvBlockV2_T1
I0829 09:22:54.281018 916722 net.cpp:122] Setting up B2_2_SConv_SparseConv
I0829 09:22:54.281025 916722 net.cpp:129] Top shape: 1 1536 8 8 (98304)
I0829 09:22:54.281030 916722 net.cpp:137] Memory required for data: 16658444
I0829 09:22:54.281036 916722 layer_factory.hpp:77] Creating layer B2_2_SConv_BN
I0829 09:22:54.281044 916722 net.cpp:84] Creating Layer B2_2_SConv_BN
I0829 09:22:54.281049 916722 net.cpp:406] B2_2_SConv_BN <- B2_2_SConvBlockV2_T1
I0829 09:22:54.281055 916722 net.cpp:367] B2_2_SConv_BN -> B2_2_SConvBlockV2_T1 (in-place)
I0829 09:22:54.281145 916722 net.cpp:122] Setting up B2_2_SConv_BN
I0829 09:22:54.281152 916722 net.cpp:129] Top shape: 1 1536 8 8 (98304)
I0829 09:22:54.281157 916722 net.cpp:137] Memory required for data: 17051660
I0829 09:22:54.281163 916722 layer_factory.hpp:77] Creating layer B2_2_SConv_Scale
I0829 09:22:54.281169 916722 net.cpp:84] Creating Layer B2_2_SConv_Scale
I0829 09:22:54.281173 916722 net.cpp:406] B2_2_SConv_Scale <- B2_2_SConvBlockV2_T1
I0829 09:22:54.281179 916722 net.cpp:380] B2_2_SConv_Scale -> B2_2_SConvBlockV2_Scale
I0829 09:22:54.281203 916722 layer_factory.hpp:77] Creating layer B2_2_SConv_Scale
I0829 09:22:54.281260 916722 net.cpp:122] Setting up B2_2_SConv_Scale
I0829 09:22:54.281266 916722 net.cpp:129] Top shape: 1 1536 8 8 (98304)
I0829 09:22:54.281271 916722 net.cpp:137] Memory required for data: 17444876
I0829 09:22:54.281277 916722 layer_factory.hpp:77] Creating layer B2_2_SConv_Conv1x1
I0829 09:22:54.281286 916722 net.cpp:84] Creating Layer B2_2_SConv_Conv1x1
I0829 09:22:54.281291 916722 net.cpp:406] B2_2_SConv_Conv1x1 <- B2_2_SConvBlockV2_Scale
I0829 09:22:54.281298 916722 net.cpp:380] B2_2_SConv_Conv1x1 -> B2_2_SConvBlockV2_Conv1x1
I0829 09:22:54.283751 916722 net.cpp:122] Setting up B2_2_SConv_Conv1x1
I0829 09:22:54.283764 916722 net.cpp:129] Top shape: 1 192 8 8 (12288)
I0829 09:22:54.283771 916722 net.cpp:137] Memory required for data: 17494028
I0829 09:22:54.283776 916722 layer_factory.hpp:77] Creating layer B2_2_SConv_ReLU
I0829 09:22:54.283785 916722 net.cpp:84] Creating Layer B2_2_SConv_ReLU
I0829 09:22:54.283790 916722 net.cpp:406] B2_2_SConv_ReLU <- B2_2_SConvBlockV2_Conv1x1
I0829 09:22:54.283797 916722 net.cpp:367] B2_2_SConv_ReLU -> B2_2_SConvBlockV2_Conv1x1 (in-place)
I0829 09:22:54.283803 916722 net.cpp:122] Setting up B2_2_SConv_ReLU
I0829 09:22:54.283807 916722 net.cpp:129] Top shape: 1 192 8 8 (12288)
I0829 09:22:54.283812 916722 net.cpp:137] Memory required for data: 17543180
I0829 09:22:54.283826 916722 layer_factory.hpp:77] Creating layer B2_2_SConv_Dropout
I0829 09:22:54.283834 916722 net.cpp:84] Creating Layer B2_2_SConv_Dropout
I0829 09:22:54.283839 916722 net.cpp:406] B2_2_SConv_Dropout <- B2_2_SConvBlockV2_Conv1x1
I0829 09:22:54.283845 916722 net.cpp:380] B2_2_SConv_Dropout -> B2_2_SConvBlockV2_Dropout
I0829 09:22:54.283871 916722 net.cpp:122] Setting up B2_2_SConv_Dropout
I0829 09:22:54.283877 916722 net.cpp:129] Top shape: 1 192 8 8 (12288)
I0829 09:22:54.283882 916722 net.cpp:137] Memory required for data: 17592332
I0829 09:22:54.283886 916722 layer_factory.hpp:77] Creating layer B2_Pooling
I0829 09:22:54.283892 916722 net.cpp:84] Creating Layer B2_Pooling
I0829 09:22:54.283897 916722 net.cpp:406] B2_Pooling <- B2_2_SConvBlockV2_Dropout
I0829 09:22:54.283902 916722 net.cpp:380] B2_Pooling -> Pooling3
I0829 09:22:54.283931 916722 net.cpp:122] Setting up B2_Pooling
I0829 09:22:54.283937 916722 net.cpp:129] Top shape: 1 192 4 4 (3072)
I0829 09:22:54.283942 916722 net.cpp:137] Memory required for data: 17604620
I0829 09:22:54.283946 916722 layer_factory.hpp:77] Creating layer B3_0_SConv_SparseConv
I0829 09:22:54.283954 916722 net.cpp:84] Creating Layer B3_0_SConv_SparseConv
I0829 09:22:54.283958 916722 net.cpp:406] B3_0_SConv_SparseConv <- Pooling3
I0829 09:22:54.283964 916722 net.cpp:380] B3_0_SConv_SparseConv -> B3_0_SConvBlockV2_T1
I0829 09:22:54.284128 916722 net.cpp:122] Setting up B3_0_SConv_SparseConv
I0829 09:22:54.284135 916722 net.cpp:129] Top shape: 1 1536 4 4 (24576)
I0829 09:22:54.284140 916722 net.cpp:137] Memory required for data: 17702924
I0829 09:22:54.284145 916722 layer_factory.hpp:77] Creating layer B3_0_SConv_BN
I0829 09:22:54.284154 916722 net.cpp:84] Creating Layer B3_0_SConv_BN
I0829 09:22:54.284158 916722 net.cpp:406] B3_0_SConv_BN <- B3_0_SConvBlockV2_T1
I0829 09:22:54.284164 916722 net.cpp:367] B3_0_SConv_BN -> B3_0_SConvBlockV2_T1 (in-place)
I0829 09:22:54.284253 916722 net.cpp:122] Setting up B3_0_SConv_BN
I0829 09:22:54.284260 916722 net.cpp:129] Top shape: 1 1536 4 4 (24576)
I0829 09:22:54.284265 916722 net.cpp:137] Memory required for data: 17801228
I0829 09:22:54.284272 916722 layer_factory.hpp:77] Creating layer B3_0_SConv_Scale
I0829 09:22:54.284277 916722 net.cpp:84] Creating Layer B3_0_SConv_Scale
I0829 09:22:54.284282 916722 net.cpp:406] B3_0_SConv_Scale <- B3_0_SConvBlockV2_T1
I0829 09:22:54.284287 916722 net.cpp:380] B3_0_SConv_Scale -> B3_0_SConvBlockV2_Scale
I0829 09:22:54.284312 916722 layer_factory.hpp:77] Creating layer B3_0_SConv_Scale
I0829 09:22:54.284370 916722 net.cpp:122] Setting up B3_0_SConv_Scale
I0829 09:22:54.284376 916722 net.cpp:129] Top shape: 1 1536 4 4 (24576)
I0829 09:22:54.284381 916722 net.cpp:137] Memory required for data: 17899532
I0829 09:22:54.284387 916722 layer_factory.hpp:77] Creating layer B3_0_SConv_Conv1x1
I0829 09:22:54.284397 916722 net.cpp:84] Creating Layer B3_0_SConv_Conv1x1
I0829 09:22:54.284402 916722 net.cpp:406] B3_0_SConv_Conv1x1 <- B3_0_SConvBlockV2_Scale
I0829 09:22:54.284408 916722 net.cpp:380] B3_0_SConv_Conv1x1 -> B3_0_SConvBlockV2_Conv1x1
I0829 09:22:54.286911 916722 net.cpp:122] Setting up B3_0_SConv_Conv1x1
I0829 09:22:54.286924 916722 net.cpp:129] Top shape: 1 192 4 4 (3072)
I0829 09:22:54.286931 916722 net.cpp:137] Memory required for data: 17911820
I0829 09:22:54.286936 916722 layer_factory.hpp:77] Creating layer B3_0_SConv_ReLU
I0829 09:22:54.286945 916722 net.cpp:84] Creating Layer B3_0_SConv_ReLU
I0829 09:22:54.286950 916722 net.cpp:406] B3_0_SConv_ReLU <- B3_0_SConvBlockV2_Conv1x1
I0829 09:22:54.286957 916722 net.cpp:367] B3_0_SConv_ReLU -> B3_0_SConvBlockV2_Conv1x1 (in-place)
I0829 09:22:54.286963 916722 net.cpp:122] Setting up B3_0_SConv_ReLU
I0829 09:22:54.286967 916722 net.cpp:129] Top shape: 1 192 4 4 (3072)
I0829 09:22:54.286972 916722 net.cpp:137] Memory required for data: 17924108
I0829 09:22:54.286976 916722 layer_factory.hpp:77] Creating layer B3_0_SConv_Dropout
I0829 09:22:54.286983 916722 net.cpp:84] Creating Layer B3_0_SConv_Dropout
I0829 09:22:54.286991 916722 net.cpp:406] B3_0_SConv_Dropout <- B3_0_SConvBlockV2_Conv1x1
I0829 09:22:54.287005 916722 net.cpp:380] B3_0_SConv_Dropout -> B3_0_SConvBlockV2_Dropout
I0829 09:22:54.287030 916722 net.cpp:122] Setting up B3_0_SConv_Dropout
I0829 09:22:54.287037 916722 net.cpp:129] Top shape: 1 192 4 4 (3072)
I0829 09:22:54.287042 916722 net.cpp:137] Memory required for data: 17936396
I0829 09:22:54.287046 916722 layer_factory.hpp:77] Creating layer B3_1_SConv_SparseConv
I0829 09:22:54.287055 916722 net.cpp:84] Creating Layer B3_1_SConv_SparseConv
I0829 09:22:54.287060 916722 net.cpp:406] B3_1_SConv_SparseConv <- B3_0_SConvBlockV2_Dropout
I0829 09:22:54.287065 916722 net.cpp:380] B3_1_SConv_SparseConv -> B3_1_SConvBlockV2_T1
I0829 09:22:54.287236 916722 net.cpp:122] Setting up B3_1_SConv_SparseConv
I0829 09:22:54.287245 916722 net.cpp:129] Top shape: 1 1536 4 4 (24576)
I0829 09:22:54.287250 916722 net.cpp:137] Memory required for data: 18034700
I0829 09:22:54.287254 916722 layer_factory.hpp:77] Creating layer B3_1_SConv_BN
I0829 09:22:54.287263 916722 net.cpp:84] Creating Layer B3_1_SConv_BN
I0829 09:22:54.287268 916722 net.cpp:406] B3_1_SConv_BN <- B3_1_SConvBlockV2_T1
I0829 09:22:54.287273 916722 net.cpp:367] B3_1_SConv_BN -> B3_1_SConvBlockV2_T1 (in-place)
I0829 09:22:54.287356 916722 net.cpp:122] Setting up B3_1_SConv_BN
I0829 09:22:54.287362 916722 net.cpp:129] Top shape: 1 1536 4 4 (24576)
I0829 09:22:54.287367 916722 net.cpp:137] Memory required for data: 18133004
I0829 09:22:54.287379 916722 layer_factory.hpp:77] Creating layer B3_1_SConv_Scale
I0829 09:22:54.287385 916722 net.cpp:84] Creating Layer B3_1_SConv_Scale
I0829 09:22:54.287389 916722 net.cpp:406] B3_1_SConv_Scale <- B3_1_SConvBlockV2_T1
I0829 09:22:54.287395 916722 net.cpp:380] B3_1_SConv_Scale -> B3_1_SConvBlockV2_Scale
I0829 09:22:54.287421 916722 layer_factory.hpp:77] Creating layer B3_1_SConv_Scale
I0829 09:22:54.287487 916722 net.cpp:122] Setting up B3_1_SConv_Scale
I0829 09:22:54.287492 916722 net.cpp:129] Top shape: 1 1536 4 4 (24576)
I0829 09:22:54.287498 916722 net.cpp:137] Memory required for data: 18231308
I0829 09:22:54.287504 916722 layer_factory.hpp:77] Creating layer B3_1_SConv_Conv1x1
I0829 09:22:54.287518 916722 net.cpp:84] Creating Layer B3_1_SConv_Conv1x1
I0829 09:22:54.287523 916722 net.cpp:406] B3_1_SConv_Conv1x1 <- B3_1_SConvBlockV2_Scale
I0829 09:22:54.287528 916722 net.cpp:380] B3_1_SConv_Conv1x1 -> B3_1_SConvBlockV2_Conv1x1
I0829 09:22:54.290022 916722 net.cpp:122] Setting up B3_1_SConv_Conv1x1
I0829 09:22:54.290035 916722 net.cpp:129] Top shape: 1 192 4 4 (3072)
I0829 09:22:54.290042 916722 net.cpp:137] Memory required for data: 18243596
I0829 09:22:54.290048 916722 layer_factory.hpp:77] Creating layer B3_1_SConv_ReLU
I0829 09:22:54.290055 916722 net.cpp:84] Creating Layer B3_1_SConv_ReLU
I0829 09:22:54.290060 916722 net.cpp:406] B3_1_SConv_ReLU <- B3_1_SConvBlockV2_Conv1x1
I0829 09:22:54.290066 916722 net.cpp:367] B3_1_SConv_ReLU -> B3_1_SConvBlockV2_Conv1x1 (in-place)
I0829 09:22:54.290072 916722 net.cpp:122] Setting up B3_1_SConv_ReLU
I0829 09:22:54.290076 916722 net.cpp:129] Top shape: 1 192 4 4 (3072)
I0829 09:22:54.290081 916722 net.cpp:137] Memory required for data: 18255884
I0829 09:22:54.290086 916722 layer_factory.hpp:77] Creating layer B3_1_SConv_Dropout
I0829 09:22:54.290093 916722 net.cpp:84] Creating Layer B3_1_SConv_Dropout
I0829 09:22:54.290097 916722 net.cpp:406] B3_1_SConv_Dropout <- B3_1_SConvBlockV2_Conv1x1
I0829 09:22:54.290103 916722 net.cpp:380] B3_1_SConv_Dropout -> B3_1_SConvBlockV2_Dropout
I0829 09:22:54.290127 916722 net.cpp:122] Setting up B3_1_SConv_Dropout
I0829 09:22:54.290134 916722 net.cpp:129] Top shape: 1 192 4 4 (3072)
I0829 09:22:54.290139 916722 net.cpp:137] Memory required for data: 18268172
I0829 09:22:54.290143 916722 layer_factory.hpp:77] Creating layer B3_2_SConv_SparseConv
I0829 09:22:54.290151 916722 net.cpp:84] Creating Layer B3_2_SConv_SparseConv
I0829 09:22:54.290156 916722 net.cpp:406] B3_2_SConv_SparseConv <- B3_1_SConvBlockV2_Dropout
I0829 09:22:54.290161 916722 net.cpp:380] B3_2_SConv_SparseConv -> B3_2_SConvBlockV2_T1
I0829 09:22:54.290336 916722 net.cpp:122] Setting up B3_2_SConv_SparseConv
I0829 09:22:54.290344 916722 net.cpp:129] Top shape: 1 1536 4 4 (24576)
I0829 09:22:54.290350 916722 net.cpp:137] Memory required for data: 18366476
I0829 09:22:54.290355 916722 layer_factory.hpp:77] Creating layer B3_2_SConv_BN
I0829 09:22:54.290364 916722 net.cpp:84] Creating Layer B3_2_SConv_BN
I0829 09:22:54.290369 916722 net.cpp:406] B3_2_SConv_BN <- B3_2_SConvBlockV2_T1
I0829 09:22:54.290376 916722 net.cpp:367] B3_2_SConv_BN -> B3_2_SConvBlockV2_T1 (in-place)
I0829 09:22:54.290459 916722 net.cpp:122] Setting up B3_2_SConv_BN
I0829 09:22:54.290465 916722 net.cpp:129] Top shape: 1 1536 4 4 (24576)
I0829 09:22:54.290472 916722 net.cpp:137] Memory required for data: 18464780
I0829 09:22:54.290477 916722 layer_factory.hpp:77] Creating layer B3_2_SConv_Scale
I0829 09:22:54.290485 916722 net.cpp:84] Creating Layer B3_2_SConv_Scale
I0829 09:22:54.290489 916722 net.cpp:406] B3_2_SConv_Scale <- B3_2_SConvBlockV2_T1
I0829 09:22:54.290495 916722 net.cpp:380] B3_2_SConv_Scale -> B3_2_SConvBlockV2_Scale
I0829 09:22:54.290518 916722 layer_factory.hpp:77] Creating layer B3_2_SConv_Scale
I0829 09:22:54.290573 916722 net.cpp:122] Setting up B3_2_SConv_Scale
I0829 09:22:54.290580 916722 net.cpp:129] Top shape: 1 1536 4 4 (24576)
I0829 09:22:54.290585 916722 net.cpp:137] Memory required for data: 18563084
I0829 09:22:54.290591 916722 layer_factory.hpp:77] Creating layer B3_2_SConv_Conv1x1
I0829 09:22:54.290601 916722 net.cpp:84] Creating Layer B3_2_SConv_Conv1x1
I0829 09:22:54.290606 916722 net.cpp:406] B3_2_SConv_Conv1x1 <- B3_2_SConvBlockV2_Scale
I0829 09:22:54.290612 916722 net.cpp:380] B3_2_SConv_Conv1x1 -> B3_2_SConvBlockV2_Conv1x1
I0829 09:22:54.293145 916722 net.cpp:122] Setting up B3_2_SConv_Conv1x1
I0829 09:22:54.293159 916722 net.cpp:129] Top shape: 1 192 4 4 (3072)
I0829 09:22:54.293164 916722 net.cpp:137] Memory required for data: 18575372
I0829 09:22:54.293170 916722 layer_factory.hpp:77] Creating layer B3_2_SConv_ReLU
I0829 09:22:54.293177 916722 net.cpp:84] Creating Layer B3_2_SConv_ReLU
I0829 09:22:54.293181 916722 net.cpp:406] B3_2_SConv_ReLU <- B3_2_SConvBlockV2_Conv1x1
I0829 09:22:54.293187 916722 net.cpp:367] B3_2_SConv_ReLU -> B3_2_SConvBlockV2_Conv1x1 (in-place)
I0829 09:22:54.293195 916722 net.cpp:122] Setting up B3_2_SConv_ReLU
I0829 09:22:54.293200 916722 net.cpp:129] Top shape: 1 192 4 4 (3072)
I0829 09:22:54.293205 916722 net.cpp:137] Memory required for data: 18587660
I0829 09:22:54.293208 916722 layer_factory.hpp:77] Creating layer B3_2_SConv_Dropout
I0829 09:22:54.293215 916722 net.cpp:84] Creating Layer B3_2_SConv_Dropout
I0829 09:22:54.293220 916722 net.cpp:406] B3_2_SConv_Dropout <- B3_2_SConvBlockV2_Conv1x1
I0829 09:22:54.293226 916722 net.cpp:380] B3_2_SConv_Dropout -> B3_2_SConvBlockV2_Dropout
I0829 09:22:54.293251 916722 net.cpp:122] Setting up B3_2_SConv_Dropout
I0829 09:22:54.293256 916722 net.cpp:129] Top shape: 1 192 4 4 (3072)
I0829 09:22:54.293262 916722 net.cpp:137] Memory required for data: 18599948
I0829 09:22:54.293267 916722 layer_factory.hpp:77] Creating layer B3_Pooling
I0829 09:22:54.293278 916722 net.cpp:84] Creating Layer B3_Pooling
I0829 09:22:54.293282 916722 net.cpp:406] B3_Pooling <- B3_2_SConvBlockV2_Dropout
I0829 09:22:54.293288 916722 net.cpp:380] B3_Pooling -> Pooling4
I0829 09:22:54.293305 916722 net.cpp:122] Setting up B3_Pooling
I0829 09:22:54.293310 916722 net.cpp:129] Top shape: 1 192 1 1 (192)
I0829 09:22:54.293315 916722 net.cpp:137] Memory required for data: 18600716
I0829 09:22:54.293319 916722 layer_factory.hpp:77] Creating layer fc1
I0829 09:22:54.293325 916722 net.cpp:84] Creating Layer fc1
I0829 09:22:54.293330 916722 net.cpp:406] fc1 <- Pooling4
I0829 09:22:54.293337 916722 net.cpp:380] fc1 -> fc1
I0829 09:22:54.293766 916722 net.cpp:122] Setting up fc1
I0829 09:22:54.293772 916722 net.cpp:129] Top shape: 1 384 (384)
I0829 09:22:54.293777 916722 net.cpp:137] Memory required for data: 18602252
I0829 09:22:54.293783 916722 layer_factory.hpp:77] Creating layer classifier
I0829 09:22:54.293807 916722 net.cpp:84] Creating Layer classifier
I0829 09:22:54.293813 916722 net.cpp:406] classifier <- fc1
I0829 09:22:54.293819 916722 net.cpp:380] classifier -> classifier
I0829 09:22:54.293885 916722 net.cpp:122] Setting up classifier
I0829 09:22:54.293892 916722 net.cpp:129] Top shape: 1 10 (10)
I0829 09:22:54.293897 916722 net.cpp:137] Memory required for data: 18602292
I0829 09:22:54.293902 916722 layer_factory.hpp:77] Creating layer classifier_classifier_0_split
I0829 09:22:54.293910 916722 net.cpp:84] Creating Layer classifier_classifier_0_split
I0829 09:22:54.293913 916722 net.cpp:406] classifier_classifier_0_split <- classifier
I0829 09:22:54.293920 916722 net.cpp:380] classifier_classifier_0_split -> classifier_classifier_0_split_0
I0829 09:22:54.293927 916722 net.cpp:380] classifier_classifier_0_split -> classifier_classifier_0_split_1
I0829 09:22:54.293946 916722 net.cpp:122] Setting up classifier_classifier_0_split
I0829 09:22:54.293951 916722 net.cpp:129] Top shape: 1 10 (10)
I0829 09:22:54.293956 916722 net.cpp:129] Top shape: 1 10 (10)
I0829 09:22:54.293962 916722 net.cpp:137] Memory required for data: 18602372
I0829 09:22:54.293965 916722 layer_factory.hpp:77] Creating layer softmax_loss
I0829 09:22:54.293972 916722 net.cpp:84] Creating Layer softmax_loss
I0829 09:22:54.293977 916722 net.cpp:406] softmax_loss <- classifier_classifier_0_split_0
I0829 09:22:54.293982 916722 net.cpp:406] softmax_loss <- label_InputData_1_split_0
I0829 09:22:54.293988 916722 net.cpp:380] softmax_loss -> softmax_loss
I0829 09:22:54.293996 916722 layer_factory.hpp:77] Creating layer softmax_loss
I0829 09:22:54.294041 916722 net.cpp:122] Setting up softmax_loss
I0829 09:22:54.294049 916722 net.cpp:129] Top shape: (1)
I0829 09:22:54.294052 916722 net.cpp:132]     with loss weight 1
I0829 09:22:54.294061 916722 net.cpp:137] Memory required for data: 18602376
I0829 09:22:54.294065 916722 layer_factory.hpp:77] Creating layer accuracy
I0829 09:22:54.294080 916722 net.cpp:84] Creating Layer accuracy
I0829 09:22:54.294085 916722 net.cpp:406] accuracy <- classifier_classifier_0_split_1
I0829 09:22:54.294090 916722 net.cpp:406] accuracy <- label_InputData_1_split_1
I0829 09:22:54.294095 916722 net.cpp:380] accuracy -> accuracy
I0829 09:22:54.294106 916722 net.cpp:122] Setting up accuracy
I0829 09:22:54.294109 916722 net.cpp:129] Top shape: (1)
I0829 09:22:54.294114 916722 net.cpp:137] Memory required for data: 18602380
I0829 09:22:54.294118 916722 net.cpp:200] accuracy does not need backward computation.
I0829 09:22:54.294123 916722 net.cpp:198] softmax_loss needs backward computation.
I0829 09:22:54.294128 916722 net.cpp:198] classifier_classifier_0_split needs backward computation.
I0829 09:22:54.294132 916722 net.cpp:198] classifier needs backward computation.
I0829 09:22:54.294137 916722 net.cpp:198] fc1 needs backward computation.
I0829 09:22:54.294140 916722 net.cpp:198] B3_Pooling needs backward computation.
I0829 09:22:54.294145 916722 net.cpp:198] B3_2_SConv_Dropout needs backward computation.
I0829 09:22:54.294149 916722 net.cpp:198] B3_2_SConv_ReLU needs backward computation.
I0829 09:22:54.294154 916722 net.cpp:198] B3_2_SConv_Conv1x1 needs backward computation.
I0829 09:22:54.294158 916722 net.cpp:198] B3_2_SConv_Scale needs backward computation.
I0829 09:22:54.294162 916722 net.cpp:198] B3_2_SConv_BN needs backward computation.
I0829 09:22:54.294167 916722 net.cpp:198] B3_2_SConv_SparseConv needs backward computation.
I0829 09:22:54.294171 916722 net.cpp:198] B3_1_SConv_Dropout needs backward computation.
I0829 09:22:54.294175 916722 net.cpp:198] B3_1_SConv_ReLU needs backward computation.
I0829 09:22:54.294179 916722 net.cpp:198] B3_1_SConv_Conv1x1 needs backward computation.
I0829 09:22:54.294183 916722 net.cpp:198] B3_1_SConv_Scale needs backward computation.
I0829 09:22:54.294188 916722 net.cpp:198] B3_1_SConv_BN needs backward computation.
I0829 09:22:54.294193 916722 net.cpp:198] B3_1_SConv_SparseConv needs backward computation.
I0829 09:22:54.294196 916722 net.cpp:198] B3_0_SConv_Dropout needs backward computation.
I0829 09:22:54.294214 916722 net.cpp:198] B3_0_SConv_ReLU needs backward computation.
I0829 09:22:54.294219 916722 net.cpp:198] B3_0_SConv_Conv1x1 needs backward computation.
I0829 09:22:54.294222 916722 net.cpp:198] B3_0_SConv_Scale needs backward computation.
I0829 09:22:54.294226 916722 net.cpp:198] B3_0_SConv_BN needs backward computation.
I0829 09:22:54.294230 916722 net.cpp:198] B3_0_SConv_SparseConv needs backward computation.
I0829 09:22:54.294235 916722 net.cpp:198] B2_Pooling needs backward computation.
I0829 09:22:54.294241 916722 net.cpp:198] B2_2_SConv_Dropout needs backward computation.
I0829 09:22:54.294245 916722 net.cpp:198] B2_2_SConv_ReLU needs backward computation.
I0829 09:22:54.294250 916722 net.cpp:198] B2_2_SConv_Conv1x1 needs backward computation.
I0829 09:22:54.294253 916722 net.cpp:198] B2_2_SConv_Scale needs backward computation.
I0829 09:22:54.294258 916722 net.cpp:198] B2_2_SConv_BN needs backward computation.
I0829 09:22:54.294262 916722 net.cpp:198] B2_2_SConv_SparseConv needs backward computation.
I0829 09:22:54.294266 916722 net.cpp:198] B2_1_SConv_Dropout needs backward computation.
I0829 09:22:54.294270 916722 net.cpp:198] B2_1_SConv_ReLU needs backward computation.
I0829 09:22:54.294275 916722 net.cpp:198] B2_1_SConv_Conv1x1 needs backward computation.
I0829 09:22:54.294279 916722 net.cpp:198] B2_1_SConv_Scale needs backward computation.
I0829 09:22:54.294283 916722 net.cpp:198] B2_1_SConv_BN needs backward computation.
I0829 09:22:54.294287 916722 net.cpp:198] B2_1_SConv_SparseConv needs backward computation.
I0829 09:22:54.294291 916722 net.cpp:198] B2_0_SConv_Dropout needs backward computation.
I0829 09:22:54.294296 916722 net.cpp:198] B2_0_SConv_ReLU needs backward computation.
I0829 09:22:54.294299 916722 net.cpp:198] B2_0_SConv_Conv1x1 needs backward computation.
I0829 09:22:54.294304 916722 net.cpp:198] B2_0_SConv_Scale needs backward computation.
I0829 09:22:54.294308 916722 net.cpp:198] B2_0_SConv_BN needs backward computation.
I0829 09:22:54.294312 916722 net.cpp:198] B2_0_SConv_SparseConv needs backward computation.
I0829 09:22:54.294317 916722 net.cpp:198] B1_Pooling needs backward computation.
I0829 09:22:54.294322 916722 net.cpp:198] B1_1_SConv_Dropout needs backward computation.
I0829 09:22:54.294325 916722 net.cpp:198] B1_1_SConv_ReLU needs backward computation.
I0829 09:22:54.294329 916722 net.cpp:198] B1_1_SConv_Conv1x1 needs backward computation.
I0829 09:22:54.294333 916722 net.cpp:198] B1_1_SConv_Scale needs backward computation.
I0829 09:22:54.294342 916722 net.cpp:198] B1_1_SConv_BN needs backward computation.
I0829 09:22:54.294345 916722 net.cpp:198] B1_1_SConv_SparseConv needs backward computation.
I0829 09:22:54.294349 916722 net.cpp:198] B1_0_SConv_Dropout needs backward computation.
I0829 09:22:54.294353 916722 net.cpp:198] B1_0_SConv_ReLU needs backward computation.
I0829 09:22:54.294358 916722 net.cpp:198] B1_0_SConv_Conv1x1 needs backward computation.
I0829 09:22:54.294363 916722 net.cpp:198] B1_0_SConv_Scale needs backward computation.
I0829 09:22:54.294366 916722 net.cpp:198] B1_0_SConv_BN needs backward computation.
I0829 09:22:54.294370 916722 net.cpp:198] B1_0_SConv_SparseConv needs backward computation.
I0829 09:22:54.294375 916722 net.cpp:198] B0_Pooling needs backward computation.
I0829 09:22:54.294379 916722 net.cpp:198] B0_1_SConv_Dropout needs backward computation.
I0829 09:22:54.294384 916722 net.cpp:198] B0_1_SConv_ReLU needs backward computation.
I0829 09:22:54.294387 916722 net.cpp:198] B0_1_SConv_Conv1x1 needs backward computation.
I0829 09:22:54.294392 916722 net.cpp:198] B0_1_SConv_Scale needs backward computation.
I0829 09:22:54.294396 916722 net.cpp:198] B0_1_SConv_BN needs backward computation.
I0829 09:22:54.294400 916722 net.cpp:198] B0_1_SConv_SparseConv needs backward computation.
I0829 09:22:54.294405 916722 net.cpp:198] B0_0_ConvBNScaleReLU_Dropout needs backward computation.
I0829 09:22:54.294409 916722 net.cpp:198] B0_0_ConvBNScaleReLU_ReLU needs backward computation.
I0829 09:22:54.294416 916722 net.cpp:198] B0_0_ConvBNScaleReLU_Scale needs backward computation.
I0829 09:22:54.294425 916722 net.cpp:198] B0_0_ConvBNScaleReLU_BN needs backward computation.
I0829 09:22:54.294430 916722 net.cpp:198] B0_0_ConvBNScaleReLU_Conv needs backward computation.
I0829 09:22:54.294435 916722 net.cpp:200] label_InputData_1_split does not need backward computation.
I0829 09:22:54.294440 916722 net.cpp:200] InputData does not need backward computation.
I0829 09:22:54.294443 916722 net.cpp:242] This network produces output accuracy
I0829 09:22:54.294448 916722 net.cpp:242] This network produces output softmax_loss
I0829 09:22:54.294481 916722 net.cpp:255] Network initialization done.
I0829 09:22:54.294610 916722 solver.cpp:56] Solver scaffolding done.
I0829 09:22:54.295784 916722 caffe.cpp:248] Starting Optimization
I0829 09:22:54.295792 916722 solver.cpp:272] Solving 
I0829 09:22:54.295797 916722 solver.cpp:273] Learning Rate Policy: fixed
I0829 09:22:54.297284 916722 solver.cpp:330] Iteration 0, Testing net (#0)
I0829 09:23:09.709524 916722 solver.cpp:397]     Test net output #0: accuracy = 0.0998
I0829 09:23:09.709592 916722 solver.cpp:397]     Test net output #1: softmax_loss = 78.6163 (* 1 = 78.6163 loss)
I0829 09:23:09.786793 916722 solver.cpp:218] Iteration 0 (0 iter/s, 15.4909s/500 iters), loss = 2.33699
I0829 09:23:09.786823 916722 solver.cpp:237]     Train net output #0: softmax_loss = 2.33699 (* 1 = 2.33699 loss)
I0829 09:23:09.786832 916722 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0829 09:23:39.439872 916722 solver.cpp:218] Iteration 500 (16.8618 iter/s, 29.6529s/500 iters), loss = 1.9317
I0829 09:23:39.439940 916722 solver.cpp:237]     Train net output #0: softmax_loss = 1.9317 (* 1 = 1.9317 loss)
I0829 09:23:39.439949 916722 sgd_solver.cpp:106] Iteration 500, lr = 0.01
I0829 09:24:09.184893 916722 solver.cpp:218] Iteration 1000 (16.8096 iter/s, 29.7448s/500 iters), loss = 1.4634
I0829 09:24:09.184942 916722 solver.cpp:237]     Train net output #0: softmax_loss = 1.4634 (* 1 = 1.4634 loss)
I0829 09:24:09.184952 916722 sgd_solver.cpp:106] Iteration 1000, lr = 0.01
I0829 09:24:38.987376 916722 solver.cpp:218] Iteration 1500 (16.7772 iter/s, 29.8024s/500 iters), loss = 0.970361
I0829 09:24:38.987429 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.970361 (* 1 = 0.970361 loss)
I0829 09:24:38.987437 916722 sgd_solver.cpp:106] Iteration 1500, lr = 0.01
I0829 09:25:08.879052 916722 solver.cpp:218] Iteration 2000 (16.7271 iter/s, 29.8916s/500 iters), loss = 1.20424
I0829 09:25:08.879103 916722 solver.cpp:237]     Train net output #0: softmax_loss = 1.20424 (* 1 = 1.20424 loss)
I0829 09:25:08.879113 916722 sgd_solver.cpp:106] Iteration 2000, lr = 0.01
I0829 09:25:38.772346 916722 solver.cpp:218] Iteration 2500 (16.7262 iter/s, 29.8932s/500 iters), loss = 1.19976
I0829 09:25:38.772409 916722 solver.cpp:237]     Train net output #0: softmax_loss = 1.19976 (* 1 = 1.19976 loss)
I0829 09:25:38.772418 916722 sgd_solver.cpp:106] Iteration 2500, lr = 0.01
I0829 09:26:08.631357 916722 solver.cpp:218] Iteration 3000 (16.7454 iter/s, 29.8589s/500 iters), loss = 1.11867
I0829 09:26:08.631409 916722 solver.cpp:237]     Train net output #0: softmax_loss = 1.11867 (* 1 = 1.11867 loss)
I0829 09:26:08.631419 916722 sgd_solver.cpp:106] Iteration 3000, lr = 0.01
I0829 09:26:38.473592 916722 solver.cpp:218] Iteration 3500 (16.7548 iter/s, 29.8421s/500 iters), loss = 1.26741
I0829 09:26:38.473652 916722 solver.cpp:237]     Train net output #0: softmax_loss = 1.26741 (* 1 = 1.26741 loss)
I0829 09:26:38.473660 916722 sgd_solver.cpp:106] Iteration 3500, lr = 0.01
I0829 09:27:08.323328 916722 solver.cpp:218] Iteration 4000 (16.7506 iter/s, 29.8496s/500 iters), loss = 0.851879
I0829 09:27:08.323377 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.851879 (* 1 = 0.851879 loss)
I0829 09:27:08.323386 916722 sgd_solver.cpp:106] Iteration 4000, lr = 0.01
I0829 09:27:38.163769 916722 solver.cpp:218] Iteration 4500 (16.7558 iter/s, 29.8403s/500 iters), loss = 1.1292
I0829 09:27:38.163839 916722 solver.cpp:237]     Train net output #0: softmax_loss = 1.1292 (* 1 = 1.1292 loss)
I0829 09:27:38.163851 916722 sgd_solver.cpp:106] Iteration 4500, lr = 0.01
I0829 09:28:07.997845 916722 solver.cpp:218] Iteration 5000 (16.7594 iter/s, 29.834s/500 iters), loss = 0.723943
I0829 09:28:07.997895 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.723943 (* 1 = 0.723943 loss)
I0829 09:28:07.997903 916722 sgd_solver.cpp:106] Iteration 5000, lr = 0.01
I0829 09:28:37.837930 916722 solver.cpp:218] Iteration 5500 (16.756 iter/s, 29.84s/500 iters), loss = 0.663086
I0829 09:28:37.837991 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.663086 (* 1 = 0.663086 loss)
I0829 09:28:37.838001 916722 sgd_solver.cpp:106] Iteration 5500, lr = 0.01
I0829 09:29:07.685600 916722 solver.cpp:218] Iteration 6000 (16.7518 iter/s, 29.8476s/500 iters), loss = 0.93376
I0829 09:29:07.685650 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.93376 (* 1 = 0.93376 loss)
I0829 09:29:07.685660 916722 sgd_solver.cpp:106] Iteration 6000, lr = 0.01
I0829 09:29:37.529520 916722 solver.cpp:218] Iteration 6500 (16.7539 iter/s, 29.8438s/500 iters), loss = 0.680884
I0829 09:29:37.529582 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.680884 (* 1 = 0.680884 loss)
I0829 09:29:37.529590 916722 sgd_solver.cpp:106] Iteration 6500, lr = 0.01
I0829 09:30:07.426872 916722 solver.cpp:218] Iteration 7000 (16.724 iter/s, 29.8972s/500 iters), loss = 0.80147
I0829 09:30:07.426921 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.80147 (* 1 = 0.80147 loss)
I0829 09:30:07.426930 916722 sgd_solver.cpp:106] Iteration 7000, lr = 0.01
I0829 09:30:37.316833 916722 solver.cpp:218] Iteration 7500 (16.7281 iter/s, 29.8899s/500 iters), loss = 0.579765
I0829 09:30:37.316888 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.579765 (* 1 = 0.579765 loss)
I0829 09:30:37.316897 916722 sgd_solver.cpp:106] Iteration 7500, lr = 0.01
I0829 09:31:07.241232 916722 solver.cpp:218] Iteration 8000 (16.7088 iter/s, 29.9243s/500 iters), loss = 0.503149
I0829 09:31:07.241284 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.503149 (* 1 = 0.503149 loss)
I0829 09:31:07.241294 916722 sgd_solver.cpp:106] Iteration 8000, lr = 0.01
I0829 09:31:37.163914 916722 solver.cpp:218] Iteration 8500 (16.7098 iter/s, 29.9226s/500 iters), loss = 0.808454
I0829 09:31:37.163966 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.808454 (* 1 = 0.808454 loss)
I0829 09:31:37.163975 916722 sgd_solver.cpp:106] Iteration 8500, lr = 0.01
I0829 09:32:07.096040 916722 solver.cpp:218] Iteration 9000 (16.7045 iter/s, 29.932s/500 iters), loss = 0.570799
I0829 09:32:07.096087 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.570799 (* 1 = 0.570799 loss)
I0829 09:32:07.096098 916722 sgd_solver.cpp:106] Iteration 9000, lr = 0.01
I0829 09:32:37.016395 916722 solver.cpp:218] Iteration 9500 (16.7111 iter/s, 29.9203s/500 iters), loss = 0.899359
I0829 09:32:37.016471 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.899359 (* 1 = 0.899359 loss)
I0829 09:32:37.016481 916722 sgd_solver.cpp:106] Iteration 9500, lr = 0.01
I0829 09:33:06.939325 916722 solver.cpp:218] Iteration 10000 (16.7097 iter/s, 29.9228s/500 iters), loss = 1.07394
I0829 09:33:06.939371 916722 solver.cpp:237]     Train net output #0: softmax_loss = 1.07394 (* 1 = 1.07394 loss)
I0829 09:33:06.939380 916722 sgd_solver.cpp:106] Iteration 10000, lr = 0.01
I0829 09:33:36.895363 916722 solver.cpp:218] Iteration 10500 (16.6912 iter/s, 29.9559s/500 iters), loss = 0.554835
I0829 09:33:36.895416 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.554835 (* 1 = 0.554835 loss)
I0829 09:33:36.895426 916722 sgd_solver.cpp:106] Iteration 10500, lr = 0.01
I0829 09:34:06.786453 916722 solver.cpp:218] Iteration 11000 (16.7274 iter/s, 29.891s/500 iters), loss = 0.402901
I0829 09:34:06.786500 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.402901 (* 1 = 0.402901 loss)
I0829 09:34:06.786510 916722 sgd_solver.cpp:106] Iteration 11000, lr = 0.01
I0829 09:34:36.691907 916722 solver.cpp:218] Iteration 11500 (16.7194 iter/s, 29.9054s/500 iters), loss = 0.495927
I0829 09:34:36.691975 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.495927 (* 1 = 0.495927 loss)
I0829 09:34:36.691984 916722 sgd_solver.cpp:106] Iteration 11500, lr = 0.01
I0829 09:35:06.603248 916722 solver.cpp:218] Iteration 12000 (16.7161 iter/s, 29.9112s/500 iters), loss = 0.353815
I0829 09:35:06.603302 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.353815 (* 1 = 0.353815 loss)
I0829 09:35:06.603312 916722 sgd_solver.cpp:106] Iteration 12000, lr = 0.01
I0829 09:35:36.514309 916722 solver.cpp:218] Iteration 12500 (16.7163 iter/s, 29.911s/500 iters), loss = 0.536471
I0829 09:35:36.514369 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.536471 (* 1 = 0.536471 loss)
I0829 09:35:36.514379 916722 sgd_solver.cpp:106] Iteration 12500, lr = 0.01
I0829 09:36:06.434741 916722 solver.cpp:218] Iteration 13000 (16.711 iter/s, 29.9203s/500 iters), loss = 0.807822
I0829 09:36:06.434788 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.807822 (* 1 = 0.807822 loss)
I0829 09:36:06.434799 916722 sgd_solver.cpp:106] Iteration 13000, lr = 0.01
I0829 09:36:36.349071 916722 solver.cpp:218] Iteration 13500 (16.7145 iter/s, 29.9142s/500 iters), loss = 0.679538
I0829 09:36:36.349135 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.679538 (* 1 = 0.679538 loss)
I0829 09:36:36.349144 916722 sgd_solver.cpp:106] Iteration 13500, lr = 0.01
I0829 09:37:06.252306 916722 solver.cpp:218] Iteration 14000 (16.7207 iter/s, 29.9031s/500 iters), loss = 0.393384
I0829 09:37:06.252357 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.393384 (* 1 = 0.393384 loss)
I0829 09:37:06.252365 916722 sgd_solver.cpp:106] Iteration 14000, lr = 0.01
I0829 09:37:36.176785 916722 solver.cpp:218] Iteration 14500 (16.7088 iter/s, 29.9244s/500 iters), loss = 0.626916
I0829 09:37:36.176857 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.626916 (* 1 = 0.626916 loss)
I0829 09:37:36.176865 916722 sgd_solver.cpp:106] Iteration 14500, lr = 0.01
I0829 09:38:06.122426 916722 solver.cpp:218] Iteration 15000 (16.697 iter/s, 29.9455s/500 iters), loss = 0.419702
I0829 09:38:06.122478 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.419702 (* 1 = 0.419702 loss)
I0829 09:38:06.122488 916722 sgd_solver.cpp:106] Iteration 15000, lr = 0.01
I0829 09:38:36.056357 916722 solver.cpp:218] Iteration 15500 (16.7035 iter/s, 29.9338s/500 iters), loss = 0.313998
I0829 09:38:36.056418 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.313998 (* 1 = 0.313998 loss)
I0829 09:38:36.056433 916722 sgd_solver.cpp:106] Iteration 15500, lr = 0.01
I0829 09:39:05.967833 916722 solver.cpp:218] Iteration 16000 (16.7161 iter/s, 29.9114s/500 iters), loss = 0.659288
I0829 09:39:05.967883 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.659287 (* 1 = 0.659287 loss)
I0829 09:39:05.967892 916722 sgd_solver.cpp:106] Iteration 16000, lr = 0.01
I0829 09:39:35.902232 916722 solver.cpp:218] Iteration 16500 (16.7032 iter/s, 29.9343s/500 iters), loss = 0.394861
I0829 09:39:35.902295 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.394861 (* 1 = 0.394861 loss)
I0829 09:39:35.902303 916722 sgd_solver.cpp:106] Iteration 16500, lr = 0.01
I0829 09:40:05.852408 916722 solver.cpp:218] Iteration 17000 (16.6945 iter/s, 29.95s/500 iters), loss = 0.576676
I0829 09:40:05.852478 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.576676 (* 1 = 0.576676 loss)
I0829 09:40:05.852488 916722 sgd_solver.cpp:106] Iteration 17000, lr = 0.01
I0829 09:40:35.776993 916722 solver.cpp:218] Iteration 17500 (16.7087 iter/s, 29.9244s/500 iters), loss = 0.470019
I0829 09:40:35.777055 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.470019 (* 1 = 0.470019 loss)
I0829 09:40:35.777063 916722 sgd_solver.cpp:106] Iteration 17500, lr = 0.01
I0829 09:41:05.725998 916722 solver.cpp:218] Iteration 18000 (16.6951 iter/s, 29.9489s/500 iters), loss = 0.61983
I0829 09:41:05.726060 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.61983 (* 1 = 0.61983 loss)
I0829 09:41:05.726069 916722 sgd_solver.cpp:106] Iteration 18000, lr = 0.01
I0829 09:41:35.658358 916722 solver.cpp:218] Iteration 18500 (16.7044 iter/s, 29.9322s/500 iters), loss = 0.331616
I0829 09:41:35.658427 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.331616 (* 1 = 0.331616 loss)
I0829 09:41:35.658437 916722 sgd_solver.cpp:106] Iteration 18500, lr = 0.01
I0829 09:42:05.595888 916722 solver.cpp:218] Iteration 19000 (16.7015 iter/s, 29.9374s/500 iters), loss = 0.211067
I0829 09:42:05.595942 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.211068 (* 1 = 0.211068 loss)
I0829 09:42:05.595952 916722 sgd_solver.cpp:106] Iteration 19000, lr = 0.01
I0829 09:42:35.533773 916722 solver.cpp:218] Iteration 19500 (16.7013 iter/s, 29.9378s/500 iters), loss = 0.680884
I0829 09:42:35.533834 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.680884 (* 1 = 0.680884 loss)
I0829 09:42:35.533843 916722 sgd_solver.cpp:106] Iteration 19500, lr = 0.01
I0829 09:43:05.479269 916722 solver.cpp:218] Iteration 20000 (16.6971 iter/s, 29.9454s/500 iters), loss = 0.344227
I0829 09:43:05.479321 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.344227 (* 1 = 0.344227 loss)
I0829 09:43:05.479331 916722 sgd_solver.cpp:106] Iteration 20000, lr = 0.01
I0829 09:43:35.427951 916722 solver.cpp:218] Iteration 20500 (16.6953 iter/s, 29.9486s/500 iters), loss = 0.694951
I0829 09:43:35.428012 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.69495 (* 1 = 0.69495 loss)
I0829 09:43:35.428021 916722 sgd_solver.cpp:106] Iteration 20500, lr = 0.01
I0829 09:44:05.357086 916722 solver.cpp:218] Iteration 21000 (16.7062 iter/s, 29.929s/500 iters), loss = 0.227312
I0829 09:44:05.357136 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.227312 (* 1 = 0.227312 loss)
I0829 09:44:05.357146 916722 sgd_solver.cpp:106] Iteration 21000, lr = 0.01
I0829 09:44:35.315237 916722 solver.cpp:218] Iteration 21500 (16.69 iter/s, 29.958s/500 iters), loss = 0.46966
I0829 09:44:35.315299 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.46966 (* 1 = 0.46966 loss)
I0829 09:44:35.315306 916722 sgd_solver.cpp:106] Iteration 21500, lr = 0.01
I0829 09:45:05.233805 916722 solver.cpp:218] Iteration 22000 (16.7121 iter/s, 29.9184s/500 iters), loss = 0.598918
I0829 09:45:05.233857 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.598918 (* 1 = 0.598918 loss)
I0829 09:45:05.233866 916722 sgd_solver.cpp:106] Iteration 22000, lr = 0.01
I0829 09:45:35.176962 916722 solver.cpp:218] Iteration 22500 (16.6984 iter/s, 29.943s/500 iters), loss = 0.612621
I0829 09:45:35.177022 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.612621 (* 1 = 0.612621 loss)
I0829 09:45:35.177031 916722 sgd_solver.cpp:106] Iteration 22500, lr = 0.01
I0829 09:46:05.107897 916722 solver.cpp:218] Iteration 23000 (16.7052 iter/s, 29.9308s/500 iters), loss = 0.389523
I0829 09:46:05.107947 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.389522 (* 1 = 0.389522 loss)
I0829 09:46:05.107959 916722 sgd_solver.cpp:106] Iteration 23000, lr = 0.01
I0829 09:46:35.036928 916722 solver.cpp:218] Iteration 23500 (16.7062 iter/s, 29.9289s/500 iters), loss = 0.383717
I0829 09:46:35.036988 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.383717 (* 1 = 0.383717 loss)
I0829 09:46:35.036996 916722 sgd_solver.cpp:106] Iteration 23500, lr = 0.01
I0829 09:47:04.969449 916722 solver.cpp:218] Iteration 24000 (16.7043 iter/s, 29.9324s/500 iters), loss = 0.40767
I0829 09:47:04.969501 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.40767 (* 1 = 0.40767 loss)
I0829 09:47:04.969511 916722 sgd_solver.cpp:106] Iteration 24000, lr = 0.01
I0829 09:47:34.891696 916722 solver.cpp:218] Iteration 24500 (16.71 iter/s, 29.9221s/500 iters), loss = 0.13767
I0829 09:47:34.891767 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13767 (* 1 = 0.13767 loss)
I0829 09:47:34.891780 916722 sgd_solver.cpp:106] Iteration 24500, lr = 0.01
I0829 09:48:04.796679 916722 solver.cpp:218] Iteration 25000 (16.7197 iter/s, 29.9049s/500 iters), loss = 0.545098
I0829 09:48:04.796741 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.545097 (* 1 = 0.545097 loss)
I0829 09:48:04.796751 916722 sgd_solver.cpp:106] Iteration 25000, lr = 0.01
I0829 09:48:34.730995 916722 solver.cpp:218] Iteration 25500 (16.7033 iter/s, 29.9342s/500 iters), loss = 0.424488
I0829 09:48:34.731056 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.424488 (* 1 = 0.424488 loss)
I0829 09:48:34.731065 916722 sgd_solver.cpp:106] Iteration 25500, lr = 0.01
I0829 09:49:04.635463 916722 solver.cpp:218] Iteration 26000 (16.72 iter/s, 29.9044s/500 iters), loss = 0.495434
I0829 09:49:04.635514 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.495434 (* 1 = 0.495434 loss)
I0829 09:49:04.635524 916722 sgd_solver.cpp:106] Iteration 26000, lr = 0.01
I0829 09:49:34.544514 916722 solver.cpp:218] Iteration 26500 (16.7174 iter/s, 29.9089s/500 iters), loss = 0.558904
I0829 09:49:34.544572 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.558904 (* 1 = 0.558904 loss)
I0829 09:49:34.544581 916722 sgd_solver.cpp:106] Iteration 26500, lr = 0.01
I0829 09:50:04.475296 916722 solver.cpp:218] Iteration 27000 (16.7053 iter/s, 29.9307s/500 iters), loss = 0.529558
I0829 09:50:04.475347 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.529558 (* 1 = 0.529558 loss)
I0829 09:50:04.475356 916722 sgd_solver.cpp:106] Iteration 27000, lr = 0.01
I0829 09:50:34.379441 916722 solver.cpp:218] Iteration 27500 (16.7202 iter/s, 29.904s/500 iters), loss = 0.465143
I0829 09:50:34.379506 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.465143 (* 1 = 0.465143 loss)
I0829 09:50:34.379515 916722 sgd_solver.cpp:106] Iteration 27500, lr = 0.01
I0829 09:51:04.280620 916722 solver.cpp:218] Iteration 28000 (16.7218 iter/s, 29.9011s/500 iters), loss = 0.82221
I0829 09:51:04.280673 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.82221 (* 1 = 0.82221 loss)
I0829 09:51:04.280681 916722 sgd_solver.cpp:106] Iteration 28000, lr = 0.01
I0829 09:51:34.197223 916722 solver.cpp:218] Iteration 28500 (16.7132 iter/s, 29.9165s/500 iters), loss = 0.504573
I0829 09:51:34.197284 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.504573 (* 1 = 0.504573 loss)
I0829 09:51:34.197293 916722 sgd_solver.cpp:106] Iteration 28500, lr = 0.01
I0829 09:52:04.108269 916722 solver.cpp:218] Iteration 29000 (16.7163 iter/s, 29.9109s/500 iters), loss = 0.451559
I0829 09:52:04.108325 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.451558 (* 1 = 0.451558 loss)
I0829 09:52:04.108333 916722 sgd_solver.cpp:106] Iteration 29000, lr = 0.01
I0829 09:52:34.021507 916722 solver.cpp:218] Iteration 29500 (16.7151 iter/s, 29.9131s/500 iters), loss = 0.368831
I0829 09:52:34.021569 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.368831 (* 1 = 0.368831 loss)
I0829 09:52:34.021579 916722 sgd_solver.cpp:106] Iteration 29500, lr = 0.01
I0829 09:53:03.946744 916722 solver.cpp:218] Iteration 30000 (16.7084 iter/s, 29.9251s/500 iters), loss = 0.454967
I0829 09:53:03.946796 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.454967 (* 1 = 0.454967 loss)
I0829 09:53:03.946805 916722 sgd_solver.cpp:106] Iteration 30000, lr = 0.01
I0829 09:53:33.877815 916722 solver.cpp:218] Iteration 30500 (16.7051 iter/s, 29.931s/500 iters), loss = 0.504143
I0829 09:53:33.877877 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.504143 (* 1 = 0.504143 loss)
I0829 09:53:33.877885 916722 sgd_solver.cpp:106] Iteration 30500, lr = 0.01
I0829 09:54:03.844955 916722 solver.cpp:218] Iteration 31000 (16.685 iter/s, 29.967s/500 iters), loss = 0.394383
I0829 09:54:03.845005 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.394383 (* 1 = 0.394383 loss)
I0829 09:54:03.845014 916722 sgd_solver.cpp:106] Iteration 31000, lr = 0.01
I0829 09:54:33.772835 916722 solver.cpp:218] Iteration 31500 (16.7069 iter/s, 29.9278s/500 iters), loss = 0.308016
I0829 09:54:33.772908 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.308016 (* 1 = 0.308016 loss)
I0829 09:54:33.772917 916722 sgd_solver.cpp:106] Iteration 31500, lr = 0.01
I0829 09:55:03.692615 916722 solver.cpp:218] Iteration 32000 (16.7114 iter/s, 29.9197s/500 iters), loss = 0.23655
I0829 09:55:03.692667 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.23655 (* 1 = 0.23655 loss)
I0829 09:55:03.692677 916722 sgd_solver.cpp:106] Iteration 32000, lr = 0.01
I0829 09:55:33.621217 916722 solver.cpp:218] Iteration 32500 (16.7065 iter/s, 29.9285s/500 iters), loss = 0.240049
I0829 09:55:33.621279 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.240049 (* 1 = 0.240049 loss)
I0829 09:55:33.621287 916722 sgd_solver.cpp:106] Iteration 32500, lr = 0.01
I0829 09:56:03.580873 916722 solver.cpp:218] Iteration 33000 (16.6892 iter/s, 29.9595s/500 iters), loss = 0.173497
I0829 09:56:03.580929 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.173497 (* 1 = 0.173497 loss)
I0829 09:56:03.580940 916722 sgd_solver.cpp:106] Iteration 33000, lr = 0.01
I0829 09:56:33.532567 916722 solver.cpp:218] Iteration 33500 (16.6936 iter/s, 29.9516s/500 iters), loss = 0.17443
I0829 09:56:33.532626 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.17443 (* 1 = 0.17443 loss)
I0829 09:56:33.532635 916722 sgd_solver.cpp:106] Iteration 33500, lr = 0.01
I0829 09:57:03.454326 916722 solver.cpp:218] Iteration 34000 (16.7103 iter/s, 29.9217s/500 iters), loss = 0.353041
I0829 09:57:03.454377 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.353041 (* 1 = 0.353041 loss)
I0829 09:57:03.454387 916722 sgd_solver.cpp:106] Iteration 34000, lr = 0.01
I0829 09:57:33.403734 916722 solver.cpp:218] Iteration 34500 (16.6949 iter/s, 29.9493s/500 iters), loss = 0.444785
I0829 09:57:33.403795 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.444785 (* 1 = 0.444785 loss)
I0829 09:57:33.403802 916722 sgd_solver.cpp:106] Iteration 34500, lr = 0.01
I0829 09:58:03.332453 916722 solver.cpp:218] Iteration 35000 (16.7064 iter/s, 29.9286s/500 iters), loss = 0.481903
I0829 09:58:03.332504 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.481903 (* 1 = 0.481903 loss)
I0829 09:58:03.332515 916722 sgd_solver.cpp:106] Iteration 35000, lr = 0.01
I0829 09:58:33.252691 916722 solver.cpp:218] Iteration 35500 (16.7112 iter/s, 29.9201s/500 iters), loss = 0.215168
I0829 09:58:33.252753 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.215168 (* 1 = 0.215168 loss)
I0829 09:58:33.252761 916722 sgd_solver.cpp:106] Iteration 35500, lr = 0.01
I0829 09:59:03.169262 916722 solver.cpp:218] Iteration 36000 (16.7132 iter/s, 29.9165s/500 iters), loss = 0.496019
I0829 09:59:03.169312 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.496019 (* 1 = 0.496019 loss)
I0829 09:59:03.169322 916722 sgd_solver.cpp:106] Iteration 36000, lr = 0.01
I0829 09:59:33.093850 916722 solver.cpp:218] Iteration 36500 (16.7087 iter/s, 29.9245s/500 iters), loss = 0.255913
I0829 09:59:33.093910 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.255913 (* 1 = 0.255913 loss)
I0829 09:59:33.093919 916722 sgd_solver.cpp:106] Iteration 36500, lr = 0.01
I0829 10:00:03.027406 916722 solver.cpp:218] Iteration 37000 (16.7037 iter/s, 29.9334s/500 iters), loss = 0.719422
I0829 10:00:03.027459 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.719422 (* 1 = 0.719422 loss)
I0829 10:00:03.027469 916722 sgd_solver.cpp:106] Iteration 37000, lr = 0.01
I0829 10:00:32.947602 916722 solver.cpp:218] Iteration 37500 (16.7112 iter/s, 29.9201s/500 iters), loss = 0.283467
I0829 10:00:32.947665 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.283468 (* 1 = 0.283468 loss)
I0829 10:00:32.947674 916722 sgd_solver.cpp:106] Iteration 37500, lr = 0.01
I0829 10:01:02.825809 916722 solver.cpp:218] Iteration 38000 (16.7347 iter/s, 29.8781s/500 iters), loss = 0.15734
I0829 10:01:02.825870 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.15734 (* 1 = 0.15734 loss)
I0829 10:01:02.825878 916722 sgd_solver.cpp:106] Iteration 38000, lr = 0.01
I0829 10:01:32.715435 916722 solver.cpp:218] Iteration 38500 (16.7283 iter/s, 29.8895s/500 iters), loss = 0.576347
I0829 10:01:32.715507 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.576347 (* 1 = 0.576347 loss)
I0829 10:01:32.715517 916722 sgd_solver.cpp:106] Iteration 38500, lr = 0.01
I0829 10:02:02.625008 916722 solver.cpp:218] Iteration 39000 (16.7171 iter/s, 29.9094s/500 iters), loss = 0.535734
I0829 10:02:02.625058 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.535734 (* 1 = 0.535734 loss)
I0829 10:02:02.625066 916722 sgd_solver.cpp:106] Iteration 39000, lr = 0.01
I0829 10:02:32.548244 916722 solver.cpp:218] Iteration 39500 (16.7095 iter/s, 29.9231s/500 iters), loss = 0.341154
I0829 10:02:32.548305 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.341154 (* 1 = 0.341154 loss)
I0829 10:02:32.548313 916722 sgd_solver.cpp:106] Iteration 39500, lr = 0.01
I0829 10:03:02.448307 916722 solver.cpp:218] Iteration 40000 (16.7224 iter/s, 29.8999s/500 iters), loss = 0.605888
I0829 10:03:02.448357 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.605888 (* 1 = 0.605888 loss)
I0829 10:03:02.448366 916722 sgd_solver.cpp:106] Iteration 40000, lr = 0.01
I0829 10:03:32.354820 916722 solver.cpp:218] Iteration 40500 (16.7188 iter/s, 29.9064s/500 iters), loss = 0.620145
I0829 10:03:32.354880 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.620146 (* 1 = 0.620146 loss)
I0829 10:03:32.354889 916722 sgd_solver.cpp:106] Iteration 40500, lr = 0.01
I0829 10:04:02.273681 916722 solver.cpp:218] Iteration 41000 (16.7119 iter/s, 29.9187s/500 iters), loss = 0.580333
I0829 10:04:02.273732 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.580333 (* 1 = 0.580333 loss)
I0829 10:04:02.273741 916722 sgd_solver.cpp:106] Iteration 41000, lr = 0.01
I0829 10:04:32.166776 916722 solver.cpp:218] Iteration 41500 (16.7263 iter/s, 29.893s/500 iters), loss = 0.52649
I0829 10:04:32.166836 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.52649 (* 1 = 0.52649 loss)
I0829 10:04:32.166844 916722 sgd_solver.cpp:106] Iteration 41500, lr = 0.01
I0829 10:05:02.072348 916722 solver.cpp:218] Iteration 42000 (16.7194 iter/s, 29.9055s/500 iters), loss = 0.318597
I0829 10:05:02.072399 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.318597 (* 1 = 0.318597 loss)
I0829 10:05:02.072408 916722 sgd_solver.cpp:106] Iteration 42000, lr = 0.01
I0829 10:05:31.988392 916722 solver.cpp:218] Iteration 42500 (16.7135 iter/s, 29.9159s/500 iters), loss = 0.468686
I0829 10:05:31.988474 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.468686 (* 1 = 0.468686 loss)
I0829 10:05:31.988483 916722 sgd_solver.cpp:106] Iteration 42500, lr = 0.01
I0829 10:06:01.913148 916722 solver.cpp:218] Iteration 43000 (16.7087 iter/s, 29.9246s/500 iters), loss = 0.446295
I0829 10:06:01.913200 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.446295 (* 1 = 0.446295 loss)
I0829 10:06:01.913211 916722 sgd_solver.cpp:106] Iteration 43000, lr = 0.01
I0829 10:06:31.832095 916722 solver.cpp:218] Iteration 43500 (16.7119 iter/s, 29.9188s/500 iters), loss = 0.311012
I0829 10:06:31.832147 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.311012 (* 1 = 0.311012 loss)
I0829 10:06:31.832155 916722 sgd_solver.cpp:106] Iteration 43500, lr = 0.01
I0829 10:07:01.773885 916722 solver.cpp:218] Iteration 44000 (16.6991 iter/s, 29.9417s/500 iters), loss = 0.198742
I0829 10:07:01.773936 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.198743 (* 1 = 0.198743 loss)
I0829 10:07:01.773944 916722 sgd_solver.cpp:106] Iteration 44000, lr = 0.01
I0829 10:07:31.699540 916722 solver.cpp:218] Iteration 44500 (16.7081 iter/s, 29.9256s/500 iters), loss = 0.195226
I0829 10:07:31.699610 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.195226 (* 1 = 0.195226 loss)
I0829 10:07:31.699625 916722 sgd_solver.cpp:106] Iteration 44500, lr = 0.01
I0829 10:08:01.629424 916722 solver.cpp:218] Iteration 45000 (16.7058 iter/s, 29.9298s/500 iters), loss = 0.300742
I0829 10:08:01.629475 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.300742 (* 1 = 0.300742 loss)
I0829 10:08:01.629484 916722 sgd_solver.cpp:106] Iteration 45000, lr = 0.01
I0829 10:08:31.565893 916722 solver.cpp:218] Iteration 45500 (16.7021 iter/s, 29.9364s/500 iters), loss = 0.212394
I0829 10:08:31.565953 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.212394 (* 1 = 0.212394 loss)
I0829 10:08:31.565960 916722 sgd_solver.cpp:106] Iteration 45500, lr = 0.01
I0829 10:09:01.514570 916722 solver.cpp:218] Iteration 46000 (16.6953 iter/s, 29.9486s/500 iters), loss = 0.205893
I0829 10:09:01.514623 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.205894 (* 1 = 0.205894 loss)
I0829 10:09:01.514633 916722 sgd_solver.cpp:106] Iteration 46000, lr = 0.01
I0829 10:09:31.442021 916722 solver.cpp:218] Iteration 46500 (16.7071 iter/s, 29.9273s/500 iters), loss = 0.208663
I0829 10:09:31.442082 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.208663 (* 1 = 0.208663 loss)
I0829 10:09:31.442091 916722 sgd_solver.cpp:106] Iteration 46500, lr = 0.01
I0829 10:10:01.380880 916722 solver.cpp:218] Iteration 47000 (16.7008 iter/s, 29.9388s/500 iters), loss = 0.392349
I0829 10:10:01.380931 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.39235 (* 1 = 0.39235 loss)
I0829 10:10:01.380941 916722 sgd_solver.cpp:106] Iteration 47000, lr = 0.01
I0829 10:10:31.320096 916722 solver.cpp:218] Iteration 47500 (16.7006 iter/s, 29.9391s/500 iters), loss = 0.240683
I0829 10:10:31.320158 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.240683 (* 1 = 0.240683 loss)
I0829 10:10:31.320165 916722 sgd_solver.cpp:106] Iteration 47500, lr = 0.01
I0829 10:11:01.244731 916722 solver.cpp:218] Iteration 48000 (16.7087 iter/s, 29.9245s/500 iters), loss = 0.241209
I0829 10:11:01.244793 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.241209 (* 1 = 0.241209 loss)
I0829 10:11:01.244803 916722 sgd_solver.cpp:106] Iteration 48000, lr = 0.01
I0829 10:11:31.168309 916722 solver.cpp:218] Iteration 48500 (16.7093 iter/s, 29.9235s/500 iters), loss = 0.214834
I0829 10:11:31.168368 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.214834 (* 1 = 0.214834 loss)
I0829 10:11:31.168376 916722 sgd_solver.cpp:106] Iteration 48500, lr = 0.01
I0829 10:12:01.059718 916722 solver.cpp:218] Iteration 49000 (16.7273 iter/s, 29.8913s/500 iters), loss = 0.493402
I0829 10:12:01.059770 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.493402 (* 1 = 0.493402 loss)
I0829 10:12:01.059780 916722 sgd_solver.cpp:106] Iteration 49000, lr = 0.01
I0829 10:12:30.964802 916722 solver.cpp:218] Iteration 49500 (16.7196 iter/s, 29.905s/500 iters), loss = 0.357943
I0829 10:12:30.964857 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.357944 (* 1 = 0.357944 loss)
I0829 10:12:30.964865 916722 sgd_solver.cpp:106] Iteration 49500, lr = 0.01
I0829 10:13:00.824025 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_50000.caffemodel
I0829 10:13:00.851115 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_50000.solverstate
I0829 10:13:00.857331 916722 solver.cpp:330] Iteration 50000, Testing net (#0)
I0829 10:13:16.311712 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8576
I0829 10:13:16.311762 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.420926 (* 1 = 0.420926 loss)
I0829 10:13:16.370469 916722 solver.cpp:218] Iteration 50000 (11.0119 iter/s, 45.4055s/500 iters), loss = 0.292965
I0829 10:13:16.370496 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.292966 (* 1 = 0.292966 loss)
I0829 10:13:16.370504 916722 sgd_solver.cpp:106] Iteration 50000, lr = 0.01
I0829 10:13:46.178090 916722 solver.cpp:218] Iteration 50500 (16.7743 iter/s, 29.8076s/500 iters), loss = 0.47829
I0829 10:13:46.178148 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.478291 (* 1 = 0.478291 loss)
I0829 10:13:46.178158 916722 sgd_solver.cpp:106] Iteration 50500, lr = 0.01
I0829 10:14:16.073124 916722 solver.cpp:218] Iteration 51000 (16.7252 iter/s, 29.8951s/500 iters), loss = 0.374435
I0829 10:14:16.073197 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.374435 (* 1 = 0.374435 loss)
I0829 10:14:16.073206 916722 sgd_solver.cpp:106] Iteration 51000, lr = 0.01
I0829 10:14:46.015630 916722 solver.cpp:218] Iteration 51500 (16.6987 iter/s, 29.9425s/500 iters), loss = 0.177023
I0829 10:14:46.015683 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.177023 (* 1 = 0.177023 loss)
I0829 10:14:46.015692 916722 sgd_solver.cpp:106] Iteration 51500, lr = 0.01
I0829 10:15:15.948050 916722 solver.cpp:218] Iteration 52000 (16.7043 iter/s, 29.9325s/500 iters), loss = 0.18663
I0829 10:15:15.948109 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.186631 (* 1 = 0.186631 loss)
I0829 10:15:15.948118 916722 sgd_solver.cpp:106] Iteration 52000, lr = 0.01
I0829 10:15:45.854158 916722 solver.cpp:218] Iteration 52500 (16.719 iter/s, 29.9061s/500 iters), loss = 0.281752
I0829 10:15:45.854213 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.281752 (* 1 = 0.281752 loss)
I0829 10:15:45.854223 916722 sgd_solver.cpp:106] Iteration 52500, lr = 0.01
I0829 10:16:15.778856 916722 solver.cpp:218] Iteration 53000 (16.7086 iter/s, 29.9247s/500 iters), loss = 0.3684
I0829 10:16:15.778918 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.368401 (* 1 = 0.368401 loss)
I0829 10:16:15.778925 916722 sgd_solver.cpp:106] Iteration 53000, lr = 0.01
I0829 10:16:45.720271 916722 solver.cpp:218] Iteration 53500 (16.6993 iter/s, 29.9414s/500 iters), loss = 0.299135
I0829 10:16:45.720329 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.299136 (* 1 = 0.299136 loss)
I0829 10:16:45.720340 916722 sgd_solver.cpp:106] Iteration 53500, lr = 0.01
I0829 10:17:15.651715 916722 solver.cpp:218] Iteration 54000 (16.7048 iter/s, 29.9315s/500 iters), loss = 0.0839412
I0829 10:17:15.651782 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0839417 (* 1 = 0.0839417 loss)
I0829 10:17:15.651790 916722 sgd_solver.cpp:106] Iteration 54000, lr = 0.01
I0829 10:17:45.597760 916722 solver.cpp:218] Iteration 54500 (16.6967 iter/s, 29.9461s/500 iters), loss = 0.0978501
I0829 10:17:45.597811 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0978507 (* 1 = 0.0978507 loss)
I0829 10:17:45.597822 916722 sgd_solver.cpp:106] Iteration 54500, lr = 0.01
I0829 10:18:15.536039 916722 solver.cpp:218] Iteration 55000 (16.701 iter/s, 29.9383s/500 iters), loss = 0.156609
I0829 10:18:15.536099 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.15661 (* 1 = 0.15661 loss)
I0829 10:18:15.536108 916722 sgd_solver.cpp:106] Iteration 55000, lr = 0.01
I0829 10:18:45.505748 916722 solver.cpp:218] Iteration 55500 (16.6835 iter/s, 29.9697s/500 iters), loss = 0.449365
I0829 10:18:45.505803 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.449366 (* 1 = 0.449366 loss)
I0829 10:18:45.505813 916722 sgd_solver.cpp:106] Iteration 55500, lr = 0.01
I0829 10:19:15.486754 916722 solver.cpp:218] Iteration 56000 (16.6772 iter/s, 29.981s/500 iters), loss = 0.150922
I0829 10:19:15.486819 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.150923 (* 1 = 0.150923 loss)
I0829 10:19:15.486829 916722 sgd_solver.cpp:106] Iteration 56000, lr = 0.01
I0829 10:19:45.451695 916722 solver.cpp:218] Iteration 56500 (16.6862 iter/s, 29.9649s/500 iters), loss = 0.120034
I0829 10:19:45.451750 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.120035 (* 1 = 0.120035 loss)
I0829 10:19:45.451761 916722 sgd_solver.cpp:106] Iteration 56500, lr = 0.01
I0829 10:20:15.411443 916722 solver.cpp:218] Iteration 57000 (16.6891 iter/s, 29.9597s/500 iters), loss = 0.424326
I0829 10:20:15.411514 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.424326 (* 1 = 0.424326 loss)
I0829 10:20:15.411527 916722 sgd_solver.cpp:106] Iteration 57000, lr = 0.01
I0829 10:20:45.392962 916722 solver.cpp:218] Iteration 57500 (16.677 iter/s, 29.9815s/500 iters), loss = 0.1323
I0829 10:20:45.393021 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.132301 (* 1 = 0.132301 loss)
I0829 10:20:45.393031 916722 sgd_solver.cpp:106] Iteration 57500, lr = 0.01
I0829 10:21:15.359712 916722 solver.cpp:218] Iteration 58000 (16.6852 iter/s, 29.9667s/500 iters), loss = 0.107645
I0829 10:21:15.359772 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.107646 (* 1 = 0.107646 loss)
I0829 10:21:15.359781 916722 sgd_solver.cpp:106] Iteration 58000, lr = 0.01
I0829 10:21:45.330857 916722 solver.cpp:218] Iteration 58500 (16.6827 iter/s, 29.9711s/500 iters), loss = 0.353377
I0829 10:21:45.330915 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.353378 (* 1 = 0.353378 loss)
I0829 10:21:45.330925 916722 sgd_solver.cpp:106] Iteration 58500, lr = 0.01
I0829 10:22:15.281085 916722 solver.cpp:218] Iteration 59000 (16.6944 iter/s, 29.9502s/500 iters), loss = 0.279889
I0829 10:22:15.281145 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.27989 (* 1 = 0.27989 loss)
I0829 10:22:15.281153 916722 sgd_solver.cpp:106] Iteration 59000, lr = 0.01
I0829 10:22:45.238479 916722 solver.cpp:218] Iteration 59500 (16.6904 iter/s, 29.9574s/500 iters), loss = 0.155469
I0829 10:22:45.238531 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.15547 (* 1 = 0.15547 loss)
I0829 10:22:45.238540 916722 sgd_solver.cpp:106] Iteration 59500, lr = 0.01
I0829 10:23:15.204371 916722 solver.cpp:218] Iteration 60000 (16.6856 iter/s, 29.9659s/500 iters), loss = 0.171647
I0829 10:23:15.204450 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.171647 (* 1 = 0.171647 loss)
I0829 10:23:15.204460 916722 sgd_solver.cpp:106] Iteration 60000, lr = 0.01
I0829 10:23:45.187650 916722 solver.cpp:218] Iteration 60500 (16.676 iter/s, 29.9832s/500 iters), loss = 0.434688
I0829 10:23:45.187700 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.434689 (* 1 = 0.434689 loss)
I0829 10:23:45.187708 916722 sgd_solver.cpp:106] Iteration 60500, lr = 0.01
I0829 10:24:15.147071 916722 solver.cpp:218] Iteration 61000 (16.6893 iter/s, 29.9594s/500 iters), loss = 0.269347
I0829 10:24:15.147133 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.269348 (* 1 = 0.269348 loss)
I0829 10:24:15.147142 916722 sgd_solver.cpp:106] Iteration 61000, lr = 0.01
I0829 10:24:45.109616 916722 solver.cpp:218] Iteration 61500 (16.6875 iter/s, 29.9625s/500 iters), loss = 0.0797742
I0829 10:24:45.109668 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0797751 (* 1 = 0.0797751 loss)
I0829 10:24:45.109675 916722 sgd_solver.cpp:106] Iteration 61500, lr = 0.01
I0829 10:25:15.112121 916722 solver.cpp:218] Iteration 62000 (16.6653 iter/s, 30.0025s/500 iters), loss = 0.203981
I0829 10:25:15.112181 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.203981 (* 1 = 0.203981 loss)
I0829 10:25:15.112190 916722 sgd_solver.cpp:106] Iteration 62000, lr = 0.01
I0829 10:25:45.083117 916722 solver.cpp:218] Iteration 62500 (16.6828 iter/s, 29.9709s/500 iters), loss = 0.348903
I0829 10:25:45.083173 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.348904 (* 1 = 0.348904 loss)
I0829 10:25:45.083184 916722 sgd_solver.cpp:106] Iteration 62500, lr = 0.01
I0829 10:26:15.037626 916722 solver.cpp:218] Iteration 63000 (16.692 iter/s, 29.9545s/500 iters), loss = 0.12608
I0829 10:26:15.037686 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.126081 (* 1 = 0.126081 loss)
I0829 10:26:15.037694 916722 sgd_solver.cpp:106] Iteration 63000, lr = 0.01
I0829 10:26:44.997481 916722 solver.cpp:218] Iteration 63500 (16.689 iter/s, 29.9598s/500 iters), loss = 0.17516
I0829 10:26:44.997530 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.175161 (* 1 = 0.175161 loss)
I0829 10:26:44.997540 916722 sgd_solver.cpp:106] Iteration 63500, lr = 0.01
I0829 10:27:14.947638 916722 solver.cpp:218] Iteration 64000 (16.6944 iter/s, 29.9501s/500 iters), loss = 0.426559
I0829 10:27:14.947710 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.42656 (* 1 = 0.42656 loss)
I0829 10:27:14.947718 916722 sgd_solver.cpp:106] Iteration 64000, lr = 0.01
I0829 10:27:44.908558 916722 solver.cpp:218] Iteration 64500 (16.6884 iter/s, 29.9609s/500 iters), loss = 0.26481
I0829 10:27:44.908613 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.264811 (* 1 = 0.264811 loss)
I0829 10:27:44.908623 916722 sgd_solver.cpp:106] Iteration 64500, lr = 0.01
I0829 10:28:14.852186 916722 solver.cpp:218] Iteration 65000 (16.6981 iter/s, 29.9436s/500 iters), loss = 0.210265
I0829 10:28:14.852245 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.210266 (* 1 = 0.210266 loss)
I0829 10:28:14.852254 916722 sgd_solver.cpp:106] Iteration 65000, lr = 0.01
I0829 10:28:44.800341 916722 solver.cpp:218] Iteration 65500 (16.6956 iter/s, 29.9481s/500 iters), loss = 0.354805
I0829 10:28:44.800396 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.354806 (* 1 = 0.354806 loss)
I0829 10:28:44.800406 916722 sgd_solver.cpp:106] Iteration 65500, lr = 0.01
I0829 10:29:14.750175 916722 solver.cpp:218] Iteration 66000 (16.6946 iter/s, 29.9498s/500 iters), loss = 0.213235
I0829 10:29:14.750236 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.213236 (* 1 = 0.213236 loss)
I0829 10:29:14.750244 916722 sgd_solver.cpp:106] Iteration 66000, lr = 0.01
I0829 10:29:44.688074 916722 solver.cpp:218] Iteration 66500 (16.7013 iter/s, 29.9378s/500 iters), loss = 0.405176
I0829 10:29:44.688129 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.405177 (* 1 = 0.405177 loss)
I0829 10:29:44.688139 916722 sgd_solver.cpp:106] Iteration 66500, lr = 0.01
I0829 10:30:14.644140 916722 solver.cpp:218] Iteration 67000 (16.6911 iter/s, 29.956s/500 iters), loss = 0.322934
I0829 10:30:14.644198 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.322935 (* 1 = 0.322935 loss)
I0829 10:30:14.644207 916722 sgd_solver.cpp:106] Iteration 67000, lr = 0.01
I0829 10:30:44.606086 916722 solver.cpp:218] Iteration 67500 (16.6879 iter/s, 29.9619s/500 iters), loss = 0.229665
I0829 10:30:44.606140 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.229666 (* 1 = 0.229666 loss)
I0829 10:30:44.606149 916722 sgd_solver.cpp:106] Iteration 67500, lr = 0.01
I0829 10:31:14.557453 916722 solver.cpp:218] Iteration 68000 (16.6938 iter/s, 29.9513s/500 iters), loss = 0.13609
I0829 10:31:14.557515 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13609 (* 1 = 0.13609 loss)
I0829 10:31:14.557523 916722 sgd_solver.cpp:106] Iteration 68000, lr = 0.01
I0829 10:31:44.515728 916722 solver.cpp:218] Iteration 68500 (16.6899 iter/s, 29.9582s/500 iters), loss = 0.331356
I0829 10:31:44.515784 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.331356 (* 1 = 0.331356 loss)
I0829 10:31:44.515792 916722 sgd_solver.cpp:106] Iteration 68500, lr = 0.01
I0829 10:32:14.481925 916722 solver.cpp:218] Iteration 69000 (16.6855 iter/s, 29.9661s/500 iters), loss = 0.186839
I0829 10:32:14.481985 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.186839 (* 1 = 0.186839 loss)
I0829 10:32:14.481993 916722 sgd_solver.cpp:106] Iteration 69000, lr = 0.01
I0829 10:32:44.446763 916722 solver.cpp:218] Iteration 69500 (16.6863 iter/s, 29.9648s/500 iters), loss = 0.543858
I0829 10:32:44.446817 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.543859 (* 1 = 0.543859 loss)
I0829 10:32:44.446826 916722 sgd_solver.cpp:106] Iteration 69500, lr = 0.01
I0829 10:33:14.405683 916722 solver.cpp:218] Iteration 70000 (16.6896 iter/s, 29.9589s/500 iters), loss = 0.343965
I0829 10:33:14.405741 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.343966 (* 1 = 0.343966 loss)
I0829 10:33:14.405750 916722 sgd_solver.cpp:106] Iteration 70000, lr = 0.01
I0829 10:33:44.378501 916722 solver.cpp:218] Iteration 70500 (16.6818 iter/s, 29.9727s/500 iters), loss = 0.0973583
I0829 10:33:44.378562 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.097359 (* 1 = 0.097359 loss)
I0829 10:33:44.378571 916722 sgd_solver.cpp:106] Iteration 70500, lr = 0.01
I0829 10:34:14.339264 916722 solver.cpp:218] Iteration 71000 (16.6885 iter/s, 29.9607s/500 iters), loss = 0.364525
I0829 10:34:14.339331 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.364525 (* 1 = 0.364525 loss)
I0829 10:34:14.339339 916722 sgd_solver.cpp:106] Iteration 71000, lr = 0.01
I0829 10:34:44.289772 916722 solver.cpp:218] Iteration 71500 (16.6943 iter/s, 29.9504s/500 iters), loss = 0.394283
I0829 10:34:44.289830 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.394284 (* 1 = 0.394284 loss)
I0829 10:34:44.289841 916722 sgd_solver.cpp:106] Iteration 71500, lr = 0.01
I0829 10:35:14.257365 916722 solver.cpp:218] Iteration 72000 (16.6847 iter/s, 29.9675s/500 iters), loss = 0.265351
I0829 10:35:14.257426 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.265352 (* 1 = 0.265352 loss)
I0829 10:35:14.257433 916722 sgd_solver.cpp:106] Iteration 72000, lr = 0.01
I0829 10:35:44.228649 916722 solver.cpp:218] Iteration 72500 (16.6827 iter/s, 29.9712s/500 iters), loss = 0.34412
I0829 10:35:44.228706 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.344121 (* 1 = 0.344121 loss)
I0829 10:35:44.228716 916722 sgd_solver.cpp:106] Iteration 72500, lr = 0.01
I0829 10:36:14.190439 916722 solver.cpp:218] Iteration 73000 (16.688 iter/s, 29.9617s/500 iters), loss = 0.290159
I0829 10:36:14.190498 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.290159 (* 1 = 0.290159 loss)
I0829 10:36:14.190506 916722 sgd_solver.cpp:106] Iteration 73000, lr = 0.01
I0829 10:36:44.158645 916722 solver.cpp:218] Iteration 73500 (16.6844 iter/s, 29.9681s/500 iters), loss = 0.281594
I0829 10:36:44.158699 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.281594 (* 1 = 0.281594 loss)
I0829 10:36:44.158710 916722 sgd_solver.cpp:106] Iteration 73500, lr = 0.01
I0829 10:37:14.112483 916722 solver.cpp:218] Iteration 74000 (16.6924 iter/s, 29.9538s/500 iters), loss = 0.257142
I0829 10:37:14.112543 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.257143 (* 1 = 0.257143 loss)
I0829 10:37:14.112552 916722 sgd_solver.cpp:106] Iteration 74000, lr = 0.01
I0829 10:37:44.066169 916722 solver.cpp:218] Iteration 74500 (16.6925 iter/s, 29.9536s/500 iters), loss = 0.526198
I0829 10:37:44.066226 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.526199 (* 1 = 0.526199 loss)
I0829 10:37:44.066236 916722 sgd_solver.cpp:106] Iteration 74500, lr = 0.01
I0829 10:38:14.022157 916722 solver.cpp:218] Iteration 75000 (16.6912 iter/s, 29.9559s/500 iters), loss = 0.788742
I0829 10:38:14.022212 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.788743 (* 1 = 0.788743 loss)
I0829 10:38:14.022222 916722 sgd_solver.cpp:106] Iteration 75000, lr = 0.01
I0829 10:38:43.992609 916722 solver.cpp:218] Iteration 75500 (16.6831 iter/s, 29.9704s/500 iters), loss = 0.178941
I0829 10:38:43.992663 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.178941 (* 1 = 0.178941 loss)
I0829 10:38:43.992673 916722 sgd_solver.cpp:106] Iteration 75500, lr = 0.01
I0829 10:39:13.971549 916722 solver.cpp:218] Iteration 76000 (16.6784 iter/s, 29.9789s/500 iters), loss = 0.239907
I0829 10:39:13.971609 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.239908 (* 1 = 0.239908 loss)
I0829 10:39:13.971618 916722 sgd_solver.cpp:106] Iteration 76000, lr = 0.01
I0829 10:39:43.947352 916722 solver.cpp:218] Iteration 76500 (16.6802 iter/s, 29.9757s/500 iters), loss = 0.342009
I0829 10:39:43.947405 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.342009 (* 1 = 0.342009 loss)
I0829 10:39:43.947415 916722 sgd_solver.cpp:106] Iteration 76500, lr = 0.01
I0829 10:40:13.899593 916722 solver.cpp:218] Iteration 77000 (16.6933 iter/s, 29.9522s/500 iters), loss = 0.544736
I0829 10:40:13.899667 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.544737 (* 1 = 0.544737 loss)
I0829 10:40:13.899679 916722 sgd_solver.cpp:106] Iteration 77000, lr = 0.01
I0829 10:40:43.864341 916722 solver.cpp:218] Iteration 77500 (16.6863 iter/s, 29.9647s/500 iters), loss = 0.107192
I0829 10:40:43.864396 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.107193 (* 1 = 0.107193 loss)
I0829 10:40:43.864406 916722 sgd_solver.cpp:106] Iteration 77500, lr = 0.01
I0829 10:41:13.835690 916722 solver.cpp:218] Iteration 78000 (16.6826 iter/s, 29.9713s/500 iters), loss = 0.282813
I0829 10:41:13.835752 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.282814 (* 1 = 0.282814 loss)
I0829 10:41:13.835760 916722 sgd_solver.cpp:106] Iteration 78000, lr = 0.01
I0829 10:41:43.776988 916722 solver.cpp:218] Iteration 78500 (16.6994 iter/s, 29.9412s/500 iters), loss = 0.18045
I0829 10:41:43.777038 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.180451 (* 1 = 0.180451 loss)
I0829 10:41:43.777047 916722 sgd_solver.cpp:106] Iteration 78500, lr = 0.01
I0829 10:42:13.735230 916722 solver.cpp:218] Iteration 79000 (16.6899 iter/s, 29.9582s/500 iters), loss = 0.265948
I0829 10:42:13.735291 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.265948 (* 1 = 0.265948 loss)
I0829 10:42:13.735299 916722 sgd_solver.cpp:106] Iteration 79000, lr = 0.01
I0829 10:42:43.671365 916722 solver.cpp:218] Iteration 79500 (16.7023 iter/s, 29.9361s/500 iters), loss = 0.299633
I0829 10:42:43.671416 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.299634 (* 1 = 0.299634 loss)
I0829 10:42:43.671424 916722 sgd_solver.cpp:106] Iteration 79500, lr = 0.01
I0829 10:43:13.598937 916722 solver.cpp:218] Iteration 80000 (16.707 iter/s, 29.9275s/500 iters), loss = 0.490379
I0829 10:43:13.598997 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.49038 (* 1 = 0.49038 loss)
I0829 10:43:13.599006 916722 sgd_solver.cpp:106] Iteration 80000, lr = 0.01
I0829 10:43:43.537982 916722 solver.cpp:218] Iteration 80500 (16.7006 iter/s, 29.939s/500 iters), loss = 0.23206
I0829 10:43:43.538030 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.232061 (* 1 = 0.232061 loss)
I0829 10:43:43.538039 916722 sgd_solver.cpp:106] Iteration 80500, lr = 0.01
I0829 10:44:13.483794 916722 solver.cpp:218] Iteration 81000 (16.6969 iter/s, 29.9457s/500 iters), loss = 0.197065
I0829 10:44:13.483855 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.197066 (* 1 = 0.197066 loss)
I0829 10:44:13.483863 916722 sgd_solver.cpp:106] Iteration 81000, lr = 0.01
I0829 10:44:43.430850 916722 solver.cpp:218] Iteration 81500 (16.6962 iter/s, 29.947s/500 iters), loss = 0.284497
I0829 10:44:43.430907 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.284498 (* 1 = 0.284498 loss)
I0829 10:44:43.430917 916722 sgd_solver.cpp:106] Iteration 81500, lr = 0.01
I0829 10:45:13.385066 916722 solver.cpp:218] Iteration 82000 (16.6922 iter/s, 29.9541s/500 iters), loss = 0.440884
I0829 10:45:13.385126 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.440885 (* 1 = 0.440885 loss)
I0829 10:45:13.385134 916722 sgd_solver.cpp:106] Iteration 82000, lr = 0.01
I0829 10:45:43.355587 916722 solver.cpp:218] Iteration 82500 (16.6831 iter/s, 29.9704s/500 iters), loss = 0.393201
I0829 10:45:43.355639 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.393202 (* 1 = 0.393202 loss)
I0829 10:45:43.355649 916722 sgd_solver.cpp:106] Iteration 82500, lr = 0.01
I0829 10:46:13.310401 916722 solver.cpp:218] Iteration 83000 (16.6919 iter/s, 29.9547s/500 iters), loss = 0.455542
I0829 10:46:13.310456 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.455543 (* 1 = 0.455543 loss)
I0829 10:46:13.310464 916722 sgd_solver.cpp:106] Iteration 83000, lr = 0.01
I0829 10:46:43.292714 916722 solver.cpp:218] Iteration 83500 (16.6765 iter/s, 29.9822s/500 iters), loss = 0.213411
I0829 10:46:43.292778 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.213411 (* 1 = 0.213411 loss)
I0829 10:46:43.292788 916722 sgd_solver.cpp:106] Iteration 83500, lr = 0.01
I0829 10:47:13.258412 916722 solver.cpp:218] Iteration 84000 (16.6858 iter/s, 29.9656s/500 iters), loss = 0.129167
I0829 10:47:13.258486 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.129167 (* 1 = 0.129167 loss)
I0829 10:47:13.258493 916722 sgd_solver.cpp:106] Iteration 84000, lr = 0.01
I0829 10:47:43.221276 916722 solver.cpp:218] Iteration 84500 (16.6874 iter/s, 29.9628s/500 iters), loss = 0.368061
I0829 10:47:43.221328 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.368062 (* 1 = 0.368062 loss)
I0829 10:47:43.221338 916722 sgd_solver.cpp:106] Iteration 84500, lr = 0.01
I0829 10:48:13.191321 916722 solver.cpp:218] Iteration 85000 (16.6834 iter/s, 29.9699s/500 iters), loss = 0.585925
I0829 10:48:13.191381 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.585926 (* 1 = 0.585926 loss)
I0829 10:48:13.191390 916722 sgd_solver.cpp:106] Iteration 85000, lr = 0.01
I0829 10:48:43.158910 916722 solver.cpp:218] Iteration 85500 (16.6848 iter/s, 29.9675s/500 iters), loss = 0.24471
I0829 10:48:43.158965 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.24471 (* 1 = 0.24471 loss)
I0829 10:48:43.158975 916722 sgd_solver.cpp:106] Iteration 85500, lr = 0.01
I0829 10:49:13.110342 916722 solver.cpp:218] Iteration 86000 (16.6938 iter/s, 29.9513s/500 iters), loss = 0.0799544
I0829 10:49:13.110406 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0799554 (* 1 = 0.0799554 loss)
I0829 10:49:13.110415 916722 sgd_solver.cpp:106] Iteration 86000, lr = 0.01
I0829 10:49:43.081897 916722 solver.cpp:218] Iteration 86500 (16.6825 iter/s, 29.9714s/500 iters), loss = 0.295776
I0829 10:49:43.081948 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.295777 (* 1 = 0.295777 loss)
I0829 10:49:43.081956 916722 sgd_solver.cpp:106] Iteration 86500, lr = 0.01
I0829 10:50:13.058280 916722 solver.cpp:218] Iteration 87000 (16.6798 iter/s, 29.9763s/500 iters), loss = 0.301934
I0829 10:50:13.058341 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.301935 (* 1 = 0.301935 loss)
I0829 10:50:13.058349 916722 sgd_solver.cpp:106] Iteration 87000, lr = 0.01
I0829 10:50:43.028561 916722 solver.cpp:218] Iteration 87500 (16.6833 iter/s, 29.9702s/500 iters), loss = 0.365304
I0829 10:50:43.028615 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.365305 (* 1 = 0.365305 loss)
I0829 10:50:43.028625 916722 sgd_solver.cpp:106] Iteration 87500, lr = 0.01
I0829 10:51:12.999430 916722 solver.cpp:218] Iteration 88000 (16.6829 iter/s, 29.9708s/500 iters), loss = 0.636932
I0829 10:51:12.999490 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.636933 (* 1 = 0.636933 loss)
I0829 10:51:12.999500 916722 sgd_solver.cpp:106] Iteration 88000, lr = 0.01
I0829 10:51:42.960552 916722 solver.cpp:218] Iteration 88500 (16.6884 iter/s, 29.961s/500 iters), loss = 0.199568
I0829 10:51:42.960608 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.199569 (* 1 = 0.199569 loss)
I0829 10:51:42.960616 916722 sgd_solver.cpp:106] Iteration 88500, lr = 0.01
I0829 10:52:12.922008 916722 solver.cpp:218] Iteration 89000 (16.6882 iter/s, 29.9614s/500 iters), loss = 0.209868
I0829 10:52:12.922065 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.209869 (* 1 = 0.209869 loss)
I0829 10:52:12.922073 916722 sgd_solver.cpp:106] Iteration 89000, lr = 0.01
I0829 10:52:42.879844 916722 solver.cpp:218] Iteration 89500 (16.6902 iter/s, 29.9577s/500 iters), loss = 0.252541
I0829 10:52:42.879899 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.252542 (* 1 = 0.252542 loss)
I0829 10:52:42.879909 916722 sgd_solver.cpp:106] Iteration 89500, lr = 0.01
I0829 10:53:12.847296 916722 solver.cpp:218] Iteration 90000 (16.6848 iter/s, 29.9674s/500 iters), loss = 0.0740703
I0829 10:53:12.847352 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0740713 (* 1 = 0.0740713 loss)
I0829 10:53:12.847359 916722 sgd_solver.cpp:106] Iteration 90000, lr = 0.01
I0829 10:53:42.814507 916722 solver.cpp:218] Iteration 90500 (16.685 iter/s, 29.9671s/500 iters), loss = 0.270296
I0829 10:53:42.814561 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.270297 (* 1 = 0.270297 loss)
I0829 10:53:42.814584 916722 sgd_solver.cpp:106] Iteration 90500, lr = 0.01
I0829 10:54:12.751268 916722 solver.cpp:218] Iteration 91000 (16.7019 iter/s, 29.9367s/500 iters), loss = 0.530359
I0829 10:54:12.751339 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.530359 (* 1 = 0.530359 loss)
I0829 10:54:12.751348 916722 sgd_solver.cpp:106] Iteration 91000, lr = 0.01
I0829 10:54:42.694777 916722 solver.cpp:218] Iteration 91500 (16.6982 iter/s, 29.9434s/500 iters), loss = 0.327376
I0829 10:54:42.694830 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.327377 (* 1 = 0.327377 loss)
I0829 10:54:42.694839 916722 sgd_solver.cpp:106] Iteration 91500, lr = 0.01
I0829 10:55:12.638849 916722 solver.cpp:218] Iteration 92000 (16.6978 iter/s, 29.944s/500 iters), loss = 0.0359568
I0829 10:55:12.638908 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0359571 (* 1 = 0.0359571 loss)
I0829 10:55:12.638917 916722 sgd_solver.cpp:106] Iteration 92000, lr = 0.01
I0829 10:55:42.602440 916722 solver.cpp:218] Iteration 92500 (16.687 iter/s, 29.9635s/500 iters), loss = 0.238685
I0829 10:55:42.602494 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.238686 (* 1 = 0.238686 loss)
I0829 10:55:42.602504 916722 sgd_solver.cpp:106] Iteration 92500, lr = 0.01
I0829 10:56:12.568747 916722 solver.cpp:218] Iteration 93000 (16.6855 iter/s, 29.9662s/500 iters), loss = 0.27372
I0829 10:56:12.568806 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.273721 (* 1 = 0.273721 loss)
I0829 10:56:12.568815 916722 sgd_solver.cpp:106] Iteration 93000, lr = 0.01
I0829 10:56:42.511348 916722 solver.cpp:218] Iteration 93500 (16.6987 iter/s, 29.9425s/500 iters), loss = 0.19399
I0829 10:56:42.511400 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.19399 (* 1 = 0.19399 loss)
I0829 10:56:42.511409 916722 sgd_solver.cpp:106] Iteration 93500, lr = 0.01
I0829 10:57:12.492872 916722 solver.cpp:218] Iteration 94000 (16.677 iter/s, 29.9814s/500 iters), loss = 0.256418
I0829 10:57:12.492931 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.256418 (* 1 = 0.256418 loss)
I0829 10:57:12.492940 916722 sgd_solver.cpp:106] Iteration 94000, lr = 0.01
I0829 10:57:42.440094 916722 solver.cpp:218] Iteration 94500 (16.6961 iter/s, 29.9471s/500 iters), loss = 0.135931
I0829 10:57:42.440145 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.135931 (* 1 = 0.135931 loss)
I0829 10:57:42.440153 916722 sgd_solver.cpp:106] Iteration 94500, lr = 0.01
I0829 10:58:12.387389 916722 solver.cpp:218] Iteration 95000 (16.696 iter/s, 29.9472s/500 iters), loss = 0.212262
I0829 10:58:12.387450 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.212263 (* 1 = 0.212263 loss)
I0829 10:58:12.387459 916722 sgd_solver.cpp:106] Iteration 95000, lr = 0.01
I0829 10:58:42.326897 916722 solver.cpp:218] Iteration 95500 (16.7004 iter/s, 29.9394s/500 iters), loss = 0.235919
I0829 10:58:42.326949 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.235919 (* 1 = 0.235919 loss)
I0829 10:58:42.326957 916722 sgd_solver.cpp:106] Iteration 95500, lr = 0.01
I0829 10:59:12.268846 916722 solver.cpp:218] Iteration 96000 (16.699 iter/s, 29.9419s/500 iters), loss = 0.253619
I0829 10:59:12.268908 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.253619 (* 1 = 0.253619 loss)
I0829 10:59:12.268918 916722 sgd_solver.cpp:106] Iteration 96000, lr = 0.01
I0829 10:59:42.238107 916722 solver.cpp:218] Iteration 96500 (16.6838 iter/s, 29.9692s/500 iters), loss = 0.211129
I0829 10:59:42.238159 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.211129 (* 1 = 0.211129 loss)
I0829 10:59:42.238168 916722 sgd_solver.cpp:106] Iteration 96500, lr = 0.01
I0829 11:00:12.193359 916722 solver.cpp:218] Iteration 97000 (16.6916 iter/s, 29.9552s/500 iters), loss = 0.184652
I0829 11:00:12.193432 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.184652 (* 1 = 0.184652 loss)
I0829 11:00:12.193444 916722 sgd_solver.cpp:106] Iteration 97000, lr = 0.01
I0829 11:00:42.161345 916722 solver.cpp:218] Iteration 97500 (16.6845 iter/s, 29.9679s/500 iters), loss = 0.304074
I0829 11:00:42.161397 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.304074 (* 1 = 0.304074 loss)
I0829 11:00:42.161406 916722 sgd_solver.cpp:106] Iteration 97500, lr = 0.01
I0829 11:01:12.126827 916722 solver.cpp:218] Iteration 98000 (16.6859 iter/s, 29.9654s/500 iters), loss = 0.528936
I0829 11:01:12.126885 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.528936 (* 1 = 0.528936 loss)
I0829 11:01:12.126894 916722 sgd_solver.cpp:106] Iteration 98000, lr = 0.01
I0829 11:01:42.108027 916722 solver.cpp:218] Iteration 98500 (16.6772 iter/s, 29.9811s/500 iters), loss = 0.122031
I0829 11:01:42.108078 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.122031 (* 1 = 0.122031 loss)
I0829 11:01:42.108085 916722 sgd_solver.cpp:106] Iteration 98500, lr = 0.01
I0829 11:02:12.075724 916722 solver.cpp:218] Iteration 99000 (16.6847 iter/s, 29.9676s/500 iters), loss = 0.226171
I0829 11:02:12.075786 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.226172 (* 1 = 0.226172 loss)
I0829 11:02:12.075795 916722 sgd_solver.cpp:106] Iteration 99000, lr = 0.01
I0829 11:02:42.066061 916722 solver.cpp:218] Iteration 99500 (16.6721 iter/s, 29.9902s/500 iters), loss = 0.167547
I0829 11:02:42.066118 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.167547 (* 1 = 0.167547 loss)
I0829 11:02:42.066128 916722 sgd_solver.cpp:106] Iteration 99500, lr = 0.01
I0829 11:03:11.986346 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_100000.caffemodel
I0829 11:03:12.005898 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_100000.solverstate
I0829 11:03:12.011999 916722 solver.cpp:330] Iteration 100000, Testing net (#0)
I0829 11:03:27.469882 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8699
I0829 11:03:27.469926 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.389404 (* 1 = 0.389404 loss)
I0829 11:03:27.528678 916722 solver.cpp:218] Iteration 100000 (10.9981 iter/s, 45.4625s/500 iters), loss = 0.227414
I0829 11:03:27.528707 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.227414 (* 1 = 0.227414 loss)
I0829 11:03:27.528715 916722 sgd_solver.cpp:106] Iteration 100000, lr = 0.01
I0829 11:03:57.368000 916722 solver.cpp:218] Iteration 100500 (16.7565 iter/s, 29.8392s/500 iters), loss = 0.109157
I0829 11:03:57.368059 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109157 (* 1 = 0.109157 loss)
I0829 11:03:57.368068 916722 sgd_solver.cpp:106] Iteration 100500, lr = 0.01
I0829 11:04:27.317621 916722 solver.cpp:218] Iteration 101000 (16.6948 iter/s, 29.9495s/500 iters), loss = 0.460143
I0829 11:04:27.317675 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.460143 (* 1 = 0.460143 loss)
I0829 11:04:27.317684 916722 sgd_solver.cpp:106] Iteration 101000, lr = 0.01
I0829 11:04:57.300465 916722 solver.cpp:218] Iteration 101500 (16.6763 iter/s, 29.9828s/500 iters), loss = 0.410893
I0829 11:04:57.300526 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.410893 (* 1 = 0.410893 loss)
I0829 11:04:57.300534 916722 sgd_solver.cpp:106] Iteration 101500, lr = 0.01
I0829 11:05:27.271080 916722 solver.cpp:218] Iteration 102000 (16.6831 iter/s, 29.9705s/500 iters), loss = 0.346863
I0829 11:05:27.271136 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.346863 (* 1 = 0.346863 loss)
I0829 11:05:27.271147 916722 sgd_solver.cpp:106] Iteration 102000, lr = 0.01
I0829 11:05:57.254499 916722 solver.cpp:218] Iteration 102500 (16.6759 iter/s, 29.9833s/500 iters), loss = 0.239587
I0829 11:05:57.254563 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.239588 (* 1 = 0.239588 loss)
I0829 11:05:57.254571 916722 sgd_solver.cpp:106] Iteration 102500, lr = 0.01
I0829 11:06:27.242759 916722 solver.cpp:218] Iteration 103000 (16.6732 iter/s, 29.9882s/500 iters), loss = 0.281456
I0829 11:06:27.242830 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.281457 (* 1 = 0.281457 loss)
I0829 11:06:27.242839 916722 sgd_solver.cpp:106] Iteration 103000, lr = 0.01
I0829 11:06:57.240379 916722 solver.cpp:218] Iteration 103500 (16.668 iter/s, 29.9975s/500 iters), loss = 0.356532
I0829 11:06:57.240450 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.356532 (* 1 = 0.356532 loss)
I0829 11:06:57.240459 916722 sgd_solver.cpp:106] Iteration 103500, lr = 0.01
I0829 11:07:27.227025 916722 solver.cpp:218] Iteration 104000 (16.6741 iter/s, 29.9866s/500 iters), loss = 0.332358
I0829 11:07:27.227082 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.332358 (* 1 = 0.332358 loss)
I0829 11:07:27.227092 916722 sgd_solver.cpp:106] Iteration 104000, lr = 0.01
I0829 11:07:57.228102 916722 solver.cpp:218] Iteration 104500 (16.6661 iter/s, 30.001s/500 iters), loss = 0.460543
I0829 11:07:57.228163 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.460544 (* 1 = 0.460544 loss)
I0829 11:07:57.228171 916722 sgd_solver.cpp:106] Iteration 104500, lr = 0.01
I0829 11:08:27.230751 916722 solver.cpp:218] Iteration 105000 (16.6652 iter/s, 30.0026s/500 iters), loss = 0.228589
I0829 11:08:27.230813 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.228589 (* 1 = 0.228589 loss)
I0829 11:08:27.230821 916722 sgd_solver.cpp:106] Iteration 105000, lr = 0.01
I0829 11:08:57.239749 916722 solver.cpp:218] Iteration 105500 (16.6617 iter/s, 30.0089s/500 iters), loss = 0.381182
I0829 11:08:57.239810 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.381182 (* 1 = 0.381182 loss)
I0829 11:08:57.239820 916722 sgd_solver.cpp:106] Iteration 105500, lr = 0.01
I0829 11:09:27.242483 916722 solver.cpp:218] Iteration 106000 (16.6652 iter/s, 30.0027s/500 iters), loss = 0.151419
I0829 11:09:27.242544 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.151419 (* 1 = 0.151419 loss)
I0829 11:09:27.242553 916722 sgd_solver.cpp:106] Iteration 106000, lr = 0.01
I0829 11:09:57.248816 916722 solver.cpp:218] Iteration 106500 (16.6632 iter/s, 30.0062s/500 iters), loss = 0.190266
I0829 11:09:57.248879 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.190267 (* 1 = 0.190267 loss)
I0829 11:09:57.248888 916722 sgd_solver.cpp:106] Iteration 106500, lr = 0.01
I0829 11:10:27.264470 916722 solver.cpp:218] Iteration 107000 (16.658 iter/s, 30.0156s/500 iters), loss = 0.143761
I0829 11:10:27.264529 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.143761 (* 1 = 0.143761 loss)
I0829 11:10:27.264537 916722 sgd_solver.cpp:106] Iteration 107000, lr = 0.01
I0829 11:10:57.267349 916722 solver.cpp:218] Iteration 107500 (16.6651 iter/s, 30.0028s/500 iters), loss = 0.186033
I0829 11:10:57.267408 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.186033 (* 1 = 0.186033 loss)
I0829 11:10:57.267417 916722 sgd_solver.cpp:106] Iteration 107500, lr = 0.01
I0829 11:11:27.257534 916722 solver.cpp:218] Iteration 108000 (16.6722 iter/s, 29.9901s/500 iters), loss = 0.546681
I0829 11:11:27.257583 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.546682 (* 1 = 0.546682 loss)
I0829 11:11:27.257594 916722 sgd_solver.cpp:106] Iteration 108000, lr = 0.01
I0829 11:11:57.260183 916722 solver.cpp:218] Iteration 108500 (16.6652 iter/s, 30.0026s/500 iters), loss = 0.116049
I0829 11:11:57.260244 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.11605 (* 1 = 0.11605 loss)
I0829 11:11:57.260253 916722 sgd_solver.cpp:106] Iteration 108500, lr = 0.01
I0829 11:12:27.268623 916722 solver.cpp:218] Iteration 109000 (16.662 iter/s, 30.0084s/500 iters), loss = 0.332691
I0829 11:12:27.268685 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.332692 (* 1 = 0.332692 loss)
I0829 11:12:27.268694 916722 sgd_solver.cpp:106] Iteration 109000, lr = 0.01
I0829 11:12:57.261178 916722 solver.cpp:218] Iteration 109500 (16.6708 iter/s, 29.9925s/500 iters), loss = 0.342159
I0829 11:12:57.261236 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.342159 (* 1 = 0.342159 loss)
I0829 11:12:57.261257 916722 sgd_solver.cpp:106] Iteration 109500, lr = 0.01
I0829 11:13:27.288614 916722 solver.cpp:218] Iteration 110000 (16.6515 iter/s, 30.0273s/500 iters), loss = 0.156915
I0829 11:13:27.288683 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.156916 (* 1 = 0.156916 loss)
I0829 11:13:27.288692 916722 sgd_solver.cpp:106] Iteration 110000, lr = 0.01
I0829 11:13:57.277189 916722 solver.cpp:218] Iteration 110500 (16.6731 iter/s, 29.9885s/500 iters), loss = 0.173184
I0829 11:13:57.277243 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.173185 (* 1 = 0.173185 loss)
I0829 11:13:57.277254 916722 sgd_solver.cpp:106] Iteration 110500, lr = 0.01
I0829 11:14:27.273898 916722 solver.cpp:218] Iteration 111000 (16.6685 iter/s, 29.9966s/500 iters), loss = 0.293253
I0829 11:14:27.273958 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.293254 (* 1 = 0.293254 loss)
I0829 11:14:27.273967 916722 sgd_solver.cpp:106] Iteration 111000, lr = 0.01
I0829 11:14:57.281749 916722 solver.cpp:218] Iteration 111500 (16.6624 iter/s, 30.0078s/500 iters), loss = 0.111272
I0829 11:14:57.281806 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111273 (* 1 = 0.111273 loss)
I0829 11:14:57.281814 916722 sgd_solver.cpp:106] Iteration 111500, lr = 0.01
I0829 11:15:27.275550 916722 solver.cpp:218] Iteration 112000 (16.6702 iter/s, 29.9937s/500 iters), loss = 0.270682
I0829 11:15:27.275606 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.270682 (* 1 = 0.270682 loss)
I0829 11:15:27.275616 916722 sgd_solver.cpp:106] Iteration 112000, lr = 0.01
I0829 11:15:57.276103 916722 solver.cpp:218] Iteration 112500 (16.6664 iter/s, 30.0005s/500 iters), loss = 0.224782
I0829 11:15:57.276163 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.224782 (* 1 = 0.224782 loss)
I0829 11:15:57.276171 916722 sgd_solver.cpp:106] Iteration 112500, lr = 0.01
I0829 11:16:27.283066 916722 solver.cpp:218] Iteration 113000 (16.6628 iter/s, 30.0069s/500 iters), loss = 0.377623
I0829 11:16:27.283123 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.377623 (* 1 = 0.377623 loss)
I0829 11:16:27.283131 916722 sgd_solver.cpp:106] Iteration 113000, lr = 0.01
I0829 11:16:57.277247 916722 solver.cpp:218] Iteration 113500 (16.6699 iter/s, 29.9941s/500 iters), loss = 0.211556
I0829 11:16:57.277302 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.211556 (* 1 = 0.211556 loss)
I0829 11:16:57.277312 916722 sgd_solver.cpp:106] Iteration 113500, lr = 0.01
I0829 11:17:27.280562 916722 solver.cpp:218] Iteration 114000 (16.6649 iter/s, 30.0032s/500 iters), loss = 0.209446
I0829 11:17:27.280623 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.209447 (* 1 = 0.209447 loss)
I0829 11:17:27.280632 916722 sgd_solver.cpp:106] Iteration 114000, lr = 0.01
I0829 11:17:57.281695 916722 solver.cpp:218] Iteration 114500 (16.6661 iter/s, 30.001s/500 iters), loss = 0.25383
I0829 11:17:57.281755 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.25383 (* 1 = 0.25383 loss)
I0829 11:17:57.281764 916722 sgd_solver.cpp:106] Iteration 114500, lr = 0.01
I0829 11:18:27.279711 916722 solver.cpp:218] Iteration 115000 (16.6678 iter/s, 29.9979s/500 iters), loss = 0.197756
I0829 11:18:27.279763 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.197756 (* 1 = 0.197756 loss)
I0829 11:18:27.279774 916722 sgd_solver.cpp:106] Iteration 115000, lr = 0.01
I0829 11:18:57.280553 916722 solver.cpp:218] Iteration 115500 (16.6662 iter/s, 30.0008s/500 iters), loss = 0.283976
I0829 11:18:57.280614 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.283976 (* 1 = 0.283976 loss)
I0829 11:18:57.280623 916722 sgd_solver.cpp:106] Iteration 115500, lr = 0.01
I0829 11:19:27.287272 916722 solver.cpp:218] Iteration 116000 (16.663 iter/s, 30.0066s/500 iters), loss = 0.526596
I0829 11:19:27.287345 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.526596 (* 1 = 0.526596 loss)
I0829 11:19:27.287358 916722 sgd_solver.cpp:106] Iteration 116000, lr = 0.01
I0829 11:19:57.281047 916722 solver.cpp:218] Iteration 116500 (16.6702 iter/s, 29.9937s/500 iters), loss = 0.497428
I0829 11:19:57.281100 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.497428 (* 1 = 0.497428 loss)
I0829 11:19:57.281109 916722 sgd_solver.cpp:106] Iteration 116500, lr = 0.01
I0829 11:20:27.284693 916722 solver.cpp:218] Iteration 117000 (16.6647 iter/s, 30.0036s/500 iters), loss = 0.29234
I0829 11:20:27.284755 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.29234 (* 1 = 0.29234 loss)
I0829 11:20:27.284765 916722 sgd_solver.cpp:106] Iteration 117000, lr = 0.01
I0829 11:20:57.275892 916722 solver.cpp:218] Iteration 117500 (16.6716 iter/s, 29.9911s/500 iters), loss = 0.092689
I0829 11:20:57.275947 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0926893 (* 1 = 0.0926893 loss)
I0829 11:20:57.275956 916722 sgd_solver.cpp:106] Iteration 117500, lr = 0.01
I0829 11:21:27.249912 916722 solver.cpp:218] Iteration 118000 (16.6812 iter/s, 29.9739s/500 iters), loss = 0.487455
I0829 11:21:27.249975 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.487455 (* 1 = 0.487455 loss)
I0829 11:21:27.249984 916722 sgd_solver.cpp:106] Iteration 118000, lr = 0.01
I0829 11:21:57.240485 916722 solver.cpp:218] Iteration 118500 (16.672 iter/s, 29.9904s/500 iters), loss = 0.319977
I0829 11:21:57.240540 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.319977 (* 1 = 0.319977 loss)
I0829 11:21:57.240548 916722 sgd_solver.cpp:106] Iteration 118500, lr = 0.01
I0829 11:22:27.188266 916722 solver.cpp:218] Iteration 119000 (16.6959 iter/s, 29.9474s/500 iters), loss = 0.299613
I0829 11:22:27.188325 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.299613 (* 1 = 0.299613 loss)
I0829 11:22:27.188333 916722 sgd_solver.cpp:106] Iteration 119000, lr = 0.01
I0829 11:22:57.134656 916722 solver.cpp:218] Iteration 119500 (16.6967 iter/s, 29.946s/500 iters), loss = 0.404845
I0829 11:22:57.134708 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.404845 (* 1 = 0.404845 loss)
I0829 11:22:57.134718 916722 sgd_solver.cpp:106] Iteration 119500, lr = 0.01
I0829 11:23:27.078148 916722 solver.cpp:218] Iteration 120000 (16.6983 iter/s, 29.9431s/500 iters), loss = 0.29109
I0829 11:23:27.078208 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.29109 (* 1 = 0.29109 loss)
I0829 11:23:27.078217 916722 sgd_solver.cpp:106] Iteration 120000, lr = 0.01
I0829 11:23:57.040729 916722 solver.cpp:218] Iteration 120500 (16.6877 iter/s, 29.9622s/500 iters), loss = 0.32863
I0829 11:23:57.040810 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.32863 (* 1 = 0.32863 loss)
I0829 11:23:57.040820 916722 sgd_solver.cpp:106] Iteration 120500, lr = 0.01
I0829 11:24:26.976709 916722 solver.cpp:218] Iteration 121000 (16.7025 iter/s, 29.9356s/500 iters), loss = 0.170695
I0829 11:24:26.976791 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.170696 (* 1 = 0.170696 loss)
I0829 11:24:26.976800 916722 sgd_solver.cpp:106] Iteration 121000, lr = 0.01
I0829 11:24:56.905506 916722 solver.cpp:218] Iteration 121500 (16.7065 iter/s, 29.9285s/500 iters), loss = 0.110295
I0829 11:24:56.905557 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110296 (* 1 = 0.110296 loss)
I0829 11:24:56.905567 916722 sgd_solver.cpp:106] Iteration 121500, lr = 0.01
I0829 11:25:26.835886 916722 solver.cpp:218] Iteration 122000 (16.7056 iter/s, 29.9301s/500 iters), loss = 0.368872
I0829 11:25:26.835947 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.368873 (* 1 = 0.368873 loss)
I0829 11:25:26.835955 916722 sgd_solver.cpp:106] Iteration 122000, lr = 0.01
I0829 11:25:56.784968 916722 solver.cpp:218] Iteration 122500 (16.6952 iter/s, 29.9488s/500 iters), loss = 0.241414
I0829 11:25:56.785023 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.241414 (* 1 = 0.241414 loss)
I0829 11:25:56.785033 916722 sgd_solver.cpp:106] Iteration 122500, lr = 0.01
I0829 11:26:26.731904 916722 solver.cpp:218] Iteration 123000 (16.6964 iter/s, 29.9466s/500 iters), loss = 0.262392
I0829 11:26:26.731978 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.262393 (* 1 = 0.262393 loss)
I0829 11:26:26.731987 916722 sgd_solver.cpp:106] Iteration 123000, lr = 0.01
I0829 11:26:56.708047 916722 solver.cpp:218] Iteration 123500 (16.6801 iter/s, 29.9758s/500 iters), loss = 0.130174
I0829 11:26:56.708102 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130174 (* 1 = 0.130174 loss)
I0829 11:26:56.708112 916722 sgd_solver.cpp:106] Iteration 123500, lr = 0.01
I0829 11:27:26.704469 916722 solver.cpp:218] Iteration 124000 (16.6688 iter/s, 29.9961s/500 iters), loss = 0.239342
I0829 11:27:26.704543 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.239343 (* 1 = 0.239343 loss)
I0829 11:27:26.704553 916722 sgd_solver.cpp:106] Iteration 124000, lr = 0.01
I0829 11:27:56.676079 916722 solver.cpp:218] Iteration 124500 (16.6826 iter/s, 29.9713s/500 iters), loss = 0.649636
I0829 11:27:56.676134 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.649636 (* 1 = 0.649636 loss)
I0829 11:27:56.676143 916722 sgd_solver.cpp:106] Iteration 124500, lr = 0.01
I0829 11:28:26.663887 916722 solver.cpp:218] Iteration 125000 (16.6736 iter/s, 29.9876s/500 iters), loss = 0.199318
I0829 11:28:26.663949 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.199319 (* 1 = 0.199319 loss)
I0829 11:28:26.663957 916722 sgd_solver.cpp:106] Iteration 125000, lr = 0.01
I0829 11:28:56.652691 916722 solver.cpp:218] Iteration 125500 (16.673 iter/s, 29.9886s/500 iters), loss = 0.147342
I0829 11:28:56.652760 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.147343 (* 1 = 0.147343 loss)
I0829 11:28:56.652768 916722 sgd_solver.cpp:106] Iteration 125500, lr = 0.01
I0829 11:29:26.630455 916722 solver.cpp:218] Iteration 126000 (16.6792 iter/s, 29.9775s/500 iters), loss = 0.134741
I0829 11:29:26.630509 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.134742 (* 1 = 0.134742 loss)
I0829 11:29:26.630517 916722 sgd_solver.cpp:106] Iteration 126000, lr = 0.01
I0829 11:29:56.582139 916722 solver.cpp:218] Iteration 126500 (16.6937 iter/s, 29.9514s/500 iters), loss = 0.386655
I0829 11:29:56.582193 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.386656 (* 1 = 0.386656 loss)
I0829 11:29:56.582202 916722 sgd_solver.cpp:106] Iteration 126500, lr = 0.01
I0829 11:30:26.557103 916722 solver.cpp:218] Iteration 127000 (16.6807 iter/s, 29.9747s/500 iters), loss = 0.427399
I0829 11:30:26.557164 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.4274 (* 1 = 0.4274 loss)
I0829 11:30:26.557173 916722 sgd_solver.cpp:106] Iteration 127000, lr = 0.01
I0829 11:30:56.513577 916722 solver.cpp:218] Iteration 127500 (16.691 iter/s, 29.9562s/500 iters), loss = 0.300373
I0829 11:30:56.513633 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.300374 (* 1 = 0.300374 loss)
I0829 11:30:56.513640 916722 sgd_solver.cpp:106] Iteration 127500, lr = 0.01
I0829 11:31:26.464419 916722 solver.cpp:218] Iteration 128000 (16.6941 iter/s, 29.9506s/500 iters), loss = 0.303827
I0829 11:31:26.464486 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.303827 (* 1 = 0.303827 loss)
I0829 11:31:26.464495 916722 sgd_solver.cpp:106] Iteration 128000, lr = 0.01
I0829 11:31:56.414054 916722 solver.cpp:218] Iteration 128500 (16.6948 iter/s, 29.9494s/500 iters), loss = 0.103146
I0829 11:31:56.414110 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.103146 (* 1 = 0.103146 loss)
I0829 11:31:56.414120 916722 sgd_solver.cpp:106] Iteration 128500, lr = 0.01
I0829 11:32:26.364079 916722 solver.cpp:218] Iteration 129000 (16.6946 iter/s, 29.9498s/500 iters), loss = 0.111346
I0829 11:32:26.364140 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111347 (* 1 = 0.111347 loss)
I0829 11:32:26.364148 916722 sgd_solver.cpp:106] Iteration 129000, lr = 0.01
I0829 11:32:56.329612 916722 solver.cpp:218] Iteration 129500 (16.6859 iter/s, 29.9653s/500 iters), loss = 0.0644854
I0829 11:32:56.329680 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0644861 (* 1 = 0.0644861 loss)
I0829 11:32:56.329694 916722 sgd_solver.cpp:106] Iteration 129500, lr = 0.01
I0829 11:33:26.290871 916722 solver.cpp:218] Iteration 130000 (16.6883 iter/s, 29.9611s/500 iters), loss = 0.142859
I0829 11:33:26.290942 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.142859 (* 1 = 0.142859 loss)
I0829 11:33:26.290951 916722 sgd_solver.cpp:106] Iteration 130000, lr = 0.01
I0829 11:33:56.273409 916722 solver.cpp:218] Iteration 130500 (16.6765 iter/s, 29.9823s/500 iters), loss = 0.202949
I0829 11:33:56.273459 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.202949 (* 1 = 0.202949 loss)
I0829 11:33:56.273468 916722 sgd_solver.cpp:106] Iteration 130500, lr = 0.01
I0829 11:34:26.243335 916722 solver.cpp:218] Iteration 131000 (16.6835 iter/s, 29.9697s/500 iters), loss = 0.379238
I0829 11:34:26.243394 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.379238 (* 1 = 0.379238 loss)
I0829 11:34:26.243403 916722 sgd_solver.cpp:106] Iteration 131000, lr = 0.01
I0829 11:34:56.207288 916722 solver.cpp:218] Iteration 131500 (16.6868 iter/s, 29.9638s/500 iters), loss = 0.197972
I0829 11:34:56.207341 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.197973 (* 1 = 0.197973 loss)
I0829 11:34:56.207351 916722 sgd_solver.cpp:106] Iteration 131500, lr = 0.01
I0829 11:35:26.199326 916722 solver.cpp:218] Iteration 132000 (16.6712 iter/s, 29.9919s/500 iters), loss = 0.1862
I0829 11:35:26.199386 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.1862 (* 1 = 0.1862 loss)
I0829 11:35:26.199395 916722 sgd_solver.cpp:106] Iteration 132000, lr = 0.01
I0829 11:35:56.177976 916722 solver.cpp:218] Iteration 132500 (16.6786 iter/s, 29.9785s/500 iters), loss = 0.21455
I0829 11:35:56.178030 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.214551 (* 1 = 0.214551 loss)
I0829 11:35:56.178041 916722 sgd_solver.cpp:106] Iteration 132500, lr = 0.01
I0829 11:36:26.148216 916722 solver.cpp:218] Iteration 133000 (16.6833 iter/s, 29.9701s/500 iters), loss = 0.256732
I0829 11:36:26.148273 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.256732 (* 1 = 0.256732 loss)
I0829 11:36:26.148283 916722 sgd_solver.cpp:106] Iteration 133000, lr = 0.01
I0829 11:36:56.117707 916722 solver.cpp:218] Iteration 133500 (16.6837 iter/s, 29.9693s/500 iters), loss = 0.156522
I0829 11:36:56.117758 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.156523 (* 1 = 0.156523 loss)
I0829 11:36:56.117769 916722 sgd_solver.cpp:106] Iteration 133500, lr = 0.01
I0829 11:37:26.070132 916722 solver.cpp:218] Iteration 134000 (16.6932 iter/s, 29.9523s/500 iters), loss = 0.0938396
I0829 11:37:26.070194 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0938402 (* 1 = 0.0938402 loss)
I0829 11:37:26.070201 916722 sgd_solver.cpp:106] Iteration 134000, lr = 0.01
I0829 11:37:56.028781 916722 solver.cpp:218] Iteration 134500 (16.6898 iter/s, 29.9585s/500 iters), loss = 0.261518
I0829 11:37:56.028833 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.261519 (* 1 = 0.261519 loss)
I0829 11:37:56.028843 916722 sgd_solver.cpp:106] Iteration 134500, lr = 0.01
I0829 11:38:25.998965 916722 solver.cpp:218] Iteration 135000 (16.6833 iter/s, 29.97s/500 iters), loss = 0.356923
I0829 11:38:25.999025 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.356924 (* 1 = 0.356924 loss)
I0829 11:38:25.999034 916722 sgd_solver.cpp:106] Iteration 135000, lr = 0.01
I0829 11:38:55.936923 916722 solver.cpp:218] Iteration 135500 (16.7013 iter/s, 29.9378s/500 iters), loss = 0.397351
I0829 11:38:55.936975 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.397352 (* 1 = 0.397352 loss)
I0829 11:38:55.936985 916722 sgd_solver.cpp:106] Iteration 135500, lr = 0.01
I0829 11:39:25.879139 916722 solver.cpp:218] Iteration 136000 (16.6989 iter/s, 29.9421s/500 iters), loss = 0.253055
I0829 11:39:25.879209 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.253055 (* 1 = 0.253055 loss)
I0829 11:39:25.879222 916722 sgd_solver.cpp:106] Iteration 136000, lr = 0.01
I0829 11:39:55.827854 916722 solver.cpp:218] Iteration 136500 (16.6953 iter/s, 29.9486s/500 iters), loss = 0.256877
I0829 11:39:55.827906 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.256878 (* 1 = 0.256878 loss)
I0829 11:39:55.827915 916722 sgd_solver.cpp:106] Iteration 136500, lr = 0.01
I0829 11:40:25.785225 916722 solver.cpp:218] Iteration 137000 (16.6905 iter/s, 29.9572s/500 iters), loss = 0.356204
I0829 11:40:25.785291 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.356205 (* 1 = 0.356205 loss)
I0829 11:40:25.785300 916722 sgd_solver.cpp:106] Iteration 137000, lr = 0.01
I0829 11:40:55.713712 916722 solver.cpp:218] Iteration 137500 (16.7066 iter/s, 29.9283s/500 iters), loss = 0.341682
I0829 11:40:55.713759 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.341682 (* 1 = 0.341682 loss)
I0829 11:40:55.713768 916722 sgd_solver.cpp:106] Iteration 137500, lr = 0.01
I0829 11:41:25.664801 916722 solver.cpp:218] Iteration 138000 (16.694 iter/s, 29.951s/500 iters), loss = 0.127787
I0829 11:41:25.664862 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.127788 (* 1 = 0.127788 loss)
I0829 11:41:25.664871 916722 sgd_solver.cpp:106] Iteration 138000, lr = 0.01
I0829 11:41:55.597405 916722 solver.cpp:218] Iteration 138500 (16.7043 iter/s, 29.9324s/500 iters), loss = 0.308714
I0829 11:41:55.597456 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.308714 (* 1 = 0.308714 loss)
I0829 11:41:55.597465 916722 sgd_solver.cpp:106] Iteration 138500, lr = 0.01
I0829 11:42:25.519567 916722 solver.cpp:218] Iteration 139000 (16.7101 iter/s, 29.922s/500 iters), loss = 0.233415
I0829 11:42:25.519631 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.233416 (* 1 = 0.233416 loss)
I0829 11:42:25.519639 916722 sgd_solver.cpp:106] Iteration 139000, lr = 0.01
I0829 11:42:55.447916 916722 solver.cpp:218] Iteration 139500 (16.7067 iter/s, 29.9282s/500 iters), loss = 0.228506
I0829 11:42:55.447966 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.228507 (* 1 = 0.228507 loss)
I0829 11:42:55.447974 916722 sgd_solver.cpp:106] Iteration 139500, lr = 0.01
I0829 11:43:25.401790 916722 solver.cpp:218] Iteration 140000 (16.6924 iter/s, 29.9537s/500 iters), loss = 0.152639
I0829 11:43:25.401847 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.15264 (* 1 = 0.15264 loss)
I0829 11:43:25.401856 916722 sgd_solver.cpp:106] Iteration 140000, lr = 0.01
I0829 11:43:55.369544 916722 solver.cpp:218] Iteration 140500 (16.6847 iter/s, 29.9676s/500 iters), loss = 0.212257
I0829 11:43:55.369594 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.212258 (* 1 = 0.212258 loss)
I0829 11:43:55.369602 916722 sgd_solver.cpp:106] Iteration 140500, lr = 0.01
I0829 11:44:25.325165 916722 solver.cpp:218] Iteration 141000 (16.6914 iter/s, 29.9555s/500 iters), loss = 0.17903
I0829 11:44:25.325223 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.179031 (* 1 = 0.179031 loss)
I0829 11:44:25.325232 916722 sgd_solver.cpp:106] Iteration 141000, lr = 0.01
I0829 11:44:55.273687 916722 solver.cpp:218] Iteration 141500 (16.6954 iter/s, 29.9484s/500 iters), loss = 0.0950248
I0829 11:44:55.273741 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0950254 (* 1 = 0.0950254 loss)
I0829 11:44:55.273751 916722 sgd_solver.cpp:106] Iteration 141500, lr = 0.01
I0829 11:45:25.221120 916722 solver.cpp:218] Iteration 142000 (16.696 iter/s, 29.9473s/500 iters), loss = 0.304562
I0829 11:45:25.221180 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.304562 (* 1 = 0.304562 loss)
I0829 11:45:25.221189 916722 sgd_solver.cpp:106] Iteration 142000, lr = 0.01
I0829 11:45:55.161613 916722 solver.cpp:218] Iteration 142500 (16.6999 iter/s, 29.9404s/500 iters), loss = 0.241569
I0829 11:45:55.161666 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.24157 (* 1 = 0.24157 loss)
I0829 11:45:55.161676 916722 sgd_solver.cpp:106] Iteration 142500, lr = 0.01
I0829 11:46:25.113417 916722 solver.cpp:218] Iteration 143000 (16.6936 iter/s, 29.9517s/500 iters), loss = 0.152248
I0829 11:46:25.113488 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152249 (* 1 = 0.152249 loss)
I0829 11:46:25.113497 916722 sgd_solver.cpp:106] Iteration 143000, lr = 0.01
I0829 11:46:55.082048 916722 solver.cpp:218] Iteration 143500 (16.6842 iter/s, 29.9685s/500 iters), loss = 0.39238
I0829 11:46:55.082100 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.392381 (* 1 = 0.392381 loss)
I0829 11:46:55.082110 916722 sgd_solver.cpp:106] Iteration 143500, lr = 0.01
I0829 11:47:25.044651 916722 solver.cpp:218] Iteration 144000 (16.6875 iter/s, 29.9625s/500 iters), loss = 0.336635
I0829 11:47:25.044710 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.336635 (* 1 = 0.336635 loss)
I0829 11:47:25.044718 916722 sgd_solver.cpp:106] Iteration 144000, lr = 0.01
I0829 11:47:54.999116 916722 solver.cpp:218] Iteration 144500 (16.6921 iter/s, 29.9543s/500 iters), loss = 0.533271
I0829 11:47:54.999167 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.533272 (* 1 = 0.533272 loss)
I0829 11:47:54.999177 916722 sgd_solver.cpp:106] Iteration 144500, lr = 0.01
I0829 11:48:24.967159 916722 solver.cpp:218] Iteration 145000 (16.6845 iter/s, 29.9679s/500 iters), loss = 0.248709
I0829 11:48:24.967219 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.24871 (* 1 = 0.24871 loss)
I0829 11:48:24.967228 916722 sgd_solver.cpp:106] Iteration 145000, lr = 0.01
I0829 11:48:54.938163 916722 solver.cpp:218] Iteration 145500 (16.6829 iter/s, 29.9709s/500 iters), loss = 0.0805982
I0829 11:48:54.938215 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0805989 (* 1 = 0.0805989 loss)
I0829 11:48:54.938225 916722 sgd_solver.cpp:106] Iteration 145500, lr = 0.01
I0829 11:49:24.914140 916722 solver.cpp:218] Iteration 146000 (16.6801 iter/s, 29.9759s/500 iters), loss = 0.260853
I0829 11:49:24.914204 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.260853 (* 1 = 0.260853 loss)
I0829 11:49:24.914214 916722 sgd_solver.cpp:106] Iteration 146000, lr = 0.01
I0829 11:49:54.885497 916722 solver.cpp:218] Iteration 146500 (16.6827 iter/s, 29.9712s/500 iters), loss = 0.182083
I0829 11:49:54.885548 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.182084 (* 1 = 0.182084 loss)
I0829 11:49:54.885556 916722 sgd_solver.cpp:106] Iteration 146500, lr = 0.01
I0829 11:50:24.870507 916722 solver.cpp:218] Iteration 147000 (16.6751 iter/s, 29.9849s/500 iters), loss = 0.306235
I0829 11:50:24.870566 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.306236 (* 1 = 0.306236 loss)
I0829 11:50:24.870575 916722 sgd_solver.cpp:106] Iteration 147000, lr = 0.01
I0829 11:50:54.846976 916722 solver.cpp:218] Iteration 147500 (16.6798 iter/s, 29.9763s/500 iters), loss = 0.267601
I0829 11:50:54.847026 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.267601 (* 1 = 0.267601 loss)
I0829 11:50:54.847035 916722 sgd_solver.cpp:106] Iteration 147500, lr = 0.01
I0829 11:51:24.851821 916722 solver.cpp:218] Iteration 148000 (16.664 iter/s, 30.0047s/500 iters), loss = 0.266143
I0829 11:51:24.851881 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.266143 (* 1 = 0.266143 loss)
I0829 11:51:24.851891 916722 sgd_solver.cpp:106] Iteration 148000, lr = 0.01
I0829 11:51:54.803308 916722 solver.cpp:218] Iteration 148500 (16.6937 iter/s, 29.9514s/500 iters), loss = 0.130685
I0829 11:51:54.803357 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130685 (* 1 = 0.130685 loss)
I0829 11:51:54.803366 916722 sgd_solver.cpp:106] Iteration 148500, lr = 0.01
I0829 11:52:24.770301 916722 solver.cpp:218] Iteration 149000 (16.6851 iter/s, 29.9669s/500 iters), loss = 0.151009
I0829 11:52:24.770367 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.15101 (* 1 = 0.15101 loss)
I0829 11:52:24.770376 916722 sgd_solver.cpp:106] Iteration 149000, lr = 0.01
I0829 11:52:54.738678 916722 solver.cpp:218] Iteration 149500 (16.6843 iter/s, 29.9682s/500 iters), loss = 0.299627
I0829 11:52:54.738744 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.299627 (* 1 = 0.299627 loss)
I0829 11:52:54.738752 916722 sgd_solver.cpp:106] Iteration 149500, lr = 0.01
I0829 11:53:24.632359 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_150000.caffemodel
I0829 11:53:24.651490 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_150000.solverstate
I0829 11:53:24.657662 916722 solver.cpp:330] Iteration 150000, Testing net (#0)
I0829 11:53:40.085934 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8663
I0829 11:53:40.085978 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.425635 (* 1 = 0.425635 loss)
I0829 11:53:40.144812 916722 solver.cpp:218] Iteration 150000 (11.0118 iter/s, 45.406s/500 iters), loss = 0.190747
I0829 11:53:40.144840 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.190747 (* 1 = 0.190747 loss)
I0829 11:53:40.144850 916722 sgd_solver.cpp:106] Iteration 150000, lr = 0.01
I0829 11:54:09.984072 916722 solver.cpp:218] Iteration 150500 (16.7565 iter/s, 29.8391s/500 iters), loss = 0.346224
I0829 11:54:09.984133 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.346225 (* 1 = 0.346225 loss)
I0829 11:54:09.984141 916722 sgd_solver.cpp:106] Iteration 150500, lr = 0.01
I0829 11:54:39.907240 916722 solver.cpp:218] Iteration 151000 (16.7095 iter/s, 29.923s/500 iters), loss = 0.173389
I0829 11:54:39.907292 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.17339 (* 1 = 0.17339 loss)
I0829 11:54:39.907300 916722 sgd_solver.cpp:106] Iteration 151000, lr = 0.01
I0829 11:55:09.854001 916722 solver.cpp:218] Iteration 151500 (16.6964 iter/s, 29.9466s/500 iters), loss = 0.533799
I0829 11:55:09.854063 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.533799 (* 1 = 0.533799 loss)
I0829 11:55:09.854072 916722 sgd_solver.cpp:106] Iteration 151500, lr = 0.01
I0829 11:55:39.816113 916722 solver.cpp:218] Iteration 152000 (16.6878 iter/s, 29.962s/500 iters), loss = 0.0708264
I0829 11:55:39.816165 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0708266 (* 1 = 0.0708266 loss)
I0829 11:55:39.816174 916722 sgd_solver.cpp:106] Iteration 152000, lr = 0.01
I0829 11:56:09.771919 916722 solver.cpp:218] Iteration 152500 (16.6912 iter/s, 29.956s/500 iters), loss = 0.184868
I0829 11:56:09.771981 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.184869 (* 1 = 0.184869 loss)
I0829 11:56:09.771989 916722 sgd_solver.cpp:106] Iteration 152500, lr = 0.01
I0829 11:56:39.739692 916722 solver.cpp:218] Iteration 153000 (16.6843 iter/s, 29.9683s/500 iters), loss = 0.427644
I0829 11:56:39.739745 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.427644 (* 1 = 0.427644 loss)
I0829 11:56:39.739755 916722 sgd_solver.cpp:106] Iteration 153000, lr = 0.01
I0829 11:57:09.712210 916722 solver.cpp:218] Iteration 153500 (16.6817 iter/s, 29.973s/500 iters), loss = 0.104101
I0829 11:57:09.712268 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104101 (* 1 = 0.104101 loss)
I0829 11:57:09.712276 916722 sgd_solver.cpp:106] Iteration 153500, lr = 0.01
I0829 11:57:39.676995 916722 solver.cpp:218] Iteration 154000 (16.686 iter/s, 29.9652s/500 iters), loss = 0.104659
I0829 11:57:39.677047 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104659 (* 1 = 0.104659 loss)
I0829 11:57:39.677057 916722 sgd_solver.cpp:106] Iteration 154000, lr = 0.01
I0829 11:58:09.647089 916722 solver.cpp:218] Iteration 154500 (16.6831 iter/s, 29.9705s/500 iters), loss = 0.250035
I0829 11:58:09.647145 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.250035 (* 1 = 0.250035 loss)
I0829 11:58:09.647152 916722 sgd_solver.cpp:106] Iteration 154500, lr = 0.01
I0829 11:58:39.619803 916722 solver.cpp:218] Iteration 155000 (16.6816 iter/s, 29.9731s/500 iters), loss = 0.118533
I0829 11:58:39.619855 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.118533 (* 1 = 0.118533 loss)
I0829 11:58:39.619879 916722 sgd_solver.cpp:106] Iteration 155000, lr = 0.01
I0829 11:59:09.609053 916722 solver.cpp:218] Iteration 155500 (16.6724 iter/s, 29.9896s/500 iters), loss = 0.157079
I0829 11:59:09.609124 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.157079 (* 1 = 0.157079 loss)
I0829 11:59:09.609133 916722 sgd_solver.cpp:106] Iteration 155500, lr = 0.01
I0829 11:59:39.551205 916722 solver.cpp:218] Iteration 156000 (16.6987 iter/s, 29.9425s/500 iters), loss = 0.27345
I0829 11:59:39.551256 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.273451 (* 1 = 0.273451 loss)
I0829 11:59:39.551267 916722 sgd_solver.cpp:106] Iteration 156000, lr = 0.01
I0829 12:00:09.506498 916722 solver.cpp:218] Iteration 156500 (16.6914 iter/s, 29.9556s/500 iters), loss = 0.113383
I0829 12:00:09.506557 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.113384 (* 1 = 0.113384 loss)
I0829 12:00:09.506567 916722 sgd_solver.cpp:106] Iteration 156500, lr = 0.01
I0829 12:00:39.482188 916722 solver.cpp:218] Iteration 157000 (16.68 iter/s, 29.976s/500 iters), loss = 0.0653006
I0829 12:00:39.482240 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0653013 (* 1 = 0.0653013 loss)
I0829 12:00:39.482250 916722 sgd_solver.cpp:106] Iteration 157000, lr = 0.01
I0829 12:01:09.480356 916722 solver.cpp:218] Iteration 157500 (16.6675 iter/s, 29.9985s/500 iters), loss = 0.171219
I0829 12:01:09.480422 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.17122 (* 1 = 0.17122 loss)
I0829 12:01:09.480437 916722 sgd_solver.cpp:106] Iteration 157500, lr = 0.01
I0829 12:01:39.450668 916722 solver.cpp:218] Iteration 158000 (16.683 iter/s, 29.9706s/500 iters), loss = 0.32784
I0829 12:01:39.450719 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.32784 (* 1 = 0.32784 loss)
I0829 12:01:39.450728 916722 sgd_solver.cpp:106] Iteration 158000, lr = 0.01
I0829 12:02:09.424499 916722 solver.cpp:218] Iteration 158500 (16.6811 iter/s, 29.9741s/500 iters), loss = 0.204122
I0829 12:02:09.424559 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.204123 (* 1 = 0.204123 loss)
I0829 12:02:09.424567 916722 sgd_solver.cpp:106] Iteration 158500, lr = 0.01
I0829 12:02:39.389724 916722 solver.cpp:218] Iteration 159000 (16.6859 iter/s, 29.9655s/500 iters), loss = 0.312605
I0829 12:02:39.389784 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.312605 (* 1 = 0.312605 loss)
I0829 12:02:39.389793 916722 sgd_solver.cpp:106] Iteration 159000, lr = 0.01
I0829 12:03:09.342811 916722 solver.cpp:218] Iteration 159500 (16.6926 iter/s, 29.9533s/500 iters), loss = 0.389866
I0829 12:03:09.342871 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.389867 (* 1 = 0.389867 loss)
I0829 12:03:09.342880 916722 sgd_solver.cpp:106] Iteration 159500, lr = 0.01
I0829 12:03:39.303426 916722 solver.cpp:218] Iteration 160000 (16.6885 iter/s, 29.9608s/500 iters), loss = 0.439966
I0829 12:03:39.303476 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.439967 (* 1 = 0.439967 loss)
I0829 12:03:39.303485 916722 sgd_solver.cpp:106] Iteration 160000, lr = 0.01
I0829 12:04:09.271481 916722 solver.cpp:218] Iteration 160500 (16.6843 iter/s, 29.9683s/500 iters), loss = 0.615974
I0829 12:04:09.271544 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.615975 (* 1 = 0.615975 loss)
I0829 12:04:09.271553 916722 sgd_solver.cpp:106] Iteration 160500, lr = 0.01
I0829 12:04:39.267071 916722 solver.cpp:218] Iteration 161000 (16.669 iter/s, 29.9958s/500 iters), loss = 0.128458
I0829 12:04:39.267122 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128459 (* 1 = 0.128459 loss)
I0829 12:04:39.267132 916722 sgd_solver.cpp:106] Iteration 161000, lr = 0.01
I0829 12:05:09.247220 916722 solver.cpp:218] Iteration 161500 (16.6776 iter/s, 29.9803s/500 iters), loss = 0.259425
I0829 12:05:09.247277 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.259425 (* 1 = 0.259425 loss)
I0829 12:05:09.247287 916722 sgd_solver.cpp:106] Iteration 161500, lr = 0.01
I0829 12:05:39.208622 916722 solver.cpp:218] Iteration 162000 (16.6881 iter/s, 29.9616s/500 iters), loss = 0.249919
I0829 12:05:39.208674 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.24992 (* 1 = 0.24992 loss)
I0829 12:05:39.208685 916722 sgd_solver.cpp:106] Iteration 162000, lr = 0.01
I0829 12:06:09.177440 916722 solver.cpp:218] Iteration 162500 (16.6839 iter/s, 29.969s/500 iters), loss = 0.248775
I0829 12:06:09.177508 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.248776 (* 1 = 0.248776 loss)
I0829 12:06:09.177517 916722 sgd_solver.cpp:106] Iteration 162500, lr = 0.01
I0829 12:06:39.167431 916722 solver.cpp:218] Iteration 163000 (16.6722 iter/s, 29.9901s/500 iters), loss = 0.0995859
I0829 12:06:39.167484 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0995868 (* 1 = 0.0995868 loss)
I0829 12:06:39.167493 916722 sgd_solver.cpp:106] Iteration 163000, lr = 0.01
I0829 12:07:09.121893 916722 solver.cpp:218] Iteration 163500 (16.6919 iter/s, 29.9546s/500 iters), loss = 0.295934
I0829 12:07:09.121951 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.295935 (* 1 = 0.295935 loss)
I0829 12:07:09.121960 916722 sgd_solver.cpp:106] Iteration 163500, lr = 0.01
I0829 12:07:39.102840 916722 solver.cpp:218] Iteration 164000 (16.6772 iter/s, 29.9811s/500 iters), loss = 0.133936
I0829 12:07:39.102892 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133937 (* 1 = 0.133937 loss)
I0829 12:07:39.102901 916722 sgd_solver.cpp:106] Iteration 164000, lr = 0.01
I0829 12:08:09.067476 916722 solver.cpp:218] Iteration 164500 (16.6863 iter/s, 29.9647s/500 iters), loss = 0.0698902
I0829 12:08:09.067535 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0698915 (* 1 = 0.0698915 loss)
I0829 12:08:09.067543 916722 sgd_solver.cpp:106] Iteration 164500, lr = 0.01
I0829 12:08:39.046464 916722 solver.cpp:218] Iteration 165000 (16.6783 iter/s, 29.9791s/500 iters), loss = 0.135427
I0829 12:08:39.046517 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.135428 (* 1 = 0.135428 loss)
I0829 12:08:39.046527 916722 sgd_solver.cpp:106] Iteration 165000, lr = 0.01
I0829 12:09:09.039367 916722 solver.cpp:218] Iteration 165500 (16.6706 iter/s, 29.993s/500 iters), loss = 0.402034
I0829 12:09:09.039423 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.402035 (* 1 = 0.402035 loss)
I0829 12:09:09.039433 916722 sgd_solver.cpp:106] Iteration 165500, lr = 0.01
I0829 12:09:39.034137 916722 solver.cpp:218] Iteration 166000 (16.6695 iter/s, 29.9949s/500 iters), loss = 0.248619
I0829 12:09:39.034190 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.248621 (* 1 = 0.248621 loss)
I0829 12:09:39.034200 916722 sgd_solver.cpp:106] Iteration 166000, lr = 0.01
I0829 12:10:09.014780 916722 solver.cpp:218] Iteration 166500 (16.6774 iter/s, 29.9807s/500 iters), loss = 0.389248
I0829 12:10:09.014839 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.389249 (* 1 = 0.389249 loss)
I0829 12:10:09.014847 916722 sgd_solver.cpp:106] Iteration 166500, lr = 0.01
I0829 12:10:38.982403 916722 solver.cpp:218] Iteration 167000 (16.6846 iter/s, 29.9677s/500 iters), loss = 0.117997
I0829 12:10:38.982455 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.117998 (* 1 = 0.117998 loss)
I0829 12:10:38.982463 916722 sgd_solver.cpp:106] Iteration 167000, lr = 0.01
I0829 12:11:08.962958 916722 solver.cpp:218] Iteration 167500 (16.6774 iter/s, 29.9806s/500 iters), loss = 0.406735
I0829 12:11:08.963019 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.406736 (* 1 = 0.406736 loss)
I0829 12:11:08.963027 916722 sgd_solver.cpp:106] Iteration 167500, lr = 0.01
I0829 12:11:38.952862 916722 solver.cpp:218] Iteration 168000 (16.6722 iter/s, 29.99s/500 iters), loss = 0.355749
I0829 12:11:38.952912 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.355751 (* 1 = 0.355751 loss)
I0829 12:11:38.952921 916722 sgd_solver.cpp:106] Iteration 168000, lr = 0.01
I0829 12:12:08.931845 916722 solver.cpp:218] Iteration 168500 (16.6783 iter/s, 29.979s/500 iters), loss = 0.272028
I0829 12:12:08.931921 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.272029 (* 1 = 0.272029 loss)
I0829 12:12:08.931928 916722 sgd_solver.cpp:106] Iteration 168500, lr = 0.01
I0829 12:12:38.923516 916722 solver.cpp:218] Iteration 169000 (16.6713 iter/s, 29.9917s/500 iters), loss = 0.186522
I0829 12:12:38.923568 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.186524 (* 1 = 0.186524 loss)
I0829 12:12:38.923576 916722 sgd_solver.cpp:106] Iteration 169000, lr = 0.01
I0829 12:13:08.897527 916722 solver.cpp:218] Iteration 169500 (16.6811 iter/s, 29.9741s/500 iters), loss = 0.119238
I0829 12:13:08.897589 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.119239 (* 1 = 0.119239 loss)
I0829 12:13:08.897598 916722 sgd_solver.cpp:106] Iteration 169500, lr = 0.01
I0829 12:13:38.900688 916722 solver.cpp:218] Iteration 170000 (16.6649 iter/s, 30.0032s/500 iters), loss = 0.251243
I0829 12:13:38.900748 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.251245 (* 1 = 0.251245 loss)
I0829 12:13:38.900755 916722 sgd_solver.cpp:106] Iteration 170000, lr = 0.01
I0829 12:14:08.868685 916722 solver.cpp:218] Iteration 170500 (16.6844 iter/s, 29.968s/500 iters), loss = 0.175342
I0829 12:14:08.868739 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.175344 (* 1 = 0.175344 loss)
I0829 12:14:08.868749 916722 sgd_solver.cpp:106] Iteration 170500, lr = 0.01
I0829 12:14:38.866065 916722 solver.cpp:218] Iteration 171000 (16.6681 iter/s, 29.9974s/500 iters), loss = 0.30428
I0829 12:14:38.866124 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.304282 (* 1 = 0.304282 loss)
I0829 12:14:38.866133 916722 sgd_solver.cpp:106] Iteration 171000, lr = 0.01
I0829 12:15:08.851485 916722 solver.cpp:218] Iteration 171500 (16.6748 iter/s, 29.9854s/500 iters), loss = 0.44911
I0829 12:15:08.851538 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.449112 (* 1 = 0.449112 loss)
I0829 12:15:08.851547 916722 sgd_solver.cpp:106] Iteration 171500, lr = 0.01
I0829 12:15:38.836087 916722 solver.cpp:218] Iteration 172000 (16.6752 iter/s, 29.9846s/500 iters), loss = 0.17609
I0829 12:15:38.836154 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.176092 (* 1 = 0.176092 loss)
I0829 12:15:38.836163 916722 sgd_solver.cpp:106] Iteration 172000, lr = 0.01
I0829 12:16:08.830745 916722 solver.cpp:218] Iteration 172500 (16.6696 iter/s, 29.9947s/500 iters), loss = 0.302877
I0829 12:16:08.830798 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.302878 (* 1 = 0.302878 loss)
I0829 12:16:08.830807 916722 sgd_solver.cpp:106] Iteration 172500, lr = 0.01
I0829 12:16:38.806910 916722 solver.cpp:218] Iteration 173000 (16.6799 iter/s, 29.9762s/500 iters), loss = 0.262491
I0829 12:16:38.806967 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.262492 (* 1 = 0.262492 loss)
I0829 12:16:38.806975 916722 sgd_solver.cpp:106] Iteration 173000, lr = 0.01
I0829 12:17:08.799269 916722 solver.cpp:218] Iteration 173500 (16.6709 iter/s, 29.9924s/500 iters), loss = 0.0906217
I0829 12:17:08.799324 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0906234 (* 1 = 0.0906234 loss)
I0829 12:17:08.799332 916722 sgd_solver.cpp:106] Iteration 173500, lr = 0.01
I0829 12:17:38.876152 916722 solver.cpp:218] Iteration 174000 (16.6241 iter/s, 30.0769s/500 iters), loss = 0.172797
I0829 12:17:38.876219 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.172798 (* 1 = 0.172798 loss)
I0829 12:17:38.876226 916722 sgd_solver.cpp:106] Iteration 174000, lr = 0.01
I0829 12:18:08.970655 916722 solver.cpp:218] Iteration 174500 (16.6143 iter/s, 30.0945s/500 iters), loss = 0.572749
I0829 12:18:08.970714 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.572751 (* 1 = 0.572751 loss)
I0829 12:18:08.970723 916722 sgd_solver.cpp:106] Iteration 174500, lr = 0.01
I0829 12:18:39.047466 916722 solver.cpp:218] Iteration 175000 (16.6241 iter/s, 30.0768s/500 iters), loss = 0.411796
I0829 12:18:39.047544 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.411798 (* 1 = 0.411798 loss)
I0829 12:18:39.047552 916722 sgd_solver.cpp:106] Iteration 175000, lr = 0.01
I0829 12:19:09.132032 916722 solver.cpp:218] Iteration 175500 (16.6198 iter/s, 30.0845s/500 iters), loss = 0.122948
I0829 12:19:09.132091 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.122949 (* 1 = 0.122949 loss)
I0829 12:19:09.132100 916722 sgd_solver.cpp:106] Iteration 175500, lr = 0.01
I0829 12:19:39.222314 916722 solver.cpp:218] Iteration 176000 (16.6167 iter/s, 30.0903s/500 iters), loss = 0.160315
I0829 12:19:39.222373 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.160317 (* 1 = 0.160317 loss)
I0829 12:19:39.222381 916722 sgd_solver.cpp:106] Iteration 176000, lr = 0.01
I0829 12:20:09.310238 916722 solver.cpp:218] Iteration 176500 (16.618 iter/s, 30.0879s/500 iters), loss = 0.323788
I0829 12:20:09.310297 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.323789 (* 1 = 0.323789 loss)
I0829 12:20:09.310307 916722 sgd_solver.cpp:106] Iteration 176500, lr = 0.01
I0829 12:20:39.382560 916722 solver.cpp:218] Iteration 177000 (16.6266 iter/s, 30.0723s/500 iters), loss = 0.172624
I0829 12:20:39.382617 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.172626 (* 1 = 0.172626 loss)
I0829 12:20:39.382627 916722 sgd_solver.cpp:106] Iteration 177000, lr = 0.01
I0829 12:21:09.443306 916722 solver.cpp:218] Iteration 177500 (16.633 iter/s, 30.0607s/500 iters), loss = 0.307431
I0829 12:21:09.443367 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.307433 (* 1 = 0.307433 loss)
I0829 12:21:09.443377 916722 sgd_solver.cpp:106] Iteration 177500, lr = 0.01
I0829 12:21:39.520467 916722 solver.cpp:218] Iteration 178000 (16.6239 iter/s, 30.0771s/500 iters), loss = 0.212598
I0829 12:21:39.520527 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.2126 (* 1 = 0.2126 loss)
I0829 12:21:39.520535 916722 sgd_solver.cpp:106] Iteration 178000, lr = 0.01
I0829 12:22:09.564033 916722 solver.cpp:218] Iteration 178500 (16.6425 iter/s, 30.0436s/500 iters), loss = 0.340532
I0829 12:22:09.564091 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.340533 (* 1 = 0.340533 loss)
I0829 12:22:09.564100 916722 sgd_solver.cpp:106] Iteration 178500, lr = 0.01
I0829 12:22:39.630208 916722 solver.cpp:218] Iteration 179000 (16.63 iter/s, 30.0662s/500 iters), loss = 0.218854
I0829 12:22:39.630268 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.218855 (* 1 = 0.218855 loss)
I0829 12:22:39.630276 916722 sgd_solver.cpp:106] Iteration 179000, lr = 0.01
I0829 12:23:09.722599 916722 solver.cpp:218] Iteration 179500 (16.6155 iter/s, 30.0924s/500 iters), loss = 0.17843
I0829 12:23:09.722656 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.178432 (* 1 = 0.178432 loss)
I0829 12:23:09.722666 916722 sgd_solver.cpp:106] Iteration 179500, lr = 0.01
I0829 12:23:39.826797 916722 solver.cpp:218] Iteration 180000 (16.609 iter/s, 30.1042s/500 iters), loss = 0.127728
I0829 12:23:39.826853 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.12773 (* 1 = 0.12773 loss)
I0829 12:23:39.826862 916722 sgd_solver.cpp:106] Iteration 180000, lr = 0.01
I0829 12:24:09.932739 916722 solver.cpp:218] Iteration 180500 (16.608 iter/s, 30.1059s/500 iters), loss = 0.239135
I0829 12:24:09.932793 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.239137 (* 1 = 0.239137 loss)
I0829 12:24:09.932801 916722 sgd_solver.cpp:106] Iteration 180500, lr = 0.01
I0829 12:24:40.013824 916722 solver.cpp:218] Iteration 181000 (16.6217 iter/s, 30.0811s/500 iters), loss = 0.111638
I0829 12:24:40.013885 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.11164 (* 1 = 0.11164 loss)
I0829 12:24:40.013893 916722 sgd_solver.cpp:106] Iteration 181000, lr = 0.01
I0829 12:25:10.114418 916722 solver.cpp:218] Iteration 181500 (16.611 iter/s, 30.1006s/500 iters), loss = 0.0566608
I0829 12:25:10.114490 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0566626 (* 1 = 0.0566626 loss)
I0829 12:25:10.114501 916722 sgd_solver.cpp:106] Iteration 181500, lr = 0.01
I0829 12:25:40.199937 916722 solver.cpp:218] Iteration 182000 (16.6193 iter/s, 30.0855s/500 iters), loss = 0.507289
I0829 12:25:40.199996 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.507291 (* 1 = 0.507291 loss)
I0829 12:25:40.200004 916722 sgd_solver.cpp:106] Iteration 182000, lr = 0.01
I0829 12:26:10.267280 916722 solver.cpp:218] Iteration 182500 (16.6294 iter/s, 30.0673s/500 iters), loss = 0.251945
I0829 12:26:10.267338 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.251947 (* 1 = 0.251947 loss)
I0829 12:26:10.267346 916722 sgd_solver.cpp:106] Iteration 182500, lr = 0.01
I0829 12:26:40.358606 916722 solver.cpp:218] Iteration 183000 (16.6161 iter/s, 30.0913s/500 iters), loss = 0.0737605
I0829 12:26:40.358666 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0737626 (* 1 = 0.0737626 loss)
I0829 12:26:40.358675 916722 sgd_solver.cpp:106] Iteration 183000, lr = 0.01
I0829 12:27:10.475615 916722 solver.cpp:218] Iteration 183500 (16.6019 iter/s, 30.117s/500 iters), loss = 0.377958
I0829 12:27:10.475673 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.37796 (* 1 = 0.37796 loss)
I0829 12:27:10.475682 916722 sgd_solver.cpp:106] Iteration 183500, lr = 0.01
I0829 12:27:40.565789 916722 solver.cpp:218] Iteration 184000 (16.6167 iter/s, 30.0902s/500 iters), loss = 0.245819
I0829 12:27:40.565847 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.245821 (* 1 = 0.245821 loss)
I0829 12:27:40.565856 916722 sgd_solver.cpp:106] Iteration 184000, lr = 0.01
I0829 12:28:10.711594 916722 solver.cpp:218] Iteration 184500 (16.5861 iter/s, 30.1458s/500 iters), loss = 0.168318
I0829 12:28:10.711658 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.16832 (* 1 = 0.16832 loss)
I0829 12:28:10.711666 916722 sgd_solver.cpp:106] Iteration 184500, lr = 0.01
I0829 12:28:40.802481 916722 solver.cpp:218] Iteration 185000 (16.6163 iter/s, 30.0909s/500 iters), loss = 0.493304
I0829 12:28:40.802541 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.493306 (* 1 = 0.493306 loss)
I0829 12:28:40.802548 916722 sgd_solver.cpp:106] Iteration 185000, lr = 0.01
I0829 12:29:10.918418 916722 solver.cpp:218] Iteration 185500 (16.6025 iter/s, 30.1159s/500 iters), loss = 0.0922612
I0829 12:29:10.918478 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0922633 (* 1 = 0.0922633 loss)
I0829 12:29:10.918486 916722 sgd_solver.cpp:106] Iteration 185500, lr = 0.01
I0829 12:29:41.019821 916722 solver.cpp:218] Iteration 186000 (16.6105 iter/s, 30.1014s/500 iters), loss = 0.0438731
I0829 12:29:41.019879 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.043875 (* 1 = 0.043875 loss)
I0829 12:29:41.019888 916722 sgd_solver.cpp:106] Iteration 186000, lr = 0.01
I0829 12:30:11.099090 916722 solver.cpp:218] Iteration 186500 (16.6228 iter/s, 30.0792s/500 iters), loss = 0.211889
I0829 12:30:11.099150 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.211891 (* 1 = 0.211891 loss)
I0829 12:30:11.099159 916722 sgd_solver.cpp:106] Iteration 186500, lr = 0.01
I0829 12:30:41.169358 916722 solver.cpp:218] Iteration 187000 (16.6279 iter/s, 30.07s/500 iters), loss = 0.139838
I0829 12:30:41.169410 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13984 (* 1 = 0.13984 loss)
I0829 12:30:41.169420 916722 sgd_solver.cpp:106] Iteration 187000, lr = 0.01
I0829 12:31:11.249344 916722 solver.cpp:218] Iteration 187500 (16.6225 iter/s, 30.0797s/500 iters), loss = 0.192958
I0829 12:31:11.249404 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.19296 (* 1 = 0.19296 loss)
I0829 12:31:11.249413 916722 sgd_solver.cpp:106] Iteration 187500, lr = 0.01
I0829 12:31:41.341356 916722 solver.cpp:218] Iteration 188000 (16.6159 iter/s, 30.0917s/500 iters), loss = 0.0474549
I0829 12:31:41.341408 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0474566 (* 1 = 0.0474566 loss)
I0829 12:31:41.341416 916722 sgd_solver.cpp:106] Iteration 188000, lr = 0.01
I0829 12:32:11.440582 916722 solver.cpp:218] Iteration 188500 (16.6119 iter/s, 30.099s/500 iters), loss = 0.268918
I0829 12:32:11.440654 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.26892 (* 1 = 0.26892 loss)
I0829 12:32:11.440662 916722 sgd_solver.cpp:106] Iteration 188500, lr = 0.01
I0829 12:32:41.544643 916722 solver.cpp:218] Iteration 189000 (16.6092 iter/s, 30.1038s/500 iters), loss = 0.281643
I0829 12:32:41.544703 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.281645 (* 1 = 0.281645 loss)
I0829 12:32:41.544710 916722 sgd_solver.cpp:106] Iteration 189000, lr = 0.01
I0829 12:33:11.644186 916722 solver.cpp:218] Iteration 189500 (16.6117 iter/s, 30.0993s/500 iters), loss = 0.288564
I0829 12:33:11.644248 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.288566 (* 1 = 0.288566 loss)
I0829 12:33:11.644258 916722 sgd_solver.cpp:106] Iteration 189500, lr = 0.01
I0829 12:33:41.744760 916722 solver.cpp:218] Iteration 190000 (16.6111 iter/s, 30.1003s/500 iters), loss = 0.198963
I0829 12:33:41.744819 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.198965 (* 1 = 0.198965 loss)
I0829 12:33:41.744827 916722 sgd_solver.cpp:106] Iteration 190000, lr = 0.01
I0829 12:34:11.821980 916722 solver.cpp:218] Iteration 190500 (16.624 iter/s, 30.077s/500 iters), loss = 0.272164
I0829 12:34:11.822041 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.272166 (* 1 = 0.272166 loss)
I0829 12:34:11.822049 916722 sgd_solver.cpp:106] Iteration 190500, lr = 0.01
I0829 12:34:41.909950 916722 solver.cpp:218] Iteration 191000 (16.6181 iter/s, 30.0877s/500 iters), loss = 0.301109
I0829 12:34:41.910009 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.301111 (* 1 = 0.301111 loss)
I0829 12:34:41.910017 916722 sgd_solver.cpp:106] Iteration 191000, lr = 0.01
I0829 12:35:12.006603 916722 solver.cpp:218] Iteration 191500 (16.6133 iter/s, 30.0964s/500 iters), loss = 0.167702
I0829 12:35:12.006665 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.167704 (* 1 = 0.167704 loss)
I0829 12:35:12.006673 916722 sgd_solver.cpp:106] Iteration 191500, lr = 0.01
I0829 12:35:42.109091 916722 solver.cpp:218] Iteration 192000 (16.61 iter/s, 30.1023s/500 iters), loss = 0.250065
I0829 12:35:42.109148 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.250068 (* 1 = 0.250068 loss)
I0829 12:35:42.109158 916722 sgd_solver.cpp:106] Iteration 192000, lr = 0.01
I0829 12:36:12.199561 916722 solver.cpp:218] Iteration 192500 (16.6167 iter/s, 30.0903s/500 iters), loss = 0.204812
I0829 12:36:12.199621 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.204814 (* 1 = 0.204814 loss)
I0829 12:36:12.199630 916722 sgd_solver.cpp:106] Iteration 192500, lr = 0.01
I0829 12:36:42.296698 916722 solver.cpp:218] Iteration 193000 (16.613 iter/s, 30.097s/500 iters), loss = 0.0683453
I0829 12:36:42.296761 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0683472 (* 1 = 0.0683472 loss)
I0829 12:36:42.296772 916722 sgd_solver.cpp:106] Iteration 193000, lr = 0.01
I0829 12:37:12.393815 916722 solver.cpp:218] Iteration 193500 (16.613 iter/s, 30.0969s/500 iters), loss = 0.180997
I0829 12:37:12.393872 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.180999 (* 1 = 0.180999 loss)
I0829 12:37:12.393880 916722 sgd_solver.cpp:106] Iteration 193500, lr = 0.01
I0829 12:37:42.494796 916722 solver.cpp:218] Iteration 194000 (16.6108 iter/s, 30.1008s/500 iters), loss = 0.490474
I0829 12:37:42.494858 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.490476 (* 1 = 0.490476 loss)
I0829 12:37:42.494866 916722 sgd_solver.cpp:106] Iteration 194000, lr = 0.01
I0829 12:38:12.588769 916722 solver.cpp:218] Iteration 194500 (16.6147 iter/s, 30.0938s/500 iters), loss = 0.11002
I0829 12:38:12.588826 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110022 (* 1 = 0.110022 loss)
I0829 12:38:12.588835 916722 sgd_solver.cpp:106] Iteration 194500, lr = 0.01
I0829 12:38:42.674822 916722 solver.cpp:218] Iteration 195000 (16.6191 iter/s, 30.0859s/500 iters), loss = 0.0940303
I0829 12:38:42.674896 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0940324 (* 1 = 0.0940324 loss)
I0829 12:38:42.674903 916722 sgd_solver.cpp:106] Iteration 195000, lr = 0.01
I0829 12:39:12.773552 916722 solver.cpp:218] Iteration 195500 (16.6121 iter/s, 30.0986s/500 iters), loss = 0.187795
I0829 12:39:12.773608 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.187797 (* 1 = 0.187797 loss)
I0829 12:39:12.773617 916722 sgd_solver.cpp:106] Iteration 195500, lr = 0.01
I0829 12:39:42.903975 916722 solver.cpp:218] Iteration 196000 (16.5946 iter/s, 30.1303s/500 iters), loss = 0.298467
I0829 12:39:42.904032 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.298469 (* 1 = 0.298469 loss)
I0829 12:39:42.904040 916722 sgd_solver.cpp:106] Iteration 196000, lr = 0.01
I0829 12:40:12.984639 916722 solver.cpp:218] Iteration 196500 (16.6221 iter/s, 30.0805s/500 iters), loss = 0.0879967
I0829 12:40:12.984699 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0879985 (* 1 = 0.0879985 loss)
I0829 12:40:12.984707 916722 sgd_solver.cpp:106] Iteration 196500, lr = 0.01
I0829 12:40:43.074822 916722 solver.cpp:218] Iteration 197000 (16.6168 iter/s, 30.09s/500 iters), loss = 0.342694
I0829 12:40:43.074882 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.342695 (* 1 = 0.342695 loss)
I0829 12:40:43.074889 916722 sgd_solver.cpp:106] Iteration 197000, lr = 0.01
I0829 12:41:13.177120 916722 solver.cpp:218] Iteration 197500 (16.6101 iter/s, 30.1022s/500 iters), loss = 0.241947
I0829 12:41:13.177178 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.241949 (* 1 = 0.241949 loss)
I0829 12:41:13.177187 916722 sgd_solver.cpp:106] Iteration 197500, lr = 0.01
I0829 12:41:43.269018 916722 solver.cpp:218] Iteration 198000 (16.6158 iter/s, 30.0918s/500 iters), loss = 0.142733
I0829 12:41:43.269078 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.142734 (* 1 = 0.142734 loss)
I0829 12:41:43.269086 916722 sgd_solver.cpp:106] Iteration 198000, lr = 0.01
I0829 12:42:13.354910 916722 solver.cpp:218] Iteration 198500 (16.6192 iter/s, 30.0858s/500 iters), loss = 0.339139
I0829 12:42:13.354967 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.339141 (* 1 = 0.339141 loss)
I0829 12:42:13.354975 916722 sgd_solver.cpp:106] Iteration 198500, lr = 0.01
I0829 12:42:43.434929 916722 solver.cpp:218] Iteration 199000 (16.6224 iter/s, 30.0799s/500 iters), loss = 0.0396123
I0829 12:42:43.434990 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.039614 (* 1 = 0.039614 loss)
I0829 12:42:43.434999 916722 sgd_solver.cpp:106] Iteration 199000, lr = 0.01
I0829 12:43:13.533371 916722 solver.cpp:218] Iteration 199500 (16.6122 iter/s, 30.0983s/500 iters), loss = 0.269667
I0829 12:43:13.533428 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.269669 (* 1 = 0.269669 loss)
I0829 12:43:13.533437 916722 sgd_solver.cpp:106] Iteration 199500, lr = 0.01
I0829 12:43:43.587532 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_200000.caffemodel
I0829 12:43:43.606668 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_200000.solverstate
I0829 12:43:43.612735 916722 solver.cpp:330] Iteration 200000, Testing net (#0)
I0829 12:43:59.048993 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8822
I0829 12:43:59.049041 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.376138 (* 1 = 0.376138 loss)
I0829 12:43:59.107728 916722 solver.cpp:218] Iteration 200000 (10.9711 iter/s, 45.5742s/500 iters), loss = 0.506128
I0829 12:43:59.107756 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.506129 (* 1 = 0.506129 loss)
I0829 12:43:59.107765 916722 sgd_solver.cpp:106] Iteration 200000, lr = 0.01
I0829 12:44:28.988008 916722 solver.cpp:218] Iteration 200500 (16.7335 iter/s, 29.8802s/500 iters), loss = 0.410122
I0829 12:44:28.988080 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.410123 (* 1 = 0.410123 loss)
I0829 12:44:28.988093 916722 sgd_solver.cpp:106] Iteration 200500, lr = 0.01
I0829 12:44:58.987730 916722 solver.cpp:218] Iteration 201000 (16.6669 iter/s, 29.9996s/500 iters), loss = 0.407462
I0829 12:44:58.987780 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.407464 (* 1 = 0.407464 loss)
I0829 12:44:58.987790 916722 sgd_solver.cpp:106] Iteration 201000, lr = 0.01
I0829 12:45:29.022598 916722 solver.cpp:218] Iteration 201500 (16.6474 iter/s, 30.0348s/500 iters), loss = 0.270022
I0829 12:45:29.022655 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.270024 (* 1 = 0.270024 loss)
I0829 12:45:29.022663 916722 sgd_solver.cpp:106] Iteration 201500, lr = 0.01
I0829 12:45:59.035192 916722 solver.cpp:218] Iteration 202000 (16.6597 iter/s, 30.0125s/500 iters), loss = 0.245887
I0829 12:45:59.035248 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.245888 (* 1 = 0.245888 loss)
I0829 12:45:59.035257 916722 sgd_solver.cpp:106] Iteration 202000, lr = 0.01
I0829 12:46:29.055588 916722 solver.cpp:218] Iteration 202500 (16.6554 iter/s, 30.0203s/500 iters), loss = 0.189082
I0829 12:46:29.055649 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.189084 (* 1 = 0.189084 loss)
I0829 12:46:29.055657 916722 sgd_solver.cpp:106] Iteration 202500, lr = 0.01
I0829 12:46:59.087983 916722 solver.cpp:218] Iteration 203000 (16.6487 iter/s, 30.0323s/500 iters), loss = 0.215221
I0829 12:46:59.088040 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.215223 (* 1 = 0.215223 loss)
I0829 12:46:59.088048 916722 sgd_solver.cpp:106] Iteration 203000, lr = 0.01
I0829 12:47:29.127943 916722 solver.cpp:218] Iteration 203500 (16.6446 iter/s, 30.0399s/500 iters), loss = 0.171337
I0829 12:47:29.128001 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.171339 (* 1 = 0.171339 loss)
I0829 12:47:29.128010 916722 sgd_solver.cpp:106] Iteration 203500, lr = 0.01
I0829 12:47:59.157490 916722 solver.cpp:218] Iteration 204000 (16.6503 iter/s, 30.0295s/500 iters), loss = 0.374164
I0829 12:47:59.157546 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.374166 (* 1 = 0.374166 loss)
I0829 12:47:59.157555 916722 sgd_solver.cpp:106] Iteration 204000, lr = 0.01
I0829 12:48:29.210418 916722 solver.cpp:218] Iteration 204500 (16.6374 iter/s, 30.0528s/500 iters), loss = 0.225677
I0829 12:48:29.210480 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.225679 (* 1 = 0.225679 loss)
I0829 12:48:29.210489 916722 sgd_solver.cpp:106] Iteration 204500, lr = 0.01
I0829 12:48:59.246609 916722 solver.cpp:218] Iteration 205000 (16.6466 iter/s, 30.0361s/500 iters), loss = 0.227509
I0829 12:48:59.246661 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.227511 (* 1 = 0.227511 loss)
I0829 12:48:59.246670 916722 sgd_solver.cpp:106] Iteration 205000, lr = 0.01
I0829 12:49:29.283259 916722 solver.cpp:218] Iteration 205500 (16.6464 iter/s, 30.0366s/500 iters), loss = 0.165018
I0829 12:49:29.283318 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.16502 (* 1 = 0.16502 loss)
I0829 12:49:29.283326 916722 sgd_solver.cpp:106] Iteration 205500, lr = 0.01
I0829 12:49:59.310636 916722 solver.cpp:218] Iteration 206000 (16.6515 iter/s, 30.0273s/500 iters), loss = 0.216064
I0829 12:49:59.310688 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.216066 (* 1 = 0.216066 loss)
I0829 12:49:59.310695 916722 sgd_solver.cpp:106] Iteration 206000, lr = 0.01
I0829 12:50:29.326205 916722 solver.cpp:218] Iteration 206500 (16.6581 iter/s, 30.0155s/500 iters), loss = 0.392906
I0829 12:50:29.326262 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.392908 (* 1 = 0.392908 loss)
I0829 12:50:29.326270 916722 sgd_solver.cpp:106] Iteration 206500, lr = 0.01
I0829 12:50:59.357287 916722 solver.cpp:218] Iteration 207000 (16.6495 iter/s, 30.031s/500 iters), loss = 0.197663
I0829 12:50:59.357345 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.197665 (* 1 = 0.197665 loss)
I0829 12:50:59.357353 916722 sgd_solver.cpp:106] Iteration 207000, lr = 0.01
I0829 12:51:29.400853 916722 solver.cpp:218] Iteration 207500 (16.6425 iter/s, 30.0435s/500 iters), loss = 0.0583028
I0829 12:51:29.400925 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0583049 (* 1 = 0.0583049 loss)
I0829 12:51:29.400934 916722 sgd_solver.cpp:106] Iteration 207500, lr = 0.01
I0829 12:51:59.436074 916722 solver.cpp:218] Iteration 208000 (16.6472 iter/s, 30.0351s/500 iters), loss = 0.334969
I0829 12:51:59.436131 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.334971 (* 1 = 0.334971 loss)
I0829 12:51:59.436141 916722 sgd_solver.cpp:106] Iteration 208000, lr = 0.01
I0829 12:52:29.474560 916722 solver.cpp:218] Iteration 208500 (16.6454 iter/s, 30.0384s/500 iters), loss = 0.283206
I0829 12:52:29.474622 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.283208 (* 1 = 0.283208 loss)
I0829 12:52:29.474632 916722 sgd_solver.cpp:106] Iteration 208500, lr = 0.01
I0829 12:52:59.512110 916722 solver.cpp:218] Iteration 209000 (16.6459 iter/s, 30.0375s/500 iters), loss = 0.110784
I0829 12:52:59.512171 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110786 (* 1 = 0.110786 loss)
I0829 12:52:59.512181 916722 sgd_solver.cpp:106] Iteration 209000, lr = 0.01
I0829 12:53:29.553772 916722 solver.cpp:218] Iteration 209500 (16.6436 iter/s, 30.0416s/500 iters), loss = 0.0648745
I0829 12:53:29.553829 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0648767 (* 1 = 0.0648767 loss)
I0829 12:53:29.553838 916722 sgd_solver.cpp:106] Iteration 209500, lr = 0.01
I0829 12:53:59.624290 916722 solver.cpp:218] Iteration 210000 (16.6276 iter/s, 30.0704s/500 iters), loss = 0.193204
I0829 12:53:59.624347 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.193206 (* 1 = 0.193206 loss)
I0829 12:53:59.624356 916722 sgd_solver.cpp:106] Iteration 210000, lr = 0.01
I0829 12:54:29.664710 916722 solver.cpp:218] Iteration 210500 (16.6443 iter/s, 30.0403s/500 iters), loss = 0.192728
I0829 12:54:29.664768 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.19273 (* 1 = 0.19273 loss)
I0829 12:54:29.664777 916722 sgd_solver.cpp:106] Iteration 210500, lr = 0.01
I0829 12:54:59.707654 916722 solver.cpp:218] Iteration 211000 (16.6429 iter/s, 30.0429s/500 iters), loss = 0.253124
I0829 12:54:59.707712 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.253126 (* 1 = 0.253126 loss)
I0829 12:54:59.707720 916722 sgd_solver.cpp:106] Iteration 211000, lr = 0.01
I0829 12:55:29.768018 916722 solver.cpp:218] Iteration 211500 (16.6332 iter/s, 30.0603s/500 iters), loss = 0.106953
I0829 12:55:29.768075 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.106955 (* 1 = 0.106955 loss)
I0829 12:55:29.768083 916722 sgd_solver.cpp:106] Iteration 211500, lr = 0.01
I0829 12:55:59.807020 916722 solver.cpp:218] Iteration 212000 (16.6451 iter/s, 30.0389s/500 iters), loss = 0.165548
I0829 12:55:59.807075 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.16555 (* 1 = 0.16555 loss)
I0829 12:55:59.807083 916722 sgd_solver.cpp:106] Iteration 212000, lr = 0.01
I0829 12:56:29.846427 916722 solver.cpp:218] Iteration 212500 (16.6448 iter/s, 30.0393s/500 iters), loss = 0.171274
I0829 12:56:29.846482 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.171276 (* 1 = 0.171276 loss)
I0829 12:56:29.846491 916722 sgd_solver.cpp:106] Iteration 212500, lr = 0.01
I0829 12:56:59.876629 916722 solver.cpp:218] Iteration 213000 (16.6499 iter/s, 30.0301s/500 iters), loss = 0.224089
I0829 12:56:59.876685 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.224092 (* 1 = 0.224092 loss)
I0829 12:56:59.876693 916722 sgd_solver.cpp:106] Iteration 213000, lr = 0.01
I0829 12:57:29.915848 916722 solver.cpp:218] Iteration 213500 (16.6449 iter/s, 30.0391s/500 iters), loss = 0.112449
I0829 12:57:29.915902 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112451 (* 1 = 0.112451 loss)
I0829 12:57:29.915910 916722 sgd_solver.cpp:106] Iteration 213500, lr = 0.01
I0829 12:57:59.973016 916722 solver.cpp:218] Iteration 214000 (16.635 iter/s, 30.0571s/500 iters), loss = 0.0558606
I0829 12:57:59.973086 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0558632 (* 1 = 0.0558632 loss)
I0829 12:57:59.973094 916722 sgd_solver.cpp:106] Iteration 214000, lr = 0.01
I0829 12:58:30.027283 916722 solver.cpp:218] Iteration 214500 (16.6366 iter/s, 30.0542s/500 iters), loss = 0.263815
I0829 12:58:30.027344 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.263818 (* 1 = 0.263818 loss)
I0829 12:58:30.027352 916722 sgd_solver.cpp:106] Iteration 214500, lr = 0.01
I0829 12:59:00.111318 916722 solver.cpp:218] Iteration 215000 (16.6201 iter/s, 30.084s/500 iters), loss = 0.0273207
I0829 12:59:00.111373 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0273232 (* 1 = 0.0273232 loss)
I0829 12:59:00.111382 916722 sgd_solver.cpp:106] Iteration 215000, lr = 0.01
I0829 12:59:30.162333 916722 solver.cpp:218] Iteration 215500 (16.6384 iter/s, 30.0509s/500 iters), loss = 0.263857
I0829 12:59:30.162393 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.263859 (* 1 = 0.263859 loss)
I0829 12:59:30.162401 916722 sgd_solver.cpp:106] Iteration 215500, lr = 0.01
I0829 13:00:00.204602 916722 solver.cpp:218] Iteration 216000 (16.6433 iter/s, 30.0422s/500 iters), loss = 0.109902
I0829 13:00:00.204658 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109905 (* 1 = 0.109905 loss)
I0829 13:00:00.204668 916722 sgd_solver.cpp:106] Iteration 216000, lr = 0.01
I0829 13:00:30.258883 916722 solver.cpp:218] Iteration 216500 (16.6366 iter/s, 30.0542s/500 iters), loss = 0.161457
I0829 13:00:30.258942 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.16146 (* 1 = 0.16146 loss)
I0829 13:00:30.258950 916722 sgd_solver.cpp:106] Iteration 216500, lr = 0.01
I0829 13:01:00.301311 916722 solver.cpp:218] Iteration 217000 (16.6432 iter/s, 30.0424s/500 iters), loss = 0.0822674
I0829 13:01:00.301367 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0822701 (* 1 = 0.0822701 loss)
I0829 13:01:00.301374 916722 sgd_solver.cpp:106] Iteration 217000, lr = 0.01
I0829 13:01:30.355330 916722 solver.cpp:218] Iteration 217500 (16.6367 iter/s, 30.0539s/500 iters), loss = 0.348834
I0829 13:01:30.355389 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.348837 (* 1 = 0.348837 loss)
I0829 13:01:30.355398 916722 sgd_solver.cpp:106] Iteration 217500, lr = 0.01
I0829 13:02:00.401273 916722 solver.cpp:218] Iteration 218000 (16.6412 iter/s, 30.0459s/500 iters), loss = 0.214716
I0829 13:02:00.401329 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.214719 (* 1 = 0.214719 loss)
I0829 13:02:00.401337 916722 sgd_solver.cpp:106] Iteration 218000, lr = 0.01
I0829 13:02:30.451505 916722 solver.cpp:218] Iteration 218500 (16.6388 iter/s, 30.0502s/500 iters), loss = 0.258612
I0829 13:02:30.451561 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.258614 (* 1 = 0.258614 loss)
I0829 13:02:30.451570 916722 sgd_solver.cpp:106] Iteration 218500, lr = 0.01
I0829 13:03:00.507373 916722 solver.cpp:218] Iteration 219000 (16.6357 iter/s, 30.0558s/500 iters), loss = 0.209391
I0829 13:03:00.507429 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.209394 (* 1 = 0.209394 loss)
I0829 13:03:00.507437 916722 sgd_solver.cpp:106] Iteration 219000, lr = 0.01
I0829 13:03:30.557749 916722 solver.cpp:218] Iteration 219500 (16.6388 iter/s, 30.0503s/500 iters), loss = 0.215266
I0829 13:03:30.557806 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.215269 (* 1 = 0.215269 loss)
I0829 13:03:30.557813 916722 sgd_solver.cpp:106] Iteration 219500, lr = 0.01
I0829 13:04:00.600950 916722 solver.cpp:218] Iteration 220000 (16.6427 iter/s, 30.0431s/500 iters), loss = 0.0915631
I0829 13:04:00.601006 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0915661 (* 1 = 0.0915661 loss)
I0829 13:04:00.601016 916722 sgd_solver.cpp:106] Iteration 220000, lr = 0.01
I0829 13:04:30.675616 916722 solver.cpp:218] Iteration 220500 (16.6255 iter/s, 30.0743s/500 iters), loss = 0.148488
I0829 13:04:30.675689 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.148491 (* 1 = 0.148491 loss)
I0829 13:04:30.675698 916722 sgd_solver.cpp:106] Iteration 220500, lr = 0.01
I0829 13:05:00.722043 916722 solver.cpp:218] Iteration 221000 (16.6413 iter/s, 30.0458s/500 iters), loss = 0.111496
I0829 13:05:00.722096 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111499 (* 1 = 0.111499 loss)
I0829 13:05:00.722105 916722 sgd_solver.cpp:106] Iteration 221000, lr = 0.01
I0829 13:05:30.764407 916722 solver.cpp:218] Iteration 221500 (16.6435 iter/s, 30.0418s/500 iters), loss = 0.407979
I0829 13:05:30.764468 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.407982 (* 1 = 0.407982 loss)
I0829 13:05:30.764477 916722 sgd_solver.cpp:106] Iteration 221500, lr = 0.01
I0829 13:06:00.808537 916722 solver.cpp:218] Iteration 222000 (16.6425 iter/s, 30.0436s/500 iters), loss = 0.274758
I0829 13:06:00.808593 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.274761 (* 1 = 0.274761 loss)
I0829 13:06:00.808601 916722 sgd_solver.cpp:106] Iteration 222000, lr = 0.01
I0829 13:06:30.861588 916722 solver.cpp:218] Iteration 222500 (16.6375 iter/s, 30.0525s/500 iters), loss = 0.211574
I0829 13:06:30.861644 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.211577 (* 1 = 0.211577 loss)
I0829 13:06:30.861654 916722 sgd_solver.cpp:106] Iteration 222500, lr = 0.01
I0829 13:07:00.929774 916722 solver.cpp:218] Iteration 223000 (16.6292 iter/s, 30.0677s/500 iters), loss = 0.122698
I0829 13:07:00.929833 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.122701 (* 1 = 0.122701 loss)
I0829 13:07:00.929841 916722 sgd_solver.cpp:106] Iteration 223000, lr = 0.01
I0829 13:07:30.984068 916722 solver.cpp:218] Iteration 223500 (16.6368 iter/s, 30.0538s/500 iters), loss = 0.0330951
I0829 13:07:30.984129 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0330982 (* 1 = 0.0330982 loss)
I0829 13:07:30.984138 916722 sgd_solver.cpp:106] Iteration 223500, lr = 0.01
I0829 13:08:01.068670 916722 solver.cpp:218] Iteration 224000 (16.6201 iter/s, 30.0841s/500 iters), loss = 0.351675
I0829 13:08:01.068725 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.351678 (* 1 = 0.351678 loss)
I0829 13:08:01.068734 916722 sgd_solver.cpp:106] Iteration 224000, lr = 0.01
I0829 13:08:31.112802 916722 solver.cpp:218] Iteration 224500 (16.6424 iter/s, 30.0437s/500 iters), loss = 0.224809
I0829 13:08:31.112856 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.224812 (* 1 = 0.224812 loss)
I0829 13:08:31.112864 916722 sgd_solver.cpp:106] Iteration 224500, lr = 0.01
I0829 13:09:01.183496 916722 solver.cpp:218] Iteration 225000 (16.6277 iter/s, 30.0703s/500 iters), loss = 0.0583608
I0829 13:09:01.183554 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0583637 (* 1 = 0.0583637 loss)
I0829 13:09:01.183562 916722 sgd_solver.cpp:106] Iteration 225000, lr = 0.01
I0829 13:09:31.226101 916722 solver.cpp:218] Iteration 225500 (16.6433 iter/s, 30.0422s/500 iters), loss = 0.169353
I0829 13:09:31.226156 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.169356 (* 1 = 0.169356 loss)
I0829 13:09:31.226164 916722 sgd_solver.cpp:106] Iteration 225500, lr = 0.01
I0829 13:10:01.268683 916722 solver.cpp:218] Iteration 226000 (16.6433 iter/s, 30.0422s/500 iters), loss = 0.133703
I0829 13:10:01.268743 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133706 (* 1 = 0.133706 loss)
I0829 13:10:01.268752 916722 sgd_solver.cpp:106] Iteration 226000, lr = 0.01
I0829 13:10:31.312005 916722 solver.cpp:218] Iteration 226500 (16.6429 iter/s, 30.0429s/500 iters), loss = 0.333203
I0829 13:10:31.312065 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.333206 (* 1 = 0.333206 loss)
I0829 13:10:31.312074 916722 sgd_solver.cpp:106] Iteration 226500, lr = 0.01
I0829 13:11:01.358076 916722 solver.cpp:218] Iteration 227000 (16.6413 iter/s, 30.0457s/500 iters), loss = 0.153142
I0829 13:11:01.358144 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.153145 (* 1 = 0.153145 loss)
I0829 13:11:01.358163 916722 sgd_solver.cpp:106] Iteration 227000, lr = 0.01
I0829 13:11:31.388998 916722 solver.cpp:218] Iteration 227500 (16.6497 iter/s, 30.0305s/500 iters), loss = 0.222002
I0829 13:11:31.389052 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.222006 (* 1 = 0.222006 loss)
I0829 13:11:31.389060 916722 sgd_solver.cpp:106] Iteration 227500, lr = 0.01
I0829 13:12:01.452244 916722 solver.cpp:218] Iteration 228000 (16.6318 iter/s, 30.0629s/500 iters), loss = 0.0875436
I0829 13:12:01.452301 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0875469 (* 1 = 0.0875469 loss)
I0829 13:12:01.452308 916722 sgd_solver.cpp:106] Iteration 228000, lr = 0.01
I0829 13:12:31.493459 916722 solver.cpp:218] Iteration 228500 (16.644 iter/s, 30.0409s/500 iters), loss = 0.241385
I0829 13:12:31.493515 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.241388 (* 1 = 0.241388 loss)
I0829 13:12:31.493522 916722 sgd_solver.cpp:106] Iteration 228500, lr = 0.01
I0829 13:13:01.537202 916722 solver.cpp:218] Iteration 229000 (16.6426 iter/s, 30.0434s/500 iters), loss = 0.320041
I0829 13:13:01.537258 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.320045 (* 1 = 0.320045 loss)
I0829 13:13:01.537266 916722 sgd_solver.cpp:106] Iteration 229000, lr = 0.01
I0829 13:13:31.594415 916722 solver.cpp:218] Iteration 229500 (16.6351 iter/s, 30.0569s/500 iters), loss = 0.107166
I0829 13:13:31.594470 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.10717 (* 1 = 0.10717 loss)
I0829 13:13:31.594480 916722 sgd_solver.cpp:106] Iteration 229500, lr = 0.01
I0829 13:14:01.655097 916722 solver.cpp:218] Iteration 230000 (16.6332 iter/s, 30.0604s/500 iters), loss = 0.171428
I0829 13:14:01.655153 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.171431 (* 1 = 0.171431 loss)
I0829 13:14:01.655162 916722 sgd_solver.cpp:106] Iteration 230000, lr = 0.01
I0829 13:14:31.700336 916722 solver.cpp:218] Iteration 230500 (16.6417 iter/s, 30.0449s/500 iters), loss = 0.18872
I0829 13:14:31.700392 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.188723 (* 1 = 0.188723 loss)
I0829 13:14:31.700400 916722 sgd_solver.cpp:106] Iteration 230500, lr = 0.01
I0829 13:15:01.749792 916722 solver.cpp:218] Iteration 231000 (16.6394 iter/s, 30.0492s/500 iters), loss = 0.227979
I0829 13:15:01.749858 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.227982 (* 1 = 0.227982 loss)
I0829 13:15:01.749867 916722 sgd_solver.cpp:106] Iteration 231000, lr = 0.01
I0829 13:15:31.805153 916722 solver.cpp:218] Iteration 231500 (16.6361 iter/s, 30.0551s/500 iters), loss = 0.186969
I0829 13:15:31.805207 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.186973 (* 1 = 0.186973 loss)
I0829 13:15:31.805215 916722 sgd_solver.cpp:106] Iteration 231500, lr = 0.01
I0829 13:16:01.889592 916722 solver.cpp:218] Iteration 232000 (16.62 iter/s, 30.0842s/500 iters), loss = 0.158844
I0829 13:16:01.889652 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.158847 (* 1 = 0.158847 loss)
I0829 13:16:01.889660 916722 sgd_solver.cpp:106] Iteration 232000, lr = 0.01
I0829 13:16:31.962277 916722 solver.cpp:218] Iteration 232500 (16.6265 iter/s, 30.0724s/500 iters), loss = 0.421027
I0829 13:16:31.962330 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.42103 (* 1 = 0.42103 loss)
I0829 13:16:31.962339 916722 sgd_solver.cpp:106] Iteration 232500, lr = 0.01
I0829 13:17:02.050457 916722 solver.cpp:218] Iteration 233000 (16.618 iter/s, 30.0879s/500 iters), loss = 0.173901
I0829 13:17:02.050511 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.173904 (* 1 = 0.173904 loss)
I0829 13:17:02.050519 916722 sgd_solver.cpp:106] Iteration 233000, lr = 0.01
I0829 13:17:32.119232 916722 solver.cpp:218] Iteration 233500 (16.6287 iter/s, 30.0685s/500 iters), loss = 0.101129
I0829 13:17:32.119290 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101133 (* 1 = 0.101133 loss)
I0829 13:17:32.119299 916722 sgd_solver.cpp:106] Iteration 233500, lr = 0.01
I0829 13:18:02.174497 916722 solver.cpp:218] Iteration 234000 (16.6362 iter/s, 30.055s/500 iters), loss = 0.178436
I0829 13:18:02.174564 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.17844 (* 1 = 0.17844 loss)
I0829 13:18:02.174573 916722 sgd_solver.cpp:106] Iteration 234000, lr = 0.01
I0829 13:18:32.214808 916722 solver.cpp:218] Iteration 234500 (16.6444 iter/s, 30.04s/500 iters), loss = 0.226835
I0829 13:18:32.214865 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.226838 (* 1 = 0.226838 loss)
I0829 13:18:32.214874 916722 sgd_solver.cpp:106] Iteration 234500, lr = 0.01
I0829 13:19:02.272397 916722 solver.cpp:218] Iteration 235000 (16.6349 iter/s, 30.0573s/500 iters), loss = 0.14721
I0829 13:19:02.272470 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.147213 (* 1 = 0.147213 loss)
I0829 13:19:02.272480 916722 sgd_solver.cpp:106] Iteration 235000, lr = 0.01
I0829 13:19:32.322672 916722 solver.cpp:218] Iteration 235500 (16.6389 iter/s, 30.05s/500 iters), loss = 0.169243
I0829 13:19:32.322726 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.169246 (* 1 = 0.169246 loss)
I0829 13:19:32.322734 916722 sgd_solver.cpp:106] Iteration 235500, lr = 0.01
I0829 13:20:02.371683 916722 solver.cpp:218] Iteration 236000 (16.6396 iter/s, 30.0488s/500 iters), loss = 0.35632
I0829 13:20:02.371740 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.356323 (* 1 = 0.356323 loss)
I0829 13:20:02.371749 916722 sgd_solver.cpp:106] Iteration 236000, lr = 0.01
I0829 13:20:32.400532 916722 solver.cpp:218] Iteration 236500 (16.6508 iter/s, 30.0286s/500 iters), loss = 0.140578
I0829 13:20:32.400590 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.14058 (* 1 = 0.14058 loss)
I0829 13:20:32.400599 916722 sgd_solver.cpp:106] Iteration 236500, lr = 0.01
I0829 13:21:02.452674 916722 solver.cpp:218] Iteration 237000 (16.6379 iter/s, 30.0519s/500 iters), loss = 0.426825
I0829 13:21:02.452731 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.426828 (* 1 = 0.426828 loss)
I0829 13:21:02.452739 916722 sgd_solver.cpp:106] Iteration 237000, lr = 0.01
I0829 13:21:32.505919 916722 solver.cpp:218] Iteration 237500 (16.6373 iter/s, 30.053s/500 iters), loss = 0.227346
I0829 13:21:32.505976 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.227348 (* 1 = 0.227348 loss)
I0829 13:21:32.505985 916722 sgd_solver.cpp:106] Iteration 237500, lr = 0.01
I0829 13:22:02.570726 916722 solver.cpp:218] Iteration 238000 (16.6309 iter/s, 30.0646s/500 iters), loss = 0.133354
I0829 13:22:02.570783 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133357 (* 1 = 0.133357 loss)
I0829 13:22:02.570792 916722 sgd_solver.cpp:106] Iteration 238000, lr = 0.01
I0829 13:22:32.665103 916722 solver.cpp:218] Iteration 238500 (16.6145 iter/s, 30.0942s/500 iters), loss = 0.145303
I0829 13:22:32.665161 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.145306 (* 1 = 0.145306 loss)
I0829 13:22:32.665169 916722 sgd_solver.cpp:106] Iteration 238500, lr = 0.01
I0829 13:23:02.752871 916722 solver.cpp:218] Iteration 239000 (16.6182 iter/s, 30.0876s/500 iters), loss = 0.103569
I0829 13:23:02.752928 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.103572 (* 1 = 0.103572 loss)
I0829 13:23:02.752936 916722 sgd_solver.cpp:106] Iteration 239000, lr = 0.01
I0829 13:23:32.853878 916722 solver.cpp:218] Iteration 239500 (16.6109 iter/s, 30.1008s/500 iters), loss = 0.252025
I0829 13:23:32.853929 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.252028 (* 1 = 0.252028 loss)
I0829 13:23:32.853937 916722 sgd_solver.cpp:106] Iteration 239500, lr = 0.01
I0829 13:24:02.956955 916722 solver.cpp:218] Iteration 240000 (16.6097 iter/s, 30.1029s/500 iters), loss = 0.288977
I0829 13:24:02.957012 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.28898 (* 1 = 0.28898 loss)
I0829 13:24:02.957020 916722 sgd_solver.cpp:106] Iteration 240000, lr = 0.01
I0829 13:24:33.072631 916722 solver.cpp:218] Iteration 240500 (16.6028 iter/s, 30.1155s/500 iters), loss = 0.0339734
I0829 13:24:33.072710 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0339761 (* 1 = 0.0339761 loss)
I0829 13:24:33.072718 916722 sgd_solver.cpp:106] Iteration 240500, lr = 0.01
I0829 13:25:03.186282 916722 solver.cpp:218] Iteration 241000 (16.6039 iter/s, 30.1134s/500 iters), loss = 0.145679
I0829 13:25:03.186339 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.145682 (* 1 = 0.145682 loss)
I0829 13:25:03.186347 916722 sgd_solver.cpp:106] Iteration 241000, lr = 0.01
I0829 13:25:33.313388 916722 solver.cpp:218] Iteration 241500 (16.5965 iter/s, 30.1269s/500 iters), loss = 0.277207
I0829 13:25:33.313444 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.27721 (* 1 = 0.27721 loss)
I0829 13:25:33.313452 916722 sgd_solver.cpp:106] Iteration 241500, lr = 0.01
I0829 13:26:03.402074 916722 solver.cpp:218] Iteration 242000 (16.6177 iter/s, 30.0885s/500 iters), loss = 0.13795
I0829 13:26:03.402130 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.137953 (* 1 = 0.137953 loss)
I0829 13:26:03.402138 916722 sgd_solver.cpp:106] Iteration 242000, lr = 0.01
I0829 13:26:33.498345 916722 solver.cpp:218] Iteration 242500 (16.6135 iter/s, 30.0961s/500 iters), loss = 0.298305
I0829 13:26:33.498401 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.298308 (* 1 = 0.298308 loss)
I0829 13:26:33.498409 916722 sgd_solver.cpp:106] Iteration 242500, lr = 0.01
I0829 13:27:03.585498 916722 solver.cpp:218] Iteration 243000 (16.6185 iter/s, 30.087s/500 iters), loss = 0.270902
I0829 13:27:03.585559 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.270905 (* 1 = 0.270905 loss)
I0829 13:27:03.585568 916722 sgd_solver.cpp:106] Iteration 243000, lr = 0.01
I0829 13:27:33.693369 916722 solver.cpp:218] Iteration 243500 (16.6071 iter/s, 30.1077s/500 iters), loss = 0.305598
I0829 13:27:33.693425 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.305602 (* 1 = 0.305602 loss)
I0829 13:27:33.693434 916722 sgd_solver.cpp:106] Iteration 243500, lr = 0.01
I0829 13:28:03.777626 916722 solver.cpp:218] Iteration 244000 (16.6201 iter/s, 30.0841s/500 iters), loss = 0.307022
I0829 13:28:03.777683 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.307025 (* 1 = 0.307025 loss)
I0829 13:28:03.777693 916722 sgd_solver.cpp:106] Iteration 244000, lr = 0.01
I0829 13:28:33.860150 916722 solver.cpp:218] Iteration 244500 (16.621 iter/s, 30.0823s/500 iters), loss = 0.25063
I0829 13:28:33.860205 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.250633 (* 1 = 0.250633 loss)
I0829 13:28:33.860213 916722 sgd_solver.cpp:106] Iteration 244500, lr = 0.01
I0829 13:29:03.972169 916722 solver.cpp:218] Iteration 245000 (16.6048 iter/s, 30.1118s/500 iters), loss = 0.23213
I0829 13:29:03.972225 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.232134 (* 1 = 0.232134 loss)
I0829 13:29:03.972234 916722 sgd_solver.cpp:106] Iteration 245000, lr = 0.01
I0829 13:29:34.078207 916722 solver.cpp:218] Iteration 245500 (16.6081 iter/s, 30.1059s/500 iters), loss = 0.118171
I0829 13:29:34.078263 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.118175 (* 1 = 0.118175 loss)
I0829 13:29:34.078271 916722 sgd_solver.cpp:106] Iteration 245500, lr = 0.01
I0829 13:30:04.190546 916722 solver.cpp:218] Iteration 246000 (16.6046 iter/s, 30.1122s/500 iters), loss = 0.232076
I0829 13:30:04.190604 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.23208 (* 1 = 0.23208 loss)
I0829 13:30:04.190613 916722 sgd_solver.cpp:106] Iteration 246000, lr = 0.01
I0829 13:30:34.290895 916722 solver.cpp:218] Iteration 246500 (16.6112 iter/s, 30.1002s/500 iters), loss = 0.130843
I0829 13:30:34.290951 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130847 (* 1 = 0.130847 loss)
I0829 13:30:34.290959 916722 sgd_solver.cpp:106] Iteration 246500, lr = 0.01
I0829 13:31:04.421890 916722 solver.cpp:218] Iteration 247000 (16.5943 iter/s, 30.1308s/500 iters), loss = 0.314237
I0829 13:31:04.421960 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.314241 (* 1 = 0.314241 loss)
I0829 13:31:04.421974 916722 sgd_solver.cpp:106] Iteration 247000, lr = 0.01
I0829 13:31:34.518548 916722 solver.cpp:218] Iteration 247500 (16.6132 iter/s, 30.0965s/500 iters), loss = 0.320696
I0829 13:31:34.518604 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.3207 (* 1 = 0.3207 loss)
I0829 13:31:34.518611 916722 sgd_solver.cpp:106] Iteration 247500, lr = 0.01
I0829 13:32:04.635015 916722 solver.cpp:218] Iteration 248000 (16.6023 iter/s, 30.1163s/500 iters), loss = 0.357336
I0829 13:32:04.635071 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.357339 (* 1 = 0.357339 loss)
I0829 13:32:04.635078 916722 sgd_solver.cpp:106] Iteration 248000, lr = 0.01
I0829 13:32:34.741183 916722 solver.cpp:218] Iteration 248500 (16.608 iter/s, 30.106s/500 iters), loss = 0.184743
I0829 13:32:34.741245 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.184747 (* 1 = 0.184747 loss)
I0829 13:32:34.741252 916722 sgd_solver.cpp:106] Iteration 248500, lr = 0.01
I0829 13:33:04.848477 916722 solver.cpp:218] Iteration 249000 (16.6074 iter/s, 30.1071s/500 iters), loss = 0.120395
I0829 13:33:04.848532 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.120399 (* 1 = 0.120399 loss)
I0829 13:33:04.848541 916722 sgd_solver.cpp:106] Iteration 249000, lr = 0.01
I0829 13:33:34.920320 916722 solver.cpp:218] Iteration 249500 (16.6269 iter/s, 30.0717s/500 iters), loss = 0.192428
I0829 13:33:34.920377 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.192432 (* 1 = 0.192432 loss)
I0829 13:33:34.920384 916722 sgd_solver.cpp:106] Iteration 249500, lr = 0.01
I0829 13:34:04.981353 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_250000.caffemodel
I0829 13:34:05.000478 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_250000.solverstate
I0829 13:34:05.006570 916722 solver.cpp:330] Iteration 250000, Testing net (#0)
I0829 13:34:20.465504 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8757
I0829 13:34:20.465554 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.406811 (* 1 = 0.406811 loss)
I0829 13:34:20.524312 916722 solver.cpp:218] Iteration 250000 (10.964 iter/s, 45.6038s/500 iters), loss = 0.14963
I0829 13:34:20.524340 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.149634 (* 1 = 0.149634 loss)
I0829 13:34:20.524348 916722 sgd_solver.cpp:106] Iteration 250000, lr = 0.01
I0829 13:34:50.461681 916722 solver.cpp:218] Iteration 250500 (16.7016 iter/s, 29.9372s/500 iters), loss = 0.151891
I0829 13:34:50.461740 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.151895 (* 1 = 0.151895 loss)
I0829 13:34:50.461748 916722 sgd_solver.cpp:106] Iteration 250500, lr = 0.01
I0829 13:35:20.500167 916722 solver.cpp:218] Iteration 251000 (16.6454 iter/s, 30.0383s/500 iters), loss = 0.222703
I0829 13:35:20.500227 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.222707 (* 1 = 0.222707 loss)
I0829 13:35:20.500236 916722 sgd_solver.cpp:106] Iteration 251000, lr = 0.01
I0829 13:35:50.580644 916722 solver.cpp:218] Iteration 251500 (16.6222 iter/s, 30.0803s/500 iters), loss = 0.160207
I0829 13:35:50.580704 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.160211 (* 1 = 0.160211 loss)
I0829 13:35:50.580713 916722 sgd_solver.cpp:106] Iteration 251500, lr = 0.01
I0829 13:36:20.693102 916722 solver.cpp:218] Iteration 252000 (16.6045 iter/s, 30.1123s/500 iters), loss = 0.0932812
I0829 13:36:20.693162 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0932854 (* 1 = 0.0932854 loss)
I0829 13:36:20.693171 916722 sgd_solver.cpp:106] Iteration 252000, lr = 0.01
I0829 13:36:50.786875 916722 solver.cpp:218] Iteration 252500 (16.6148 iter/s, 30.0936s/500 iters), loss = 0.21879
I0829 13:36:50.786934 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.218794 (* 1 = 0.218794 loss)
I0829 13:36:50.786943 916722 sgd_solver.cpp:106] Iteration 252500, lr = 0.01
I0829 13:37:20.901057 916722 solver.cpp:218] Iteration 253000 (16.6036 iter/s, 30.114s/500 iters), loss = 0.182113
I0829 13:37:20.901126 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.182118 (* 1 = 0.182118 loss)
I0829 13:37:20.901149 916722 sgd_solver.cpp:106] Iteration 253000, lr = 0.01
I0829 13:37:51.023455 916722 solver.cpp:218] Iteration 253500 (16.599 iter/s, 30.1222s/500 iters), loss = 0.20622
I0829 13:37:51.023515 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.206224 (* 1 = 0.206224 loss)
I0829 13:37:51.023523 916722 sgd_solver.cpp:106] Iteration 253500, lr = 0.01
I0829 13:38:21.121161 916722 solver.cpp:218] Iteration 254000 (16.6126 iter/s, 30.0976s/500 iters), loss = 0.0301996
I0829 13:38:21.121217 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0302037 (* 1 = 0.0302037 loss)
I0829 13:38:21.121227 916722 sgd_solver.cpp:106] Iteration 254000, lr = 0.01
I0829 13:38:51.242240 916722 solver.cpp:218] Iteration 254500 (16.6 iter/s, 30.1204s/500 iters), loss = 0.387996
I0829 13:38:51.242300 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.388 (* 1 = 0.388 loss)
I0829 13:38:51.242308 916722 sgd_solver.cpp:106] Iteration 254500, lr = 0.01
I0829 13:39:21.350173 916722 solver.cpp:218] Iteration 255000 (16.6073 iter/s, 30.1073s/500 iters), loss = 0.212054
I0829 13:39:21.350226 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.212058 (* 1 = 0.212058 loss)
I0829 13:39:21.350234 916722 sgd_solver.cpp:106] Iteration 255000, lr = 0.01
I0829 13:39:51.471797 916722 solver.cpp:218] Iteration 255500 (16.5997 iter/s, 30.121s/500 iters), loss = 0.121189
I0829 13:39:51.471855 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.121193 (* 1 = 0.121193 loss)
I0829 13:39:51.471863 916722 sgd_solver.cpp:106] Iteration 255500, lr = 0.01
I0829 13:40:21.582051 916722 solver.cpp:218] Iteration 256000 (16.606 iter/s, 30.1096s/500 iters), loss = 0.247596
I0829 13:40:21.582110 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.2476 (* 1 = 0.2476 loss)
I0829 13:40:21.582118 916722 sgd_solver.cpp:106] Iteration 256000, lr = 0.01
I0829 13:40:51.695327 916722 solver.cpp:218] Iteration 256500 (16.6043 iter/s, 30.1127s/500 iters), loss = 0.294564
I0829 13:40:51.695387 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.294568 (* 1 = 0.294568 loss)
I0829 13:40:51.695395 916722 sgd_solver.cpp:106] Iteration 256500, lr = 0.01
I0829 13:41:21.841135 916722 solver.cpp:218] Iteration 257000 (16.5864 iter/s, 30.1452s/500 iters), loss = 0.0841899
I0829 13:41:21.841193 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0841941 (* 1 = 0.0841941 loss)
I0829 13:41:21.841202 916722 sgd_solver.cpp:106] Iteration 257000, lr = 0.01
I0829 13:41:51.940598 916722 solver.cpp:218] Iteration 257500 (16.6119 iter/s, 30.0989s/500 iters), loss = 0.169683
I0829 13:41:51.940660 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.169687 (* 1 = 0.169687 loss)
I0829 13:41:51.940670 916722 sgd_solver.cpp:106] Iteration 257500, lr = 0.01
I0829 13:42:22.067472 916722 solver.cpp:218] Iteration 258000 (16.5968 iter/s, 30.1263s/500 iters), loss = 0.312249
I0829 13:42:22.067533 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.312254 (* 1 = 0.312254 loss)
I0829 13:42:22.067541 916722 sgd_solver.cpp:106] Iteration 258000, lr = 0.01
I0829 13:42:52.184149 916722 solver.cpp:218] Iteration 258500 (16.6024 iter/s, 30.1162s/500 iters), loss = 0.477198
I0829 13:42:52.184204 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.477203 (* 1 = 0.477203 loss)
I0829 13:42:52.184213 916722 sgd_solver.cpp:106] Iteration 258500, lr = 0.01
I0829 13:43:22.295287 916722 solver.cpp:218] Iteration 259000 (16.6054 iter/s, 30.1106s/500 iters), loss = 0.0982364
I0829 13:43:22.295349 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0982408 (* 1 = 0.0982408 loss)
I0829 13:43:22.295357 916722 sgd_solver.cpp:106] Iteration 259000, lr = 0.01
I0829 13:43:52.382735 916722 solver.cpp:218] Iteration 259500 (16.6185 iter/s, 30.087s/500 iters), loss = 0.109883
I0829 13:43:52.382808 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109887 (* 1 = 0.109887 loss)
I0829 13:43:52.382817 916722 sgd_solver.cpp:106] Iteration 259500, lr = 0.01
I0829 13:44:22.473290 916722 solver.cpp:218] Iteration 260000 (16.6168 iter/s, 30.0901s/500 iters), loss = 0.137004
I0829 13:44:22.473346 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.137008 (* 1 = 0.137008 loss)
I0829 13:44:22.473354 916722 sgd_solver.cpp:106] Iteration 260000, lr = 0.01
I0829 13:44:52.578943 916722 solver.cpp:218] Iteration 260500 (16.6084 iter/s, 30.1052s/500 iters), loss = 0.164623
I0829 13:44:52.579000 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.164627 (* 1 = 0.164627 loss)
I0829 13:44:52.579008 916722 sgd_solver.cpp:106] Iteration 260500, lr = 0.01
I0829 13:45:22.699827 916722 solver.cpp:218] Iteration 261000 (16.6 iter/s, 30.1205s/500 iters), loss = 0.303622
I0829 13:45:22.699888 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.303626 (* 1 = 0.303626 loss)
I0829 13:45:22.699898 916722 sgd_solver.cpp:106] Iteration 261000, lr = 0.01
I0829 13:45:52.813726 916722 solver.cpp:218] Iteration 261500 (16.6039 iter/s, 30.1135s/500 iters), loss = 0.154865
I0829 13:45:52.813784 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.154869 (* 1 = 0.154869 loss)
I0829 13:45:52.813793 916722 sgd_solver.cpp:106] Iteration 261500, lr = 0.01
I0829 13:46:22.949354 916722 solver.cpp:218] Iteration 262000 (16.5919 iter/s, 30.1352s/500 iters), loss = 0.0885414
I0829 13:46:22.949414 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0885456 (* 1 = 0.0885456 loss)
I0829 13:46:22.949424 916722 sgd_solver.cpp:106] Iteration 262000, lr = 0.01
I0829 13:46:53.068312 916722 solver.cpp:218] Iteration 262500 (16.6011 iter/s, 30.1186s/500 iters), loss = 0.374801
I0829 13:46:53.068368 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.374805 (* 1 = 0.374805 loss)
I0829 13:46:53.068377 916722 sgd_solver.cpp:106] Iteration 262500, lr = 0.01
I0829 13:47:23.198331 916722 solver.cpp:218] Iteration 263000 (16.595 iter/s, 30.1296s/500 iters), loss = 0.147149
I0829 13:47:23.198393 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.147154 (* 1 = 0.147154 loss)
I0829 13:47:23.198401 916722 sgd_solver.cpp:106] Iteration 263000, lr = 0.01
I0829 13:47:53.329202 916722 solver.cpp:218] Iteration 263500 (16.5945 iter/s, 30.1305s/500 iters), loss = 0.161684
I0829 13:47:53.329257 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.161688 (* 1 = 0.161688 loss)
I0829 13:47:53.329267 916722 sgd_solver.cpp:106] Iteration 263500, lr = 0.01
I0829 13:48:23.459762 916722 solver.cpp:218] Iteration 264000 (16.5947 iter/s, 30.1302s/500 iters), loss = 0.200341
I0829 13:48:23.459823 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.200345 (* 1 = 0.200345 loss)
I0829 13:48:23.459831 916722 sgd_solver.cpp:106] Iteration 264000, lr = 0.01
I0829 13:48:53.606920 916722 solver.cpp:218] Iteration 264500 (16.5855 iter/s, 30.1468s/500 iters), loss = 0.165609
I0829 13:48:53.606973 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.165614 (* 1 = 0.165614 loss)
I0829 13:48:53.606981 916722 sgd_solver.cpp:106] Iteration 264500, lr = 0.01
I0829 13:49:23.736479 916722 solver.cpp:218] Iteration 265000 (16.5952 iter/s, 30.1292s/500 iters), loss = 0.319877
I0829 13:49:23.736541 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.319882 (* 1 = 0.319882 loss)
I0829 13:49:23.736549 916722 sgd_solver.cpp:106] Iteration 265000, lr = 0.01
I0829 13:49:53.898244 916722 solver.cpp:218] Iteration 265500 (16.5775 iter/s, 30.1614s/500 iters), loss = 0.310298
I0829 13:49:53.898299 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.310303 (* 1 = 0.310303 loss)
I0829 13:49:53.898308 916722 sgd_solver.cpp:106] Iteration 265500, lr = 0.01
I0829 13:50:24.025409 916722 solver.cpp:218] Iteration 266000 (16.5965 iter/s, 30.1268s/500 iters), loss = 0.0454655
I0829 13:50:24.025481 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.04547 (* 1 = 0.04547 loss)
I0829 13:50:24.025494 916722 sgd_solver.cpp:106] Iteration 266000, lr = 0.01
I0829 13:50:54.163142 916722 solver.cpp:218] Iteration 266500 (16.5907 iter/s, 30.1374s/500 iters), loss = 0.156261
I0829 13:50:54.163200 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.156266 (* 1 = 0.156266 loss)
I0829 13:50:54.163208 916722 sgd_solver.cpp:106] Iteration 266500, lr = 0.01
I0829 13:51:24.287257 916722 solver.cpp:218] Iteration 267000 (16.5982 iter/s, 30.1238s/500 iters), loss = 0.174421
I0829 13:51:24.287317 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.174425 (* 1 = 0.174425 loss)
I0829 13:51:24.287324 916722 sgd_solver.cpp:106] Iteration 267000, lr = 0.01
I0829 13:51:54.415467 916722 solver.cpp:218] Iteration 267500 (16.5959 iter/s, 30.1279s/500 iters), loss = 0.0600649
I0829 13:51:54.415524 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0600694 (* 1 = 0.0600694 loss)
I0829 13:51:54.415534 916722 sgd_solver.cpp:106] Iteration 267500, lr = 0.01
I0829 13:52:24.537052 916722 solver.cpp:218] Iteration 268000 (16.5996 iter/s, 30.1213s/500 iters), loss = 0.0493373
I0829 13:52:24.537108 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0493417 (* 1 = 0.0493417 loss)
I0829 13:52:24.537117 916722 sgd_solver.cpp:106] Iteration 268000, lr = 0.01
I0829 13:52:54.672505 916722 solver.cpp:218] Iteration 268500 (16.5919 iter/s, 30.1352s/500 iters), loss = 0.244771
I0829 13:52:54.672565 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.244775 (* 1 = 0.244775 loss)
I0829 13:52:54.672574 916722 sgd_solver.cpp:106] Iteration 268500, lr = 0.01
I0829 13:53:24.838300 916722 solver.cpp:218] Iteration 269000 (16.5752 iter/s, 30.1655s/500 iters), loss = 0.401499
I0829 13:53:24.838359 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.401504 (* 1 = 0.401504 loss)
I0829 13:53:24.838368 916722 sgd_solver.cpp:106] Iteration 269000, lr = 0.01
I0829 13:53:54.982215 916722 solver.cpp:218] Iteration 269500 (16.5873 iter/s, 30.1436s/500 iters), loss = 0.150254
I0829 13:53:54.982272 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.150259 (* 1 = 0.150259 loss)
I0829 13:53:54.982281 916722 sgd_solver.cpp:106] Iteration 269500, lr = 0.01
I0829 13:54:25.128192 916722 solver.cpp:218] Iteration 270000 (16.5861 iter/s, 30.1457s/500 iters), loss = 0.276725
I0829 13:54:25.128250 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.276729 (* 1 = 0.276729 loss)
I0829 13:54:25.128259 916722 sgd_solver.cpp:106] Iteration 270000, lr = 0.01
I0829 13:54:55.287864 916722 solver.cpp:218] Iteration 270500 (16.5786 iter/s, 30.1594s/500 iters), loss = 0.095401
I0829 13:54:55.287922 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0954057 (* 1 = 0.0954057 loss)
I0829 13:54:55.287931 916722 sgd_solver.cpp:106] Iteration 270500, lr = 0.01
I0829 13:55:25.439365 916722 solver.cpp:218] Iteration 271000 (16.5831 iter/s, 30.1512s/500 iters), loss = 0.152221
I0829 13:55:25.439425 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152226 (* 1 = 0.152226 loss)
I0829 13:55:25.439435 916722 sgd_solver.cpp:106] Iteration 271000, lr = 0.01
I0829 13:55:55.601982 916722 solver.cpp:218] Iteration 271500 (16.577 iter/s, 30.1623s/500 iters), loss = 0.140433
I0829 13:55:55.602041 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.140438 (* 1 = 0.140438 loss)
I0829 13:55:55.602048 916722 sgd_solver.cpp:106] Iteration 271500, lr = 0.01
I0829 13:56:25.746400 916722 solver.cpp:218] Iteration 272000 (16.587 iter/s, 30.1441s/500 iters), loss = 0.137339
I0829 13:56:25.746460 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.137344 (* 1 = 0.137344 loss)
I0829 13:56:25.746469 916722 sgd_solver.cpp:106] Iteration 272000, lr = 0.01
I0829 13:56:55.905416 916722 solver.cpp:218] Iteration 272500 (16.5789 iter/s, 30.1588s/500 iters), loss = 0.429001
I0829 13:56:55.905485 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.429006 (* 1 = 0.429006 loss)
I0829 13:56:55.905501 916722 sgd_solver.cpp:106] Iteration 272500, lr = 0.01
I0829 13:57:26.050083 916722 solver.cpp:218] Iteration 273000 (16.5868 iter/s, 30.1444s/500 iters), loss = 0.160993
I0829 13:57:26.050143 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.160998 (* 1 = 0.160998 loss)
I0829 13:57:26.050153 916722 sgd_solver.cpp:106] Iteration 273000, lr = 0.01
I0829 13:57:56.208595 916722 solver.cpp:218] Iteration 273500 (16.5792 iter/s, 30.1582s/500 iters), loss = 0.275247
I0829 13:57:56.208652 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.275252 (* 1 = 0.275252 loss)
I0829 13:57:56.208662 916722 sgd_solver.cpp:106] Iteration 273500, lr = 0.01
I0829 13:58:26.353150 916722 solver.cpp:218] Iteration 274000 (16.5869 iter/s, 30.1443s/500 iters), loss = 0.11211
I0829 13:58:26.353209 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112115 (* 1 = 0.112115 loss)
I0829 13:58:26.353217 916722 sgd_solver.cpp:106] Iteration 274000, lr = 0.01
I0829 13:58:56.478261 916722 solver.cpp:218] Iteration 274500 (16.5976 iter/s, 30.1249s/500 iters), loss = 0.0545469
I0829 13:58:56.478317 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0545514 (* 1 = 0.0545514 loss)
I0829 13:58:56.478324 916722 sgd_solver.cpp:106] Iteration 274500, lr = 0.01
I0829 13:59:26.616978 916722 solver.cpp:218] Iteration 275000 (16.5901 iter/s, 30.1385s/500 iters), loss = 0.396118
I0829 13:59:26.617038 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.396122 (* 1 = 0.396122 loss)
I0829 13:59:26.617046 916722 sgd_solver.cpp:106] Iteration 275000, lr = 0.01
I0829 13:59:56.787520 916722 solver.cpp:218] Iteration 275500 (16.5726 iter/s, 30.1703s/500 iters), loss = 0.26767
I0829 13:59:56.787575 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.267674 (* 1 = 0.267674 loss)
I0829 13:59:56.787582 916722 sgd_solver.cpp:106] Iteration 275500, lr = 0.01
I0829 14:00:26.923488 916722 solver.cpp:218] Iteration 276000 (16.5916 iter/s, 30.1357s/500 iters), loss = 0.102177
I0829 14:00:26.923549 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.102181 (* 1 = 0.102181 loss)
I0829 14:00:26.923557 916722 sgd_solver.cpp:106] Iteration 276000, lr = 0.01
I0829 14:00:57.061388 916722 solver.cpp:218] Iteration 276500 (16.5905 iter/s, 30.1376s/500 iters), loss = 0.126868
I0829 14:00:57.061445 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.126872 (* 1 = 0.126872 loss)
I0829 14:00:57.061453 916722 sgd_solver.cpp:106] Iteration 276500, lr = 0.01
I0829 14:01:27.214490 916722 solver.cpp:218] Iteration 277000 (16.5822 iter/s, 30.1529s/500 iters), loss = 0.0320168
I0829 14:01:27.214551 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0320212 (* 1 = 0.0320212 loss)
I0829 14:01:27.214560 916722 sgd_solver.cpp:106] Iteration 277000, lr = 0.01
I0829 14:01:57.440340 916722 solver.cpp:218] Iteration 277500 (16.5423 iter/s, 30.2256s/500 iters), loss = 0.089542
I0829 14:01:57.440397 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0895465 (* 1 = 0.0895465 loss)
I0829 14:01:57.440405 916722 sgd_solver.cpp:106] Iteration 277500, lr = 0.01
I0829 14:02:27.671746 916722 solver.cpp:218] Iteration 278000 (16.5392 iter/s, 30.2312s/500 iters), loss = 0.128099
I0829 14:02:27.671806 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128103 (* 1 = 0.128103 loss)
I0829 14:02:27.671815 916722 sgd_solver.cpp:106] Iteration 278000, lr = 0.01
I0829 14:02:57.901912 916722 solver.cpp:218] Iteration 278500 (16.5399 iter/s, 30.2299s/500 iters), loss = 0.257935
I0829 14:02:57.901963 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.257939 (* 1 = 0.257939 loss)
I0829 14:02:57.901971 916722 sgd_solver.cpp:106] Iteration 278500, lr = 0.01
I0829 14:03:28.132267 916722 solver.cpp:218] Iteration 279000 (16.5398 iter/s, 30.2301s/500 iters), loss = 0.361477
I0829 14:03:28.132335 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.361481 (* 1 = 0.361481 loss)
I0829 14:03:28.132344 916722 sgd_solver.cpp:106] Iteration 279000, lr = 0.01
I0829 14:03:58.364647 916722 solver.cpp:218] Iteration 279500 (16.5387 iter/s, 30.2321s/500 iters), loss = 0.151848
I0829 14:03:58.364717 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.151853 (* 1 = 0.151853 loss)
I0829 14:03:58.364727 916722 sgd_solver.cpp:106] Iteration 279500, lr = 0.01
I0829 14:04:28.597877 916722 solver.cpp:218] Iteration 280000 (16.5382 iter/s, 30.233s/500 iters), loss = 0.0733267
I0829 14:04:28.597939 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0733314 (* 1 = 0.0733314 loss)
I0829 14:04:28.597947 916722 sgd_solver.cpp:106] Iteration 280000, lr = 0.01
I0829 14:04:58.810423 916722 solver.cpp:218] Iteration 280500 (16.5495 iter/s, 30.2123s/500 iters), loss = 0.101901
I0829 14:04:58.810482 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101905 (* 1 = 0.101905 loss)
I0829 14:04:58.810490 916722 sgd_solver.cpp:106] Iteration 280500, lr = 0.01
I0829 14:05:29.056216 916722 solver.cpp:218] Iteration 281000 (16.5313 iter/s, 30.2456s/500 iters), loss = 0.499457
I0829 14:05:29.056275 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.499462 (* 1 = 0.499462 loss)
I0829 14:05:29.056283 916722 sgd_solver.cpp:106] Iteration 281000, lr = 0.01
I0829 14:05:59.256611 916722 solver.cpp:218] Iteration 281500 (16.5562 iter/s, 30.2002s/500 iters), loss = 0.291808
I0829 14:05:59.256673 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.291813 (* 1 = 0.291813 loss)
I0829 14:05:59.256682 916722 sgd_solver.cpp:106] Iteration 281500, lr = 0.01
I0829 14:06:29.459745 916722 solver.cpp:218] Iteration 282000 (16.5547 iter/s, 30.2029s/500 iters), loss = 0.142684
I0829 14:06:29.459801 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.142688 (* 1 = 0.142688 loss)
I0829 14:06:29.459810 916722 sgd_solver.cpp:106] Iteration 282000, lr = 0.01
I0829 14:06:59.651551 916722 solver.cpp:218] Iteration 282500 (16.5609 iter/s, 30.1916s/500 iters), loss = 0.0941598
I0829 14:06:59.651610 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0941647 (* 1 = 0.0941647 loss)
I0829 14:06:59.651618 916722 sgd_solver.cpp:106] Iteration 282500, lr = 0.01
I0829 14:07:29.836079 916722 solver.cpp:218] Iteration 283000 (16.5649 iter/s, 30.1843s/500 iters), loss = 0.0766672
I0829 14:07:29.836139 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0766721 (* 1 = 0.0766721 loss)
I0829 14:07:29.836148 916722 sgd_solver.cpp:106] Iteration 283000, lr = 0.01
I0829 14:08:00.039815 916722 solver.cpp:218] Iteration 283500 (16.5544 iter/s, 30.2035s/500 iters), loss = 0.1115
I0829 14:08:00.039872 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111505 (* 1 = 0.111505 loss)
I0829 14:08:00.039880 916722 sgd_solver.cpp:106] Iteration 283500, lr = 0.01
I0829 14:08:30.257366 916722 solver.cpp:218] Iteration 284000 (16.5468 iter/s, 30.2173s/500 iters), loss = 0.510773
I0829 14:08:30.257426 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.510778 (* 1 = 0.510778 loss)
I0829 14:08:30.257433 916722 sgd_solver.cpp:106] Iteration 284000, lr = 0.01
I0829 14:09:00.455265 916722 solver.cpp:218] Iteration 284500 (16.5576 iter/s, 30.1977s/500 iters), loss = 0.044009
I0829 14:09:00.455323 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0440139 (* 1 = 0.0440139 loss)
I0829 14:09:00.455332 916722 sgd_solver.cpp:106] Iteration 284500, lr = 0.01
I0829 14:09:30.664613 916722 solver.cpp:218] Iteration 285000 (16.5513 iter/s, 30.2091s/500 iters), loss = 0.294943
I0829 14:09:30.664669 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.294948 (* 1 = 0.294948 loss)
I0829 14:09:30.664677 916722 sgd_solver.cpp:106] Iteration 285000, lr = 0.01
I0829 14:10:00.867576 916722 solver.cpp:218] Iteration 285500 (16.5548 iter/s, 30.2027s/500 iters), loss = 0.373864
I0829 14:10:00.867630 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.373869 (* 1 = 0.373869 loss)
I0829 14:10:00.867638 916722 sgd_solver.cpp:106] Iteration 285500, lr = 0.01
I0829 14:10:31.080310 916722 solver.cpp:218] Iteration 286000 (16.5494 iter/s, 30.2125s/500 iters), loss = 0.234293
I0829 14:10:31.080379 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.234298 (* 1 = 0.234298 loss)
I0829 14:10:31.080399 916722 sgd_solver.cpp:106] Iteration 286000, lr = 0.01
I0829 14:11:01.287539 916722 solver.cpp:218] Iteration 286500 (16.5525 iter/s, 30.207s/500 iters), loss = 0.302528
I0829 14:11:01.287593 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.302533 (* 1 = 0.302533 loss)
I0829 14:11:01.287601 916722 sgd_solver.cpp:106] Iteration 286500, lr = 0.01
I0829 14:11:31.509917 916722 solver.cpp:218] Iteration 287000 (16.5441 iter/s, 30.2222s/500 iters), loss = 0.269869
I0829 14:11:31.509975 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.269875 (* 1 = 0.269875 loss)
I0829 14:11:31.509984 916722 sgd_solver.cpp:106] Iteration 287000, lr = 0.01
I0829 14:12:01.730048 916722 solver.cpp:218] Iteration 287500 (16.5454 iter/s, 30.2199s/500 iters), loss = 0.350271
I0829 14:12:01.730101 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.350276 (* 1 = 0.350276 loss)
I0829 14:12:01.730109 916722 sgd_solver.cpp:106] Iteration 287500, lr = 0.01
I0829 14:12:31.944134 916722 solver.cpp:218] Iteration 288000 (16.5487 iter/s, 30.2139s/500 iters), loss = 0.649851
I0829 14:12:31.944195 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.649857 (* 1 = 0.649857 loss)
I0829 14:12:31.944203 916722 sgd_solver.cpp:106] Iteration 288000, lr = 0.01
I0829 14:13:02.161008 916722 solver.cpp:218] Iteration 288500 (16.5472 iter/s, 30.2167s/500 iters), loss = 0.163246
I0829 14:13:02.161063 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.163251 (* 1 = 0.163251 loss)
I0829 14:13:02.161072 916722 sgd_solver.cpp:106] Iteration 288500, lr = 0.01
I0829 14:13:32.365311 916722 solver.cpp:218] Iteration 289000 (16.5534 iter/s, 30.2052s/500 iters), loss = 0.0852766
I0829 14:13:32.365370 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0852818 (* 1 = 0.0852818 loss)
I0829 14:13:32.365379 916722 sgd_solver.cpp:106] Iteration 289000, lr = 0.01
I0829 14:14:02.559257 916722 solver.cpp:218] Iteration 289500 (16.5591 iter/s, 30.1949s/500 iters), loss = 0.0581002
I0829 14:14:02.559312 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0581054 (* 1 = 0.0581054 loss)
I0829 14:14:02.559320 916722 sgd_solver.cpp:106] Iteration 289500, lr = 0.01
I0829 14:14:32.775744 916722 solver.cpp:218] Iteration 290000 (16.5468 iter/s, 30.2174s/500 iters), loss = 0.297682
I0829 14:14:32.775802 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.297687 (* 1 = 0.297687 loss)
I0829 14:14:32.775810 916722 sgd_solver.cpp:106] Iteration 290000, lr = 0.01
I0829 14:15:02.962110 916722 solver.cpp:218] Iteration 290500 (16.5633 iter/s, 30.1872s/500 iters), loss = 0.488641
I0829 14:15:02.962167 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.488646 (* 1 = 0.488646 loss)
I0829 14:15:02.962175 916722 sgd_solver.cpp:106] Iteration 290500, lr = 0.01
I0829 14:15:33.136463 916722 solver.cpp:218] Iteration 291000 (16.5699 iter/s, 30.1751s/500 iters), loss = 0.353684
I0829 14:15:33.136524 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.353689 (* 1 = 0.353689 loss)
I0829 14:15:33.136533 916722 sgd_solver.cpp:106] Iteration 291000, lr = 0.01
I0829 14:16:03.315452 916722 solver.cpp:218] Iteration 291500 (16.5674 iter/s, 30.1797s/500 iters), loss = 0.266298
I0829 14:16:03.315508 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.266303 (* 1 = 0.266303 loss)
I0829 14:16:03.315516 916722 sgd_solver.cpp:106] Iteration 291500, lr = 0.01
I0829 14:16:33.490278 916722 solver.cpp:218] Iteration 292000 (16.5697 iter/s, 30.1755s/500 iters), loss = 0.0942364
I0829 14:16:33.490336 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0942419 (* 1 = 0.0942419 loss)
I0829 14:16:33.490345 916722 sgd_solver.cpp:106] Iteration 292000, lr = 0.01
I0829 14:17:03.697041 916722 solver.cpp:218] Iteration 292500 (16.5522 iter/s, 30.2074s/500 iters), loss = 0.260554
I0829 14:17:03.697111 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.260559 (* 1 = 0.260559 loss)
I0829 14:17:03.697120 916722 sgd_solver.cpp:106] Iteration 292500, lr = 0.01
I0829 14:17:33.901212 916722 solver.cpp:218] Iteration 293000 (16.5537 iter/s, 30.2048s/500 iters), loss = 0.312038
I0829 14:17:33.901270 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.312043 (* 1 = 0.312043 loss)
I0829 14:17:33.901278 916722 sgd_solver.cpp:106] Iteration 293000, lr = 0.01
I0829 14:18:04.104328 916722 solver.cpp:218] Iteration 293500 (16.5543 iter/s, 30.2037s/500 iters), loss = 0.173064
I0829 14:18:04.104383 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.173069 (* 1 = 0.173069 loss)
I0829 14:18:04.104391 916722 sgd_solver.cpp:106] Iteration 293500, lr = 0.01
I0829 14:18:34.302853 916722 solver.cpp:218] Iteration 294000 (16.5568 iter/s, 30.1991s/500 iters), loss = 0.255291
I0829 14:18:34.302912 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.255297 (* 1 = 0.255297 loss)
I0829 14:18:34.302922 916722 sgd_solver.cpp:106] Iteration 294000, lr = 0.01
I0829 14:19:04.500396 916722 solver.cpp:218] Iteration 294500 (16.5574 iter/s, 30.1981s/500 iters), loss = 0.253742
I0829 14:19:04.500463 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.253747 (* 1 = 0.253747 loss)
I0829 14:19:04.500470 916722 sgd_solver.cpp:106] Iteration 294500, lr = 0.01
I0829 14:19:34.699448 916722 solver.cpp:218] Iteration 295000 (16.5566 iter/s, 30.1995s/500 iters), loss = 0.211038
I0829 14:19:34.699507 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.211044 (* 1 = 0.211044 loss)
I0829 14:19:34.699517 916722 sgd_solver.cpp:106] Iteration 295000, lr = 0.01
I0829 14:20:04.911317 916722 solver.cpp:218] Iteration 295500 (16.5495 iter/s, 30.2123s/500 iters), loss = 0.426846
I0829 14:20:04.911371 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.426851 (* 1 = 0.426851 loss)
I0829 14:20:04.911379 916722 sgd_solver.cpp:106] Iteration 295500, lr = 0.01
I0829 14:20:35.131407 916722 solver.cpp:218] Iteration 296000 (16.545 iter/s, 30.2205s/500 iters), loss = 0.161456
I0829 14:20:35.131461 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.161462 (* 1 = 0.161462 loss)
I0829 14:20:35.131469 916722 sgd_solver.cpp:106] Iteration 296000, lr = 0.01
I0829 14:21:05.369017 916722 solver.cpp:218] Iteration 296500 (16.5355 iter/s, 30.238s/500 iters), loss = 0.161847
I0829 14:21:05.369067 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.161853 (* 1 = 0.161853 loss)
I0829 14:21:05.369076 916722 sgd_solver.cpp:106] Iteration 296500, lr = 0.01
I0829 14:21:35.604354 916722 solver.cpp:218] Iteration 297000 (16.5367 iter/s, 30.2357s/500 iters), loss = 0.20482
I0829 14:21:35.604410 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.204826 (* 1 = 0.204826 loss)
I0829 14:21:35.604419 916722 sgd_solver.cpp:106] Iteration 297000, lr = 0.01
I0829 14:22:05.847235 916722 solver.cpp:218] Iteration 297500 (16.5326 iter/s, 30.2432s/500 iters), loss = 0.323622
I0829 14:22:05.847290 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.323628 (* 1 = 0.323628 loss)
I0829 14:22:05.847298 916722 sgd_solver.cpp:106] Iteration 297500, lr = 0.01
I0829 14:22:36.073403 916722 solver.cpp:218] Iteration 298000 (16.5418 iter/s, 30.2265s/500 iters), loss = 0.176188
I0829 14:22:36.073462 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.176194 (* 1 = 0.176194 loss)
I0829 14:22:36.073469 916722 sgd_solver.cpp:106] Iteration 298000, lr = 0.01
I0829 14:23:06.294157 916722 solver.cpp:218] Iteration 298500 (16.5448 iter/s, 30.2211s/500 iters), loss = 0.0779265
I0829 14:23:06.294214 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0779326 (* 1 = 0.0779326 loss)
I0829 14:23:06.294221 916722 sgd_solver.cpp:106] Iteration 298500, lr = 0.01
I0829 14:23:36.535403 916722 solver.cpp:218] Iteration 299000 (16.5335 iter/s, 30.2415s/500 iters), loss = 0.154864
I0829 14:23:36.535471 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.15487 (* 1 = 0.15487 loss)
I0829 14:23:36.535483 916722 sgd_solver.cpp:106] Iteration 299000, lr = 0.01
I0829 14:24:06.744513 916722 solver.cpp:218] Iteration 299500 (16.5512 iter/s, 30.2094s/500 iters), loss = 0.0412538
I0829 14:24:06.744571 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.04126 (* 1 = 0.04126 loss)
I0829 14:24:06.744580 916722 sgd_solver.cpp:106] Iteration 299500, lr = 0.01
I0829 14:24:36.886474 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_300000.caffemodel
I0829 14:24:36.905637 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_300000.solverstate
I0829 14:24:36.911728 916722 solver.cpp:330] Iteration 300000, Testing net (#0)
I0829 14:24:52.392158 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8838
I0829 14:24:52.392206 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.363762 (* 1 = 0.363762 loss)
I0829 14:24:52.450994 916722 solver.cpp:218] Iteration 300000 (10.9393 iter/s, 45.7069s/500 iters), loss = 0.309273
I0829 14:24:52.451021 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.309279 (* 1 = 0.309279 loss)
I0829 14:24:52.451030 916722 sgd_solver.cpp:106] Iteration 300000, lr = 0.01
I0829 14:25:22.389788 916722 solver.cpp:218] Iteration 300500 (16.7006 iter/s, 29.939s/500 iters), loss = 0.0138835
I0829 14:25:22.389842 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0138898 (* 1 = 0.0138898 loss)
I0829 14:25:22.389850 916722 sgd_solver.cpp:106] Iteration 300500, lr = 0.01
I0829 14:25:52.492367 916722 solver.cpp:218] Iteration 301000 (16.6098 iter/s, 30.1028s/500 iters), loss = 0.255466
I0829 14:25:52.492430 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.255472 (* 1 = 0.255472 loss)
I0829 14:25:52.492457 916722 sgd_solver.cpp:106] Iteration 301000, lr = 0.01
I0829 14:26:22.591711 916722 solver.cpp:218] Iteration 301500 (16.6115 iter/s, 30.0995s/500 iters), loss = 0.206359
I0829 14:26:22.591771 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.206366 (* 1 = 0.206366 loss)
I0829 14:26:22.591780 916722 sgd_solver.cpp:106] Iteration 301500, lr = 0.01
I0829 14:26:52.712096 916722 solver.cpp:218] Iteration 302000 (16.5999 iter/s, 30.1206s/500 iters), loss = 0.296781
I0829 14:26:52.712153 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.296787 (* 1 = 0.296787 loss)
I0829 14:26:52.712162 916722 sgd_solver.cpp:106] Iteration 302000, lr = 0.01
I0829 14:27:22.836297 916722 solver.cpp:218] Iteration 302500 (16.5978 iter/s, 30.1244s/500 iters), loss = 0.140948
I0829 14:27:22.836354 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.140955 (* 1 = 0.140955 loss)
I0829 14:27:22.836361 916722 sgd_solver.cpp:106] Iteration 302500, lr = 0.01
I0829 14:27:52.947576 916722 solver.cpp:218] Iteration 303000 (16.605 iter/s, 30.1115s/500 iters), loss = 0.319042
I0829 14:27:52.947634 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.319048 (* 1 = 0.319048 loss)
I0829 14:27:52.947643 916722 sgd_solver.cpp:106] Iteration 303000, lr = 0.01
I0829 14:28:23.075011 916722 solver.cpp:218] Iteration 303500 (16.5961 iter/s, 30.1276s/500 iters), loss = 0.12685
I0829 14:28:23.075071 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.126856 (* 1 = 0.126856 loss)
I0829 14:28:23.075079 916722 sgd_solver.cpp:106] Iteration 303500, lr = 0.01
I0829 14:28:53.223816 916722 solver.cpp:218] Iteration 304000 (16.5843 iter/s, 30.149s/500 iters), loss = 0.119132
I0829 14:28:53.223875 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.119138 (* 1 = 0.119138 loss)
I0829 14:28:53.223884 916722 sgd_solver.cpp:106] Iteration 304000, lr = 0.01
I0829 14:29:23.334893 916722 solver.cpp:218] Iteration 304500 (16.6051 iter/s, 30.1112s/500 iters), loss = 0.0956106
I0829 14:29:23.334954 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0956167 (* 1 = 0.0956167 loss)
I0829 14:29:23.334961 916722 sgd_solver.cpp:106] Iteration 304500, lr = 0.01
I0829 14:29:53.486997 916722 solver.cpp:218] Iteration 305000 (16.5825 iter/s, 30.1522s/500 iters), loss = 0.111221
I0829 14:29:53.487074 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111227 (* 1 = 0.111227 loss)
I0829 14:29:53.487082 916722 sgd_solver.cpp:106] Iteration 305000, lr = 0.01
I0829 14:30:23.577586 916722 solver.cpp:218] Iteration 305500 (16.6164 iter/s, 30.0907s/500 iters), loss = 0.484038
I0829 14:30:23.577647 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.484043 (* 1 = 0.484043 loss)
I0829 14:30:23.577656 916722 sgd_solver.cpp:106] Iteration 305500, lr = 0.01
I0829 14:30:53.698424 916722 solver.cpp:218] Iteration 306000 (16.5997 iter/s, 30.121s/500 iters), loss = 0.130773
I0829 14:30:53.698489 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130779 (* 1 = 0.130779 loss)
I0829 14:30:53.698498 916722 sgd_solver.cpp:106] Iteration 306000, lr = 0.01
I0829 14:31:23.802439 916722 solver.cpp:218] Iteration 306500 (16.609 iter/s, 30.1041s/500 iters), loss = 0.0449548
I0829 14:31:23.802500 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0449604 (* 1 = 0.0449604 loss)
I0829 14:31:23.802507 916722 sgd_solver.cpp:106] Iteration 306500, lr = 0.01
I0829 14:31:53.910751 916722 solver.cpp:218] Iteration 307000 (16.6067 iter/s, 30.1084s/500 iters), loss = 0.168373
I0829 14:31:53.910810 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.168379 (* 1 = 0.168379 loss)
I0829 14:31:53.910818 916722 sgd_solver.cpp:106] Iteration 307000, lr = 0.01
I0829 14:32:24.024583 916722 solver.cpp:218] Iteration 307500 (16.6036 iter/s, 30.1139s/500 iters), loss = 0.385139
I0829 14:32:24.024646 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.385144 (* 1 = 0.385144 loss)
I0829 14:32:24.024653 916722 sgd_solver.cpp:106] Iteration 307500, lr = 0.01
I0829 14:32:54.140697 916722 solver.cpp:218] Iteration 308000 (16.6024 iter/s, 30.1162s/500 iters), loss = 0.276695
I0829 14:32:54.140776 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.2767 (* 1 = 0.2767 loss)
I0829 14:32:54.140784 916722 sgd_solver.cpp:106] Iteration 308000, lr = 0.01
I0829 14:33:24.238751 916722 solver.cpp:218] Iteration 308500 (16.6123 iter/s, 30.0981s/500 iters), loss = 0.176606
I0829 14:33:24.238812 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.176612 (* 1 = 0.176612 loss)
I0829 14:33:24.238821 916722 sgd_solver.cpp:106] Iteration 308500, lr = 0.01
I0829 14:33:54.355204 916722 solver.cpp:218] Iteration 309000 (16.6022 iter/s, 30.1165s/500 iters), loss = 0.239047
I0829 14:33:54.355260 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.239053 (* 1 = 0.239053 loss)
I0829 14:33:54.355268 916722 sgd_solver.cpp:106] Iteration 309000, lr = 0.01
I0829 14:34:24.482399 916722 solver.cpp:218] Iteration 309500 (16.5963 iter/s, 30.1273s/500 iters), loss = 0.138198
I0829 14:34:24.482462 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.138204 (* 1 = 0.138204 loss)
I0829 14:34:24.482471 916722 sgd_solver.cpp:106] Iteration 309500, lr = 0.01
I0829 14:34:54.590116 916722 solver.cpp:218] Iteration 310000 (16.607 iter/s, 30.1078s/500 iters), loss = 0.24844
I0829 14:34:54.590171 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.248445 (* 1 = 0.248445 loss)
I0829 14:34:54.590179 916722 sgd_solver.cpp:106] Iteration 310000, lr = 0.01
I0829 14:35:24.716699 916722 solver.cpp:218] Iteration 310500 (16.5966 iter/s, 30.1267s/500 iters), loss = 0.284635
I0829 14:35:24.716758 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.28464 (* 1 = 0.28464 loss)
I0829 14:35:24.716768 916722 sgd_solver.cpp:106] Iteration 310500, lr = 0.01
I0829 14:35:54.820981 916722 solver.cpp:218] Iteration 311000 (16.6089 iter/s, 30.1043s/500 iters), loss = 0.0829642
I0829 14:35:54.821038 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0829697 (* 1 = 0.0829697 loss)
I0829 14:35:54.821045 916722 sgd_solver.cpp:106] Iteration 311000, lr = 0.01
I0829 14:36:24.942554 916722 solver.cpp:218] Iteration 311500 (16.5994 iter/s, 30.1216s/500 iters), loss = 0.0843604
I0829 14:36:24.942629 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.084366 (* 1 = 0.084366 loss)
I0829 14:36:24.942637 916722 sgd_solver.cpp:106] Iteration 311500, lr = 0.01
I0829 14:36:55.064122 916722 solver.cpp:218] Iteration 312000 (16.5994 iter/s, 30.1216s/500 iters), loss = 0.24332
I0829 14:36:55.064184 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.243326 (* 1 = 0.243326 loss)
I0829 14:36:55.064193 916722 sgd_solver.cpp:106] Iteration 312000, lr = 0.01
I0829 14:37:25.199273 916722 solver.cpp:218] Iteration 312500 (16.5919 iter/s, 30.1352s/500 iters), loss = 0.069481
I0829 14:37:25.199331 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0694864 (* 1 = 0.0694864 loss)
I0829 14:37:25.199339 916722 sgd_solver.cpp:106] Iteration 312500, lr = 0.01
I0829 14:37:55.319876 916722 solver.cpp:218] Iteration 313000 (16.5999 iter/s, 30.1207s/500 iters), loss = 0.176412
I0829 14:37:55.319936 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.176417 (* 1 = 0.176417 loss)
I0829 14:37:55.319945 916722 sgd_solver.cpp:106] Iteration 313000, lr = 0.01
I0829 14:38:25.436810 916722 solver.cpp:218] Iteration 313500 (16.6019 iter/s, 30.117s/500 iters), loss = 0.143989
I0829 14:38:25.436867 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.143994 (* 1 = 0.143994 loss)
I0829 14:38:25.436875 916722 sgd_solver.cpp:106] Iteration 313500, lr = 0.01
I0829 14:38:55.556797 916722 solver.cpp:218] Iteration 314000 (16.6003 iter/s, 30.12s/500 iters), loss = 0.258822
I0829 14:38:55.556859 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.258827 (* 1 = 0.258827 loss)
I0829 14:38:55.556867 916722 sgd_solver.cpp:106] Iteration 314000, lr = 0.01
I0829 14:39:25.676100 916722 solver.cpp:218] Iteration 314500 (16.6006 iter/s, 30.1193s/500 iters), loss = 0.170366
I0829 14:39:25.676156 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.170371 (* 1 = 0.170371 loss)
I0829 14:39:25.676164 916722 sgd_solver.cpp:106] Iteration 314500, lr = 0.01
I0829 14:39:55.811372 916722 solver.cpp:218] Iteration 315000 (16.5918 iter/s, 30.1353s/500 iters), loss = 0.287264
I0829 14:39:55.811432 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.287269 (* 1 = 0.287269 loss)
I0829 14:39:55.811440 916722 sgd_solver.cpp:106] Iteration 315000, lr = 0.01
I0829 14:40:25.934980 916722 solver.cpp:218] Iteration 315500 (16.5983 iter/s, 30.1236s/500 iters), loss = 0.307623
I0829 14:40:25.935039 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.307628 (* 1 = 0.307628 loss)
I0829 14:40:25.935046 916722 sgd_solver.cpp:106] Iteration 315500, lr = 0.01
I0829 14:40:56.142182 916722 solver.cpp:218] Iteration 316000 (16.5523 iter/s, 30.2072s/500 iters), loss = 0.0207664
I0829 14:40:56.142242 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0207717 (* 1 = 0.0207717 loss)
I0829 14:40:56.142251 916722 sgd_solver.cpp:106] Iteration 316000, lr = 0.01
I0829 14:41:26.353996 916722 solver.cpp:218] Iteration 316500 (16.5498 iter/s, 30.2118s/500 iters), loss = 0.208828
I0829 14:41:26.354051 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.208833 (* 1 = 0.208833 loss)
I0829 14:41:26.354059 916722 sgd_solver.cpp:106] Iteration 316500, lr = 0.01
I0829 14:41:56.558661 916722 solver.cpp:218] Iteration 317000 (16.5537 iter/s, 30.2047s/500 iters), loss = 0.0315656
I0829 14:41:56.558719 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0315706 (* 1 = 0.0315706 loss)
I0829 14:41:56.558727 916722 sgd_solver.cpp:106] Iteration 317000, lr = 0.01
I0829 14:42:26.765647 916722 solver.cpp:218] Iteration 317500 (16.5524 iter/s, 30.207s/500 iters), loss = 0.0329907
I0829 14:42:26.765702 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.032996 (* 1 = 0.032996 loss)
I0829 14:42:26.765710 916722 sgd_solver.cpp:106] Iteration 317500, lr = 0.01
I0829 14:42:56.966768 916722 solver.cpp:218] Iteration 318000 (16.5557 iter/s, 30.2011s/500 iters), loss = 0.183522
I0829 14:42:56.966836 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.183527 (* 1 = 0.183527 loss)
I0829 14:42:56.966848 916722 sgd_solver.cpp:106] Iteration 318000, lr = 0.01
I0829 14:43:27.161051 916722 solver.cpp:218] Iteration 318500 (16.5594 iter/s, 30.1943s/500 iters), loss = 0.222261
I0829 14:43:27.161105 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.222266 (* 1 = 0.222266 loss)
I0829 14:43:27.161113 916722 sgd_solver.cpp:106] Iteration 318500, lr = 0.01
I0829 14:43:57.352550 916722 solver.cpp:218] Iteration 319000 (16.5609 iter/s, 30.1915s/500 iters), loss = 0.201023
I0829 14:43:57.352608 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.201028 (* 1 = 0.201028 loss)
I0829 14:43:57.352617 916722 sgd_solver.cpp:106] Iteration 319000, lr = 0.01
I0829 14:44:27.574136 916722 solver.cpp:218] Iteration 319500 (16.5445 iter/s, 30.2216s/500 iters), loss = 0.27156
I0829 14:44:27.574193 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.271565 (* 1 = 0.271565 loss)
I0829 14:44:27.574201 916722 sgd_solver.cpp:106] Iteration 319500, lr = 0.01
I0829 14:44:57.789409 916722 solver.cpp:218] Iteration 320000 (16.5479 iter/s, 30.2153s/500 iters), loss = 0.097214
I0829 14:44:57.789469 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0972187 (* 1 = 0.0972187 loss)
I0829 14:44:57.789476 916722 sgd_solver.cpp:106] Iteration 320000, lr = 0.01
I0829 14:45:27.981979 916722 solver.cpp:218] Iteration 320500 (16.5604 iter/s, 30.1926s/500 iters), loss = 0.0494929
I0829 14:45:27.982029 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0494977 (* 1 = 0.0494977 loss)
I0829 14:45:27.982038 916722 sgd_solver.cpp:106] Iteration 320500, lr = 0.01
I0829 14:45:58.186525 916722 solver.cpp:218] Iteration 321000 (16.5538 iter/s, 30.2046s/500 iters), loss = 0.234001
I0829 14:45:58.186584 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.234006 (* 1 = 0.234006 loss)
I0829 14:45:58.186592 916722 sgd_solver.cpp:106] Iteration 321000, lr = 0.01
I0829 14:46:28.381661 916722 solver.cpp:218] Iteration 321500 (16.559 iter/s, 30.1951s/500 iters), loss = 0.253663
I0829 14:46:28.381714 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.253668 (* 1 = 0.253668 loss)
I0829 14:46:28.381722 916722 sgd_solver.cpp:106] Iteration 321500, lr = 0.01
I0829 14:46:58.592799 916722 solver.cpp:218] Iteration 322000 (16.5502 iter/s, 30.2112s/500 iters), loss = 0.182779
I0829 14:46:58.592857 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.182785 (* 1 = 0.182785 loss)
I0829 14:46:58.592865 916722 sgd_solver.cpp:106] Iteration 322000, lr = 0.01
I0829 14:47:28.815063 916722 solver.cpp:218] Iteration 322500 (16.5441 iter/s, 30.2223s/500 iters), loss = 0.462264
I0829 14:47:28.815120 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.462269 (* 1 = 0.462269 loss)
I0829 14:47:28.815129 916722 sgd_solver.cpp:106] Iteration 322500, lr = 0.01
I0829 14:47:59.017843 916722 solver.cpp:218] Iteration 323000 (16.5548 iter/s, 30.2028s/500 iters), loss = 0.0448799
I0829 14:47:59.017902 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0448849 (* 1 = 0.0448849 loss)
I0829 14:47:59.017910 916722 sgd_solver.cpp:106] Iteration 323000, lr = 0.01
I0829 14:48:29.217029 916722 solver.cpp:218] Iteration 323500 (16.5567 iter/s, 30.1992s/500 iters), loss = 0.233811
I0829 14:48:29.217085 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.233816 (* 1 = 0.233816 loss)
I0829 14:48:29.217093 916722 sgd_solver.cpp:106] Iteration 323500, lr = 0.01
I0829 14:48:59.428480 916722 solver.cpp:218] Iteration 324000 (16.55 iter/s, 30.2115s/500 iters), loss = 0.0555535
I0829 14:48:59.428541 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0555584 (* 1 = 0.0555584 loss)
I0829 14:48:59.428550 916722 sgd_solver.cpp:106] Iteration 324000, lr = 0.01
I0829 14:49:29.640770 916722 solver.cpp:218] Iteration 324500 (16.5496 iter/s, 30.2123s/500 iters), loss = 0.126743
I0829 14:49:29.640841 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.126748 (* 1 = 0.126748 loss)
I0829 14:49:29.640849 916722 sgd_solver.cpp:106] Iteration 324500, lr = 0.01
I0829 14:49:59.846276 916722 solver.cpp:218] Iteration 325000 (16.5533 iter/s, 30.2055s/500 iters), loss = 0.141165
I0829 14:49:59.846331 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.14117 (* 1 = 0.14117 loss)
I0829 14:49:59.846340 916722 sgd_solver.cpp:106] Iteration 325000, lr = 0.01
I0829 14:50:30.068950 916722 solver.cpp:218] Iteration 325500 (16.5439 iter/s, 30.2227s/500 iters), loss = 0.33125
I0829 14:50:30.069007 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.331255 (* 1 = 0.331255 loss)
I0829 14:50:30.069015 916722 sgd_solver.cpp:106] Iteration 325500, lr = 0.01
I0829 14:51:00.291715 916722 solver.cpp:218] Iteration 326000 (16.5438 iter/s, 30.2228s/500 iters), loss = 0.128112
I0829 14:51:00.291772 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128117 (* 1 = 0.128117 loss)
I0829 14:51:00.291780 916722 sgd_solver.cpp:106] Iteration 326000, lr = 0.01
I0829 14:51:30.475891 916722 solver.cpp:218] Iteration 326500 (16.565 iter/s, 30.1842s/500 iters), loss = 0.228725
I0829 14:51:30.475948 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.228729 (* 1 = 0.228729 loss)
I0829 14:51:30.475956 916722 sgd_solver.cpp:106] Iteration 326500, lr = 0.01
I0829 14:52:00.689113 916722 solver.cpp:218] Iteration 327000 (16.549 iter/s, 30.2132s/500 iters), loss = 0.168228
I0829 14:52:00.689168 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.168233 (* 1 = 0.168233 loss)
I0829 14:52:00.689177 916722 sgd_solver.cpp:106] Iteration 327000, lr = 0.01
I0829 14:52:30.899298 916722 solver.cpp:218] Iteration 327500 (16.5507 iter/s, 30.2102s/500 iters), loss = 0.192407
I0829 14:52:30.899355 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.192411 (* 1 = 0.192411 loss)
I0829 14:52:30.899363 916722 sgd_solver.cpp:106] Iteration 327500, lr = 0.01
I0829 14:53:01.093670 916722 solver.cpp:218] Iteration 328000 (16.5594 iter/s, 30.1944s/500 iters), loss = 0.0558865
I0829 14:53:01.093727 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0558911 (* 1 = 0.0558911 loss)
I0829 14:53:01.093735 916722 sgd_solver.cpp:106] Iteration 328000, lr = 0.01
I0829 14:53:31.313050 916722 solver.cpp:218] Iteration 328500 (16.5457 iter/s, 30.2194s/500 iters), loss = 0.202562
I0829 14:53:31.313107 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.202567 (* 1 = 0.202567 loss)
I0829 14:53:31.313117 916722 sgd_solver.cpp:106] Iteration 328500, lr = 0.01
I0829 14:54:01.540128 916722 solver.cpp:218] Iteration 329000 (16.5415 iter/s, 30.2271s/500 iters), loss = 0.221286
I0829 14:54:01.540185 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.221291 (* 1 = 0.221291 loss)
I0829 14:54:01.540194 916722 sgd_solver.cpp:106] Iteration 329000, lr = 0.01
I0829 14:54:31.756966 916722 solver.cpp:218] Iteration 329500 (16.5471 iter/s, 30.2168s/500 iters), loss = 0.156255
I0829 14:54:31.757021 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.15626 (* 1 = 0.15626 loss)
I0829 14:54:31.757030 916722 sgd_solver.cpp:106] Iteration 329500, lr = 0.01
I0829 14:55:01.957469 916722 solver.cpp:218] Iteration 330000 (16.556 iter/s, 30.2005s/500 iters), loss = 0.0414734
I0829 14:55:01.957532 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0414781 (* 1 = 0.0414781 loss)
I0829 14:55:01.957540 916722 sgd_solver.cpp:106] Iteration 330000, lr = 0.01
I0829 14:55:32.160050 916722 solver.cpp:218] Iteration 330500 (16.5549 iter/s, 30.2026s/500 iters), loss = 0.0772761
I0829 14:55:32.160107 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0772807 (* 1 = 0.0772807 loss)
I0829 14:55:32.160115 916722 sgd_solver.cpp:106] Iteration 330500, lr = 0.01
I0829 14:56:02.367094 916722 solver.cpp:218] Iteration 331000 (16.5524 iter/s, 30.207s/500 iters), loss = 0.134071
I0829 14:56:02.367147 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.134076 (* 1 = 0.134076 loss)
I0829 14:56:02.367156 916722 sgd_solver.cpp:106] Iteration 331000, lr = 0.01
I0829 14:56:32.576402 916722 solver.cpp:218] Iteration 331500 (16.5512 iter/s, 30.2093s/500 iters), loss = 0.302172
I0829 14:56:32.576493 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.302177 (* 1 = 0.302177 loss)
I0829 14:56:32.576501 916722 sgd_solver.cpp:106] Iteration 331500, lr = 0.01
I0829 14:57:02.786923 916722 solver.cpp:218] Iteration 332000 (16.5505 iter/s, 30.2105s/500 iters), loss = 0.132274
I0829 14:57:02.786976 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.132278 (* 1 = 0.132278 loss)
I0829 14:57:02.786983 916722 sgd_solver.cpp:106] Iteration 332000, lr = 0.01
I0829 14:57:32.981709 916722 solver.cpp:218] Iteration 332500 (16.5592 iter/s, 30.1948s/500 iters), loss = 0.237928
I0829 14:57:32.981765 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.237933 (* 1 = 0.237933 loss)
I0829 14:57:32.981773 916722 sgd_solver.cpp:106] Iteration 332500, lr = 0.01
I0829 14:58:03.178980 916722 solver.cpp:218] Iteration 333000 (16.5578 iter/s, 30.1973s/500 iters), loss = 0.0458886
I0829 14:58:03.179035 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0458932 (* 1 = 0.0458932 loss)
I0829 14:58:03.179044 916722 sgd_solver.cpp:106] Iteration 333000, lr = 0.01
I0829 14:58:33.375463 916722 solver.cpp:218] Iteration 333500 (16.5582 iter/s, 30.1965s/500 iters), loss = 0.0894549
I0829 14:58:33.375522 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0894595 (* 1 = 0.0894595 loss)
I0829 14:58:33.375530 916722 sgd_solver.cpp:106] Iteration 333500, lr = 0.01
I0829 14:59:03.578562 916722 solver.cpp:218] Iteration 334000 (16.5546 iter/s, 30.2031s/500 iters), loss = 0.230674
I0829 14:59:03.578615 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.230678 (* 1 = 0.230678 loss)
I0829 14:59:03.578624 916722 sgd_solver.cpp:106] Iteration 334000, lr = 0.01
I0829 14:59:33.814728 916722 solver.cpp:218] Iteration 334500 (16.5365 iter/s, 30.2362s/500 iters), loss = 0.1689
I0829 14:59:33.814786 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.168905 (* 1 = 0.168905 loss)
I0829 14:59:33.814795 916722 sgd_solver.cpp:106] Iteration 334500, lr = 0.01
I0829 15:00:04.038448 916722 solver.cpp:218] Iteration 335000 (16.5433 iter/s, 30.2237s/500 iters), loss = 0.0423029
I0829 15:00:04.038506 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0423075 (* 1 = 0.0423075 loss)
I0829 15:00:04.038513 916722 sgd_solver.cpp:106] Iteration 335000, lr = 0.01
I0829 15:00:34.237040 916722 solver.cpp:218] Iteration 335500 (16.5571 iter/s, 30.1986s/500 iters), loss = 0.34971
I0829 15:00:34.237098 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.349714 (* 1 = 0.349714 loss)
I0829 15:00:34.237107 916722 sgd_solver.cpp:106] Iteration 335500, lr = 0.01
I0829 15:01:04.441826 916722 solver.cpp:218] Iteration 336000 (16.5537 iter/s, 30.2048s/500 iters), loss = 0.312919
I0829 15:01:04.441881 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.312924 (* 1 = 0.312924 loss)
I0829 15:01:04.441890 916722 sgd_solver.cpp:106] Iteration 336000, lr = 0.01
I0829 15:01:34.663991 916722 solver.cpp:218] Iteration 336500 (16.5442 iter/s, 30.2222s/500 iters), loss = 0.0719146
I0829 15:01:34.664049 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0719194 (* 1 = 0.0719194 loss)
I0829 15:01:34.664057 916722 sgd_solver.cpp:106] Iteration 336500, lr = 0.01
I0829 15:02:04.906788 916722 solver.cpp:218] Iteration 337000 (16.5329 iter/s, 30.2428s/500 iters), loss = 0.12674
I0829 15:02:04.906848 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.126745 (* 1 = 0.126745 loss)
I0829 15:02:04.906857 916722 sgd_solver.cpp:106] Iteration 337000, lr = 0.01
I0829 15:02:35.096500 916722 solver.cpp:218] Iteration 337500 (16.5619 iter/s, 30.1897s/500 iters), loss = 0.106235
I0829 15:02:35.096565 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.10624 (* 1 = 0.10624 loss)
I0829 15:02:35.096575 916722 sgd_solver.cpp:106] Iteration 337500, lr = 0.01
I0829 15:03:05.310664 916722 solver.cpp:218] Iteration 338000 (16.5485 iter/s, 30.2141s/500 iters), loss = 0.139811
I0829 15:03:05.310750 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139816 (* 1 = 0.139816 loss)
I0829 15:03:05.310773 916722 sgd_solver.cpp:106] Iteration 338000, lr = 0.01
I0829 15:03:35.534734 916722 solver.cpp:218] Iteration 338500 (16.5431 iter/s, 30.224s/500 iters), loss = 0.155943
I0829 15:03:35.534788 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.155948 (* 1 = 0.155948 loss)
I0829 15:03:35.534796 916722 sgd_solver.cpp:106] Iteration 338500, lr = 0.01
I0829 15:04:05.792778 916722 solver.cpp:218] Iteration 339000 (16.5245 iter/s, 30.258s/500 iters), loss = 0.0508267
I0829 15:04:05.792834 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0508316 (* 1 = 0.0508316 loss)
I0829 15:04:05.792841 916722 sgd_solver.cpp:106] Iteration 339000, lr = 0.01
I0829 15:04:36.017985 916722 solver.cpp:218] Iteration 339500 (16.5425 iter/s, 30.2252s/500 iters), loss = 0.0797918
I0829 15:04:36.018044 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0797966 (* 1 = 0.0797966 loss)
I0829 15:04:36.018054 916722 sgd_solver.cpp:106] Iteration 339500, lr = 0.01
I0829 15:05:06.245434 916722 solver.cpp:218] Iteration 340000 (16.5413 iter/s, 30.2274s/500 iters), loss = 0.283555
I0829 15:05:06.245489 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.28356 (* 1 = 0.28356 loss)
I0829 15:05:06.245497 916722 sgd_solver.cpp:106] Iteration 340000, lr = 0.01
I0829 15:05:36.462354 916722 solver.cpp:218] Iteration 340500 (16.547 iter/s, 30.2169s/500 iters), loss = 0.0962352
I0829 15:05:36.462414 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0962399 (* 1 = 0.0962399 loss)
I0829 15:05:36.462422 916722 sgd_solver.cpp:106] Iteration 340500, lr = 0.01
I0829 15:06:06.682643 916722 solver.cpp:218] Iteration 341000 (16.5452 iter/s, 30.2203s/500 iters), loss = 0.303354
I0829 15:06:06.682699 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.303359 (* 1 = 0.303359 loss)
I0829 15:06:06.682708 916722 sgd_solver.cpp:106] Iteration 341000, lr = 0.01
I0829 15:06:36.899075 916722 solver.cpp:218] Iteration 341500 (16.5473 iter/s, 30.2164s/500 iters), loss = 0.127588
I0829 15:06:36.899133 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.127592 (* 1 = 0.127592 loss)
I0829 15:06:36.899142 916722 sgd_solver.cpp:106] Iteration 341500, lr = 0.01
I0829 15:07:07.109649 916722 solver.cpp:218] Iteration 342000 (16.5505 iter/s, 30.2106s/500 iters), loss = 0.130767
I0829 15:07:07.109707 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130772 (* 1 = 0.130772 loss)
I0829 15:07:07.109716 916722 sgd_solver.cpp:106] Iteration 342000, lr = 0.01
I0829 15:07:37.344523 916722 solver.cpp:218] Iteration 342500 (16.5372 iter/s, 30.2349s/500 iters), loss = 0.205874
I0829 15:07:37.344583 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.205879 (* 1 = 0.205879 loss)
I0829 15:07:37.344592 916722 sgd_solver.cpp:106] Iteration 342500, lr = 0.01
I0829 15:08:07.601748 916722 solver.cpp:218] Iteration 343000 (16.525 iter/s, 30.2572s/500 iters), loss = 0.259499
I0829 15:08:07.601804 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.259504 (* 1 = 0.259504 loss)
I0829 15:08:07.601812 916722 sgd_solver.cpp:106] Iteration 343000, lr = 0.01
I0829 15:08:37.819447 916722 solver.cpp:218] Iteration 343500 (16.5466 iter/s, 30.2177s/500 iters), loss = 0.106715
I0829 15:08:37.819507 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.10672 (* 1 = 0.10672 loss)
I0829 15:08:37.819515 916722 sgd_solver.cpp:106] Iteration 343500, lr = 0.01
I0829 15:09:08.046963 916722 solver.cpp:218] Iteration 344000 (16.5412 iter/s, 30.2275s/500 iters), loss = 0.171197
I0829 15:09:08.047019 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.171202 (* 1 = 0.171202 loss)
I0829 15:09:08.047026 916722 sgd_solver.cpp:106] Iteration 344000, lr = 0.01
I0829 15:09:38.265527 916722 solver.cpp:218] Iteration 344500 (16.5461 iter/s, 30.2186s/500 iters), loss = 0.261057
I0829 15:09:38.265596 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.261063 (* 1 = 0.261063 loss)
I0829 15:09:38.265609 916722 sgd_solver.cpp:106] Iteration 344500, lr = 0.01
I0829 15:10:08.504684 916722 solver.cpp:218] Iteration 345000 (16.5349 iter/s, 30.2391s/500 iters), loss = 0.0635858
I0829 15:10:08.504741 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0635911 (* 1 = 0.0635911 loss)
I0829 15:10:08.504750 916722 sgd_solver.cpp:106] Iteration 345000, lr = 0.01
I0829 15:10:38.713853 916722 solver.cpp:218] Iteration 345500 (16.5513 iter/s, 30.2092s/500 iters), loss = 0.123469
I0829 15:10:38.713908 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.123474 (* 1 = 0.123474 loss)
I0829 15:10:38.713917 916722 sgd_solver.cpp:106] Iteration 345500, lr = 0.01
I0829 15:11:08.933993 916722 solver.cpp:218] Iteration 346000 (16.5453 iter/s, 30.2201s/500 iters), loss = 0.335852
I0829 15:11:08.934046 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.335857 (* 1 = 0.335857 loss)
I0829 15:11:08.934053 916722 sgd_solver.cpp:106] Iteration 346000, lr = 0.01
I0829 15:11:39.187578 916722 solver.cpp:218] Iteration 346500 (16.527 iter/s, 30.2536s/500 iters), loss = 0.29636
I0829 15:11:39.187633 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.296365 (* 1 = 0.296365 loss)
I0829 15:11:39.187641 916722 sgd_solver.cpp:106] Iteration 346500, lr = 0.01
I0829 15:12:09.438817 916722 solver.cpp:218] Iteration 347000 (16.5283 iter/s, 30.2512s/500 iters), loss = 0.472494
I0829 15:12:09.438870 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.4725 (* 1 = 0.4725 loss)
I0829 15:12:09.438879 916722 sgd_solver.cpp:106] Iteration 347000, lr = 0.01
I0829 15:12:39.649631 916722 solver.cpp:218] Iteration 347500 (16.5504 iter/s, 30.2108s/500 iters), loss = 0.22496
I0829 15:12:39.649683 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.224965 (* 1 = 0.224965 loss)
I0829 15:12:39.649693 916722 sgd_solver.cpp:106] Iteration 347500, lr = 0.01
I0829 15:13:09.869869 916722 solver.cpp:218] Iteration 348000 (16.5452 iter/s, 30.2202s/500 iters), loss = 0.0867162
I0829 15:13:09.869923 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0867211 (* 1 = 0.0867211 loss)
I0829 15:13:09.869932 916722 sgd_solver.cpp:106] Iteration 348000, lr = 0.01
I0829 15:13:40.082070 916722 solver.cpp:218] Iteration 348500 (16.5496 iter/s, 30.2122s/500 iters), loss = 0.166765
I0829 15:13:40.082121 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.16677 (* 1 = 0.16677 loss)
I0829 15:13:40.082130 916722 sgd_solver.cpp:106] Iteration 348500, lr = 0.01
I0829 15:14:10.314898 916722 solver.cpp:218] Iteration 349000 (16.5383 iter/s, 30.2328s/500 iters), loss = 0.0819486
I0829 15:14:10.314962 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0819539 (* 1 = 0.0819539 loss)
I0829 15:14:10.314971 916722 sgd_solver.cpp:106] Iteration 349000, lr = 0.01
I0829 15:14:40.528312 916722 solver.cpp:218] Iteration 349500 (16.5489 iter/s, 30.2134s/500 iters), loss = 0.281978
I0829 15:14:40.528374 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.281984 (* 1 = 0.281984 loss)
I0829 15:14:40.528383 916722 sgd_solver.cpp:106] Iteration 349500, lr = 0.01
I0829 15:15:10.680239 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_350000.caffemodel
I0829 15:15:10.699368 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_350000.solverstate
I0829 15:15:10.705480 916722 solver.cpp:330] Iteration 350000, Testing net (#0)
I0829 15:15:26.129024 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8625
I0829 15:15:26.129073 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.479458 (* 1 = 0.479458 loss)
I0829 15:15:26.187737 916722 solver.cpp:218] Iteration 350000 (10.9506 iter/s, 45.6594s/500 iters), loss = 0.0247816
I0829 15:15:26.187763 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0247872 (* 1 = 0.0247872 loss)
I0829 15:15:26.187772 916722 sgd_solver.cpp:106] Iteration 350000, lr = 0.01
I0829 15:15:56.122957 916722 solver.cpp:218] Iteration 350500 (16.7027 iter/s, 29.9352s/500 iters), loss = 0.0273595
I0829 15:15:56.123032 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0273649 (* 1 = 0.0273649 loss)
I0829 15:15:56.123040 916722 sgd_solver.cpp:106] Iteration 350500, lr = 0.01
I0829 15:16:26.163101 916722 solver.cpp:218] Iteration 351000 (16.6444 iter/s, 30.0401s/500 iters), loss = 0.0895076
I0829 15:16:26.163161 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0895131 (* 1 = 0.0895131 loss)
I0829 15:16:26.163168 916722 sgd_solver.cpp:106] Iteration 351000, lr = 0.01
I0829 15:16:56.236635 916722 solver.cpp:218] Iteration 351500 (16.6259 iter/s, 30.0735s/500 iters), loss = 0.189577
I0829 15:16:56.236696 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.189582 (* 1 = 0.189582 loss)
I0829 15:16:56.236704 916722 sgd_solver.cpp:106] Iteration 351500, lr = 0.01
I0829 15:17:26.316457 916722 solver.cpp:218] Iteration 352000 (16.6224 iter/s, 30.0798s/500 iters), loss = 0.276091
I0829 15:17:26.316515 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.276096 (* 1 = 0.276096 loss)
I0829 15:17:26.316524 916722 sgd_solver.cpp:106] Iteration 352000, lr = 0.01
I0829 15:17:56.397414 916722 solver.cpp:218] Iteration 352500 (16.6218 iter/s, 30.0809s/500 iters), loss = 0.376071
I0829 15:17:56.397469 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.376077 (* 1 = 0.376077 loss)
I0829 15:17:56.397478 916722 sgd_solver.cpp:106] Iteration 352500, lr = 0.01
I0829 15:18:26.499972 916722 solver.cpp:218] Iteration 353000 (16.6099 iter/s, 30.1026s/500 iters), loss = 0.357891
I0829 15:18:26.500041 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.357897 (* 1 = 0.357897 loss)
I0829 15:18:26.500048 916722 sgd_solver.cpp:106] Iteration 353000, lr = 0.01
I0829 15:18:56.610635 916722 solver.cpp:218] Iteration 353500 (16.6054 iter/s, 30.1106s/500 iters), loss = 0.232945
I0829 15:18:56.610692 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.232951 (* 1 = 0.232951 loss)
I0829 15:18:56.610699 916722 sgd_solver.cpp:106] Iteration 353500, lr = 0.01
I0829 15:19:26.736835 916722 solver.cpp:218] Iteration 354000 (16.5969 iter/s, 30.1262s/500 iters), loss = 0.316724
I0829 15:19:26.736896 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.31673 (* 1 = 0.31673 loss)
I0829 15:19:26.736904 916722 sgd_solver.cpp:106] Iteration 354000, lr = 0.01
I0829 15:19:56.882203 916722 solver.cpp:218] Iteration 354500 (16.5863 iter/s, 30.1454s/500 iters), loss = 0.199571
I0829 15:19:56.882261 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.199576 (* 1 = 0.199576 loss)
I0829 15:19:56.882269 916722 sgd_solver.cpp:106] Iteration 354500, lr = 0.01
I0829 15:20:27.027546 916722 solver.cpp:218] Iteration 355000 (16.5863 iter/s, 30.1453s/500 iters), loss = 0.561493
I0829 15:20:27.027606 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.561498 (* 1 = 0.561498 loss)
I0829 15:20:27.027616 916722 sgd_solver.cpp:106] Iteration 355000, lr = 0.01
I0829 15:20:57.192868 916722 solver.cpp:218] Iteration 355500 (16.5753 iter/s, 30.1653s/500 iters), loss = 0.234932
I0829 15:20:57.192930 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.234938 (* 1 = 0.234938 loss)
I0829 15:20:57.192939 916722 sgd_solver.cpp:106] Iteration 355500, lr = 0.01
I0829 15:21:27.364327 916722 solver.cpp:218] Iteration 356000 (16.572 iter/s, 30.1714s/500 iters), loss = 0.0615798
I0829 15:21:27.364387 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0615855 (* 1 = 0.0615855 loss)
I0829 15:21:27.364395 916722 sgd_solver.cpp:106] Iteration 356000, lr = 0.01
I0829 15:21:57.503123 916722 solver.cpp:218] Iteration 356500 (16.59 iter/s, 30.1385s/500 iters), loss = 0.16954
I0829 15:21:57.503185 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.169546 (* 1 = 0.169546 loss)
I0829 15:21:57.503193 916722 sgd_solver.cpp:106] Iteration 356500, lr = 0.01
I0829 15:22:27.667479 916722 solver.cpp:218] Iteration 357000 (16.576 iter/s, 30.1641s/500 iters), loss = 0.430885
I0829 15:22:27.667553 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.430891 (* 1 = 0.430891 loss)
I0829 15:22:27.667562 916722 sgd_solver.cpp:106] Iteration 357000, lr = 0.01
I0829 15:22:57.853682 916722 solver.cpp:218] Iteration 357500 (16.564 iter/s, 30.186s/500 iters), loss = 0.23404
I0829 15:22:57.853742 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.234046 (* 1 = 0.234046 loss)
I0829 15:22:57.853751 916722 sgd_solver.cpp:106] Iteration 357500, lr = 0.01
I0829 15:23:28.066223 916722 solver.cpp:218] Iteration 358000 (16.5495 iter/s, 30.2123s/500 iters), loss = 0.0421499
I0829 15:23:28.066288 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0421556 (* 1 = 0.0421556 loss)
I0829 15:23:28.066298 916722 sgd_solver.cpp:106] Iteration 358000, lr = 0.01
I0829 15:23:58.288570 916722 solver.cpp:218] Iteration 358500 (16.5442 iter/s, 30.2221s/500 iters), loss = 0.236687
I0829 15:23:58.288626 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.236693 (* 1 = 0.236693 loss)
I0829 15:23:58.288635 916722 sgd_solver.cpp:106] Iteration 358500, lr = 0.01
I0829 15:24:28.517655 916722 solver.cpp:218] Iteration 359000 (16.5405 iter/s, 30.2289s/500 iters), loss = 0.104242
I0829 15:24:28.517715 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104247 (* 1 = 0.104247 loss)
I0829 15:24:28.517724 916722 sgd_solver.cpp:106] Iteration 359000, lr = 0.01
I0829 15:24:58.741566 916722 solver.cpp:218] Iteration 359500 (16.5433 iter/s, 30.2237s/500 iters), loss = 0.107816
I0829 15:24:58.741622 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.107822 (* 1 = 0.107822 loss)
I0829 15:24:58.741631 916722 sgd_solver.cpp:106] Iteration 359500, lr = 0.01
I0829 15:25:28.963799 916722 solver.cpp:218] Iteration 360000 (16.5442 iter/s, 30.2221s/500 iters), loss = 0.248553
I0829 15:25:28.963860 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.248559 (* 1 = 0.248559 loss)
I0829 15:25:28.963868 916722 sgd_solver.cpp:106] Iteration 360000, lr = 0.01
I0829 15:25:59.239625 916722 solver.cpp:218] Iteration 360500 (16.5149 iter/s, 30.2757s/500 iters), loss = 0.479989
I0829 15:25:59.239686 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.479995 (* 1 = 0.479995 loss)
I0829 15:25:59.239693 916722 sgd_solver.cpp:106] Iteration 360500, lr = 0.01
I0829 15:26:29.437664 916722 solver.cpp:218] Iteration 361000 (16.5575 iter/s, 30.1979s/500 iters), loss = 0.303537
I0829 15:26:29.437726 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.303543 (* 1 = 0.303543 loss)
I0829 15:26:29.437734 916722 sgd_solver.cpp:106] Iteration 361000, lr = 0.01
I0829 15:26:59.652658 916722 solver.cpp:218] Iteration 361500 (16.5482 iter/s, 30.2148s/500 iters), loss = 0.159469
I0829 15:26:59.652719 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159475 (* 1 = 0.159475 loss)
I0829 15:26:59.652729 916722 sgd_solver.cpp:106] Iteration 361500, lr = 0.01
I0829 15:27:29.889109 916722 solver.cpp:218] Iteration 362000 (16.5364 iter/s, 30.2363s/500 iters), loss = 0.0830748
I0829 15:27:29.889170 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.083081 (* 1 = 0.083081 loss)
I0829 15:27:29.889178 916722 sgd_solver.cpp:106] Iteration 362000, lr = 0.01
I0829 15:28:00.126495 916722 solver.cpp:218] Iteration 362500 (16.5359 iter/s, 30.2372s/500 iters), loss = 0.104656
I0829 15:28:00.126549 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104662 (* 1 = 0.104662 loss)
I0829 15:28:00.126559 916722 sgd_solver.cpp:106] Iteration 362500, lr = 0.01
I0829 15:28:30.348740 916722 solver.cpp:218] Iteration 363000 (16.5442 iter/s, 30.2221s/500 iters), loss = 0.225498
I0829 15:28:30.348803 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.225505 (* 1 = 0.225505 loss)
I0829 15:28:30.348810 916722 sgd_solver.cpp:106] Iteration 363000, lr = 0.01
I0829 15:29:00.592252 916722 solver.cpp:218] Iteration 363500 (16.5325 iter/s, 30.2434s/500 iters), loss = 0.103417
I0829 15:29:00.592319 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.103424 (* 1 = 0.103424 loss)
I0829 15:29:00.592331 916722 sgd_solver.cpp:106] Iteration 363500, lr = 0.01
I0829 15:29:30.786636 916722 solver.cpp:218] Iteration 364000 (16.5594 iter/s, 30.1943s/500 iters), loss = 0.100014
I0829 15:29:30.786695 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.10002 (* 1 = 0.10002 loss)
I0829 15:29:30.786702 916722 sgd_solver.cpp:106] Iteration 364000, lr = 0.01
I0829 15:30:00.985409 916722 solver.cpp:218] Iteration 364500 (16.557 iter/s, 30.1987s/500 iters), loss = 0.0761951
I0829 15:30:00.985467 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0762018 (* 1 = 0.0762018 loss)
I0829 15:30:00.985476 916722 sgd_solver.cpp:106] Iteration 364500, lr = 0.01
I0829 15:30:31.194588 916722 solver.cpp:218] Iteration 365000 (16.5513 iter/s, 30.2091s/500 iters), loss = 0.140641
I0829 15:30:31.194644 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.140648 (* 1 = 0.140648 loss)
I0829 15:30:31.194653 916722 sgd_solver.cpp:106] Iteration 365000, lr = 0.01
I0829 15:31:01.415199 916722 solver.cpp:218] Iteration 365500 (16.5451 iter/s, 30.2205s/500 iters), loss = 0.149746
I0829 15:31:01.415261 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.149752 (* 1 = 0.149752 loss)
I0829 15:31:01.415269 916722 sgd_solver.cpp:106] Iteration 365500, lr = 0.01
I0829 15:31:31.631960 916722 solver.cpp:218] Iteration 366000 (16.5472 iter/s, 30.2167s/500 iters), loss = 0.246904
I0829 15:31:31.632021 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.24691 (* 1 = 0.24691 loss)
I0829 15:31:31.632030 916722 sgd_solver.cpp:106] Iteration 366000, lr = 0.01
I0829 15:32:01.854466 916722 solver.cpp:218] Iteration 366500 (16.544 iter/s, 30.2224s/500 iters), loss = 0.31364
I0829 15:32:01.854523 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.313646 (* 1 = 0.313646 loss)
I0829 15:32:01.854532 916722 sgd_solver.cpp:106] Iteration 366500, lr = 0.01
I0829 15:32:32.077883 916722 solver.cpp:218] Iteration 367000 (16.5435 iter/s, 30.2233s/500 iters), loss = 0.103045
I0829 15:32:32.077944 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.103052 (* 1 = 0.103052 loss)
I0829 15:32:32.077952 916722 sgd_solver.cpp:106] Iteration 367000, lr = 0.01
I0829 15:33:02.315179 916722 solver.cpp:218] Iteration 367500 (16.5359 iter/s, 30.2372s/500 iters), loss = 0.349327
I0829 15:33:02.315237 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.349333 (* 1 = 0.349333 loss)
I0829 15:33:02.315244 916722 sgd_solver.cpp:106] Iteration 367500, lr = 0.01
I0829 15:33:32.544970 916722 solver.cpp:218] Iteration 368000 (16.54 iter/s, 30.2297s/500 iters), loss = 0.328068
I0829 15:33:32.545032 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.328074 (* 1 = 0.328074 loss)
I0829 15:33:32.545039 916722 sgd_solver.cpp:106] Iteration 368000, lr = 0.01
I0829 15:34:02.768368 916722 solver.cpp:218] Iteration 368500 (16.5435 iter/s, 30.2233s/500 iters), loss = 0.417513
I0829 15:34:02.768429 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.417519 (* 1 = 0.417519 loss)
I0829 15:34:02.768450 916722 sgd_solver.cpp:106] Iteration 368500, lr = 0.01
I0829 15:34:33.035331 916722 solver.cpp:218] Iteration 369000 (16.5197 iter/s, 30.2669s/500 iters), loss = 0.286492
I0829 15:34:33.035396 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.286498 (* 1 = 0.286498 loss)
I0829 15:34:33.035405 916722 sgd_solver.cpp:106] Iteration 369000, lr = 0.01
I0829 15:35:03.253587 916722 solver.cpp:218] Iteration 369500 (16.5463 iter/s, 30.2182s/500 iters), loss = 0.219134
I0829 15:35:03.253643 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.21914 (* 1 = 0.21914 loss)
I0829 15:35:03.253652 916722 sgd_solver.cpp:106] Iteration 369500, lr = 0.01
I0829 15:35:33.475622 916722 solver.cpp:218] Iteration 370000 (16.5443 iter/s, 30.222s/500 iters), loss = 0.251742
I0829 15:35:33.475695 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.251749 (* 1 = 0.251749 loss)
I0829 15:35:33.475708 916722 sgd_solver.cpp:106] Iteration 370000, lr = 0.01
I0829 15:36:03.724033 916722 solver.cpp:218] Iteration 370500 (16.5298 iter/s, 30.2483s/500 iters), loss = 0.0397772
I0829 15:36:03.724089 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0397833 (* 1 = 0.0397833 loss)
I0829 15:36:03.724097 916722 sgd_solver.cpp:106] Iteration 370500, lr = 0.01
I0829 15:36:33.954710 916722 solver.cpp:218] Iteration 371000 (16.5395 iter/s, 30.2306s/500 iters), loss = 0.360627
I0829 15:36:33.954766 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.360633 (* 1 = 0.360633 loss)
I0829 15:36:33.954773 916722 sgd_solver.cpp:106] Iteration 371000, lr = 0.01
I0829 15:37:04.195768 916722 solver.cpp:218] Iteration 371500 (16.5339 iter/s, 30.241s/500 iters), loss = 0.0789842
I0829 15:37:04.195827 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0789903 (* 1 = 0.0789903 loss)
I0829 15:37:04.195835 916722 sgd_solver.cpp:106] Iteration 371500, lr = 0.01
I0829 15:37:34.437654 916722 solver.cpp:218] Iteration 372000 (16.5334 iter/s, 30.2418s/500 iters), loss = 0.0529281
I0829 15:37:34.437717 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0529345 (* 1 = 0.0529345 loss)
I0829 15:37:34.437726 916722 sgd_solver.cpp:106] Iteration 372000, lr = 0.01
I0829 15:38:04.672266 916722 solver.cpp:218] Iteration 372500 (16.5374 iter/s, 30.2345s/500 iters), loss = 0.138289
I0829 15:38:04.672329 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.138295 (* 1 = 0.138295 loss)
I0829 15:38:04.672338 916722 sgd_solver.cpp:106] Iteration 372500, lr = 0.01
I0829 15:38:34.920888 916722 solver.cpp:218] Iteration 373000 (16.5297 iter/s, 30.2486s/500 iters), loss = 0.290736
I0829 15:38:34.920949 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.290743 (* 1 = 0.290743 loss)
I0829 15:38:34.920958 916722 sgd_solver.cpp:106] Iteration 373000, lr = 0.01
I0829 15:39:05.163905 916722 solver.cpp:218] Iteration 373500 (16.5328 iter/s, 30.2429s/500 iters), loss = 0.201651
I0829 15:39:05.163966 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.201657 (* 1 = 0.201657 loss)
I0829 15:39:05.163975 916722 sgd_solver.cpp:106] Iteration 373500, lr = 0.01
I0829 15:39:35.428336 916722 solver.cpp:218] Iteration 374000 (16.5211 iter/s, 30.2644s/500 iters), loss = 0.0334218
I0829 15:39:35.428397 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0334282 (* 1 = 0.0334282 loss)
I0829 15:39:35.428406 916722 sgd_solver.cpp:106] Iteration 374000, lr = 0.01
I0829 15:40:05.666715 916722 solver.cpp:218] Iteration 374500 (16.5353 iter/s, 30.2383s/500 iters), loss = 0.223166
I0829 15:40:05.666772 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.223172 (* 1 = 0.223172 loss)
I0829 15:40:05.666780 916722 sgd_solver.cpp:106] Iteration 374500, lr = 0.01
I0829 15:40:35.907665 916722 solver.cpp:218] Iteration 375000 (16.5339 iter/s, 30.2409s/500 iters), loss = 0.145893
I0829 15:40:35.907721 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.1459 (* 1 = 0.1459 loss)
I0829 15:40:35.907730 916722 sgd_solver.cpp:106] Iteration 375000, lr = 0.01
I0829 15:41:06.155805 916722 solver.cpp:218] Iteration 375500 (16.53 iter/s, 30.2481s/500 iters), loss = 0.0912098
I0829 15:41:06.155865 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0912162 (* 1 = 0.0912162 loss)
I0829 15:41:06.155874 916722 sgd_solver.cpp:106] Iteration 375500, lr = 0.01
I0829 15:41:36.410548 916722 solver.cpp:218] Iteration 376000 (16.5264 iter/s, 30.2547s/500 iters), loss = 0.111861
I0829 15:41:36.410609 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111868 (* 1 = 0.111868 loss)
I0829 15:41:36.410617 916722 sgd_solver.cpp:106] Iteration 376000, lr = 0.01
I0829 15:42:06.652406 916722 solver.cpp:218] Iteration 376500 (16.5334 iter/s, 30.2418s/500 iters), loss = 0.131014
I0829 15:42:06.652472 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13102 (* 1 = 0.13102 loss)
I0829 15:42:06.652480 916722 sgd_solver.cpp:106] Iteration 376500, lr = 0.01
I0829 15:42:36.905910 916722 solver.cpp:218] Iteration 377000 (16.527 iter/s, 30.2534s/500 iters), loss = 0.130956
I0829 15:42:36.905977 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130962 (* 1 = 0.130962 loss)
I0829 15:42:36.905987 916722 sgd_solver.cpp:106] Iteration 377000, lr = 0.01
I0829 15:43:07.138954 916722 solver.cpp:218] Iteration 377500 (16.5382 iter/s, 30.233s/500 iters), loss = 0.0926758
I0829 15:43:07.139016 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0926822 (* 1 = 0.0926822 loss)
I0829 15:43:07.139025 916722 sgd_solver.cpp:106] Iteration 377500, lr = 0.01
I0829 15:43:37.379494 916722 solver.cpp:218] Iteration 378000 (16.5341 iter/s, 30.2405s/500 iters), loss = 0.352222
I0829 15:43:37.379554 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.352228 (* 1 = 0.352228 loss)
I0829 15:43:37.379562 916722 sgd_solver.cpp:106] Iteration 378000, lr = 0.01
I0829 15:44:07.604877 916722 solver.cpp:218] Iteration 378500 (16.5424 iter/s, 30.2253s/500 iters), loss = 0.196215
I0829 15:44:07.604936 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.196221 (* 1 = 0.196221 loss)
I0829 15:44:07.604944 916722 sgd_solver.cpp:106] Iteration 378500, lr = 0.01
I0829 15:44:37.838889 916722 solver.cpp:218] Iteration 379000 (16.5377 iter/s, 30.234s/500 iters), loss = 0.0526787
I0829 15:44:37.838950 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0526851 (* 1 = 0.0526851 loss)
I0829 15:44:37.838958 916722 sgd_solver.cpp:106] Iteration 379000, lr = 0.01
I0829 15:45:08.056922 916722 solver.cpp:218] Iteration 379500 (16.5464 iter/s, 30.218s/500 iters), loss = 0.0696758
I0829 15:45:08.056980 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.069682 (* 1 = 0.069682 loss)
I0829 15:45:08.056989 916722 sgd_solver.cpp:106] Iteration 379500, lr = 0.01
I0829 15:45:38.284837 916722 solver.cpp:218] Iteration 380000 (16.541 iter/s, 30.2279s/500 iters), loss = 0.26504
I0829 15:45:38.284898 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.265046 (* 1 = 0.265046 loss)
I0829 15:45:38.284905 916722 sgd_solver.cpp:106] Iteration 380000, lr = 0.01
I0829 15:46:08.515206 916722 solver.cpp:218] Iteration 380500 (16.5397 iter/s, 30.2303s/500 iters), loss = 0.118804
I0829 15:46:08.515264 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.11881 (* 1 = 0.11881 loss)
I0829 15:46:08.515272 916722 sgd_solver.cpp:106] Iteration 380500, lr = 0.01
I0829 15:46:38.761196 916722 solver.cpp:218] Iteration 381000 (16.5311 iter/s, 30.2459s/500 iters), loss = 0.118863
I0829 15:46:38.761258 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.118869 (* 1 = 0.118869 loss)
I0829 15:46:38.761266 916722 sgd_solver.cpp:106] Iteration 381000, lr = 0.01
I0829 15:47:08.968310 916722 solver.cpp:218] Iteration 381500 (16.5524 iter/s, 30.2071s/500 iters), loss = 0.476657
I0829 15:47:08.968370 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.476664 (* 1 = 0.476664 loss)
I0829 15:47:08.968379 916722 sgd_solver.cpp:106] Iteration 381500, lr = 0.01
I0829 15:47:39.200346 916722 solver.cpp:218] Iteration 382000 (16.5388 iter/s, 30.232s/500 iters), loss = 0.368238
I0829 15:47:39.200407 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.368244 (* 1 = 0.368244 loss)
I0829 15:47:39.200415 916722 sgd_solver.cpp:106] Iteration 382000, lr = 0.01
I0829 15:48:09.432512 916722 solver.cpp:218] Iteration 382500 (16.5387 iter/s, 30.2321s/500 iters), loss = 0.297408
I0829 15:48:09.432577 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.297414 (* 1 = 0.297414 loss)
I0829 15:48:09.432586 916722 sgd_solver.cpp:106] Iteration 382500, lr = 0.01
I0829 15:48:39.658354 916722 solver.cpp:218] Iteration 383000 (16.5422 iter/s, 30.2258s/500 iters), loss = 0.319723
I0829 15:48:39.658411 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.31973 (* 1 = 0.31973 loss)
I0829 15:48:39.658421 916722 sgd_solver.cpp:106] Iteration 383000, lr = 0.01
I0829 15:49:09.877919 916722 solver.cpp:218] Iteration 383500 (16.5456 iter/s, 30.2195s/500 iters), loss = 0.112633
I0829 15:49:09.877995 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112639 (* 1 = 0.112639 loss)
I0829 15:49:09.878003 916722 sgd_solver.cpp:106] Iteration 383500, lr = 0.01
I0829 15:49:40.105042 916722 solver.cpp:218] Iteration 384000 (16.5415 iter/s, 30.2271s/500 iters), loss = 0.153825
I0829 15:49:40.105103 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.153831 (* 1 = 0.153831 loss)
I0829 15:49:40.105113 916722 sgd_solver.cpp:106] Iteration 384000, lr = 0.01
I0829 15:50:10.339865 916722 solver.cpp:218] Iteration 384500 (16.5372 iter/s, 30.2348s/500 iters), loss = 0.0790777
I0829 15:50:10.339931 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0790844 (* 1 = 0.0790844 loss)
I0829 15:50:10.339938 916722 sgd_solver.cpp:106] Iteration 384500, lr = 0.01
I0829 15:50:40.562842 916722 solver.cpp:218] Iteration 385000 (16.5437 iter/s, 30.2229s/500 iters), loss = 0.0563793
I0829 15:50:40.562906 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0563859 (* 1 = 0.0563859 loss)
I0829 15:50:40.562914 916722 sgd_solver.cpp:106] Iteration 385000, lr = 0.01
I0829 15:51:10.794431 916722 solver.cpp:218] Iteration 385500 (16.539 iter/s, 30.2315s/500 iters), loss = 0.177868
I0829 15:51:10.794490 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.177875 (* 1 = 0.177875 loss)
I0829 15:51:10.794498 916722 sgd_solver.cpp:106] Iteration 385500, lr = 0.01
I0829 15:51:41.007961 916722 solver.cpp:218] Iteration 386000 (16.5489 iter/s, 30.2135s/500 iters), loss = 0.113505
I0829 15:51:41.008023 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.113511 (* 1 = 0.113511 loss)
I0829 15:51:41.008031 916722 sgd_solver.cpp:106] Iteration 386000, lr = 0.01
I0829 15:52:11.237491 916722 solver.cpp:218] Iteration 386500 (16.5401 iter/s, 30.2295s/500 iters), loss = 0.34512
I0829 15:52:11.237547 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.345127 (* 1 = 0.345127 loss)
I0829 15:52:11.237555 916722 sgd_solver.cpp:106] Iteration 386500, lr = 0.01
I0829 15:52:41.458349 916722 solver.cpp:218] Iteration 387000 (16.5449 iter/s, 30.2208s/500 iters), loss = 0.436185
I0829 15:52:41.458411 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.436192 (* 1 = 0.436192 loss)
I0829 15:52:41.458420 916722 sgd_solver.cpp:106] Iteration 387000, lr = 0.01
I0829 15:53:11.669771 916722 solver.cpp:218] Iteration 387500 (16.5501 iter/s, 30.2114s/500 iters), loss = 0.396069
I0829 15:53:11.669826 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.396075 (* 1 = 0.396075 loss)
I0829 15:53:11.669833 916722 sgd_solver.cpp:106] Iteration 387500, lr = 0.01
I0829 15:53:41.887212 916722 solver.cpp:218] Iteration 388000 (16.5468 iter/s, 30.2174s/500 iters), loss = 0.151073
I0829 15:53:41.887274 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.151079 (* 1 = 0.151079 loss)
I0829 15:53:41.887282 916722 sgd_solver.cpp:106] Iteration 388000, lr = 0.01
I0829 15:54:12.106076 916722 solver.cpp:218] Iteration 388500 (16.546 iter/s, 30.2188s/500 iters), loss = 0.261228
I0829 15:54:12.106137 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.261235 (* 1 = 0.261235 loss)
I0829 15:54:12.106144 916722 sgd_solver.cpp:106] Iteration 388500, lr = 0.01
I0829 15:54:42.339633 916722 solver.cpp:218] Iteration 389000 (16.5379 iter/s, 30.2335s/500 iters), loss = 0.125568
I0829 15:54:42.339694 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.125575 (* 1 = 0.125575 loss)
I0829 15:54:42.339702 916722 sgd_solver.cpp:106] Iteration 389000, lr = 0.01
I0829 15:55:12.568892 916722 solver.cpp:218] Iteration 389500 (16.5403 iter/s, 30.2292s/500 iters), loss = 0.0842818
I0829 15:55:12.568958 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0842881 (* 1 = 0.0842881 loss)
I0829 15:55:12.568966 916722 sgd_solver.cpp:106] Iteration 389500, lr = 0.01
I0829 15:55:42.799533 916722 solver.cpp:218] Iteration 390000 (16.5396 iter/s, 30.2304s/500 iters), loss = 0.143915
I0829 15:55:42.799604 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.143921 (* 1 = 0.143921 loss)
I0829 15:55:42.799623 916722 sgd_solver.cpp:106] Iteration 390000, lr = 0.01
I0829 15:56:13.036314 916722 solver.cpp:218] Iteration 390500 (16.5363 iter/s, 30.2364s/500 iters), loss = 0.1471
I0829 15:56:13.036371 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.147106 (* 1 = 0.147106 loss)
I0829 15:56:13.036379 916722 sgd_solver.cpp:106] Iteration 390500, lr = 0.01
I0829 15:56:43.287070 916722 solver.cpp:218] Iteration 391000 (16.5287 iter/s, 30.2504s/500 iters), loss = 0.0238955
I0829 15:56:43.287133 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.023902 (* 1 = 0.023902 loss)
I0829 15:56:43.287142 916722 sgd_solver.cpp:106] Iteration 391000, lr = 0.01
I0829 15:57:13.498315 916722 solver.cpp:218] Iteration 391500 (16.5503 iter/s, 30.2109s/500 iters), loss = 0.302169
I0829 15:57:13.498370 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.302175 (* 1 = 0.302175 loss)
I0829 15:57:13.498378 916722 sgd_solver.cpp:106] Iteration 391500, lr = 0.01
I0829 15:57:43.739322 916722 solver.cpp:218] Iteration 392000 (16.534 iter/s, 30.2407s/500 iters), loss = 0.194416
I0829 15:57:43.739382 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.194423 (* 1 = 0.194423 loss)
I0829 15:57:43.739390 916722 sgd_solver.cpp:106] Iteration 392000, lr = 0.01
I0829 15:58:13.973583 916722 solver.cpp:218] Iteration 392500 (16.5377 iter/s, 30.234s/500 iters), loss = 0.0465364
I0829 15:58:13.973646 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0465431 (* 1 = 0.0465431 loss)
I0829 15:58:13.973655 916722 sgd_solver.cpp:106] Iteration 392500, lr = 0.01
I0829 15:58:44.201772 916722 solver.cpp:218] Iteration 393000 (16.541 iter/s, 30.2279s/500 iters), loss = 0.165309
I0829 15:58:44.201833 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.165316 (* 1 = 0.165316 loss)
I0829 15:58:44.201841 916722 sgd_solver.cpp:106] Iteration 393000, lr = 0.01
I0829 15:59:14.435596 916722 solver.cpp:218] Iteration 393500 (16.5379 iter/s, 30.2336s/500 iters), loss = 0.392826
I0829 15:59:14.435657 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.392832 (* 1 = 0.392832 loss)
I0829 15:59:14.435667 916722 sgd_solver.cpp:106] Iteration 393500, lr = 0.01
I0829 15:59:44.661762 916722 solver.cpp:218] Iteration 394000 (16.5421 iter/s, 30.2259s/500 iters), loss = 0.0646741
I0829 15:59:44.661823 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0646802 (* 1 = 0.0646802 loss)
I0829 15:59:44.661831 916722 sgd_solver.cpp:106] Iteration 394000, lr = 0.01
I0829 16:00:14.908475 916722 solver.cpp:218] Iteration 394500 (16.5308 iter/s, 30.2465s/500 iters), loss = 0.136461
I0829 16:00:14.908535 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.136468 (* 1 = 0.136468 loss)
I0829 16:00:14.908542 916722 sgd_solver.cpp:106] Iteration 394500, lr = 0.01
I0829 16:00:45.159235 916722 solver.cpp:218] Iteration 395000 (16.5286 iter/s, 30.2505s/500 iters), loss = 0.0602241
I0829 16:00:45.159296 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0602303 (* 1 = 0.0602303 loss)
I0829 16:00:45.159303 916722 sgd_solver.cpp:106] Iteration 395000, lr = 0.01
I0829 16:01:15.381747 916722 solver.cpp:218] Iteration 395500 (16.5441 iter/s, 30.2223s/500 iters), loss = 0.139065
I0829 16:01:15.381808 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139071 (* 1 = 0.139071 loss)
I0829 16:01:15.381817 916722 sgd_solver.cpp:106] Iteration 395500, lr = 0.01
I0829 16:01:45.613438 916722 solver.cpp:218] Iteration 396000 (16.5391 iter/s, 30.2315s/500 iters), loss = 0.0660425
I0829 16:01:45.613495 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0660488 (* 1 = 0.0660488 loss)
I0829 16:01:45.613504 916722 sgd_solver.cpp:106] Iteration 396000, lr = 0.01
I0829 16:02:15.867409 916722 solver.cpp:218] Iteration 396500 (16.5269 iter/s, 30.2538s/500 iters), loss = 0.187255
I0829 16:02:15.867483 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.187261 (* 1 = 0.187261 loss)
I0829 16:02:15.867496 916722 sgd_solver.cpp:106] Iteration 396500, lr = 0.01
I0829 16:02:46.076684 916722 solver.cpp:218] Iteration 397000 (16.5513 iter/s, 30.2091s/500 iters), loss = 0.124453
I0829 16:02:46.076745 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.124459 (* 1 = 0.124459 loss)
I0829 16:02:46.076752 916722 sgd_solver.cpp:106] Iteration 397000, lr = 0.01
I0829 16:03:16.302572 916722 solver.cpp:218] Iteration 397500 (16.5422 iter/s, 30.2257s/500 iters), loss = 0.186493
I0829 16:03:16.302634 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.186499 (* 1 = 0.186499 loss)
I0829 16:03:16.302642 916722 sgd_solver.cpp:106] Iteration 397500, lr = 0.01
I0829 16:03:46.536707 916722 solver.cpp:218] Iteration 398000 (16.5377 iter/s, 30.234s/500 iters), loss = 0.157125
I0829 16:03:46.536760 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.157132 (* 1 = 0.157132 loss)
I0829 16:03:46.536768 916722 sgd_solver.cpp:106] Iteration 398000, lr = 0.01
I0829 16:04:16.774863 916722 solver.cpp:218] Iteration 398500 (16.5355 iter/s, 30.238s/500 iters), loss = 0.0528938
I0829 16:04:16.774924 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0529007 (* 1 = 0.0529007 loss)
I0829 16:04:16.774932 916722 sgd_solver.cpp:106] Iteration 398500, lr = 0.01
I0829 16:04:47.009843 916722 solver.cpp:218] Iteration 399000 (16.5372 iter/s, 30.2348s/500 iters), loss = 0.269254
I0829 16:04:47.009898 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.269261 (* 1 = 0.269261 loss)
I0829 16:04:47.009907 916722 sgd_solver.cpp:106] Iteration 399000, lr = 0.01
I0829 16:05:17.248893 916722 solver.cpp:218] Iteration 399500 (16.535 iter/s, 30.2389s/500 iters), loss = 0.0231784
I0829 16:05:17.248952 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0231854 (* 1 = 0.0231854 loss)
I0829 16:05:17.248960 916722 sgd_solver.cpp:106] Iteration 399500, lr = 0.01
I0829 16:05:47.439872 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_400000.caffemodel
I0829 16:05:47.459034 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_400000.solverstate
I0829 16:05:47.465133 916722 solver.cpp:330] Iteration 400000, Testing net (#0)
I0829 16:06:02.826428 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8592
I0829 16:06:02.826472 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.43858 (* 1 = 0.43858 loss)
I0829 16:06:02.885282 916722 solver.cpp:218] Iteration 400000 (10.9562 iter/s, 45.6362s/500 iters), loss = 0.327645
I0829 16:06:02.885309 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.327652 (* 1 = 0.327652 loss)
I0829 16:06:02.885318 916722 sgd_solver.cpp:106] Iteration 400000, lr = 0.01
I0829 16:06:32.874459 916722 solver.cpp:218] Iteration 400500 (16.6728 iter/s, 29.989s/500 iters), loss = 0.0589812
I0829 16:06:32.874523 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0589882 (* 1 = 0.0589882 loss)
I0829 16:06:32.874531 916722 sgd_solver.cpp:106] Iteration 400500, lr = 0.01
I0829 16:07:03.009805 916722 solver.cpp:218] Iteration 401000 (16.5919 iter/s, 30.1352s/500 iters), loss = 0.255968
I0829 16:07:03.009860 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.255975 (* 1 = 0.255975 loss)
I0829 16:07:03.009868 916722 sgd_solver.cpp:106] Iteration 401000, lr = 0.01
I0829 16:07:33.231190 916722 solver.cpp:218] Iteration 401500 (16.5447 iter/s, 30.2212s/500 iters), loss = 0.057175
I0829 16:07:33.231252 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.057182 (* 1 = 0.057182 loss)
I0829 16:07:33.231261 916722 sgd_solver.cpp:106] Iteration 401500, lr = 0.01
I0829 16:08:03.447994 916722 solver.cpp:218] Iteration 402000 (16.5472 iter/s, 30.2167s/500 iters), loss = 0.260762
I0829 16:08:03.448050 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.260769 (* 1 = 0.260769 loss)
I0829 16:08:03.448058 916722 sgd_solver.cpp:106] Iteration 402000, lr = 0.01
I0829 16:08:33.656462 916722 solver.cpp:218] Iteration 402500 (16.5517 iter/s, 30.2083s/500 iters), loss = 0.222312
I0829 16:08:33.656541 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.222319 (* 1 = 0.222319 loss)
I0829 16:08:33.656550 916722 sgd_solver.cpp:106] Iteration 402500, lr = 0.01
I0829 16:09:03.874249 916722 solver.cpp:218] Iteration 403000 (16.5466 iter/s, 30.2176s/500 iters), loss = 0.0404737
I0829 16:09:03.874301 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0404807 (* 1 = 0.0404807 loss)
I0829 16:09:03.874310 916722 sgd_solver.cpp:106] Iteration 403000, lr = 0.01
I0829 16:09:34.091672 916722 solver.cpp:218] Iteration 403500 (16.5468 iter/s, 30.2173s/500 iters), loss = 0.2372
I0829 16:09:34.091730 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.237207 (* 1 = 0.237207 loss)
I0829 16:09:34.091738 916722 sgd_solver.cpp:106] Iteration 403500, lr = 0.01
I0829 16:10:04.324172 916722 solver.cpp:218] Iteration 404000 (16.5386 iter/s, 30.2324s/500 iters), loss = 0.206726
I0829 16:10:04.324231 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.206733 (* 1 = 0.206733 loss)
I0829 16:10:04.324239 916722 sgd_solver.cpp:106] Iteration 404000, lr = 0.01
I0829 16:10:34.530951 916722 solver.cpp:218] Iteration 404500 (16.5526 iter/s, 30.2067s/500 iters), loss = 0.275942
I0829 16:10:34.531009 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.275949 (* 1 = 0.275949 loss)
I0829 16:10:34.531018 916722 sgd_solver.cpp:106] Iteration 404500, lr = 0.01
I0829 16:11:04.735524 916722 solver.cpp:218] Iteration 405000 (16.5538 iter/s, 30.2045s/500 iters), loss = 0.159575
I0829 16:11:04.735581 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159582 (* 1 = 0.159582 loss)
I0829 16:11:04.735589 916722 sgd_solver.cpp:106] Iteration 405000, lr = 0.01
I0829 16:11:34.953707 916722 solver.cpp:218] Iteration 405500 (16.5464 iter/s, 30.2181s/500 iters), loss = 0.227959
I0829 16:11:34.953770 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.227966 (* 1 = 0.227966 loss)
I0829 16:11:34.953778 916722 sgd_solver.cpp:106] Iteration 405500, lr = 0.01
I0829 16:12:05.174464 916722 solver.cpp:218] Iteration 406000 (16.545 iter/s, 30.2206s/500 iters), loss = 0.251843
I0829 16:12:05.174521 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.251849 (* 1 = 0.251849 loss)
I0829 16:12:05.174530 916722 sgd_solver.cpp:106] Iteration 406000, lr = 0.01
I0829 16:12:35.419531 916722 solver.cpp:218] Iteration 406500 (16.5317 iter/s, 30.245s/500 iters), loss = 0.525418
I0829 16:12:35.419595 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.525425 (* 1 = 0.525425 loss)
I0829 16:12:35.419602 916722 sgd_solver.cpp:106] Iteration 406500, lr = 0.01
I0829 16:13:05.627043 916722 solver.cpp:218] Iteration 407000 (16.5522 iter/s, 30.2074s/500 iters), loss = 0.152028
I0829 16:13:05.627107 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152034 (* 1 = 0.152034 loss)
I0829 16:13:05.627116 916722 sgd_solver.cpp:106] Iteration 407000, lr = 0.01
I0829 16:13:35.840023 916722 solver.cpp:218] Iteration 407500 (16.5492 iter/s, 30.2129s/500 iters), loss = 0.130635
I0829 16:13:35.840090 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130642 (* 1 = 0.130642 loss)
I0829 16:13:35.840098 916722 sgd_solver.cpp:106] Iteration 407500, lr = 0.01
I0829 16:14:06.041121 916722 solver.cpp:218] Iteration 408000 (16.5558 iter/s, 30.201s/500 iters), loss = 0.110418
I0829 16:14:06.041177 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110424 (* 1 = 0.110424 loss)
I0829 16:14:06.041185 916722 sgd_solver.cpp:106] Iteration 408000, lr = 0.01
I0829 16:14:36.265358 916722 solver.cpp:218] Iteration 408500 (16.5431 iter/s, 30.2241s/500 iters), loss = 0.221173
I0829 16:14:36.265419 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.22118 (* 1 = 0.22118 loss)
I0829 16:14:36.265429 916722 sgd_solver.cpp:106] Iteration 408500, lr = 0.01
I0829 16:15:06.456604 916722 solver.cpp:218] Iteration 409000 (16.5612 iter/s, 30.1911s/500 iters), loss = 0.0658557
I0829 16:15:06.456679 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0658624 (* 1 = 0.0658624 loss)
I0829 16:15:06.456688 916722 sgd_solver.cpp:106] Iteration 409000, lr = 0.01
I0829 16:15:36.661650 916722 solver.cpp:218] Iteration 409500 (16.5536 iter/s, 30.2049s/500 iters), loss = 0.267947
I0829 16:15:36.661710 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.267954 (* 1 = 0.267954 loss)
I0829 16:15:36.661720 916722 sgd_solver.cpp:106] Iteration 409500, lr = 0.01
I0829 16:16:06.890573 916722 solver.cpp:218] Iteration 410000 (16.5405 iter/s, 30.2288s/500 iters), loss = 0.133943
I0829 16:16:06.890632 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13395 (* 1 = 0.13395 loss)
I0829 16:16:06.890640 916722 sgd_solver.cpp:106] Iteration 410000, lr = 0.01
I0829 16:16:37.111310 916722 solver.cpp:218] Iteration 410500 (16.545 iter/s, 30.2206s/500 iters), loss = 0.0944709
I0829 16:16:37.111371 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0944778 (* 1 = 0.0944778 loss)
I0829 16:16:37.111378 916722 sgd_solver.cpp:106] Iteration 410500, lr = 0.01
I0829 16:17:07.312806 916722 solver.cpp:218] Iteration 411000 (16.5555 iter/s, 30.2014s/500 iters), loss = 0.107319
I0829 16:17:07.312865 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.107326 (* 1 = 0.107326 loss)
I0829 16:17:07.312873 916722 sgd_solver.cpp:106] Iteration 411000, lr = 0.01
I0829 16:17:37.538393 916722 solver.cpp:218] Iteration 411500 (16.5423 iter/s, 30.2255s/500 iters), loss = 0.218862
I0829 16:17:37.538452 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.218869 (* 1 = 0.218869 loss)
I0829 16:17:37.538460 916722 sgd_solver.cpp:106] Iteration 411500, lr = 0.01
I0829 16:18:07.741575 916722 solver.cpp:218] Iteration 412000 (16.5546 iter/s, 30.2031s/500 iters), loss = 0.101733
I0829 16:18:07.741636 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.10174 (* 1 = 0.10174 loss)
I0829 16:18:07.741644 916722 sgd_solver.cpp:106] Iteration 412000, lr = 0.01
I0829 16:18:37.954346 916722 solver.cpp:218] Iteration 412500 (16.5493 iter/s, 30.2127s/500 iters), loss = 0.123679
I0829 16:18:37.954402 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.123686 (* 1 = 0.123686 loss)
I0829 16:18:37.954411 916722 sgd_solver.cpp:106] Iteration 412500, lr = 0.01
I0829 16:19:08.152945 916722 solver.cpp:218] Iteration 413000 (16.5571 iter/s, 30.1985s/500 iters), loss = 0.0979982
I0829 16:19:08.153004 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0980051 (* 1 = 0.0980051 loss)
I0829 16:19:08.153013 916722 sgd_solver.cpp:106] Iteration 413000, lr = 0.01
I0829 16:19:38.352227 916722 solver.cpp:218] Iteration 413500 (16.5567 iter/s, 30.1992s/500 iters), loss = 0.345315
I0829 16:19:38.352281 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.345322 (* 1 = 0.345322 loss)
I0829 16:19:38.352289 916722 sgd_solver.cpp:106] Iteration 413500, lr = 0.01
I0829 16:20:08.558413 916722 solver.cpp:218] Iteration 414000 (16.5529 iter/s, 30.2061s/500 iters), loss = 0.0833255
I0829 16:20:08.558472 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0833325 (* 1 = 0.0833325 loss)
I0829 16:20:08.558480 916722 sgd_solver.cpp:106] Iteration 414000, lr = 0.01
I0829 16:20:38.753942 916722 solver.cpp:218] Iteration 414500 (16.5588 iter/s, 30.1954s/500 iters), loss = 0.441136
I0829 16:20:38.753999 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.441143 (* 1 = 0.441143 loss)
I0829 16:20:38.754009 916722 sgd_solver.cpp:106] Iteration 414500, lr = 0.01
I0829 16:21:08.976501 916722 solver.cpp:218] Iteration 415000 (16.544 iter/s, 30.2225s/500 iters), loss = 0.17668
I0829 16:21:08.976558 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.176687 (* 1 = 0.176687 loss)
I0829 16:21:08.976567 916722 sgd_solver.cpp:106] Iteration 415000, lr = 0.01
I0829 16:21:39.180106 916722 solver.cpp:218] Iteration 415500 (16.5544 iter/s, 30.2035s/500 iters), loss = 0.177137
I0829 16:21:39.180179 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.177144 (* 1 = 0.177144 loss)
I0829 16:21:39.180192 916722 sgd_solver.cpp:106] Iteration 415500, lr = 0.01
I0829 16:22:09.366379 916722 solver.cpp:218] Iteration 416000 (16.5639 iter/s, 30.1862s/500 iters), loss = 0.14903
I0829 16:22:09.366437 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.149037 (* 1 = 0.149037 loss)
I0829 16:22:09.366446 916722 sgd_solver.cpp:106] Iteration 416000, lr = 0.01
I0829 16:22:39.565224 916722 solver.cpp:218] Iteration 416500 (16.557 iter/s, 30.1988s/500 iters), loss = 0.481965
I0829 16:22:39.565285 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.481972 (* 1 = 0.481972 loss)
I0829 16:22:39.565294 916722 sgd_solver.cpp:106] Iteration 416500, lr = 0.01
I0829 16:23:09.754048 916722 solver.cpp:218] Iteration 417000 (16.5625 iter/s, 30.1887s/500 iters), loss = 0.278933
I0829 16:23:09.754107 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.27894 (* 1 = 0.27894 loss)
I0829 16:23:09.754115 916722 sgd_solver.cpp:106] Iteration 417000, lr = 0.01
I0829 16:23:39.963212 916722 solver.cpp:218] Iteration 417500 (16.5513 iter/s, 30.2091s/500 iters), loss = 0.276973
I0829 16:23:39.963271 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.27698 (* 1 = 0.27698 loss)
I0829 16:23:39.963280 916722 sgd_solver.cpp:106] Iteration 417500, lr = 0.01
I0829 16:24:10.152462 916722 solver.cpp:218] Iteration 418000 (16.5622 iter/s, 30.1892s/500 iters), loss = 0.154623
I0829 16:24:10.152520 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.15463 (* 1 = 0.15463 loss)
I0829 16:24:10.152529 916722 sgd_solver.cpp:106] Iteration 418000, lr = 0.01
I0829 16:24:40.345265 916722 solver.cpp:218] Iteration 418500 (16.5603 iter/s, 30.1927s/500 iters), loss = 0.269843
I0829 16:24:40.345326 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.269851 (* 1 = 0.269851 loss)
I0829 16:24:40.345335 916722 sgd_solver.cpp:106] Iteration 418500, lr = 0.01
I0829 16:25:10.561576 916722 solver.cpp:218] Iteration 419000 (16.5474 iter/s, 30.2162s/500 iters), loss = 0.0721899
I0829 16:25:10.561640 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0721973 (* 1 = 0.0721973 loss)
I0829 16:25:10.561648 916722 sgd_solver.cpp:106] Iteration 419000, lr = 0.01
I0829 16:25:40.748260 916722 solver.cpp:218] Iteration 419500 (16.5636 iter/s, 30.1866s/500 iters), loss = 0.175665
I0829 16:25:40.748315 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.175672 (* 1 = 0.175672 loss)
I0829 16:25:40.748323 916722 sgd_solver.cpp:106] Iteration 419500, lr = 0.01
I0829 16:26:10.960861 916722 solver.cpp:218] Iteration 420000 (16.5494 iter/s, 30.2125s/500 iters), loss = 0.116961
I0829 16:26:10.960922 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.116968 (* 1 = 0.116968 loss)
I0829 16:26:10.960929 916722 sgd_solver.cpp:106] Iteration 420000, lr = 0.01
I0829 16:26:41.158949 916722 solver.cpp:218] Iteration 420500 (16.5574 iter/s, 30.198s/500 iters), loss = 0.163474
I0829 16:26:41.159010 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.163482 (* 1 = 0.163482 loss)
I0829 16:26:41.159018 916722 sgd_solver.cpp:106] Iteration 420500, lr = 0.01
I0829 16:27:11.367092 916722 solver.cpp:218] Iteration 421000 (16.5519 iter/s, 30.2081s/500 iters), loss = 0.248933
I0829 16:27:11.367151 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.24894 (* 1 = 0.24894 loss)
I0829 16:27:11.367159 916722 sgd_solver.cpp:106] Iteration 421000, lr = 0.01
I0829 16:27:41.565860 916722 solver.cpp:218] Iteration 421500 (16.557 iter/s, 30.1987s/500 iters), loss = 0.174222
I0829 16:27:41.565922 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.17423 (* 1 = 0.17423 loss)
I0829 16:27:41.565929 916722 sgd_solver.cpp:106] Iteration 421500, lr = 0.01
I0829 16:28:11.774314 916722 solver.cpp:218] Iteration 422000 (16.5517 iter/s, 30.2084s/500 iters), loss = 0.166707
I0829 16:28:11.774371 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.166714 (* 1 = 0.166714 loss)
I0829 16:28:11.774379 916722 sgd_solver.cpp:106] Iteration 422000, lr = 0.01
I0829 16:28:41.985237 916722 solver.cpp:218] Iteration 422500 (16.5503 iter/s, 30.2108s/500 iters), loss = 0.0402917
I0829 16:28:41.985309 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0402994 (* 1 = 0.0402994 loss)
I0829 16:28:41.985318 916722 sgd_solver.cpp:106] Iteration 422500, lr = 0.01
I0829 16:29:12.209564 916722 solver.cpp:218] Iteration 423000 (16.543 iter/s, 30.2242s/500 iters), loss = 0.0340107
I0829 16:29:12.209621 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0340186 (* 1 = 0.0340186 loss)
I0829 16:29:12.209630 916722 sgd_solver.cpp:106] Iteration 423000, lr = 0.01
I0829 16:29:42.429530 916722 solver.cpp:218] Iteration 423500 (16.5454 iter/s, 30.2199s/500 iters), loss = 0.15962
I0829 16:29:42.429592 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159628 (* 1 = 0.159628 loss)
I0829 16:29:42.429600 916722 sgd_solver.cpp:106] Iteration 423500, lr = 0.01
I0829 16:30:12.611275 916722 solver.cpp:218] Iteration 424000 (16.5663 iter/s, 30.1817s/500 iters), loss = 0.0117274
I0829 16:30:12.611336 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0117354 (* 1 = 0.0117354 loss)
I0829 16:30:12.611344 916722 sgd_solver.cpp:106] Iteration 424000, lr = 0.01
I0829 16:30:42.825328 916722 solver.cpp:218] Iteration 424500 (16.5486 iter/s, 30.214s/500 iters), loss = 0.30455
I0829 16:30:42.825388 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.304558 (* 1 = 0.304558 loss)
I0829 16:30:42.825397 916722 sgd_solver.cpp:106] Iteration 424500, lr = 0.01
I0829 16:31:13.015717 916722 solver.cpp:218] Iteration 425000 (16.5616 iter/s, 30.1904s/500 iters), loss = 0.193537
I0829 16:31:13.015775 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.193545 (* 1 = 0.193545 loss)
I0829 16:31:13.015784 916722 sgd_solver.cpp:106] Iteration 425000, lr = 0.01
I0829 16:31:43.217226 916722 solver.cpp:218] Iteration 425500 (16.5555 iter/s, 30.2015s/500 iters), loss = 0.161518
I0829 16:31:43.217285 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.161526 (* 1 = 0.161526 loss)
I0829 16:31:43.217293 916722 sgd_solver.cpp:106] Iteration 425500, lr = 0.01
I0829 16:32:13.406077 916722 solver.cpp:218] Iteration 426000 (16.5624 iter/s, 30.1888s/500 iters), loss = 0.240075
I0829 16:32:13.406137 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.240083 (* 1 = 0.240083 loss)
I0829 16:32:13.406145 916722 sgd_solver.cpp:106] Iteration 426000, lr = 0.01
I0829 16:32:43.604696 916722 solver.cpp:218] Iteration 426500 (16.5571 iter/s, 30.1986s/500 iters), loss = 0.0656318
I0829 16:32:43.604768 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0656395 (* 1 = 0.0656395 loss)
I0829 16:32:43.604776 916722 sgd_solver.cpp:106] Iteration 426500, lr = 0.01
I0829 16:33:13.811785 916722 solver.cpp:218] Iteration 427000 (16.5524 iter/s, 30.2071s/500 iters), loss = 0.0805309
I0829 16:33:13.811847 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0805386 (* 1 = 0.0805386 loss)
I0829 16:33:13.811856 916722 sgd_solver.cpp:106] Iteration 427000, lr = 0.01
I0829 16:33:44.020475 916722 solver.cpp:218] Iteration 427500 (16.5515 iter/s, 30.2087s/500 iters), loss = 0.250869
I0829 16:33:44.020539 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.250877 (* 1 = 0.250877 loss)
I0829 16:33:44.020547 916722 sgd_solver.cpp:106] Iteration 427500, lr = 0.01
I0829 16:34:14.220185 916722 solver.cpp:218] Iteration 428000 (16.5565 iter/s, 30.1997s/500 iters), loss = 0.134638
I0829 16:34:14.220247 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.134645 (* 1 = 0.134645 loss)
I0829 16:34:14.220255 916722 sgd_solver.cpp:106] Iteration 428000, lr = 0.01
I0829 16:34:44.439875 916722 solver.cpp:218] Iteration 428500 (16.5455 iter/s, 30.2197s/500 iters), loss = 0.232073
I0829 16:34:44.439934 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.232081 (* 1 = 0.232081 loss)
I0829 16:34:44.439942 916722 sgd_solver.cpp:106] Iteration 428500, lr = 0.01
I0829 16:35:14.676437 916722 solver.cpp:218] Iteration 429000 (16.5363 iter/s, 30.2365s/500 iters), loss = 0.246893
I0829 16:35:14.676527 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.246901 (* 1 = 0.246901 loss)
I0829 16:35:14.676535 916722 sgd_solver.cpp:106] Iteration 429000, lr = 0.01
I0829 16:35:44.891501 916722 solver.cpp:218] Iteration 429500 (16.5481 iter/s, 30.215s/500 iters), loss = 0.290282
I0829 16:35:44.891566 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.29029 (* 1 = 0.29029 loss)
I0829 16:35:44.891574 916722 sgd_solver.cpp:106] Iteration 429500, lr = 0.01
I0829 16:36:15.121165 916722 solver.cpp:218] Iteration 430000 (16.5401 iter/s, 30.2296s/500 iters), loss = 0.50054
I0829 16:36:15.121223 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.500548 (* 1 = 0.500548 loss)
I0829 16:36:15.121232 916722 sgd_solver.cpp:106] Iteration 430000, lr = 0.01
I0829 16:36:45.337813 916722 solver.cpp:218] Iteration 430500 (16.5472 iter/s, 30.2166s/500 iters), loss = 0.317782
I0829 16:36:45.337872 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.317791 (* 1 = 0.317791 loss)
I0829 16:36:45.337880 916722 sgd_solver.cpp:106] Iteration 430500, lr = 0.01
I0829 16:37:15.541941 916722 solver.cpp:218] Iteration 431000 (16.554 iter/s, 30.2041s/500 iters), loss = 0.243749
I0829 16:37:15.541994 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.243757 (* 1 = 0.243757 loss)
I0829 16:37:15.542002 916722 sgd_solver.cpp:106] Iteration 431000, lr = 0.01
I0829 16:37:45.738507 916722 solver.cpp:218] Iteration 431500 (16.5582 iter/s, 30.1965s/500 iters), loss = 0.23961
I0829 16:37:45.738565 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.239618 (* 1 = 0.239618 loss)
I0829 16:37:45.738574 916722 sgd_solver.cpp:106] Iteration 431500, lr = 0.01
I0829 16:38:15.954501 916722 solver.cpp:218] Iteration 432000 (16.5475 iter/s, 30.216s/500 iters), loss = 0.365597
I0829 16:38:15.954562 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.365605 (* 1 = 0.365605 loss)
I0829 16:38:15.954571 916722 sgd_solver.cpp:106] Iteration 432000, lr = 0.01
I0829 16:38:46.184805 916722 solver.cpp:218] Iteration 432500 (16.5397 iter/s, 30.2303s/500 iters), loss = 0.237173
I0829 16:38:46.184864 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.23718 (* 1 = 0.23718 loss)
I0829 16:38:46.184871 916722 sgd_solver.cpp:106] Iteration 432500, lr = 0.01
I0829 16:39:16.392659 916722 solver.cpp:218] Iteration 433000 (16.552 iter/s, 30.2078s/500 iters), loss = 0.0694016
I0829 16:39:16.392720 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0694093 (* 1 = 0.0694093 loss)
I0829 16:39:16.392729 916722 sgd_solver.cpp:106] Iteration 433000, lr = 0.01
I0829 16:39:46.593515 916722 solver.cpp:218] Iteration 433500 (16.5558 iter/s, 30.2008s/500 iters), loss = 0.240532
I0829 16:39:46.593570 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.24054 (* 1 = 0.24054 loss)
I0829 16:39:46.593578 916722 sgd_solver.cpp:106] Iteration 433500, lr = 0.01
I0829 16:40:16.820749 916722 solver.cpp:218] Iteration 434000 (16.5414 iter/s, 30.2272s/500 iters), loss = 0.221537
I0829 16:40:16.820808 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.221545 (* 1 = 0.221545 loss)
I0829 16:40:16.820816 916722 sgd_solver.cpp:106] Iteration 434000, lr = 0.01
I0829 16:40:47.037422 916722 solver.cpp:218] Iteration 434500 (16.5472 iter/s, 30.2166s/500 iters), loss = 0.242746
I0829 16:40:47.037477 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.242754 (* 1 = 0.242754 loss)
I0829 16:40:47.037485 916722 sgd_solver.cpp:106] Iteration 434500, lr = 0.01
I0829 16:41:17.238490 916722 solver.cpp:218] Iteration 435000 (16.5557 iter/s, 30.201s/500 iters), loss = 0.0689305
I0829 16:41:17.238551 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0689383 (* 1 = 0.0689383 loss)
I0829 16:41:17.238560 916722 sgd_solver.cpp:106] Iteration 435000, lr = 0.01
I0829 16:41:47.443869 916722 solver.cpp:218] Iteration 435500 (16.5534 iter/s, 30.2053s/500 iters), loss = 0.339221
I0829 16:41:47.443943 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.339228 (* 1 = 0.339228 loss)
I0829 16:41:47.443959 916722 sgd_solver.cpp:106] Iteration 435500, lr = 0.01
I0829 16:42:17.638137 916722 solver.cpp:218] Iteration 436000 (16.5595 iter/s, 30.1942s/500 iters), loss = 0.0337813
I0829 16:42:17.638196 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0337891 (* 1 = 0.0337891 loss)
I0829 16:42:17.638206 916722 sgd_solver.cpp:106] Iteration 436000, lr = 0.01
I0829 16:42:47.851517 916722 solver.cpp:218] Iteration 436500 (16.549 iter/s, 30.2133s/500 iters), loss = 0.169148
I0829 16:42:47.851578 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.169156 (* 1 = 0.169156 loss)
I0829 16:42:47.851586 916722 sgd_solver.cpp:106] Iteration 436500, lr = 0.01
I0829 16:43:18.047268 916722 solver.cpp:218] Iteration 437000 (16.5587 iter/s, 30.1957s/500 iters), loss = 0.0634484
I0829 16:43:18.047328 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0634562 (* 1 = 0.0634562 loss)
I0829 16:43:18.047336 916722 sgd_solver.cpp:106] Iteration 437000, lr = 0.01
I0829 16:43:48.257320 916722 solver.cpp:218] Iteration 437500 (16.5508 iter/s, 30.21s/500 iters), loss = 0.396941
I0829 16:43:48.257380 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.396949 (* 1 = 0.396949 loss)
I0829 16:43:48.257388 916722 sgd_solver.cpp:106] Iteration 437500, lr = 0.01
I0829 16:44:18.448855 916722 solver.cpp:218] Iteration 438000 (16.561 iter/s, 30.1915s/500 iters), loss = 0.139199
I0829 16:44:18.448910 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139207 (* 1 = 0.139207 loss)
I0829 16:44:18.448918 916722 sgd_solver.cpp:106] Iteration 438000, lr = 0.01
I0829 16:44:48.632496 916722 solver.cpp:218] Iteration 438500 (16.5653 iter/s, 30.1836s/500 iters), loss = 0.202531
I0829 16:44:48.632555 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.202539 (* 1 = 0.202539 loss)
I0829 16:44:48.632563 916722 sgd_solver.cpp:106] Iteration 438500, lr = 0.01
I0829 16:45:18.814690 916722 solver.cpp:218] Iteration 439000 (16.5661 iter/s, 30.1821s/500 iters), loss = 0.399637
I0829 16:45:18.814746 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.399645 (* 1 = 0.399645 loss)
I0829 16:45:18.814754 916722 sgd_solver.cpp:106] Iteration 439000, lr = 0.01
I0829 16:45:49.009269 916722 solver.cpp:218] Iteration 439500 (16.5593 iter/s, 30.1945s/500 iters), loss = 0.221466
I0829 16:45:49.009328 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.221474 (* 1 = 0.221474 loss)
I0829 16:45:49.009336 916722 sgd_solver.cpp:106] Iteration 439500, lr = 0.01
I0829 16:46:19.194104 916722 solver.cpp:218] Iteration 440000 (16.5646 iter/s, 30.1848s/500 iters), loss = 0.222455
I0829 16:46:19.194160 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.222462 (* 1 = 0.222462 loss)
I0829 16:46:19.194169 916722 sgd_solver.cpp:106] Iteration 440000, lr = 0.01
I0829 16:46:49.392673 916722 solver.cpp:218] Iteration 440500 (16.5571 iter/s, 30.1985s/500 iters), loss = 0.290307
I0829 16:46:49.392731 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.290315 (* 1 = 0.290315 loss)
I0829 16:46:49.392740 916722 sgd_solver.cpp:106] Iteration 440500, lr = 0.01
I0829 16:47:19.576571 916722 solver.cpp:218] Iteration 441000 (16.5652 iter/s, 30.1838s/500 iters), loss = 0.128553
I0829 16:47:19.576629 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128561 (* 1 = 0.128561 loss)
I0829 16:47:19.576637 916722 sgd_solver.cpp:106] Iteration 441000, lr = 0.01
I0829 16:47:49.757807 916722 solver.cpp:218] Iteration 441500 (16.5666 iter/s, 30.1812s/500 iters), loss = 0.442573
I0829 16:47:49.757865 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.442581 (* 1 = 0.442581 loss)
I0829 16:47:49.757874 916722 sgd_solver.cpp:106] Iteration 441500, lr = 0.01
I0829 16:48:19.943667 916722 solver.cpp:218] Iteration 442000 (16.5641 iter/s, 30.1858s/500 iters), loss = 0.0370749
I0829 16:48:19.943735 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0370825 (* 1 = 0.0370825 loss)
I0829 16:48:19.943748 916722 sgd_solver.cpp:106] Iteration 442000, lr = 0.01
I0829 16:48:50.123497 916722 solver.cpp:218] Iteration 442500 (16.5674 iter/s, 30.1798s/500 iters), loss = 0.164293
I0829 16:48:50.123555 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.164301 (* 1 = 0.164301 loss)
I0829 16:48:50.123564 916722 sgd_solver.cpp:106] Iteration 442500, lr = 0.01
I0829 16:49:20.310101 916722 solver.cpp:218] Iteration 443000 (16.5637 iter/s, 30.1865s/500 iters), loss = 0.0739436
I0829 16:49:20.310155 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0739513 (* 1 = 0.0739513 loss)
I0829 16:49:20.310163 916722 sgd_solver.cpp:106] Iteration 443000, lr = 0.01
I0829 16:49:50.479475 916722 solver.cpp:218] Iteration 443500 (16.5731 iter/s, 30.1693s/500 iters), loss = 0.207596
I0829 16:49:50.479537 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.207604 (* 1 = 0.207604 loss)
I0829 16:49:50.479544 916722 sgd_solver.cpp:106] Iteration 443500, lr = 0.01
I0829 16:50:20.654497 916722 solver.cpp:218] Iteration 444000 (16.57 iter/s, 30.175s/500 iters), loss = 0.0927765
I0829 16:50:20.654552 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0927843 (* 1 = 0.0927843 loss)
I0829 16:50:20.654561 916722 sgd_solver.cpp:106] Iteration 444000, lr = 0.01
I0829 16:50:50.815333 916722 solver.cpp:218] Iteration 444500 (16.5778 iter/s, 30.1608s/500 iters), loss = 0.307352
I0829 16:50:50.815395 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.30736 (* 1 = 0.30736 loss)
I0829 16:50:50.815404 916722 sgd_solver.cpp:106] Iteration 444500, lr = 0.01
I0829 16:51:20.991207 916722 solver.cpp:218] Iteration 445000 (16.5696 iter/s, 30.1758s/500 iters), loss = 0.130524
I0829 16:51:20.991264 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130532 (* 1 = 0.130532 loss)
I0829 16:51:20.991272 916722 sgd_solver.cpp:106] Iteration 445000, lr = 0.01
I0829 16:51:51.137270 916722 solver.cpp:218] Iteration 445500 (16.5859 iter/s, 30.146s/500 iters), loss = 0.460678
I0829 16:51:51.137329 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.460686 (* 1 = 0.460686 loss)
I0829 16:51:51.137337 916722 sgd_solver.cpp:106] Iteration 445500, lr = 0.01
I0829 16:52:21.287674 916722 solver.cpp:218] Iteration 446000 (16.5836 iter/s, 30.1503s/500 iters), loss = 0.249774
I0829 16:52:21.287727 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.249782 (* 1 = 0.249782 loss)
I0829 16:52:21.287735 916722 sgd_solver.cpp:106] Iteration 446000, lr = 0.01
I0829 16:52:51.437000 916722 solver.cpp:218] Iteration 446500 (16.5842 iter/s, 30.1493s/500 iters), loss = 0.210579
I0829 16:52:51.437058 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.210587 (* 1 = 0.210587 loss)
I0829 16:52:51.437067 916722 sgd_solver.cpp:106] Iteration 446500, lr = 0.01
I0829 16:53:21.584251 916722 solver.cpp:218] Iteration 447000 (16.5853 iter/s, 30.1472s/500 iters), loss = 0.169258
I0829 16:53:21.584307 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.169266 (* 1 = 0.169266 loss)
I0829 16:53:21.584316 916722 sgd_solver.cpp:106] Iteration 447000, lr = 0.01
I0829 16:53:51.724212 916722 solver.cpp:218] Iteration 447500 (16.5893 iter/s, 30.1399s/500 iters), loss = 0.105959
I0829 16:53:51.724269 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105968 (* 1 = 0.105968 loss)
I0829 16:53:51.724277 916722 sgd_solver.cpp:106] Iteration 447500, lr = 0.01
I0829 16:54:21.887104 916722 solver.cpp:218] Iteration 448000 (16.5767 iter/s, 30.1628s/500 iters), loss = 0.0316846
I0829 16:54:21.887158 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0316932 (* 1 = 0.0316932 loss)
I0829 16:54:21.887167 916722 sgd_solver.cpp:106] Iteration 448000, lr = 0.01
I0829 16:54:52.044400 916722 solver.cpp:218] Iteration 448500 (16.5798 iter/s, 30.1572s/500 iters), loss = 0.230131
I0829 16:54:52.044474 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.23014 (* 1 = 0.23014 loss)
I0829 16:54:52.044483 916722 sgd_solver.cpp:106] Iteration 448500, lr = 0.01
I0829 16:55:22.207834 916722 solver.cpp:218] Iteration 449000 (16.5764 iter/s, 30.1634s/500 iters), loss = 0.106939
I0829 16:55:22.207901 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.106948 (* 1 = 0.106948 loss)
I0829 16:55:22.207909 916722 sgd_solver.cpp:106] Iteration 449000, lr = 0.01
I0829 16:55:52.365279 916722 solver.cpp:218] Iteration 449500 (16.5797 iter/s, 30.1574s/500 iters), loss = 0.106796
I0829 16:55:52.365332 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.106805 (* 1 = 0.106805 loss)
I0829 16:55:52.365340 916722 sgd_solver.cpp:106] Iteration 449500, lr = 0.01
I0829 16:56:22.470899 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_450000.caffemodel
I0829 16:56:22.489957 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_450000.solverstate
I0829 16:56:22.496080 916722 solver.cpp:330] Iteration 450000, Testing net (#0)
I0829 16:56:24.640050 916722 blocking_queue.cpp:49] Waiting for data
I0829 16:56:37.912845 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8604
I0829 16:56:37.912890 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.449075 (* 1 = 0.449075 loss)
I0829 16:56:37.971611 916722 solver.cpp:218] Iteration 450000 (10.9634 iter/s, 45.6063s/500 iters), loss = 0.199575
I0829 16:56:37.971637 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.199583 (* 1 = 0.199583 loss)
I0829 16:56:37.971645 916722 sgd_solver.cpp:106] Iteration 450000, lr = 0.01
I0829 16:57:07.902938 916722 solver.cpp:218] Iteration 450500 (16.7049 iter/s, 29.9313s/500 iters), loss = 0.0879802
I0829 16:57:07.902997 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0879884 (* 1 = 0.0879884 loss)
I0829 16:57:07.903005 916722 sgd_solver.cpp:106] Iteration 450500, lr = 0.01
I0829 16:57:37.961872 916722 solver.cpp:218] Iteration 451000 (16.634 iter/s, 30.0589s/500 iters), loss = 0.19668
I0829 16:57:37.961935 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.196688 (* 1 = 0.196688 loss)
I0829 16:57:37.961942 916722 sgd_solver.cpp:106] Iteration 451000, lr = 0.01
I0829 16:58:08.060264 916722 solver.cpp:218] Iteration 451500 (16.6122 iter/s, 30.0983s/500 iters), loss = 0.224187
I0829 16:58:08.060322 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.224195 (* 1 = 0.224195 loss)
I0829 16:58:08.060331 916722 sgd_solver.cpp:106] Iteration 451500, lr = 0.01
I0829 16:58:38.151059 916722 solver.cpp:218] Iteration 452000 (16.6164 iter/s, 30.0907s/500 iters), loss = 0.098463
I0829 16:58:38.151124 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0984712 (* 1 = 0.0984712 loss)
I0829 16:58:38.151132 916722 sgd_solver.cpp:106] Iteration 452000, lr = 0.01
I0829 16:59:08.212400 916722 solver.cpp:218] Iteration 452500 (16.6327 iter/s, 30.0613s/500 iters), loss = 0.207394
I0829 16:59:08.212478 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.207402 (* 1 = 0.207402 loss)
I0829 16:59:08.212487 916722 sgd_solver.cpp:106] Iteration 452500, lr = 0.01
I0829 16:59:38.271776 916722 solver.cpp:218] Iteration 453000 (16.6338 iter/s, 30.0593s/500 iters), loss = 0.237278
I0829 16:59:38.271837 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.237286 (* 1 = 0.237286 loss)
I0829 16:59:38.271845 916722 sgd_solver.cpp:106] Iteration 453000, lr = 0.01
I0829 17:00:08.365849 916722 solver.cpp:218] Iteration 453500 (16.6146 iter/s, 30.094s/500 iters), loss = 0.0614272
I0829 17:00:08.365911 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0614356 (* 1 = 0.0614356 loss)
I0829 17:00:08.365919 916722 sgd_solver.cpp:106] Iteration 453500, lr = 0.01
I0829 17:00:38.426399 916722 solver.cpp:218] Iteration 454000 (16.6331 iter/s, 30.0605s/500 iters), loss = 0.0759469
I0829 17:00:38.426460 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0759553 (* 1 = 0.0759553 loss)
I0829 17:00:38.426468 916722 sgd_solver.cpp:106] Iteration 454000, lr = 0.01
I0829 17:01:08.497670 916722 solver.cpp:218] Iteration 454500 (16.6272 iter/s, 30.0712s/500 iters), loss = 0.256447
I0829 17:01:08.497740 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.256455 (* 1 = 0.256455 loss)
I0829 17:01:08.497750 916722 sgd_solver.cpp:106] Iteration 454500, lr = 0.01
I0829 17:01:38.583556 916722 solver.cpp:218] Iteration 455000 (16.6191 iter/s, 30.0858s/500 iters), loss = 0.506566
I0829 17:01:38.583611 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.506575 (* 1 = 0.506575 loss)
I0829 17:01:38.583619 916722 sgd_solver.cpp:106] Iteration 455000, lr = 0.01
I0829 17:02:08.663735 916722 solver.cpp:218] Iteration 455500 (16.6223 iter/s, 30.0801s/500 iters), loss = 0.297058
I0829 17:02:08.663794 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.297066 (* 1 = 0.297066 loss)
I0829 17:02:08.663803 916722 sgd_solver.cpp:106] Iteration 455500, lr = 0.01
I0829 17:02:38.765947 916722 solver.cpp:218] Iteration 456000 (16.6101 iter/s, 30.1021s/500 iters), loss = 0.0642417
I0829 17:02:38.766007 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0642503 (* 1 = 0.0642503 loss)
I0829 17:02:38.766016 916722 sgd_solver.cpp:106] Iteration 456000, lr = 0.01
I0829 17:03:08.856454 916722 solver.cpp:218] Iteration 456500 (16.6166 iter/s, 30.0904s/500 iters), loss = 0.162819
I0829 17:03:08.856513 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.162828 (* 1 = 0.162828 loss)
I0829 17:03:08.856521 916722 sgd_solver.cpp:106] Iteration 456500, lr = 0.01
I0829 17:03:38.951225 916722 solver.cpp:218] Iteration 457000 (16.6142 iter/s, 30.0947s/500 iters), loss = 0.136142
I0829 17:03:38.951287 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13615 (* 1 = 0.13615 loss)
I0829 17:03:38.951295 916722 sgd_solver.cpp:106] Iteration 457000, lr = 0.01
I0829 17:04:09.025869 916722 solver.cpp:218] Iteration 457500 (16.6255 iter/s, 30.0743s/500 iters), loss = 0.4248
I0829 17:04:09.025925 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.424809 (* 1 = 0.424809 loss)
I0829 17:04:09.025934 916722 sgd_solver.cpp:106] Iteration 457500, lr = 0.01
I0829 17:04:39.107113 916722 solver.cpp:218] Iteration 458000 (16.6218 iter/s, 30.0809s/500 iters), loss = 0.0932476
I0829 17:04:39.107174 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.093256 (* 1 = 0.093256 loss)
I0829 17:04:39.107183 916722 sgd_solver.cpp:106] Iteration 458000, lr = 0.01
I0829 17:05:09.190662 916722 solver.cpp:218] Iteration 458500 (16.6206 iter/s, 30.0832s/500 iters), loss = 0.116418
I0829 17:05:09.190716 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.116426 (* 1 = 0.116426 loss)
I0829 17:05:09.190726 916722 sgd_solver.cpp:106] Iteration 458500, lr = 0.01
I0829 17:05:39.257350 916722 solver.cpp:218] Iteration 459000 (16.6299 iter/s, 30.0664s/500 iters), loss = 0.167518
I0829 17:05:39.257411 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.167526 (* 1 = 0.167526 loss)
I0829 17:05:39.257421 916722 sgd_solver.cpp:106] Iteration 459000, lr = 0.01
I0829 17:06:09.337428 916722 solver.cpp:218] Iteration 459500 (16.6225 iter/s, 30.0798s/500 iters), loss = 0.0692325
I0829 17:06:09.337492 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0692408 (* 1 = 0.0692408 loss)
I0829 17:06:09.337500 916722 sgd_solver.cpp:106] Iteration 459500, lr = 0.01
I0829 17:06:39.419086 916722 solver.cpp:218] Iteration 460000 (16.6216 iter/s, 30.0814s/500 iters), loss = 0.111668
I0829 17:06:39.419147 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111676 (* 1 = 0.111676 loss)
I0829 17:06:39.419155 916722 sgd_solver.cpp:106] Iteration 460000, lr = 0.01
I0829 17:07:09.465950 916722 solver.cpp:218] Iteration 460500 (16.6408 iter/s, 30.0466s/500 iters), loss = 0.278054
I0829 17:07:09.466009 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.278063 (* 1 = 0.278063 loss)
I0829 17:07:09.466017 916722 sgd_solver.cpp:106] Iteration 460500, lr = 0.01
I0829 17:07:39.504680 916722 solver.cpp:218] Iteration 461000 (16.6453 iter/s, 30.0385s/500 iters), loss = 0.205145
I0829 17:07:39.504756 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.205154 (* 1 = 0.205154 loss)
I0829 17:07:39.504765 916722 sgd_solver.cpp:106] Iteration 461000, lr = 0.01
I0829 17:08:09.552028 916722 solver.cpp:218] Iteration 461500 (16.6406 iter/s, 30.0471s/500 iters), loss = 0.219515
I0829 17:08:09.552088 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.219524 (* 1 = 0.219524 loss)
I0829 17:08:09.552096 916722 sgd_solver.cpp:106] Iteration 461500, lr = 0.01
I0829 17:08:39.596653 916722 solver.cpp:218] Iteration 462000 (16.6421 iter/s, 30.0444s/500 iters), loss = 0.185292
I0829 17:08:39.596709 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.1853 (* 1 = 0.1853 loss)
I0829 17:08:39.596719 916722 sgd_solver.cpp:106] Iteration 462000, lr = 0.01
I0829 17:09:09.665478 916722 solver.cpp:218] Iteration 462500 (16.6287 iter/s, 30.0686s/500 iters), loss = 0.0902439
I0829 17:09:09.665539 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0902523 (* 1 = 0.0902523 loss)
I0829 17:09:09.665549 916722 sgd_solver.cpp:106] Iteration 462500, lr = 0.01
I0829 17:09:39.727835 916722 solver.cpp:218] Iteration 463000 (16.6322 iter/s, 30.0621s/500 iters), loss = 0.0717133
I0829 17:09:39.727895 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0717217 (* 1 = 0.0717217 loss)
I0829 17:09:39.727905 916722 sgd_solver.cpp:106] Iteration 463000, lr = 0.01
I0829 17:10:09.838371 916722 solver.cpp:218] Iteration 463500 (16.6056 iter/s, 30.1103s/500 iters), loss = 0.113891
I0829 17:10:09.838430 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.1139 (* 1 = 0.1139 loss)
I0829 17:10:09.838439 916722 sgd_solver.cpp:106] Iteration 463500, lr = 0.01
I0829 17:10:39.929718 916722 solver.cpp:218] Iteration 464000 (16.6162 iter/s, 30.0911s/500 iters), loss = 0.148519
I0829 17:10:39.929777 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.148527 (* 1 = 0.148527 loss)
I0829 17:10:39.929785 916722 sgd_solver.cpp:106] Iteration 464000, lr = 0.01
I0829 17:11:10.006068 916722 solver.cpp:218] Iteration 464500 (16.6245 iter/s, 30.0761s/500 iters), loss = 0.1359
I0829 17:11:10.006124 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.135909 (* 1 = 0.135909 loss)
I0829 17:11:10.006132 916722 sgd_solver.cpp:106] Iteration 464500, lr = 0.01
I0829 17:11:40.100023 916722 solver.cpp:218] Iteration 465000 (16.6147 iter/s, 30.0937s/500 iters), loss = 0.306776
I0829 17:11:40.100076 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.306784 (* 1 = 0.306784 loss)
I0829 17:11:40.100085 916722 sgd_solver.cpp:106] Iteration 465000, lr = 0.01
I0829 17:12:10.181654 916722 solver.cpp:218] Iteration 465500 (16.6215 iter/s, 30.0814s/500 iters), loss = 0.364887
I0829 17:12:10.181713 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.364895 (* 1 = 0.364895 loss)
I0829 17:12:10.181721 916722 sgd_solver.cpp:106] Iteration 465500, lr = 0.01
I0829 17:12:40.255005 916722 solver.cpp:218] Iteration 466000 (16.6261 iter/s, 30.0732s/500 iters), loss = 0.0697827
I0829 17:12:40.255064 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0697911 (* 1 = 0.0697911 loss)
I0829 17:12:40.255071 916722 sgd_solver.cpp:106] Iteration 466000, lr = 0.01
I0829 17:13:10.316738 916722 solver.cpp:218] Iteration 466500 (16.6325 iter/s, 30.0615s/500 iters), loss = 0.138497
I0829 17:13:10.316813 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.138506 (* 1 = 0.138506 loss)
I0829 17:13:10.316821 916722 sgd_solver.cpp:106] Iteration 466500, lr = 0.01
I0829 17:13:40.367844 916722 solver.cpp:218] Iteration 467000 (16.6384 iter/s, 30.0509s/500 iters), loss = 0.0936453
I0829 17:13:40.367899 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0936538 (* 1 = 0.0936538 loss)
I0829 17:13:40.367908 916722 sgd_solver.cpp:106] Iteration 467000, lr = 0.01
I0829 17:14:10.432365 916722 solver.cpp:218] Iteration 467500 (16.631 iter/s, 30.0643s/500 iters), loss = 0.157173
I0829 17:14:10.432449 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.157181 (* 1 = 0.157181 loss)
I0829 17:14:10.432464 916722 sgd_solver.cpp:106] Iteration 467500, lr = 0.01
I0829 17:14:40.481892 916722 solver.cpp:218] Iteration 468000 (16.6393 iter/s, 30.0493s/500 iters), loss = 0.0598157
I0829 17:14:40.481945 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.059824 (* 1 = 0.059824 loss)
I0829 17:14:40.481953 916722 sgd_solver.cpp:106] Iteration 468000, lr = 0.01
I0829 17:15:10.538094 916722 solver.cpp:218] Iteration 468500 (16.6356 iter/s, 30.056s/500 iters), loss = 0.164212
I0829 17:15:10.538149 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.164221 (* 1 = 0.164221 loss)
I0829 17:15:10.538157 916722 sgd_solver.cpp:106] Iteration 468500, lr = 0.01
I0829 17:15:40.619496 916722 solver.cpp:218] Iteration 469000 (16.6217 iter/s, 30.0812s/500 iters), loss = 0.0488995
I0829 17:15:40.619554 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0489079 (* 1 = 0.0489079 loss)
I0829 17:15:40.619561 916722 sgd_solver.cpp:106] Iteration 469000, lr = 0.01
I0829 17:16:10.712530 916722 solver.cpp:218] Iteration 469500 (16.6152 iter/s, 30.0929s/500 iters), loss = 0.150863
I0829 17:16:10.712591 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.150872 (* 1 = 0.150872 loss)
I0829 17:16:10.712601 916722 sgd_solver.cpp:106] Iteration 469500, lr = 0.01
I0829 17:16:40.820396 916722 solver.cpp:218] Iteration 470000 (16.607 iter/s, 30.1077s/500 iters), loss = 0.252626
I0829 17:16:40.820477 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.252634 (* 1 = 0.252634 loss)
I0829 17:16:40.820485 916722 sgd_solver.cpp:106] Iteration 470000, lr = 0.01
I0829 17:17:10.953148 916722 solver.cpp:218] Iteration 470500 (16.5933 iter/s, 30.1326s/500 iters), loss = 0.204893
I0829 17:17:10.953204 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.204902 (* 1 = 0.204902 loss)
I0829 17:17:10.953212 916722 sgd_solver.cpp:106] Iteration 470500, lr = 0.01
I0829 17:17:41.072218 916722 solver.cpp:218] Iteration 471000 (16.6009 iter/s, 30.1189s/500 iters), loss = 0.32273
I0829 17:17:41.072278 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.322739 (* 1 = 0.322739 loss)
I0829 17:17:41.072288 916722 sgd_solver.cpp:106] Iteration 471000, lr = 0.01
I0829 17:18:11.182622 916722 solver.cpp:218] Iteration 471500 (16.6056 iter/s, 30.1103s/500 iters), loss = 0.0810773
I0829 17:18:11.182679 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0810859 (* 1 = 0.0810859 loss)
I0829 17:18:11.182687 916722 sgd_solver.cpp:106] Iteration 471500, lr = 0.01
I0829 17:18:41.311223 916722 solver.cpp:218] Iteration 472000 (16.5956 iter/s, 30.1285s/500 iters), loss = 0.205631
I0829 17:18:41.311280 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.20564 (* 1 = 0.20564 loss)
I0829 17:18:41.311288 916722 sgd_solver.cpp:106] Iteration 472000, lr = 0.01
I0829 17:19:11.453357 916722 solver.cpp:218] Iteration 472500 (16.5882 iter/s, 30.142s/500 iters), loss = 0.0736899
I0829 17:19:11.453413 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0736987 (* 1 = 0.0736987 loss)
I0829 17:19:11.453420 916722 sgd_solver.cpp:106] Iteration 472500, lr = 0.01
I0829 17:19:41.577138 916722 solver.cpp:218] Iteration 473000 (16.5983 iter/s, 30.1236s/500 iters), loss = 0.233062
I0829 17:19:41.577198 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.23307 (* 1 = 0.23307 loss)
I0829 17:19:41.577205 916722 sgd_solver.cpp:106] Iteration 473000, lr = 0.01
I0829 17:20:11.782081 916722 solver.cpp:218] Iteration 473500 (16.5537 iter/s, 30.2048s/500 iters), loss = 0.04504
I0829 17:20:11.782140 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0450488 (* 1 = 0.0450488 loss)
I0829 17:20:11.782150 916722 sgd_solver.cpp:106] Iteration 473500, lr = 0.01
I0829 17:20:41.979660 916722 solver.cpp:218] Iteration 474000 (16.5577 iter/s, 30.1974s/500 iters), loss = 0.110942
I0829 17:20:41.979732 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110951 (* 1 = 0.110951 loss)
I0829 17:20:41.979741 916722 sgd_solver.cpp:106] Iteration 474000, lr = 0.01
I0829 17:21:12.180496 916722 solver.cpp:218] Iteration 474500 (16.5559 iter/s, 30.2007s/500 iters), loss = 0.173992
I0829 17:21:12.180555 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.174001 (* 1 = 0.174001 loss)
I0829 17:21:12.180563 916722 sgd_solver.cpp:106] Iteration 474500, lr = 0.01
I0829 17:21:42.379853 916722 solver.cpp:218] Iteration 475000 (16.5567 iter/s, 30.1992s/500 iters), loss = 0.470339
I0829 17:21:42.379914 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.470348 (* 1 = 0.470348 loss)
I0829 17:21:42.379921 916722 sgd_solver.cpp:106] Iteration 475000, lr = 0.01
I0829 17:22:12.586499 916722 solver.cpp:218] Iteration 475500 (16.5527 iter/s, 30.2065s/500 iters), loss = 0.161759
I0829 17:22:12.586560 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.161768 (* 1 = 0.161768 loss)
I0829 17:22:12.586568 916722 sgd_solver.cpp:106] Iteration 475500, lr = 0.01
I0829 17:22:42.782907 916722 solver.cpp:218] Iteration 476000 (16.5583 iter/s, 30.1963s/500 iters), loss = 0.113797
I0829 17:22:42.782970 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.113806 (* 1 = 0.113806 loss)
I0829 17:22:42.782979 916722 sgd_solver.cpp:106] Iteration 476000, lr = 0.01
I0829 17:23:13.000922 916722 solver.cpp:218] Iteration 476500 (16.5465 iter/s, 30.2179s/500 iters), loss = 0.223498
I0829 17:23:13.000984 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.223507 (* 1 = 0.223507 loss)
I0829 17:23:13.000993 916722 sgd_solver.cpp:106] Iteration 476500, lr = 0.01
I0829 17:23:43.138568 916722 solver.cpp:218] Iteration 477000 (16.5906 iter/s, 30.1375s/500 iters), loss = 0.180635
I0829 17:23:43.138629 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.180645 (* 1 = 0.180645 loss)
I0829 17:23:43.138638 916722 sgd_solver.cpp:106] Iteration 477000, lr = 0.01
I0829 17:24:13.268851 916722 solver.cpp:218] Iteration 477500 (16.5947 iter/s, 30.1302s/500 iters), loss = 0.230063
I0829 17:24:13.268915 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.230072 (* 1 = 0.230072 loss)
I0829 17:24:13.268924 916722 sgd_solver.cpp:106] Iteration 477500, lr = 0.01
I0829 17:24:43.409049 916722 solver.cpp:218] Iteration 478000 (16.5892 iter/s, 30.1401s/500 iters), loss = 0.0821854
I0829 17:24:43.409111 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0821946 (* 1 = 0.0821946 loss)
I0829 17:24:43.409118 916722 sgd_solver.cpp:106] Iteration 478000, lr = 0.01
I0829 17:25:13.587507 916722 solver.cpp:218] Iteration 478500 (16.5682 iter/s, 30.1783s/500 iters), loss = 0.249994
I0829 17:25:13.587568 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.250004 (* 1 = 0.250004 loss)
I0829 17:25:13.587576 916722 sgd_solver.cpp:106] Iteration 478500, lr = 0.01
I0829 17:25:43.767076 916722 solver.cpp:218] Iteration 479000 (16.5676 iter/s, 30.1794s/500 iters), loss = 0.159879
I0829 17:25:43.767130 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159888 (* 1 = 0.159888 loss)
I0829 17:25:43.767138 916722 sgd_solver.cpp:106] Iteration 479000, lr = 0.01
I0829 17:26:13.924036 916722 solver.cpp:218] Iteration 479500 (16.58 iter/s, 30.1568s/500 iters), loss = 0.237374
I0829 17:26:13.924093 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.237383 (* 1 = 0.237383 loss)
I0829 17:26:13.924100 916722 sgd_solver.cpp:106] Iteration 479500, lr = 0.01
I0829 17:26:44.095108 916722 solver.cpp:218] Iteration 480000 (16.5722 iter/s, 30.171s/500 iters), loss = 0.422853
I0829 17:26:44.095165 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.422863 (* 1 = 0.422863 loss)
I0829 17:26:44.095172 916722 sgd_solver.cpp:106] Iteration 480000, lr = 0.01
I0829 17:27:14.277710 916722 solver.cpp:218] Iteration 480500 (16.5659 iter/s, 30.1825s/500 iters), loss = 0.353883
I0829 17:27:14.277771 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.353893 (* 1 = 0.353893 loss)
I0829 17:27:14.277781 916722 sgd_solver.cpp:106] Iteration 480500, lr = 0.01
I0829 17:27:44.475941 916722 solver.cpp:218] Iteration 481000 (16.5573 iter/s, 30.1981s/500 iters), loss = 0.212519
I0829 17:27:44.476016 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.212528 (* 1 = 0.212528 loss)
I0829 17:27:44.476025 916722 sgd_solver.cpp:106] Iteration 481000, lr = 0.01
I0829 17:28:14.634568 916722 solver.cpp:218] Iteration 481500 (16.5791 iter/s, 30.1585s/500 iters), loss = 0.259556
I0829 17:28:14.634627 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.259565 (* 1 = 0.259565 loss)
I0829 17:28:14.634636 916722 sgd_solver.cpp:106] Iteration 481500, lr = 0.01
I0829 17:28:44.806665 916722 solver.cpp:218] Iteration 482000 (16.5717 iter/s, 30.172s/500 iters), loss = 0.32598
I0829 17:28:44.806727 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.32599 (* 1 = 0.32599 loss)
I0829 17:28:44.806736 916722 sgd_solver.cpp:106] Iteration 482000, lr = 0.01
I0829 17:29:15.003458 916722 solver.cpp:218] Iteration 482500 (16.5581 iter/s, 30.1967s/500 iters), loss = 0.202107
I0829 17:29:15.003517 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.202116 (* 1 = 0.202116 loss)
I0829 17:29:15.003525 916722 sgd_solver.cpp:106] Iteration 482500, lr = 0.01
I0829 17:29:45.175303 916722 solver.cpp:218] Iteration 483000 (16.5718 iter/s, 30.1717s/500 iters), loss = 0.277462
I0829 17:29:45.175359 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.277471 (* 1 = 0.277471 loss)
I0829 17:29:45.175367 916722 sgd_solver.cpp:106] Iteration 483000, lr = 0.01
I0829 17:30:15.331544 916722 solver.cpp:218] Iteration 483500 (16.5804 iter/s, 30.1561s/500 iters), loss = 0.315727
I0829 17:30:15.331600 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.315736 (* 1 = 0.315736 loss)
I0829 17:30:15.331609 916722 sgd_solver.cpp:106] Iteration 483500, lr = 0.01
I0829 17:30:45.525570 916722 solver.cpp:218] Iteration 484000 (16.5596 iter/s, 30.1939s/500 iters), loss = 0.184618
I0829 17:30:45.525631 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.184627 (* 1 = 0.184627 loss)
I0829 17:30:45.525640 916722 sgd_solver.cpp:106] Iteration 484000, lr = 0.01
I0829 17:31:15.693177 916722 solver.cpp:218] Iteration 484500 (16.5741 iter/s, 30.1675s/500 iters), loss = 0.0239077
I0829 17:31:15.693239 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0239168 (* 1 = 0.0239168 loss)
I0829 17:31:15.693248 916722 sgd_solver.cpp:106] Iteration 484500, lr = 0.01
I0829 17:31:45.868461 916722 solver.cpp:218] Iteration 485000 (16.5699 iter/s, 30.1752s/500 iters), loss = 0.236714
I0829 17:31:45.868523 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.236723 (* 1 = 0.236723 loss)
I0829 17:31:45.868531 916722 sgd_solver.cpp:106] Iteration 485000, lr = 0.01
I0829 17:32:16.043642 916722 solver.cpp:218] Iteration 485500 (16.57 iter/s, 30.1751s/500 iters), loss = 0.300158
I0829 17:32:16.043704 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.300167 (* 1 = 0.300167 loss)
I0829 17:32:16.043712 916722 sgd_solver.cpp:106] Iteration 485500, lr = 0.01
I0829 17:32:46.204156 916722 solver.cpp:218] Iteration 486000 (16.578 iter/s, 30.1604s/500 iters), loss = 0.129999
I0829 17:32:46.204216 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130008 (* 1 = 0.130008 loss)
I0829 17:32:46.204226 916722 sgd_solver.cpp:106] Iteration 486000, lr = 0.01
I0829 17:33:16.370879 916722 solver.cpp:218] Iteration 486500 (16.5746 iter/s, 30.1666s/500 iters), loss = 0.374218
I0829 17:33:16.370942 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.374227 (* 1 = 0.374227 loss)
I0829 17:33:16.370951 916722 sgd_solver.cpp:106] Iteration 486500, lr = 0.01
I0829 17:33:46.530383 916722 solver.cpp:218] Iteration 487000 (16.5786 iter/s, 30.1594s/500 iters), loss = 0.141932
I0829 17:33:46.530443 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.141941 (* 1 = 0.141941 loss)
I0829 17:33:46.530452 916722 sgd_solver.cpp:106] Iteration 487000, lr = 0.01
I0829 17:34:16.690215 916722 solver.cpp:218] Iteration 487500 (16.5784 iter/s, 30.1597s/500 iters), loss = 0.0128074
I0829 17:34:16.690286 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0128164 (* 1 = 0.0128164 loss)
I0829 17:34:16.690295 916722 sgd_solver.cpp:106] Iteration 487500, lr = 0.01
I0829 17:34:46.873083 916722 solver.cpp:218] Iteration 488000 (16.5658 iter/s, 30.1827s/500 iters), loss = 0.120072
I0829 17:34:46.873142 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.120081 (* 1 = 0.120081 loss)
I0829 17:34:46.873150 916722 sgd_solver.cpp:106] Iteration 488000, lr = 0.01
I0829 17:35:17.028162 916722 solver.cpp:218] Iteration 488500 (16.581 iter/s, 30.155s/500 iters), loss = 0.0818055
I0829 17:35:17.028223 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0818147 (* 1 = 0.0818147 loss)
I0829 17:35:17.028231 916722 sgd_solver.cpp:106] Iteration 488500, lr = 0.01
I0829 17:35:47.193493 916722 solver.cpp:218] Iteration 489000 (16.5754 iter/s, 30.1652s/500 iters), loss = 0.342862
I0829 17:35:47.193552 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.342871 (* 1 = 0.342871 loss)
I0829 17:35:47.193560 916722 sgd_solver.cpp:106] Iteration 489000, lr = 0.01
I0829 17:36:17.354267 916722 solver.cpp:218] Iteration 489500 (16.5779 iter/s, 30.1607s/500 iters), loss = 0.265135
I0829 17:36:17.354327 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.265145 (* 1 = 0.265145 loss)
I0829 17:36:17.354336 916722 sgd_solver.cpp:106] Iteration 489500, lr = 0.01
I0829 17:36:47.519881 916722 solver.cpp:218] Iteration 490000 (16.5752 iter/s, 30.1655s/500 iters), loss = 0.145768
I0829 17:36:47.519940 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.145777 (* 1 = 0.145777 loss)
I0829 17:36:47.519948 916722 sgd_solver.cpp:106] Iteration 490000, lr = 0.01
I0829 17:37:17.661005 916722 solver.cpp:218] Iteration 490500 (16.5887 iter/s, 30.141s/500 iters), loss = 0.276941
I0829 17:37:17.661064 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.27695 (* 1 = 0.27695 loss)
I0829 17:37:17.661072 916722 sgd_solver.cpp:106] Iteration 490500, lr = 0.01
I0829 17:37:47.820852 916722 solver.cpp:218] Iteration 491000 (16.5784 iter/s, 30.1597s/500 iters), loss = 0.162825
I0829 17:37:47.820914 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.162835 (* 1 = 0.162835 loss)
I0829 17:37:47.820922 916722 sgd_solver.cpp:106] Iteration 491000, lr = 0.01
I0829 17:38:17.975209 916722 solver.cpp:218] Iteration 491500 (16.5814 iter/s, 30.1542s/500 iters), loss = 0.21445
I0829 17:38:17.975263 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.214459 (* 1 = 0.214459 loss)
I0829 17:38:17.975271 916722 sgd_solver.cpp:106] Iteration 491500, lr = 0.01
I0829 17:38:48.140898 916722 solver.cpp:218] Iteration 492000 (16.5752 iter/s, 30.1656s/500 iters), loss = 0.175789
I0829 17:38:48.140954 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.175798 (* 1 = 0.175798 loss)
I0829 17:38:48.140964 916722 sgd_solver.cpp:106] Iteration 492000, lr = 0.01
I0829 17:39:18.277209 916722 solver.cpp:218] Iteration 492500 (16.5914 iter/s, 30.1362s/500 iters), loss = 0.0753425
I0829 17:39:18.277264 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0753516 (* 1 = 0.0753516 loss)
I0829 17:39:18.277273 916722 sgd_solver.cpp:106] Iteration 492500, lr = 0.01
I0829 17:39:48.426620 916722 solver.cpp:218] Iteration 493000 (16.5841 iter/s, 30.1493s/500 iters), loss = 0.12264
I0829 17:39:48.426678 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.122649 (* 1 = 0.122649 loss)
I0829 17:39:48.426687 916722 sgd_solver.cpp:106] Iteration 493000, lr = 0.01
I0829 17:40:18.584877 916722 solver.cpp:218] Iteration 493500 (16.5793 iter/s, 30.1581s/500 iters), loss = 0.0774698
I0829 17:40:18.584936 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0774789 (* 1 = 0.0774789 loss)
I0829 17:40:18.584944 916722 sgd_solver.cpp:106] Iteration 493500, lr = 0.01
I0829 17:40:48.741102 916722 solver.cpp:218] Iteration 494000 (16.5804 iter/s, 30.1561s/500 iters), loss = 0.139561
I0829 17:40:48.741173 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13957 (* 1 = 0.13957 loss)
I0829 17:40:48.741184 916722 sgd_solver.cpp:106] Iteration 494000, lr = 0.01
I0829 17:41:18.909473 916722 solver.cpp:218] Iteration 494500 (16.5737 iter/s, 30.1682s/500 iters), loss = 0.297335
I0829 17:41:18.909534 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.297344 (* 1 = 0.297344 loss)
I0829 17:41:18.909543 916722 sgd_solver.cpp:106] Iteration 494500, lr = 0.01
I0829 17:41:49.063256 916722 solver.cpp:218] Iteration 495000 (16.5817 iter/s, 30.1536s/500 iters), loss = 0.389497
I0829 17:41:49.063313 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.389506 (* 1 = 0.389506 loss)
I0829 17:41:49.063323 916722 sgd_solver.cpp:106] Iteration 495000, lr = 0.01
I0829 17:42:19.215514 916722 solver.cpp:218] Iteration 495500 (16.5826 iter/s, 30.1521s/500 iters), loss = 0.201378
I0829 17:42:19.215567 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.201387 (* 1 = 0.201387 loss)
I0829 17:42:19.215575 916722 sgd_solver.cpp:106] Iteration 495500, lr = 0.01
I0829 17:42:49.355794 916722 solver.cpp:218] Iteration 496000 (16.5892 iter/s, 30.1402s/500 iters), loss = 0.136214
I0829 17:42:49.355849 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.136222 (* 1 = 0.136222 loss)
I0829 17:42:49.355856 916722 sgd_solver.cpp:106] Iteration 496000, lr = 0.01
I0829 17:43:19.513353 916722 solver.cpp:218] Iteration 496500 (16.5797 iter/s, 30.1574s/500 iters), loss = 0.157568
I0829 17:43:19.513411 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.157576 (* 1 = 0.157576 loss)
I0829 17:43:19.513420 916722 sgd_solver.cpp:106] Iteration 496500, lr = 0.01
I0829 17:43:49.692538 916722 solver.cpp:218] Iteration 497000 (16.5678 iter/s, 30.1791s/500 iters), loss = 0.149779
I0829 17:43:49.692595 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.149787 (* 1 = 0.149787 loss)
I0829 17:43:49.692605 916722 sgd_solver.cpp:106] Iteration 497000, lr = 0.01
I0829 17:44:19.851985 916722 solver.cpp:218] Iteration 497500 (16.5786 iter/s, 30.1593s/500 iters), loss = 0.24059
I0829 17:44:19.852043 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.240599 (* 1 = 0.240599 loss)
I0829 17:44:19.852052 916722 sgd_solver.cpp:106] Iteration 497500, lr = 0.01
I0829 17:44:50.004995 916722 solver.cpp:218] Iteration 498000 (16.5822 iter/s, 30.1529s/500 iters), loss = 0.319333
I0829 17:44:50.005054 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.319342 (* 1 = 0.319342 loss)
I0829 17:44:50.005064 916722 sgd_solver.cpp:106] Iteration 498000, lr = 0.01
I0829 17:45:20.174453 916722 solver.cpp:218] Iteration 498500 (16.5731 iter/s, 30.1693s/500 iters), loss = 0.114905
I0829 17:45:20.174512 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.114913 (* 1 = 0.114913 loss)
I0829 17:45:20.174520 916722 sgd_solver.cpp:106] Iteration 498500, lr = 0.01
I0829 17:45:50.314321 916722 solver.cpp:218] Iteration 499000 (16.5894 iter/s, 30.1397s/500 iters), loss = 0.255412
I0829 17:45:50.314378 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.255421 (* 1 = 0.255421 loss)
I0829 17:45:50.314388 916722 sgd_solver.cpp:106] Iteration 499000, lr = 0.01
I0829 17:46:20.474521 916722 solver.cpp:218] Iteration 499500 (16.5782 iter/s, 30.1601s/500 iters), loss = 0.0993343
I0829 17:46:20.474582 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.099343 (* 1 = 0.099343 loss)
I0829 17:46:20.474591 916722 sgd_solver.cpp:106] Iteration 499500, lr = 0.01
I0829 17:46:50.575647 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_500000.caffemodel
I0829 17:46:50.594597 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_500000.solverstate
I0829 17:46:50.600657 916722 solver.cpp:330] Iteration 500000, Testing net (#0)
I0829 17:47:05.979183 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8841
I0829 17:47:05.979233 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.369354 (* 1 = 0.369354 loss)
I0829 17:47:06.037950 916722 solver.cpp:218] Iteration 500000 (10.9738 iter/s, 45.5633s/500 iters), loss = 0.217006
I0829 17:47:06.037986 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.217015 (* 1 = 0.217015 loss)
I0829 17:47:06.037994 916722 sgd_solver.cpp:106] Iteration 500000, lr = 0.01
I0829 17:47:35.952100 916722 solver.cpp:218] Iteration 500500 (16.7146 iter/s, 29.914s/500 iters), loss = 0.0573225
I0829 17:47:35.952172 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0573313 (* 1 = 0.0573313 loss)
I0829 17:47:35.952193 916722 sgd_solver.cpp:106] Iteration 500500, lr = 0.01
I0829 17:48:06.002568 916722 solver.cpp:218] Iteration 501000 (16.6388 iter/s, 30.0503s/500 iters), loss = 0.361893
I0829 17:48:06.002624 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.361902 (* 1 = 0.361902 loss)
I0829 17:48:06.002632 916722 sgd_solver.cpp:106] Iteration 501000, lr = 0.01
I0829 17:48:36.081912 916722 solver.cpp:218] Iteration 501500 (16.6228 iter/s, 30.0792s/500 iters), loss = 0.048702
I0829 17:48:36.081966 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0487105 (* 1 = 0.0487105 loss)
I0829 17:48:36.081974 916722 sgd_solver.cpp:106] Iteration 501500, lr = 0.01
I0829 17:49:06.153123 916722 solver.cpp:218] Iteration 502000 (16.6273 iter/s, 30.0711s/500 iters), loss = 0.323353
I0829 17:49:06.153179 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.323361 (* 1 = 0.323361 loss)
I0829 17:49:06.153187 916722 sgd_solver.cpp:106] Iteration 502000, lr = 0.01
I0829 17:49:36.233595 916722 solver.cpp:218] Iteration 502500 (16.6221 iter/s, 30.0804s/500 iters), loss = 0.113793
I0829 17:49:36.233654 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.113801 (* 1 = 0.113801 loss)
I0829 17:49:36.233661 916722 sgd_solver.cpp:106] Iteration 502500, lr = 0.01
I0829 17:50:06.302297 916722 solver.cpp:218] Iteration 503000 (16.6286 iter/s, 30.0686s/500 iters), loss = 0.288067
I0829 17:50:06.302356 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.288076 (* 1 = 0.288076 loss)
I0829 17:50:06.302366 916722 sgd_solver.cpp:106] Iteration 503000, lr = 0.01
I0829 17:50:36.395478 916722 solver.cpp:218] Iteration 503500 (16.6151 iter/s, 30.0931s/500 iters), loss = 0.16908
I0829 17:50:36.395536 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.169089 (* 1 = 0.169089 loss)
I0829 17:50:36.395545 916722 sgd_solver.cpp:106] Iteration 503500, lr = 0.01
I0829 17:51:06.465582 916722 solver.cpp:218] Iteration 504000 (16.6279 iter/s, 30.07s/500 iters), loss = 0.304563
I0829 17:51:06.465641 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.304572 (* 1 = 0.304572 loss)
I0829 17:51:06.465649 916722 sgd_solver.cpp:106] Iteration 504000, lr = 0.01
I0829 17:51:36.539655 916722 solver.cpp:218] Iteration 504500 (16.6257 iter/s, 30.074s/500 iters), loss = 0.124495
I0829 17:51:36.539716 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.124503 (* 1 = 0.124503 loss)
I0829 17:51:36.539723 916722 sgd_solver.cpp:106] Iteration 504500, lr = 0.01
I0829 17:52:06.659370 916722 solver.cpp:218] Iteration 505000 (16.6005 iter/s, 30.1196s/500 iters), loss = 0.0363865
I0829 17:52:06.659428 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0363952 (* 1 = 0.0363952 loss)
I0829 17:52:06.659436 916722 sgd_solver.cpp:106] Iteration 505000, lr = 0.01
I0829 17:52:36.737296 916722 solver.cpp:218] Iteration 505500 (16.6236 iter/s, 30.0778s/500 iters), loss = 0.225243
I0829 17:52:36.737357 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.225251 (* 1 = 0.225251 loss)
I0829 17:52:36.737366 916722 sgd_solver.cpp:106] Iteration 505500, lr = 0.01
I0829 17:53:06.823904 916722 solver.cpp:218] Iteration 506000 (16.6188 iter/s, 30.0865s/500 iters), loss = 0.167835
I0829 17:53:06.823957 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.167844 (* 1 = 0.167844 loss)
I0829 17:53:06.823966 916722 sgd_solver.cpp:106] Iteration 506000, lr = 0.01
I0829 17:53:36.907280 916722 solver.cpp:218] Iteration 506500 (16.6205 iter/s, 30.0833s/500 iters), loss = 0.106309
I0829 17:53:36.907352 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.106318 (* 1 = 0.106318 loss)
I0829 17:53:36.907361 916722 sgd_solver.cpp:106] Iteration 506500, lr = 0.01
I0829 17:54:06.997247 916722 solver.cpp:218] Iteration 507000 (16.6169 iter/s, 30.0898s/500 iters), loss = 0.134974
I0829 17:54:06.997304 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.134983 (* 1 = 0.134983 loss)
I0829 17:54:06.997313 916722 sgd_solver.cpp:106] Iteration 507000, lr = 0.01
I0829 17:54:37.079404 916722 solver.cpp:218] Iteration 507500 (16.6212 iter/s, 30.0821s/500 iters), loss = 0.051126
I0829 17:54:37.079465 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0511348 (* 1 = 0.0511348 loss)
I0829 17:54:37.079473 916722 sgd_solver.cpp:106] Iteration 507500, lr = 0.01
I0829 17:55:07.149572 916722 solver.cpp:218] Iteration 508000 (16.6278 iter/s, 30.0701s/500 iters), loss = 0.0294464
I0829 17:55:07.149629 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.029455 (* 1 = 0.029455 loss)
I0829 17:55:07.149637 916722 sgd_solver.cpp:106] Iteration 508000, lr = 0.01
I0829 17:55:37.230181 916722 solver.cpp:218] Iteration 508500 (16.6221 iter/s, 30.0805s/500 iters), loss = 0.330371
I0829 17:55:37.230242 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.33038 (* 1 = 0.33038 loss)
I0829 17:55:37.230249 916722 sgd_solver.cpp:106] Iteration 508500, lr = 0.01
I0829 17:56:07.305480 916722 solver.cpp:218] Iteration 509000 (16.625 iter/s, 30.0752s/500 iters), loss = 0.136388
I0829 17:56:07.305539 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.136397 (* 1 = 0.136397 loss)
I0829 17:56:07.305547 916722 sgd_solver.cpp:106] Iteration 509000, lr = 0.01
I0829 17:56:37.393112 916722 solver.cpp:218] Iteration 509500 (16.6182 iter/s, 30.0875s/500 iters), loss = 0.282226
I0829 17:56:37.393174 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.282234 (* 1 = 0.282234 loss)
I0829 17:56:37.393182 916722 sgd_solver.cpp:106] Iteration 509500, lr = 0.01
I0829 17:57:07.474475 916722 solver.cpp:218] Iteration 510000 (16.6217 iter/s, 30.0812s/500 iters), loss = 0.273246
I0829 17:57:07.474535 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.273254 (* 1 = 0.273254 loss)
I0829 17:57:07.474543 916722 sgd_solver.cpp:106] Iteration 510000, lr = 0.01
I0829 17:57:37.544541 916722 solver.cpp:218] Iteration 510500 (16.6279 iter/s, 30.07s/500 iters), loss = 0.23016
I0829 17:57:37.544598 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.230169 (* 1 = 0.230169 loss)
I0829 17:57:37.544607 916722 sgd_solver.cpp:106] Iteration 510500, lr = 0.01
I0829 17:58:07.652149 916722 solver.cpp:218] Iteration 511000 (16.6072 iter/s, 30.1075s/500 iters), loss = 0.270977
I0829 17:58:07.652206 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.270985 (* 1 = 0.270985 loss)
I0829 17:58:07.652215 916722 sgd_solver.cpp:106] Iteration 511000, lr = 0.01
I0829 17:58:37.748127 916722 solver.cpp:218] Iteration 511500 (16.6136 iter/s, 30.0959s/500 iters), loss = 0.260515
I0829 17:58:37.748184 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.260523 (* 1 = 0.260523 loss)
I0829 17:58:37.748193 916722 sgd_solver.cpp:106] Iteration 511500, lr = 0.01
I0829 17:59:07.818725 916722 solver.cpp:218] Iteration 512000 (16.6276 iter/s, 30.0705s/500 iters), loss = 0.0477172
I0829 17:59:07.818784 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0477259 (* 1 = 0.0477259 loss)
I0829 17:59:07.818792 916722 sgd_solver.cpp:106] Iteration 512000, lr = 0.01
I0829 17:59:37.957882 916722 solver.cpp:218] Iteration 512500 (16.5898 iter/s, 30.139s/500 iters), loss = 0.0679361
I0829 17:59:37.957947 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0679449 (* 1 = 0.0679449 loss)
I0829 17:59:37.957957 916722 sgd_solver.cpp:106] Iteration 512500, lr = 0.01
I0829 18:00:08.062806 916722 solver.cpp:218] Iteration 513000 (16.6086 iter/s, 30.1048s/500 iters), loss = 0.187658
I0829 18:00:08.062876 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.187667 (* 1 = 0.187667 loss)
I0829 18:00:08.062889 916722 sgd_solver.cpp:106] Iteration 513000, lr = 0.01
I0829 18:00:38.182456 916722 solver.cpp:218] Iteration 513500 (16.6005 iter/s, 30.1195s/500 iters), loss = 0.161102
I0829 18:00:38.182515 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.161111 (* 1 = 0.161111 loss)
I0829 18:00:38.182523 916722 sgd_solver.cpp:106] Iteration 513500, lr = 0.01
I0829 18:01:08.298969 916722 solver.cpp:218] Iteration 514000 (16.6022 iter/s, 30.1164s/500 iters), loss = 0.154028
I0829 18:01:08.299027 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.154037 (* 1 = 0.154037 loss)
I0829 18:01:08.299036 916722 sgd_solver.cpp:106] Iteration 514000, lr = 0.01
I0829 18:01:38.408493 916722 solver.cpp:218] Iteration 514500 (16.6061 iter/s, 30.1094s/500 iters), loss = 0.0677215
I0829 18:01:38.408551 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0677304 (* 1 = 0.0677304 loss)
I0829 18:01:38.408560 916722 sgd_solver.cpp:106] Iteration 514500, lr = 0.01
I0829 18:02:08.505920 916722 solver.cpp:218] Iteration 515000 (16.6128 iter/s, 30.0973s/500 iters), loss = 0.13233
I0829 18:02:08.505978 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.132339 (* 1 = 0.132339 loss)
I0829 18:02:08.505986 916722 sgd_solver.cpp:106] Iteration 515000, lr = 0.01
I0829 18:02:38.621899 916722 solver.cpp:218] Iteration 515500 (16.6025 iter/s, 30.1159s/500 iters), loss = 0.143055
I0829 18:02:38.621956 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.143064 (* 1 = 0.143064 loss)
I0829 18:02:38.621965 916722 sgd_solver.cpp:106] Iteration 515500, lr = 0.01
I0829 18:03:08.730434 916722 solver.cpp:218] Iteration 516000 (16.6066 iter/s, 30.1084s/500 iters), loss = 0.191719
I0829 18:03:08.730492 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.191728 (* 1 = 0.191728 loss)
I0829 18:03:08.730501 916722 sgd_solver.cpp:106] Iteration 516000, lr = 0.01
I0829 18:03:38.824358 916722 solver.cpp:218] Iteration 516500 (16.6147 iter/s, 30.0938s/500 iters), loss = 0.254307
I0829 18:03:38.824417 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.254316 (* 1 = 0.254316 loss)
I0829 18:03:38.824431 916722 sgd_solver.cpp:106] Iteration 516500, lr = 0.01
I0829 18:04:08.920078 916722 solver.cpp:218] Iteration 517000 (16.6137 iter/s, 30.0956s/500 iters), loss = 0.514533
I0829 18:04:08.920135 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.514542 (* 1 = 0.514542 loss)
I0829 18:04:08.920145 916722 sgd_solver.cpp:106] Iteration 517000, lr = 0.01
I0829 18:04:38.993345 916722 solver.cpp:218] Iteration 517500 (16.6261 iter/s, 30.0732s/500 iters), loss = 0.412959
I0829 18:04:38.993407 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.412968 (* 1 = 0.412968 loss)
I0829 18:04:38.993417 916722 sgd_solver.cpp:106] Iteration 517500, lr = 0.01
I0829 18:05:09.070861 916722 solver.cpp:218] Iteration 518000 (16.6238 iter/s, 30.0774s/500 iters), loss = 0.213527
I0829 18:05:09.070919 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.213536 (* 1 = 0.213536 loss)
I0829 18:05:09.070927 916722 sgd_solver.cpp:106] Iteration 518000, lr = 0.01
I0829 18:05:39.158675 916722 solver.cpp:218] Iteration 518500 (16.6181 iter/s, 30.0877s/500 iters), loss = 0.18155
I0829 18:05:39.158735 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.181559 (* 1 = 0.181559 loss)
I0829 18:05:39.158744 916722 sgd_solver.cpp:106] Iteration 518500, lr = 0.01
I0829 18:06:09.247941 916722 solver.cpp:218] Iteration 519000 (16.6173 iter/s, 30.0891s/500 iters), loss = 0.246385
I0829 18:06:09.247993 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.246394 (* 1 = 0.246394 loss)
I0829 18:06:09.248001 916722 sgd_solver.cpp:106] Iteration 519000, lr = 0.01
I0829 18:06:39.339187 916722 solver.cpp:218] Iteration 519500 (16.6162 iter/s, 30.0911s/500 iters), loss = 0.186045
I0829 18:06:39.339257 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.186055 (* 1 = 0.186055 loss)
I0829 18:06:39.339265 916722 sgd_solver.cpp:106] Iteration 519500, lr = 0.01
I0829 18:07:09.435037 916722 solver.cpp:218] Iteration 520000 (16.6137 iter/s, 30.0957s/500 iters), loss = 0.180837
I0829 18:07:09.435096 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.180846 (* 1 = 0.180846 loss)
I0829 18:07:09.435103 916722 sgd_solver.cpp:106] Iteration 520000, lr = 0.01
I0829 18:07:39.517575 916722 solver.cpp:218] Iteration 520500 (16.621 iter/s, 30.0824s/500 iters), loss = 0.124167
I0829 18:07:39.517637 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.124177 (* 1 = 0.124177 loss)
I0829 18:07:39.517645 916722 sgd_solver.cpp:106] Iteration 520500, lr = 0.01
I0829 18:08:09.583822 916722 solver.cpp:218] Iteration 521000 (16.63 iter/s, 30.0661s/500 iters), loss = 0.350729
I0829 18:08:09.583880 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.350739 (* 1 = 0.350739 loss)
I0829 18:08:09.583889 916722 sgd_solver.cpp:106] Iteration 521000, lr = 0.01
I0829 18:08:39.643363 916722 solver.cpp:218] Iteration 521500 (16.6337 iter/s, 30.0594s/500 iters), loss = 0.435981
I0829 18:08:39.643421 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.435991 (* 1 = 0.435991 loss)
I0829 18:08:39.643429 916722 sgd_solver.cpp:106] Iteration 521500, lr = 0.01
I0829 18:09:09.688115 916722 solver.cpp:218] Iteration 522000 (16.6419 iter/s, 30.0446s/500 iters), loss = 0.155556
I0829 18:09:09.688175 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.155565 (* 1 = 0.155565 loss)
I0829 18:09:09.688184 916722 sgd_solver.cpp:106] Iteration 522000, lr = 0.01
I0829 18:09:39.749240 916722 solver.cpp:218] Iteration 522500 (16.6328 iter/s, 30.061s/500 iters), loss = 0.0359115
I0829 18:09:39.749302 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0359209 (* 1 = 0.0359209 loss)
I0829 18:09:39.749310 916722 sgd_solver.cpp:106] Iteration 522500, lr = 0.01
I0829 18:10:09.820780 916722 solver.cpp:218] Iteration 523000 (16.6271 iter/s, 30.0714s/500 iters), loss = 0.287912
I0829 18:10:09.820839 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.287921 (* 1 = 0.287921 loss)
I0829 18:10:09.820847 916722 sgd_solver.cpp:106] Iteration 523000, lr = 0.01
I0829 18:10:39.880053 916722 solver.cpp:218] Iteration 523500 (16.6339 iter/s, 30.0592s/500 iters), loss = 0.0824527
I0829 18:10:39.880115 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0824624 (* 1 = 0.0824624 loss)
I0829 18:10:39.880123 916722 sgd_solver.cpp:106] Iteration 523500, lr = 0.01
I0829 18:11:09.959813 916722 solver.cpp:218] Iteration 524000 (16.6225 iter/s, 30.0797s/500 iters), loss = 0.0423554
I0829 18:11:09.959873 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0423651 (* 1 = 0.0423651 loss)
I0829 18:11:09.959882 916722 sgd_solver.cpp:106] Iteration 524000, lr = 0.01
I0829 18:11:40.058992 916722 solver.cpp:218] Iteration 524500 (16.6118 iter/s, 30.0991s/500 iters), loss = 0.211385
I0829 18:11:40.059052 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.211395 (* 1 = 0.211395 loss)
I0829 18:11:40.059062 916722 sgd_solver.cpp:106] Iteration 524500, lr = 0.01
I0829 18:12:10.146319 916722 solver.cpp:218] Iteration 525000 (16.6184 iter/s, 30.0872s/500 iters), loss = 0.294823
I0829 18:12:10.146378 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.294833 (* 1 = 0.294833 loss)
I0829 18:12:10.146387 916722 sgd_solver.cpp:106] Iteration 525000, lr = 0.01
I0829 18:12:40.267506 916722 solver.cpp:218] Iteration 525500 (16.5998 iter/s, 30.1209s/500 iters), loss = 0.181636
I0829 18:12:40.267563 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.181646 (* 1 = 0.181646 loss)
I0829 18:12:40.267572 916722 sgd_solver.cpp:106] Iteration 525500, lr = 0.01
I0829 18:13:10.360028 916722 solver.cpp:218] Iteration 526000 (16.6156 iter/s, 30.0923s/500 iters), loss = 0.0708594
I0829 18:13:10.360088 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0708691 (* 1 = 0.0708691 loss)
I0829 18:13:10.360097 916722 sgd_solver.cpp:106] Iteration 526000, lr = 0.01
I0829 18:13:40.469667 916722 solver.cpp:218] Iteration 526500 (16.6061 iter/s, 30.1094s/500 iters), loss = 0.200588
I0829 18:13:40.469738 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.200598 (* 1 = 0.200598 loss)
I0829 18:13:40.469746 916722 sgd_solver.cpp:106] Iteration 526500, lr = 0.01
I0829 18:14:10.576310 916722 solver.cpp:218] Iteration 527000 (16.6078 iter/s, 30.1064s/500 iters), loss = 0.145028
I0829 18:14:10.576370 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.145038 (* 1 = 0.145038 loss)
I0829 18:14:10.576380 916722 sgd_solver.cpp:106] Iteration 527000, lr = 0.01
I0829 18:14:40.677080 916722 solver.cpp:218] Iteration 527500 (16.611 iter/s, 30.1005s/500 iters), loss = 0.240394
I0829 18:14:40.677140 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.240404 (* 1 = 0.240404 loss)
I0829 18:14:40.677148 916722 sgd_solver.cpp:106] Iteration 527500, lr = 0.01
I0829 18:15:10.783331 916722 solver.cpp:218] Iteration 528000 (16.608 iter/s, 30.106s/500 iters), loss = 0.127408
I0829 18:15:10.783392 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.127418 (* 1 = 0.127418 loss)
I0829 18:15:10.783401 916722 sgd_solver.cpp:106] Iteration 528000, lr = 0.01
I0829 18:15:40.877574 916722 solver.cpp:218] Iteration 528500 (16.6146 iter/s, 30.094s/500 iters), loss = 0.111278
I0829 18:15:40.877635 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111288 (* 1 = 0.111288 loss)
I0829 18:15:40.877645 916722 sgd_solver.cpp:106] Iteration 528500, lr = 0.01
I0829 18:16:10.961802 916722 solver.cpp:218] Iteration 529000 (16.6201 iter/s, 30.084s/500 iters), loss = 0.180063
I0829 18:16:10.961860 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.180073 (* 1 = 0.180073 loss)
I0829 18:16:10.961869 916722 sgd_solver.cpp:106] Iteration 529000, lr = 0.01
I0829 18:16:41.060928 916722 solver.cpp:218] Iteration 529500 (16.6119 iter/s, 30.0989s/500 iters), loss = 0.431851
I0829 18:16:41.060981 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.431861 (* 1 = 0.431861 loss)
I0829 18:16:41.060989 916722 sgd_solver.cpp:106] Iteration 529500, lr = 0.01
I0829 18:17:11.167137 916722 solver.cpp:218] Iteration 530000 (16.608 iter/s, 30.106s/500 iters), loss = 0.0340311
I0829 18:17:11.167193 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0340412 (* 1 = 0.0340412 loss)
I0829 18:17:11.167202 916722 sgd_solver.cpp:106] Iteration 530000, lr = 0.01
I0829 18:17:41.250119 916722 solver.cpp:218] Iteration 530500 (16.6208 iter/s, 30.0828s/500 iters), loss = 0.0611625
I0829 18:17:41.250180 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0611727 (* 1 = 0.0611727 loss)
I0829 18:17:41.250188 916722 sgd_solver.cpp:106] Iteration 530500, lr = 0.01
I0829 18:18:11.354632 916722 solver.cpp:218] Iteration 531000 (16.6089 iter/s, 30.1043s/500 iters), loss = 0.111674
I0829 18:18:11.354692 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111684 (* 1 = 0.111684 loss)
I0829 18:18:11.354701 916722 sgd_solver.cpp:106] Iteration 531000, lr = 0.01
I0829 18:18:41.450232 916722 solver.cpp:218] Iteration 531500 (16.6138 iter/s, 30.0954s/500 iters), loss = 0.30065
I0829 18:18:41.450291 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.30066 (* 1 = 0.30066 loss)
I0829 18:18:41.450300 916722 sgd_solver.cpp:106] Iteration 531500, lr = 0.01
I0829 18:19:11.559012 916722 solver.cpp:218] Iteration 532000 (16.6066 iter/s, 30.1086s/500 iters), loss = 0.0898448
I0829 18:19:11.559072 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0898547 (* 1 = 0.0898547 loss)
I0829 18:19:11.559082 916722 sgd_solver.cpp:106] Iteration 532000, lr = 0.01
I0829 18:19:41.686741 916722 solver.cpp:218] Iteration 532500 (16.5961 iter/s, 30.1276s/500 iters), loss = 0.189914
I0829 18:19:41.686801 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.189924 (* 1 = 0.189924 loss)
I0829 18:19:41.686810 916722 sgd_solver.cpp:106] Iteration 532500, lr = 0.01
I0829 18:20:11.773993 916722 solver.cpp:218] Iteration 533000 (16.6184 iter/s, 30.0871s/500 iters), loss = 0.20542
I0829 18:20:11.774077 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.20543 (* 1 = 0.20543 loss)
I0829 18:20:11.774085 916722 sgd_solver.cpp:106] Iteration 533000, lr = 0.01
I0829 18:20:41.873976 916722 solver.cpp:218] Iteration 533500 (16.6114 iter/s, 30.0998s/500 iters), loss = 0.0559127
I0829 18:20:41.874038 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0559228 (* 1 = 0.0559228 loss)
I0829 18:20:41.874047 916722 sgd_solver.cpp:106] Iteration 533500, lr = 0.01
I0829 18:21:11.961305 916722 solver.cpp:218] Iteration 534000 (16.6184 iter/s, 30.0872s/500 iters), loss = 0.0731675
I0829 18:21:11.961360 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0731778 (* 1 = 0.0731778 loss)
I0829 18:21:11.961369 916722 sgd_solver.cpp:106] Iteration 534000, lr = 0.01
I0829 18:21:42.067826 916722 solver.cpp:218] Iteration 534500 (16.6078 iter/s, 30.1064s/500 iters), loss = 0.178432
I0829 18:21:42.067883 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.178443 (* 1 = 0.178443 loss)
I0829 18:21:42.067890 916722 sgd_solver.cpp:106] Iteration 534500, lr = 0.01
I0829 18:22:12.163398 916722 solver.cpp:218] Iteration 535000 (16.6138 iter/s, 30.0954s/500 iters), loss = 0.230745
I0829 18:22:12.163458 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.230755 (* 1 = 0.230755 loss)
I0829 18:22:12.163467 916722 sgd_solver.cpp:106] Iteration 535000, lr = 0.01
I0829 18:22:42.286204 916722 solver.cpp:218] Iteration 535500 (16.5988 iter/s, 30.1226s/500 iters), loss = 0.370781
I0829 18:22:42.286264 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.370791 (* 1 = 0.370791 loss)
I0829 18:22:42.286273 916722 sgd_solver.cpp:106] Iteration 535500, lr = 0.01
I0829 18:23:12.386992 916722 solver.cpp:218] Iteration 536000 (16.6109 iter/s, 30.1006s/500 iters), loss = 0.139972
I0829 18:23:12.387053 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139983 (* 1 = 0.139983 loss)
I0829 18:23:12.387061 916722 sgd_solver.cpp:106] Iteration 536000, lr = 0.01
I0829 18:23:42.485096 916722 solver.cpp:218] Iteration 536500 (16.6124 iter/s, 30.0979s/500 iters), loss = 0.167864
I0829 18:23:42.485157 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.167874 (* 1 = 0.167874 loss)
I0829 18:23:42.485164 916722 sgd_solver.cpp:106] Iteration 536500, lr = 0.01
I0829 18:24:12.594516 916722 solver.cpp:218] Iteration 537000 (16.6062 iter/s, 30.1093s/500 iters), loss = 0.112516
I0829 18:24:12.594573 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112527 (* 1 = 0.112527 loss)
I0829 18:24:12.594583 916722 sgd_solver.cpp:106] Iteration 537000, lr = 0.01
I0829 18:24:42.678550 916722 solver.cpp:218] Iteration 537500 (16.6202 iter/s, 30.0839s/500 iters), loss = 0.224709
I0829 18:24:42.678611 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.224719 (* 1 = 0.224719 loss)
I0829 18:24:42.678618 916722 sgd_solver.cpp:106] Iteration 537500, lr = 0.01
I0829 18:25:12.793987 916722 solver.cpp:218] Iteration 538000 (16.6029 iter/s, 30.1153s/500 iters), loss = 0.161244
I0829 18:25:12.794047 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.161254 (* 1 = 0.161254 loss)
I0829 18:25:12.794055 916722 sgd_solver.cpp:106] Iteration 538000, lr = 0.01
I0829 18:25:42.881958 916722 solver.cpp:218] Iteration 538500 (16.618 iter/s, 30.0878s/500 iters), loss = 0.234546
I0829 18:25:42.882016 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.234557 (* 1 = 0.234557 loss)
I0829 18:25:42.882025 916722 sgd_solver.cpp:106] Iteration 538500, lr = 0.01
I0829 18:26:12.961339 916722 solver.cpp:218] Iteration 539000 (16.6228 iter/s, 30.0792s/500 iters), loss = 0.283094
I0829 18:26:12.961397 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.283105 (* 1 = 0.283105 loss)
I0829 18:26:12.961406 916722 sgd_solver.cpp:106] Iteration 539000, lr = 0.01
I0829 18:26:43.038394 916722 solver.cpp:218] Iteration 539500 (16.624 iter/s, 30.0769s/500 iters), loss = 0.282358
I0829 18:26:43.038462 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.282368 (* 1 = 0.282368 loss)
I0829 18:26:43.038475 916722 sgd_solver.cpp:106] Iteration 539500, lr = 0.01
I0829 18:27:13.120545 916722 solver.cpp:218] Iteration 540000 (16.6212 iter/s, 30.082s/500 iters), loss = 0.0418191
I0829 18:27:13.120605 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0418298 (* 1 = 0.0418298 loss)
I0829 18:27:13.120615 916722 sgd_solver.cpp:106] Iteration 540000, lr = 0.01
I0829 18:27:43.204886 916722 solver.cpp:218] Iteration 540500 (16.62 iter/s, 30.0842s/500 iters), loss = 0.184087
I0829 18:27:43.204943 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.184097 (* 1 = 0.184097 loss)
I0829 18:27:43.204952 916722 sgd_solver.cpp:106] Iteration 540500, lr = 0.01
I0829 18:28:13.285660 916722 solver.cpp:218] Iteration 541000 (16.622 iter/s, 30.0806s/500 iters), loss = 0.0695116
I0829 18:28:13.285720 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0695219 (* 1 = 0.0695219 loss)
I0829 18:28:13.285729 916722 sgd_solver.cpp:106] Iteration 541000, lr = 0.01
I0829 18:28:43.371920 916722 solver.cpp:218] Iteration 541500 (16.619 iter/s, 30.0861s/500 iters), loss = 0.402167
I0829 18:28:43.371978 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.402177 (* 1 = 0.402177 loss)
I0829 18:28:43.371986 916722 sgd_solver.cpp:106] Iteration 541500, lr = 0.01
I0829 18:29:13.458294 916722 solver.cpp:218] Iteration 542000 (16.6189 iter/s, 30.0862s/500 iters), loss = 0.239511
I0829 18:29:13.458353 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.239522 (* 1 = 0.239522 loss)
I0829 18:29:13.458362 916722 sgd_solver.cpp:106] Iteration 542000, lr = 0.01
I0829 18:29:43.539453 916722 solver.cpp:218] Iteration 542500 (16.6218 iter/s, 30.081s/500 iters), loss = 0.0735073
I0829 18:29:43.539505 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0735178 (* 1 = 0.0735178 loss)
I0829 18:29:43.539515 916722 sgd_solver.cpp:106] Iteration 542500, lr = 0.01
I0829 18:30:13.635586 916722 solver.cpp:218] Iteration 543000 (16.6135 iter/s, 30.096s/500 iters), loss = 0.0520979
I0829 18:30:13.635643 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0521086 (* 1 = 0.0521086 loss)
I0829 18:30:13.635653 916722 sgd_solver.cpp:106] Iteration 543000, lr = 0.01
I0829 18:30:43.720382 916722 solver.cpp:218] Iteration 543500 (16.6198 iter/s, 30.0847s/500 iters), loss = 0.23719
I0829 18:30:43.720456 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.237201 (* 1 = 0.237201 loss)
I0829 18:30:43.720465 916722 sgd_solver.cpp:106] Iteration 543500, lr = 0.01
I0829 18:31:13.812770 916722 solver.cpp:218] Iteration 544000 (16.6156 iter/s, 30.0922s/500 iters), loss = 0.420685
I0829 18:31:13.812829 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.420696 (* 1 = 0.420696 loss)
I0829 18:31:13.812837 916722 sgd_solver.cpp:106] Iteration 544000, lr = 0.01
I0829 18:31:43.892045 916722 solver.cpp:218] Iteration 544500 (16.6228 iter/s, 30.0791s/500 iters), loss = 0.627093
I0829 18:31:43.892102 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.627103 (* 1 = 0.627103 loss)
I0829 18:31:43.892109 916722 sgd_solver.cpp:106] Iteration 544500, lr = 0.01
I0829 18:32:13.985083 916722 solver.cpp:218] Iteration 545000 (16.6152 iter/s, 30.0929s/500 iters), loss = 0.312192
I0829 18:32:13.985142 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.312203 (* 1 = 0.312203 loss)
I0829 18:32:13.985150 916722 sgd_solver.cpp:106] Iteration 545000, lr = 0.01
I0829 18:32:44.066177 916722 solver.cpp:218] Iteration 545500 (16.6218 iter/s, 30.081s/500 iters), loss = 0.208417
I0829 18:32:44.066234 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.208428 (* 1 = 0.208428 loss)
I0829 18:32:44.066242 916722 sgd_solver.cpp:106] Iteration 545500, lr = 0.01
I0829 18:33:14.152985 916722 solver.cpp:218] Iteration 546000 (16.6187 iter/s, 30.0867s/500 iters), loss = 0.188961
I0829 18:33:14.153056 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.188972 (* 1 = 0.188972 loss)
I0829 18:33:14.153069 916722 sgd_solver.cpp:106] Iteration 546000, lr = 0.01
I0829 18:33:44.237810 916722 solver.cpp:218] Iteration 546500 (16.6198 iter/s, 30.0847s/500 iters), loss = 0.273836
I0829 18:33:44.237865 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.273847 (* 1 = 0.273847 loss)
I0829 18:33:44.237874 916722 sgd_solver.cpp:106] Iteration 546500, lr = 0.01
I0829 18:34:14.336195 916722 solver.cpp:218] Iteration 547000 (16.6123 iter/s, 30.0983s/500 iters), loss = 0.126996
I0829 18:34:14.336252 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.127006 (* 1 = 0.127006 loss)
I0829 18:34:14.336261 916722 sgd_solver.cpp:106] Iteration 547000, lr = 0.01
I0829 18:34:44.420727 916722 solver.cpp:218] Iteration 547500 (16.6199 iter/s, 30.0844s/500 iters), loss = 0.134853
I0829 18:34:44.420780 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.134864 (* 1 = 0.134864 loss)
I0829 18:34:44.420789 916722 sgd_solver.cpp:106] Iteration 547500, lr = 0.01
I0829 18:35:14.502769 916722 solver.cpp:218] Iteration 548000 (16.6213 iter/s, 30.0819s/500 iters), loss = 0.130731
I0829 18:35:14.502827 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130742 (* 1 = 0.130742 loss)
I0829 18:35:14.502835 916722 sgd_solver.cpp:106] Iteration 548000, lr = 0.01
I0829 18:35:44.594275 916722 solver.cpp:218] Iteration 548500 (16.6161 iter/s, 30.0914s/500 iters), loss = 0.307642
I0829 18:35:44.594331 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.307653 (* 1 = 0.307653 loss)
I0829 18:35:44.594339 916722 sgd_solver.cpp:106] Iteration 548500, lr = 0.01
I0829 18:36:14.692148 916722 solver.cpp:218] Iteration 549000 (16.6125 iter/s, 30.0977s/500 iters), loss = 0.0666662
I0829 18:36:14.692209 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0666766 (* 1 = 0.0666766 loss)
I0829 18:36:14.692217 916722 sgd_solver.cpp:106] Iteration 549000, lr = 0.01
I0829 18:36:44.800792 916722 solver.cpp:218] Iteration 549500 (16.6066 iter/s, 30.1085s/500 iters), loss = 0.100276
I0829 18:36:44.800850 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.100286 (* 1 = 0.100286 loss)
I0829 18:36:44.800859 916722 sgd_solver.cpp:106] Iteration 549500, lr = 0.01
I0829 18:37:14.827370 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_550000.caffemodel
I0829 18:37:14.846698 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_550000.solverstate
I0829 18:37:14.852844 916722 solver.cpp:330] Iteration 550000, Testing net (#0)
I0829 18:37:30.323256 916722 solver.cpp:397]     Test net output #0: accuracy = 0.893
I0829 18:37:30.323300 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.350514 (* 1 = 0.350514 loss)
I0829 18:37:30.382150 916722 solver.cpp:218] Iteration 550000 (10.9694 iter/s, 45.5812s/500 iters), loss = 0.116336
I0829 18:37:30.382179 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.116347 (* 1 = 0.116347 loss)
I0829 18:37:30.382189 916722 sgd_solver.cpp:106] Iteration 550000, lr = 0.01
I0829 18:38:00.301311 916722 solver.cpp:218] Iteration 550500 (16.7118 iter/s, 29.919s/500 iters), loss = 0.0173864
I0829 18:38:00.301369 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0173968 (* 1 = 0.0173968 loss)
I0829 18:38:00.301378 916722 sgd_solver.cpp:106] Iteration 550500, lr = 0.01
I0829 18:38:30.334748 916722 solver.cpp:218] Iteration 551000 (16.6482 iter/s, 30.0333s/500 iters), loss = 0.164271
I0829 18:38:30.334805 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.164281 (* 1 = 0.164281 loss)
I0829 18:38:30.334812 916722 sgd_solver.cpp:106] Iteration 551000, lr = 0.01
I0829 18:39:00.388020 916722 solver.cpp:218] Iteration 551500 (16.6372 iter/s, 30.0531s/500 iters), loss = 0.108049
I0829 18:39:00.388078 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.108059 (* 1 = 0.108059 loss)
I0829 18:39:00.388087 916722 sgd_solver.cpp:106] Iteration 551500, lr = 0.01
I0829 18:39:30.462868 916722 solver.cpp:218] Iteration 552000 (16.6253 iter/s, 30.0747s/500 iters), loss = 0.0589553
I0829 18:39:30.462945 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0589655 (* 1 = 0.0589655 loss)
I0829 18:39:30.462954 916722 sgd_solver.cpp:106] Iteration 552000, lr = 0.01
I0829 18:40:00.511656 916722 solver.cpp:218] Iteration 552500 (16.6397 iter/s, 30.0486s/500 iters), loss = 0.0928605
I0829 18:40:00.511715 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0928707 (* 1 = 0.0928707 loss)
I0829 18:40:00.511724 916722 sgd_solver.cpp:106] Iteration 552500, lr = 0.01
I0829 18:40:30.593021 916722 solver.cpp:218] Iteration 553000 (16.6217 iter/s, 30.0812s/500 iters), loss = 0.211698
I0829 18:40:30.593077 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.211709 (* 1 = 0.211709 loss)
I0829 18:40:30.593086 916722 sgd_solver.cpp:106] Iteration 553000, lr = 0.01
I0829 18:41:00.662998 916722 solver.cpp:218] Iteration 553500 (16.628 iter/s, 30.0698s/500 iters), loss = 0.19497
I0829 18:41:00.663053 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.19498 (* 1 = 0.19498 loss)
I0829 18:41:00.663062 916722 sgd_solver.cpp:106] Iteration 553500, lr = 0.01
I0829 18:41:30.751077 916722 solver.cpp:218] Iteration 554000 (16.6179 iter/s, 30.0879s/500 iters), loss = 0.114386
I0829 18:41:30.751137 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.114396 (* 1 = 0.114396 loss)
I0829 18:41:30.751144 916722 sgd_solver.cpp:106] Iteration 554000, lr = 0.01
I0829 18:42:00.820997 916722 solver.cpp:218] Iteration 554500 (16.628 iter/s, 30.0698s/500 iters), loss = 0.139054
I0829 18:42:00.821054 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139064 (* 1 = 0.139064 loss)
I0829 18:42:00.821063 916722 sgd_solver.cpp:106] Iteration 554500, lr = 0.01
I0829 18:42:30.906915 916722 solver.cpp:218] Iteration 555000 (16.6191 iter/s, 30.0858s/500 iters), loss = 0.185866
I0829 18:42:30.906972 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.185876 (* 1 = 0.185876 loss)
I0829 18:42:30.906980 916722 sgd_solver.cpp:106] Iteration 555000, lr = 0.01
I0829 18:43:00.977756 916722 solver.cpp:218] Iteration 555500 (16.6275 iter/s, 30.0707s/500 iters), loss = 0.163122
I0829 18:43:00.977813 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.163132 (* 1 = 0.163132 loss)
I0829 18:43:00.977820 916722 sgd_solver.cpp:106] Iteration 555500, lr = 0.01
I0829 18:43:31.063491 916722 solver.cpp:218] Iteration 556000 (16.6192 iter/s, 30.0856s/500 iters), loss = 0.217811
I0829 18:43:31.063550 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.217821 (* 1 = 0.217821 loss)
I0829 18:43:31.063558 916722 sgd_solver.cpp:106] Iteration 556000, lr = 0.01
I0829 18:44:01.139322 916722 solver.cpp:218] Iteration 556500 (16.6247 iter/s, 30.0757s/500 iters), loss = 0.267018
I0829 18:44:01.139377 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.267028 (* 1 = 0.267028 loss)
I0829 18:44:01.139385 916722 sgd_solver.cpp:106] Iteration 556500, lr = 0.01
I0829 18:44:31.223414 916722 solver.cpp:218] Iteration 557000 (16.6201 iter/s, 30.084s/500 iters), loss = 0.185691
I0829 18:44:31.223470 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.185701 (* 1 = 0.185701 loss)
I0829 18:44:31.223479 916722 sgd_solver.cpp:106] Iteration 557000, lr = 0.01
I0829 18:45:01.292325 916722 solver.cpp:218] Iteration 557500 (16.6285 iter/s, 30.0688s/500 iters), loss = 0.0322376
I0829 18:45:01.292378 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0322476 (* 1 = 0.0322476 loss)
I0829 18:45:01.292387 916722 sgd_solver.cpp:106] Iteration 557500, lr = 0.01
I0829 18:45:31.364317 916722 solver.cpp:218] Iteration 558000 (16.6268 iter/s, 30.0719s/500 iters), loss = 0.326463
I0829 18:45:31.364372 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.326473 (* 1 = 0.326473 loss)
I0829 18:45:31.364380 916722 sgd_solver.cpp:106] Iteration 558000, lr = 0.01
I0829 18:46:01.402019 916722 solver.cpp:218] Iteration 558500 (16.6458 iter/s, 30.0376s/500 iters), loss = 0.0403484
I0829 18:46:01.402087 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0403585 (* 1 = 0.0403585 loss)
I0829 18:46:01.402099 916722 sgd_solver.cpp:106] Iteration 558500, lr = 0.01
I0829 18:46:31.469020 916722 solver.cpp:218] Iteration 559000 (16.6294 iter/s, 30.0672s/500 iters), loss = 0.0280055
I0829 18:46:31.469075 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0280156 (* 1 = 0.0280156 loss)
I0829 18:46:31.469084 916722 sgd_solver.cpp:106] Iteration 559000, lr = 0.01
I0829 18:47:01.550628 916722 solver.cpp:218] Iteration 559500 (16.6213 iter/s, 30.082s/500 iters), loss = 0.112499
I0829 18:47:01.550685 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112509 (* 1 = 0.112509 loss)
I0829 18:47:01.550693 916722 sgd_solver.cpp:106] Iteration 559500, lr = 0.01
I0829 18:47:31.618389 916722 solver.cpp:218] Iteration 560000 (16.6289 iter/s, 30.0681s/500 iters), loss = 0.101222
I0829 18:47:31.618444 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101232 (* 1 = 0.101232 loss)
I0829 18:47:31.618453 916722 sgd_solver.cpp:106] Iteration 560000, lr = 0.01
I0829 18:48:01.682607 916722 solver.cpp:218] Iteration 560500 (16.6309 iter/s, 30.0645s/500 iters), loss = 0.0974851
I0829 18:48:01.682663 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0974952 (* 1 = 0.0974952 loss)
I0829 18:48:01.682672 916722 sgd_solver.cpp:106] Iteration 560500, lr = 0.01
I0829 18:48:31.756943 916722 solver.cpp:218] Iteration 561000 (16.6253 iter/s, 30.0746s/500 iters), loss = 0.176769
I0829 18:48:31.756999 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.176779 (* 1 = 0.176779 loss)
I0829 18:48:31.757007 916722 sgd_solver.cpp:106] Iteration 561000, lr = 0.01
I0829 18:49:01.828426 916722 solver.cpp:218] Iteration 561500 (16.6269 iter/s, 30.0717s/500 iters), loss = 0.209308
I0829 18:49:01.828485 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.209318 (* 1 = 0.209318 loss)
I0829 18:49:01.828492 916722 sgd_solver.cpp:106] Iteration 561500, lr = 0.01
I0829 18:49:31.879683 916722 solver.cpp:218] Iteration 562000 (16.6381 iter/s, 30.0515s/500 iters), loss = 0.169561
I0829 18:49:31.879736 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.169572 (* 1 = 0.169572 loss)
I0829 18:49:31.879745 916722 sgd_solver.cpp:106] Iteration 562000, lr = 0.01
I0829 18:50:01.946408 916722 solver.cpp:218] Iteration 562500 (16.6296 iter/s, 30.067s/500 iters), loss = 0.474359
I0829 18:50:01.946462 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.474369 (* 1 = 0.474369 loss)
I0829 18:50:01.946471 916722 sgd_solver.cpp:106] Iteration 562500, lr = 0.01
I0829 18:50:32.052323 916722 solver.cpp:218] Iteration 563000 (16.6079 iter/s, 30.1061s/500 iters), loss = 0.0866483
I0829 18:50:32.052381 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0866584 (* 1 = 0.0866584 loss)
I0829 18:50:32.052389 916722 sgd_solver.cpp:106] Iteration 563000, lr = 0.01
I0829 18:51:02.084991 916722 solver.cpp:218] Iteration 563500 (16.6484 iter/s, 30.0329s/500 iters), loss = 0.31842
I0829 18:51:02.085047 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.31843 (* 1 = 0.31843 loss)
I0829 18:51:02.085055 916722 sgd_solver.cpp:106] Iteration 563500, lr = 0.01
I0829 18:51:32.141310 916722 solver.cpp:218] Iteration 564000 (16.6353 iter/s, 30.0565s/500 iters), loss = 0.0531043
I0829 18:51:32.141366 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0531144 (* 1 = 0.0531144 loss)
I0829 18:51:32.141374 916722 sgd_solver.cpp:106] Iteration 564000, lr = 0.01
I0829 18:52:02.204205 916722 solver.cpp:218] Iteration 564500 (16.6317 iter/s, 30.0631s/500 iters), loss = 0.0430127
I0829 18:52:02.204260 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0430227 (* 1 = 0.0430227 loss)
I0829 18:52:02.204269 916722 sgd_solver.cpp:106] Iteration 564500, lr = 0.01
I0829 18:52:32.264390 916722 solver.cpp:218] Iteration 565000 (16.6332 iter/s, 30.0603s/500 iters), loss = 0.12311
I0829 18:52:32.264465 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.12312 (* 1 = 0.12312 loss)
I0829 18:52:32.264479 916722 sgd_solver.cpp:106] Iteration 565000, lr = 0.01
I0829 18:53:02.323127 916722 solver.cpp:218] Iteration 565500 (16.634 iter/s, 30.0589s/500 iters), loss = 0.0805929
I0829 18:53:02.323185 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0806033 (* 1 = 0.0806033 loss)
I0829 18:53:02.323194 916722 sgd_solver.cpp:106] Iteration 565500, lr = 0.01
I0829 18:53:32.347409 916722 solver.cpp:218] Iteration 566000 (16.6531 iter/s, 30.0244s/500 iters), loss = 0.0728519
I0829 18:53:32.347467 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0728622 (* 1 = 0.0728622 loss)
I0829 18:53:32.347476 916722 sgd_solver.cpp:106] Iteration 566000, lr = 0.01
I0829 18:54:02.381136 916722 solver.cpp:218] Iteration 566500 (16.6479 iter/s, 30.0338s/500 iters), loss = 0.244249
I0829 18:54:02.381192 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.24426 (* 1 = 0.24426 loss)
I0829 18:54:02.381201 916722 sgd_solver.cpp:106] Iteration 566500, lr = 0.01
I0829 18:54:32.414070 916722 solver.cpp:218] Iteration 567000 (16.6483 iter/s, 30.033s/500 iters), loss = 0.0759996
I0829 18:54:32.414126 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0760099 (* 1 = 0.0760099 loss)
I0829 18:54:32.414135 916722 sgd_solver.cpp:106] Iteration 567000, lr = 0.01
I0829 18:55:02.433713 916722 solver.cpp:218] Iteration 567500 (16.6557 iter/s, 30.0197s/500 iters), loss = 0.227295
I0829 18:55:02.433771 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.227305 (* 1 = 0.227305 loss)
I0829 18:55:02.433779 916722 sgd_solver.cpp:106] Iteration 567500, lr = 0.01
I0829 18:55:32.482856 916722 solver.cpp:218] Iteration 568000 (16.6394 iter/s, 30.0492s/500 iters), loss = 0.136601
I0829 18:55:32.482913 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.136612 (* 1 = 0.136612 loss)
I0829 18:55:32.482920 916722 sgd_solver.cpp:106] Iteration 568000, lr = 0.01
I0829 18:56:02.530994 916722 solver.cpp:218] Iteration 568500 (16.6399 iter/s, 30.0482s/500 iters), loss = 0.221008
I0829 18:56:02.531052 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.221018 (* 1 = 0.221018 loss)
I0829 18:56:02.531061 916722 sgd_solver.cpp:106] Iteration 568500, lr = 0.01
I0829 18:56:32.595608 916722 solver.cpp:218] Iteration 569000 (16.6308 iter/s, 30.0647s/500 iters), loss = 0.064737
I0829 18:56:32.595664 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0647471 (* 1 = 0.0647471 loss)
I0829 18:56:32.595672 916722 sgd_solver.cpp:106] Iteration 569000, lr = 0.01
I0829 18:57:02.693186 916722 solver.cpp:218] Iteration 569500 (16.6126 iter/s, 30.0976s/500 iters), loss = 0.109806
I0829 18:57:02.693244 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109816 (* 1 = 0.109816 loss)
I0829 18:57:02.693253 916722 sgd_solver.cpp:106] Iteration 569500, lr = 0.01
I0829 18:57:32.746615 916722 solver.cpp:218] Iteration 570000 (16.637 iter/s, 30.0535s/500 iters), loss = 0.36893
I0829 18:57:32.746672 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.36894 (* 1 = 0.36894 loss)
I0829 18:57:32.746680 916722 sgd_solver.cpp:106] Iteration 570000, lr = 0.01
I0829 18:58:02.832759 916722 solver.cpp:218] Iteration 570500 (16.6189 iter/s, 30.0862s/500 iters), loss = 0.0599412
I0829 18:58:02.832818 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0599514 (* 1 = 0.0599514 loss)
I0829 18:58:02.832826 916722 sgd_solver.cpp:106] Iteration 570500, lr = 0.01
I0829 18:58:32.878953 916722 solver.cpp:218] Iteration 571000 (16.641 iter/s, 30.0462s/500 iters), loss = 0.0958995
I0829 18:58:32.879010 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0959099 (* 1 = 0.0959099 loss)
I0829 18:58:32.879019 916722 sgd_solver.cpp:106] Iteration 571000, lr = 0.01
I0829 18:59:02.939370 916722 solver.cpp:218] Iteration 571500 (16.6331 iter/s, 30.0605s/500 iters), loss = 0.244682
I0829 18:59:02.939429 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.244692 (* 1 = 0.244692 loss)
I0829 18:59:02.939436 916722 sgd_solver.cpp:106] Iteration 571500, lr = 0.01
I0829 18:59:33.017699 916722 solver.cpp:218] Iteration 572000 (16.6232 iter/s, 30.0784s/500 iters), loss = 0.042805
I0829 18:59:33.017765 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0428154 (* 1 = 0.0428154 loss)
I0829 18:59:33.017773 916722 sgd_solver.cpp:106] Iteration 572000, lr = 0.01
I0829 19:00:03.077325 916722 solver.cpp:218] Iteration 572500 (16.6336 iter/s, 30.0597s/500 iters), loss = 0.0377925
I0829 19:00:03.077383 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0378028 (* 1 = 0.0378028 loss)
I0829 19:00:03.077390 916722 sgd_solver.cpp:106] Iteration 572500, lr = 0.01
I0829 19:00:33.133455 916722 solver.cpp:218] Iteration 573000 (16.6355 iter/s, 30.0562s/500 iters), loss = 0.266786
I0829 19:00:33.133512 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.266796 (* 1 = 0.266796 loss)
I0829 19:00:33.133520 916722 sgd_solver.cpp:106] Iteration 573000, lr = 0.01
I0829 19:01:03.176085 916722 solver.cpp:218] Iteration 573500 (16.643 iter/s, 30.0427s/500 iters), loss = 0.346431
I0829 19:01:03.176143 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.346441 (* 1 = 0.346441 loss)
I0829 19:01:03.176151 916722 sgd_solver.cpp:106] Iteration 573500, lr = 0.01
I0829 19:01:33.226969 916722 solver.cpp:218] Iteration 574000 (16.6384 iter/s, 30.0509s/500 iters), loss = 0.572983
I0829 19:01:33.227025 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.572993 (* 1 = 0.572993 loss)
I0829 19:01:33.227032 916722 sgd_solver.cpp:106] Iteration 574000, lr = 0.01
I0829 19:02:03.271687 916722 solver.cpp:218] Iteration 574500 (16.6418 iter/s, 30.0447s/500 iters), loss = 0.0527406
I0829 19:02:03.271745 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0527506 (* 1 = 0.0527506 loss)
I0829 19:02:03.271754 916722 sgd_solver.cpp:106] Iteration 574500, lr = 0.01
I0829 19:02:33.331694 916722 solver.cpp:218] Iteration 575000 (16.6334 iter/s, 30.06s/500 iters), loss = 0.130901
I0829 19:02:33.331753 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130911 (* 1 = 0.130911 loss)
I0829 19:02:33.331761 916722 sgd_solver.cpp:106] Iteration 575000, lr = 0.01
I0829 19:03:03.393214 916722 solver.cpp:218] Iteration 575500 (16.6326 iter/s, 30.0615s/500 iters), loss = 0.183208
I0829 19:03:03.393270 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.183218 (* 1 = 0.183218 loss)
I0829 19:03:03.393278 916722 sgd_solver.cpp:106] Iteration 575500, lr = 0.01
I0829 19:03:33.438635 916722 solver.cpp:218] Iteration 576000 (16.6415 iter/s, 30.0454s/500 iters), loss = 0.0621974
I0829 19:03:33.438690 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0622076 (* 1 = 0.0622076 loss)
I0829 19:03:33.438699 916722 sgd_solver.cpp:106] Iteration 576000, lr = 0.01
I0829 19:04:03.496084 916722 solver.cpp:218] Iteration 576500 (16.6348 iter/s, 30.0575s/500 iters), loss = 0.114975
I0829 19:04:03.496141 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.114986 (* 1 = 0.114986 loss)
I0829 19:04:03.496150 916722 sgd_solver.cpp:106] Iteration 576500, lr = 0.01
I0829 19:04:33.550863 916722 solver.cpp:218] Iteration 577000 (16.6363 iter/s, 30.0548s/500 iters), loss = 0.1149
I0829 19:04:33.550918 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.11491 (* 1 = 0.11491 loss)
I0829 19:04:33.550926 916722 sgd_solver.cpp:106] Iteration 577000, lr = 0.01
I0829 19:05:03.594014 916722 solver.cpp:218] Iteration 577500 (16.6427 iter/s, 30.0431s/500 iters), loss = 0.105432
I0829 19:05:03.594069 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105443 (* 1 = 0.105443 loss)
I0829 19:05:03.594077 916722 sgd_solver.cpp:106] Iteration 577500, lr = 0.01
I0829 19:05:33.662673 916722 solver.cpp:218] Iteration 578000 (16.6286 iter/s, 30.0687s/500 iters), loss = 0.109332
I0829 19:05:33.662727 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109342 (* 1 = 0.109342 loss)
I0829 19:05:33.662735 916722 sgd_solver.cpp:106] Iteration 578000, lr = 0.01
I0829 19:06:03.717238 916722 solver.cpp:218] Iteration 578500 (16.6364 iter/s, 30.0546s/500 iters), loss = 0.369397
I0829 19:06:03.717310 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.369407 (* 1 = 0.369407 loss)
I0829 19:06:03.717319 916722 sgd_solver.cpp:106] Iteration 578500, lr = 0.01
I0829 19:06:33.802038 916722 solver.cpp:218] Iteration 579000 (16.6197 iter/s, 30.0848s/500 iters), loss = 0.159123
I0829 19:06:33.802093 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159134 (* 1 = 0.159134 loss)
I0829 19:06:33.802100 916722 sgd_solver.cpp:106] Iteration 579000, lr = 0.01
I0829 19:07:03.863144 916722 solver.cpp:218] Iteration 579500 (16.6328 iter/s, 30.0611s/500 iters), loss = 0.115866
I0829 19:07:03.863204 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115877 (* 1 = 0.115877 loss)
I0829 19:07:03.863212 916722 sgd_solver.cpp:106] Iteration 579500, lr = 0.01
I0829 19:07:33.911628 916722 solver.cpp:218] Iteration 580000 (16.6398 iter/s, 30.0485s/500 iters), loss = 0.106686
I0829 19:07:33.911684 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.106696 (* 1 = 0.106696 loss)
I0829 19:07:33.911692 916722 sgd_solver.cpp:106] Iteration 580000, lr = 0.01
I0829 19:08:03.958027 916722 solver.cpp:218] Iteration 580500 (16.6409 iter/s, 30.0464s/500 iters), loss = 0.0644406
I0829 19:08:03.958086 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.064451 (* 1 = 0.064451 loss)
I0829 19:08:03.958094 916722 sgd_solver.cpp:106] Iteration 580500, lr = 0.01
I0829 19:08:34.023645 916722 solver.cpp:218] Iteration 581000 (16.6303 iter/s, 30.0656s/500 iters), loss = 0.368408
I0829 19:08:34.023702 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.368418 (* 1 = 0.368418 loss)
I0829 19:08:34.023711 916722 sgd_solver.cpp:106] Iteration 581000, lr = 0.01
I0829 19:09:04.075794 916722 solver.cpp:218] Iteration 581500 (16.6378 iter/s, 30.0521s/500 iters), loss = 0.161479
I0829 19:09:04.075852 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.16149 (* 1 = 0.16149 loss)
I0829 19:09:04.075860 916722 sgd_solver.cpp:106] Iteration 581500, lr = 0.01
I0829 19:09:34.138079 916722 solver.cpp:218] Iteration 582000 (16.6321 iter/s, 30.0623s/500 iters), loss = 0.223258
I0829 19:09:34.138131 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.223269 (* 1 = 0.223269 loss)
I0829 19:09:34.138139 916722 sgd_solver.cpp:106] Iteration 582000, lr = 0.01
I0829 19:10:04.193526 916722 solver.cpp:218] Iteration 582500 (16.6359 iter/s, 30.0554s/500 iters), loss = 0.318704
I0829 19:10:04.193584 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.318714 (* 1 = 0.318714 loss)
I0829 19:10:04.193593 916722 sgd_solver.cpp:106] Iteration 582500, lr = 0.01
I0829 19:10:34.254673 916722 solver.cpp:218] Iteration 583000 (16.6328 iter/s, 30.0611s/500 iters), loss = 0.17305
I0829 19:10:34.254727 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.173061 (* 1 = 0.173061 loss)
I0829 19:10:34.254736 916722 sgd_solver.cpp:106] Iteration 583000, lr = 0.01
I0829 19:11:04.311518 916722 solver.cpp:218] Iteration 583500 (16.6352 iter/s, 30.0568s/500 iters), loss = 0.0357384
I0829 19:11:04.311576 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0357491 (* 1 = 0.0357491 loss)
I0829 19:11:04.311584 916722 sgd_solver.cpp:106] Iteration 583500, lr = 0.01
I0829 19:11:34.367724 916722 solver.cpp:218] Iteration 584000 (16.6355 iter/s, 30.0562s/500 iters), loss = 0.156345
I0829 19:11:34.367781 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.156355 (* 1 = 0.156355 loss)
I0829 19:11:34.367789 916722 sgd_solver.cpp:106] Iteration 584000, lr = 0.01
I0829 19:12:04.437568 916722 solver.cpp:218] Iteration 584500 (16.628 iter/s, 30.0698s/500 iters), loss = 0.0347757
I0829 19:12:04.437623 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0347862 (* 1 = 0.0347862 loss)
I0829 19:12:04.437631 916722 sgd_solver.cpp:106] Iteration 584500, lr = 0.01
I0829 19:12:34.496104 916722 solver.cpp:218] Iteration 585000 (16.6342 iter/s, 30.0585s/500 iters), loss = 0.0940232
I0829 19:12:34.496176 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0940338 (* 1 = 0.0940338 loss)
I0829 19:12:34.496184 916722 sgd_solver.cpp:106] Iteration 585000, lr = 0.01
I0829 19:13:04.562800 916722 solver.cpp:218] Iteration 585500 (16.6297 iter/s, 30.0667s/500 iters), loss = 0.0598715
I0829 19:13:04.562855 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0598822 (* 1 = 0.0598822 loss)
I0829 19:13:04.562862 916722 sgd_solver.cpp:106] Iteration 585500, lr = 0.01
I0829 19:13:34.636386 916722 solver.cpp:218] Iteration 586000 (16.6259 iter/s, 30.0736s/500 iters), loss = 0.111788
I0829 19:13:34.636456 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111799 (* 1 = 0.111799 loss)
I0829 19:13:34.636466 916722 sgd_solver.cpp:106] Iteration 586000, lr = 0.01
I0829 19:14:04.697033 916722 solver.cpp:218] Iteration 586500 (16.6331 iter/s, 30.0606s/500 iters), loss = 0.163588
I0829 19:14:04.697085 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.163599 (* 1 = 0.163599 loss)
I0829 19:14:04.697093 916722 sgd_solver.cpp:106] Iteration 586500, lr = 0.01
I0829 19:14:34.754338 916722 solver.cpp:218] Iteration 587000 (16.6349 iter/s, 30.0573s/500 iters), loss = 0.0905288
I0829 19:14:34.754396 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0905397 (* 1 = 0.0905397 loss)
I0829 19:14:34.754405 916722 sgd_solver.cpp:106] Iteration 587000, lr = 0.01
I0829 19:15:04.812228 916722 solver.cpp:218] Iteration 587500 (16.6346 iter/s, 30.0579s/500 iters), loss = 0.239818
I0829 19:15:04.812281 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.239828 (* 1 = 0.239828 loss)
I0829 19:15:04.812289 916722 sgd_solver.cpp:106] Iteration 587500, lr = 0.01
I0829 19:15:34.855463 916722 solver.cpp:218] Iteration 588000 (16.6427 iter/s, 30.0432s/500 iters), loss = 0.132415
I0829 19:15:34.855521 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.132426 (* 1 = 0.132426 loss)
I0829 19:15:34.855530 916722 sgd_solver.cpp:106] Iteration 588000, lr = 0.01
I0829 19:16:04.904083 916722 solver.cpp:218] Iteration 588500 (16.6397 iter/s, 30.0486s/500 iters), loss = 0.23181
I0829 19:16:04.904136 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.231821 (* 1 = 0.231821 loss)
I0829 19:16:04.904145 916722 sgd_solver.cpp:106] Iteration 588500, lr = 0.01
I0829 19:16:34.951525 916722 solver.cpp:218] Iteration 589000 (16.6404 iter/s, 30.0474s/500 iters), loss = 0.144832
I0829 19:16:34.951586 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.144843 (* 1 = 0.144843 loss)
I0829 19:16:34.951593 916722 sgd_solver.cpp:106] Iteration 589000, lr = 0.01
I0829 19:17:04.996716 916722 solver.cpp:218] Iteration 589500 (16.6416 iter/s, 30.0451s/500 iters), loss = 0.151755
I0829 19:17:04.996771 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.151766 (* 1 = 0.151766 loss)
I0829 19:17:04.996779 916722 sgd_solver.cpp:106] Iteration 589500, lr = 0.01
I0829 19:17:35.044579 916722 solver.cpp:218] Iteration 590000 (16.6401 iter/s, 30.0478s/500 iters), loss = 0.274775
I0829 19:17:35.044637 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.274786 (* 1 = 0.274786 loss)
I0829 19:17:35.044646 916722 sgd_solver.cpp:106] Iteration 590000, lr = 0.01
I0829 19:18:05.105618 916722 solver.cpp:218] Iteration 590500 (16.6328 iter/s, 30.061s/500 iters), loss = 0.124711
I0829 19:18:05.105675 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.124722 (* 1 = 0.124722 loss)
I0829 19:18:05.105684 916722 sgd_solver.cpp:106] Iteration 590500, lr = 0.01
I0829 19:18:35.153537 916722 solver.cpp:218] Iteration 591000 (16.6401 iter/s, 30.0479s/500 iters), loss = 0.218361
I0829 19:18:35.153589 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.218372 (* 1 = 0.218372 loss)
I0829 19:18:35.153599 916722 sgd_solver.cpp:106] Iteration 591000, lr = 0.01
I0829 19:19:05.200803 916722 solver.cpp:218] Iteration 591500 (16.6405 iter/s, 30.0472s/500 iters), loss = 0.356538
I0829 19:19:05.200866 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.356549 (* 1 = 0.356549 loss)
I0829 19:19:05.200879 916722 sgd_solver.cpp:106] Iteration 591500, lr = 0.01
I0829 19:19:35.266793 916722 solver.cpp:218] Iteration 592000 (16.6301 iter/s, 30.0659s/500 iters), loss = 0.536055
I0829 19:19:35.266851 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.536066 (* 1 = 0.536066 loss)
I0829 19:19:35.266860 916722 sgd_solver.cpp:106] Iteration 592000, lr = 0.01
I0829 19:20:05.309368 916722 solver.cpp:218] Iteration 592500 (16.6431 iter/s, 30.0425s/500 iters), loss = 0.210257
I0829 19:20:05.309422 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.210268 (* 1 = 0.210268 loss)
I0829 19:20:05.309432 916722 sgd_solver.cpp:106] Iteration 592500, lr = 0.01
I0829 19:20:35.355401 916722 solver.cpp:218] Iteration 593000 (16.6413 iter/s, 30.0457s/500 iters), loss = 0.0647242
I0829 19:20:35.355459 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.064735 (* 1 = 0.064735 loss)
I0829 19:20:35.355468 916722 sgd_solver.cpp:106] Iteration 593000, lr = 0.01
I0829 19:21:05.425778 916722 solver.cpp:218] Iteration 593500 (16.628 iter/s, 30.0698s/500 iters), loss = 0.518239
I0829 19:21:05.425835 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.51825 (* 1 = 0.51825 loss)
I0829 19:21:05.425844 916722 sgd_solver.cpp:106] Iteration 593500, lr = 0.01
I0829 19:21:35.480226 916722 solver.cpp:218] Iteration 594000 (16.6368 iter/s, 30.0539s/500 iters), loss = 0.18639
I0829 19:21:35.480285 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.186401 (* 1 = 0.186401 loss)
I0829 19:21:35.480293 916722 sgd_solver.cpp:106] Iteration 594000, lr = 0.01
I0829 19:22:05.525132 916722 solver.cpp:218] Iteration 594500 (16.6421 iter/s, 30.0444s/500 iters), loss = 0.288416
I0829 19:22:05.525187 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.288426 (* 1 = 0.288426 loss)
I0829 19:22:05.525197 916722 sgd_solver.cpp:106] Iteration 594500, lr = 0.01
I0829 19:22:35.585628 916722 solver.cpp:218] Iteration 595000 (16.6334 iter/s, 30.06s/500 iters), loss = 0.0650954
I0829 19:22:35.585688 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0651057 (* 1 = 0.0651057 loss)
I0829 19:22:35.585697 916722 sgd_solver.cpp:106] Iteration 595000, lr = 0.01
I0829 19:23:05.641088 916722 solver.cpp:218] Iteration 595500 (16.6362 iter/s, 30.055s/500 iters), loss = 0.0265682
I0829 19:23:05.641141 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0265785 (* 1 = 0.0265785 loss)
I0829 19:23:05.641150 916722 sgd_solver.cpp:106] Iteration 595500, lr = 0.01
I0829 19:23:35.688452 916722 solver.cpp:218] Iteration 596000 (16.6407 iter/s, 30.0469s/500 iters), loss = 0.12327
I0829 19:23:35.688510 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.123281 (* 1 = 0.123281 loss)
I0829 19:23:35.688519 916722 sgd_solver.cpp:106] Iteration 596000, lr = 0.01
I0829 19:24:05.746487 916722 solver.cpp:218] Iteration 596500 (16.6347 iter/s, 30.0576s/500 iters), loss = 0.117207
I0829 19:24:05.746544 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.117218 (* 1 = 0.117218 loss)
I0829 19:24:05.746552 916722 sgd_solver.cpp:106] Iteration 596500, lr = 0.01
I0829 19:24:35.801209 916722 solver.cpp:218] Iteration 597000 (16.6366 iter/s, 30.0543s/500 iters), loss = 0.0788273
I0829 19:24:35.801270 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.078838 (* 1 = 0.078838 loss)
I0829 19:24:35.801277 916722 sgd_solver.cpp:106] Iteration 597000, lr = 0.01
I0829 19:25:05.856176 916722 solver.cpp:218] Iteration 597500 (16.6364 iter/s, 30.0545s/500 iters), loss = 0.265871
I0829 19:25:05.856233 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.265882 (* 1 = 0.265882 loss)
I0829 19:25:05.856241 916722 sgd_solver.cpp:106] Iteration 597500, lr = 0.01
I0829 19:25:35.908185 916722 solver.cpp:218] Iteration 598000 (16.638 iter/s, 30.0516s/500 iters), loss = 0.164461
I0829 19:25:35.908243 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.164471 (* 1 = 0.164471 loss)
I0829 19:25:35.908252 916722 sgd_solver.cpp:106] Iteration 598000, lr = 0.01
I0829 19:26:05.947888 916722 solver.cpp:218] Iteration 598500 (16.6448 iter/s, 30.0393s/500 iters), loss = 0.294395
I0829 19:26:05.947957 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.294406 (* 1 = 0.294406 loss)
I0829 19:26:05.947980 916722 sgd_solver.cpp:106] Iteration 598500, lr = 0.01
I0829 19:26:35.982247 916722 solver.cpp:218] Iteration 599000 (16.6478 iter/s, 30.034s/500 iters), loss = 0.313146
I0829 19:26:35.982308 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.313157 (* 1 = 0.313157 loss)
I0829 19:26:35.982316 916722 sgd_solver.cpp:106] Iteration 599000, lr = 0.01
I0829 19:27:06.037534 916722 solver.cpp:218] Iteration 599500 (16.6362 iter/s, 30.0549s/500 iters), loss = 0.153105
I0829 19:27:06.037587 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.153116 (* 1 = 0.153116 loss)
I0829 19:27:06.037595 916722 sgd_solver.cpp:106] Iteration 599500, lr = 0.01
I0829 19:27:36.019845 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_600000.caffemodel
I0829 19:27:36.038966 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_600000.solverstate
I0829 19:27:36.045020 916722 solver.cpp:330] Iteration 600000, Testing net (#0)
I0829 19:27:51.433446 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8931
I0829 19:27:51.433491 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.333086 (* 1 = 0.333086 loss)
I0829 19:27:51.492318 916722 solver.cpp:218] Iteration 600000 (11.0001 iter/s, 45.4543s/500 iters), loss = 0.151546
I0829 19:27:51.492347 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.151557 (* 1 = 0.151557 loss)
I0829 19:27:51.492355 916722 sgd_solver.cpp:106] Iteration 600000, lr = 0.01
I0829 19:28:21.419690 916722 solver.cpp:218] Iteration 600500 (16.7073 iter/s, 29.9271s/500 iters), loss = 0.0497801
I0829 19:28:21.419750 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0497908 (* 1 = 0.0497908 loss)
I0829 19:28:21.419759 916722 sgd_solver.cpp:106] Iteration 600500, lr = 0.01
I0829 19:28:51.426522 916722 solver.cpp:218] Iteration 601000 (16.6631 iter/s, 30.0065s/500 iters), loss = 0.0916062
I0829 19:28:51.426581 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0916169 (* 1 = 0.0916169 loss)
I0829 19:28:51.426589 916722 sgd_solver.cpp:106] Iteration 601000, lr = 0.01
I0829 19:29:21.454071 916722 solver.cpp:218] Iteration 601500 (16.6515 iter/s, 30.0272s/500 iters), loss = 0.279967
I0829 19:29:21.454124 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.279977 (* 1 = 0.279977 loss)
I0829 19:29:21.454133 916722 sgd_solver.cpp:106] Iteration 601500, lr = 0.01
I0829 19:29:51.509047 916722 solver.cpp:218] Iteration 602000 (16.6363 iter/s, 30.0547s/500 iters), loss = 0.191171
I0829 19:29:51.509100 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.191182 (* 1 = 0.191182 loss)
I0829 19:29:51.509109 916722 sgd_solver.cpp:106] Iteration 602000, lr = 0.01
I0829 19:30:21.521255 916722 solver.cpp:218] Iteration 602500 (16.66 iter/s, 30.0119s/500 iters), loss = 0.163798
I0829 19:30:21.521311 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.163809 (* 1 = 0.163809 loss)
I0829 19:30:21.521319 916722 sgd_solver.cpp:106] Iteration 602500, lr = 0.01
I0829 19:30:51.545919 916722 solver.cpp:218] Iteration 603000 (16.6531 iter/s, 30.0244s/500 iters), loss = 0.206956
I0829 19:30:51.545974 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.206967 (* 1 = 0.206967 loss)
I0829 19:30:51.545982 916722 sgd_solver.cpp:106] Iteration 603000, lr = 0.01
I0829 19:31:21.605252 916722 solver.cpp:218] Iteration 603500 (16.6339 iter/s, 30.0591s/500 iters), loss = 0.100515
I0829 19:31:21.605312 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.100526 (* 1 = 0.100526 loss)
I0829 19:31:21.605320 916722 sgd_solver.cpp:106] Iteration 603500, lr = 0.01
I0829 19:31:51.629418 916722 solver.cpp:218] Iteration 604000 (16.6534 iter/s, 30.0239s/500 iters), loss = 0.105705
I0829 19:31:51.629492 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105715 (* 1 = 0.105715 loss)
I0829 19:31:51.629499 916722 sgd_solver.cpp:106] Iteration 604000, lr = 0.01
I0829 19:32:21.659058 916722 solver.cpp:218] Iteration 604500 (16.6504 iter/s, 30.0294s/500 iters), loss = 0.294087
I0829 19:32:21.659116 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.294098 (* 1 = 0.294098 loss)
I0829 19:32:21.659123 916722 sgd_solver.cpp:106] Iteration 604500, lr = 0.01
I0829 19:32:51.699715 916722 solver.cpp:218] Iteration 605000 (16.6442 iter/s, 30.0404s/500 iters), loss = 0.203746
I0829 19:32:51.699771 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.203756 (* 1 = 0.203756 loss)
I0829 19:32:51.699780 916722 sgd_solver.cpp:106] Iteration 605000, lr = 0.01
I0829 19:33:21.717103 916722 solver.cpp:218] Iteration 605500 (16.6571 iter/s, 30.0172s/500 iters), loss = 0.110972
I0829 19:33:21.717164 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110982 (* 1 = 0.110982 loss)
I0829 19:33:21.717173 916722 sgd_solver.cpp:106] Iteration 605500, lr = 0.01
I0829 19:33:51.747464 916722 solver.cpp:218] Iteration 606000 (16.6499 iter/s, 30.0301s/500 iters), loss = 0.182495
I0829 19:33:51.747515 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.182506 (* 1 = 0.182506 loss)
I0829 19:33:51.747524 916722 sgd_solver.cpp:106] Iteration 606000, lr = 0.01
I0829 19:34:21.770382 916722 solver.cpp:218] Iteration 606500 (16.6541 iter/s, 30.0227s/500 iters), loss = 0.160908
I0829 19:34:21.770437 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.160919 (* 1 = 0.160919 loss)
I0829 19:34:21.770445 916722 sgd_solver.cpp:106] Iteration 606500, lr = 0.01
I0829 19:34:51.823477 916722 solver.cpp:218] Iteration 607000 (16.6373 iter/s, 30.0529s/500 iters), loss = 0.132249
I0829 19:34:51.823527 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13226 (* 1 = 0.13226 loss)
I0829 19:34:51.823535 916722 sgd_solver.cpp:106] Iteration 607000, lr = 0.01
I0829 19:35:21.844341 916722 solver.cpp:218] Iteration 607500 (16.6552 iter/s, 30.0207s/500 iters), loss = 0.118726
I0829 19:35:21.844393 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.118737 (* 1 = 0.118737 loss)
I0829 19:35:21.844403 916722 sgd_solver.cpp:106] Iteration 607500, lr = 0.01
I0829 19:35:51.855309 916722 solver.cpp:218] Iteration 608000 (16.6607 iter/s, 30.0108s/500 iters), loss = 0.24389
I0829 19:35:51.855365 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.2439 (* 1 = 0.2439 loss)
I0829 19:35:51.855373 916722 sgd_solver.cpp:106] Iteration 608000, lr = 0.01
I0829 19:36:21.840469 916722 solver.cpp:218] Iteration 608500 (16.675 iter/s, 29.985s/500 iters), loss = 0.0873879
I0829 19:36:21.840523 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0873983 (* 1 = 0.0873983 loss)
I0829 19:36:21.840533 916722 sgd_solver.cpp:106] Iteration 608500, lr = 0.01
I0829 19:36:51.826330 916722 solver.cpp:218] Iteration 609000 (16.6746 iter/s, 29.9857s/500 iters), loss = 0.0890367
I0829 19:36:51.826388 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.089047 (* 1 = 0.089047 loss)
I0829 19:36:51.826396 916722 sgd_solver.cpp:106] Iteration 609000, lr = 0.01
I0829 19:37:21.810869 916722 solver.cpp:218] Iteration 609500 (16.6754 iter/s, 29.9844s/500 iters), loss = 0.107417
I0829 19:37:21.810922 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.107427 (* 1 = 0.107427 loss)
I0829 19:37:21.810932 916722 sgd_solver.cpp:106] Iteration 609500, lr = 0.01
I0829 19:37:51.796659 916722 solver.cpp:218] Iteration 610000 (16.6747 iter/s, 29.9856s/500 iters), loss = 0.134859
I0829 19:37:51.796718 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.134869 (* 1 = 0.134869 loss)
I0829 19:37:51.796727 916722 sgd_solver.cpp:106] Iteration 610000, lr = 0.01
I0829 19:38:21.763813 916722 solver.cpp:218] Iteration 610500 (16.685 iter/s, 29.967s/500 iters), loss = 0.16637
I0829 19:38:21.763864 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.16638 (* 1 = 0.16638 loss)
I0829 19:38:21.763882 916722 sgd_solver.cpp:106] Iteration 610500, lr = 0.01
I0829 19:38:51.727119 916722 solver.cpp:218] Iteration 611000 (16.6872 iter/s, 29.9631s/500 iters), loss = 0.0667957
I0829 19:38:51.727187 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0668055 (* 1 = 0.0668055 loss)
I0829 19:38:51.727196 916722 sgd_solver.cpp:106] Iteration 611000, lr = 0.01
I0829 19:39:21.699327 916722 solver.cpp:218] Iteration 611500 (16.6822 iter/s, 29.972s/500 iters), loss = 0.381095
I0829 19:39:21.699380 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.381105 (* 1 = 0.381105 loss)
I0829 19:39:21.699389 916722 sgd_solver.cpp:106] Iteration 611500, lr = 0.01
I0829 19:39:51.678686 916722 solver.cpp:218] Iteration 612000 (16.6782 iter/s, 29.9792s/500 iters), loss = 0.115817
I0829 19:39:51.678750 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115827 (* 1 = 0.115827 loss)
I0829 19:39:51.678758 916722 sgd_solver.cpp:106] Iteration 612000, lr = 0.01
I0829 19:40:21.662714 916722 solver.cpp:218] Iteration 612500 (16.6756 iter/s, 29.9839s/500 iters), loss = 0.174629
I0829 19:40:21.662766 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.174638 (* 1 = 0.174638 loss)
I0829 19:40:21.662775 916722 sgd_solver.cpp:106] Iteration 612500, lr = 0.01
I0829 19:40:51.670531 916722 solver.cpp:218] Iteration 613000 (16.6624 iter/s, 30.0077s/500 iters), loss = 0.33209
I0829 19:40:51.670589 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.3321 (* 1 = 0.3321 loss)
I0829 19:40:51.670598 916722 sgd_solver.cpp:106] Iteration 613000, lr = 0.01
I0829 19:41:21.681284 916722 solver.cpp:218] Iteration 613500 (16.6608 iter/s, 30.0106s/500 iters), loss = 0.171893
I0829 19:41:21.681341 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.171903 (* 1 = 0.171903 loss)
I0829 19:41:21.681349 916722 sgd_solver.cpp:106] Iteration 613500, lr = 0.01
I0829 19:41:51.683954 916722 solver.cpp:218] Iteration 614000 (16.6653 iter/s, 30.0025s/500 iters), loss = 0.0643054
I0829 19:41:51.684015 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0643149 (* 1 = 0.0643149 loss)
I0829 19:41:51.684022 916722 sgd_solver.cpp:106] Iteration 614000, lr = 0.01
I0829 19:42:21.704403 916722 solver.cpp:218] Iteration 614500 (16.6554 iter/s, 30.0203s/500 iters), loss = 0.0407188
I0829 19:42:21.704483 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0407286 (* 1 = 0.0407286 loss)
I0829 19:42:21.704491 916722 sgd_solver.cpp:106] Iteration 614500, lr = 0.01
I0829 19:42:51.712919 916722 solver.cpp:218] Iteration 615000 (16.662 iter/s, 30.0083s/500 iters), loss = 0.136666
I0829 19:42:51.712977 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.136676 (* 1 = 0.136676 loss)
I0829 19:42:51.712986 916722 sgd_solver.cpp:106] Iteration 615000, lr = 0.01
I0829 19:43:21.717767 916722 solver.cpp:218] Iteration 615500 (16.6641 iter/s, 30.0047s/500 iters), loss = 0.223238
I0829 19:43:21.717825 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.223248 (* 1 = 0.223248 loss)
I0829 19:43:21.717834 916722 sgd_solver.cpp:106] Iteration 615500, lr = 0.01
I0829 19:43:51.745124 916722 solver.cpp:218] Iteration 616000 (16.6516 iter/s, 30.0272s/500 iters), loss = 0.0680056
I0829 19:43:51.745183 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0680152 (* 1 = 0.0680152 loss)
I0829 19:43:51.745191 916722 sgd_solver.cpp:106] Iteration 616000, lr = 0.01
I0829 19:44:21.776165 916722 solver.cpp:218] Iteration 616500 (16.6495 iter/s, 30.0309s/500 iters), loss = 0.315046
I0829 19:44:21.776223 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.315056 (* 1 = 0.315056 loss)
I0829 19:44:21.776232 916722 sgd_solver.cpp:106] Iteration 616500, lr = 0.01
I0829 19:44:51.769573 916722 solver.cpp:218] Iteration 617000 (16.6704 iter/s, 29.9933s/500 iters), loss = 0.379213
I0829 19:44:51.769623 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.379222 (* 1 = 0.379222 loss)
I0829 19:44:51.769634 916722 sgd_solver.cpp:106] Iteration 617000, lr = 0.01
I0829 19:45:21.779848 916722 solver.cpp:218] Iteration 617500 (16.661 iter/s, 30.0101s/500 iters), loss = 0.237837
I0829 19:45:21.779915 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.237847 (* 1 = 0.237847 loss)
I0829 19:45:21.779924 916722 sgd_solver.cpp:106] Iteration 617500, lr = 0.01
I0829 19:45:51.806494 916722 solver.cpp:218] Iteration 618000 (16.652 iter/s, 30.0265s/500 iters), loss = 0.0192078
I0829 19:45:51.806546 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0192175 (* 1 = 0.0192175 loss)
I0829 19:45:51.806555 916722 sgd_solver.cpp:106] Iteration 618000, lr = 0.01
I0829 19:46:21.835966 916722 solver.cpp:218] Iteration 618500 (16.6504 iter/s, 30.0293s/500 iters), loss = 0.119981
I0829 19:46:21.836025 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.11999 (* 1 = 0.11999 loss)
I0829 19:46:21.836035 916722 sgd_solver.cpp:106] Iteration 618500, lr = 0.01
I0829 19:46:51.856361 916722 solver.cpp:218] Iteration 619000 (16.6554 iter/s, 30.0203s/500 iters), loss = 0.143275
I0829 19:46:51.856418 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.143285 (* 1 = 0.143285 loss)
I0829 19:46:51.856432 916722 sgd_solver.cpp:106] Iteration 619000, lr = 0.01
I0829 19:47:21.890581 916722 solver.cpp:218] Iteration 619500 (16.6478 iter/s, 30.0341s/500 iters), loss = 0.11733
I0829 19:47:21.890642 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.11734 (* 1 = 0.11734 loss)
I0829 19:47:21.890651 916722 sgd_solver.cpp:106] Iteration 619500, lr = 0.01
I0829 19:47:51.930704 916722 solver.cpp:218] Iteration 620000 (16.6445 iter/s, 30.04s/500 iters), loss = 0.192171
I0829 19:47:51.930760 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.192181 (* 1 = 0.192181 loss)
I0829 19:47:51.930768 916722 sgd_solver.cpp:106] Iteration 620000, lr = 0.01
I0829 19:48:21.999161 916722 solver.cpp:218] Iteration 620500 (16.6288 iter/s, 30.0683s/500 iters), loss = 0.162012
I0829 19:48:21.999223 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.162022 (* 1 = 0.162022 loss)
I0829 19:48:21.999233 916722 sgd_solver.cpp:106] Iteration 620500, lr = 0.01
I0829 19:48:52.035648 916722 solver.cpp:218] Iteration 621000 (16.6465 iter/s, 30.0363s/500 iters), loss = 0.144017
I0829 19:48:52.035706 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.144026 (* 1 = 0.144026 loss)
I0829 19:48:52.035713 916722 sgd_solver.cpp:106] Iteration 621000, lr = 0.01
I0829 19:49:22.076654 916722 solver.cpp:218] Iteration 621500 (16.644 iter/s, 30.0409s/500 iters), loss = 0.171782
I0829 19:49:22.076715 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.171792 (* 1 = 0.171792 loss)
I0829 19:49:22.076725 916722 sgd_solver.cpp:106] Iteration 621500, lr = 0.01
I0829 19:49:52.117478 916722 solver.cpp:218] Iteration 622000 (16.6441 iter/s, 30.0407s/500 iters), loss = 0.143858
I0829 19:49:52.117532 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.143868 (* 1 = 0.143868 loss)
I0829 19:49:52.117540 916722 sgd_solver.cpp:106] Iteration 622000, lr = 0.01
I0829 19:50:22.144119 916722 solver.cpp:218] Iteration 622500 (16.6519 iter/s, 30.0265s/500 iters), loss = 0.291324
I0829 19:50:22.144173 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.291334 (* 1 = 0.291334 loss)
I0829 19:50:22.144182 916722 sgd_solver.cpp:106] Iteration 622500, lr = 0.01
I0829 19:50:52.188817 916722 solver.cpp:218] Iteration 623000 (16.6419 iter/s, 30.0446s/500 iters), loss = 0.122882
I0829 19:50:52.188876 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.122891 (* 1 = 0.122891 loss)
I0829 19:50:52.188885 916722 sgd_solver.cpp:106] Iteration 623000, lr = 0.01
I0829 19:51:22.230393 916722 solver.cpp:218] Iteration 623500 (16.6437 iter/s, 30.0414s/500 iters), loss = 0.133939
I0829 19:51:22.230453 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133949 (* 1 = 0.133949 loss)
I0829 19:51:22.230460 916722 sgd_solver.cpp:106] Iteration 623500, lr = 0.01
I0829 19:51:52.256713 916722 solver.cpp:218] Iteration 624000 (16.6521 iter/s, 30.0262s/500 iters), loss = 0.0994065
I0829 19:51:52.256793 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.099416 (* 1 = 0.099416 loss)
I0829 19:51:52.256801 916722 sgd_solver.cpp:106] Iteration 624000, lr = 0.01
I0829 19:52:22.301450 916722 solver.cpp:218] Iteration 624500 (16.6419 iter/s, 30.0446s/500 iters), loss = 0.0123081
I0829 19:52:22.301510 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0123177 (* 1 = 0.0123177 loss)
I0829 19:52:22.301518 916722 sgd_solver.cpp:106] Iteration 624500, lr = 0.01
I0829 19:52:52.352735 916722 solver.cpp:218] Iteration 625000 (16.6383 iter/s, 30.0512s/500 iters), loss = 0.079823
I0829 19:52:52.352790 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0798326 (* 1 = 0.0798326 loss)
I0829 19:52:52.352799 916722 sgd_solver.cpp:106] Iteration 625000, lr = 0.01
I0829 19:53:22.394731 916722 solver.cpp:218] Iteration 625500 (16.6434 iter/s, 30.0419s/500 iters), loss = 0.184955
I0829 19:53:22.394786 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.184965 (* 1 = 0.184965 loss)
I0829 19:53:22.394795 916722 sgd_solver.cpp:106] Iteration 625500, lr = 0.01
I0829 19:53:52.439280 916722 solver.cpp:218] Iteration 626000 (16.642 iter/s, 30.0444s/500 iters), loss = 0.109389
I0829 19:53:52.439338 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109399 (* 1 = 0.109399 loss)
I0829 19:53:52.439347 916722 sgd_solver.cpp:106] Iteration 626000, lr = 0.01
I0829 19:54:22.508692 916722 solver.cpp:218] Iteration 626500 (16.6283 iter/s, 30.0693s/500 iters), loss = 0.217488
I0829 19:54:22.508747 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.217497 (* 1 = 0.217497 loss)
I0829 19:54:22.508755 916722 sgd_solver.cpp:106] Iteration 626500, lr = 0.01
I0829 19:54:52.566550 916722 solver.cpp:218] Iteration 627000 (16.6346 iter/s, 30.0579s/500 iters), loss = 0.183163
I0829 19:54:52.566602 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.183173 (* 1 = 0.183173 loss)
I0829 19:54:52.566612 916722 sgd_solver.cpp:106] Iteration 627000, lr = 0.01
I0829 19:55:22.628753 916722 solver.cpp:218] Iteration 627500 (16.6322 iter/s, 30.0622s/500 iters), loss = 0.235473
I0829 19:55:22.628813 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.235482 (* 1 = 0.235482 loss)
I0829 19:55:22.628823 916722 sgd_solver.cpp:106] Iteration 627500, lr = 0.01
I0829 19:55:52.667011 916722 solver.cpp:218] Iteration 628000 (16.6454 iter/s, 30.0383s/500 iters), loss = 0.107403
I0829 19:55:52.667066 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.107413 (* 1 = 0.107413 loss)
I0829 19:55:52.667074 916722 sgd_solver.cpp:106] Iteration 628000, lr = 0.01
I0829 19:56:22.704568 916722 solver.cpp:218] Iteration 628500 (16.6458 iter/s, 30.0376s/500 iters), loss = 0.239539
I0829 19:56:22.704627 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.239549 (* 1 = 0.239549 loss)
I0829 19:56:22.704635 916722 sgd_solver.cpp:106] Iteration 628500, lr = 0.01
I0829 19:56:52.746263 916722 solver.cpp:218] Iteration 629000 (16.6435 iter/s, 30.0417s/500 iters), loss = 0.194983
I0829 19:56:52.746320 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.194992 (* 1 = 0.194992 loss)
I0829 19:56:52.746327 916722 sgd_solver.cpp:106] Iteration 629000, lr = 0.01
I0829 19:57:22.793443 916722 solver.cpp:218] Iteration 629500 (16.6405 iter/s, 30.0472s/500 iters), loss = 0.378866
I0829 19:57:22.793502 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.378876 (* 1 = 0.378876 loss)
I0829 19:57:22.793510 916722 sgd_solver.cpp:106] Iteration 629500, lr = 0.01
I0829 19:57:52.822280 916722 solver.cpp:218] Iteration 630000 (16.6507 iter/s, 30.0288s/500 iters), loss = 0.114262
I0829 19:57:52.822335 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.114271 (* 1 = 0.114271 loss)
I0829 19:57:52.822343 916722 sgd_solver.cpp:106] Iteration 630000, lr = 0.01
I0829 19:58:22.881191 916722 solver.cpp:218] Iteration 630500 (16.634 iter/s, 30.0589s/500 iters), loss = 0.300897
I0829 19:58:22.881263 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.300906 (* 1 = 0.300906 loss)
I0829 19:58:22.881273 916722 sgd_solver.cpp:106] Iteration 630500, lr = 0.01
I0829 19:58:52.909729 916722 solver.cpp:218] Iteration 631000 (16.6509 iter/s, 30.0285s/500 iters), loss = 0.219206
I0829 19:58:52.909781 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.219216 (* 1 = 0.219216 loss)
I0829 19:58:52.909790 916722 sgd_solver.cpp:106] Iteration 631000, lr = 0.01
I0829 19:59:22.949131 916722 solver.cpp:218] Iteration 631500 (16.6448 iter/s, 30.0394s/500 iters), loss = 0.21296
I0829 19:59:22.949184 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.21297 (* 1 = 0.21297 loss)
I0829 19:59:22.949193 916722 sgd_solver.cpp:106] Iteration 631500, lr = 0.01
I0829 19:59:53.000852 916722 solver.cpp:218] Iteration 632000 (16.638 iter/s, 30.0517s/500 iters), loss = 0.115244
I0829 19:59:53.000912 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115253 (* 1 = 0.115253 loss)
I0829 19:59:53.000921 916722 sgd_solver.cpp:106] Iteration 632000, lr = 0.01
I0829 20:00:23.044384 916722 solver.cpp:218] Iteration 632500 (16.6425 iter/s, 30.0435s/500 iters), loss = 0.0776871
I0829 20:00:23.044445 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.077696 (* 1 = 0.077696 loss)
I0829 20:00:23.044453 916722 sgd_solver.cpp:106] Iteration 632500, lr = 0.01
I0829 20:00:53.077970 916722 solver.cpp:218] Iteration 633000 (16.6481 iter/s, 30.0335s/500 iters), loss = 0.426836
I0829 20:00:53.078027 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.426844 (* 1 = 0.426844 loss)
I0829 20:00:53.078035 916722 sgd_solver.cpp:106] Iteration 633000, lr = 0.01
I0829 20:01:23.126744 916722 solver.cpp:218] Iteration 633500 (16.6396 iter/s, 30.0487s/500 iters), loss = 0.261953
I0829 20:01:23.126802 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.261961 (* 1 = 0.261961 loss)
I0829 20:01:23.126811 916722 sgd_solver.cpp:106] Iteration 633500, lr = 0.01
I0829 20:01:53.167652 916722 solver.cpp:218] Iteration 634000 (16.644 iter/s, 30.0409s/500 iters), loss = 0.0708027
I0829 20:01:53.167709 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0708114 (* 1 = 0.0708114 loss)
I0829 20:01:53.167717 916722 sgd_solver.cpp:106] Iteration 634000, lr = 0.01
I0829 20:02:23.221804 916722 solver.cpp:218] Iteration 634500 (16.6367 iter/s, 30.0541s/500 iters), loss = 0.224741
I0829 20:02:23.221863 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.22475 (* 1 = 0.22475 loss)
I0829 20:02:23.221870 916722 sgd_solver.cpp:106] Iteration 634500, lr = 0.01
I0829 20:02:53.279502 916722 solver.cpp:218] Iteration 635000 (16.6347 iter/s, 30.0577s/500 iters), loss = 0.182875
I0829 20:02:53.279557 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.182884 (* 1 = 0.182884 loss)
I0829 20:02:53.279565 916722 sgd_solver.cpp:106] Iteration 635000, lr = 0.01
I0829 20:03:23.318753 916722 solver.cpp:218] Iteration 635500 (16.6449 iter/s, 30.0392s/500 iters), loss = 0.210763
I0829 20:03:23.318810 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.210772 (* 1 = 0.210772 loss)
I0829 20:03:23.318818 916722 sgd_solver.cpp:106] Iteration 635500, lr = 0.01
I0829 20:03:53.372434 916722 solver.cpp:218] Iteration 636000 (16.6369 iter/s, 30.0536s/500 iters), loss = 0.114472
I0829 20:03:53.372493 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.114481 (* 1 = 0.114481 loss)
I0829 20:03:53.372501 916722 sgd_solver.cpp:106] Iteration 636000, lr = 0.01
I0829 20:04:23.416409 916722 solver.cpp:218] Iteration 636500 (16.6423 iter/s, 30.0439s/500 iters), loss = 0.0677265
I0829 20:04:23.416474 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0677353 (* 1 = 0.0677353 loss)
I0829 20:04:23.416483 916722 sgd_solver.cpp:106] Iteration 636500, lr = 0.01
I0829 20:04:53.534986 916722 solver.cpp:218] Iteration 637000 (16.6011 iter/s, 30.1185s/500 iters), loss = 0.18567
I0829 20:04:53.535054 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.185679 (* 1 = 0.185679 loss)
I0829 20:04:53.535066 916722 sgd_solver.cpp:106] Iteration 637000, lr = 0.01
I0829 20:05:23.664242 916722 solver.cpp:218] Iteration 637500 (16.5952 iter/s, 30.1292s/500 iters), loss = 0.0796285
I0829 20:05:23.664301 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0796377 (* 1 = 0.0796377 loss)
I0829 20:05:23.664310 916722 sgd_solver.cpp:106] Iteration 637500, lr = 0.01
I0829 20:05:53.796903 916722 solver.cpp:218] Iteration 638000 (16.5933 iter/s, 30.1326s/500 iters), loss = 0.094209
I0829 20:05:53.796957 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0942182 (* 1 = 0.0942182 loss)
I0829 20:05:53.796967 916722 sgd_solver.cpp:106] Iteration 638000, lr = 0.01
I0829 20:06:23.944344 916722 solver.cpp:218] Iteration 638500 (16.5852 iter/s, 30.1474s/500 iters), loss = 0.427508
I0829 20:06:23.944401 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.427518 (* 1 = 0.427518 loss)
I0829 20:06:23.944408 916722 sgd_solver.cpp:106] Iteration 638500, lr = 0.01
I0829 20:06:54.086616 916722 solver.cpp:218] Iteration 639000 (16.588 iter/s, 30.1422s/500 iters), loss = 0.0563032
I0829 20:06:54.086670 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0563125 (* 1 = 0.0563125 loss)
I0829 20:06:54.086678 916722 sgd_solver.cpp:106] Iteration 639000, lr = 0.01
I0829 20:07:24.209652 916722 solver.cpp:218] Iteration 639500 (16.5986 iter/s, 30.123s/500 iters), loss = 0.176679
I0829 20:07:24.209709 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.176689 (* 1 = 0.176689 loss)
I0829 20:07:24.209717 916722 sgd_solver.cpp:106] Iteration 639500, lr = 0.01
I0829 20:07:54.361531 916722 solver.cpp:218] Iteration 640000 (16.5828 iter/s, 30.1518s/500 iters), loss = 0.164704
I0829 20:07:54.361585 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.164713 (* 1 = 0.164713 loss)
I0829 20:07:54.361594 916722 sgd_solver.cpp:106] Iteration 640000, lr = 0.01
I0829 20:08:24.513247 916722 solver.cpp:218] Iteration 640500 (16.5828 iter/s, 30.1517s/500 iters), loss = 0.206648
I0829 20:08:24.513303 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.206657 (* 1 = 0.206657 loss)
I0829 20:08:24.513310 916722 sgd_solver.cpp:106] Iteration 640500, lr = 0.01
I0829 20:08:54.649895 916722 solver.cpp:218] Iteration 641000 (16.5911 iter/s, 30.1366s/500 iters), loss = 0.1096
I0829 20:08:54.649952 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109609 (* 1 = 0.109609 loss)
I0829 20:08:54.649961 916722 sgd_solver.cpp:106] Iteration 641000, lr = 0.01
I0829 20:09:24.803426 916722 solver.cpp:218] Iteration 641500 (16.5818 iter/s, 30.1535s/500 iters), loss = 0.264473
I0829 20:09:24.803485 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.264482 (* 1 = 0.264482 loss)
I0829 20:09:24.803494 916722 sgd_solver.cpp:106] Iteration 641500, lr = 0.01
I0829 20:09:54.931672 916722 solver.cpp:218] Iteration 642000 (16.5958 iter/s, 30.1282s/500 iters), loss = 0.154402
I0829 20:09:54.931730 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.154411 (* 1 = 0.154411 loss)
I0829 20:09:54.931738 916722 sgd_solver.cpp:106] Iteration 642000, lr = 0.01
I0829 20:10:25.067044 916722 solver.cpp:218] Iteration 642500 (16.5918 iter/s, 30.1353s/500 iters), loss = 0.546553
I0829 20:10:25.067102 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.546562 (* 1 = 0.546562 loss)
I0829 20:10:25.067111 916722 sgd_solver.cpp:106] Iteration 642500, lr = 0.01
I0829 20:10:55.203033 916722 solver.cpp:218] Iteration 643000 (16.5915 iter/s, 30.1359s/500 iters), loss = 0.260829
I0829 20:10:55.203088 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.260839 (* 1 = 0.260839 loss)
I0829 20:10:55.203096 916722 sgd_solver.cpp:106] Iteration 643000, lr = 0.01
I0829 20:11:25.332115 916722 solver.cpp:218] Iteration 643500 (16.5953 iter/s, 30.129s/500 iters), loss = 0.103835
I0829 20:11:25.332186 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.103844 (* 1 = 0.103844 loss)
I0829 20:11:25.332195 916722 sgd_solver.cpp:106] Iteration 643500, lr = 0.01
I0829 20:11:55.475421 916722 solver.cpp:218] Iteration 644000 (16.5875 iter/s, 30.1432s/500 iters), loss = 0.187876
I0829 20:11:55.475476 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.187885 (* 1 = 0.187885 loss)
I0829 20:11:55.475484 916722 sgd_solver.cpp:106] Iteration 644000, lr = 0.01
I0829 20:12:25.603688 916722 solver.cpp:218] Iteration 644500 (16.5958 iter/s, 30.1282s/500 iters), loss = 0.0846528
I0829 20:12:25.603760 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0846619 (* 1 = 0.0846619 loss)
I0829 20:12:25.603768 916722 sgd_solver.cpp:106] Iteration 644500, lr = 0.01
I0829 20:12:55.761822 916722 solver.cpp:218] Iteration 645000 (16.5793 iter/s, 30.158s/500 iters), loss = 0.177425
I0829 20:12:55.761876 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.177434 (* 1 = 0.177434 loss)
I0829 20:12:55.761885 916722 sgd_solver.cpp:106] Iteration 645000, lr = 0.01
I0829 20:13:25.893491 916722 solver.cpp:218] Iteration 645500 (16.5939 iter/s, 30.1316s/500 iters), loss = 0.209869
I0829 20:13:25.893554 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.209878 (* 1 = 0.209878 loss)
I0829 20:13:25.893563 916722 sgd_solver.cpp:106] Iteration 645500, lr = 0.01
I0829 20:13:56.027277 916722 solver.cpp:218] Iteration 646000 (16.5927 iter/s, 30.1337s/500 iters), loss = 0.245148
I0829 20:13:56.027333 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.245157 (* 1 = 0.245157 loss)
I0829 20:13:56.027343 916722 sgd_solver.cpp:106] Iteration 646000, lr = 0.01
I0829 20:14:26.159128 916722 solver.cpp:218] Iteration 646500 (16.5938 iter/s, 30.1318s/500 iters), loss = 0.181568
I0829 20:14:26.159188 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.181577 (* 1 = 0.181577 loss)
I0829 20:14:26.159196 916722 sgd_solver.cpp:106] Iteration 646500, lr = 0.01
I0829 20:14:56.303479 916722 solver.cpp:218] Iteration 647000 (16.5869 iter/s, 30.1443s/500 iters), loss = 0.0956658
I0829 20:14:56.303535 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0956753 (* 1 = 0.0956753 loss)
I0829 20:14:56.303544 916722 sgd_solver.cpp:106] Iteration 647000, lr = 0.01
I0829 20:15:26.445896 916722 solver.cpp:218] Iteration 647500 (16.588 iter/s, 30.1423s/500 iters), loss = 0.144284
I0829 20:15:26.445956 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.144294 (* 1 = 0.144294 loss)
I0829 20:15:26.445964 916722 sgd_solver.cpp:106] Iteration 647500, lr = 0.01
I0829 20:15:56.588917 916722 solver.cpp:218] Iteration 648000 (16.5876 iter/s, 30.1429s/500 iters), loss = 0.147486
I0829 20:15:56.588969 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.147496 (* 1 = 0.147496 loss)
I0829 20:15:56.588979 916722 sgd_solver.cpp:106] Iteration 648000, lr = 0.01
I0829 20:16:26.762899 916722 solver.cpp:218] Iteration 648500 (16.5706 iter/s, 30.1739s/500 iters), loss = 0.201736
I0829 20:16:26.762956 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.201745 (* 1 = 0.201745 loss)
I0829 20:16:26.762965 916722 sgd_solver.cpp:106] Iteration 648500, lr = 0.01
I0829 20:16:56.884685 916722 solver.cpp:218] Iteration 649000 (16.5993 iter/s, 30.1217s/500 iters), loss = 0.180303
I0829 20:16:56.884739 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.180313 (* 1 = 0.180313 loss)
I0829 20:16:56.884758 916722 sgd_solver.cpp:106] Iteration 649000, lr = 0.01
I0829 20:17:27.022720 916722 solver.cpp:218] Iteration 649500 (16.5904 iter/s, 30.138s/500 iters), loss = 0.159706
I0829 20:17:27.022775 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159715 (* 1 = 0.159715 loss)
I0829 20:17:27.022784 916722 sgd_solver.cpp:106] Iteration 649500, lr = 0.01
I0829 20:17:57.103314 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_650000.caffemodel
I0829 20:17:57.122439 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_650000.solverstate
I0829 20:17:57.128690 916722 solver.cpp:330] Iteration 650000, Testing net (#0)
I0829 20:18:12.564594 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8921
I0829 20:18:12.564646 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.357456 (* 1 = 0.357456 loss)
I0829 20:18:12.623457 916722 solver.cpp:218] Iteration 650000 (10.9648 iter/s, 45.6006s/500 iters), loss = 0.0390863
I0829 20:18:12.623486 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0390958 (* 1 = 0.0390958 loss)
I0829 20:18:12.623493 916722 sgd_solver.cpp:106] Iteration 650000, lr = 0.01
I0829 20:18:42.525218 916722 solver.cpp:218] Iteration 650500 (16.7215 iter/s, 29.9017s/500 iters), loss = 0.273715
I0829 20:18:42.525286 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.273725 (* 1 = 0.273725 loss)
I0829 20:18:42.525295 916722 sgd_solver.cpp:106] Iteration 650500, lr = 0.01
I0829 20:19:12.538789 916722 solver.cpp:218] Iteration 651000 (16.6592 iter/s, 30.0135s/500 iters), loss = 0.106193
I0829 20:19:12.538847 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.106202 (* 1 = 0.106202 loss)
I0829 20:19:12.538856 916722 sgd_solver.cpp:106] Iteration 651000, lr = 0.01
I0829 20:19:42.581656 916722 solver.cpp:218] Iteration 651500 (16.6429 iter/s, 30.0428s/500 iters), loss = 0.170113
I0829 20:19:42.581714 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.170122 (* 1 = 0.170122 loss)
I0829 20:19:42.581722 916722 sgd_solver.cpp:106] Iteration 651500, lr = 0.01
I0829 20:20:12.644836 916722 solver.cpp:218] Iteration 652000 (16.6317 iter/s, 30.0631s/500 iters), loss = 0.0243182
I0829 20:20:12.644891 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0243273 (* 1 = 0.0243273 loss)
I0829 20:20:12.644899 916722 sgd_solver.cpp:106] Iteration 652000, lr = 0.01
I0829 20:20:42.697881 916722 solver.cpp:218] Iteration 652500 (16.6373 iter/s, 30.053s/500 iters), loss = 0.237072
I0829 20:20:42.697938 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.237081 (* 1 = 0.237081 loss)
I0829 20:20:42.697947 916722 sgd_solver.cpp:106] Iteration 652500, lr = 0.01
I0829 20:21:12.752835 916722 solver.cpp:218] Iteration 653000 (16.6362 iter/s, 30.0549s/500 iters), loss = 0.213452
I0829 20:21:12.752892 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.213461 (* 1 = 0.213461 loss)
I0829 20:21:12.752900 916722 sgd_solver.cpp:106] Iteration 653000, lr = 0.01
I0829 20:21:42.822052 916722 solver.cpp:218] Iteration 653500 (16.6284 iter/s, 30.0691s/500 iters), loss = 0.330547
I0829 20:21:42.822113 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.330556 (* 1 = 0.330556 loss)
I0829 20:21:42.822121 916722 sgd_solver.cpp:106] Iteration 653500, lr = 0.01
I0829 20:22:12.880364 916722 solver.cpp:218] Iteration 654000 (16.6344 iter/s, 30.0582s/500 iters), loss = 0.0713996
I0829 20:22:12.880430 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0714086 (* 1 = 0.0714086 loss)
I0829 20:22:12.880439 916722 sgd_solver.cpp:106] Iteration 654000, lr = 0.01
I0829 20:22:42.947926 916722 solver.cpp:218] Iteration 654500 (16.6293 iter/s, 30.0675s/500 iters), loss = 0.262359
I0829 20:22:42.947986 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.262368 (* 1 = 0.262368 loss)
I0829 20:22:42.947994 916722 sgd_solver.cpp:106] Iteration 654500, lr = 0.01
I0829 20:23:13.022126 916722 solver.cpp:218] Iteration 655000 (16.6256 iter/s, 30.0741s/500 iters), loss = 0.0657802
I0829 20:23:13.022187 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0657893 (* 1 = 0.0657893 loss)
I0829 20:23:13.022195 916722 sgd_solver.cpp:106] Iteration 655000, lr = 0.01
I0829 20:23:43.107538 916722 solver.cpp:218] Iteration 655500 (16.6194 iter/s, 30.0853s/500 iters), loss = 0.0767528
I0829 20:23:43.107599 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0767621 (* 1 = 0.0767621 loss)
I0829 20:23:43.107609 916722 sgd_solver.cpp:106] Iteration 655500, lr = 0.01
I0829 20:24:13.179323 916722 solver.cpp:218] Iteration 656000 (16.6269 iter/s, 30.0717s/500 iters), loss = 0.255593
I0829 20:24:13.179392 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.255602 (* 1 = 0.255602 loss)
I0829 20:24:13.179409 916722 sgd_solver.cpp:106] Iteration 656000, lr = 0.01
I0829 20:24:43.244462 916722 solver.cpp:218] Iteration 656500 (16.6306 iter/s, 30.065s/500 iters), loss = 0.291287
I0829 20:24:43.244513 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.291296 (* 1 = 0.291296 loss)
I0829 20:24:43.244522 916722 sgd_solver.cpp:106] Iteration 656500, lr = 0.01
I0829 20:25:13.291584 916722 solver.cpp:218] Iteration 657000 (16.6406 iter/s, 30.047s/500 iters), loss = 0.135239
I0829 20:25:13.291637 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.135248 (* 1 = 0.135248 loss)
I0829 20:25:13.291646 916722 sgd_solver.cpp:106] Iteration 657000, lr = 0.01
I0829 20:25:43.376163 916722 solver.cpp:218] Iteration 657500 (16.6199 iter/s, 30.0845s/500 iters), loss = 0.0656707
I0829 20:25:43.376224 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0656797 (* 1 = 0.0656797 loss)
I0829 20:25:43.376232 916722 sgd_solver.cpp:106] Iteration 657500, lr = 0.01
I0829 20:26:13.423424 916722 solver.cpp:218] Iteration 658000 (16.6405 iter/s, 30.0472s/500 iters), loss = 0.250745
I0829 20:26:13.423480 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.250754 (* 1 = 0.250754 loss)
I0829 20:26:13.423487 916722 sgd_solver.cpp:106] Iteration 658000, lr = 0.01
I0829 20:26:43.480615 916722 solver.cpp:218] Iteration 658500 (16.635 iter/s, 30.0571s/500 iters), loss = 0.338187
I0829 20:26:43.480675 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.338196 (* 1 = 0.338196 loss)
I0829 20:26:43.480684 916722 sgd_solver.cpp:106] Iteration 658500, lr = 0.01
I0829 20:27:13.544050 916722 solver.cpp:218] Iteration 659000 (16.6316 iter/s, 30.0633s/500 iters), loss = 0.236521
I0829 20:27:13.544106 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.23653 (* 1 = 0.23653 loss)
I0829 20:27:13.544114 916722 sgd_solver.cpp:106] Iteration 659000, lr = 0.01
I0829 20:27:43.614055 916722 solver.cpp:218] Iteration 659500 (16.6279 iter/s, 30.0699s/500 iters), loss = 0.239041
I0829 20:27:43.614115 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.23905 (* 1 = 0.23905 loss)
I0829 20:27:43.614125 916722 sgd_solver.cpp:106] Iteration 659500, lr = 0.01
I0829 20:28:13.680944 916722 solver.cpp:218] Iteration 660000 (16.6296 iter/s, 30.0668s/500 iters), loss = 0.0914102
I0829 20:28:13.681000 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0914193 (* 1 = 0.0914193 loss)
I0829 20:28:13.681008 916722 sgd_solver.cpp:106] Iteration 660000, lr = 0.01
I0829 20:28:43.739172 916722 solver.cpp:218] Iteration 660500 (16.6344 iter/s, 30.0581s/500 iters), loss = 0.0965203
I0829 20:28:43.739229 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0965294 (* 1 = 0.0965294 loss)
I0829 20:28:43.739238 916722 sgd_solver.cpp:106] Iteration 660500, lr = 0.01
I0829 20:29:13.795413 916722 solver.cpp:218] Iteration 661000 (16.6355 iter/s, 30.0561s/500 iters), loss = 0.106009
I0829 20:29:13.795467 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.106019 (* 1 = 0.106019 loss)
I0829 20:29:13.795475 916722 sgd_solver.cpp:106] Iteration 661000, lr = 0.01
I0829 20:29:43.860905 916722 solver.cpp:218] Iteration 661500 (16.6304 iter/s, 30.0654s/500 iters), loss = 0.125134
I0829 20:29:43.860965 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.125143 (* 1 = 0.125143 loss)
I0829 20:29:43.860973 916722 sgd_solver.cpp:106] Iteration 661500, lr = 0.01
I0829 20:30:13.926831 916722 solver.cpp:218] Iteration 662000 (16.6302 iter/s, 30.0658s/500 iters), loss = 0.082572
I0829 20:30:13.926889 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0825809 (* 1 = 0.0825809 loss)
I0829 20:30:13.926898 916722 sgd_solver.cpp:106] Iteration 662000, lr = 0.01
I0829 20:30:44.014008 916722 solver.cpp:218] Iteration 662500 (16.6184 iter/s, 30.0871s/500 iters), loss = 0.0784004
I0829 20:30:44.014075 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0784094 (* 1 = 0.0784094 loss)
I0829 20:30:44.014091 916722 sgd_solver.cpp:106] Iteration 662500, lr = 0.01
I0829 20:31:14.070036 916722 solver.cpp:218] Iteration 663000 (16.6357 iter/s, 30.0559s/500 iters), loss = 0.151435
I0829 20:31:14.070089 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.151444 (* 1 = 0.151444 loss)
I0829 20:31:14.070097 916722 sgd_solver.cpp:106] Iteration 663000, lr = 0.01
I0829 20:31:44.123589 916722 solver.cpp:218] Iteration 663500 (16.637 iter/s, 30.0535s/500 iters), loss = 0.275815
I0829 20:31:44.123646 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.275824 (* 1 = 0.275824 loss)
I0829 20:31:44.123653 916722 sgd_solver.cpp:106] Iteration 663500, lr = 0.01
I0829 20:32:14.166553 916722 solver.cpp:218] Iteration 664000 (16.6429 iter/s, 30.0429s/500 iters), loss = 0.0550738
I0829 20:32:14.166608 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0550827 (* 1 = 0.0550827 loss)
I0829 20:32:14.166616 916722 sgd_solver.cpp:106] Iteration 664000, lr = 0.01
I0829 20:32:44.221853 916722 solver.cpp:218] Iteration 664500 (16.6361 iter/s, 30.0552s/500 iters), loss = 0.293322
I0829 20:32:44.221908 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.293331 (* 1 = 0.293331 loss)
I0829 20:32:44.221917 916722 sgd_solver.cpp:106] Iteration 664500, lr = 0.01
I0829 20:33:14.278165 916722 solver.cpp:218] Iteration 665000 (16.6355 iter/s, 30.0562s/500 iters), loss = 0.329129
I0829 20:33:14.278219 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.329138 (* 1 = 0.329138 loss)
I0829 20:33:14.278228 916722 sgd_solver.cpp:106] Iteration 665000, lr = 0.01
I0829 20:33:44.313045 916722 solver.cpp:218] Iteration 665500 (16.6474 iter/s, 30.0348s/500 iters), loss = 0.147558
I0829 20:33:44.313097 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.147567 (* 1 = 0.147567 loss)
I0829 20:33:44.313104 916722 sgd_solver.cpp:106] Iteration 665500, lr = 0.01
I0829 20:34:14.401402 916722 solver.cpp:218] Iteration 666000 (16.6178 iter/s, 30.0883s/500 iters), loss = 0.114877
I0829 20:34:14.401459 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.114886 (* 1 = 0.114886 loss)
I0829 20:34:14.401468 916722 sgd_solver.cpp:106] Iteration 666000, lr = 0.01
I0829 20:34:44.447777 916722 solver.cpp:218] Iteration 666500 (16.641 iter/s, 30.0463s/500 iters), loss = 0.278367
I0829 20:34:44.447837 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.278377 (* 1 = 0.278377 loss)
I0829 20:34:44.447846 916722 sgd_solver.cpp:106] Iteration 666500, lr = 0.01
I0829 20:35:14.497973 916722 solver.cpp:218] Iteration 667000 (16.6389 iter/s, 30.0501s/500 iters), loss = 0.207301
I0829 20:35:14.498028 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.207311 (* 1 = 0.207311 loss)
I0829 20:35:14.498036 916722 sgd_solver.cpp:106] Iteration 667000, lr = 0.01
I0829 20:35:44.551532 916722 solver.cpp:218] Iteration 667500 (16.637 iter/s, 30.0535s/500 iters), loss = 0.198116
I0829 20:35:44.551587 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.198125 (* 1 = 0.198125 loss)
I0829 20:35:44.551595 916722 sgd_solver.cpp:106] Iteration 667500, lr = 0.01
I0829 20:36:14.601521 916722 solver.cpp:218] Iteration 668000 (16.639 iter/s, 30.0499s/500 iters), loss = 0.301555
I0829 20:36:14.601574 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.301564 (* 1 = 0.301564 loss)
I0829 20:36:14.601583 916722 sgd_solver.cpp:106] Iteration 668000, lr = 0.01
I0829 20:36:44.660557 916722 solver.cpp:218] Iteration 668500 (16.634 iter/s, 30.0589s/500 iters), loss = 0.163848
I0829 20:36:44.660619 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.163857 (* 1 = 0.163857 loss)
I0829 20:36:44.660627 916722 sgd_solver.cpp:106] Iteration 668500, lr = 0.01
I0829 20:37:14.675361 916722 solver.cpp:218] Iteration 669000 (16.6585 iter/s, 30.0147s/500 iters), loss = 0.222189
I0829 20:37:14.675413 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.222198 (* 1 = 0.222198 loss)
I0829 20:37:14.675422 916722 sgd_solver.cpp:106] Iteration 669000, lr = 0.01
I0829 20:37:44.695879 916722 solver.cpp:218] Iteration 669500 (16.6553 iter/s, 30.0204s/500 iters), loss = 0.407463
I0829 20:37:44.695946 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.407472 (* 1 = 0.407472 loss)
I0829 20:37:44.695955 916722 sgd_solver.cpp:106] Iteration 669500, lr = 0.01
I0829 20:38:14.721323 916722 solver.cpp:218] Iteration 670000 (16.6526 iter/s, 30.0253s/500 iters), loss = 0.271192
I0829 20:38:14.721379 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.271201 (* 1 = 0.271201 loss)
I0829 20:38:14.721386 916722 sgd_solver.cpp:106] Iteration 670000, lr = 0.01
I0829 20:38:44.778937 916722 solver.cpp:218] Iteration 670500 (16.6348 iter/s, 30.0575s/500 iters), loss = 0.12735
I0829 20:38:44.778992 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.127359 (* 1 = 0.127359 loss)
I0829 20:38:44.779001 916722 sgd_solver.cpp:106] Iteration 670500, lr = 0.01
I0829 20:39:14.829171 916722 solver.cpp:218] Iteration 671000 (16.6389 iter/s, 30.0501s/500 iters), loss = 0.325699
I0829 20:39:14.829226 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.325707 (* 1 = 0.325707 loss)
I0829 20:39:14.829234 916722 sgd_solver.cpp:106] Iteration 671000, lr = 0.01
I0829 20:39:44.891947 916722 solver.cpp:218] Iteration 671500 (16.6319 iter/s, 30.0627s/500 iters), loss = 0.148547
I0829 20:39:44.892004 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.148556 (* 1 = 0.148556 loss)
I0829 20:39:44.892011 916722 sgd_solver.cpp:106] Iteration 671500, lr = 0.01
I0829 20:40:14.966118 916722 solver.cpp:218] Iteration 672000 (16.6256 iter/s, 30.0741s/500 iters), loss = 0.109984
I0829 20:40:14.966171 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109993 (* 1 = 0.109993 loss)
I0829 20:40:14.966179 916722 sgd_solver.cpp:106] Iteration 672000, lr = 0.01
I0829 20:40:45.039014 916722 solver.cpp:218] Iteration 672500 (16.6263 iter/s, 30.0728s/500 iters), loss = 0.103215
I0829 20:40:45.039069 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.103224 (* 1 = 0.103224 loss)
I0829 20:40:45.039077 916722 sgd_solver.cpp:106] Iteration 672500, lr = 0.01
I0829 20:41:15.101727 916722 solver.cpp:218] Iteration 673000 (16.632 iter/s, 30.0626s/500 iters), loss = 0.0810232
I0829 20:41:15.101784 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0810324 (* 1 = 0.0810324 loss)
I0829 20:41:15.101792 916722 sgd_solver.cpp:106] Iteration 673000, lr = 0.01
I0829 20:41:45.177237 916722 solver.cpp:218] Iteration 673500 (16.6249 iter/s, 30.0754s/500 iters), loss = 0.118012
I0829 20:41:45.177296 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.118021 (* 1 = 0.118021 loss)
I0829 20:41:45.177304 916722 sgd_solver.cpp:106] Iteration 673500, lr = 0.01
I0829 20:42:15.246155 916722 solver.cpp:218] Iteration 674000 (16.6285 iter/s, 30.0688s/500 iters), loss = 0.201866
I0829 20:42:15.246210 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.201875 (* 1 = 0.201875 loss)
I0829 20:42:15.246219 916722 sgd_solver.cpp:106] Iteration 674000, lr = 0.01
I0829 20:42:45.318351 916722 solver.cpp:218] Iteration 674500 (16.6267 iter/s, 30.0721s/500 iters), loss = 0.116513
I0829 20:42:45.318406 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.116522 (* 1 = 0.116522 loss)
I0829 20:42:45.318415 916722 sgd_solver.cpp:106] Iteration 674500, lr = 0.01
I0829 20:43:15.372123 916722 solver.cpp:218] Iteration 675000 (16.6369 iter/s, 30.0537s/500 iters), loss = 0.076216
I0829 20:43:15.372177 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.076225 (* 1 = 0.076225 loss)
I0829 20:43:15.372186 916722 sgd_solver.cpp:106] Iteration 675000, lr = 0.01
I0829 20:43:45.433049 916722 solver.cpp:218] Iteration 675500 (16.6329 iter/s, 30.0608s/500 iters), loss = 0.0951786
I0829 20:43:45.433104 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0951873 (* 1 = 0.0951873 loss)
I0829 20:43:45.433111 916722 sgd_solver.cpp:106] Iteration 675500, lr = 0.01
I0829 20:44:15.502288 916722 solver.cpp:218] Iteration 676000 (16.6283 iter/s, 30.0692s/500 iters), loss = 0.276991
I0829 20:44:15.502358 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.276999 (* 1 = 0.276999 loss)
I0829 20:44:15.502367 916722 sgd_solver.cpp:106] Iteration 676000, lr = 0.01
I0829 20:44:45.567698 916722 solver.cpp:218] Iteration 676500 (16.6305 iter/s, 30.0653s/500 iters), loss = 0.154585
I0829 20:44:45.567750 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.154593 (* 1 = 0.154593 loss)
I0829 20:44:45.567759 916722 sgd_solver.cpp:106] Iteration 676500, lr = 0.01
I0829 20:45:15.639719 916722 solver.cpp:218] Iteration 677000 (16.6268 iter/s, 30.0719s/500 iters), loss = 0.141266
I0829 20:45:15.639771 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.141275 (* 1 = 0.141275 loss)
I0829 20:45:15.639780 916722 sgd_solver.cpp:106] Iteration 677000, lr = 0.01
I0829 20:45:45.707556 916722 solver.cpp:218] Iteration 677500 (16.6291 iter/s, 30.0677s/500 iters), loss = 0.165713
I0829 20:45:45.707609 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.165722 (* 1 = 0.165722 loss)
I0829 20:45:45.707617 916722 sgd_solver.cpp:106] Iteration 677500, lr = 0.01
I0829 20:46:15.752182 916722 solver.cpp:218] Iteration 678000 (16.642 iter/s, 30.0445s/500 iters), loss = 0.0777072
I0829 20:46:15.752238 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0777162 (* 1 = 0.0777162 loss)
I0829 20:46:15.752246 916722 sgd_solver.cpp:106] Iteration 678000, lr = 0.01
I0829 20:46:45.810983 916722 solver.cpp:218] Iteration 678500 (16.6341 iter/s, 30.0587s/500 iters), loss = 0.0776829
I0829 20:46:45.811039 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.077692 (* 1 = 0.077692 loss)
I0829 20:46:45.811048 916722 sgd_solver.cpp:106] Iteration 678500, lr = 0.01
I0829 20:47:15.858397 916722 solver.cpp:218] Iteration 679000 (16.6404 iter/s, 30.0473s/500 iters), loss = 0.327872
I0829 20:47:15.858451 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.327881 (* 1 = 0.327881 loss)
I0829 20:47:15.858459 916722 sgd_solver.cpp:106] Iteration 679000, lr = 0.01
I0829 20:47:45.906236 916722 solver.cpp:218] Iteration 679500 (16.6402 iter/s, 30.0477s/500 iters), loss = 0.050331
I0829 20:47:45.906294 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.05034 (* 1 = 0.05034 loss)
I0829 20:47:45.906303 916722 sgd_solver.cpp:106] Iteration 679500, lr = 0.01
I0829 20:48:15.942138 916722 solver.cpp:218] Iteration 680000 (16.6468 iter/s, 30.0358s/500 iters), loss = 0.221537
I0829 20:48:15.942193 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.221546 (* 1 = 0.221546 loss)
I0829 20:48:15.942200 916722 sgd_solver.cpp:106] Iteration 680000, lr = 0.01
I0829 20:48:46.005239 916722 solver.cpp:218] Iteration 680500 (16.6318 iter/s, 30.063s/500 iters), loss = 0.100596
I0829 20:48:46.005293 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.100605 (* 1 = 0.100605 loss)
I0829 20:48:46.005301 916722 sgd_solver.cpp:106] Iteration 680500, lr = 0.01
I0829 20:49:16.062117 916722 solver.cpp:218] Iteration 681000 (16.6352 iter/s, 30.0567s/500 iters), loss = 0.157013
I0829 20:49:16.062171 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.157022 (* 1 = 0.157022 loss)
I0829 20:49:16.062180 916722 sgd_solver.cpp:106] Iteration 681000, lr = 0.01
I0829 20:49:46.114078 916722 solver.cpp:218] Iteration 681500 (16.6379 iter/s, 30.0518s/500 iters), loss = 0.137275
I0829 20:49:46.114130 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.137284 (* 1 = 0.137284 loss)
I0829 20:49:46.114138 916722 sgd_solver.cpp:106] Iteration 681500, lr = 0.01
I0829 20:50:16.154809 916722 solver.cpp:218] Iteration 682000 (16.6441 iter/s, 30.0406s/500 iters), loss = 0.277988
I0829 20:50:16.154861 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.277997 (* 1 = 0.277997 loss)
I0829 20:50:16.154870 916722 sgd_solver.cpp:106] Iteration 682000, lr = 0.01
I0829 20:50:46.203050 916722 solver.cpp:218] Iteration 682500 (16.64 iter/s, 30.0481s/500 iters), loss = 0.0156439
I0829 20:50:46.203119 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0156528 (* 1 = 0.0156528 loss)
I0829 20:50:46.203132 916722 sgd_solver.cpp:106] Iteration 682500, lr = 0.01
I0829 20:51:16.260967 916722 solver.cpp:218] Iteration 683000 (16.6346 iter/s, 30.0578s/500 iters), loss = 0.130666
I0829 20:51:16.261020 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130675 (* 1 = 0.130675 loss)
I0829 20:51:16.261029 916722 sgd_solver.cpp:106] Iteration 683000, lr = 0.01
I0829 20:51:46.333528 916722 solver.cpp:218] Iteration 683500 (16.6265 iter/s, 30.0724s/500 iters), loss = 0.171842
I0829 20:51:46.333583 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.171851 (* 1 = 0.171851 loss)
I0829 20:51:46.333592 916722 sgd_solver.cpp:106] Iteration 683500, lr = 0.01
I0829 20:52:16.343279 916722 solver.cpp:218] Iteration 684000 (16.6613 iter/s, 30.0096s/500 iters), loss = 0.157497
I0829 20:52:16.343333 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.157505 (* 1 = 0.157505 loss)
I0829 20:52:16.343343 916722 sgd_solver.cpp:106] Iteration 684000, lr = 0.01
I0829 20:52:46.393044 916722 solver.cpp:218] Iteration 684500 (16.6391 iter/s, 30.0496s/500 iters), loss = 0.0434948
I0829 20:52:46.393100 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0435032 (* 1 = 0.0435032 loss)
I0829 20:52:46.393108 916722 sgd_solver.cpp:106] Iteration 684500, lr = 0.01
I0829 20:53:16.418104 916722 solver.cpp:218] Iteration 685000 (16.6528 iter/s, 30.0249s/500 iters), loss = 0.0551966
I0829 20:53:16.418159 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.055205 (* 1 = 0.055205 loss)
I0829 20:53:16.418169 916722 sgd_solver.cpp:106] Iteration 685000, lr = 0.01
I0829 20:53:46.453550 916722 solver.cpp:218] Iteration 685500 (16.6471 iter/s, 30.0353s/500 iters), loss = 0.334354
I0829 20:53:46.453608 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.334363 (* 1 = 0.334363 loss)
I0829 20:53:46.453615 916722 sgd_solver.cpp:106] Iteration 685500, lr = 0.01
I0829 20:54:16.502055 916722 solver.cpp:218] Iteration 686000 (16.6398 iter/s, 30.0484s/500 iters), loss = 0.0441381
I0829 20:54:16.502112 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0441464 (* 1 = 0.0441464 loss)
I0829 20:54:16.502120 916722 sgd_solver.cpp:106] Iteration 686000, lr = 0.01
I0829 20:54:46.545063 916722 solver.cpp:218] Iteration 686500 (16.6429 iter/s, 30.0429s/500 iters), loss = 0.138643
I0829 20:54:46.545116 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.138651 (* 1 = 0.138651 loss)
I0829 20:54:46.545125 916722 sgd_solver.cpp:106] Iteration 686500, lr = 0.01
I0829 20:55:16.603296 916722 solver.cpp:218] Iteration 687000 (16.6344 iter/s, 30.0581s/500 iters), loss = 0.0601184
I0829 20:55:16.603353 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0601269 (* 1 = 0.0601269 loss)
I0829 20:55:16.603360 916722 sgd_solver.cpp:106] Iteration 687000, lr = 0.01
I0829 20:55:46.629657 916722 solver.cpp:218] Iteration 687500 (16.6521 iter/s, 30.0262s/500 iters), loss = 0.254345
I0829 20:55:46.629714 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.254354 (* 1 = 0.254354 loss)
I0829 20:55:46.629724 916722 sgd_solver.cpp:106] Iteration 687500, lr = 0.01
I0829 20:56:16.667955 916722 solver.cpp:218] Iteration 688000 (16.6455 iter/s, 30.0382s/500 iters), loss = 0.0173174
I0829 20:56:16.668010 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.017326 (* 1 = 0.017326 loss)
I0829 20:56:16.668018 916722 sgd_solver.cpp:106] Iteration 688000, lr = 0.01
I0829 20:56:46.710186 916722 solver.cpp:218] Iteration 688500 (16.6433 iter/s, 30.0421s/500 iters), loss = 0.242449
I0829 20:56:46.710242 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.242457 (* 1 = 0.242457 loss)
I0829 20:56:46.710249 916722 sgd_solver.cpp:106] Iteration 688500, lr = 0.01
I0829 20:57:16.756000 916722 solver.cpp:218] Iteration 689000 (16.6413 iter/s, 30.0457s/500 iters), loss = 0.441972
I0829 20:57:16.756067 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.44198 (* 1 = 0.44198 loss)
I0829 20:57:16.756080 916722 sgd_solver.cpp:106] Iteration 689000, lr = 0.01
I0829 20:57:46.805689 916722 solver.cpp:218] Iteration 689500 (16.6392 iter/s, 30.0496s/500 iters), loss = 0.0595824
I0829 20:57:46.805745 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0595909 (* 1 = 0.0595909 loss)
I0829 20:57:46.805754 916722 sgd_solver.cpp:106] Iteration 689500, lr = 0.01
I0829 20:58:16.841271 916722 solver.cpp:218] Iteration 690000 (16.647 iter/s, 30.0355s/500 iters), loss = 0.224766
I0829 20:58:16.841325 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.224775 (* 1 = 0.224775 loss)
I0829 20:58:16.841333 916722 sgd_solver.cpp:106] Iteration 690000, lr = 0.01
I0829 20:58:46.886693 916722 solver.cpp:218] Iteration 690500 (16.6415 iter/s, 30.0453s/500 iters), loss = 0.112899
I0829 20:58:46.886752 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112908 (* 1 = 0.112908 loss)
I0829 20:58:46.886762 916722 sgd_solver.cpp:106] Iteration 690500, lr = 0.01
I0829 20:59:16.935163 916722 solver.cpp:218] Iteration 691000 (16.6398 iter/s, 30.0484s/500 iters), loss = 0.172049
I0829 20:59:16.935214 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.172058 (* 1 = 0.172058 loss)
I0829 20:59:16.935221 916722 sgd_solver.cpp:106] Iteration 691000, lr = 0.01
I0829 20:59:46.974213 916722 solver.cpp:218] Iteration 691500 (16.6451 iter/s, 30.0389s/500 iters), loss = 0.284921
I0829 20:59:46.974268 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.28493 (* 1 = 0.28493 loss)
I0829 20:59:46.974277 916722 sgd_solver.cpp:106] Iteration 691500, lr = 0.01
I0829 21:00:17.001298 916722 solver.cpp:218] Iteration 692000 (16.6517 iter/s, 30.027s/500 iters), loss = 0.134627
I0829 21:00:17.001354 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.134635 (* 1 = 0.134635 loss)
I0829 21:00:17.001363 916722 sgd_solver.cpp:106] Iteration 692000, lr = 0.01
I0829 21:00:47.035356 916722 solver.cpp:218] Iteration 692500 (16.6478 iter/s, 30.0339s/500 iters), loss = 0.136178
I0829 21:00:47.035420 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.136187 (* 1 = 0.136187 loss)
I0829 21:00:47.035429 916722 sgd_solver.cpp:106] Iteration 692500, lr = 0.01
I0829 21:01:17.075420 916722 solver.cpp:218] Iteration 693000 (16.6445 iter/s, 30.0399s/500 iters), loss = 0.0687452
I0829 21:01:17.075475 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0687536 (* 1 = 0.0687536 loss)
I0829 21:01:17.075484 916722 sgd_solver.cpp:106] Iteration 693000, lr = 0.01
I0829 21:01:47.132829 916722 solver.cpp:218] Iteration 693500 (16.6349 iter/s, 30.0573s/500 iters), loss = 0.156722
I0829 21:01:47.132887 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.15673 (* 1 = 0.15673 loss)
I0829 21:01:47.132896 916722 sgd_solver.cpp:106] Iteration 693500, lr = 0.01
I0829 21:02:17.180436 916722 solver.cpp:218] Iteration 694000 (16.6403 iter/s, 30.0475s/500 iters), loss = 0.0929653
I0829 21:02:17.180506 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0929737 (* 1 = 0.0929737 loss)
I0829 21:02:17.180516 916722 sgd_solver.cpp:106] Iteration 694000, lr = 0.01
I0829 21:02:47.196158 916722 solver.cpp:218] Iteration 694500 (16.658 iter/s, 30.0156s/500 iters), loss = 0.134838
I0829 21:02:47.196214 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.134846 (* 1 = 0.134846 loss)
I0829 21:02:47.196223 916722 sgd_solver.cpp:106] Iteration 694500, lr = 0.01
I0829 21:03:17.223690 916722 solver.cpp:218] Iteration 695000 (16.6514 iter/s, 30.0274s/500 iters), loss = 0.0881271
I0829 21:03:17.223742 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0881355 (* 1 = 0.0881355 loss)
I0829 21:03:17.223752 916722 sgd_solver.cpp:106] Iteration 695000, lr = 0.01
I0829 21:03:47.278259 916722 solver.cpp:218] Iteration 695500 (16.6365 iter/s, 30.0545s/500 iters), loss = 0.256596
I0829 21:03:47.278311 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.256604 (* 1 = 0.256604 loss)
I0829 21:03:47.278321 916722 sgd_solver.cpp:106] Iteration 695500, lr = 0.01
I0829 21:04:17.316335 916722 solver.cpp:218] Iteration 696000 (16.6456 iter/s, 30.038s/500 iters), loss = 0.367288
I0829 21:04:17.316397 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.367296 (* 1 = 0.367296 loss)
I0829 21:04:17.316406 916722 sgd_solver.cpp:106] Iteration 696000, lr = 0.01
I0829 21:04:47.341030 916722 solver.cpp:218] Iteration 696500 (16.653 iter/s, 30.0246s/500 iters), loss = 0.0920393
I0829 21:04:47.341084 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0920477 (* 1 = 0.0920477 loss)
I0829 21:04:47.341092 916722 sgd_solver.cpp:106] Iteration 696500, lr = 0.01
I0829 21:05:17.390965 916722 solver.cpp:218] Iteration 697000 (16.639 iter/s, 30.0498s/500 iters), loss = 0.0636882
I0829 21:05:17.391018 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0636968 (* 1 = 0.0636968 loss)
I0829 21:05:17.391026 916722 sgd_solver.cpp:106] Iteration 697000, lr = 0.01
I0829 21:05:47.424203 916722 solver.cpp:218] Iteration 697500 (16.6483 iter/s, 30.0331s/500 iters), loss = 0.211865
I0829 21:05:47.424254 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.211873 (* 1 = 0.211873 loss)
I0829 21:05:47.424263 916722 sgd_solver.cpp:106] Iteration 697500, lr = 0.01
I0829 21:06:17.467583 916722 solver.cpp:218] Iteration 698000 (16.6427 iter/s, 30.0433s/500 iters), loss = 0.345473
I0829 21:06:17.467633 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.345481 (* 1 = 0.345481 loss)
I0829 21:06:17.467640 916722 sgd_solver.cpp:106] Iteration 698000, lr = 0.01
I0829 21:06:47.493430 916722 solver.cpp:218] Iteration 698500 (16.6524 iter/s, 30.0257s/500 iters), loss = 0.261091
I0829 21:06:47.493482 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.261099 (* 1 = 0.261099 loss)
I0829 21:06:47.493490 916722 sgd_solver.cpp:106] Iteration 698500, lr = 0.01
I0829 21:07:17.535239 916722 solver.cpp:218] Iteration 699000 (16.6435 iter/s, 30.0417s/500 iters), loss = 0.105633
I0829 21:07:17.535290 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105641 (* 1 = 0.105641 loss)
I0829 21:07:17.535300 916722 sgd_solver.cpp:106] Iteration 699000, lr = 0.01
I0829 21:07:47.570569 916722 solver.cpp:218] Iteration 699500 (16.6471 iter/s, 30.0352s/500 iters), loss = 0.110473
I0829 21:07:47.570618 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110481 (* 1 = 0.110481 loss)
I0829 21:07:47.570627 916722 sgd_solver.cpp:106] Iteration 699500, lr = 0.01
I0829 21:08:17.562140 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_700000.caffemodel
I0829 21:08:17.581674 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_700000.solverstate
I0829 21:08:17.587924 916722 solver.cpp:330] Iteration 700000, Testing net (#0)
I0829 21:08:33.044946 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8678
I0829 21:08:33.044988 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.443979 (* 1 = 0.443979 loss)
I0829 21:08:33.103823 916722 solver.cpp:218] Iteration 700000 (10.981 iter/s, 45.5331s/500 iters), loss = 0.207509
I0829 21:08:33.103852 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.207517 (* 1 = 0.207517 loss)
I0829 21:08:33.103860 916722 sgd_solver.cpp:106] Iteration 700000, lr = 0.01
I0829 21:09:03.005630 916722 solver.cpp:218] Iteration 700500 (16.7215 iter/s, 29.9017s/500 iters), loss = 0.499239
I0829 21:09:03.005686 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.499247 (* 1 = 0.499247 loss)
I0829 21:09:03.005694 916722 sgd_solver.cpp:106] Iteration 700500, lr = 0.01
I0829 21:09:33.026216 916722 solver.cpp:218] Iteration 701000 (16.6553 iter/s, 30.0205s/500 iters), loss = 0.0609425
I0829 21:09:33.026268 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0609505 (* 1 = 0.0609505 loss)
I0829 21:09:33.026278 916722 sgd_solver.cpp:106] Iteration 701000, lr = 0.01
I0829 21:10:03.046908 916722 solver.cpp:218] Iteration 701500 (16.6552 iter/s, 30.0206s/500 iters), loss = 0.430509
I0829 21:10:03.046972 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.430517 (* 1 = 0.430517 loss)
I0829 21:10:03.046981 916722 sgd_solver.cpp:106] Iteration 701500, lr = 0.01
I0829 21:10:33.099937 916722 solver.cpp:218] Iteration 702000 (16.6373 iter/s, 30.0529s/500 iters), loss = 0.350699
I0829 21:10:33.099990 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.350707 (* 1 = 0.350707 loss)
I0829 21:10:33.099999 916722 sgd_solver.cpp:106] Iteration 702000, lr = 0.01
I0829 21:11:03.150642 916722 solver.cpp:218] Iteration 702500 (16.6386 iter/s, 30.0506s/500 iters), loss = 0.168857
I0829 21:11:03.150692 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.168865 (* 1 = 0.168865 loss)
I0829 21:11:03.150700 916722 sgd_solver.cpp:106] Iteration 702500, lr = 0.01
I0829 21:11:33.197475 916722 solver.cpp:218] Iteration 703000 (16.6407 iter/s, 30.0467s/500 iters), loss = 0.111134
I0829 21:11:33.197526 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111143 (* 1 = 0.111143 loss)
I0829 21:11:33.197535 916722 sgd_solver.cpp:106] Iteration 703000, lr = 0.01
I0829 21:12:03.237118 916722 solver.cpp:218] Iteration 703500 (16.6447 iter/s, 30.0395s/500 iters), loss = 0.0587494
I0829 21:12:03.237169 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0587579 (* 1 = 0.0587579 loss)
I0829 21:12:03.237179 916722 sgd_solver.cpp:106] Iteration 703500, lr = 0.01
I0829 21:12:33.295457 916722 solver.cpp:218] Iteration 704000 (16.6344 iter/s, 30.0582s/500 iters), loss = 0.136496
I0829 21:12:33.295507 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.136505 (* 1 = 0.136505 loss)
I0829 21:12:33.295516 916722 sgd_solver.cpp:106] Iteration 704000, lr = 0.01
I0829 21:13:03.330070 916722 solver.cpp:218] Iteration 704500 (16.6475 iter/s, 30.0345s/500 iters), loss = 0.272534
I0829 21:13:03.330121 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.272543 (* 1 = 0.272543 loss)
I0829 21:13:03.330129 916722 sgd_solver.cpp:106] Iteration 704500, lr = 0.01
I0829 21:13:33.368978 916722 solver.cpp:218] Iteration 705000 (16.6451 iter/s, 30.0388s/500 iters), loss = 0.143036
I0829 21:13:33.369029 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.143044 (* 1 = 0.143044 loss)
I0829 21:13:33.369036 916722 sgd_solver.cpp:106] Iteration 705000, lr = 0.01
I0829 21:14:03.439679 916722 solver.cpp:218] Iteration 705500 (16.6275 iter/s, 30.0706s/500 iters), loss = 0.224037
I0829 21:14:03.439733 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.224046 (* 1 = 0.224046 loss)
I0829 21:14:03.439741 916722 sgd_solver.cpp:106] Iteration 705500, lr = 0.01
I0829 21:14:33.463310 916722 solver.cpp:218] Iteration 706000 (16.6536 iter/s, 30.0235s/500 iters), loss = 0.0526985
I0829 21:14:33.463362 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0527069 (* 1 = 0.0527069 loss)
I0829 21:14:33.463371 916722 sgd_solver.cpp:106] Iteration 706000, lr = 0.01
I0829 21:15:03.510572 916722 solver.cpp:218] Iteration 706500 (16.6405 iter/s, 30.0472s/500 iters), loss = 0.103842
I0829 21:15:03.510623 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.10385 (* 1 = 0.10385 loss)
I0829 21:15:03.510632 916722 sgd_solver.cpp:106] Iteration 706500, lr = 0.01
I0829 21:15:33.570775 916722 solver.cpp:218] Iteration 707000 (16.6333 iter/s, 30.0601s/500 iters), loss = 0.159331
I0829 21:15:33.570827 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159339 (* 1 = 0.159339 loss)
I0829 21:15:33.570835 916722 sgd_solver.cpp:106] Iteration 707000, lr = 0.01
I0829 21:16:03.602985 916722 solver.cpp:218] Iteration 707500 (16.6488 iter/s, 30.0321s/500 iters), loss = 0.139477
I0829 21:16:03.603036 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139486 (* 1 = 0.139486 loss)
I0829 21:16:03.603044 916722 sgd_solver.cpp:106] Iteration 707500, lr = 0.01
I0829 21:16:33.648191 916722 solver.cpp:218] Iteration 708000 (16.6416 iter/s, 30.0451s/500 iters), loss = 0.19762
I0829 21:16:33.648252 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.197629 (* 1 = 0.197629 loss)
I0829 21:16:33.648265 916722 sgd_solver.cpp:106] Iteration 708000, lr = 0.01
I0829 21:17:03.689786 916722 solver.cpp:218] Iteration 708500 (16.6436 iter/s, 30.0415s/500 iters), loss = 0.163175
I0829 21:17:03.689837 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.163184 (* 1 = 0.163184 loss)
I0829 21:17:03.689846 916722 sgd_solver.cpp:106] Iteration 708500, lr = 0.01
I0829 21:17:33.732514 916722 solver.cpp:218] Iteration 709000 (16.643 iter/s, 30.0426s/500 iters), loss = 0.264164
I0829 21:17:33.732566 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.264172 (* 1 = 0.264172 loss)
I0829 21:17:33.732574 916722 sgd_solver.cpp:106] Iteration 709000, lr = 0.01
I0829 21:18:03.772503 916722 solver.cpp:218] Iteration 709500 (16.6445 iter/s, 30.0399s/500 iters), loss = 0.0709056
I0829 21:18:03.772554 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.070914 (* 1 = 0.070914 loss)
I0829 21:18:03.772562 916722 sgd_solver.cpp:106] Iteration 709500, lr = 0.01
I0829 21:18:33.814812 916722 solver.cpp:218] Iteration 710000 (16.6432 iter/s, 30.0422s/500 iters), loss = 0.0519623
I0829 21:18:33.814867 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0519705 (* 1 = 0.0519705 loss)
I0829 21:18:33.814877 916722 sgd_solver.cpp:106] Iteration 710000, lr = 0.01
I0829 21:19:03.851213 916722 solver.cpp:218] Iteration 710500 (16.6465 iter/s, 30.0363s/500 iters), loss = 0.0930899
I0829 21:19:03.851263 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0930981 (* 1 = 0.0930981 loss)
I0829 21:19:03.851271 916722 sgd_solver.cpp:106] Iteration 710500, lr = 0.01
I0829 21:19:33.897589 916722 solver.cpp:218] Iteration 711000 (16.641 iter/s, 30.0463s/500 iters), loss = 0.295669
I0829 21:19:33.897640 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.295678 (* 1 = 0.295678 loss)
I0829 21:19:33.897648 916722 sgd_solver.cpp:106] Iteration 711000, lr = 0.01
I0829 21:20:03.937892 916722 solver.cpp:218] Iteration 711500 (16.6444 iter/s, 30.0402s/500 iters), loss = 0.282759
I0829 21:20:03.937940 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.282767 (* 1 = 0.282767 loss)
I0829 21:20:03.937948 916722 sgd_solver.cpp:106] Iteration 711500, lr = 0.01
I0829 21:20:33.992156 916722 solver.cpp:218] Iteration 712000 (16.6366 iter/s, 30.0542s/500 iters), loss = 0.192114
I0829 21:20:33.992209 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.192122 (* 1 = 0.192122 loss)
I0829 21:20:33.992218 916722 sgd_solver.cpp:106] Iteration 712000, lr = 0.01
I0829 21:21:04.021234 916722 solver.cpp:218] Iteration 712500 (16.6506 iter/s, 30.029s/500 iters), loss = 0.142873
I0829 21:21:04.021286 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.142881 (* 1 = 0.142881 loss)
I0829 21:21:04.021294 916722 sgd_solver.cpp:106] Iteration 712500, lr = 0.01
I0829 21:21:34.087256 916722 solver.cpp:218] Iteration 713000 (16.6301 iter/s, 30.066s/500 iters), loss = 0.0783617
I0829 21:21:34.087311 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0783696 (* 1 = 0.0783696 loss)
I0829 21:21:34.087321 916722 sgd_solver.cpp:106] Iteration 713000, lr = 0.01
I0829 21:22:04.110368 916722 solver.cpp:218] Iteration 713500 (16.6539 iter/s, 30.023s/500 iters), loss = 0.155089
I0829 21:22:04.110419 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.155097 (* 1 = 0.155097 loss)
I0829 21:22:04.110427 916722 sgd_solver.cpp:106] Iteration 713500, lr = 0.01
I0829 21:22:34.154670 916722 solver.cpp:218] Iteration 714000 (16.6421 iter/s, 30.0442s/500 iters), loss = 0.337761
I0829 21:22:34.154724 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.33777 (* 1 = 0.33777 loss)
I0829 21:22:34.154732 916722 sgd_solver.cpp:106] Iteration 714000, lr = 0.01
I0829 21:23:04.194811 916722 solver.cpp:218] Iteration 714500 (16.6444 iter/s, 30.0401s/500 iters), loss = 0.155612
I0829 21:23:04.194877 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.15562 (* 1 = 0.15562 loss)
I0829 21:23:04.194886 916722 sgd_solver.cpp:106] Iteration 714500, lr = 0.01
I0829 21:23:34.210795 916722 solver.cpp:218] Iteration 715000 (16.6578 iter/s, 30.0159s/500 iters), loss = 0.077693
I0829 21:23:34.210851 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0777008 (* 1 = 0.0777008 loss)
I0829 21:23:34.210860 916722 sgd_solver.cpp:106] Iteration 715000, lr = 0.01
I0829 21:24:04.240209 916722 solver.cpp:218] Iteration 715500 (16.6504 iter/s, 30.0293s/500 iters), loss = 0.0362401
I0829 21:24:04.240262 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0362478 (* 1 = 0.0362478 loss)
I0829 21:24:04.240270 916722 sgd_solver.cpp:106] Iteration 715500, lr = 0.01
I0829 21:24:34.274958 916722 solver.cpp:218] Iteration 716000 (16.6474 iter/s, 30.0347s/500 iters), loss = 0.178283
I0829 21:24:34.275010 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.178291 (* 1 = 0.178291 loss)
I0829 21:24:34.275018 916722 sgd_solver.cpp:106] Iteration 716000, lr = 0.01
I0829 21:25:04.300069 916722 solver.cpp:218] Iteration 716500 (16.6528 iter/s, 30.025s/500 iters), loss = 0.125125
I0829 21:25:04.300122 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.125132 (* 1 = 0.125132 loss)
I0829 21:25:04.300130 916722 sgd_solver.cpp:106] Iteration 716500, lr = 0.01
I0829 21:25:34.357043 916722 solver.cpp:218] Iteration 717000 (16.6351 iter/s, 30.0569s/500 iters), loss = 0.0961726
I0829 21:25:34.357100 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0961803 (* 1 = 0.0961803 loss)
I0829 21:25:34.357108 916722 sgd_solver.cpp:106] Iteration 717000, lr = 0.01
I0829 21:26:04.365417 916722 solver.cpp:218] Iteration 717500 (16.6621 iter/s, 30.0083s/500 iters), loss = 0.0714038
I0829 21:26:04.365473 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0714117 (* 1 = 0.0714117 loss)
I0829 21:26:04.365480 916722 sgd_solver.cpp:106] Iteration 717500, lr = 0.01
I0829 21:26:34.387631 916722 solver.cpp:218] Iteration 718000 (16.6544 iter/s, 30.0221s/500 iters), loss = 0.0580046
I0829 21:26:34.387688 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0580126 (* 1 = 0.0580126 loss)
I0829 21:26:34.387696 916722 sgd_solver.cpp:106] Iteration 718000, lr = 0.01
I0829 21:27:04.414685 916722 solver.cpp:218] Iteration 718500 (16.6517 iter/s, 30.027s/500 iters), loss = 0.201254
I0829 21:27:04.414738 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.201262 (* 1 = 0.201262 loss)
I0829 21:27:04.414746 916722 sgd_solver.cpp:106] Iteration 718500, lr = 0.01
I0829 21:27:34.451367 916722 solver.cpp:218] Iteration 719000 (16.6464 iter/s, 30.0366s/500 iters), loss = 0.214422
I0829 21:27:34.451424 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.21443 (* 1 = 0.21443 loss)
I0829 21:27:34.451432 916722 sgd_solver.cpp:106] Iteration 719000, lr = 0.01
I0829 21:28:04.476164 916722 solver.cpp:218] Iteration 719500 (16.6529 iter/s, 30.0247s/500 iters), loss = 0.269141
I0829 21:28:04.476217 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.269149 (* 1 = 0.269149 loss)
I0829 21:28:04.476225 916722 sgd_solver.cpp:106] Iteration 719500, lr = 0.01
I0829 21:28:34.491621 916722 solver.cpp:218] Iteration 720000 (16.6581 iter/s, 30.0154s/500 iters), loss = 0.245234
I0829 21:28:34.491677 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.245242 (* 1 = 0.245242 loss)
I0829 21:28:34.491686 916722 sgd_solver.cpp:106] Iteration 720000, lr = 0.01
I0829 21:29:04.530050 916722 solver.cpp:218] Iteration 720500 (16.6454 iter/s, 30.0383s/500 iters), loss = 0.456823
I0829 21:29:04.530102 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.456831 (* 1 = 0.456831 loss)
I0829 21:29:04.530109 916722 sgd_solver.cpp:106] Iteration 720500, lr = 0.01
I0829 21:29:34.578194 916722 solver.cpp:218] Iteration 721000 (16.64 iter/s, 30.0481s/500 iters), loss = 0.165817
I0829 21:29:34.578249 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.165825 (* 1 = 0.165825 loss)
I0829 21:29:34.578258 916722 sgd_solver.cpp:106] Iteration 721000, lr = 0.01
I0829 21:30:04.609594 916722 solver.cpp:218] Iteration 721500 (16.6493 iter/s, 30.0313s/500 iters), loss = 0.0461548
I0829 21:30:04.609663 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0461629 (* 1 = 0.0461629 loss)
I0829 21:30:04.609673 916722 sgd_solver.cpp:106] Iteration 721500, lr = 0.01
I0829 21:30:34.628813 916722 solver.cpp:218] Iteration 722000 (16.6561 iter/s, 30.0191s/500 iters), loss = 0.321772
I0829 21:30:34.628866 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.32178 (* 1 = 0.32178 loss)
I0829 21:30:34.628875 916722 sgd_solver.cpp:106] Iteration 722000, lr = 0.01
I0829 21:31:04.629058 916722 solver.cpp:218] Iteration 722500 (16.6666 iter/s, 30.0002s/500 iters), loss = 0.0578552
I0829 21:31:04.629112 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0578632 (* 1 = 0.0578632 loss)
I0829 21:31:04.629119 916722 sgd_solver.cpp:106] Iteration 722500, lr = 0.01
I0829 21:31:34.636356 916722 solver.cpp:218] Iteration 723000 (16.6627 iter/s, 30.0072s/500 iters), loss = 0.108805
I0829 21:31:34.636413 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.108813 (* 1 = 0.108813 loss)
I0829 21:31:34.636421 916722 sgd_solver.cpp:106] Iteration 723000, lr = 0.01
I0829 21:32:04.654204 916722 solver.cpp:218] Iteration 723500 (16.6568 iter/s, 30.0178s/500 iters), loss = 0.125739
I0829 21:32:04.654258 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.125748 (* 1 = 0.125748 loss)
I0829 21:32:04.654265 916722 sgd_solver.cpp:106] Iteration 723500, lr = 0.01
I0829 21:32:34.676095 916722 solver.cpp:218] Iteration 724000 (16.6546 iter/s, 30.0218s/500 iters), loss = 0.401945
I0829 21:32:34.676149 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.401953 (* 1 = 0.401953 loss)
I0829 21:32:34.676157 916722 sgd_solver.cpp:106] Iteration 724000, lr = 0.01
I0829 21:33:04.696583 916722 solver.cpp:218] Iteration 724500 (16.6553 iter/s, 30.0204s/500 iters), loss = 0.258874
I0829 21:33:04.696640 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.258882 (* 1 = 0.258882 loss)
I0829 21:33:04.696648 916722 sgd_solver.cpp:106] Iteration 724500, lr = 0.01
I0829 21:33:34.704316 916722 solver.cpp:218] Iteration 725000 (16.6624 iter/s, 30.0076s/500 iters), loss = 0.18323
I0829 21:33:34.704370 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.183238 (* 1 = 0.183238 loss)
I0829 21:33:34.704380 916722 sgd_solver.cpp:106] Iteration 725000, lr = 0.01
I0829 21:34:04.695230 916722 solver.cpp:218] Iteration 725500 (16.6718 iter/s, 29.9908s/500 iters), loss = 0.100942
I0829 21:34:04.695279 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.10095 (* 1 = 0.10095 loss)
I0829 21:34:04.695288 916722 sgd_solver.cpp:106] Iteration 725500, lr = 0.01
I0829 21:34:34.690788 916722 solver.cpp:218] Iteration 726000 (16.6692 iter/s, 29.9955s/500 iters), loss = 0.1833
I0829 21:34:34.690842 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.183308 (* 1 = 0.183308 loss)
I0829 21:34:34.690850 916722 sgd_solver.cpp:106] Iteration 726000, lr = 0.01
I0829 21:35:04.694017 916722 solver.cpp:218] Iteration 726500 (16.6649 iter/s, 30.0031s/500 iters), loss = 0.065318
I0829 21:35:04.694068 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0653261 (* 1 = 0.0653261 loss)
I0829 21:35:04.694077 916722 sgd_solver.cpp:106] Iteration 726500, lr = 0.01
I0829 21:35:34.694888 916722 solver.cpp:218] Iteration 727000 (16.6662 iter/s, 30.0008s/500 iters), loss = 0.170556
I0829 21:35:34.694942 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.170564 (* 1 = 0.170564 loss)
I0829 21:35:34.694952 916722 sgd_solver.cpp:106] Iteration 727000, lr = 0.01
I0829 21:36:04.725083 916722 solver.cpp:218] Iteration 727500 (16.65 iter/s, 30.0301s/500 iters), loss = 0.286951
I0829 21:36:04.725133 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.286959 (* 1 = 0.286959 loss)
I0829 21:36:04.725142 916722 sgd_solver.cpp:106] Iteration 727500, lr = 0.01
I0829 21:36:34.748649 916722 solver.cpp:218] Iteration 728000 (16.6536 iter/s, 30.0235s/500 iters), loss = 0.280609
I0829 21:36:34.748721 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.280617 (* 1 = 0.280617 loss)
I0829 21:36:34.748729 916722 sgd_solver.cpp:106] Iteration 728000, lr = 0.01
I0829 21:37:04.757920 916722 solver.cpp:218] Iteration 728500 (16.6616 iter/s, 30.0092s/500 iters), loss = 0.298523
I0829 21:37:04.757973 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.298532 (* 1 = 0.298532 loss)
I0829 21:37:04.757982 916722 sgd_solver.cpp:106] Iteration 728500, lr = 0.01
I0829 21:37:34.757721 916722 solver.cpp:218] Iteration 729000 (16.6668 iter/s, 29.9997s/500 iters), loss = 0.401613
I0829 21:37:34.757771 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.401621 (* 1 = 0.401621 loss)
I0829 21:37:34.757781 916722 sgd_solver.cpp:106] Iteration 729000, lr = 0.01
I0829 21:38:04.783214 916722 solver.cpp:218] Iteration 729500 (16.6526 iter/s, 30.0254s/500 iters), loss = 0.136551
I0829 21:38:04.783272 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13656 (* 1 = 0.13656 loss)
I0829 21:38:04.783279 916722 sgd_solver.cpp:106] Iteration 729500, lr = 0.01
I0829 21:38:34.787387 916722 solver.cpp:218] Iteration 730000 (16.6644 iter/s, 30.0041s/500 iters), loss = 0.389831
I0829 21:38:34.787442 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.389839 (* 1 = 0.389839 loss)
I0829 21:38:34.787451 916722 sgd_solver.cpp:106] Iteration 730000, lr = 0.01
I0829 21:39:04.808291 916722 solver.cpp:218] Iteration 730500 (16.6551 iter/s, 30.0208s/500 iters), loss = 0.250926
I0829 21:39:04.808346 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.250934 (* 1 = 0.250934 loss)
I0829 21:39:04.808354 916722 sgd_solver.cpp:106] Iteration 730500, lr = 0.01
I0829 21:39:34.818583 916722 solver.cpp:218] Iteration 731000 (16.661 iter/s, 30.0102s/500 iters), loss = 0.218116
I0829 21:39:34.818636 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.218124 (* 1 = 0.218124 loss)
I0829 21:39:34.818645 916722 sgd_solver.cpp:106] Iteration 731000, lr = 0.01
I0829 21:40:04.823716 916722 solver.cpp:218] Iteration 731500 (16.6639 iter/s, 30.005s/500 iters), loss = 0.231822
I0829 21:40:04.823769 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.23183 (* 1 = 0.23183 loss)
I0829 21:40:04.823777 916722 sgd_solver.cpp:106] Iteration 731500, lr = 0.01
I0829 21:40:34.849644 916722 solver.cpp:218] Iteration 732000 (16.6523 iter/s, 30.0258s/500 iters), loss = 0.132927
I0829 21:40:34.849695 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.132935 (* 1 = 0.132935 loss)
I0829 21:40:34.849704 916722 sgd_solver.cpp:106] Iteration 732000, lr = 0.01
I0829 21:41:04.850749 916722 solver.cpp:218] Iteration 732500 (16.6661 iter/s, 30.001s/500 iters), loss = 0.0494637
I0829 21:41:04.850805 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0494715 (* 1 = 0.0494715 loss)
I0829 21:41:04.850812 916722 sgd_solver.cpp:106] Iteration 732500, lr = 0.01
I0829 21:41:34.847992 916722 solver.cpp:218] Iteration 733000 (16.6683 iter/s, 29.9971s/500 iters), loss = 0.247189
I0829 21:41:34.848039 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.247196 (* 1 = 0.247196 loss)
I0829 21:41:34.848049 916722 sgd_solver.cpp:106] Iteration 733000, lr = 0.01
I0829 21:42:04.836961 916722 solver.cpp:218] Iteration 733500 (16.6728 iter/s, 29.9889s/500 iters), loss = 0.0859369
I0829 21:42:04.837019 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0859446 (* 1 = 0.0859446 loss)
I0829 21:42:04.837028 916722 sgd_solver.cpp:106] Iteration 733500, lr = 0.01
I0829 21:42:34.836340 916722 solver.cpp:218] Iteration 734000 (16.6671 iter/s, 29.9993s/500 iters), loss = 0.0601075
I0829 21:42:34.836391 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0601153 (* 1 = 0.0601153 loss)
I0829 21:42:34.836401 916722 sgd_solver.cpp:106] Iteration 734000, lr = 0.01
I0829 21:43:04.840288 916722 solver.cpp:218] Iteration 734500 (16.6645 iter/s, 30.0038s/500 iters), loss = 0.0747929
I0829 21:43:04.840353 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0748008 (* 1 = 0.0748008 loss)
I0829 21:43:04.840365 916722 sgd_solver.cpp:106] Iteration 734500, lr = 0.01
I0829 21:43:34.826388 916722 solver.cpp:218] Iteration 735000 (16.6745 iter/s, 29.986s/500 iters), loss = 0.157168
I0829 21:43:34.826439 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.157176 (* 1 = 0.157176 loss)
I0829 21:43:34.826449 916722 sgd_solver.cpp:106] Iteration 735000, lr = 0.01
I0829 21:44:04.831362 916722 solver.cpp:218] Iteration 735500 (16.664 iter/s, 30.0049s/500 iters), loss = 0.330229
I0829 21:44:04.831415 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.330237 (* 1 = 0.330237 loss)
I0829 21:44:04.831424 916722 sgd_solver.cpp:106] Iteration 735500, lr = 0.01
I0829 21:44:34.809949 916722 solver.cpp:218] Iteration 736000 (16.6786 iter/s, 29.9785s/500 iters), loss = 0.105116
I0829 21:44:34.809998 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105123 (* 1 = 0.105123 loss)
I0829 21:44:34.810007 916722 sgd_solver.cpp:106] Iteration 736000, lr = 0.01
I0829 21:45:04.789701 916722 solver.cpp:218] Iteration 736500 (16.678 iter/s, 29.9797s/500 iters), loss = 0.263635
I0829 21:45:04.789753 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.263643 (* 1 = 0.263643 loss)
I0829 21:45:04.789762 916722 sgd_solver.cpp:106] Iteration 736500, lr = 0.01
I0829 21:45:34.785490 916722 solver.cpp:218] Iteration 737000 (16.6691 iter/s, 29.9957s/500 iters), loss = 0.204493
I0829 21:45:34.785538 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.204501 (* 1 = 0.204501 loss)
I0829 21:45:34.785548 916722 sgd_solver.cpp:106] Iteration 737000, lr = 0.01
I0829 21:46:04.777284 916722 solver.cpp:218] Iteration 737500 (16.6713 iter/s, 29.9917s/500 iters), loss = 0.127202
I0829 21:46:04.777340 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.127209 (* 1 = 0.127209 loss)
I0829 21:46:04.777348 916722 sgd_solver.cpp:106] Iteration 737500, lr = 0.01
I0829 21:46:34.775305 916722 solver.cpp:218] Iteration 738000 (16.6678 iter/s, 29.9979s/500 iters), loss = 0.176813
I0829 21:46:34.775353 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.17682 (* 1 = 0.17682 loss)
I0829 21:46:34.775363 916722 sgd_solver.cpp:106] Iteration 738000, lr = 0.01
I0829 21:47:04.763778 916722 solver.cpp:218] Iteration 738500 (16.6731 iter/s, 29.9884s/500 iters), loss = 0.348532
I0829 21:47:04.763836 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.34854 (* 1 = 0.34854 loss)
I0829 21:47:04.763845 916722 sgd_solver.cpp:106] Iteration 738500, lr = 0.01
I0829 21:47:34.750000 916722 solver.cpp:218] Iteration 739000 (16.6744 iter/s, 29.9861s/500 iters), loss = 0.0362495
I0829 21:47:34.750051 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0362572 (* 1 = 0.0362572 loss)
I0829 21:47:34.750059 916722 sgd_solver.cpp:106] Iteration 739000, lr = 0.01
I0829 21:48:04.723167 916722 solver.cpp:218] Iteration 739500 (16.6816 iter/s, 29.9731s/500 iters), loss = 0.0798125
I0829 21:48:04.723224 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0798203 (* 1 = 0.0798203 loss)
I0829 21:48:04.723233 916722 sgd_solver.cpp:106] Iteration 739500, lr = 0.01
I0829 21:48:34.723330 916722 solver.cpp:218] Iteration 740000 (16.6666 iter/s, 30.0001s/500 iters), loss = 0.147097
I0829 21:48:34.723383 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.147104 (* 1 = 0.147104 loss)
I0829 21:48:34.723392 916722 sgd_solver.cpp:106] Iteration 740000, lr = 0.01
I0829 21:49:04.706687 916722 solver.cpp:218] Iteration 740500 (16.676 iter/s, 29.9833s/500 iters), loss = 0.364287
I0829 21:49:04.706732 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.364294 (* 1 = 0.364294 loss)
I0829 21:49:04.706743 916722 sgd_solver.cpp:106] Iteration 740500, lr = 0.01
I0829 21:49:34.688212 916722 solver.cpp:218] Iteration 741000 (16.677 iter/s, 29.9814s/500 iters), loss = 0.333542
I0829 21:49:34.688282 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.33355 (* 1 = 0.33355 loss)
I0829 21:49:34.688290 916722 sgd_solver.cpp:106] Iteration 741000, lr = 0.01
I0829 21:50:04.660687 916722 solver.cpp:218] Iteration 741500 (16.682 iter/s, 29.9724s/500 iters), loss = 0.0542122
I0829 21:50:04.660737 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.05422 (* 1 = 0.05422 loss)
I0829 21:50:04.660746 916722 sgd_solver.cpp:106] Iteration 741500, lr = 0.01
I0829 21:50:34.663894 916722 solver.cpp:218] Iteration 742000 (16.6649 iter/s, 30.0031s/500 iters), loss = 0.0873242
I0829 21:50:34.663949 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.087332 (* 1 = 0.087332 loss)
I0829 21:50:34.663957 916722 sgd_solver.cpp:106] Iteration 742000, lr = 0.01
I0829 21:51:04.628823 916722 solver.cpp:218] Iteration 742500 (16.6862 iter/s, 29.9648s/500 iters), loss = 0.297643
I0829 21:51:04.628868 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.297651 (* 1 = 0.297651 loss)
I0829 21:51:04.628878 916722 sgd_solver.cpp:106] Iteration 742500, lr = 0.01
I0829 21:51:34.616138 916722 solver.cpp:218] Iteration 743000 (16.6738 iter/s, 29.9872s/500 iters), loss = 0.138645
I0829 21:51:34.616191 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.138652 (* 1 = 0.138652 loss)
I0829 21:51:34.616200 916722 sgd_solver.cpp:106] Iteration 743000, lr = 0.01
I0829 21:52:04.602722 916722 solver.cpp:218] Iteration 743500 (16.6742 iter/s, 29.9865s/500 iters), loss = 0.241154
I0829 21:52:04.602769 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.241161 (* 1 = 0.241161 loss)
I0829 21:52:04.602779 916722 sgd_solver.cpp:106] Iteration 743500, lr = 0.01
I0829 21:52:34.584224 916722 solver.cpp:218] Iteration 744000 (16.677 iter/s, 29.9814s/500 iters), loss = 0.0559845
I0829 21:52:34.584282 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.055992 (* 1 = 0.055992 loss)
I0829 21:52:34.584290 916722 sgd_solver.cpp:106] Iteration 744000, lr = 0.01
I0829 21:53:04.558466 916722 solver.cpp:218] Iteration 744500 (16.6811 iter/s, 29.9741s/500 iters), loss = 0.248544
I0829 21:53:04.558512 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.248552 (* 1 = 0.248552 loss)
I0829 21:53:04.558521 916722 sgd_solver.cpp:106] Iteration 744500, lr = 0.01
I0829 21:53:34.528106 916722 solver.cpp:218] Iteration 745000 (16.6836 iter/s, 29.9695s/500 iters), loss = 0.297144
I0829 21:53:34.528163 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.297152 (* 1 = 0.297152 loss)
I0829 21:53:34.528172 916722 sgd_solver.cpp:106] Iteration 745000, lr = 0.01
I0829 21:54:04.502543 916722 solver.cpp:218] Iteration 745500 (16.6809 iter/s, 29.9743s/500 iters), loss = 0.220606
I0829 21:54:04.502589 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.220614 (* 1 = 0.220614 loss)
I0829 21:54:04.502597 916722 sgd_solver.cpp:106] Iteration 745500, lr = 0.01
I0829 21:54:34.480502 916722 solver.cpp:218] Iteration 746000 (16.6789 iter/s, 29.9779s/500 iters), loss = 0.235126
I0829 21:54:34.480561 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.235134 (* 1 = 0.235134 loss)
I0829 21:54:34.480569 916722 sgd_solver.cpp:106] Iteration 746000, lr = 0.01
I0829 21:55:04.468782 916722 solver.cpp:218] Iteration 746500 (16.6732 iter/s, 29.9882s/500 iters), loss = 0.268107
I0829 21:55:04.468828 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.268115 (* 1 = 0.268115 loss)
I0829 21:55:04.468837 916722 sgd_solver.cpp:106] Iteration 746500, lr = 0.01
I0829 21:55:34.434633 916722 solver.cpp:218] Iteration 747000 (16.6857 iter/s, 29.9658s/500 iters), loss = 0.0430186
I0829 21:55:34.434689 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0430264 (* 1 = 0.0430264 loss)
I0829 21:55:34.434697 916722 sgd_solver.cpp:106] Iteration 747000, lr = 0.01
I0829 21:56:04.409538 916722 solver.cpp:218] Iteration 747500 (16.6807 iter/s, 29.9748s/500 iters), loss = 0.172058
I0829 21:56:04.409585 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.172066 (* 1 = 0.172066 loss)
I0829 21:56:04.409593 916722 sgd_solver.cpp:106] Iteration 747500, lr = 0.01
I0829 21:56:34.373356 916722 solver.cpp:218] Iteration 748000 (16.6868 iter/s, 29.9638s/500 iters), loss = 0.113388
I0829 21:56:34.373433 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.113395 (* 1 = 0.113395 loss)
I0829 21:56:34.373442 916722 sgd_solver.cpp:106] Iteration 748000, lr = 0.01
I0829 21:57:04.366845 916722 solver.cpp:218] Iteration 748500 (16.6703 iter/s, 29.9934s/500 iters), loss = 0.0738016
I0829 21:57:04.366890 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0738096 (* 1 = 0.0738096 loss)
I0829 21:57:04.366899 916722 sgd_solver.cpp:106] Iteration 748500, lr = 0.01
I0829 21:57:34.340910 916722 solver.cpp:218] Iteration 749000 (16.6811 iter/s, 29.974s/500 iters), loss = 0.313398
I0829 21:57:34.340966 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.313406 (* 1 = 0.313406 loss)
I0829 21:57:34.340974 916722 sgd_solver.cpp:106] Iteration 749000, lr = 0.01
I0829 21:58:04.302721 916722 solver.cpp:218] Iteration 749500 (16.688 iter/s, 29.9617s/500 iters), loss = 0.212969
I0829 21:58:04.302773 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.212977 (* 1 = 0.212977 loss)
I0829 21:58:04.302783 916722 sgd_solver.cpp:106] Iteration 749500, lr = 0.01
I0829 21:58:34.220645 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_750000.caffemodel
I0829 21:58:34.239881 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_750000.solverstate
I0829 21:58:34.246098 916722 solver.cpp:330] Iteration 750000, Testing net (#0)
I0829 21:58:49.682708 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8965
I0829 21:58:49.682755 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.340103 (* 1 = 0.340103 loss)
I0829 21:58:49.741428 916722 solver.cpp:218] Iteration 750000 (11.0039 iter/s, 45.4386s/500 iters), loss = 0.177519
I0829 21:58:49.741456 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.177527 (* 1 = 0.177527 loss)
I0829 21:58:49.741464 916722 sgd_solver.cpp:106] Iteration 750000, lr = 0.01
I0829 21:59:19.574641 916722 solver.cpp:218] Iteration 750500 (16.7599 iter/s, 29.8331s/500 iters), loss = 0.0788544
I0829 21:59:19.574700 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0788622 (* 1 = 0.0788622 loss)
I0829 21:59:19.574709 916722 sgd_solver.cpp:106] Iteration 750500, lr = 0.01
I0829 21:59:49.542632 916722 solver.cpp:218] Iteration 751000 (16.6845 iter/s, 29.9679s/500 iters), loss = 0.112257
I0829 21:59:49.542685 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112265 (* 1 = 0.112265 loss)
I0829 21:59:49.542694 916722 sgd_solver.cpp:106] Iteration 751000, lr = 0.01
I0829 22:00:19.510674 916722 solver.cpp:218] Iteration 751500 (16.6845 iter/s, 29.968s/500 iters), loss = 0.236813
I0829 22:00:19.510730 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.236821 (* 1 = 0.236821 loss)
I0829 22:00:19.510740 916722 sgd_solver.cpp:106] Iteration 751500, lr = 0.01
I0829 22:00:49.489405 916722 solver.cpp:218] Iteration 752000 (16.6785 iter/s, 29.9787s/500 iters), loss = 0.183468
I0829 22:00:49.489455 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.183476 (* 1 = 0.183476 loss)
I0829 22:00:49.489464 916722 sgd_solver.cpp:106] Iteration 752000, lr = 0.01
I0829 22:01:19.463150 916722 solver.cpp:218] Iteration 752500 (16.6813 iter/s, 29.9737s/500 iters), loss = 0.0190066
I0829 22:01:19.463204 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0190145 (* 1 = 0.0190145 loss)
I0829 22:01:19.463212 916722 sgd_solver.cpp:106] Iteration 752500, lr = 0.01
I0829 22:01:49.476436 916722 solver.cpp:218] Iteration 753000 (16.6593 iter/s, 30.0132s/500 iters), loss = 0.095484
I0829 22:01:49.476495 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0954918 (* 1 = 0.0954918 loss)
I0829 22:01:49.476503 916722 sgd_solver.cpp:106] Iteration 753000, lr = 0.01
I0829 22:02:19.508795 916722 solver.cpp:218] Iteration 753500 (16.6488 iter/s, 30.0323s/500 iters), loss = 0.0769534
I0829 22:02:19.508857 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0769614 (* 1 = 0.0769614 loss)
I0829 22:02:19.508869 916722 sgd_solver.cpp:106] Iteration 753500, lr = 0.01
I0829 22:02:49.538439 916722 solver.cpp:218] Iteration 754000 (16.6503 iter/s, 30.0296s/500 iters), loss = 0.211659
I0829 22:02:49.538493 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.211667 (* 1 = 0.211667 loss)
I0829 22:02:49.538501 916722 sgd_solver.cpp:106] Iteration 754000, lr = 0.01
I0829 22:03:19.529927 916722 solver.cpp:218] Iteration 754500 (16.6714 iter/s, 29.9914s/500 iters), loss = 0.211899
I0829 22:03:19.529971 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.211907 (* 1 = 0.211907 loss)
I0829 22:03:19.529983 916722 sgd_solver.cpp:106] Iteration 754500, lr = 0.01
I0829 22:03:49.526535 916722 solver.cpp:218] Iteration 755000 (16.6686 iter/s, 29.9965s/500 iters), loss = 0.224995
I0829 22:03:49.526589 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.225003 (* 1 = 0.225003 loss)
I0829 22:03:49.526598 916722 sgd_solver.cpp:106] Iteration 755000, lr = 0.01
I0829 22:04:19.532927 916722 solver.cpp:218] Iteration 755500 (16.6632 iter/s, 30.0063s/500 iters), loss = 0.232947
I0829 22:04:19.532981 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.232955 (* 1 = 0.232955 loss)
I0829 22:04:19.532990 916722 sgd_solver.cpp:106] Iteration 755500, lr = 0.01
I0829 22:04:49.528458 916722 solver.cpp:218] Iteration 756000 (16.6692 iter/s, 29.9954s/500 iters), loss = 0.243936
I0829 22:04:49.528508 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.243944 (* 1 = 0.243944 loss)
I0829 22:04:49.528518 916722 sgd_solver.cpp:106] Iteration 756000, lr = 0.01
I0829 22:05:19.516563 916722 solver.cpp:218] Iteration 756500 (16.6733 iter/s, 29.988s/500 iters), loss = 0.151439
I0829 22:05:19.516618 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.151447 (* 1 = 0.151447 loss)
I0829 22:05:19.516628 916722 sgd_solver.cpp:106] Iteration 756500, lr = 0.01
I0829 22:05:49.488075 916722 solver.cpp:218] Iteration 757000 (16.6826 iter/s, 29.9714s/500 iters), loss = 0.0818246
I0829 22:05:49.488127 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0818324 (* 1 = 0.0818324 loss)
I0829 22:05:49.488137 916722 sgd_solver.cpp:106] Iteration 757000, lr = 0.01
I0829 22:06:19.463701 916722 solver.cpp:218] Iteration 757500 (16.6803 iter/s, 29.9755s/500 iters), loss = 0.236252
I0829 22:06:19.463753 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.236259 (* 1 = 0.236259 loss)
I0829 22:06:19.463762 916722 sgd_solver.cpp:106] Iteration 757500, lr = 0.01
I0829 22:06:49.455106 916722 solver.cpp:218] Iteration 758000 (16.6715 iter/s, 29.9913s/500 iters), loss = 0.118762
I0829 22:06:49.455158 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.11877 (* 1 = 0.11877 loss)
I0829 22:06:49.455168 916722 sgd_solver.cpp:106] Iteration 758000, lr = 0.01
I0829 22:07:19.440379 916722 solver.cpp:218] Iteration 758500 (16.6749 iter/s, 29.9852s/500 iters), loss = 0.0858354
I0829 22:07:19.440455 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.085843 (* 1 = 0.085843 loss)
I0829 22:07:19.440464 916722 sgd_solver.cpp:106] Iteration 758500, lr = 0.01
I0829 22:07:49.420686 916722 solver.cpp:218] Iteration 759000 (16.6777 iter/s, 29.9802s/500 iters), loss = 0.238879
I0829 22:07:49.420738 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.238887 (* 1 = 0.238887 loss)
I0829 22:07:49.420748 916722 sgd_solver.cpp:106] Iteration 759000, lr = 0.01
I0829 22:08:19.414788 916722 solver.cpp:218] Iteration 759500 (16.67 iter/s, 29.994s/500 iters), loss = 0.134069
I0829 22:08:19.414847 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.134077 (* 1 = 0.134077 loss)
I0829 22:08:19.414855 916722 sgd_solver.cpp:106] Iteration 759500, lr = 0.01
I0829 22:08:49.402364 916722 solver.cpp:218] Iteration 760000 (16.6736 iter/s, 29.9875s/500 iters), loss = 0.302703
I0829 22:08:49.402416 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.302711 (* 1 = 0.302711 loss)
I0829 22:08:49.402438 916722 sgd_solver.cpp:106] Iteration 760000, lr = 0.01
I0829 22:09:19.378216 916722 solver.cpp:218] Iteration 760500 (16.6801 iter/s, 29.9758s/500 iters), loss = 0.198232
I0829 22:09:19.378280 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.19824 (* 1 = 0.19824 loss)
I0829 22:09:19.378288 916722 sgd_solver.cpp:106] Iteration 760500, lr = 0.01
I0829 22:09:49.351181 916722 solver.cpp:218] Iteration 761000 (16.6818 iter/s, 29.9729s/500 iters), loss = 0.0378127
I0829 22:09:49.351230 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0378206 (* 1 = 0.0378206 loss)
I0829 22:09:49.351240 916722 sgd_solver.cpp:106] Iteration 761000, lr = 0.01
I0829 22:10:19.335784 916722 solver.cpp:218] Iteration 761500 (16.6753 iter/s, 29.9845s/500 iters), loss = 0.164922
I0829 22:10:19.335848 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.16493 (* 1 = 0.16493 loss)
I0829 22:10:19.335857 916722 sgd_solver.cpp:106] Iteration 761500, lr = 0.01
I0829 22:10:49.311657 916722 solver.cpp:218] Iteration 762000 (16.6801 iter/s, 29.9758s/500 iters), loss = 0.343068
I0829 22:10:49.311710 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.343076 (* 1 = 0.343076 loss)
I0829 22:10:49.311718 916722 sgd_solver.cpp:106] Iteration 762000, lr = 0.01
I0829 22:11:19.283586 916722 solver.cpp:218] Iteration 762500 (16.6823 iter/s, 29.9718s/500 iters), loss = 0.041171
I0829 22:11:19.283645 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0411786 (* 1 = 0.0411786 loss)
I0829 22:11:19.283653 916722 sgd_solver.cpp:106] Iteration 762500, lr = 0.01
I0829 22:11:49.257759 916722 solver.cpp:218] Iteration 763000 (16.6811 iter/s, 29.9741s/500 iters), loss = 0.14194
I0829 22:11:49.257810 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.141948 (* 1 = 0.141948 loss)
I0829 22:11:49.257819 916722 sgd_solver.cpp:106] Iteration 763000, lr = 0.01
I0829 22:12:19.239003 916722 solver.cpp:218] Iteration 763500 (16.6771 iter/s, 29.9812s/500 iters), loss = 0.199113
I0829 22:12:19.239061 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.19912 (* 1 = 0.19912 loss)
I0829 22:12:19.239069 916722 sgd_solver.cpp:106] Iteration 763500, lr = 0.01
I0829 22:12:49.217146 916722 solver.cpp:218] Iteration 764000 (16.6789 iter/s, 29.978s/500 iters), loss = 0.0914101
I0829 22:12:49.217196 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0914176 (* 1 = 0.0914176 loss)
I0829 22:12:49.217206 916722 sgd_solver.cpp:106] Iteration 764000, lr = 0.01
I0829 22:13:19.191769 916722 solver.cpp:218] Iteration 764500 (16.6808 iter/s, 29.9745s/500 iters), loss = 0.107783
I0829 22:13:19.191824 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.107791 (* 1 = 0.107791 loss)
I0829 22:13:19.191833 916722 sgd_solver.cpp:106] Iteration 764500, lr = 0.01
I0829 22:13:49.162699 916722 solver.cpp:218] Iteration 765000 (16.6829 iter/s, 29.9708s/500 iters), loss = 0.155784
I0829 22:13:49.162750 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.155791 (* 1 = 0.155791 loss)
I0829 22:13:49.162760 916722 sgd_solver.cpp:106] Iteration 765000, lr = 0.01
I0829 22:14:19.130594 916722 solver.cpp:218] Iteration 765500 (16.6846 iter/s, 29.9678s/500 iters), loss = 0.0695209
I0829 22:14:19.130651 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0695284 (* 1 = 0.0695284 loss)
I0829 22:14:19.130659 916722 sgd_solver.cpp:106] Iteration 765500, lr = 0.01
I0829 22:14:49.078686 916722 solver.cpp:218] Iteration 766000 (16.6956 iter/s, 29.948s/500 iters), loss = 0.117387
I0829 22:14:49.078738 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.117395 (* 1 = 0.117395 loss)
I0829 22:14:49.078747 916722 sgd_solver.cpp:106] Iteration 766000, lr = 0.01
I0829 22:15:19.027968 916722 solver.cpp:218] Iteration 766500 (16.6949 iter/s, 29.9492s/500 iters), loss = 0.160779
I0829 22:15:19.028028 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.160786 (* 1 = 0.160786 loss)
I0829 22:15:19.028035 916722 sgd_solver.cpp:106] Iteration 766500, lr = 0.01
I0829 22:15:48.987242 916722 solver.cpp:218] Iteration 767000 (16.6894 iter/s, 29.9592s/500 iters), loss = 0.159485
I0829 22:15:48.987295 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159493 (* 1 = 0.159493 loss)
I0829 22:15:48.987305 916722 sgd_solver.cpp:106] Iteration 767000, lr = 0.01
I0829 22:16:18.948066 916722 solver.cpp:218] Iteration 767500 (16.6885 iter/s, 29.9607s/500 iters), loss = 0.0493407
I0829 22:16:18.948130 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0493484 (* 1 = 0.0493484 loss)
I0829 22:16:18.948139 916722 sgd_solver.cpp:106] Iteration 767500, lr = 0.01
I0829 22:16:48.927326 916722 solver.cpp:218] Iteration 768000 (16.6783 iter/s, 29.9792s/500 iters), loss = 0.121839
I0829 22:16:48.927376 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.121847 (* 1 = 0.121847 loss)
I0829 22:16:48.927385 916722 sgd_solver.cpp:106] Iteration 768000, lr = 0.01
I0829 22:17:18.892927 916722 solver.cpp:218] Iteration 768500 (16.6859 iter/s, 29.9655s/500 iters), loss = 0.13825
I0829 22:17:18.892980 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.138258 (* 1 = 0.138258 loss)
I0829 22:17:18.892988 916722 sgd_solver.cpp:106] Iteration 768500, lr = 0.01
I0829 22:17:48.877280 916722 solver.cpp:218] Iteration 769000 (16.6754 iter/s, 29.9843s/500 iters), loss = 0.118877
I0829 22:17:48.877332 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.118885 (* 1 = 0.118885 loss)
I0829 22:17:48.877342 916722 sgd_solver.cpp:106] Iteration 769000, lr = 0.01
I0829 22:18:18.847005 916722 solver.cpp:218] Iteration 769500 (16.6836 iter/s, 29.9696s/500 iters), loss = 0.110355
I0829 22:18:18.847061 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110363 (* 1 = 0.110363 loss)
I0829 22:18:18.847069 916722 sgd_solver.cpp:106] Iteration 769500, lr = 0.01
I0829 22:18:48.812265 916722 solver.cpp:218] Iteration 770000 (16.686 iter/s, 29.9652s/500 iters), loss = 0.169764
I0829 22:18:48.812316 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.169772 (* 1 = 0.169772 loss)
I0829 22:18:48.812326 916722 sgd_solver.cpp:106] Iteration 770000, lr = 0.01
I0829 22:19:18.789675 916722 solver.cpp:218] Iteration 770500 (16.6793 iter/s, 29.9773s/500 iters), loss = 0.11415
I0829 22:19:18.789731 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.114158 (* 1 = 0.114158 loss)
I0829 22:19:18.789741 916722 sgd_solver.cpp:106] Iteration 770500, lr = 0.01
I0829 22:19:48.755304 916722 solver.cpp:218] Iteration 771000 (16.6858 iter/s, 29.9655s/500 iters), loss = 0.32531
I0829 22:19:48.755355 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.325318 (* 1 = 0.325318 loss)
I0829 22:19:48.755365 916722 sgd_solver.cpp:106] Iteration 771000, lr = 0.01
I0829 22:20:18.708487 916722 solver.cpp:218] Iteration 771500 (16.6928 iter/s, 29.9531s/500 iters), loss = 0.108845
I0829 22:20:18.708544 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.108853 (* 1 = 0.108853 loss)
I0829 22:20:18.708552 916722 sgd_solver.cpp:106] Iteration 771500, lr = 0.01
I0829 22:20:48.690021 916722 solver.cpp:218] Iteration 772000 (16.677 iter/s, 29.9814s/500 iters), loss = 0.0552045
I0829 22:20:48.690069 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0552127 (* 1 = 0.0552127 loss)
I0829 22:20:48.690078 916722 sgd_solver.cpp:106] Iteration 772000, lr = 0.01
I0829 22:21:18.663668 916722 solver.cpp:218] Iteration 772500 (16.6814 iter/s, 29.9736s/500 iters), loss = 0.0544026
I0829 22:21:18.663723 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0544107 (* 1 = 0.0544107 loss)
I0829 22:21:18.663733 916722 sgd_solver.cpp:106] Iteration 772500, lr = 0.01
I0829 22:21:48.632490 916722 solver.cpp:218] Iteration 773000 (16.6841 iter/s, 29.9687s/500 iters), loss = 0.220896
I0829 22:21:48.632541 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.220904 (* 1 = 0.220904 loss)
I0829 22:21:48.632550 916722 sgd_solver.cpp:106] Iteration 773000, lr = 0.01
I0829 22:22:18.598343 916722 solver.cpp:218] Iteration 773500 (16.6857 iter/s, 29.9658s/500 iters), loss = 0.0736376
I0829 22:22:18.598414 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0736456 (* 1 = 0.0736456 loss)
I0829 22:22:18.598423 916722 sgd_solver.cpp:106] Iteration 773500, lr = 0.01
I0829 22:22:48.554764 916722 solver.cpp:218] Iteration 774000 (16.691 iter/s, 29.9563s/500 iters), loss = 0.0895415
I0829 22:22:48.554817 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0895495 (* 1 = 0.0895495 loss)
I0829 22:22:48.554826 916722 sgd_solver.cpp:106] Iteration 774000, lr = 0.01
I0829 22:23:18.499395 916722 solver.cpp:218] Iteration 774500 (16.6975 iter/s, 29.9445s/500 iters), loss = 0.140743
I0829 22:23:18.499452 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.140751 (* 1 = 0.140751 loss)
I0829 22:23:18.499460 916722 sgd_solver.cpp:106] Iteration 774500, lr = 0.01
I0829 22:23:48.472380 916722 solver.cpp:218] Iteration 775000 (16.6817 iter/s, 29.9729s/500 iters), loss = 0.263397
I0829 22:23:48.472434 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.263405 (* 1 = 0.263405 loss)
I0829 22:23:48.472443 916722 sgd_solver.cpp:106] Iteration 775000, lr = 0.01
I0829 22:24:18.432611 916722 solver.cpp:218] Iteration 775500 (16.6888 iter/s, 29.9601s/500 iters), loss = 0.0350482
I0829 22:24:18.432669 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0350563 (* 1 = 0.0350563 loss)
I0829 22:24:18.432678 916722 sgd_solver.cpp:106] Iteration 775500, lr = 0.01
I0829 22:24:48.389600 916722 solver.cpp:218] Iteration 776000 (16.6907 iter/s, 29.9569s/500 iters), loss = 0.184182
I0829 22:24:48.389652 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.184191 (* 1 = 0.184191 loss)
I0829 22:24:48.389662 916722 sgd_solver.cpp:106] Iteration 776000, lr = 0.01
I0829 22:25:18.349272 916722 solver.cpp:218] Iteration 776500 (16.6892 iter/s, 29.9596s/500 iters), loss = 0.0701632
I0829 22:25:18.349324 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0701713 (* 1 = 0.0701713 loss)
I0829 22:25:18.349332 916722 sgd_solver.cpp:106] Iteration 776500, lr = 0.01
I0829 22:25:48.302904 916722 solver.cpp:218] Iteration 777000 (16.6925 iter/s, 29.9535s/500 iters), loss = 0.090083
I0829 22:25:48.302958 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0900912 (* 1 = 0.0900912 loss)
I0829 22:25:48.302968 916722 sgd_solver.cpp:106] Iteration 777000, lr = 0.01
I0829 22:26:18.270002 916722 solver.cpp:218] Iteration 777500 (16.685 iter/s, 29.967s/500 iters), loss = 0.0945063
I0829 22:26:18.270058 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0945145 (* 1 = 0.0945145 loss)
I0829 22:26:18.270067 916722 sgd_solver.cpp:106] Iteration 777500, lr = 0.01
I0829 22:26:48.235873 916722 solver.cpp:218] Iteration 778000 (16.6857 iter/s, 29.9658s/500 iters), loss = 0.0996005
I0829 22:26:48.235924 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0996087 (* 1 = 0.0996087 loss)
I0829 22:26:48.235934 916722 sgd_solver.cpp:106] Iteration 778000, lr = 0.01
I0829 22:27:18.201237 916722 solver.cpp:218] Iteration 778500 (16.686 iter/s, 29.9653s/500 iters), loss = 0.235741
I0829 22:27:18.201292 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.235749 (* 1 = 0.235749 loss)
I0829 22:27:18.201301 916722 sgd_solver.cpp:106] Iteration 778500, lr = 0.01
I0829 22:27:48.181979 916722 solver.cpp:218] Iteration 779000 (16.6774 iter/s, 29.9806s/500 iters), loss = 0.184317
I0829 22:27:48.182027 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.184325 (* 1 = 0.184325 loss)
I0829 22:27:48.182037 916722 sgd_solver.cpp:106] Iteration 779000, lr = 0.01
I0829 22:28:18.149986 916722 solver.cpp:218] Iteration 779500 (16.6845 iter/s, 29.9679s/500 iters), loss = 0.589928
I0829 22:28:18.150040 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.589936 (* 1 = 0.589936 loss)
I0829 22:28:18.150048 916722 sgd_solver.cpp:106] Iteration 779500, lr = 0.01
I0829 22:28:48.103102 916722 solver.cpp:218] Iteration 780000 (16.6927 iter/s, 29.9532s/500 iters), loss = 0.109861
I0829 22:28:48.103150 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109869 (* 1 = 0.109869 loss)
I0829 22:28:48.103171 916722 sgd_solver.cpp:106] Iteration 780000, lr = 0.01
I0829 22:29:18.053208 916722 solver.cpp:218] Iteration 780500 (16.6943 iter/s, 29.9504s/500 iters), loss = 0.0128299
I0829 22:29:18.053278 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0128379 (* 1 = 0.0128379 loss)
I0829 22:29:18.053287 916722 sgd_solver.cpp:106] Iteration 780500, lr = 0.01
I0829 22:29:48.028219 916722 solver.cpp:218] Iteration 781000 (16.6804 iter/s, 29.9753s/500 iters), loss = 0.116651
I0829 22:29:48.028270 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.116659 (* 1 = 0.116659 loss)
I0829 22:29:48.028278 916722 sgd_solver.cpp:106] Iteration 781000, lr = 0.01
I0829 22:30:17.973417 916722 solver.cpp:218] Iteration 781500 (16.697 iter/s, 29.9455s/500 iters), loss = 0.240222
I0829 22:30:17.973474 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.24023 (* 1 = 0.24023 loss)
I0829 22:30:17.973484 916722 sgd_solver.cpp:106] Iteration 781500, lr = 0.01
I0829 22:30:47.927951 916722 solver.cpp:218] Iteration 782000 (16.6918 iter/s, 29.9548s/500 iters), loss = 0.0609178
I0829 22:30:47.928001 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0609257 (* 1 = 0.0609257 loss)
I0829 22:30:47.928010 916722 sgd_solver.cpp:106] Iteration 782000, lr = 0.01
I0829 22:31:17.870957 916722 solver.cpp:218] Iteration 782500 (16.6983 iter/s, 29.9432s/500 iters), loss = 0.335855
I0829 22:31:17.871016 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.335862 (* 1 = 0.335862 loss)
I0829 22:31:17.871026 916722 sgd_solver.cpp:106] Iteration 782500, lr = 0.01
I0829 22:31:47.810201 916722 solver.cpp:218] Iteration 783000 (16.7004 iter/s, 29.9394s/500 iters), loss = 0.0788533
I0829 22:31:47.810254 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0788609 (* 1 = 0.0788609 loss)
I0829 22:31:47.810263 916722 sgd_solver.cpp:106] Iteration 783000, lr = 0.01
I0829 22:32:17.753023 916722 solver.cpp:218] Iteration 783500 (16.6984 iter/s, 29.943s/500 iters), loss = 0.0628279
I0829 22:32:17.753082 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0628357 (* 1 = 0.0628357 loss)
I0829 22:32:17.753089 916722 sgd_solver.cpp:106] Iteration 783500, lr = 0.01
I0829 22:32:47.701823 916722 solver.cpp:218] Iteration 784000 (16.6951 iter/s, 29.949s/500 iters), loss = 0.221437
I0829 22:32:47.701874 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.221445 (* 1 = 0.221445 loss)
I0829 22:32:47.701882 916722 sgd_solver.cpp:106] Iteration 784000, lr = 0.01
I0829 22:33:17.659404 916722 solver.cpp:218] Iteration 784500 (16.6902 iter/s, 29.9578s/500 iters), loss = 0.0616068
I0829 22:33:17.659461 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0616146 (* 1 = 0.0616146 loss)
I0829 22:33:17.659469 916722 sgd_solver.cpp:106] Iteration 784500, lr = 0.01
I0829 22:33:47.644153 916722 solver.cpp:218] Iteration 785000 (16.6751 iter/s, 29.9849s/500 iters), loss = 0.154023
I0829 22:33:47.644204 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.154031 (* 1 = 0.154031 loss)
I0829 22:33:47.644214 916722 sgd_solver.cpp:106] Iteration 785000, lr = 0.01
I0829 22:34:17.607966 916722 solver.cpp:218] Iteration 785500 (16.6867 iter/s, 29.964s/500 iters), loss = 0.155062
I0829 22:34:17.608021 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.15507 (* 1 = 0.15507 loss)
I0829 22:34:17.608028 916722 sgd_solver.cpp:106] Iteration 785500, lr = 0.01
I0829 22:34:47.568094 916722 solver.cpp:218] Iteration 786000 (16.6888 iter/s, 29.9603s/500 iters), loss = 0.142222
I0829 22:34:47.568141 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.142229 (* 1 = 0.142229 loss)
I0829 22:34:47.568150 916722 sgd_solver.cpp:106] Iteration 786000, lr = 0.01
I0829 22:35:17.549440 916722 solver.cpp:218] Iteration 786500 (16.677 iter/s, 29.9815s/500 iters), loss = 0.165727
I0829 22:35:17.549504 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.165735 (* 1 = 0.165735 loss)
I0829 22:35:17.549515 916722 sgd_solver.cpp:106] Iteration 786500, lr = 0.01
I0829 22:35:47.536864 916722 solver.cpp:218] Iteration 787000 (16.6736 iter/s, 29.9875s/500 iters), loss = 0.146331
I0829 22:35:47.536916 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.146339 (* 1 = 0.146339 loss)
I0829 22:35:47.536926 916722 sgd_solver.cpp:106] Iteration 787000, lr = 0.01
I0829 22:36:17.505357 916722 solver.cpp:218] Iteration 787500 (16.6841 iter/s, 29.9686s/500 iters), loss = 0.450168
I0829 22:36:17.505414 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.450176 (* 1 = 0.450176 loss)
I0829 22:36:17.505422 916722 sgd_solver.cpp:106] Iteration 787500, lr = 0.01
I0829 22:36:47.496384 916722 solver.cpp:218] Iteration 788000 (16.6716 iter/s, 29.9911s/500 iters), loss = 0.207737
I0829 22:36:47.496443 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.207744 (* 1 = 0.207744 loss)
I0829 22:36:47.496454 916722 sgd_solver.cpp:106] Iteration 788000, lr = 0.01
I0829 22:37:17.490904 916722 solver.cpp:218] Iteration 788500 (16.6697 iter/s, 29.9946s/500 iters), loss = 0.0849605
I0829 22:37:17.490962 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0849683 (* 1 = 0.0849683 loss)
I0829 22:37:17.490970 916722 sgd_solver.cpp:106] Iteration 788500, lr = 0.01
I0829 22:37:47.472877 916722 solver.cpp:218] Iteration 789000 (16.6766 iter/s, 29.9821s/500 iters), loss = 0.195113
I0829 22:37:47.472927 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.195121 (* 1 = 0.195121 loss)
I0829 22:37:47.472937 916722 sgd_solver.cpp:106] Iteration 789000, lr = 0.01
I0829 22:38:17.450810 916722 solver.cpp:218] Iteration 789500 (16.6789 iter/s, 29.978s/500 iters), loss = 0.251413
I0829 22:38:17.450872 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.251421 (* 1 = 0.251421 loss)
I0829 22:38:17.450881 916722 sgd_solver.cpp:106] Iteration 789500, lr = 0.01
I0829 22:38:47.422523 916722 solver.cpp:218] Iteration 790000 (16.6824 iter/s, 29.9718s/500 iters), loss = 0.133364
I0829 22:38:47.422574 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133371 (* 1 = 0.133371 loss)
I0829 22:38:47.422582 916722 sgd_solver.cpp:106] Iteration 790000, lr = 0.01
I0829 22:39:17.378355 916722 solver.cpp:218] Iteration 790500 (16.6912 iter/s, 29.9559s/500 iters), loss = 0.0603052
I0829 22:39:17.378410 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0603129 (* 1 = 0.0603129 loss)
I0829 22:39:17.378419 916722 sgd_solver.cpp:106] Iteration 790500, lr = 0.01
I0829 22:39:47.352108 916722 solver.cpp:218] Iteration 791000 (16.6812 iter/s, 29.9738s/500 iters), loss = 0.317668
I0829 22:39:47.352157 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.317676 (* 1 = 0.317676 loss)
I0829 22:39:47.352166 916722 sgd_solver.cpp:106] Iteration 791000, lr = 0.01
I0829 22:40:17.327795 916722 solver.cpp:218] Iteration 791500 (16.6801 iter/s, 29.9757s/500 iters), loss = 0.236273
I0829 22:40:17.327854 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.236281 (* 1 = 0.236281 loss)
I0829 22:40:17.327862 916722 sgd_solver.cpp:106] Iteration 791500, lr = 0.01
I0829 22:40:47.284792 916722 solver.cpp:218] Iteration 792000 (16.6906 iter/s, 29.957s/500 iters), loss = 0.186072
I0829 22:40:47.284847 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.186079 (* 1 = 0.186079 loss)
I0829 22:40:47.284854 916722 sgd_solver.cpp:106] Iteration 792000, lr = 0.01
I0829 22:41:17.254886 916722 solver.cpp:218] Iteration 792500 (16.6833 iter/s, 29.9701s/500 iters), loss = 0.0382881
I0829 22:41:17.254945 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0382956 (* 1 = 0.0382956 loss)
I0829 22:41:17.254953 916722 sgd_solver.cpp:106] Iteration 792500, lr = 0.01
I0829 22:41:47.212966 916722 solver.cpp:218] Iteration 793000 (16.69 iter/s, 29.9581s/500 iters), loss = 0.305743
I0829 22:41:47.213018 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.30575 (* 1 = 0.30575 loss)
I0829 22:41:47.213027 916722 sgd_solver.cpp:106] Iteration 793000, lr = 0.01
I0829 22:42:17.184376 916722 solver.cpp:218] Iteration 793500 (16.6825 iter/s, 29.9715s/500 iters), loss = 0.485566
I0829 22:42:17.184448 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.485574 (* 1 = 0.485574 loss)
I0829 22:42:17.184458 916722 sgd_solver.cpp:106] Iteration 793500, lr = 0.01
I0829 22:42:47.137763 916722 solver.cpp:218] Iteration 794000 (16.6926 iter/s, 29.9534s/500 iters), loss = 0.10294
I0829 22:42:47.137816 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.102947 (* 1 = 0.102947 loss)
I0829 22:42:47.137826 916722 sgd_solver.cpp:106] Iteration 794000, lr = 0.01
I0829 22:43:17.090708 916722 solver.cpp:218] Iteration 794500 (16.6928 iter/s, 29.953s/500 iters), loss = 0.0801009
I0829 22:43:17.090763 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0801084 (* 1 = 0.0801084 loss)
I0829 22:43:17.090772 916722 sgd_solver.cpp:106] Iteration 794500, lr = 0.01
I0829 22:43:47.054394 916722 solver.cpp:218] Iteration 795000 (16.6869 iter/s, 29.9637s/500 iters), loss = 0.204498
I0829 22:43:47.054440 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.204506 (* 1 = 0.204506 loss)
I0829 22:43:47.054450 916722 sgd_solver.cpp:106] Iteration 795000, lr = 0.01
I0829 22:44:17.008064 916722 solver.cpp:218] Iteration 795500 (16.6924 iter/s, 29.9537s/500 iters), loss = 0.140073
I0829 22:44:17.008117 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.14008 (* 1 = 0.14008 loss)
I0829 22:44:17.008126 916722 sgd_solver.cpp:106] Iteration 795500, lr = 0.01
I0829 22:44:47.011512 916722 solver.cpp:218] Iteration 796000 (16.6647 iter/s, 30.0035s/500 iters), loss = 0.151218
I0829 22:44:47.011574 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.151225 (* 1 = 0.151225 loss)
I0829 22:44:47.011581 916722 sgd_solver.cpp:106] Iteration 796000, lr = 0.01
I0829 22:45:16.972144 916722 solver.cpp:218] Iteration 796500 (16.6886 iter/s, 29.9606s/500 iters), loss = 0.143388
I0829 22:45:16.972195 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.143395 (* 1 = 0.143395 loss)
I0829 22:45:16.972205 916722 sgd_solver.cpp:106] Iteration 796500, lr = 0.01
I0829 22:45:46.947340 916722 solver.cpp:218] Iteration 797000 (16.6804 iter/s, 29.9752s/500 iters), loss = 0.136198
I0829 22:45:46.947402 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.136205 (* 1 = 0.136205 loss)
I0829 22:45:46.947409 916722 sgd_solver.cpp:106] Iteration 797000, lr = 0.01
I0829 22:46:16.934885 916722 solver.cpp:218] Iteration 797500 (16.6736 iter/s, 29.9875s/500 iters), loss = 0.151545
I0829 22:46:16.934937 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.151552 (* 1 = 0.151552 loss)
I0829 22:46:16.934947 916722 sgd_solver.cpp:106] Iteration 797500, lr = 0.01
I0829 22:46:46.896780 916722 solver.cpp:218] Iteration 798000 (16.6879 iter/s, 29.9619s/500 iters), loss = 0.0288861
I0829 22:46:46.896839 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.028893 (* 1 = 0.028893 loss)
I0829 22:46:46.896848 916722 sgd_solver.cpp:106] Iteration 798000, lr = 0.01
I0829 22:47:16.859804 916722 solver.cpp:218] Iteration 798500 (16.6872 iter/s, 29.963s/500 iters), loss = 0.0414129
I0829 22:47:16.859856 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0414198 (* 1 = 0.0414198 loss)
I0829 22:47:16.859864 916722 sgd_solver.cpp:106] Iteration 798500, lr = 0.01
I0829 22:47:46.824092 916722 solver.cpp:218] Iteration 799000 (16.6865 iter/s, 29.9643s/500 iters), loss = 0.160506
I0829 22:47:46.824151 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.160512 (* 1 = 0.160512 loss)
I0829 22:47:46.824158 916722 sgd_solver.cpp:106] Iteration 799000, lr = 0.01
I0829 22:48:16.785605 916722 solver.cpp:218] Iteration 799500 (16.6881 iter/s, 29.9615s/500 iters), loss = 0.0173839
I0829 22:48:16.785657 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0173907 (* 1 = 0.0173907 loss)
I0829 22:48:16.785668 916722 sgd_solver.cpp:106] Iteration 799500, lr = 0.01
I0829 22:48:46.668879 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_800000.caffemodel
I0829 22:48:46.687947 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_800000.solverstate
I0829 22:48:46.694195 916722 solver.cpp:330] Iteration 800000, Testing net (#0)
I0829 22:49:02.018121 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8987
I0829 22:49:02.018167 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.342757 (* 1 = 0.342757 loss)
I0829 22:49:02.076879 916722 solver.cpp:218] Iteration 800000 (11.0396 iter/s, 45.2913s/500 iters), loss = 0.273956
I0829 22:49:02.076903 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.273963 (* 1 = 0.273963 loss)
I0829 22:49:02.076911 916722 sgd_solver.cpp:106] Iteration 800000, lr = 0.01
I0829 22:49:31.901510 916722 solver.cpp:218] Iteration 800500 (16.7647 iter/s, 29.8246s/500 iters), loss = 0.217828
I0829 22:49:31.901566 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.217834 (* 1 = 0.217834 loss)
I0829 22:49:31.901574 916722 sgd_solver.cpp:106] Iteration 800500, lr = 0.01
I0829 22:50:01.829429 916722 solver.cpp:218] Iteration 801000 (16.7068 iter/s, 29.9279s/500 iters), loss = 0.0613541
I0829 22:50:01.829476 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0613606 (* 1 = 0.0613606 loss)
I0829 22:50:01.829486 916722 sgd_solver.cpp:106] Iteration 801000, lr = 0.01
I0829 22:50:31.786197 916722 solver.cpp:218] Iteration 801500 (16.6907 iter/s, 29.9568s/500 iters), loss = 0.124672
I0829 22:50:31.786252 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.124679 (* 1 = 0.124679 loss)
I0829 22:50:31.786260 916722 sgd_solver.cpp:106] Iteration 801500, lr = 0.01
I0829 22:51:01.738098 916722 solver.cpp:218] Iteration 802000 (16.6934 iter/s, 29.9519s/500 iters), loss = 0.0927229
I0829 22:51:01.738147 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0927295 (* 1 = 0.0927295 loss)
I0829 22:51:01.738157 916722 sgd_solver.cpp:106] Iteration 802000, lr = 0.01
I0829 22:51:31.703101 916722 solver.cpp:218] Iteration 802500 (16.6861 iter/s, 29.965s/500 iters), loss = 0.0800875
I0829 22:51:31.703161 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.080094 (* 1 = 0.080094 loss)
I0829 22:51:31.703171 916722 sgd_solver.cpp:106] Iteration 802500, lr = 0.01
I0829 22:52:01.666677 916722 solver.cpp:218] Iteration 803000 (16.6869 iter/s, 29.9636s/500 iters), loss = 0.0833209
I0829 22:52:01.666726 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0833277 (* 1 = 0.0833277 loss)
I0829 22:52:01.666736 916722 sgd_solver.cpp:106] Iteration 803000, lr = 0.01
I0829 22:52:31.625504 916722 solver.cpp:218] Iteration 803500 (16.6896 iter/s, 29.9588s/500 iters), loss = 0.0699136
I0829 22:52:31.625567 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0699204 (* 1 = 0.0699204 loss)
I0829 22:52:31.625576 916722 sgd_solver.cpp:106] Iteration 803500, lr = 0.01
I0829 22:53:01.598876 916722 solver.cpp:218] Iteration 804000 (16.6815 iter/s, 29.9733s/500 iters), loss = 0.0645189
I0829 22:53:01.598924 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0645258 (* 1 = 0.0645258 loss)
I0829 22:53:01.598933 916722 sgd_solver.cpp:106] Iteration 804000, lr = 0.01
I0829 22:53:31.582736 916722 solver.cpp:218] Iteration 804500 (16.6756 iter/s, 29.9839s/500 iters), loss = 0.0865491
I0829 22:53:31.582794 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.086556 (* 1 = 0.086556 loss)
I0829 22:53:31.582803 916722 sgd_solver.cpp:106] Iteration 804500, lr = 0.01
I0829 22:54:01.551245 916722 solver.cpp:218] Iteration 805000 (16.6842 iter/s, 29.9685s/500 iters), loss = 0.300554
I0829 22:54:01.551293 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.300561 (* 1 = 0.300561 loss)
I0829 22:54:01.551302 916722 sgd_solver.cpp:106] Iteration 805000, lr = 0.01
I0829 22:54:31.515744 916722 solver.cpp:218] Iteration 805500 (16.6864 iter/s, 29.9645s/500 iters), loss = 0.203855
I0829 22:54:31.515811 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.203862 (* 1 = 0.203862 loss)
I0829 22:54:31.515823 916722 sgd_solver.cpp:106] Iteration 805500, lr = 0.01
I0829 22:55:01.475787 916722 solver.cpp:218] Iteration 806000 (16.6889 iter/s, 29.96s/500 iters), loss = 0.253908
I0829 22:55:01.475836 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.253915 (* 1 = 0.253915 loss)
I0829 22:55:01.475845 916722 sgd_solver.cpp:106] Iteration 806000, lr = 0.01
I0829 22:55:31.438022 916722 solver.cpp:218] Iteration 806500 (16.6877 iter/s, 29.9622s/500 iters), loss = 0.0282253
I0829 22:55:31.438077 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0282323 (* 1 = 0.0282323 loss)
I0829 22:55:31.438086 916722 sgd_solver.cpp:106] Iteration 806500, lr = 0.01
I0829 22:56:01.407966 916722 solver.cpp:218] Iteration 807000 (16.6834 iter/s, 29.9699s/500 iters), loss = 0.124281
I0829 22:56:01.408015 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.124288 (* 1 = 0.124288 loss)
I0829 22:56:01.408023 916722 sgd_solver.cpp:106] Iteration 807000, lr = 0.01
I0829 22:56:31.353452 916722 solver.cpp:218] Iteration 807500 (16.697 iter/s, 29.9455s/500 iters), loss = 0.130912
I0829 22:56:31.353513 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130919 (* 1 = 0.130919 loss)
I0829 22:56:31.353520 916722 sgd_solver.cpp:106] Iteration 807500, lr = 0.01
I0829 22:57:01.299800 916722 solver.cpp:218] Iteration 808000 (16.6965 iter/s, 29.9463s/500 iters), loss = 0.173337
I0829 22:57:01.299849 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.173344 (* 1 = 0.173344 loss)
I0829 22:57:01.299856 916722 sgd_solver.cpp:106] Iteration 808000, lr = 0.01
I0829 22:57:31.245059 916722 solver.cpp:218] Iteration 808500 (16.6971 iter/s, 29.9452s/500 iters), loss = 0.00758752
I0829 22:57:31.245118 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.00759449 (* 1 = 0.00759449 loss)
I0829 22:57:31.245127 916722 sgd_solver.cpp:106] Iteration 808500, lr = 0.01
I0829 22:58:01.194743 916722 solver.cpp:218] Iteration 809000 (16.6947 iter/s, 29.9496s/500 iters), loss = 0.139263
I0829 22:58:01.194792 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13927 (* 1 = 0.13927 loss)
I0829 22:58:01.194802 916722 sgd_solver.cpp:106] Iteration 809000, lr = 0.01
I0829 22:58:31.137674 916722 solver.cpp:218] Iteration 809500 (16.6984 iter/s, 29.9429s/500 iters), loss = 0.132376
I0829 22:58:31.137730 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.132383 (* 1 = 0.132383 loss)
I0829 22:58:31.137738 916722 sgd_solver.cpp:106] Iteration 809500, lr = 0.01
I0829 22:59:01.106863 916722 solver.cpp:218] Iteration 810000 (16.6838 iter/s, 29.9692s/500 iters), loss = 0.267778
I0829 22:59:01.106910 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.267785 (* 1 = 0.267785 loss)
I0829 22:59:01.106920 916722 sgd_solver.cpp:106] Iteration 810000, lr = 0.01
I0829 22:59:31.057332 916722 solver.cpp:218] Iteration 810500 (16.6942 iter/s, 29.9504s/500 iters), loss = 0.421982
I0829 22:59:31.057385 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.421989 (* 1 = 0.421989 loss)
I0829 22:59:31.057394 916722 sgd_solver.cpp:106] Iteration 810500, lr = 0.01
I0829 23:00:01.018180 916722 solver.cpp:218] Iteration 811000 (16.6885 iter/s, 29.9608s/500 iters), loss = 0.172107
I0829 23:00:01.018227 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.172114 (* 1 = 0.172114 loss)
I0829 23:00:01.018237 916722 sgd_solver.cpp:106] Iteration 811000, lr = 0.01
I0829 23:00:30.987313 916722 solver.cpp:218] Iteration 811500 (16.6838 iter/s, 29.9691s/500 iters), loss = 0.0304611
I0829 23:00:30.987372 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0304679 (* 1 = 0.0304679 loss)
I0829 23:00:30.987381 916722 sgd_solver.cpp:106] Iteration 811500, lr = 0.01
I0829 23:01:00.950943 916722 solver.cpp:218] Iteration 812000 (16.6869 iter/s, 29.9636s/500 iters), loss = 0.122424
I0829 23:01:00.950991 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.122431 (* 1 = 0.122431 loss)
I0829 23:01:00.951012 916722 sgd_solver.cpp:106] Iteration 812000, lr = 0.01
I0829 23:01:30.951411 916722 solver.cpp:218] Iteration 812500 (16.6664 iter/s, 30.0004s/500 iters), loss = 0.0443366
I0829 23:01:30.951478 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0443433 (* 1 = 0.0443433 loss)
I0829 23:01:30.951488 916722 sgd_solver.cpp:106] Iteration 812500, lr = 0.01
I0829 23:02:00.906466 916722 solver.cpp:218] Iteration 813000 (16.6917 iter/s, 29.955s/500 iters), loss = 0.143678
I0829 23:02:00.906513 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.143685 (* 1 = 0.143685 loss)
I0829 23:02:00.906522 916722 sgd_solver.cpp:106] Iteration 813000, lr = 0.01
I0829 23:02:30.884651 916722 solver.cpp:218] Iteration 813500 (16.6788 iter/s, 29.9782s/500 iters), loss = 0.0686378
I0829 23:02:30.884716 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0686444 (* 1 = 0.0686444 loss)
I0829 23:02:30.884727 916722 sgd_solver.cpp:106] Iteration 813500, lr = 0.01
I0829 23:03:00.854223 916722 solver.cpp:218] Iteration 814000 (16.6837 iter/s, 29.9694s/500 iters), loss = 0.235325
I0829 23:03:00.854271 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.235331 (* 1 = 0.235331 loss)
I0829 23:03:00.854280 916722 sgd_solver.cpp:106] Iteration 814000, lr = 0.01
I0829 23:03:30.806921 916722 solver.cpp:218] Iteration 814500 (16.6931 iter/s, 29.9525s/500 iters), loss = 0.164656
I0829 23:03:30.806979 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.164663 (* 1 = 0.164663 loss)
I0829 23:03:30.806988 916722 sgd_solver.cpp:106] Iteration 814500, lr = 0.01
I0829 23:04:00.755570 916722 solver.cpp:218] Iteration 815000 (16.6954 iter/s, 29.9484s/500 iters), loss = 0.115106
I0829 23:04:00.755617 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115113 (* 1 = 0.115113 loss)
I0829 23:04:00.755626 916722 sgd_solver.cpp:106] Iteration 815000, lr = 0.01
I0829 23:04:30.696301 916722 solver.cpp:218] Iteration 815500 (16.6998 iter/s, 29.9405s/500 iters), loss = 0.0474233
I0829 23:04:30.696357 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0474303 (* 1 = 0.0474303 loss)
I0829 23:04:30.696365 916722 sgd_solver.cpp:106] Iteration 815500, lr = 0.01
I0829 23:05:00.658799 916722 solver.cpp:218] Iteration 816000 (16.6876 iter/s, 29.9623s/500 iters), loss = 0.14908
I0829 23:05:00.658847 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.149087 (* 1 = 0.149087 loss)
I0829 23:05:00.658855 916722 sgd_solver.cpp:106] Iteration 816000, lr = 0.01
I0829 23:05:30.623948 916722 solver.cpp:218] Iteration 816500 (16.6861 iter/s, 29.965s/500 iters), loss = 0.290899
I0829 23:05:30.624008 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.290906 (* 1 = 0.290906 loss)
I0829 23:05:30.624017 916722 sgd_solver.cpp:106] Iteration 816500, lr = 0.01
I0829 23:06:00.584633 916722 solver.cpp:218] Iteration 817000 (16.6886 iter/s, 29.9605s/500 iters), loss = 0.197769
I0829 23:06:00.584681 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.197776 (* 1 = 0.197776 loss)
I0829 23:06:00.584690 916722 sgd_solver.cpp:106] Iteration 817000, lr = 0.01
I0829 23:06:30.551055 916722 solver.cpp:218] Iteration 817500 (16.6854 iter/s, 29.9663s/500 iters), loss = 0.351132
I0829 23:06:30.551113 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.351138 (* 1 = 0.351138 loss)
I0829 23:06:30.551122 916722 sgd_solver.cpp:106] Iteration 817500, lr = 0.01
I0829 23:07:00.516032 916722 solver.cpp:218] Iteration 818000 (16.6862 iter/s, 29.9648s/500 iters), loss = 0.052693
I0829 23:07:00.516081 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0526997 (* 1 = 0.0526997 loss)
I0829 23:07:00.516090 916722 sgd_solver.cpp:106] Iteration 818000, lr = 0.01
I0829 23:07:30.480916 916722 solver.cpp:218] Iteration 818500 (16.6863 iter/s, 29.9647s/500 iters), loss = 0.254794
I0829 23:07:30.480974 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.254801 (* 1 = 0.254801 loss)
I0829 23:07:30.480983 916722 sgd_solver.cpp:106] Iteration 818500, lr = 0.01
I0829 23:08:00.459103 916722 solver.cpp:218] Iteration 819000 (16.6789 iter/s, 29.978s/500 iters), loss = 0.0944793
I0829 23:08:00.459152 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0944861 (* 1 = 0.0944861 loss)
I0829 23:08:00.459162 916722 sgd_solver.cpp:106] Iteration 819000, lr = 0.01
I0829 23:08:30.399549 916722 solver.cpp:218] Iteration 819500 (16.6999 iter/s, 29.9403s/500 iters), loss = 0.253858
I0829 23:08:30.399611 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.253865 (* 1 = 0.253865 loss)
I0829 23:08:30.399621 916722 sgd_solver.cpp:106] Iteration 819500, lr = 0.01
I0829 23:09:00.345217 916722 solver.cpp:218] Iteration 820000 (16.697 iter/s, 29.9455s/500 iters), loss = 0.141267
I0829 23:09:00.345264 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.141274 (* 1 = 0.141274 loss)
I0829 23:09:00.345274 916722 sgd_solver.cpp:106] Iteration 820000, lr = 0.01
I0829 23:09:30.280778 916722 solver.cpp:218] Iteration 820500 (16.7026 iter/s, 29.9354s/500 iters), loss = 0.11172
I0829 23:09:30.280838 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111727 (* 1 = 0.111727 loss)
I0829 23:09:30.280846 916722 sgd_solver.cpp:106] Iteration 820500, lr = 0.01
I0829 23:10:00.223052 916722 solver.cpp:218] Iteration 821000 (16.6989 iter/s, 29.9421s/500 iters), loss = 0.0761389
I0829 23:10:00.223111 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0761457 (* 1 = 0.0761457 loss)
I0829 23:10:00.223121 916722 sgd_solver.cpp:106] Iteration 821000, lr = 0.01
I0829 23:10:30.138738 916722 solver.cpp:218] Iteration 821500 (16.7137 iter/s, 29.9156s/500 iters), loss = 0.0471717
I0829 23:10:30.138798 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0471785 (* 1 = 0.0471785 loss)
I0829 23:10:30.138806 916722 sgd_solver.cpp:106] Iteration 821500, lr = 0.01
I0829 23:11:00.052851 916722 solver.cpp:218] Iteration 822000 (16.7146 iter/s, 29.914s/500 iters), loss = 0.308362
I0829 23:11:00.052896 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.308369 (* 1 = 0.308369 loss)
I0829 23:11:00.052903 916722 sgd_solver.cpp:106] Iteration 822000, lr = 0.01
I0829 23:11:29.968462 916722 solver.cpp:218] Iteration 822500 (16.7137 iter/s, 29.9155s/500 iters), loss = 0.133514
I0829 23:11:29.968520 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13352 (* 1 = 0.13352 loss)
I0829 23:11:29.968528 916722 sgd_solver.cpp:106] Iteration 822500, lr = 0.01
I0829 23:11:59.877105 916722 solver.cpp:218] Iteration 823000 (16.7176 iter/s, 29.9085s/500 iters), loss = 0.0579115
I0829 23:11:59.877154 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0579183 (* 1 = 0.0579183 loss)
I0829 23:11:59.877164 916722 sgd_solver.cpp:106] Iteration 823000, lr = 0.01
I0829 23:12:29.809455 916722 solver.cpp:218] Iteration 823500 (16.7044 iter/s, 29.9322s/500 iters), loss = 0.276174
I0829 23:12:29.809509 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.276181 (* 1 = 0.276181 loss)
I0829 23:12:29.809518 916722 sgd_solver.cpp:106] Iteration 823500, lr = 0.01
I0829 23:12:59.752869 916722 solver.cpp:218] Iteration 824000 (16.6982 iter/s, 29.9433s/500 iters), loss = 0.230305
I0829 23:12:59.752916 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.230312 (* 1 = 0.230312 loss)
I0829 23:12:59.752926 916722 sgd_solver.cpp:106] Iteration 824000, lr = 0.01
I0829 23:13:29.683809 916722 solver.cpp:218] Iteration 824500 (16.7052 iter/s, 29.9308s/500 iters), loss = 0.0454081
I0829 23:13:29.683866 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.045415 (* 1 = 0.045415 loss)
I0829 23:13:29.683876 916722 sgd_solver.cpp:106] Iteration 824500, lr = 0.01
I0829 23:13:59.602583 916722 solver.cpp:218] Iteration 825000 (16.712 iter/s, 29.9187s/500 iters), loss = 0.231106
I0829 23:13:59.602636 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.231113 (* 1 = 0.231113 loss)
I0829 23:13:59.602648 916722 sgd_solver.cpp:106] Iteration 825000, lr = 0.01
I0829 23:14:29.534263 916722 solver.cpp:218] Iteration 825500 (16.7048 iter/s, 29.9316s/500 iters), loss = 0.115235
I0829 23:14:29.534335 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115242 (* 1 = 0.115242 loss)
I0829 23:14:29.534343 916722 sgd_solver.cpp:106] Iteration 825500, lr = 0.01
I0829 23:14:59.476902 916722 solver.cpp:218] Iteration 826000 (16.6987 iter/s, 29.9425s/500 iters), loss = 0.0833451
I0829 23:14:59.476951 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0833521 (* 1 = 0.0833521 loss)
I0829 23:14:59.476961 916722 sgd_solver.cpp:106] Iteration 826000, lr = 0.01
I0829 23:15:29.403596 916722 solver.cpp:218] Iteration 826500 (16.7075 iter/s, 29.9266s/500 iters), loss = 0.126037
I0829 23:15:29.403656 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.126044 (* 1 = 0.126044 loss)
I0829 23:15:29.403663 916722 sgd_solver.cpp:106] Iteration 826500, lr = 0.01
I0829 23:15:59.343982 916722 solver.cpp:218] Iteration 827000 (16.6999 iter/s, 29.9403s/500 iters), loss = 0.128961
I0829 23:15:59.344033 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128968 (* 1 = 0.128968 loss)
I0829 23:15:59.344043 916722 sgd_solver.cpp:106] Iteration 827000, lr = 0.01
I0829 23:16:29.305074 916722 solver.cpp:218] Iteration 827500 (16.6884 iter/s, 29.961s/500 iters), loss = 0.216275
I0829 23:16:29.305128 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.216282 (* 1 = 0.216282 loss)
I0829 23:16:29.305136 916722 sgd_solver.cpp:106] Iteration 827500, lr = 0.01
I0829 23:16:59.229352 916722 solver.cpp:218] Iteration 828000 (16.7089 iter/s, 29.9242s/500 iters), loss = 0.137694
I0829 23:16:59.229401 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.137701 (* 1 = 0.137701 loss)
I0829 23:16:59.229411 916722 sgd_solver.cpp:106] Iteration 828000, lr = 0.01
I0829 23:17:29.167513 916722 solver.cpp:218] Iteration 828500 (16.7011 iter/s, 29.9381s/500 iters), loss = 0.17941
I0829 23:17:29.167570 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.179417 (* 1 = 0.179417 loss)
I0829 23:17:29.167579 916722 sgd_solver.cpp:106] Iteration 828500, lr = 0.01
I0829 23:17:59.102733 916722 solver.cpp:218] Iteration 829000 (16.7028 iter/s, 29.9351s/500 iters), loss = 0.0681366
I0829 23:17:59.102785 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0681433 (* 1 = 0.0681433 loss)
I0829 23:17:59.102794 916722 sgd_solver.cpp:106] Iteration 829000, lr = 0.01
I0829 23:18:29.033272 916722 solver.cpp:218] Iteration 829500 (16.7054 iter/s, 29.9305s/500 iters), loss = 0.1989
I0829 23:18:29.033331 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.198907 (* 1 = 0.198907 loss)
I0829 23:18:29.033340 916722 sgd_solver.cpp:106] Iteration 829500, lr = 0.01
I0829 23:18:58.998134 916722 solver.cpp:218] Iteration 830000 (16.6863 iter/s, 29.9648s/500 iters), loss = 0.0462698
I0829 23:18:58.998186 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0462763 (* 1 = 0.0462763 loss)
I0829 23:18:58.998195 916722 sgd_solver.cpp:106] Iteration 830000, lr = 0.01
I0829 23:19:28.929850 916722 solver.cpp:218] Iteration 830500 (16.7047 iter/s, 29.9316s/500 iters), loss = 0.0715272
I0829 23:19:28.929908 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0715337 (* 1 = 0.0715337 loss)
I0829 23:19:28.929917 916722 sgd_solver.cpp:106] Iteration 830500, lr = 0.01
I0829 23:19:58.872779 916722 solver.cpp:218] Iteration 831000 (16.6985 iter/s, 29.9428s/500 iters), loss = 0.0774134
I0829 23:19:58.872829 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.07742 (* 1 = 0.07742 loss)
I0829 23:19:58.872838 916722 sgd_solver.cpp:106] Iteration 831000, lr = 0.01
I0829 23:20:28.825302 916722 solver.cpp:218] Iteration 831500 (16.6931 iter/s, 29.9525s/500 iters), loss = 0.14072
I0829 23:20:28.825359 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.140727 (* 1 = 0.140727 loss)
I0829 23:20:28.825367 916722 sgd_solver.cpp:106] Iteration 831500, lr = 0.01
I0829 23:20:58.759308 916722 solver.cpp:218] Iteration 832000 (16.7035 iter/s, 29.9339s/500 iters), loss = 0.174086
I0829 23:20:58.759357 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.174092 (* 1 = 0.174092 loss)
I0829 23:20:58.759377 916722 sgd_solver.cpp:106] Iteration 832000, lr = 0.01
I0829 23:21:28.694156 916722 solver.cpp:218] Iteration 832500 (16.703 iter/s, 29.9348s/500 iters), loss = 0.210681
I0829 23:21:28.694221 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.210688 (* 1 = 0.210688 loss)
I0829 23:21:28.694229 916722 sgd_solver.cpp:106] Iteration 832500, lr = 0.01
I0829 23:21:58.642846 916722 solver.cpp:218] Iteration 833000 (16.6953 iter/s, 29.9486s/500 iters), loss = 0.0634347
I0829 23:21:58.642896 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0634412 (* 1 = 0.0634412 loss)
I0829 23:21:58.642904 916722 sgd_solver.cpp:106] Iteration 833000, lr = 0.01
I0829 23:22:28.584542 916722 solver.cpp:218] Iteration 833500 (16.6992 iter/s, 29.9416s/500 iters), loss = 0.01688
I0829 23:22:28.584604 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0168864 (* 1 = 0.0168864 loss)
I0829 23:22:28.584614 916722 sgd_solver.cpp:106] Iteration 833500, lr = 0.01
I0829 23:22:58.532352 916722 solver.cpp:218] Iteration 834000 (16.6958 iter/s, 29.9477s/500 iters), loss = 0.182345
I0829 23:22:58.532407 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.182351 (* 1 = 0.182351 loss)
I0829 23:22:58.532416 916722 sgd_solver.cpp:106] Iteration 834000, lr = 0.01
I0829 23:23:28.467967 916722 solver.cpp:218] Iteration 834500 (16.7026 iter/s, 29.9355s/500 iters), loss = 0.0753103
I0829 23:23:28.468026 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0753167 (* 1 = 0.0753167 loss)
I0829 23:23:28.468034 916722 sgd_solver.cpp:106] Iteration 834500, lr = 0.01
I0829 23:23:58.396399 916722 solver.cpp:218] Iteration 835000 (16.7066 iter/s, 29.9284s/500 iters), loss = 0.23725
I0829 23:23:58.396456 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.237257 (* 1 = 0.237257 loss)
I0829 23:23:58.396466 916722 sgd_solver.cpp:106] Iteration 835000, lr = 0.01
I0829 23:24:28.356601 916722 solver.cpp:218] Iteration 835500 (16.6888 iter/s, 29.9601s/500 iters), loss = 0.227509
I0829 23:24:28.356657 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.227516 (* 1 = 0.227516 loss)
I0829 23:24:28.356667 916722 sgd_solver.cpp:106] Iteration 835500, lr = 0.01
I0829 23:24:58.314040 916722 solver.cpp:218] Iteration 836000 (16.6904 iter/s, 29.9574s/500 iters), loss = 0.104811
I0829 23:24:58.314090 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104818 (* 1 = 0.104818 loss)
I0829 23:24:58.314100 916722 sgd_solver.cpp:106] Iteration 836000, lr = 0.01
I0829 23:25:28.249855 916722 solver.cpp:218] Iteration 836500 (16.7024 iter/s, 29.9357s/500 iters), loss = 0.188168
I0829 23:25:28.249909 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.188174 (* 1 = 0.188174 loss)
I0829 23:25:28.249917 916722 sgd_solver.cpp:106] Iteration 836500, lr = 0.01
I0829 23:25:58.203307 916722 solver.cpp:218] Iteration 837000 (16.6926 iter/s, 29.9534s/500 iters), loss = 0.136053
I0829 23:25:58.203356 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13606 (* 1 = 0.13606 loss)
I0829 23:25:58.203366 916722 sgd_solver.cpp:106] Iteration 837000, lr = 0.01
I0829 23:26:28.142848 916722 solver.cpp:218] Iteration 837500 (16.7004 iter/s, 29.9395s/500 iters), loss = 0.164285
I0829 23:26:28.142904 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.164292 (* 1 = 0.164292 loss)
I0829 23:26:28.142911 916722 sgd_solver.cpp:106] Iteration 837500, lr = 0.01
I0829 23:26:58.060813 916722 solver.cpp:218] Iteration 838000 (16.7124 iter/s, 29.9179s/500 iters), loss = 0.204213
I0829 23:26:58.060863 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.20422 (* 1 = 0.20422 loss)
I0829 23:26:58.060874 916722 sgd_solver.cpp:106] Iteration 838000, lr = 0.01
I0829 23:27:27.982072 916722 solver.cpp:218] Iteration 838500 (16.7106 iter/s, 29.9212s/500 iters), loss = 0.136855
I0829 23:27:27.982146 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.136861 (* 1 = 0.136861 loss)
I0829 23:27:27.982162 916722 sgd_solver.cpp:106] Iteration 838500, lr = 0.01
I0829 23:27:57.892823 916722 solver.cpp:218] Iteration 839000 (16.7164 iter/s, 29.9107s/500 iters), loss = 0.209239
I0829 23:27:57.892874 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.209245 (* 1 = 0.209245 loss)
I0829 23:27:57.892884 916722 sgd_solver.cpp:106] Iteration 839000, lr = 0.01
I0829 23:28:27.803687 916722 solver.cpp:218] Iteration 839500 (16.7164 iter/s, 29.9108s/500 iters), loss = 0.0781471
I0829 23:28:27.803750 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0781534 (* 1 = 0.0781534 loss)
I0829 23:28:27.803758 916722 sgd_solver.cpp:106] Iteration 839500, lr = 0.01
I0829 23:28:57.729974 916722 solver.cpp:218] Iteration 840000 (16.7078 iter/s, 29.9262s/500 iters), loss = 0.130937
I0829 23:28:57.730023 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130944 (* 1 = 0.130944 loss)
I0829 23:28:57.730031 916722 sgd_solver.cpp:106] Iteration 840000, lr = 0.01
I0829 23:29:27.635105 916722 solver.cpp:218] Iteration 840500 (16.7196 iter/s, 29.9051s/500 iters), loss = 0.177731
I0829 23:29:27.635164 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.177738 (* 1 = 0.177738 loss)
I0829 23:29:27.635174 916722 sgd_solver.cpp:106] Iteration 840500, lr = 0.01
I0829 23:29:57.571795 916722 solver.cpp:218] Iteration 841000 (16.702 iter/s, 29.9366s/500 iters), loss = 0.214904
I0829 23:29:57.571848 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.214911 (* 1 = 0.214911 loss)
I0829 23:29:57.571856 916722 sgd_solver.cpp:106] Iteration 841000, lr = 0.01
I0829 23:30:27.499169 916722 solver.cpp:218] Iteration 841500 (16.7071 iter/s, 29.9273s/500 iters), loss = 0.193624
I0829 23:30:27.499226 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.193631 (* 1 = 0.193631 loss)
I0829 23:30:27.499235 916722 sgd_solver.cpp:106] Iteration 841500, lr = 0.01
I0829 23:30:57.406919 916722 solver.cpp:218] Iteration 842000 (16.7181 iter/s, 29.9077s/500 iters), loss = 0.0565849
I0829 23:30:57.406971 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0565912 (* 1 = 0.0565912 loss)
I0829 23:30:57.406980 916722 sgd_solver.cpp:106] Iteration 842000, lr = 0.01
I0829 23:31:27.334432 916722 solver.cpp:218] Iteration 842500 (16.7071 iter/s, 29.9274s/500 iters), loss = 0.0481271
I0829 23:31:27.334488 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0481333 (* 1 = 0.0481333 loss)
I0829 23:31:27.334496 916722 sgd_solver.cpp:106] Iteration 842500, lr = 0.01
I0829 23:31:57.275761 916722 solver.cpp:218] Iteration 843000 (16.6994 iter/s, 29.9413s/500 iters), loss = 0.329513
I0829 23:31:57.275810 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.329519 (* 1 = 0.329519 loss)
I0829 23:31:57.275818 916722 sgd_solver.cpp:106] Iteration 843000, lr = 0.01
I0829 23:32:27.218981 916722 solver.cpp:218] Iteration 843500 (16.6983 iter/s, 29.9432s/500 iters), loss = 0.50403
I0829 23:32:27.219038 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.504036 (* 1 = 0.504036 loss)
I0829 23:32:27.219045 916722 sgd_solver.cpp:106] Iteration 843500, lr = 0.01
I0829 23:32:57.163920 916722 solver.cpp:218] Iteration 844000 (16.6974 iter/s, 29.9449s/500 iters), loss = 0.123995
I0829 23:32:57.163972 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.124001 (* 1 = 0.124001 loss)
I0829 23:32:57.163982 916722 sgd_solver.cpp:106] Iteration 844000, lr = 0.01
I0829 23:33:27.103806 916722 solver.cpp:218] Iteration 844500 (16.7002 iter/s, 29.9398s/500 iters), loss = 0.15157
I0829 23:33:27.103858 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.151576 (* 1 = 0.151576 loss)
I0829 23:33:27.103866 916722 sgd_solver.cpp:106] Iteration 844500, lr = 0.01
I0829 23:33:57.049948 916722 solver.cpp:218] Iteration 845000 (16.6967 iter/s, 29.9461s/500 iters), loss = 0.0580766
I0829 23:33:57.050000 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0580825 (* 1 = 0.0580825 loss)
I0829 23:33:57.050010 916722 sgd_solver.cpp:106] Iteration 845000, lr = 0.01
I0829 23:34:26.976771 916722 solver.cpp:218] Iteration 845500 (16.7075 iter/s, 29.9268s/500 iters), loss = 0.167943
I0829 23:34:26.976840 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.167949 (* 1 = 0.167949 loss)
I0829 23:34:26.976848 916722 sgd_solver.cpp:106] Iteration 845500, lr = 0.01
I0829 23:34:56.897171 916722 solver.cpp:218] Iteration 846000 (16.7111 iter/s, 29.9203s/500 iters), loss = 0.0792549
I0829 23:34:56.897222 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0792607 (* 1 = 0.0792607 loss)
I0829 23:34:56.897231 916722 sgd_solver.cpp:106] Iteration 846000, lr = 0.01
I0829 23:35:26.801890 916722 solver.cpp:218] Iteration 846500 (16.7198 iter/s, 29.9047s/500 iters), loss = 0.137222
I0829 23:35:26.801946 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.137228 (* 1 = 0.137228 loss)
I0829 23:35:26.801954 916722 sgd_solver.cpp:106] Iteration 846500, lr = 0.01
I0829 23:35:56.733893 916722 solver.cpp:218] Iteration 847000 (16.7046 iter/s, 29.9319s/500 iters), loss = 0.0398007
I0829 23:35:56.733944 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0398065 (* 1 = 0.0398065 loss)
I0829 23:35:56.733954 916722 sgd_solver.cpp:106] Iteration 847000, lr = 0.01
I0829 23:36:26.630787 916722 solver.cpp:218] Iteration 847500 (16.7242 iter/s, 29.8968s/500 iters), loss = 0.16023
I0829 23:36:26.630843 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.160235 (* 1 = 0.160235 loss)
I0829 23:36:26.630852 916722 sgd_solver.cpp:106] Iteration 847500, lr = 0.01
I0829 23:36:56.539880 916722 solver.cpp:218] Iteration 848000 (16.7174 iter/s, 29.909s/500 iters), loss = 0.087276
I0829 23:36:56.539928 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0872819 (* 1 = 0.0872819 loss)
I0829 23:36:56.539938 916722 sgd_solver.cpp:106] Iteration 848000, lr = 0.01
I0829 23:37:26.480253 916722 solver.cpp:218] Iteration 848500 (16.7001 iter/s, 29.94s/500 iters), loss = 0.29235
I0829 23:37:26.480314 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.292355 (* 1 = 0.292355 loss)
I0829 23:37:26.480322 916722 sgd_solver.cpp:106] Iteration 848500, lr = 0.01
I0829 23:37:56.421239 916722 solver.cpp:218] Iteration 849000 (16.6997 iter/s, 29.9406s/500 iters), loss = 0.206318
I0829 23:37:56.421286 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.206324 (* 1 = 0.206324 loss)
I0829 23:37:56.421294 916722 sgd_solver.cpp:106] Iteration 849000, lr = 0.01
I0829 23:38:26.363972 916722 solver.cpp:218] Iteration 849500 (16.6987 iter/s, 29.9424s/500 iters), loss = 0.301224
I0829 23:38:26.364029 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.30123 (* 1 = 0.30123 loss)
I0829 23:38:26.364038 916722 sgd_solver.cpp:106] Iteration 849500, lr = 0.01
I0829 23:38:56.250969 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_850000.caffemodel
I0829 23:38:56.270028 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_850000.solverstate
I0829 23:38:56.276223 916722 solver.cpp:330] Iteration 850000, Testing net (#0)
I0829 23:39:11.618690 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8914
I0829 23:39:11.618743 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.364717 (* 1 = 0.364717 loss)
I0829 23:39:11.677359 916722 solver.cpp:218] Iteration 850000 (11.0344 iter/s, 45.3129s/500 iters), loss = 0.286849
I0829 23:39:11.677385 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.286855 (* 1 = 0.286855 loss)
I0829 23:39:11.677393 916722 sgd_solver.cpp:106] Iteration 850000, lr = 0.01
I0829 23:39:41.466409 916722 solver.cpp:218] Iteration 850500 (16.7849 iter/s, 29.7887s/500 iters), loss = 0.419289
I0829 23:39:41.466455 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.419295 (* 1 = 0.419295 loss)
I0829 23:39:41.466464 916722 sgd_solver.cpp:106] Iteration 850500, lr = 0.01
I0829 23:40:11.361793 916722 solver.cpp:218] Iteration 851000 (16.7252 iter/s, 29.8951s/500 iters), loss = 0.173116
I0829 23:40:11.361860 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.173122 (* 1 = 0.173122 loss)
I0829 23:40:11.361868 916722 sgd_solver.cpp:106] Iteration 851000, lr = 0.01
I0829 23:40:41.289042 916722 solver.cpp:218] Iteration 851500 (16.7074 iter/s, 29.9269s/500 iters), loss = 0.211738
I0829 23:40:41.289098 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.211744 (* 1 = 0.211744 loss)
I0829 23:40:41.289108 916722 sgd_solver.cpp:106] Iteration 851500, lr = 0.01
I0829 23:41:11.235682 916722 solver.cpp:218] Iteration 852000 (16.6965 iter/s, 29.9464s/500 iters), loss = 0.138639
I0829 23:41:11.235738 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.138645 (* 1 = 0.138645 loss)
I0829 23:41:11.235745 916722 sgd_solver.cpp:106] Iteration 852000, lr = 0.01
I0829 23:41:41.165141 916722 solver.cpp:218] Iteration 852500 (16.7061 iter/s, 29.9292s/500 iters), loss = 0.0861258
I0829 23:41:41.165192 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0861318 (* 1 = 0.0861318 loss)
I0829 23:41:41.165202 916722 sgd_solver.cpp:106] Iteration 852500, lr = 0.01
I0829 23:42:11.107298 916722 solver.cpp:218] Iteration 853000 (16.699 iter/s, 29.9419s/500 iters), loss = 0.401818
I0829 23:42:11.107355 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.401824 (* 1 = 0.401824 loss)
I0829 23:42:11.107363 916722 sgd_solver.cpp:106] Iteration 853000, lr = 0.01
I0829 23:42:41.065184 916722 solver.cpp:218] Iteration 853500 (16.6902 iter/s, 29.9576s/500 iters), loss = 0.281198
I0829 23:42:41.065237 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.281204 (* 1 = 0.281204 loss)
I0829 23:42:41.065246 916722 sgd_solver.cpp:106] Iteration 853500, lr = 0.01
I0829 23:43:11.026152 916722 solver.cpp:218] Iteration 854000 (16.6885 iter/s, 29.9607s/500 iters), loss = 0.272715
I0829 23:43:11.026208 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.272721 (* 1 = 0.272721 loss)
I0829 23:43:11.026217 916722 sgd_solver.cpp:106] Iteration 854000, lr = 0.01
I0829 23:43:40.975435 916722 solver.cpp:218] Iteration 854500 (16.695 iter/s, 29.9491s/500 iters), loss = 0.0451604
I0829 23:43:40.975486 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0451667 (* 1 = 0.0451667 loss)
I0829 23:43:40.975497 916722 sgd_solver.cpp:106] Iteration 854500, lr = 0.01
I0829 23:44:10.933049 916722 solver.cpp:218] Iteration 855000 (16.6904 iter/s, 29.9574s/500 iters), loss = 0.162168
I0829 23:44:10.933101 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.162174 (* 1 = 0.162174 loss)
I0829 23:44:10.933110 916722 sgd_solver.cpp:106] Iteration 855000, lr = 0.01
I0829 23:44:40.898772 916722 solver.cpp:218] Iteration 855500 (16.6858 iter/s, 29.9655s/500 iters), loss = 0.196849
I0829 23:44:40.898820 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.196855 (* 1 = 0.196855 loss)
I0829 23:44:40.898829 916722 sgd_solver.cpp:106] Iteration 855500, lr = 0.01
I0829 23:45:10.846576 916722 solver.cpp:218] Iteration 856000 (16.6958 iter/s, 29.9476s/500 iters), loss = 0.0483996
I0829 23:45:10.846633 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0484056 (* 1 = 0.0484056 loss)
I0829 23:45:10.846642 916722 sgd_solver.cpp:106] Iteration 856000, lr = 0.01
I0829 23:45:40.796918 916722 solver.cpp:218] Iteration 856500 (16.6944 iter/s, 29.9501s/500 iters), loss = 0.363628
I0829 23:45:40.796969 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.363635 (* 1 = 0.363635 loss)
I0829 23:45:40.796980 916722 sgd_solver.cpp:106] Iteration 856500, lr = 0.01
I0829 23:46:10.741044 916722 solver.cpp:218] Iteration 857000 (16.6979 iter/s, 29.9439s/500 iters), loss = 0.0932646
I0829 23:46:10.741099 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0932705 (* 1 = 0.0932705 loss)
I0829 23:46:10.741108 916722 sgd_solver.cpp:106] Iteration 857000, lr = 0.01
I0829 23:46:40.696007 916722 solver.cpp:218] Iteration 857500 (16.6918 iter/s, 29.9548s/500 iters), loss = 0.23247
I0829 23:46:40.696058 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.232476 (* 1 = 0.232476 loss)
I0829 23:46:40.696079 916722 sgd_solver.cpp:106] Iteration 857500, lr = 0.01
I0829 23:47:10.645727 916722 solver.cpp:218] Iteration 858000 (16.6947 iter/s, 29.9495s/500 iters), loss = 0.0941081
I0829 23:47:10.645794 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0941142 (* 1 = 0.0941142 loss)
I0829 23:47:10.645813 916722 sgd_solver.cpp:106] Iteration 858000, lr = 0.01
I0829 23:47:40.586803 916722 solver.cpp:218] Iteration 858500 (16.6996 iter/s, 29.9409s/500 iters), loss = 0.114143
I0829 23:47:40.586856 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.114149 (* 1 = 0.114149 loss)
I0829 23:47:40.586866 916722 sgd_solver.cpp:106] Iteration 858500, lr = 0.01
I0829 23:48:10.522619 916722 solver.cpp:218] Iteration 859000 (16.7025 iter/s, 29.9356s/500 iters), loss = 0.152916
I0829 23:48:10.522675 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152923 (* 1 = 0.152923 loss)
I0829 23:48:10.522683 916722 sgd_solver.cpp:106] Iteration 859000, lr = 0.01
I0829 23:48:40.468071 916722 solver.cpp:218] Iteration 859500 (16.6971 iter/s, 29.9453s/500 iters), loss = 0.0782494
I0829 23:48:40.468120 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0782557 (* 1 = 0.0782557 loss)
I0829 23:48:40.468130 916722 sgd_solver.cpp:106] Iteration 859500, lr = 0.01
I0829 23:49:10.405566 916722 solver.cpp:218] Iteration 860000 (16.7016 iter/s, 29.9373s/500 iters), loss = 0.165296
I0829 23:49:10.405617 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.165302 (* 1 = 0.165302 loss)
I0829 23:49:10.405625 916722 sgd_solver.cpp:106] Iteration 860000, lr = 0.01
I0829 23:49:40.342267 916722 solver.cpp:218] Iteration 860500 (16.702 iter/s, 29.9365s/500 iters), loss = 0.258275
I0829 23:49:40.342319 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.258281 (* 1 = 0.258281 loss)
I0829 23:49:40.342329 916722 sgd_solver.cpp:106] Iteration 860500, lr = 0.01
I0829 23:50:10.290773 916722 solver.cpp:218] Iteration 861000 (16.6954 iter/s, 29.9483s/500 iters), loss = 0.0972328
I0829 23:50:10.290834 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0972389 (* 1 = 0.0972389 loss)
I0829 23:50:10.290843 916722 sgd_solver.cpp:106] Iteration 861000, lr = 0.01
I0829 23:50:40.223449 916722 solver.cpp:218] Iteration 861500 (16.7042 iter/s, 29.9325s/500 iters), loss = 0.105016
I0829 23:50:40.223505 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105023 (* 1 = 0.105023 loss)
I0829 23:50:40.223515 916722 sgd_solver.cpp:106] Iteration 861500, lr = 0.01
I0829 23:51:10.167569 916722 solver.cpp:218] Iteration 862000 (16.6978 iter/s, 29.944s/500 iters), loss = 0.0612134
I0829 23:51:10.167627 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0612194 (* 1 = 0.0612194 loss)
I0829 23:51:10.167635 916722 sgd_solver.cpp:106] Iteration 862000, lr = 0.01
I0829 23:51:40.113878 916722 solver.cpp:218] Iteration 862500 (16.6966 iter/s, 29.9462s/500 iters), loss = 0.0753464
I0829 23:51:40.113929 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0753524 (* 1 = 0.0753524 loss)
I0829 23:51:40.113937 916722 sgd_solver.cpp:106] Iteration 862500, lr = 0.01
I0829 23:52:10.053437 916722 solver.cpp:218] Iteration 863000 (16.7004 iter/s, 29.9394s/500 iters), loss = 0.121163
I0829 23:52:10.053493 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.121169 (* 1 = 0.121169 loss)
I0829 23:52:10.053501 916722 sgd_solver.cpp:106] Iteration 863000, lr = 0.01
I0829 23:52:39.982652 916722 solver.cpp:218] Iteration 863500 (16.7062 iter/s, 29.9291s/500 iters), loss = 0.203429
I0829 23:52:39.982703 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.203435 (* 1 = 0.203435 loss)
I0829 23:52:39.982712 916722 sgd_solver.cpp:106] Iteration 863500, lr = 0.01
I0829 23:53:09.916594 916722 solver.cpp:218] Iteration 864000 (16.7035 iter/s, 29.9338s/500 iters), loss = 0.162108
I0829 23:53:09.916666 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.162114 (* 1 = 0.162114 loss)
I0829 23:53:09.916676 916722 sgd_solver.cpp:106] Iteration 864000, lr = 0.01
I0829 23:53:39.835877 916722 solver.cpp:218] Iteration 864500 (16.7117 iter/s, 29.9191s/500 iters), loss = 0.137795
I0829 23:53:39.835922 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.137801 (* 1 = 0.137801 loss)
I0829 23:53:39.835932 916722 sgd_solver.cpp:106] Iteration 864500, lr = 0.01
I0829 23:54:09.761032 916722 solver.cpp:218] Iteration 865000 (16.7084 iter/s, 29.925s/500 iters), loss = 0.0229684
I0829 23:54:09.761090 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0229745 (* 1 = 0.0229745 loss)
I0829 23:54:09.761098 916722 sgd_solver.cpp:106] Iteration 865000, lr = 0.01
I0829 23:54:39.678654 916722 solver.cpp:218] Iteration 865500 (16.7126 iter/s, 29.9175s/500 iters), loss = 0.119335
I0829 23:54:39.678705 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.119342 (* 1 = 0.119342 loss)
I0829 23:54:39.678714 916722 sgd_solver.cpp:106] Iteration 865500, lr = 0.01
I0829 23:55:09.605285 916722 solver.cpp:218] Iteration 866000 (16.7076 iter/s, 29.9265s/500 iters), loss = 0.0865434
I0829 23:55:09.605342 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0865497 (* 1 = 0.0865497 loss)
I0829 23:55:09.605351 916722 sgd_solver.cpp:106] Iteration 866000, lr = 0.01
I0829 23:55:39.531507 916722 solver.cpp:218] Iteration 866500 (16.7078 iter/s, 29.9261s/500 iters), loss = 0.163768
I0829 23:55:39.531559 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.163775 (* 1 = 0.163775 loss)
I0829 23:55:39.531569 916722 sgd_solver.cpp:106] Iteration 866500, lr = 0.01
I0829 23:56:09.451961 916722 solver.cpp:218] Iteration 867000 (16.711 iter/s, 29.9203s/500 iters), loss = 0.236298
I0829 23:56:09.452015 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.236304 (* 1 = 0.236304 loss)
I0829 23:56:09.452024 916722 sgd_solver.cpp:106] Iteration 867000, lr = 0.01
I0829 23:56:39.395596 916722 solver.cpp:218] Iteration 867500 (16.6981 iter/s, 29.9435s/500 iters), loss = 0.463638
I0829 23:56:39.395648 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.463645 (* 1 = 0.463645 loss)
I0829 23:56:39.395658 916722 sgd_solver.cpp:106] Iteration 867500, lr = 0.01
I0829 23:57:09.301416 916722 solver.cpp:218] Iteration 868000 (16.7192 iter/s, 29.9057s/500 iters), loss = 0.151514
I0829 23:57:09.301472 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.15152 (* 1 = 0.15152 loss)
I0829 23:57:09.301481 916722 sgd_solver.cpp:106] Iteration 868000, lr = 0.01
I0829 23:57:39.221208 916722 solver.cpp:218] Iteration 868500 (16.7114 iter/s, 29.9197s/500 iters), loss = 0.186556
I0829 23:57:39.221257 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.186563 (* 1 = 0.186563 loss)
I0829 23:57:39.221267 916722 sgd_solver.cpp:106] Iteration 868500, lr = 0.01
I0829 23:58:09.119885 916722 solver.cpp:218] Iteration 869000 (16.7232 iter/s, 29.8986s/500 iters), loss = 0.0380629
I0829 23:58:09.119942 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0380691 (* 1 = 0.0380691 loss)
I0829 23:58:09.119951 916722 sgd_solver.cpp:106] Iteration 869000, lr = 0.01
I0829 23:58:39.022248 916722 solver.cpp:218] Iteration 869500 (16.7212 iter/s, 29.9022s/500 iters), loss = 0.0281621
I0829 23:58:39.022302 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0281683 (* 1 = 0.0281683 loss)
I0829 23:58:39.022312 916722 sgd_solver.cpp:106] Iteration 869500, lr = 0.01
I0829 23:59:08.917760 916722 solver.cpp:218] Iteration 870000 (16.725 iter/s, 29.8954s/500 iters), loss = 0.0661803
I0829 23:59:08.917819 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0661865 (* 1 = 0.0661865 loss)
I0829 23:59:08.917826 916722 sgd_solver.cpp:106] Iteration 870000, lr = 0.01
I0829 23:59:38.820524 916722 solver.cpp:218] Iteration 870500 (16.7209 iter/s, 29.9026s/500 iters), loss = 0.161568
I0829 23:59:38.820576 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.161574 (* 1 = 0.161574 loss)
I0829 23:59:38.820586 916722 sgd_solver.cpp:106] Iteration 870500, lr = 0.01
I0830 00:00:08.711596 916722 solver.cpp:218] Iteration 871000 (16.7275 iter/s, 29.8909s/500 iters), loss = 0.246927
I0830 00:00:08.711665 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.246933 (* 1 = 0.246933 loss)
I0830 00:00:08.711673 916722 sgd_solver.cpp:106] Iteration 871000, lr = 0.01
I0830 00:00:38.627022 916722 solver.cpp:218] Iteration 871500 (16.7139 iter/s, 29.9153s/500 iters), loss = 0.234179
I0830 00:00:38.627074 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.234185 (* 1 = 0.234185 loss)
I0830 00:00:38.627082 916722 sgd_solver.cpp:106] Iteration 871500, lr = 0.01
I0830 00:01:08.535110 916722 solver.cpp:218] Iteration 872000 (16.7179 iter/s, 29.908s/500 iters), loss = 0.147853
I0830 00:01:08.535173 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.147859 (* 1 = 0.147859 loss)
I0830 00:01:08.535181 916722 sgd_solver.cpp:106] Iteration 872000, lr = 0.01
I0830 00:01:38.435760 916722 solver.cpp:218] Iteration 872500 (16.7221 iter/s, 29.9005s/500 iters), loss = 0.238873
I0830 00:01:38.435811 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.238879 (* 1 = 0.238879 loss)
I0830 00:01:38.435820 916722 sgd_solver.cpp:106] Iteration 872500, lr = 0.01
I0830 00:02:08.342680 916722 solver.cpp:218] Iteration 873000 (16.7186 iter/s, 29.9068s/500 iters), loss = 0.122585
I0830 00:02:08.342737 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.122591 (* 1 = 0.122591 loss)
I0830 00:02:08.342746 916722 sgd_solver.cpp:106] Iteration 873000, lr = 0.01
I0830 00:02:38.260282 916722 solver.cpp:218] Iteration 873500 (16.7126 iter/s, 29.9175s/500 iters), loss = 0.197145
I0830 00:02:38.260337 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.197151 (* 1 = 0.197151 loss)
I0830 00:02:38.260346 916722 sgd_solver.cpp:106] Iteration 873500, lr = 0.01
I0830 00:03:08.187288 916722 solver.cpp:218] Iteration 874000 (16.7074 iter/s, 29.9269s/500 iters), loss = 0.192103
I0830 00:03:08.187350 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.192109 (* 1 = 0.192109 loss)
I0830 00:03:08.187359 916722 sgd_solver.cpp:106] Iteration 874000, lr = 0.01
I0830 00:03:38.111907 916722 solver.cpp:218] Iteration 874500 (16.7087 iter/s, 29.9245s/500 iters), loss = 0.153714
I0830 00:03:38.111961 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.15372 (* 1 = 0.15372 loss)
I0830 00:03:38.111969 916722 sgd_solver.cpp:106] Iteration 874500, lr = 0.01
I0830 00:04:08.023478 916722 solver.cpp:218] Iteration 875000 (16.716 iter/s, 29.9115s/500 iters), loss = 0.0746559
I0830 00:04:08.023538 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.074662 (* 1 = 0.074662 loss)
I0830 00:04:08.023546 916722 sgd_solver.cpp:106] Iteration 875000, lr = 0.01
I0830 00:04:37.941845 916722 solver.cpp:218] Iteration 875500 (16.7122 iter/s, 29.9182s/500 iters), loss = 0.162534
I0830 00:04:37.941897 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.162541 (* 1 = 0.162541 loss)
I0830 00:04:37.941905 916722 sgd_solver.cpp:106] Iteration 875500, lr = 0.01
I0830 00:05:07.867048 916722 solver.cpp:218] Iteration 876000 (16.7084 iter/s, 29.9251s/500 iters), loss = 0.141182
I0830 00:05:07.867107 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.141188 (* 1 = 0.141188 loss)
I0830 00:05:07.867116 916722 sgd_solver.cpp:106] Iteration 876000, lr = 0.01
I0830 00:05:37.778940 916722 solver.cpp:218] Iteration 876500 (16.7158 iter/s, 29.9118s/500 iters), loss = 0.157194
I0830 00:05:37.778996 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.157201 (* 1 = 0.157201 loss)
I0830 00:05:37.779006 916722 sgd_solver.cpp:106] Iteration 876500, lr = 0.01
I0830 00:06:07.676996 916722 solver.cpp:218] Iteration 877000 (16.7236 iter/s, 29.8979s/500 iters), loss = 0.169953
I0830 00:06:07.677052 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.169959 (* 1 = 0.169959 loss)
I0830 00:06:07.677062 916722 sgd_solver.cpp:106] Iteration 877000, lr = 0.01
I0830 00:06:37.573705 916722 solver.cpp:218] Iteration 877500 (16.7243 iter/s, 29.8966s/500 iters), loss = 0.180334
I0830 00:06:37.573773 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.180341 (* 1 = 0.180341 loss)
I0830 00:06:37.573783 916722 sgd_solver.cpp:106] Iteration 877500, lr = 0.01
I0830 00:07:07.453464 916722 solver.cpp:218] Iteration 878000 (16.7338 iter/s, 29.8796s/500 iters), loss = 0.0499906
I0830 00:07:07.453531 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0499969 (* 1 = 0.0499969 loss)
I0830 00:07:07.453539 916722 sgd_solver.cpp:106] Iteration 878000, lr = 0.01
I0830 00:07:37.337937 916722 solver.cpp:218] Iteration 878500 (16.7312 iter/s, 29.8844s/500 iters), loss = 0.25754
I0830 00:07:37.337988 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.257546 (* 1 = 0.257546 loss)
I0830 00:07:37.337998 916722 sgd_solver.cpp:106] Iteration 878500, lr = 0.01
I0830 00:08:07.231520 916722 solver.cpp:218] Iteration 879000 (16.7261 iter/s, 29.8935s/500 iters), loss = 0.115062
I0830 00:08:07.231580 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115068 (* 1 = 0.115068 loss)
I0830 00:08:07.231587 916722 sgd_solver.cpp:106] Iteration 879000, lr = 0.01
I0830 00:08:37.108176 916722 solver.cpp:218] Iteration 879500 (16.7355 iter/s, 29.8765s/500 iters), loss = 0.288675
I0830 00:08:37.108227 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.288682 (* 1 = 0.288682 loss)
I0830 00:08:37.108237 916722 sgd_solver.cpp:106] Iteration 879500, lr = 0.01
I0830 00:09:06.986037 916722 solver.cpp:218] Iteration 880000 (16.7349 iter/s, 29.8777s/500 iters), loss = 0.188234
I0830 00:09:06.986094 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.188241 (* 1 = 0.188241 loss)
I0830 00:09:06.986102 916722 sgd_solver.cpp:106] Iteration 880000, lr = 0.01
I0830 00:09:36.867506 916722 solver.cpp:218] Iteration 880500 (16.7328 iter/s, 29.8814s/500 iters), loss = 0.135874
I0830 00:09:36.867559 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.135881 (* 1 = 0.135881 loss)
I0830 00:09:36.867569 916722 sgd_solver.cpp:106] Iteration 880500, lr = 0.01
I0830 00:10:06.760241 916722 solver.cpp:218] Iteration 881000 (16.7265 iter/s, 29.8926s/500 iters), loss = 0.0879118
I0830 00:10:06.760298 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0879183 (* 1 = 0.0879183 loss)
I0830 00:10:06.760306 916722 sgd_solver.cpp:106] Iteration 881000, lr = 0.01
I0830 00:10:36.672188 916722 solver.cpp:218] Iteration 881500 (16.7158 iter/s, 29.9118s/500 iters), loss = 0.149362
I0830 00:10:36.672240 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.149369 (* 1 = 0.149369 loss)
I0830 00:10:36.672250 916722 sgd_solver.cpp:106] Iteration 881500, lr = 0.01
I0830 00:11:06.547293 916722 solver.cpp:218] Iteration 882000 (16.7364 iter/s, 29.875s/500 iters), loss = 0.0511773
I0830 00:11:06.547353 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.051184 (* 1 = 0.051184 loss)
I0830 00:11:06.547361 916722 sgd_solver.cpp:106] Iteration 882000, lr = 0.01
I0830 00:11:36.425843 916722 solver.cpp:218] Iteration 882500 (16.7345 iter/s, 29.8785s/500 iters), loss = 0.220074
I0830 00:11:36.425894 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.22008 (* 1 = 0.22008 loss)
I0830 00:11:36.425902 916722 sgd_solver.cpp:106] Iteration 882500, lr = 0.01
I0830 00:12:06.337311 916722 solver.cpp:218] Iteration 883000 (16.716 iter/s, 29.9114s/500 iters), loss = 0.20883
I0830 00:12:06.337371 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.208836 (* 1 = 0.208836 loss)
I0830 00:12:06.337379 916722 sgd_solver.cpp:106] Iteration 883000, lr = 0.01
I0830 00:12:36.225919 916722 solver.cpp:218] Iteration 883500 (16.7288 iter/s, 29.8885s/500 iters), loss = 0.246907
I0830 00:12:36.225973 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.246913 (* 1 = 0.246913 loss)
I0830 00:12:36.225982 916722 sgd_solver.cpp:106] Iteration 883500, lr = 0.01
I0830 00:13:06.122423 916722 solver.cpp:218] Iteration 884000 (16.7244 iter/s, 29.8964s/500 iters), loss = 0.151986
I0830 00:13:06.122494 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.151993 (* 1 = 0.151993 loss)
I0830 00:13:06.122524 916722 sgd_solver.cpp:106] Iteration 884000, lr = 0.01
I0830 00:13:36.030894 916722 solver.cpp:218] Iteration 884500 (16.7177 iter/s, 29.9084s/500 iters), loss = 0.0658215
I0830 00:13:36.030946 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0658282 (* 1 = 0.0658282 loss)
I0830 00:13:36.030953 916722 sgd_solver.cpp:106] Iteration 884500, lr = 0.01
I0830 00:14:05.951481 916722 solver.cpp:218] Iteration 885000 (16.7109 iter/s, 29.9205s/500 iters), loss = 0.0817661
I0830 00:14:05.951540 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0817728 (* 1 = 0.0817728 loss)
I0830 00:14:05.951550 916722 sgd_solver.cpp:106] Iteration 885000, lr = 0.01
I0830 00:14:35.885149 916722 solver.cpp:218] Iteration 885500 (16.7036 iter/s, 29.9336s/500 iters), loss = 0.153831
I0830 00:14:35.885200 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.153838 (* 1 = 0.153838 loss)
I0830 00:14:35.885207 916722 sgd_solver.cpp:106] Iteration 885500, lr = 0.01
I0830 00:15:05.853047 916722 solver.cpp:218] Iteration 886000 (16.6846 iter/s, 29.9678s/500 iters), loss = 0.145431
I0830 00:15:05.853109 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.145437 (* 1 = 0.145437 loss)
I0830 00:15:05.853118 916722 sgd_solver.cpp:106] Iteration 886000, lr = 0.01
I0830 00:15:35.821732 916722 solver.cpp:218] Iteration 886500 (16.6841 iter/s, 29.9686s/500 iters), loss = 0.274639
I0830 00:15:35.821781 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.274645 (* 1 = 0.274645 loss)
I0830 00:15:35.821789 916722 sgd_solver.cpp:106] Iteration 886500, lr = 0.01
I0830 00:16:05.784229 916722 solver.cpp:218] Iteration 887000 (16.6876 iter/s, 29.9624s/500 iters), loss = 0.220548
I0830 00:16:05.784291 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.220555 (* 1 = 0.220555 loss)
I0830 00:16:05.784299 916722 sgd_solver.cpp:106] Iteration 887000, lr = 0.01
I0830 00:16:35.752599 916722 solver.cpp:218] Iteration 887500 (16.6843 iter/s, 29.9683s/500 iters), loss = 0.192899
I0830 00:16:35.752653 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.192905 (* 1 = 0.192905 loss)
I0830 00:16:35.752665 916722 sgd_solver.cpp:106] Iteration 887500, lr = 0.01
I0830 00:17:05.720950 916722 solver.cpp:218] Iteration 888000 (16.6843 iter/s, 29.9683s/500 iters), loss = 0.0359952
I0830 00:17:05.721009 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.036002 (* 1 = 0.036002 loss)
I0830 00:17:05.721017 916722 sgd_solver.cpp:106] Iteration 888000, lr = 0.01
I0830 00:17:35.667389 916722 solver.cpp:218] Iteration 888500 (16.6965 iter/s, 29.9464s/500 iters), loss = 0.0988149
I0830 00:17:35.667441 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0988219 (* 1 = 0.0988219 loss)
I0830 00:17:35.667451 916722 sgd_solver.cpp:106] Iteration 888500, lr = 0.01
I0830 00:18:05.603857 916722 solver.cpp:218] Iteration 889000 (16.7021 iter/s, 29.9364s/500 iters), loss = 0.17496
I0830 00:18:05.603916 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.174967 (* 1 = 0.174967 loss)
I0830 00:18:05.603925 916722 sgd_solver.cpp:106] Iteration 889000, lr = 0.01
I0830 00:18:35.542492 916722 solver.cpp:218] Iteration 889500 (16.7009 iter/s, 29.9386s/500 iters), loss = 0.104914
I0830 00:18:35.542544 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104921 (* 1 = 0.104921 loss)
I0830 00:18:35.542554 916722 sgd_solver.cpp:106] Iteration 889500, lr = 0.01
I0830 00:19:05.500231 916722 solver.cpp:218] Iteration 890000 (16.6902 iter/s, 29.9577s/500 iters), loss = 0.107648
I0830 00:19:05.500290 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.107655 (* 1 = 0.107655 loss)
I0830 00:19:05.500299 916722 sgd_solver.cpp:106] Iteration 890000, lr = 0.01
I0830 00:19:35.447119 916722 solver.cpp:218] Iteration 890500 (16.6963 iter/s, 29.9468s/500 iters), loss = 0.0979872
I0830 00:19:35.447171 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0979943 (* 1 = 0.0979943 loss)
I0830 00:19:35.447194 916722 sgd_solver.cpp:106] Iteration 890500, lr = 0.01
I0830 00:20:05.409042 916722 solver.cpp:218] Iteration 891000 (16.6879 iter/s, 29.9618s/500 iters), loss = 0.216879
I0830 00:20:05.409111 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.216886 (* 1 = 0.216886 loss)
I0830 00:20:05.409134 916722 sgd_solver.cpp:106] Iteration 891000, lr = 0.01
I0830 00:20:35.382915 916722 solver.cpp:218] Iteration 891500 (16.6812 iter/s, 29.9738s/500 iters), loss = 0.143905
I0830 00:20:35.382966 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.143912 (* 1 = 0.143912 loss)
I0830 00:20:35.382975 916722 sgd_solver.cpp:106] Iteration 891500, lr = 0.01
I0830 00:21:05.357427 916722 solver.cpp:218] Iteration 892000 (16.6809 iter/s, 29.9744s/500 iters), loss = 0.0959138
I0830 00:21:05.357491 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0959207 (* 1 = 0.0959207 loss)
I0830 00:21:05.357501 916722 sgd_solver.cpp:106] Iteration 892000, lr = 0.01
I0830 00:21:35.324097 916722 solver.cpp:218] Iteration 892500 (16.6853 iter/s, 29.9666s/500 iters), loss = 0.119389
I0830 00:21:35.324151 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.119396 (* 1 = 0.119396 loss)
I0830 00:21:35.324159 916722 sgd_solver.cpp:106] Iteration 892500, lr = 0.01
I0830 00:22:05.285655 916722 solver.cpp:218] Iteration 893000 (16.6881 iter/s, 29.9615s/500 iters), loss = 0.107317
I0830 00:22:05.285714 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.107323 (* 1 = 0.107323 loss)
I0830 00:22:05.285722 916722 sgd_solver.cpp:106] Iteration 893000, lr = 0.01
I0830 00:22:35.252831 916722 solver.cpp:218] Iteration 893500 (16.685 iter/s, 29.9671s/500 iters), loss = 0.432265
I0830 00:22:35.252883 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.432271 (* 1 = 0.432271 loss)
I0830 00:22:35.252892 916722 sgd_solver.cpp:106] Iteration 893500, lr = 0.01
I0830 00:23:05.179472 916722 solver.cpp:218] Iteration 894000 (16.7076 iter/s, 29.9266s/500 iters), loss = 0.142893
I0830 00:23:05.179533 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.1429 (* 1 = 0.1429 loss)
I0830 00:23:05.179541 916722 sgd_solver.cpp:106] Iteration 894000, lr = 0.01
I0830 00:23:35.091027 916722 solver.cpp:218] Iteration 894500 (16.716 iter/s, 29.9115s/500 iters), loss = 0.430192
I0830 00:23:35.091082 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.430198 (* 1 = 0.430198 loss)
I0830 00:23:35.091091 916722 sgd_solver.cpp:106] Iteration 894500, lr = 0.01
I0830 00:24:04.989333 916722 solver.cpp:218] Iteration 895000 (16.7234 iter/s, 29.8982s/500 iters), loss = 0.299738
I0830 00:24:04.989392 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.299745 (* 1 = 0.299745 loss)
I0830 00:24:04.989401 916722 sgd_solver.cpp:106] Iteration 895000, lr = 0.01
I0830 00:24:34.885278 916722 solver.cpp:218] Iteration 895500 (16.7247 iter/s, 29.8958s/500 iters), loss = 0.132778
I0830 00:24:34.885330 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.132785 (* 1 = 0.132785 loss)
I0830 00:24:34.885339 916722 sgd_solver.cpp:106] Iteration 895500, lr = 0.01
I0830 00:25:04.783303 916722 solver.cpp:218] Iteration 896000 (16.7236 iter/s, 29.8979s/500 iters), loss = 0.14572
I0830 00:25:04.783361 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.145726 (* 1 = 0.145726 loss)
I0830 00:25:04.783370 916722 sgd_solver.cpp:106] Iteration 896000, lr = 0.01
I0830 00:25:34.705421 916722 solver.cpp:218] Iteration 896500 (16.7101 iter/s, 29.922s/500 iters), loss = 0.202654
I0830 00:25:34.705473 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.202661 (* 1 = 0.202661 loss)
I0830 00:25:34.705482 916722 sgd_solver.cpp:106] Iteration 896500, lr = 0.01
I0830 00:26:04.637188 916722 solver.cpp:218] Iteration 897000 (16.7047 iter/s, 29.9317s/500 iters), loss = 0.0807704
I0830 00:26:04.637248 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0807767 (* 1 = 0.0807767 loss)
I0830 00:26:04.637256 916722 sgd_solver.cpp:106] Iteration 897000, lr = 0.01
I0830 00:26:34.561785 916722 solver.cpp:218] Iteration 897500 (16.7087 iter/s, 29.9245s/500 iters), loss = 0.0944925
I0830 00:26:34.561838 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0944989 (* 1 = 0.0944989 loss)
I0830 00:26:34.561847 916722 sgd_solver.cpp:106] Iteration 897500, lr = 0.01
I0830 00:27:04.494657 916722 solver.cpp:218] Iteration 898000 (16.7041 iter/s, 29.9328s/500 iters), loss = 0.206602
I0830 00:27:04.494724 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.206608 (* 1 = 0.206608 loss)
I0830 00:27:04.494732 916722 sgd_solver.cpp:106] Iteration 898000, lr = 0.01
I0830 00:27:34.452646 916722 solver.cpp:218] Iteration 898500 (16.6901 iter/s, 29.9579s/500 iters), loss = 0.0735105
I0830 00:27:34.452698 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0735169 (* 1 = 0.0735169 loss)
I0830 00:27:34.452708 916722 sgd_solver.cpp:106] Iteration 898500, lr = 0.01
I0830 00:28:04.411918 916722 solver.cpp:218] Iteration 899000 (16.6894 iter/s, 29.9592s/500 iters), loss = 0.060972
I0830 00:28:04.411976 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0609786 (* 1 = 0.0609786 loss)
I0830 00:28:04.411984 916722 sgd_solver.cpp:106] Iteration 899000, lr = 0.01
I0830 00:28:34.372224 916722 solver.cpp:218] Iteration 899500 (16.6888 iter/s, 29.9602s/500 iters), loss = 0.0182667
I0830 00:28:34.372277 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0182732 (* 1 = 0.0182732 loss)
I0830 00:28:34.372284 916722 sgd_solver.cpp:106] Iteration 899500, lr = 0.01
I0830 00:29:04.294852 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_900000.caffemodel
I0830 00:29:04.314208 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_900000.solverstate
I0830 00:29:04.320480 916722 solver.cpp:330] Iteration 900000, Testing net (#0)
I0830 00:29:19.794077 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8403
I0830 00:29:19.794118 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.518675 (* 1 = 0.518675 loss)
I0830 00:29:19.853055 916722 solver.cpp:218] Iteration 900000 (10.9937 iter/s, 45.4807s/500 iters), loss = 0.0607386
I0830 00:29:19.853083 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.060745 (* 1 = 0.060745 loss)
I0830 00:29:19.853091 916722 sgd_solver.cpp:106] Iteration 900000, lr = 0.01
I0830 00:29:49.692433 916722 solver.cpp:218] Iteration 900500 (16.7564 iter/s, 29.8393s/500 iters), loss = 0.0561913
I0830 00:29:49.692494 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0561979 (* 1 = 0.0561979 loss)
I0830 00:29:49.692502 916722 sgd_solver.cpp:106] Iteration 900500, lr = 0.01
I0830 00:30:19.630905 916722 solver.cpp:218] Iteration 901000 (16.701 iter/s, 29.9384s/500 iters), loss = 0.462868
I0830 00:30:19.630957 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.462875 (* 1 = 0.462875 loss)
I0830 00:30:19.630966 916722 sgd_solver.cpp:106] Iteration 901000, lr = 0.01
I0830 00:30:49.614842 916722 solver.cpp:218] Iteration 901500 (16.6756 iter/s, 29.9839s/500 iters), loss = 0.431058
I0830 00:30:49.614904 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.431065 (* 1 = 0.431065 loss)
I0830 00:30:49.614913 916722 sgd_solver.cpp:106] Iteration 901500, lr = 0.01
I0830 00:31:19.594570 916722 solver.cpp:218] Iteration 902000 (16.678 iter/s, 29.9796s/500 iters), loss = 0.248037
I0830 00:31:19.594624 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.248044 (* 1 = 0.248044 loss)
I0830 00:31:19.594632 916722 sgd_solver.cpp:106] Iteration 902000, lr = 0.01
I0830 00:31:49.571671 916722 solver.cpp:218] Iteration 902500 (16.6794 iter/s, 29.977s/500 iters), loss = 0.0284661
I0830 00:31:49.571730 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0284729 (* 1 = 0.0284729 loss)
I0830 00:31:49.571739 916722 sgd_solver.cpp:106] Iteration 902500, lr = 0.01
I0830 00:32:19.547120 916722 solver.cpp:218] Iteration 903000 (16.6804 iter/s, 29.9754s/500 iters), loss = 0.145098
I0830 00:32:19.547185 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.145105 (* 1 = 0.145105 loss)
I0830 00:32:19.547194 916722 sgd_solver.cpp:106] Iteration 903000, lr = 0.01
I0830 00:32:49.525903 916722 solver.cpp:218] Iteration 903500 (16.6785 iter/s, 29.9787s/500 iters), loss = 0.136881
I0830 00:32:49.525970 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.136887 (* 1 = 0.136887 loss)
I0830 00:32:49.525979 916722 sgd_solver.cpp:106] Iteration 903500, lr = 0.01
I0830 00:33:19.500931 916722 solver.cpp:218] Iteration 904000 (16.6806 iter/s, 29.9749s/500 iters), loss = 0.0978506
I0830 00:33:19.500986 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0978575 (* 1 = 0.0978575 loss)
I0830 00:33:19.500996 916722 sgd_solver.cpp:106] Iteration 904000, lr = 0.01
I0830 00:33:49.487809 916722 solver.cpp:218] Iteration 904500 (16.674 iter/s, 29.9868s/500 iters), loss = 0.171668
I0830 00:33:49.487866 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.171674 (* 1 = 0.171674 loss)
I0830 00:33:49.487874 916722 sgd_solver.cpp:106] Iteration 904500, lr = 0.01
I0830 00:34:19.468387 916722 solver.cpp:218] Iteration 905000 (16.6775 iter/s, 29.9805s/500 iters), loss = 0.00695179
I0830 00:34:19.468446 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.00695885 (* 1 = 0.00695885 loss)
I0830 00:34:19.468457 916722 sgd_solver.cpp:106] Iteration 905000, lr = 0.01
I0830 00:34:49.442895 916722 solver.cpp:218] Iteration 905500 (16.6809 iter/s, 29.9744s/500 iters), loss = 0.131503
I0830 00:34:49.442955 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13151 (* 1 = 0.13151 loss)
I0830 00:34:49.442965 916722 sgd_solver.cpp:106] Iteration 905500, lr = 0.01
I0830 00:35:19.415208 916722 solver.cpp:218] Iteration 906000 (16.6821 iter/s, 29.9722s/500 iters), loss = 0.134316
I0830 00:35:19.415262 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.134323 (* 1 = 0.134323 loss)
I0830 00:35:19.415272 916722 sgd_solver.cpp:106] Iteration 906000, lr = 0.01
I0830 00:35:49.377461 916722 solver.cpp:218] Iteration 906500 (16.6877 iter/s, 29.9622s/500 iters), loss = 0.214033
I0830 00:35:49.377521 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.21404 (* 1 = 0.21404 loss)
I0830 00:35:49.377529 916722 sgd_solver.cpp:106] Iteration 906500, lr = 0.01
I0830 00:36:19.358338 916722 solver.cpp:218] Iteration 907000 (16.6773 iter/s, 29.9808s/500 iters), loss = 0.0549779
I0830 00:36:19.358390 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0549849 (* 1 = 0.0549849 loss)
I0830 00:36:19.358402 916722 sgd_solver.cpp:106] Iteration 907000, lr = 0.01
I0830 00:36:49.318639 916722 solver.cpp:218] Iteration 907500 (16.6888 iter/s, 29.9602s/500 iters), loss = 0.172103
I0830 00:36:49.318698 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.17211 (* 1 = 0.17211 loss)
I0830 00:36:49.318707 916722 sgd_solver.cpp:106] Iteration 907500, lr = 0.01
I0830 00:37:19.300005 916722 solver.cpp:218] Iteration 908000 (16.6771 iter/s, 29.9813s/500 iters), loss = 0.123722
I0830 00:37:19.300060 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.123728 (* 1 = 0.123728 loss)
I0830 00:37:19.300071 916722 sgd_solver.cpp:106] Iteration 908000, lr = 0.01
I0830 00:37:49.266227 916722 solver.cpp:218] Iteration 908500 (16.6855 iter/s, 29.9661s/500 iters), loss = 0.0740675
I0830 00:37:49.266289 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0740744 (* 1 = 0.0740744 loss)
I0830 00:37:49.266297 916722 sgd_solver.cpp:106] Iteration 908500, lr = 0.01
I0830 00:38:19.266206 916722 solver.cpp:218] Iteration 909000 (16.6667 iter/s, 29.9999s/500 iters), loss = 0.321748
I0830 00:38:19.266255 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.321755 (* 1 = 0.321755 loss)
I0830 00:38:19.266263 916722 sgd_solver.cpp:106] Iteration 909000, lr = 0.01
I0830 00:38:49.212759 916722 solver.cpp:218] Iteration 909500 (16.6965 iter/s, 29.9465s/500 iters), loss = 0.0261864
I0830 00:38:49.212841 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0261937 (* 1 = 0.0261937 loss)
I0830 00:38:49.212859 916722 sgd_solver.cpp:106] Iteration 909500, lr = 0.01
I0830 00:39:19.175813 916722 solver.cpp:218] Iteration 910000 (16.6873 iter/s, 29.9629s/500 iters), loss = 0.0397362
I0830 00:39:19.175868 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0397435 (* 1 = 0.0397435 loss)
I0830 00:39:19.175876 916722 sgd_solver.cpp:106] Iteration 910000, lr = 0.01
I0830 00:39:49.118693 916722 solver.cpp:218] Iteration 910500 (16.6985 iter/s, 29.9428s/500 iters), loss = 0.148363
I0830 00:39:49.118754 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.148371 (* 1 = 0.148371 loss)
I0830 00:39:49.118763 916722 sgd_solver.cpp:106] Iteration 910500, lr = 0.01
I0830 00:40:19.065740 916722 solver.cpp:218] Iteration 911000 (16.6962 iter/s, 29.9469s/500 iters), loss = 0.317958
I0830 00:40:19.065794 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.317965 (* 1 = 0.317965 loss)
I0830 00:40:19.065804 916722 sgd_solver.cpp:106] Iteration 911000, lr = 0.01
I0830 00:40:49.007802 916722 solver.cpp:218] Iteration 911500 (16.699 iter/s, 29.942s/500 iters), loss = 0.248455
I0830 00:40:49.007863 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.248462 (* 1 = 0.248462 loss)
I0830 00:40:49.007872 916722 sgd_solver.cpp:106] Iteration 911500, lr = 0.01
I0830 00:41:18.951745 916722 solver.cpp:218] Iteration 912000 (16.6979 iter/s, 29.9438s/500 iters), loss = 0.237254
I0830 00:41:18.951798 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.237261 (* 1 = 0.237261 loss)
I0830 00:41:18.951807 916722 sgd_solver.cpp:106] Iteration 912000, lr = 0.01
I0830 00:41:48.888198 916722 solver.cpp:218] Iteration 912500 (16.7021 iter/s, 29.9364s/500 iters), loss = 0.24219
I0830 00:41:48.888258 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.242198 (* 1 = 0.242198 loss)
I0830 00:41:48.888267 916722 sgd_solver.cpp:106] Iteration 912500, lr = 0.01
I0830 00:42:18.829339 916722 solver.cpp:218] Iteration 913000 (16.6995 iter/s, 29.941s/500 iters), loss = 0.112704
I0830 00:42:18.829394 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112711 (* 1 = 0.112711 loss)
I0830 00:42:18.829406 916722 sgd_solver.cpp:106] Iteration 913000, lr = 0.01
I0830 00:42:48.781836 916722 solver.cpp:218] Iteration 913500 (16.6932 iter/s, 29.9524s/500 iters), loss = 0.128734
I0830 00:42:48.781893 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128742 (* 1 = 0.128742 loss)
I0830 00:42:48.781901 916722 sgd_solver.cpp:106] Iteration 913500, lr = 0.01
I0830 00:43:18.724969 916722 solver.cpp:218] Iteration 914000 (16.6984 iter/s, 29.943s/500 iters), loss = 0.355656
I0830 00:43:18.725020 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.355664 (* 1 = 0.355664 loss)
I0830 00:43:18.725030 916722 sgd_solver.cpp:106] Iteration 914000, lr = 0.01
I0830 00:43:48.679040 916722 solver.cpp:218] Iteration 914500 (16.6923 iter/s, 29.954s/500 iters), loss = 0.278347
I0830 00:43:48.679100 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.278354 (* 1 = 0.278354 loss)
I0830 00:43:48.679109 916722 sgd_solver.cpp:106] Iteration 914500, lr = 0.01
I0830 00:44:18.642184 916722 solver.cpp:218] Iteration 915000 (16.6872 iter/s, 29.9631s/500 iters), loss = 0.110554
I0830 00:44:18.642239 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110561 (* 1 = 0.110561 loss)
I0830 00:44:18.642249 916722 sgd_solver.cpp:106] Iteration 915000, lr = 0.01
I0830 00:44:48.603957 916722 solver.cpp:218] Iteration 915500 (16.688 iter/s, 29.9617s/500 iters), loss = 0.273181
I0830 00:44:48.604017 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.273189 (* 1 = 0.273189 loss)
I0830 00:44:48.604025 916722 sgd_solver.cpp:106] Iteration 915500, lr = 0.01
I0830 00:45:18.574968 916722 solver.cpp:218] Iteration 916000 (16.683 iter/s, 29.9706s/500 iters), loss = 0.188953
I0830 00:45:18.575034 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.188961 (* 1 = 0.188961 loss)
I0830 00:45:18.575045 916722 sgd_solver.cpp:106] Iteration 916000, lr = 0.01
I0830 00:45:48.542126 916722 solver.cpp:218] Iteration 916500 (16.6856 iter/s, 29.966s/500 iters), loss = 0.107954
I0830 00:45:48.542197 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.107961 (* 1 = 0.107961 loss)
I0830 00:45:48.542207 916722 sgd_solver.cpp:106] Iteration 916500, lr = 0.01
I0830 00:46:18.482584 916722 solver.cpp:218] Iteration 917000 (16.7005 iter/s, 29.9393s/500 iters), loss = 0.274084
I0830 00:46:18.482638 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.274092 (* 1 = 0.274092 loss)
I0830 00:46:18.482648 916722 sgd_solver.cpp:106] Iteration 917000, lr = 0.01
I0830 00:46:48.410372 916722 solver.cpp:218] Iteration 917500 (16.7075 iter/s, 29.9267s/500 iters), loss = 0.122329
I0830 00:46:48.410434 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.122336 (* 1 = 0.122336 loss)
I0830 00:46:48.410444 916722 sgd_solver.cpp:106] Iteration 917500, lr = 0.01
I0830 00:47:18.328856 916722 solver.cpp:218] Iteration 918000 (16.7127 iter/s, 29.9174s/500 iters), loss = 0.160209
I0830 00:47:18.328907 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.160217 (* 1 = 0.160217 loss)
I0830 00:47:18.328917 916722 sgd_solver.cpp:106] Iteration 918000, lr = 0.01
I0830 00:47:48.252007 916722 solver.cpp:218] Iteration 918500 (16.71 iter/s, 29.9222s/500 iters), loss = 0.250598
I0830 00:47:48.252068 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.250606 (* 1 = 0.250606 loss)
I0830 00:47:48.252076 916722 sgd_solver.cpp:106] Iteration 918500, lr = 0.01
I0830 00:48:18.165958 916722 solver.cpp:218] Iteration 919000 (16.7151 iter/s, 29.913s/500 iters), loss = 0.360756
I0830 00:48:18.166013 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.360763 (* 1 = 0.360763 loss)
I0830 00:48:18.166021 916722 sgd_solver.cpp:106] Iteration 919000, lr = 0.01
I0830 00:48:48.080273 916722 solver.cpp:218] Iteration 919500 (16.7149 iter/s, 29.9134s/500 iters), loss = 0.278912
I0830 00:48:48.080334 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.27892 (* 1 = 0.27892 loss)
I0830 00:48:48.080343 916722 sgd_solver.cpp:106] Iteration 919500, lr = 0.01
I0830 00:49:17.990607 916722 solver.cpp:218] Iteration 920000 (16.7171 iter/s, 29.9095s/500 iters), loss = 0.308356
I0830 00:49:17.990660 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.308364 (* 1 = 0.308364 loss)
I0830 00:49:17.990669 916722 sgd_solver.cpp:106] Iteration 920000, lr = 0.01
I0830 00:49:47.907879 916722 solver.cpp:218] Iteration 920500 (16.7132 iter/s, 29.9164s/500 iters), loss = 0.129604
I0830 00:49:47.907940 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.129612 (* 1 = 0.129612 loss)
I0830 00:49:47.907948 916722 sgd_solver.cpp:106] Iteration 920500, lr = 0.01
I0830 00:50:17.803975 916722 solver.cpp:218] Iteration 921000 (16.725 iter/s, 29.8953s/500 iters), loss = 0.136565
I0830 00:50:17.804028 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.136572 (* 1 = 0.136572 loss)
I0830 00:50:17.804037 916722 sgd_solver.cpp:106] Iteration 921000, lr = 0.01
I0830 00:50:47.735049 916722 solver.cpp:218] Iteration 921500 (16.7055 iter/s, 29.9303s/500 iters), loss = 0.0433199
I0830 00:50:47.735110 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0433275 (* 1 = 0.0433275 loss)
I0830 00:50:47.735119 916722 sgd_solver.cpp:106] Iteration 921500, lr = 0.01
I0830 00:51:17.635743 916722 solver.cpp:218] Iteration 922000 (16.7224 iter/s, 29.9s/500 iters), loss = 0.124667
I0830 00:51:17.635797 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.124674 (* 1 = 0.124674 loss)
I0830 00:51:17.635808 916722 sgd_solver.cpp:106] Iteration 922000, lr = 0.01
I0830 00:51:47.550976 916722 solver.cpp:218] Iteration 922500 (16.7143 iter/s, 29.9145s/500 iters), loss = 0.0463611
I0830 00:51:47.551033 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0463688 (* 1 = 0.0463688 loss)
I0830 00:51:47.551043 916722 sgd_solver.cpp:106] Iteration 922500, lr = 0.01
I0830 00:52:17.484426 916722 solver.cpp:218] Iteration 923000 (16.7041 iter/s, 29.9328s/500 iters), loss = 0.142785
I0830 00:52:17.484490 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.142793 (* 1 = 0.142793 loss)
I0830 00:52:17.484500 916722 sgd_solver.cpp:106] Iteration 923000, lr = 0.01
I0830 00:52:47.399825 916722 solver.cpp:218] Iteration 923500 (16.7142 iter/s, 29.9147s/500 iters), loss = 0.188168
I0830 00:52:47.399897 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.188175 (* 1 = 0.188175 loss)
I0830 00:52:47.399905 916722 sgd_solver.cpp:106] Iteration 923500, lr = 0.01
I0830 00:53:17.310568 916722 solver.cpp:218] Iteration 924000 (16.7168 iter/s, 29.9101s/500 iters), loss = 0.155978
I0830 00:53:17.310622 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.155986 (* 1 = 0.155986 loss)
I0830 00:53:17.310633 916722 sgd_solver.cpp:106] Iteration 924000, lr = 0.01
I0830 00:53:47.228420 916722 solver.cpp:218] Iteration 924500 (16.7128 iter/s, 29.9172s/500 iters), loss = 0.105407
I0830 00:53:47.228492 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105415 (* 1 = 0.105415 loss)
I0830 00:53:47.228502 916722 sgd_solver.cpp:106] Iteration 924500, lr = 0.01
I0830 00:54:17.162283 916722 solver.cpp:218] Iteration 925000 (16.7038 iter/s, 29.9333s/500 iters), loss = 0.499336
I0830 00:54:17.162338 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.499344 (* 1 = 0.499344 loss)
I0830 00:54:17.162348 916722 sgd_solver.cpp:106] Iteration 925000, lr = 0.01
I0830 00:54:47.088599 916722 solver.cpp:218] Iteration 925500 (16.708 iter/s, 29.9258s/500 iters), loss = 0.136949
I0830 00:54:47.088660 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.136956 (* 1 = 0.136956 loss)
I0830 00:54:47.088668 916722 sgd_solver.cpp:106] Iteration 925500, lr = 0.01
I0830 00:55:17.019505 916722 solver.cpp:218] Iteration 926000 (16.7054 iter/s, 29.9304s/500 iters), loss = 0.440453
I0830 00:55:17.019559 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.44046 (* 1 = 0.44046 loss)
I0830 00:55:17.019570 916722 sgd_solver.cpp:106] Iteration 926000, lr = 0.01
I0830 00:55:46.930106 916722 solver.cpp:218] Iteration 926500 (16.7168 iter/s, 29.9101s/500 iters), loss = 0.057089
I0830 00:55:46.930166 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0570964 (* 1 = 0.0570964 loss)
I0830 00:55:46.930176 916722 sgd_solver.cpp:106] Iteration 926500, lr = 0.01
I0830 00:56:16.837097 916722 solver.cpp:218] Iteration 927000 (16.7188 iter/s, 29.9065s/500 iters), loss = 0.148154
I0830 00:56:16.837150 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.148162 (* 1 = 0.148162 loss)
I0830 00:56:16.837160 916722 sgd_solver.cpp:106] Iteration 927000, lr = 0.01
I0830 00:56:46.751459 916722 solver.cpp:218] Iteration 927500 (16.7147 iter/s, 29.9139s/500 iters), loss = 0.228325
I0830 00:56:46.751523 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.228333 (* 1 = 0.228333 loss)
I0830 00:56:46.751531 916722 sgd_solver.cpp:106] Iteration 927500, lr = 0.01
I0830 00:57:16.654824 916722 solver.cpp:218] Iteration 928000 (16.7208 iter/s, 29.9029s/500 iters), loss = 0.142991
I0830 00:57:16.654877 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.142999 (* 1 = 0.142999 loss)
I0830 00:57:16.654886 916722 sgd_solver.cpp:106] Iteration 928000, lr = 0.01
I0830 00:57:46.550746 916722 solver.cpp:218] Iteration 928500 (16.7249 iter/s, 29.8955s/500 iters), loss = 0.147147
I0830 00:57:46.550806 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.147155 (* 1 = 0.147155 loss)
I0830 00:57:46.550815 916722 sgd_solver.cpp:106] Iteration 928500, lr = 0.01
I0830 00:58:16.472342 916722 solver.cpp:218] Iteration 929000 (16.7106 iter/s, 29.9211s/500 iters), loss = 0.132402
I0830 00:58:16.472395 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.132409 (* 1 = 0.132409 loss)
I0830 00:58:16.472404 916722 sgd_solver.cpp:106] Iteration 929000, lr = 0.01
I0830 00:58:46.372447 916722 solver.cpp:218] Iteration 929500 (16.7226 iter/s, 29.8997s/500 iters), loss = 0.361499
I0830 00:58:46.372524 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.361507 (* 1 = 0.361507 loss)
I0830 00:58:46.372534 916722 sgd_solver.cpp:106] Iteration 929500, lr = 0.01
I0830 00:59:16.277263 916722 solver.cpp:218] Iteration 930000 (16.72 iter/s, 29.9044s/500 iters), loss = 0.0820425
I0830 00:59:16.277318 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0820501 (* 1 = 0.0820501 loss)
I0830 00:59:16.277326 916722 sgd_solver.cpp:106] Iteration 930000, lr = 0.01
I0830 00:59:46.185837 916722 solver.cpp:218] Iteration 930500 (16.7178 iter/s, 29.9082s/500 iters), loss = 0.156784
I0830 00:59:46.185896 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.156791 (* 1 = 0.156791 loss)
I0830 00:59:46.185904 916722 sgd_solver.cpp:106] Iteration 930500, lr = 0.01
I0830 01:00:16.096488 916722 solver.cpp:218] Iteration 931000 (16.7167 iter/s, 29.9102s/500 iters), loss = 0.283583
I0830 01:00:16.096540 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.28359 (* 1 = 0.28359 loss)
I0830 01:00:16.096549 916722 sgd_solver.cpp:106] Iteration 931000, lr = 0.01
I0830 01:00:46.007273 916722 solver.cpp:218] Iteration 931500 (16.7166 iter/s, 29.9104s/500 iters), loss = 0.235136
I0830 01:00:46.007329 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.235144 (* 1 = 0.235144 loss)
I0830 01:00:46.007337 916722 sgd_solver.cpp:106] Iteration 931500, lr = 0.01
I0830 01:01:15.926775 916722 solver.cpp:218] Iteration 932000 (16.7117 iter/s, 29.9191s/500 iters), loss = 0.0623437
I0830 01:01:15.926831 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0623517 (* 1 = 0.0623517 loss)
I0830 01:01:15.926842 916722 sgd_solver.cpp:106] Iteration 932000, lr = 0.01
I0830 01:01:45.831745 916722 solver.cpp:218] Iteration 932500 (16.7198 iter/s, 29.9046s/500 iters), loss = 0.171132
I0830 01:01:45.831804 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.17114 (* 1 = 0.17114 loss)
I0830 01:01:45.831812 916722 sgd_solver.cpp:106] Iteration 932500, lr = 0.01
I0830 01:02:15.716367 916722 solver.cpp:218] Iteration 933000 (16.7312 iter/s, 29.8843s/500 iters), loss = 0.191272
I0830 01:02:15.716421 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.191279 (* 1 = 0.191279 loss)
I0830 01:02:15.716449 916722 sgd_solver.cpp:106] Iteration 933000, lr = 0.01
I0830 01:02:45.606587 916722 solver.cpp:218] Iteration 933500 (16.7281 iter/s, 29.8899s/500 iters), loss = 0.103578
I0830 01:02:45.606647 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.103585 (* 1 = 0.103585 loss)
I0830 01:02:45.606657 916722 sgd_solver.cpp:106] Iteration 933500, lr = 0.01
I0830 01:03:15.504683 916722 solver.cpp:218] Iteration 934000 (16.7237 iter/s, 29.8977s/500 iters), loss = 0.229565
I0830 01:03:15.504736 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.229573 (* 1 = 0.229573 loss)
I0830 01:03:15.504746 916722 sgd_solver.cpp:106] Iteration 934000, lr = 0.01
I0830 01:03:45.403640 916722 solver.cpp:218] Iteration 934500 (16.7232 iter/s, 29.8986s/500 iters), loss = 0.0846177
I0830 01:03:45.403697 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0846256 (* 1 = 0.0846256 loss)
I0830 01:03:45.403707 916722 sgd_solver.cpp:106] Iteration 934500, lr = 0.01
I0830 01:04:15.280031 916722 solver.cpp:218] Iteration 935000 (16.7358 iter/s, 29.8761s/500 iters), loss = 0.0444507
I0830 01:04:15.280083 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0444585 (* 1 = 0.0444585 loss)
I0830 01:04:15.280093 916722 sgd_solver.cpp:106] Iteration 935000, lr = 0.01
I0830 01:04:45.169319 916722 solver.cpp:218] Iteration 935500 (16.7286 iter/s, 29.889s/500 iters), loss = 0.171164
I0830 01:04:45.169374 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.171171 (* 1 = 0.171171 loss)
I0830 01:04:45.169382 916722 sgd_solver.cpp:106] Iteration 935500, lr = 0.01
I0830 01:05:15.061107 916722 solver.cpp:218] Iteration 936000 (16.7272 iter/s, 29.8915s/500 iters), loss = 0.152696
I0830 01:05:15.061157 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152704 (* 1 = 0.152704 loss)
I0830 01:05:15.061179 916722 sgd_solver.cpp:106] Iteration 936000, lr = 0.01
I0830 01:05:44.955685 916722 solver.cpp:218] Iteration 936500 (16.7256 iter/s, 29.8943s/500 iters), loss = 0.170744
I0830 01:05:44.955758 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.170752 (* 1 = 0.170752 loss)
I0830 01:05:44.955767 916722 sgd_solver.cpp:106] Iteration 936500, lr = 0.01
I0830 01:06:14.843396 916722 solver.cpp:218] Iteration 937000 (16.7295 iter/s, 29.8874s/500 iters), loss = 0.0316997
I0830 01:06:14.843449 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0317073 (* 1 = 0.0317073 loss)
I0830 01:06:14.843461 916722 sgd_solver.cpp:106] Iteration 937000, lr = 0.01
I0830 01:06:44.731921 916722 solver.cpp:218] Iteration 937500 (16.729 iter/s, 29.8882s/500 iters), loss = 0.0165109
I0830 01:06:44.731982 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0165183 (* 1 = 0.0165183 loss)
I0830 01:06:44.731990 916722 sgd_solver.cpp:106] Iteration 937500, lr = 0.01
I0830 01:07:14.630060 916722 solver.cpp:218] Iteration 938000 (16.7236 iter/s, 29.8978s/500 iters), loss = 0.260329
I0830 01:07:14.630115 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.260336 (* 1 = 0.260336 loss)
I0830 01:07:14.630125 916722 sgd_solver.cpp:106] Iteration 938000, lr = 0.01
I0830 01:07:44.535023 916722 solver.cpp:218] Iteration 938500 (16.7198 iter/s, 29.9047s/500 iters), loss = 0.066756
I0830 01:07:44.535084 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0667635 (* 1 = 0.0667635 loss)
I0830 01:07:44.535091 916722 sgd_solver.cpp:106] Iteration 938500, lr = 0.01
I0830 01:08:14.424043 916722 solver.cpp:218] Iteration 939000 (16.7287 iter/s, 29.8887s/500 iters), loss = 0.654762
I0830 01:08:14.424096 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.65477 (* 1 = 0.65477 loss)
I0830 01:08:14.424108 916722 sgd_solver.cpp:106] Iteration 939000, lr = 0.01
I0830 01:08:44.327991 916722 solver.cpp:218] Iteration 939500 (16.7204 iter/s, 29.9037s/500 iters), loss = 0.139308
I0830 01:08:44.328050 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139316 (* 1 = 0.139316 loss)
I0830 01:08:44.328058 916722 sgd_solver.cpp:106] Iteration 939500, lr = 0.01
I0830 01:09:14.209563 916722 solver.cpp:218] Iteration 940000 (16.7329 iter/s, 29.8813s/500 iters), loss = 0.259053
I0830 01:09:14.209614 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.25906 (* 1 = 0.25906 loss)
I0830 01:09:14.209625 916722 sgd_solver.cpp:106] Iteration 940000, lr = 0.01
I0830 01:09:44.131218 916722 solver.cpp:218] Iteration 940500 (16.7105 iter/s, 29.9214s/500 iters), loss = 0.256889
I0830 01:09:44.131273 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.256897 (* 1 = 0.256897 loss)
I0830 01:09:44.131281 916722 sgd_solver.cpp:106] Iteration 940500, lr = 0.01
I0830 01:10:14.025473 916722 solver.cpp:218] Iteration 941000 (16.7258 iter/s, 29.894s/500 iters), loss = 0.0818452
I0830 01:10:14.025527 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0818528 (* 1 = 0.0818528 loss)
I0830 01:10:14.025537 916722 sgd_solver.cpp:106] Iteration 941000, lr = 0.01
I0830 01:10:43.943545 916722 solver.cpp:218] Iteration 941500 (16.7125 iter/s, 29.9178s/500 iters), loss = 0.071655
I0830 01:10:43.943607 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0716626 (* 1 = 0.0716626 loss)
I0830 01:10:43.943616 916722 sgd_solver.cpp:106] Iteration 941500, lr = 0.01
I0830 01:11:13.851698 916722 solver.cpp:218] Iteration 942000 (16.718 iter/s, 29.9079s/500 iters), loss = 0.184739
I0830 01:11:13.851752 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.184747 (* 1 = 0.184747 loss)
I0830 01:11:13.851763 916722 sgd_solver.cpp:106] Iteration 942000, lr = 0.01
I0830 01:11:43.788971 916722 solver.cpp:218] Iteration 942500 (16.7017 iter/s, 29.937s/500 iters), loss = 0.12602
I0830 01:11:43.789036 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.126028 (* 1 = 0.126028 loss)
I0830 01:11:43.789043 916722 sgd_solver.cpp:106] Iteration 942500, lr = 0.01
I0830 01:12:13.719118 916722 solver.cpp:218] Iteration 943000 (16.7057 iter/s, 29.9299s/500 iters), loss = 0.123137
I0830 01:12:13.719172 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.123145 (* 1 = 0.123145 loss)
I0830 01:12:13.719180 916722 sgd_solver.cpp:106] Iteration 943000, lr = 0.01
I0830 01:12:43.658939 916722 solver.cpp:218] Iteration 943500 (16.7003 iter/s, 29.9396s/500 iters), loss = 0.283297
I0830 01:12:43.659013 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.283304 (* 1 = 0.283304 loss)
I0830 01:12:43.659021 916722 sgd_solver.cpp:106] Iteration 943500, lr = 0.01
I0830 01:13:13.621209 916722 solver.cpp:218] Iteration 944000 (16.6878 iter/s, 29.962s/500 iters), loss = 0.162501
I0830 01:13:13.621263 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.162509 (* 1 = 0.162509 loss)
I0830 01:13:13.621271 916722 sgd_solver.cpp:106] Iteration 944000, lr = 0.01
I0830 01:13:43.585075 916722 solver.cpp:218] Iteration 944500 (16.6869 iter/s, 29.9636s/500 iters), loss = 0.127727
I0830 01:13:43.585134 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.127735 (* 1 = 0.127735 loss)
I0830 01:13:43.585142 916722 sgd_solver.cpp:106] Iteration 944500, lr = 0.01
I0830 01:14:13.522881 916722 solver.cpp:218] Iteration 945000 (16.7014 iter/s, 29.9375s/500 iters), loss = 0.12848
I0830 01:14:13.522928 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128488 (* 1 = 0.128488 loss)
I0830 01:14:13.522938 916722 sgd_solver.cpp:106] Iteration 945000, lr = 0.01
I0830 01:14:43.465178 916722 solver.cpp:218] Iteration 945500 (16.6989 iter/s, 29.9421s/500 iters), loss = 0.0451524
I0830 01:14:43.465238 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0451603 (* 1 = 0.0451603 loss)
I0830 01:14:43.465246 916722 sgd_solver.cpp:106] Iteration 945500, lr = 0.01
I0830 01:15:13.441751 916722 solver.cpp:218] Iteration 946000 (16.6798 iter/s, 29.9763s/500 iters), loss = 0.0132088
I0830 01:15:13.441810 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0132168 (* 1 = 0.0132168 loss)
I0830 01:15:13.441819 916722 sgd_solver.cpp:106] Iteration 946000, lr = 0.01
I0830 01:15:43.403832 916722 solver.cpp:218] Iteration 946500 (16.6879 iter/s, 29.9618s/500 iters), loss = 0.252798
I0830 01:15:43.403892 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.252806 (* 1 = 0.252806 loss)
I0830 01:15:43.403901 916722 sgd_solver.cpp:106] Iteration 946500, lr = 0.01
I0830 01:16:13.360926 916722 solver.cpp:218] Iteration 947000 (16.6907 iter/s, 29.9568s/500 iters), loss = 0.215909
I0830 01:16:13.360982 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.215918 (* 1 = 0.215918 loss)
I0830 01:16:13.360993 916722 sgd_solver.cpp:106] Iteration 947000, lr = 0.01
I0830 01:16:43.296335 916722 solver.cpp:218] Iteration 947500 (16.7028 iter/s, 29.9352s/500 iters), loss = 0.0869434
I0830 01:16:43.296396 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0869517 (* 1 = 0.0869517 loss)
I0830 01:16:43.296403 916722 sgd_solver.cpp:106] Iteration 947500, lr = 0.01
I0830 01:17:13.232550 916722 solver.cpp:218] Iteration 948000 (16.7023 iter/s, 29.936s/500 iters), loss = 0.053407
I0830 01:17:13.232604 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0534155 (* 1 = 0.0534155 loss)
I0830 01:17:13.232614 916722 sgd_solver.cpp:106] Iteration 948000, lr = 0.01
I0830 01:17:43.156643 916722 solver.cpp:218] Iteration 948500 (16.7091 iter/s, 29.9238s/500 iters), loss = 0.160742
I0830 01:17:43.156702 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.16075 (* 1 = 0.16075 loss)
I0830 01:17:43.156711 916722 sgd_solver.cpp:106] Iteration 948500, lr = 0.01
I0830 01:18:13.077549 916722 solver.cpp:218] Iteration 949000 (16.7109 iter/s, 29.9207s/500 iters), loss = 0.0912741
I0830 01:18:13.077601 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0912825 (* 1 = 0.0912825 loss)
I0830 01:18:13.077611 916722 sgd_solver.cpp:106] Iteration 949000, lr = 0.01
I0830 01:18:43.023054 916722 solver.cpp:218] Iteration 949500 (16.6971 iter/s, 29.9453s/500 iters), loss = 0.0921853
I0830 01:18:43.023125 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0921936 (* 1 = 0.0921936 loss)
I0830 01:18:43.023134 916722 sgd_solver.cpp:106] Iteration 949500, lr = 0.01
I0830 01:19:12.887989 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_950000.caffemodel
I0830 01:19:12.907272 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_950000.solverstate
I0830 01:19:12.913547 916722 solver.cpp:330] Iteration 950000, Testing net (#0)
I0830 01:19:28.303782 916722 solver.cpp:397]     Test net output #0: accuracy = 0.9036
I0830 01:19:28.303833 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.320229 (* 1 = 0.320229 loss)
I0830 01:19:28.362675 916722 solver.cpp:218] Iteration 950000 (11.028 iter/s, 45.3393s/500 iters), loss = 0.263438
I0830 01:19:28.362701 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.263446 (* 1 = 0.263446 loss)
I0830 01:19:28.362709 916722 sgd_solver.cpp:106] Iteration 950000, lr = 0.01
I0830 01:19:58.170886 916722 solver.cpp:218] Iteration 950500 (16.774 iter/s, 29.808s/500 iters), loss = 0.10857
I0830 01:19:58.170943 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.108579 (* 1 = 0.108579 loss)
I0830 01:19:58.170951 916722 sgd_solver.cpp:106] Iteration 950500, lr = 0.01
I0830 01:20:28.039176 916722 solver.cpp:218] Iteration 951000 (16.7403 iter/s, 29.868s/500 iters), loss = 0.143518
I0830 01:20:28.039237 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.143526 (* 1 = 0.143526 loss)
I0830 01:20:28.039245 916722 sgd_solver.cpp:106] Iteration 951000, lr = 0.01
I0830 01:20:57.939975 916722 solver.cpp:218] Iteration 951500 (16.7221 iter/s, 29.9006s/500 iters), loss = 0.054656
I0830 01:20:57.940030 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0546642 (* 1 = 0.0546642 loss)
I0830 01:20:57.940040 916722 sgd_solver.cpp:106] Iteration 951500, lr = 0.01
I0830 01:21:27.864063 916722 solver.cpp:218] Iteration 952000 (16.7091 iter/s, 29.9238s/500 iters), loss = 0.317709
I0830 01:21:27.864123 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.317717 (* 1 = 0.317717 loss)
I0830 01:21:27.864132 916722 sgd_solver.cpp:106] Iteration 952000, lr = 0.01
I0830 01:21:57.774365 916722 solver.cpp:218] Iteration 952500 (16.7168 iter/s, 29.9101s/500 iters), loss = 0.319817
I0830 01:21:57.774418 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.319825 (* 1 = 0.319825 loss)
I0830 01:21:57.774430 916722 sgd_solver.cpp:106] Iteration 952500, lr = 0.01
I0830 01:22:27.689651 916722 solver.cpp:218] Iteration 953000 (16.714 iter/s, 29.915s/500 iters), loss = 0.0572396
I0830 01:22:27.689709 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0572476 (* 1 = 0.0572476 loss)
I0830 01:22:27.689718 916722 sgd_solver.cpp:106] Iteration 953000, lr = 0.01
I0830 01:22:57.629366 916722 solver.cpp:218] Iteration 953500 (16.7004 iter/s, 29.9395s/500 iters), loss = 0.293993
I0830 01:22:57.629417 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.294001 (* 1 = 0.294001 loss)
I0830 01:22:57.629427 916722 sgd_solver.cpp:106] Iteration 953500, lr = 0.01
I0830 01:23:27.573626 916722 solver.cpp:218] Iteration 954000 (16.6978 iter/s, 29.944s/500 iters), loss = 0.0549245
I0830 01:23:27.573688 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0549325 (* 1 = 0.0549325 loss)
I0830 01:23:27.573695 916722 sgd_solver.cpp:106] Iteration 954000, lr = 0.01
I0830 01:23:57.518776 916722 solver.cpp:218] Iteration 954500 (16.6973 iter/s, 29.9449s/500 iters), loss = 0.122012
I0830 01:23:57.518832 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.12202 (* 1 = 0.12202 loss)
I0830 01:23:57.518843 916722 sgd_solver.cpp:106] Iteration 954500, lr = 0.01
I0830 01:24:27.462023 916722 solver.cpp:218] Iteration 955000 (16.6984 iter/s, 29.943s/500 iters), loss = 0.131035
I0830 01:24:27.462097 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131043 (* 1 = 0.131043 loss)
I0830 01:24:27.462110 916722 sgd_solver.cpp:106] Iteration 955000, lr = 0.01
I0830 01:24:57.401547 916722 solver.cpp:218] Iteration 955500 (16.7005 iter/s, 29.9393s/500 iters), loss = 0.105006
I0830 01:24:57.401602 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105014 (* 1 = 0.105014 loss)
I0830 01:24:57.401610 916722 sgd_solver.cpp:106] Iteration 955500, lr = 0.01
I0830 01:25:27.367717 916722 solver.cpp:218] Iteration 956000 (16.6856 iter/s, 29.9659s/500 iters), loss = 0.0609777
I0830 01:25:27.367777 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0609859 (* 1 = 0.0609859 loss)
I0830 01:25:27.367786 916722 sgd_solver.cpp:106] Iteration 956000, lr = 0.01
I0830 01:25:57.336871 916722 solver.cpp:218] Iteration 956500 (16.684 iter/s, 29.9689s/500 iters), loss = 0.0654721
I0830 01:25:57.336925 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0654804 (* 1 = 0.0654804 loss)
I0830 01:25:57.336933 916722 sgd_solver.cpp:106] Iteration 956500, lr = 0.01
I0830 01:26:27.263437 916722 solver.cpp:218] Iteration 957000 (16.7077 iter/s, 29.9263s/500 iters), loss = 0.0600308
I0830 01:26:27.263499 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0600389 (* 1 = 0.0600389 loss)
I0830 01:26:27.263506 916722 sgd_solver.cpp:106] Iteration 957000, lr = 0.01
I0830 01:26:57.200971 916722 solver.cpp:218] Iteration 957500 (16.7016 iter/s, 29.9373s/500 iters), loss = 0.246787
I0830 01:26:57.201025 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.246795 (* 1 = 0.246795 loss)
I0830 01:26:57.201033 916722 sgd_solver.cpp:106] Iteration 957500, lr = 0.01
I0830 01:27:27.115633 916722 solver.cpp:218] Iteration 958000 (16.7143 iter/s, 29.9144s/500 iters), loss = 0.0265241
I0830 01:27:27.115691 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0265322 (* 1 = 0.0265322 loss)
I0830 01:27:27.115700 916722 sgd_solver.cpp:106] Iteration 958000, lr = 0.01
I0830 01:27:57.026485 916722 solver.cpp:218] Iteration 958500 (16.7165 iter/s, 29.9106s/500 iters), loss = 0.260193
I0830 01:27:57.026540 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.260201 (* 1 = 0.260201 loss)
I0830 01:27:57.026548 916722 sgd_solver.cpp:106] Iteration 958500, lr = 0.01
I0830 01:28:26.947499 916722 solver.cpp:218] Iteration 959000 (16.7108 iter/s, 29.9208s/500 iters), loss = 0.0216969
I0830 01:28:26.947559 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.021705 (* 1 = 0.021705 loss)
I0830 01:28:26.947568 916722 sgd_solver.cpp:106] Iteration 959000, lr = 0.01
I0830 01:28:56.869086 916722 solver.cpp:218] Iteration 959500 (16.7105 iter/s, 29.9213s/500 iters), loss = 0.0842266
I0830 01:28:56.869139 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0842347 (* 1 = 0.0842347 loss)
I0830 01:28:56.869148 916722 sgd_solver.cpp:106] Iteration 959500, lr = 0.01
I0830 01:29:26.747400 916722 solver.cpp:218] Iteration 960000 (16.7347 iter/s, 29.8781s/500 iters), loss = 0.24907
I0830 01:29:26.747459 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.249078 (* 1 = 0.249078 loss)
I0830 01:29:26.747468 916722 sgd_solver.cpp:106] Iteration 960000, lr = 0.01
I0830 01:29:56.646421 916722 solver.cpp:218] Iteration 960500 (16.7231 iter/s, 29.8988s/500 iters), loss = 0.225196
I0830 01:29:56.646477 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.225204 (* 1 = 0.225204 loss)
I0830 01:29:56.646488 916722 sgd_solver.cpp:106] Iteration 960500, lr = 0.01
I0830 01:30:26.546733 916722 solver.cpp:218] Iteration 961000 (16.7224 iter/s, 29.9001s/500 iters), loss = 0.137034
I0830 01:30:26.546793 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.137042 (* 1 = 0.137042 loss)
I0830 01:30:26.546802 916722 sgd_solver.cpp:106] Iteration 961000, lr = 0.01
I0830 01:30:56.441507 916722 solver.cpp:218] Iteration 961500 (16.7255 iter/s, 29.8945s/500 iters), loss = 0.0411825
I0830 01:30:56.441561 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0411906 (* 1 = 0.0411906 loss)
I0830 01:30:56.441582 916722 sgd_solver.cpp:106] Iteration 961500, lr = 0.01
I0830 01:31:26.338148 916722 solver.cpp:218] Iteration 962000 (16.7244 iter/s, 29.8964s/500 iters), loss = 0.124447
I0830 01:31:26.338217 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.124455 (* 1 = 0.124455 loss)
I0830 01:31:26.338229 916722 sgd_solver.cpp:106] Iteration 962000, lr = 0.01
I0830 01:31:56.272801 916722 solver.cpp:218] Iteration 962500 (16.7032 iter/s, 29.9344s/500 iters), loss = 0.138225
I0830 01:31:56.272853 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.138233 (* 1 = 0.138233 loss)
I0830 01:31:56.272863 916722 sgd_solver.cpp:106] Iteration 962500, lr = 0.01
I0830 01:32:26.166395 916722 solver.cpp:218] Iteration 963000 (16.7261 iter/s, 29.8934s/500 iters), loss = 0.187047
I0830 01:32:26.166455 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.187055 (* 1 = 0.187055 loss)
I0830 01:32:26.166463 916722 sgd_solver.cpp:106] Iteration 963000, lr = 0.01
I0830 01:32:56.072872 916722 solver.cpp:218] Iteration 963500 (16.7189 iter/s, 29.9062s/500 iters), loss = 0.0292704
I0830 01:32:56.072926 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0292787 (* 1 = 0.0292787 loss)
I0830 01:32:56.072937 916722 sgd_solver.cpp:106] Iteration 963500, lr = 0.01
I0830 01:33:25.958582 916722 solver.cpp:218] Iteration 964000 (16.7305 iter/s, 29.8855s/500 iters), loss = 0.0292594
I0830 01:33:25.958643 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0292677 (* 1 = 0.0292677 loss)
I0830 01:33:25.958652 916722 sgd_solver.cpp:106] Iteration 964000, lr = 0.01
I0830 01:33:55.865875 916722 solver.cpp:218] Iteration 964500 (16.7185 iter/s, 29.9071s/500 iters), loss = 0.12957
I0830 01:33:55.865934 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.129579 (* 1 = 0.129579 loss)
I0830 01:33:55.865944 916722 sgd_solver.cpp:106] Iteration 964500, lr = 0.01
I0830 01:34:25.776374 916722 solver.cpp:218] Iteration 965000 (16.7167 iter/s, 29.9103s/500 iters), loss = 0.0998728
I0830 01:34:25.776439 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0998814 (* 1 = 0.0998814 loss)
I0830 01:34:25.776448 916722 sgd_solver.cpp:106] Iteration 965000, lr = 0.01
I0830 01:34:55.687036 916722 solver.cpp:218] Iteration 965500 (16.7166 iter/s, 29.9104s/500 iters), loss = 0.326178
I0830 01:34:55.687093 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.326186 (* 1 = 0.326186 loss)
I0830 01:34:55.687103 916722 sgd_solver.cpp:106] Iteration 965500, lr = 0.01
I0830 01:35:25.597137 916722 solver.cpp:218] Iteration 966000 (16.7169 iter/s, 29.9099s/500 iters), loss = 0.356677
I0830 01:35:25.597198 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.356685 (* 1 = 0.356685 loss)
I0830 01:35:25.597206 916722 sgd_solver.cpp:106] Iteration 966000, lr = 0.01
I0830 01:35:55.507740 916722 solver.cpp:218] Iteration 966500 (16.7166 iter/s, 29.9104s/500 iters), loss = 0.0733077
I0830 01:35:55.507794 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0733161 (* 1 = 0.0733161 loss)
I0830 01:35:55.507804 916722 sgd_solver.cpp:106] Iteration 966500, lr = 0.01
I0830 01:36:25.422705 916722 solver.cpp:218] Iteration 967000 (16.7142 iter/s, 29.9147s/500 iters), loss = 0.089037
I0830 01:36:25.422765 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0890451 (* 1 = 0.0890451 loss)
I0830 01:36:25.422773 916722 sgd_solver.cpp:106] Iteration 967000, lr = 0.01
I0830 01:36:55.339692 916722 solver.cpp:218] Iteration 967500 (16.713 iter/s, 29.9168s/500 iters), loss = 0.0522658
I0830 01:36:55.339748 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.052274 (* 1 = 0.052274 loss)
I0830 01:36:55.339756 916722 sgd_solver.cpp:106] Iteration 967500, lr = 0.01
I0830 01:37:25.276415 916722 solver.cpp:218] Iteration 968000 (16.702 iter/s, 29.9365s/500 iters), loss = 0.0928484
I0830 01:37:25.276485 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0928567 (* 1 = 0.0928567 loss)
I0830 01:37:25.276494 916722 sgd_solver.cpp:106] Iteration 968000, lr = 0.01
I0830 01:37:55.176055 916722 solver.cpp:218] Iteration 968500 (16.7227 iter/s, 29.8994s/500 iters), loss = 0.403352
I0830 01:37:55.176110 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.40336 (* 1 = 0.40336 loss)
I0830 01:37:55.176118 916722 sgd_solver.cpp:106] Iteration 968500, lr = 0.01
I0830 01:38:25.091236 916722 solver.cpp:218] Iteration 969000 (16.714 iter/s, 29.915s/500 iters), loss = 0.173879
I0830 01:38:25.091308 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.173887 (* 1 = 0.173887 loss)
I0830 01:38:25.091317 916722 sgd_solver.cpp:106] Iteration 969000, lr = 0.01
I0830 01:38:54.990666 916722 solver.cpp:218] Iteration 969500 (16.7229 iter/s, 29.8992s/500 iters), loss = 0.0996442
I0830 01:38:54.990721 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0996522 (* 1 = 0.0996522 loss)
I0830 01:38:54.990731 916722 sgd_solver.cpp:106] Iteration 969500, lr = 0.01
I0830 01:39:24.892913 916722 solver.cpp:218] Iteration 970000 (16.7213 iter/s, 29.902s/500 iters), loss = 0.0724805
I0830 01:39:24.892972 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0724885 (* 1 = 0.0724885 loss)
I0830 01:39:24.892980 916722 sgd_solver.cpp:106] Iteration 970000, lr = 0.01
I0830 01:39:54.778651 916722 solver.cpp:218] Iteration 970500 (16.7305 iter/s, 29.8855s/500 iters), loss = 0.15991
I0830 01:39:54.778703 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159918 (* 1 = 0.159918 loss)
I0830 01:39:54.778712 916722 sgd_solver.cpp:106] Iteration 970500, lr = 0.01
I0830 01:40:24.644917 916722 solver.cpp:218] Iteration 971000 (16.7414 iter/s, 29.866s/500 iters), loss = 0.0895407
I0830 01:40:24.644975 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0895488 (* 1 = 0.0895488 loss)
I0830 01:40:24.644984 916722 sgd_solver.cpp:106] Iteration 971000, lr = 0.01
I0830 01:40:54.517216 916722 solver.cpp:218] Iteration 971500 (16.738 iter/s, 29.8721s/500 iters), loss = 0.21959
I0830 01:40:54.517274 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.219599 (* 1 = 0.219599 loss)
I0830 01:40:54.517284 916722 sgd_solver.cpp:106] Iteration 971500, lr = 0.01
I0830 01:41:24.403326 916722 solver.cpp:218] Iteration 972000 (16.7303 iter/s, 29.8859s/500 iters), loss = 0.0883735
I0830 01:41:24.403388 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0883816 (* 1 = 0.0883816 loss)
I0830 01:41:24.403396 916722 sgd_solver.cpp:106] Iteration 972000, lr = 0.01
I0830 01:41:54.272365 916722 solver.cpp:218] Iteration 972500 (16.7399 iter/s, 29.8688s/500 iters), loss = 0.069347
I0830 01:41:54.272419 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0693551 (* 1 = 0.0693551 loss)
I0830 01:41:54.272436 916722 sgd_solver.cpp:106] Iteration 972500, lr = 0.01
I0830 01:42:24.141496 916722 solver.cpp:218] Iteration 973000 (16.7398 iter/s, 29.8689s/500 iters), loss = 0.142011
I0830 01:42:24.141556 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.142019 (* 1 = 0.142019 loss)
I0830 01:42:24.141564 916722 sgd_solver.cpp:106] Iteration 973000, lr = 0.01
I0830 01:42:53.992939 916722 solver.cpp:218] Iteration 973500 (16.7497 iter/s, 29.8512s/500 iters), loss = 0.142469
I0830 01:42:53.992995 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.142477 (* 1 = 0.142477 loss)
I0830 01:42:53.993005 916722 sgd_solver.cpp:106] Iteration 973500, lr = 0.01
I0830 01:43:23.861940 916722 solver.cpp:218] Iteration 974000 (16.7399 iter/s, 29.8688s/500 iters), loss = 0.148762
I0830 01:43:23.862000 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.148771 (* 1 = 0.148771 loss)
I0830 01:43:23.862008 916722 sgd_solver.cpp:106] Iteration 974000, lr = 0.01
I0830 01:43:53.733144 916722 solver.cpp:218] Iteration 974500 (16.7387 iter/s, 29.871s/500 iters), loss = 0.150155
I0830 01:43:53.733197 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.150164 (* 1 = 0.150164 loss)
I0830 01:43:53.733207 916722 sgd_solver.cpp:106] Iteration 974500, lr = 0.01
I0830 01:44:23.615864 916722 solver.cpp:218] Iteration 975000 (16.7322 iter/s, 29.8825s/500 iters), loss = 0.210983
I0830 01:44:23.615934 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.210991 (* 1 = 0.210991 loss)
I0830 01:44:23.615943 916722 sgd_solver.cpp:106] Iteration 975000, lr = 0.01
I0830 01:44:53.491441 916722 solver.cpp:218] Iteration 975500 (16.7362 iter/s, 29.8753s/500 iters), loss = 0.279104
I0830 01:44:53.491489 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.279112 (* 1 = 0.279112 loss)
I0830 01:44:53.491499 916722 sgd_solver.cpp:106] Iteration 975500, lr = 0.01
I0830 01:45:23.374956 916722 solver.cpp:218] Iteration 976000 (16.7318 iter/s, 29.8833s/500 iters), loss = 0.205804
I0830 01:45:23.375016 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.205812 (* 1 = 0.205812 loss)
I0830 01:45:23.375025 916722 sgd_solver.cpp:106] Iteration 976000, lr = 0.01
I0830 01:45:53.239503 916722 solver.cpp:218] Iteration 976500 (16.7424 iter/s, 29.8643s/500 iters), loss = 0.152425
I0830 01:45:53.239557 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152434 (* 1 = 0.152434 loss)
I0830 01:45:53.239568 916722 sgd_solver.cpp:106] Iteration 976500, lr = 0.01
I0830 01:46:23.135479 916722 solver.cpp:218] Iteration 977000 (16.7248 iter/s, 29.8957s/500 iters), loss = 0.310369
I0830 01:46:23.135535 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.310377 (* 1 = 0.310377 loss)
I0830 01:46:23.135545 916722 sgd_solver.cpp:106] Iteration 977000, lr = 0.01
I0830 01:46:53.011859 916722 solver.cpp:218] Iteration 977500 (16.7358 iter/s, 29.8761s/500 iters), loss = 0.292923
I0830 01:46:53.011906 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.292931 (* 1 = 0.292931 loss)
I0830 01:46:53.011915 916722 sgd_solver.cpp:106] Iteration 977500, lr = 0.01
I0830 01:47:22.882639 916722 solver.cpp:218] Iteration 978000 (16.7389 iter/s, 29.8706s/500 iters), loss = 0.157098
I0830 01:47:22.882694 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.157107 (* 1 = 0.157107 loss)
I0830 01:47:22.882702 916722 sgd_solver.cpp:106] Iteration 978000, lr = 0.01
I0830 01:47:52.761838 916722 solver.cpp:218] Iteration 978500 (16.7342 iter/s, 29.879s/500 iters), loss = 0.0879459
I0830 01:47:52.761886 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0879546 (* 1 = 0.0879546 loss)
I0830 01:47:52.761895 916722 sgd_solver.cpp:106] Iteration 978500, lr = 0.01
I0830 01:48:22.631656 916722 solver.cpp:218] Iteration 979000 (16.7394 iter/s, 29.8696s/500 iters), loss = 0.089344
I0830 01:48:22.631712 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0893528 (* 1 = 0.0893528 loss)
I0830 01:48:22.631721 916722 sgd_solver.cpp:106] Iteration 979000, lr = 0.01
I0830 01:48:52.515106 916722 solver.cpp:218] Iteration 979500 (16.7318 iter/s, 29.8832s/500 iters), loss = 0.134331
I0830 01:48:52.515153 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13434 (* 1 = 0.13434 loss)
I0830 01:48:52.515162 916722 sgd_solver.cpp:106] Iteration 979500, lr = 0.01
I0830 01:49:22.386811 916722 solver.cpp:218] Iteration 980000 (16.7384 iter/s, 29.8715s/500 iters), loss = 0.144928
I0830 01:49:22.386868 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.144937 (* 1 = 0.144937 loss)
I0830 01:49:22.386875 916722 sgd_solver.cpp:106] Iteration 980000, lr = 0.01
I0830 01:49:52.258611 916722 solver.cpp:218] Iteration 980500 (16.7383 iter/s, 29.8716s/500 iters), loss = 0.282776
I0830 01:49:52.258666 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.282785 (* 1 = 0.282785 loss)
I0830 01:49:52.258675 916722 sgd_solver.cpp:106] Iteration 980500, lr = 0.01
I0830 01:50:22.119168 916722 solver.cpp:218] Iteration 981000 (16.7446 iter/s, 29.8603s/500 iters), loss = 0.368317
I0830 01:50:22.119231 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.368326 (* 1 = 0.368326 loss)
I0830 01:50:22.119239 916722 sgd_solver.cpp:106] Iteration 981000, lr = 0.01
I0830 01:50:51.993769 916722 solver.cpp:218] Iteration 981500 (16.7368 iter/s, 29.8744s/500 iters), loss = 0.182778
I0830 01:50:51.993829 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.182787 (* 1 = 0.182787 loss)
I0830 01:50:51.993856 916722 sgd_solver.cpp:106] Iteration 981500, lr = 0.01
I0830 01:51:21.873240 916722 solver.cpp:218] Iteration 982000 (16.734 iter/s, 29.8792s/500 iters), loss = 0.101735
I0830 01:51:21.873314 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101744 (* 1 = 0.101744 loss)
I0830 01:51:21.873324 916722 sgd_solver.cpp:106] Iteration 982000, lr = 0.01
I0830 01:51:51.747817 916722 solver.cpp:218] Iteration 982500 (16.7368 iter/s, 29.8743s/500 iters), loss = 0.0561679
I0830 01:51:51.747872 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0561769 (* 1 = 0.0561769 loss)
I0830 01:51:51.747882 916722 sgd_solver.cpp:106] Iteration 982500, lr = 0.01
I0830 01:52:21.623965 916722 solver.cpp:218] Iteration 983000 (16.7359 iter/s, 29.8759s/500 iters), loss = 0.300297
I0830 01:52:21.624037 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.300307 (* 1 = 0.300307 loss)
I0830 01:52:21.624045 916722 sgd_solver.cpp:106] Iteration 983000, lr = 0.01
I0830 01:52:51.510844 916722 solver.cpp:218] Iteration 983500 (16.7299 iter/s, 29.8866s/500 iters), loss = 0.341454
I0830 01:52:51.510895 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.341463 (* 1 = 0.341463 loss)
I0830 01:52:51.510905 916722 sgd_solver.cpp:106] Iteration 983500, lr = 0.01
I0830 01:53:21.389310 916722 solver.cpp:218] Iteration 984000 (16.7346 iter/s, 29.8782s/500 iters), loss = 0.198279
I0830 01:53:21.389366 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.198289 (* 1 = 0.198289 loss)
I0830 01:53:21.389375 916722 sgd_solver.cpp:106] Iteration 984000, lr = 0.01
I0830 01:53:51.291836 916722 solver.cpp:218] Iteration 984500 (16.72 iter/s, 29.9042s/500 iters), loss = 0.0855095
I0830 01:53:51.291887 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0855187 (* 1 = 0.0855187 loss)
I0830 01:53:51.291896 916722 sgd_solver.cpp:106] Iteration 984500, lr = 0.01
I0830 01:54:21.185251 916722 solver.cpp:218] Iteration 985000 (16.725 iter/s, 29.8954s/500 iters), loss = 0.097583
I0830 01:54:21.185312 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0975924 (* 1 = 0.0975924 loss)
I0830 01:54:21.185319 916722 sgd_solver.cpp:106] Iteration 985000, lr = 0.01
I0830 01:54:51.085523 916722 solver.cpp:218] Iteration 985500 (16.7212 iter/s, 29.9021s/500 iters), loss = 0.0786804
I0830 01:54:51.085577 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0786896 (* 1 = 0.0786896 loss)
I0830 01:54:51.085588 916722 sgd_solver.cpp:106] Iteration 985500, lr = 0.01
I0830 01:55:20.969215 916722 solver.cpp:218] Iteration 986000 (16.7306 iter/s, 29.8854s/500 iters), loss = 0.133083
I0830 01:55:20.969276 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133093 (* 1 = 0.133093 loss)
I0830 01:55:20.969285 916722 sgd_solver.cpp:106] Iteration 986000, lr = 0.01
I0830 01:55:50.873785 916722 solver.cpp:218] Iteration 986500 (16.7189 iter/s, 29.9062s/500 iters), loss = 0.240485
I0830 01:55:50.873838 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.240495 (* 1 = 0.240495 loss)
I0830 01:55:50.873848 916722 sgd_solver.cpp:106] Iteration 986500, lr = 0.01
I0830 01:56:20.778995 916722 solver.cpp:218] Iteration 987000 (16.7186 iter/s, 29.9068s/500 iters), loss = 0.174157
I0830 01:56:20.779057 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.174166 (* 1 = 0.174166 loss)
I0830 01:56:20.779067 916722 sgd_solver.cpp:106] Iteration 987000, lr = 0.01
I0830 01:56:50.678716 916722 solver.cpp:218] Iteration 987500 (16.7217 iter/s, 29.9012s/500 iters), loss = 0.194318
I0830 01:56:50.678767 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.194327 (* 1 = 0.194327 loss)
I0830 01:56:50.678776 916722 sgd_solver.cpp:106] Iteration 987500, lr = 0.01
I0830 01:57:20.572607 916722 solver.cpp:218] Iteration 988000 (16.725 iter/s, 29.8953s/500 iters), loss = 0.0536859
I0830 01:57:20.572675 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.053695 (* 1 = 0.053695 loss)
I0830 01:57:20.572690 916722 sgd_solver.cpp:106] Iteration 988000, lr = 0.01
I0830 01:57:50.496629 916722 solver.cpp:218] Iteration 988500 (16.7083 iter/s, 29.9253s/500 iters), loss = 0.304938
I0830 01:57:50.496680 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.304947 (* 1 = 0.304947 loss)
I0830 01:57:50.496690 916722 sgd_solver.cpp:106] Iteration 988500, lr = 0.01
I0830 01:58:20.419169 916722 solver.cpp:218] Iteration 989000 (16.7091 iter/s, 29.9238s/500 iters), loss = 0.0588821
I0830 01:58:20.419231 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0588911 (* 1 = 0.0588911 loss)
I0830 01:58:20.419239 916722 sgd_solver.cpp:106] Iteration 989000, lr = 0.01
I0830 01:58:50.335368 916722 solver.cpp:218] Iteration 989500 (16.7127 iter/s, 29.9174s/500 iters), loss = 0.0640566
I0830 01:58:50.335426 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0640656 (* 1 = 0.0640656 loss)
I0830 01:58:50.335436 916722 sgd_solver.cpp:106] Iteration 989500, lr = 0.01
I0830 01:59:20.262421 916722 solver.cpp:218] Iteration 990000 (16.7067 iter/s, 29.9282s/500 iters), loss = 0.0974497
I0830 01:59:20.262482 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0974587 (* 1 = 0.0974587 loss)
I0830 01:59:20.262490 916722 sgd_solver.cpp:106] Iteration 990000, lr = 0.01
I0830 01:59:50.194622 916722 solver.cpp:218] Iteration 990500 (16.7038 iter/s, 29.9333s/500 iters), loss = 0.14309
I0830 01:59:50.194672 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.143099 (* 1 = 0.143099 loss)
I0830 01:59:50.194680 916722 sgd_solver.cpp:106] Iteration 990500, lr = 0.01
I0830 02:00:20.105791 916722 solver.cpp:218] Iteration 991000 (16.7156 iter/s, 29.9122s/500 iters), loss = 0.0292785
I0830 02:00:20.105854 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0292876 (* 1 = 0.0292876 loss)
I0830 02:00:20.105862 916722 sgd_solver.cpp:106] Iteration 991000, lr = 0.01
I0830 02:00:50.022878 916722 solver.cpp:218] Iteration 991500 (16.7123 iter/s, 29.918s/500 iters), loss = 0.150124
I0830 02:00:50.022933 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.150133 (* 1 = 0.150133 loss)
I0830 02:00:50.022943 916722 sgd_solver.cpp:106] Iteration 991500, lr = 0.01
I0830 02:01:19.940346 916722 solver.cpp:218] Iteration 992000 (16.7121 iter/s, 29.9184s/500 iters), loss = 0.16929
I0830 02:01:19.940407 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.169299 (* 1 = 0.169299 loss)
I0830 02:01:19.940414 916722 sgd_solver.cpp:106] Iteration 992000, lr = 0.01
I0830 02:01:49.889207 916722 solver.cpp:218] Iteration 992500 (16.6947 iter/s, 29.9497s/500 iters), loss = 0.0766969
I0830 02:01:49.889262 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.076706 (* 1 = 0.076706 loss)
I0830 02:01:49.889271 916722 sgd_solver.cpp:106] Iteration 992500, lr = 0.01
I0830 02:02:19.790307 916722 solver.cpp:218] Iteration 993000 (16.7213 iter/s, 29.9019s/500 iters), loss = 0.135543
I0830 02:02:19.790364 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.135552 (* 1 = 0.135552 loss)
I0830 02:02:19.790372 916722 sgd_solver.cpp:106] Iteration 993000, lr = 0.01
I0830 02:02:49.696007 916722 solver.cpp:218] Iteration 993500 (16.7188 iter/s, 29.9065s/500 iters), loss = 0.0703187
I0830 02:02:49.696063 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0703275 (* 1 = 0.0703275 loss)
I0830 02:02:49.696071 916722 sgd_solver.cpp:106] Iteration 993500, lr = 0.01
I0830 02:03:19.607600 916722 solver.cpp:218] Iteration 994000 (16.7155 iter/s, 29.9123s/500 iters), loss = 0.109861
I0830 02:03:19.607664 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.10987 (* 1 = 0.10987 loss)
I0830 02:03:19.607673 916722 sgd_solver.cpp:106] Iteration 994000, lr = 0.01
I0830 02:03:49.535815 916722 solver.cpp:218] Iteration 994500 (16.7063 iter/s, 29.9289s/500 iters), loss = 0.0666549
I0830 02:03:49.535871 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0666638 (* 1 = 0.0666638 loss)
I0830 02:03:49.535879 916722 sgd_solver.cpp:106] Iteration 994500, lr = 0.01
I0830 02:04:19.427280 916722 solver.cpp:218] Iteration 995000 (16.7268 iter/s, 29.8921s/500 iters), loss = 0.187249
I0830 02:04:19.427348 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.187258 (* 1 = 0.187258 loss)
I0830 02:04:19.427357 916722 sgd_solver.cpp:106] Iteration 995000, lr = 0.01
I0830 02:04:49.334208 916722 solver.cpp:218] Iteration 995500 (16.7182 iter/s, 29.9075s/500 iters), loss = 0.0778317
I0830 02:04:49.334264 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0778407 (* 1 = 0.0778407 loss)
I0830 02:04:49.334271 916722 sgd_solver.cpp:106] Iteration 995500, lr = 0.01
I0830 02:05:19.228539 916722 solver.cpp:218] Iteration 996000 (16.7252 iter/s, 29.8949s/500 iters), loss = 0.214946
I0830 02:05:19.228600 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.214955 (* 1 = 0.214955 loss)
I0830 02:05:19.228608 916722 sgd_solver.cpp:106] Iteration 996000, lr = 0.01
I0830 02:05:49.134578 916722 solver.cpp:218] Iteration 996500 (16.7187 iter/s, 29.9066s/500 iters), loss = 0.0730545
I0830 02:05:49.134631 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0730633 (* 1 = 0.0730633 loss)
I0830 02:05:49.134639 916722 sgd_solver.cpp:106] Iteration 996500, lr = 0.01
I0830 02:06:19.026783 916722 solver.cpp:218] Iteration 997000 (16.7265 iter/s, 29.8928s/500 iters), loss = 0.172132
I0830 02:06:19.026841 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.172141 (* 1 = 0.172141 loss)
I0830 02:06:19.026850 916722 sgd_solver.cpp:106] Iteration 997000, lr = 0.01
I0830 02:06:48.953861 916722 solver.cpp:218] Iteration 997500 (16.707 iter/s, 29.9276s/500 iters), loss = 0.14497
I0830 02:06:48.953913 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.144978 (* 1 = 0.144978 loss)
I0830 02:06:48.953922 916722 sgd_solver.cpp:106] Iteration 997500, lr = 0.01
I0830 02:07:18.858234 916722 solver.cpp:218] Iteration 998000 (16.7197 iter/s, 29.9049s/500 iters), loss = 0.402311
I0830 02:07:18.858294 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.40232 (* 1 = 0.40232 loss)
I0830 02:07:18.858304 916722 sgd_solver.cpp:106] Iteration 998000, lr = 0.01
I0830 02:07:48.770439 916722 solver.cpp:218] Iteration 998500 (16.7153 iter/s, 29.9127s/500 iters), loss = 0.307052
I0830 02:07:48.770493 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.307061 (* 1 = 0.307061 loss)
I0830 02:07:48.770503 916722 sgd_solver.cpp:106] Iteration 998500, lr = 0.01
I0830 02:08:18.674274 916722 solver.cpp:218] Iteration 999000 (16.72 iter/s, 29.9043s/500 iters), loss = 0.16014
I0830 02:08:18.674335 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.160149 (* 1 = 0.160149 loss)
I0830 02:08:18.674343 916722 sgd_solver.cpp:106] Iteration 999000, lr = 0.01
I0830 02:08:48.604146 916722 solver.cpp:218] Iteration 999500 (16.7055 iter/s, 29.9303s/500 iters), loss = 0.173487
I0830 02:08:48.604202 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.173496 (* 1 = 0.173496 loss)
I0830 02:08:48.604211 916722 sgd_solver.cpp:106] Iteration 999500, lr = 0.01
I0830 02:09:18.431844 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_1000000.caffemodel
I0830 02:09:18.451017 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_1000000.solverstate
I0830 02:09:18.457283 916722 solver.cpp:330] Iteration 1000000, Testing net (#0)
I0830 02:09:33.884790 916722 solver.cpp:397]     Test net output #0: accuracy = 0.9003
I0830 02:09:33.884840 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.325481 (* 1 = 0.325481 loss)
I0830 02:09:33.943562 916722 solver.cpp:218] Iteration 1000000 (11.0278 iter/s, 45.34s/500 iters), loss = 0.335167
I0830 02:09:33.943589 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.335176 (* 1 = 0.335176 loss)
I0830 02:09:33.943598 916722 sgd_solver.cpp:106] Iteration 1000000, lr = 0.01
I0830 02:10:03.724949 916722 solver.cpp:218] Iteration 1000500 (16.7888 iter/s, 29.7818s/500 iters), loss = 0.104094
I0830 02:10:03.725023 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104103 (* 1 = 0.104103 loss)
I0830 02:10:03.725042 916722 sgd_solver.cpp:106] Iteration 1000500, lr = 0.01
I0830 02:10:33.595469 916722 solver.cpp:218] Iteration 1001000 (16.7387 iter/s, 29.8709s/500 iters), loss = 0.24884
I0830 02:10:33.595525 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.248849 (* 1 = 0.248849 loss)
I0830 02:10:33.595535 916722 sgd_solver.cpp:106] Iteration 1001000, lr = 0.01
I0830 02:11:03.515787 916722 solver.cpp:218] Iteration 1001500 (16.7109 iter/s, 29.9207s/500 iters), loss = 0.290184
I0830 02:11:03.515846 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.290193 (* 1 = 0.290193 loss)
I0830 02:11:03.515856 916722 sgd_solver.cpp:106] Iteration 1001500, lr = 0.01
I0830 02:11:33.423324 916722 solver.cpp:218] Iteration 1002000 (16.718 iter/s, 29.9079s/500 iters), loss = 0.180239
I0830 02:11:33.423379 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.180248 (* 1 = 0.180248 loss)
I0830 02:11:33.423389 916722 sgd_solver.cpp:106] Iteration 1002000, lr = 0.01
I0830 02:12:03.347918 916722 solver.cpp:218] Iteration 1002500 (16.7085 iter/s, 29.9249s/500 iters), loss = 0.203754
I0830 02:12:03.347976 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.203763 (* 1 = 0.203763 loss)
I0830 02:12:03.347985 916722 sgd_solver.cpp:106] Iteration 1002500, lr = 0.01
I0830 02:12:33.277810 916722 solver.cpp:218] Iteration 1003000 (16.7055 iter/s, 29.9302s/500 iters), loss = 0.258142
I0830 02:12:33.277861 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.258151 (* 1 = 0.258151 loss)
I0830 02:12:33.277871 916722 sgd_solver.cpp:106] Iteration 1003000, lr = 0.01
I0830 02:13:03.209272 916722 solver.cpp:218] Iteration 1003500 (16.7047 iter/s, 29.9318s/500 iters), loss = 0.0839057
I0830 02:13:03.209331 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0839149 (* 1 = 0.0839149 loss)
I0830 02:13:03.209339 916722 sgd_solver.cpp:106] Iteration 1003500, lr = 0.01
I0830 02:13:33.136266 916722 solver.cpp:218] Iteration 1004000 (16.7072 iter/s, 29.9273s/500 iters), loss = 0.0222873
I0830 02:13:33.136322 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0222963 (* 1 = 0.0222963 loss)
I0830 02:13:33.136332 916722 sgd_solver.cpp:106] Iteration 1004000, lr = 0.01
I0830 02:14:03.076726 916722 solver.cpp:218] Iteration 1004500 (16.6997 iter/s, 29.9407s/500 iters), loss = 0.0447992
I0830 02:14:03.076795 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0448082 (* 1 = 0.0448082 loss)
I0830 02:14:03.076803 916722 sgd_solver.cpp:106] Iteration 1004500, lr = 0.01
I0830 02:14:33.004721 916722 solver.cpp:218] Iteration 1005000 (16.7066 iter/s, 29.9282s/500 iters), loss = 0.149348
I0830 02:14:33.004776 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.149357 (* 1 = 0.149357 loss)
I0830 02:14:33.004786 916722 sgd_solver.cpp:106] Iteration 1005000, lr = 0.01
I0830 02:15:02.933421 916722 solver.cpp:218] Iteration 1005500 (16.7062 iter/s, 29.929s/500 iters), loss = 0.148704
I0830 02:15:02.933483 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.148712 (* 1 = 0.148712 loss)
I0830 02:15:02.933491 916722 sgd_solver.cpp:106] Iteration 1005500, lr = 0.01
I0830 02:15:32.863971 916722 solver.cpp:218] Iteration 1006000 (16.7052 iter/s, 29.9308s/500 iters), loss = 0.0433056
I0830 02:15:32.864025 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0433143 (* 1 = 0.0433143 loss)
I0830 02:15:32.864034 916722 sgd_solver.cpp:106] Iteration 1006000, lr = 0.01
I0830 02:16:02.814255 916722 solver.cpp:218] Iteration 1006500 (16.6942 iter/s, 29.9505s/500 iters), loss = 0.184587
I0830 02:16:02.814314 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.184595 (* 1 = 0.184595 loss)
I0830 02:16:02.814322 916722 sgd_solver.cpp:106] Iteration 1006500, lr = 0.01
I0830 02:16:32.742918 916722 solver.cpp:218] Iteration 1007000 (16.7063 iter/s, 29.9289s/500 iters), loss = 0.132399
I0830 02:16:32.742970 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.132408 (* 1 = 0.132408 loss)
I0830 02:16:32.742997 916722 sgd_solver.cpp:106] Iteration 1007000, lr = 0.01
I0830 02:17:02.666198 916722 solver.cpp:218] Iteration 1007500 (16.7093 iter/s, 29.9235s/500 iters), loss = 0.0524263
I0830 02:17:02.666275 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0524349 (* 1 = 0.0524349 loss)
I0830 02:17:02.666285 916722 sgd_solver.cpp:106] Iteration 1007500, lr = 0.01
I0830 02:17:32.570677 916722 solver.cpp:218] Iteration 1008000 (16.7198 iter/s, 29.9047s/500 iters), loss = 0.19548
I0830 02:17:32.570734 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.195488 (* 1 = 0.195488 loss)
I0830 02:17:32.570742 916722 sgd_solver.cpp:106] Iteration 1008000, lr = 0.01
I0830 02:18:02.477629 916722 solver.cpp:218] Iteration 1008500 (16.7184 iter/s, 29.9072s/500 iters), loss = 0.13915
I0830 02:18:02.477689 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139159 (* 1 = 0.139159 loss)
I0830 02:18:02.477697 916722 sgd_solver.cpp:106] Iteration 1008500, lr = 0.01
I0830 02:18:32.396430 916722 solver.cpp:218] Iteration 1009000 (16.7118 iter/s, 29.919s/500 iters), loss = 0.104776
I0830 02:18:32.396505 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104785 (* 1 = 0.104785 loss)
I0830 02:18:32.396517 916722 sgd_solver.cpp:106] Iteration 1009000, lr = 0.01
I0830 02:19:02.334132 916722 solver.cpp:218] Iteration 1009500 (16.7013 iter/s, 29.9379s/500 iters), loss = 0.0951319
I0830 02:19:02.334192 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0951405 (* 1 = 0.0951405 loss)
I0830 02:19:02.334200 916722 sgd_solver.cpp:106] Iteration 1009500, lr = 0.01
I0830 02:19:32.271319 916722 solver.cpp:218] Iteration 1010000 (16.7015 iter/s, 29.9374s/500 iters), loss = 0.237909
I0830 02:19:32.271373 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.237918 (* 1 = 0.237918 loss)
I0830 02:19:32.271381 916722 sgd_solver.cpp:106] Iteration 1010000, lr = 0.01
I0830 02:20:02.200186 916722 solver.cpp:218] Iteration 1010500 (16.7062 iter/s, 29.9291s/500 iters), loss = 0.124513
I0830 02:20:02.200246 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.124522 (* 1 = 0.124522 loss)
I0830 02:20:02.200254 916722 sgd_solver.cpp:106] Iteration 1010500, lr = 0.01
I0830 02:20:32.127471 916722 solver.cpp:218] Iteration 1011000 (16.7071 iter/s, 29.9275s/500 iters), loss = 0.184802
I0830 02:20:32.127528 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.184811 (* 1 = 0.184811 loss)
I0830 02:20:32.127539 916722 sgd_solver.cpp:106] Iteration 1011000, lr = 0.01
I0830 02:21:02.082521 916722 solver.cpp:218] Iteration 1011500 (16.6916 iter/s, 29.9552s/500 iters), loss = 0.12962
I0830 02:21:02.082578 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.129629 (* 1 = 0.129629 loss)
I0830 02:21:02.082587 916722 sgd_solver.cpp:106] Iteration 1011500, lr = 0.01
I0830 02:21:32.022356 916722 solver.cpp:218] Iteration 1012000 (16.7001 iter/s, 29.94s/500 iters), loss = 0.200864
I0830 02:21:32.022410 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.200872 (* 1 = 0.200872 loss)
I0830 02:21:32.022420 916722 sgd_solver.cpp:106] Iteration 1012000, lr = 0.01
I0830 02:22:01.938380 916722 solver.cpp:218] Iteration 1012500 (16.7134 iter/s, 29.9162s/500 iters), loss = 0.190879
I0830 02:22:01.938437 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.190887 (* 1 = 0.190887 loss)
I0830 02:22:01.938446 916722 sgd_solver.cpp:106] Iteration 1012500, lr = 0.01
I0830 02:22:31.862357 916722 solver.cpp:218] Iteration 1013000 (16.7089 iter/s, 29.9241s/500 iters), loss = 0.125559
I0830 02:22:31.862412 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.125567 (* 1 = 0.125567 loss)
I0830 02:22:31.862422 916722 sgd_solver.cpp:106] Iteration 1013000, lr = 0.01
I0830 02:23:01.817086 916722 solver.cpp:218] Iteration 1013500 (16.6918 iter/s, 29.9549s/500 iters), loss = 0.452003
I0830 02:23:01.817165 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.452011 (* 1 = 0.452011 loss)
I0830 02:23:01.817189 916722 sgd_solver.cpp:106] Iteration 1013500, lr = 0.01
I0830 02:23:31.737149 916722 solver.cpp:218] Iteration 1014000 (16.7111 iter/s, 29.9202s/500 iters), loss = 0.0678078
I0830 02:23:31.737202 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0678165 (* 1 = 0.0678165 loss)
I0830 02:23:31.737212 916722 sgd_solver.cpp:106] Iteration 1014000, lr = 0.01
I0830 02:24:01.672935 916722 solver.cpp:218] Iteration 1014500 (16.7023 iter/s, 29.9359s/500 iters), loss = 0.0806215
I0830 02:24:01.672993 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0806302 (* 1 = 0.0806302 loss)
I0830 02:24:01.673002 916722 sgd_solver.cpp:106] Iteration 1014500, lr = 0.01
I0830 02:24:31.603443 916722 solver.cpp:218] Iteration 1015000 (16.7053 iter/s, 29.9307s/500 iters), loss = 0.277794
I0830 02:24:31.603495 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.277803 (* 1 = 0.277803 loss)
I0830 02:24:31.603505 916722 sgd_solver.cpp:106] Iteration 1015000, lr = 0.01
I0830 02:25:01.522588 916722 solver.cpp:218] Iteration 1015500 (16.7116 iter/s, 29.9193s/500 iters), loss = 0.0798163
I0830 02:25:01.522646 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0798249 (* 1 = 0.0798249 loss)
I0830 02:25:01.522655 916722 sgd_solver.cpp:106] Iteration 1015500, lr = 0.01
I0830 02:25:31.441606 916722 solver.cpp:218] Iteration 1016000 (16.7117 iter/s, 29.9192s/500 iters), loss = 0.109051
I0830 02:25:31.441661 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109059 (* 1 = 0.109059 loss)
I0830 02:25:31.441673 916722 sgd_solver.cpp:106] Iteration 1016000, lr = 0.01
I0830 02:26:01.362902 916722 solver.cpp:218] Iteration 1016500 (16.7104 iter/s, 29.9214s/500 iters), loss = 0.0674807
I0830 02:26:01.362962 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0674892 (* 1 = 0.0674892 loss)
I0830 02:26:01.362972 916722 sgd_solver.cpp:106] Iteration 1016500, lr = 0.01
I0830 02:26:31.287748 916722 solver.cpp:218] Iteration 1017000 (16.7085 iter/s, 29.925s/500 iters), loss = 0.276791
I0830 02:26:31.287804 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.276799 (* 1 = 0.276799 loss)
I0830 02:26:31.287813 916722 sgd_solver.cpp:106] Iteration 1017000, lr = 0.01
I0830 02:27:01.223515 916722 solver.cpp:218] Iteration 1017500 (16.7024 iter/s, 29.9359s/500 iters), loss = 0.267619
I0830 02:27:01.223573 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.267628 (* 1 = 0.267628 loss)
I0830 02:27:01.223582 916722 sgd_solver.cpp:106] Iteration 1017500, lr = 0.01
I0830 02:27:31.165544 916722 solver.cpp:218] Iteration 1018000 (16.6989 iter/s, 29.9422s/500 iters), loss = 0.27099
I0830 02:27:31.165598 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.270998 (* 1 = 0.270998 loss)
I0830 02:27:31.165607 916722 sgd_solver.cpp:106] Iteration 1018000, lr = 0.01
I0830 02:28:01.117496 916722 solver.cpp:218] Iteration 1018500 (16.6938 iter/s, 29.9512s/500 iters), loss = 0.278205
I0830 02:28:01.117552 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.278214 (* 1 = 0.278214 loss)
I0830 02:28:01.117561 916722 sgd_solver.cpp:106] Iteration 1018500, lr = 0.01
I0830 02:28:31.057227 916722 solver.cpp:218] Iteration 1019000 (16.7007 iter/s, 29.9389s/500 iters), loss = 0.152001
I0830 02:28:31.057279 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152009 (* 1 = 0.152009 loss)
I0830 02:28:31.057287 916722 sgd_solver.cpp:106] Iteration 1019000, lr = 0.01
I0830 02:29:01.001405 916722 solver.cpp:218] Iteration 1019500 (16.6982 iter/s, 29.9434s/500 iters), loss = 0.240284
I0830 02:29:01.001462 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.240292 (* 1 = 0.240292 loss)
I0830 02:29:01.001471 916722 sgd_solver.cpp:106] Iteration 1019500, lr = 0.01
I0830 02:29:30.921178 916722 solver.cpp:218] Iteration 1020000 (16.7118 iter/s, 29.919s/500 iters), loss = 0.0743577
I0830 02:29:30.921233 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.074366 (* 1 = 0.074366 loss)
I0830 02:29:30.921254 916722 sgd_solver.cpp:106] Iteration 1020000, lr = 0.01
I0830 02:30:00.891029 916722 solver.cpp:218] Iteration 1020500 (16.6838 iter/s, 29.9692s/500 iters), loss = 0.241058
I0830 02:30:00.891098 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.241067 (* 1 = 0.241067 loss)
I0830 02:30:00.891108 916722 sgd_solver.cpp:106] Iteration 1020500, lr = 0.01
I0830 02:30:30.815660 916722 solver.cpp:218] Iteration 1021000 (16.709 iter/s, 29.924s/500 iters), loss = 0.0870097
I0830 02:30:30.815716 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0870178 (* 1 = 0.0870178 loss)
I0830 02:30:30.815724 916722 sgd_solver.cpp:106] Iteration 1021000, lr = 0.01
I0830 02:31:00.780028 916722 solver.cpp:218] Iteration 1021500 (16.6868 iter/s, 29.9638s/500 iters), loss = 0.0976666
I0830 02:31:00.780087 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0976746 (* 1 = 0.0976746 loss)
I0830 02:31:00.780097 916722 sgd_solver.cpp:106] Iteration 1021500, lr = 0.01
I0830 02:31:30.728026 916722 solver.cpp:218] Iteration 1022000 (16.6959 iter/s, 29.9474s/500 iters), loss = 0.0142935
I0830 02:31:30.728085 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0143015 (* 1 = 0.0143015 loss)
I0830 02:31:30.728094 916722 sgd_solver.cpp:106] Iteration 1022000, lr = 0.01
I0830 02:32:00.666152 916722 solver.cpp:218] Iteration 1022500 (16.7014 iter/s, 29.9376s/500 iters), loss = 0.216421
I0830 02:32:00.666209 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.216429 (* 1 = 0.216429 loss)
I0830 02:32:00.666218 916722 sgd_solver.cpp:106] Iteration 1022500, lr = 0.01
I0830 02:32:30.583263 916722 solver.cpp:218] Iteration 1023000 (16.7131 iter/s, 29.9166s/500 iters), loss = 0.0939271
I0830 02:32:30.583315 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0939353 (* 1 = 0.0939353 loss)
I0830 02:32:30.583325 916722 sgd_solver.cpp:106] Iteration 1023000, lr = 0.01
I0830 02:33:00.500716 916722 solver.cpp:218] Iteration 1023500 (16.7129 iter/s, 29.917s/500 iters), loss = 0.218872
I0830 02:33:00.500792 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.21888 (* 1 = 0.21888 loss)
I0830 02:33:00.500799 916722 sgd_solver.cpp:106] Iteration 1023500, lr = 0.01
I0830 02:33:30.427641 916722 solver.cpp:218] Iteration 1024000 (16.7076 iter/s, 29.9265s/500 iters), loss = 0.384401
I0830 02:33:30.427698 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.384409 (* 1 = 0.384409 loss)
I0830 02:33:30.427708 916722 sgd_solver.cpp:106] Iteration 1024000, lr = 0.01
I0830 02:34:00.360375 916722 solver.cpp:218] Iteration 1024500 (16.7044 iter/s, 29.9323s/500 iters), loss = 0.201158
I0830 02:34:00.360440 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.201166 (* 1 = 0.201166 loss)
I0830 02:34:00.360450 916722 sgd_solver.cpp:106] Iteration 1024500, lr = 0.01
I0830 02:34:30.266613 916722 solver.cpp:218] Iteration 1025000 (16.7192 iter/s, 29.9058s/500 iters), loss = 0.262585
I0830 02:34:30.266667 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.262593 (* 1 = 0.262593 loss)
I0830 02:34:30.266678 916722 sgd_solver.cpp:106] Iteration 1025000, lr = 0.01
I0830 02:35:00.178189 916722 solver.cpp:218] Iteration 1025500 (16.7162 iter/s, 29.9112s/500 iters), loss = 0.310724
I0830 02:35:00.178252 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.310732 (* 1 = 0.310732 loss)
I0830 02:35:00.178261 916722 sgd_solver.cpp:106] Iteration 1025500, lr = 0.01
I0830 02:35:30.096928 916722 solver.cpp:218] Iteration 1026000 (16.7121 iter/s, 29.9184s/500 iters), loss = 0.196647
I0830 02:35:30.096984 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.196655 (* 1 = 0.196655 loss)
I0830 02:35:30.096994 916722 sgd_solver.cpp:106] Iteration 1026000, lr = 0.01
I0830 02:35:59.998863 916722 solver.cpp:218] Iteration 1026500 (16.7215 iter/s, 29.9016s/500 iters), loss = 0.173524
I0830 02:35:59.998924 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.173532 (* 1 = 0.173532 loss)
I0830 02:35:59.998932 916722 sgd_solver.cpp:106] Iteration 1026500, lr = 0.01
I0830 02:36:29.892580 916722 solver.cpp:218] Iteration 1027000 (16.7261 iter/s, 29.8934s/500 iters), loss = 0.174159
I0830 02:36:29.892634 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.174167 (* 1 = 0.174167 loss)
I0830 02:36:29.892645 916722 sgd_solver.cpp:106] Iteration 1027000, lr = 0.01
I0830 02:36:59.786830 916722 solver.cpp:218] Iteration 1027500 (16.7258 iter/s, 29.8939s/500 iters), loss = 0.0754295
I0830 02:36:59.786901 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0754374 (* 1 = 0.0754374 loss)
I0830 02:36:59.786911 916722 sgd_solver.cpp:106] Iteration 1027500, lr = 0.01
I0830 02:37:29.680934 916722 solver.cpp:218] Iteration 1028000 (16.7259 iter/s, 29.8938s/500 iters), loss = 0.0758447
I0830 02:37:29.680985 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0758526 (* 1 = 0.0758526 loss)
I0830 02:37:29.680994 916722 sgd_solver.cpp:106] Iteration 1028000, lr = 0.01
I0830 02:37:59.584017 916722 solver.cpp:218] Iteration 1028500 (16.7208 iter/s, 29.9028s/500 iters), loss = 0.103488
I0830 02:37:59.584081 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.103496 (* 1 = 0.103496 loss)
I0830 02:37:59.584090 916722 sgd_solver.cpp:106] Iteration 1028500, lr = 0.01
I0830 02:38:29.470681 916722 solver.cpp:218] Iteration 1029000 (16.73 iter/s, 29.8864s/500 iters), loss = 0.303434
I0830 02:38:29.470736 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.303442 (* 1 = 0.303442 loss)
I0830 02:38:29.470743 916722 sgd_solver.cpp:106] Iteration 1029000, lr = 0.01
I0830 02:38:59.372354 916722 solver.cpp:218] Iteration 1029500 (16.7216 iter/s, 29.9014s/500 iters), loss = 0.169759
I0830 02:38:59.372417 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.169767 (* 1 = 0.169767 loss)
I0830 02:38:59.372431 916722 sgd_solver.cpp:106] Iteration 1029500, lr = 0.01
I0830 02:39:29.257052 916722 solver.cpp:218] Iteration 1030000 (16.7311 iter/s, 29.8844s/500 iters), loss = 0.141829
I0830 02:39:29.257107 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.141837 (* 1 = 0.141837 loss)
I0830 02:39:29.257115 916722 sgd_solver.cpp:106] Iteration 1030000, lr = 0.01
I0830 02:39:59.142495 916722 solver.cpp:218] Iteration 1030500 (16.7307 iter/s, 29.8852s/500 iters), loss = 0.179543
I0830 02:39:59.142557 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.179551 (* 1 = 0.179551 loss)
I0830 02:39:59.142566 916722 sgd_solver.cpp:106] Iteration 1030500, lr = 0.01
I0830 02:40:29.060199 916722 solver.cpp:218] Iteration 1031000 (16.7126 iter/s, 29.9175s/500 iters), loss = 0.240277
I0830 02:40:29.060251 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.240286 (* 1 = 0.240286 loss)
I0830 02:40:29.060261 916722 sgd_solver.cpp:106] Iteration 1031000, lr = 0.01
I0830 02:40:58.994441 916722 solver.cpp:218] Iteration 1031500 (16.7034 iter/s, 29.934s/500 iters), loss = 0.108093
I0830 02:40:58.994500 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.108101 (* 1 = 0.108101 loss)
I0830 02:40:58.994508 916722 sgd_solver.cpp:106] Iteration 1031500, lr = 0.01
I0830 02:41:28.900323 916722 solver.cpp:218] Iteration 1032000 (16.7192 iter/s, 29.9057s/500 iters), loss = 0.0377906
I0830 02:41:28.900373 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0377987 (* 1 = 0.0377987 loss)
I0830 02:41:28.900382 916722 sgd_solver.cpp:106] Iteration 1032000, lr = 0.01
I0830 02:41:58.825762 916722 solver.cpp:218] Iteration 1032500 (16.7083 iter/s, 29.9253s/500 iters), loss = 0.0281433
I0830 02:41:58.825819 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0281516 (* 1 = 0.0281516 loss)
I0830 02:41:58.825827 916722 sgd_solver.cpp:106] Iteration 1032500, lr = 0.01
I0830 02:42:28.739404 916722 solver.cpp:218] Iteration 1033000 (16.7149 iter/s, 29.9135s/500 iters), loss = 0.15594
I0830 02:42:28.739460 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.155948 (* 1 = 0.155948 loss)
I0830 02:42:28.739470 916722 sgd_solver.cpp:106] Iteration 1033000, lr = 0.01
I0830 02:42:58.649714 916722 solver.cpp:218] Iteration 1033500 (16.7167 iter/s, 29.9101s/500 iters), loss = 0.163272
I0830 02:42:58.649789 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.16328 (* 1 = 0.16328 loss)
I0830 02:42:58.649798 916722 sgd_solver.cpp:106] Iteration 1033500, lr = 0.01
I0830 02:43:28.565223 916722 solver.cpp:218] Iteration 1034000 (16.7138 iter/s, 29.9153s/500 iters), loss = 0.0278997
I0830 02:43:28.565279 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0279079 (* 1 = 0.0279079 loss)
I0830 02:43:28.565289 916722 sgd_solver.cpp:106] Iteration 1034000, lr = 0.01
I0830 02:43:58.482868 916722 solver.cpp:218] Iteration 1034500 (16.7126 iter/s, 29.9175s/500 iters), loss = 0.0118096
I0830 02:43:58.482929 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0118178 (* 1 = 0.0118178 loss)
I0830 02:43:58.482939 916722 sgd_solver.cpp:106] Iteration 1034500, lr = 0.01
I0830 02:44:28.390661 916722 solver.cpp:218] Iteration 1035000 (16.7181 iter/s, 29.9076s/500 iters), loss = 0.0680221
I0830 02:44:28.390715 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0680302 (* 1 = 0.0680302 loss)
I0830 02:44:28.390725 916722 sgd_solver.cpp:106] Iteration 1035000, lr = 0.01
I0830 02:44:58.312913 916722 solver.cpp:218] Iteration 1035500 (16.71 iter/s, 29.9221s/500 iters), loss = 0.311372
I0830 02:44:58.312974 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.31138 (* 1 = 0.31138 loss)
I0830 02:44:58.312983 916722 sgd_solver.cpp:106] Iteration 1035500, lr = 0.01
I0830 02:45:28.249310 916722 solver.cpp:218] Iteration 1036000 (16.7022 iter/s, 29.9363s/500 iters), loss = 0.212881
I0830 02:45:28.249359 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.212889 (* 1 = 0.212889 loss)
I0830 02:45:28.249369 916722 sgd_solver.cpp:106] Iteration 1036000, lr = 0.01
I0830 02:45:58.167029 916722 solver.cpp:218] Iteration 1036500 (16.7126 iter/s, 29.9176s/500 iters), loss = 0.0426442
I0830 02:45:58.167086 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0426523 (* 1 = 0.0426523 loss)
I0830 02:45:58.167094 916722 sgd_solver.cpp:106] Iteration 1036500, lr = 0.01
I0830 02:46:28.092065 916722 solver.cpp:218] Iteration 1037000 (16.7085 iter/s, 29.9249s/500 iters), loss = 0.0782882
I0830 02:46:28.092119 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0782964 (* 1 = 0.0782964 loss)
I0830 02:46:28.092129 916722 sgd_solver.cpp:106] Iteration 1037000, lr = 0.01
I0830 02:46:58.031399 916722 solver.cpp:218] Iteration 1037500 (16.7005 iter/s, 29.9392s/500 iters), loss = 0.173304
I0830 02:46:58.031461 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.173312 (* 1 = 0.173312 loss)
I0830 02:46:58.031469 916722 sgd_solver.cpp:106] Iteration 1037500, lr = 0.01
I0830 02:47:27.962136 916722 solver.cpp:218] Iteration 1038000 (16.7053 iter/s, 29.9306s/500 iters), loss = 0.0900682
I0830 02:47:27.962193 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0900763 (* 1 = 0.0900763 loss)
I0830 02:47:27.962203 916722 sgd_solver.cpp:106] Iteration 1038000, lr = 0.01
I0830 02:47:57.884567 916722 solver.cpp:218] Iteration 1038500 (16.7099 iter/s, 29.9223s/500 iters), loss = 0.486513
I0830 02:47:57.884631 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.486521 (* 1 = 0.486521 loss)
I0830 02:47:57.884640 916722 sgd_solver.cpp:106] Iteration 1038500, lr = 0.01
I0830 02:48:27.787286 916722 solver.cpp:218] Iteration 1039000 (16.7209 iter/s, 29.9026s/500 iters), loss = 0.210467
I0830 02:48:27.787341 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.210475 (* 1 = 0.210475 loss)
I0830 02:48:27.787350 916722 sgd_solver.cpp:106] Iteration 1039000, lr = 0.01
I0830 02:48:57.691213 916722 solver.cpp:218] Iteration 1039500 (16.7203 iter/s, 29.9038s/500 iters), loss = 0.472469
I0830 02:48:57.691275 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.472477 (* 1 = 0.472477 loss)
I0830 02:48:57.691284 916722 sgd_solver.cpp:106] Iteration 1039500, lr = 0.01
I0830 02:49:27.589218 916722 solver.cpp:218] Iteration 1040000 (16.7236 iter/s, 29.8979s/500 iters), loss = 0.403519
I0830 02:49:27.589284 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.403527 (* 1 = 0.403527 loss)
I0830 02:49:27.589293 916722 sgd_solver.cpp:106] Iteration 1040000, lr = 0.01
I0830 02:49:57.489897 916722 solver.cpp:218] Iteration 1040500 (16.7221 iter/s, 29.9006s/500 iters), loss = 0.0721447
I0830 02:49:57.489966 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0721527 (* 1 = 0.0721527 loss)
I0830 02:49:57.489974 916722 sgd_solver.cpp:106] Iteration 1040500, lr = 0.01
I0830 02:50:27.385964 916722 solver.cpp:218] Iteration 1041000 (16.7247 iter/s, 29.896s/500 iters), loss = 0.16805
I0830 02:50:27.386015 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.168058 (* 1 = 0.168058 loss)
I0830 02:50:27.386024 916722 sgd_solver.cpp:106] Iteration 1041000, lr = 0.01
I0830 02:50:57.317876 916722 solver.cpp:218] Iteration 1041500 (16.7046 iter/s, 29.9318s/500 iters), loss = 0.48782
I0830 02:50:57.317939 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.487828 (* 1 = 0.487828 loss)
I0830 02:50:57.317946 916722 sgd_solver.cpp:106] Iteration 1041500, lr = 0.01
I0830 02:51:27.200130 916722 solver.cpp:218] Iteration 1042000 (16.7324 iter/s, 29.8822s/500 iters), loss = 0.0456878
I0830 02:51:27.200184 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0456959 (* 1 = 0.0456959 loss)
I0830 02:51:27.200193 916722 sgd_solver.cpp:106] Iteration 1042000, lr = 0.01
I0830 02:51:57.100433 916722 solver.cpp:218] Iteration 1042500 (16.7223 iter/s, 29.9002s/500 iters), loss = 0.125501
I0830 02:51:57.100507 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.125509 (* 1 = 0.125509 loss)
I0830 02:51:57.100517 916722 sgd_solver.cpp:106] Iteration 1042500, lr = 0.01
I0830 02:52:27.002779 916722 solver.cpp:218] Iteration 1043000 (16.7211 iter/s, 29.9023s/500 iters), loss = 0.159359
I0830 02:52:27.002832 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159367 (* 1 = 0.159367 loss)
I0830 02:52:27.002840 916722 sgd_solver.cpp:106] Iteration 1043000, lr = 0.01
I0830 02:52:56.922188 916722 solver.cpp:218] Iteration 1043500 (16.7116 iter/s, 29.9193s/500 iters), loss = 0.0908801
I0830 02:52:56.922250 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.090888 (* 1 = 0.090888 loss)
I0830 02:52:56.922258 916722 sgd_solver.cpp:106] Iteration 1043500, lr = 0.01
I0830 02:53:26.833174 916722 solver.cpp:218] Iteration 1044000 (16.7163 iter/s, 29.9109s/500 iters), loss = 0.322705
I0830 02:53:26.833227 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.322713 (* 1 = 0.322713 loss)
I0830 02:53:26.833236 916722 sgd_solver.cpp:106] Iteration 1044000, lr = 0.01
I0830 02:53:56.740818 916722 solver.cpp:218] Iteration 1044500 (16.7182 iter/s, 29.9076s/500 iters), loss = 0.386549
I0830 02:53:56.740876 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.386556 (* 1 = 0.386556 loss)
I0830 02:53:56.740885 916722 sgd_solver.cpp:106] Iteration 1044500, lr = 0.01
I0830 02:54:26.639776 916722 solver.cpp:218] Iteration 1045000 (16.723 iter/s, 29.8989s/500 iters), loss = 0.107108
I0830 02:54:26.639830 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.107116 (* 1 = 0.107116 loss)
I0830 02:54:26.639840 916722 sgd_solver.cpp:106] Iteration 1045000, lr = 0.01
I0830 02:54:56.522985 916722 solver.cpp:218] Iteration 1045500 (16.7318 iter/s, 29.8831s/500 iters), loss = 0.030455
I0830 02:54:56.523043 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0304631 (* 1 = 0.0304631 loss)
I0830 02:54:56.523052 916722 sgd_solver.cpp:106] Iteration 1045500, lr = 0.01
I0830 02:55:26.420573 916722 solver.cpp:218] Iteration 1046000 (16.7238 iter/s, 29.8975s/500 iters), loss = 0.164512
I0830 02:55:26.420629 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.16452 (* 1 = 0.16452 loss)
I0830 02:55:26.420640 916722 sgd_solver.cpp:106] Iteration 1046000, lr = 0.01
I0830 02:55:56.326817 916722 solver.cpp:218] Iteration 1046500 (16.719 iter/s, 29.9062s/500 iters), loss = 0.21135
I0830 02:55:56.326892 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.211358 (* 1 = 0.211358 loss)
I0830 02:55:56.326901 916722 sgd_solver.cpp:106] Iteration 1046500, lr = 0.01
I0830 02:56:26.246656 916722 solver.cpp:218] Iteration 1047000 (16.7114 iter/s, 29.9198s/500 iters), loss = 0.186213
I0830 02:56:26.246711 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.186221 (* 1 = 0.186221 loss)
I0830 02:56:26.246721 916722 sgd_solver.cpp:106] Iteration 1047000, lr = 0.01
I0830 02:56:56.174762 916722 solver.cpp:218] Iteration 1047500 (16.7067 iter/s, 29.9281s/500 iters), loss = 0.174147
I0830 02:56:56.174822 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.174155 (* 1 = 0.174155 loss)
I0830 02:56:56.174830 916722 sgd_solver.cpp:106] Iteration 1047500, lr = 0.01
I0830 02:57:26.098728 916722 solver.cpp:218] Iteration 1048000 (16.709 iter/s, 29.9239s/500 iters), loss = 0.490736
I0830 02:57:26.098783 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.490744 (* 1 = 0.490744 loss)
I0830 02:57:26.098793 916722 sgd_solver.cpp:106] Iteration 1048000, lr = 0.01
I0830 02:57:55.993103 916722 solver.cpp:218] Iteration 1048500 (16.7256 iter/s, 29.8943s/500 iters), loss = 0.0644514
I0830 02:57:55.993162 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0644595 (* 1 = 0.0644595 loss)
I0830 02:57:55.993171 916722 sgd_solver.cpp:106] Iteration 1048500, lr = 0.01
I0830 02:58:25.897783 916722 solver.cpp:218] Iteration 1049000 (16.7198 iter/s, 29.9046s/500 iters), loss = 0.136191
I0830 02:58:25.897835 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.136199 (* 1 = 0.136199 loss)
I0830 02:58:25.897845 916722 sgd_solver.cpp:106] Iteration 1049000, lr = 0.01
I0830 02:58:55.800868 916722 solver.cpp:218] Iteration 1049500 (16.7207 iter/s, 29.903s/500 iters), loss = 0.258582
I0830 02:58:55.800922 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.25859 (* 1 = 0.25859 loss)
I0830 02:58:55.800930 916722 sgd_solver.cpp:106] Iteration 1049500, lr = 0.01
I0830 02:59:25.632570 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_1050000.caffemodel
I0830 02:59:25.652150 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_1050000.solverstate
I0830 02:59:25.658411 916722 solver.cpp:330] Iteration 1050000, Testing net (#0)
I0830 02:59:41.082032 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8816
I0830 02:59:41.082085 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.401957 (* 1 = 0.401957 loss)
I0830 02:59:41.141059 916722 solver.cpp:218] Iteration 1050000 (11.0278 iter/s, 45.3401s/500 iters), loss = 0.221997
I0830 02:59:41.141089 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.222005 (* 1 = 0.222005 loss)
I0830 02:59:41.141098 916722 sgd_solver.cpp:106] Iteration 1050000, lr = 0.01
I0830 03:00:10.895442 916722 solver.cpp:218] Iteration 1050500 (16.8043 iter/s, 29.7543s/500 iters), loss = 0.472434
I0830 03:00:10.895495 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.472442 (* 1 = 0.472442 loss)
I0830 03:00:10.895504 916722 sgd_solver.cpp:106] Iteration 1050500, lr = 0.01
I0830 03:00:40.723096 916722 solver.cpp:218] Iteration 1051000 (16.763 iter/s, 29.8276s/500 iters), loss = 0.204549
I0830 03:00:40.723156 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.204557 (* 1 = 0.204557 loss)
I0830 03:00:40.723165 916722 sgd_solver.cpp:106] Iteration 1051000, lr = 0.01
I0830 03:01:10.605530 916722 solver.cpp:218] Iteration 1051500 (16.7323 iter/s, 29.8824s/500 iters), loss = 0.162287
I0830 03:01:10.605581 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.162295 (* 1 = 0.162295 loss)
I0830 03:01:10.605590 916722 sgd_solver.cpp:106] Iteration 1051500, lr = 0.01
I0830 03:01:40.491187 916722 solver.cpp:218] Iteration 1052000 (16.7305 iter/s, 29.8856s/500 iters), loss = 0.24769
I0830 03:01:40.491258 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.247698 (* 1 = 0.247698 loss)
I0830 03:01:40.491271 916722 sgd_solver.cpp:106] Iteration 1052000, lr = 0.01
I0830 03:02:10.360349 916722 solver.cpp:218] Iteration 1052500 (16.7398 iter/s, 29.8689s/500 iters), loss = 0.27589
I0830 03:02:10.360404 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.275898 (* 1 = 0.275898 loss)
I0830 03:02:10.360414 916722 sgd_solver.cpp:106] Iteration 1052500, lr = 0.01
I0830 03:02:40.242851 916722 solver.cpp:218] Iteration 1053000 (16.7324 iter/s, 29.8822s/500 iters), loss = 0.128874
I0830 03:02:40.242913 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128882 (* 1 = 0.128882 loss)
I0830 03:02:40.242923 916722 sgd_solver.cpp:106] Iteration 1053000, lr = 0.01
I0830 03:03:10.112035 916722 solver.cpp:218] Iteration 1053500 (16.7398 iter/s, 29.8689s/500 iters), loss = 0.124792
I0830 03:03:10.112088 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.1248 (* 1 = 0.1248 loss)
I0830 03:03:10.112097 916722 sgd_solver.cpp:106] Iteration 1053500, lr = 0.01
I0830 03:03:39.986768 916722 solver.cpp:218] Iteration 1054000 (16.7367 iter/s, 29.8745s/500 iters), loss = 0.358573
I0830 03:03:39.986827 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.358581 (* 1 = 0.358581 loss)
I0830 03:03:39.986836 916722 sgd_solver.cpp:106] Iteration 1054000, lr = 0.01
I0830 03:04:09.856036 916722 solver.cpp:218] Iteration 1054500 (16.7398 iter/s, 29.869s/500 iters), loss = 0.0562063
I0830 03:04:09.856091 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0562144 (* 1 = 0.0562144 loss)
I0830 03:04:09.856101 916722 sgd_solver.cpp:106] Iteration 1054500, lr = 0.01
I0830 03:04:39.736222 916722 solver.cpp:218] Iteration 1055000 (16.7336 iter/s, 29.8799s/500 iters), loss = 0.0620892
I0830 03:04:39.736282 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0620971 (* 1 = 0.0620971 loss)
I0830 03:04:39.736290 916722 sgd_solver.cpp:106] Iteration 1055000, lr = 0.01
I0830 03:05:09.615171 916722 solver.cpp:218] Iteration 1055500 (16.7343 iter/s, 29.8787s/500 iters), loss = 0.11471
I0830 03:05:09.615223 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.114718 (* 1 = 0.114718 loss)
I0830 03:05:09.615232 916722 sgd_solver.cpp:106] Iteration 1055500, lr = 0.01
I0830 03:05:39.508510 916722 solver.cpp:218] Iteration 1056000 (16.7263 iter/s, 29.8931s/500 iters), loss = 0.264271
I0830 03:05:39.508571 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.264279 (* 1 = 0.264279 loss)
I0830 03:05:39.508580 916722 sgd_solver.cpp:106] Iteration 1056000, lr = 0.01
I0830 03:06:09.405889 916722 solver.cpp:218] Iteration 1056500 (16.724 iter/s, 29.8972s/500 iters), loss = 0.11263
I0830 03:06:09.405941 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112638 (* 1 = 0.112638 loss)
I0830 03:06:09.405949 916722 sgd_solver.cpp:106] Iteration 1056500, lr = 0.01
I0830 03:06:39.312824 916722 solver.cpp:218] Iteration 1057000 (16.7186 iter/s, 29.9067s/500 iters), loss = 0.0468554
I0830 03:06:39.312885 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0468629 (* 1 = 0.0468629 loss)
I0830 03:06:39.312893 916722 sgd_solver.cpp:106] Iteration 1057000, lr = 0.01
I0830 03:07:09.230767 916722 solver.cpp:218] Iteration 1057500 (16.7125 iter/s, 29.9177s/500 iters), loss = 0.307521
I0830 03:07:09.230821 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.307528 (* 1 = 0.307528 loss)
I0830 03:07:09.230829 916722 sgd_solver.cpp:106] Iteration 1057500, lr = 0.01
I0830 03:07:39.154479 916722 solver.cpp:218] Iteration 1058000 (16.7093 iter/s, 29.9235s/500 iters), loss = 0.100098
I0830 03:07:39.154541 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.100105 (* 1 = 0.100105 loss)
I0830 03:07:39.154549 916722 sgd_solver.cpp:106] Iteration 1058000, lr = 0.01
I0830 03:08:09.086993 916722 solver.cpp:218] Iteration 1058500 (16.7043 iter/s, 29.9323s/500 iters), loss = 0.150157
I0830 03:08:09.087047 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.150164 (* 1 = 0.150164 loss)
I0830 03:08:09.087057 916722 sgd_solver.cpp:106] Iteration 1058500, lr = 0.01
I0830 03:08:39.015516 916722 solver.cpp:218] Iteration 1059000 (16.7066 iter/s, 29.9284s/500 iters), loss = 0.230405
I0830 03:08:39.015588 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.230412 (* 1 = 0.230412 loss)
I0830 03:08:39.015596 916722 sgd_solver.cpp:106] Iteration 1059000, lr = 0.01
I0830 03:09:08.970463 916722 solver.cpp:218] Iteration 1059500 (16.6918 iter/s, 29.9548s/500 iters), loss = 0.0375877
I0830 03:09:08.970516 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0375952 (* 1 = 0.0375952 loss)
I0830 03:09:08.970525 916722 sgd_solver.cpp:106] Iteration 1059500, lr = 0.01
I0830 03:09:38.898633 916722 solver.cpp:218] Iteration 1060000 (16.7067 iter/s, 29.928s/500 iters), loss = 0.254048
I0830 03:09:38.898692 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.254055 (* 1 = 0.254055 loss)
I0830 03:09:38.898701 916722 sgd_solver.cpp:106] Iteration 1060000, lr = 0.01
I0830 03:10:08.845870 916722 solver.cpp:218] Iteration 1060500 (16.6961 iter/s, 29.9471s/500 iters), loss = 0.243189
I0830 03:10:08.845921 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.243196 (* 1 = 0.243196 loss)
I0830 03:10:08.845930 916722 sgd_solver.cpp:106] Iteration 1060500, lr = 0.01
I0830 03:10:38.779054 916722 solver.cpp:218] Iteration 1061000 (16.7039 iter/s, 29.9331s/500 iters), loss = 0.0490939
I0830 03:10:38.779116 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0491013 (* 1 = 0.0491013 loss)
I0830 03:10:38.779124 916722 sgd_solver.cpp:106] Iteration 1061000, lr = 0.01
I0830 03:11:08.711441 916722 solver.cpp:218] Iteration 1061500 (16.7044 iter/s, 29.9322s/500 iters), loss = 0.0916148
I0830 03:11:08.711495 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0916222 (* 1 = 0.0916222 loss)
I0830 03:11:08.711505 916722 sgd_solver.cpp:106] Iteration 1061500, lr = 0.01
I0830 03:11:38.650831 916722 solver.cpp:218] Iteration 1062000 (16.7005 iter/s, 29.9393s/500 iters), loss = 0.254856
I0830 03:11:38.650892 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.254863 (* 1 = 0.254863 loss)
I0830 03:11:38.650899 916722 sgd_solver.cpp:106] Iteration 1062000, lr = 0.01
I0830 03:12:08.572059 916722 solver.cpp:218] Iteration 1062500 (16.7106 iter/s, 29.9211s/500 iters), loss = 0.242312
I0830 03:12:08.572114 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.242319 (* 1 = 0.242319 loss)
I0830 03:12:08.572125 916722 sgd_solver.cpp:106] Iteration 1062500, lr = 0.01
I0830 03:12:38.486346 916722 solver.cpp:218] Iteration 1063000 (16.7145 iter/s, 29.9142s/500 iters), loss = 0.183725
I0830 03:12:38.486404 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.183732 (* 1 = 0.183732 loss)
I0830 03:12:38.486413 916722 sgd_solver.cpp:106] Iteration 1063000, lr = 0.01
I0830 03:13:08.427745 916722 solver.cpp:218] Iteration 1063500 (16.6994 iter/s, 29.9413s/500 iters), loss = 0.214653
I0830 03:13:08.427800 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.214661 (* 1 = 0.214661 loss)
I0830 03:13:08.427810 916722 sgd_solver.cpp:106] Iteration 1063500, lr = 0.01
I0830 03:13:38.341261 916722 solver.cpp:218] Iteration 1064000 (16.7149 iter/s, 29.9134s/500 iters), loss = 0.276356
I0830 03:13:38.341320 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.276364 (* 1 = 0.276364 loss)
I0830 03:13:38.341329 916722 sgd_solver.cpp:106] Iteration 1064000, lr = 0.01
I0830 03:14:08.254703 916722 solver.cpp:218] Iteration 1064500 (16.715 iter/s, 29.9133s/500 iters), loss = 0.0924151
I0830 03:14:08.254755 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0924224 (* 1 = 0.0924224 loss)
I0830 03:14:08.254765 916722 sgd_solver.cpp:106] Iteration 1064500, lr = 0.01
I0830 03:14:38.186415 916722 solver.cpp:218] Iteration 1065000 (16.7048 iter/s, 29.9316s/500 iters), loss = 0.0527803
I0830 03:14:38.186475 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0527876 (* 1 = 0.0527876 loss)
I0830 03:14:38.186484 916722 sgd_solver.cpp:106] Iteration 1065000, lr = 0.01
I0830 03:15:08.111583 916722 solver.cpp:218] Iteration 1065500 (16.7084 iter/s, 29.9251s/500 iters), loss = 0.0645327
I0830 03:15:08.111636 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0645401 (* 1 = 0.0645401 loss)
I0830 03:15:08.111646 916722 sgd_solver.cpp:106] Iteration 1065500, lr = 0.01
I0830 03:15:38.039544 916722 solver.cpp:218] Iteration 1066000 (16.7068 iter/s, 29.9279s/500 iters), loss = 0.236072
I0830 03:15:38.039616 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.23608 (* 1 = 0.23608 loss)
I0830 03:15:38.039625 916722 sgd_solver.cpp:106] Iteration 1066000, lr = 0.01
I0830 03:16:07.991376 916722 solver.cpp:218] Iteration 1066500 (16.6935 iter/s, 29.9517s/500 iters), loss = 0.132721
I0830 03:16:07.991428 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.132728 (* 1 = 0.132728 loss)
I0830 03:16:07.991438 916722 sgd_solver.cpp:106] Iteration 1066500, lr = 0.01
I0830 03:16:37.935190 916722 solver.cpp:218] Iteration 1067000 (16.698 iter/s, 29.9437s/500 iters), loss = 0.0212798
I0830 03:16:37.935248 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0212871 (* 1 = 0.0212871 loss)
I0830 03:16:37.935256 916722 sgd_solver.cpp:106] Iteration 1067000, lr = 0.01
I0830 03:17:07.878201 916722 solver.cpp:218] Iteration 1067500 (16.6984 iter/s, 29.9429s/500 iters), loss = 0.0190931
I0830 03:17:07.878250 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0191005 (* 1 = 0.0191005 loss)
I0830 03:17:07.878260 916722 sgd_solver.cpp:106] Iteration 1067500, lr = 0.01
I0830 03:17:37.829646 916722 solver.cpp:218] Iteration 1068000 (16.6937 iter/s, 29.9514s/500 iters), loss = 0.153075
I0830 03:17:37.829707 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.153082 (* 1 = 0.153082 loss)
I0830 03:17:37.829716 916722 sgd_solver.cpp:106] Iteration 1068000, lr = 0.01
I0830 03:18:07.778389 916722 solver.cpp:218] Iteration 1068500 (16.6952 iter/s, 29.9487s/500 iters), loss = 0.365915
I0830 03:18:07.778441 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.365922 (* 1 = 0.365922 loss)
I0830 03:18:07.778450 916722 sgd_solver.cpp:106] Iteration 1068500, lr = 0.01
I0830 03:18:37.708420 916722 solver.cpp:218] Iteration 1069000 (16.7057 iter/s, 29.93s/500 iters), loss = 0.146295
I0830 03:18:37.708487 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.146302 (* 1 = 0.146302 loss)
I0830 03:18:37.708496 916722 sgd_solver.cpp:106] Iteration 1069000, lr = 0.01
I0830 03:19:07.653352 916722 solver.cpp:218] Iteration 1069500 (16.6974 iter/s, 29.9448s/500 iters), loss = 0.345789
I0830 03:19:07.653404 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.345797 (* 1 = 0.345797 loss)
I0830 03:19:07.653414 916722 sgd_solver.cpp:106] Iteration 1069500, lr = 0.01
I0830 03:19:37.578331 916722 solver.cpp:218] Iteration 1070000 (16.7085 iter/s, 29.9249s/500 iters), loss = 0.27444
I0830 03:19:37.578389 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.274447 (* 1 = 0.274447 loss)
I0830 03:19:37.578398 916722 sgd_solver.cpp:106] Iteration 1070000, lr = 0.01
I0830 03:20:07.515332 916722 solver.cpp:218] Iteration 1070500 (16.7018 iter/s, 29.9369s/500 iters), loss = 0.247562
I0830 03:20:07.515384 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.247569 (* 1 = 0.247569 loss)
I0830 03:20:07.515393 916722 sgd_solver.cpp:106] Iteration 1070500, lr = 0.01
I0830 03:20:37.440073 916722 solver.cpp:218] Iteration 1071000 (16.7086 iter/s, 29.9247s/500 iters), loss = 0.234016
I0830 03:20:37.440133 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.234023 (* 1 = 0.234023 loss)
I0830 03:20:37.440141 916722 sgd_solver.cpp:106] Iteration 1071000, lr = 0.01
I0830 03:21:07.385910 916722 solver.cpp:218] Iteration 1071500 (16.6969 iter/s, 29.9458s/500 iters), loss = 0.126189
I0830 03:21:07.385962 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.126197 (* 1 = 0.126197 loss)
I0830 03:21:07.385970 916722 sgd_solver.cpp:106] Iteration 1071500, lr = 0.01
I0830 03:21:37.311650 916722 solver.cpp:218] Iteration 1072000 (16.7081 iter/s, 29.9257s/500 iters), loss = 0.112449
I0830 03:21:37.311722 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112456 (* 1 = 0.112456 loss)
I0830 03:21:37.311731 916722 sgd_solver.cpp:106] Iteration 1072000, lr = 0.01
I0830 03:22:07.249323 916722 solver.cpp:218] Iteration 1072500 (16.7014 iter/s, 29.9376s/500 iters), loss = 0.0574387
I0830 03:22:07.249377 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0574463 (* 1 = 0.0574463 loss)
I0830 03:22:07.249385 916722 sgd_solver.cpp:106] Iteration 1072500, lr = 0.01
I0830 03:22:37.195829 916722 solver.cpp:218] Iteration 1073000 (16.6965 iter/s, 29.9464s/500 iters), loss = 0.134853
I0830 03:22:37.195888 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.134861 (* 1 = 0.134861 loss)
I0830 03:22:37.195896 916722 sgd_solver.cpp:106] Iteration 1073000, lr = 0.01
I0830 03:23:07.131752 916722 solver.cpp:218] Iteration 1073500 (16.7024 iter/s, 29.9359s/500 iters), loss = 0.337575
I0830 03:23:07.131808 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.337582 (* 1 = 0.337582 loss)
I0830 03:23:07.131819 916722 sgd_solver.cpp:106] Iteration 1073500, lr = 0.01
I0830 03:23:37.083880 916722 solver.cpp:218] Iteration 1074000 (16.6933 iter/s, 29.9521s/500 iters), loss = 0.0810165
I0830 03:23:37.083938 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0810241 (* 1 = 0.0810241 loss)
I0830 03:23:37.083946 916722 sgd_solver.cpp:106] Iteration 1074000, lr = 0.01
I0830 03:24:07.019743 916722 solver.cpp:218] Iteration 1074500 (16.7024 iter/s, 29.9358s/500 iters), loss = 0.224541
I0830 03:24:07.019795 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.224548 (* 1 = 0.224548 loss)
I0830 03:24:07.019806 916722 sgd_solver.cpp:106] Iteration 1074500, lr = 0.01
I0830 03:24:36.987150 916722 solver.cpp:218] Iteration 1075000 (16.6848 iter/s, 29.9673s/500 iters), loss = 0.0583435
I0830 03:24:36.987210 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0583507 (* 1 = 0.0583507 loss)
I0830 03:24:36.987217 916722 sgd_solver.cpp:106] Iteration 1075000, lr = 0.01
I0830 03:25:06.897151 916722 solver.cpp:218] Iteration 1075500 (16.7169 iter/s, 29.9099s/500 iters), loss = 0.053972
I0830 03:25:06.897204 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0539793 (* 1 = 0.0539793 loss)
I0830 03:25:06.897214 916722 sgd_solver.cpp:106] Iteration 1075500, lr = 0.01
I0830 03:25:36.828755 916722 solver.cpp:218] Iteration 1076000 (16.7048 iter/s, 29.9315s/500 iters), loss = 0.292654
I0830 03:25:36.828811 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.292662 (* 1 = 0.292662 loss)
I0830 03:25:36.828820 916722 sgd_solver.cpp:106] Iteration 1076000, lr = 0.01
I0830 03:26:06.756532 916722 solver.cpp:218] Iteration 1076500 (16.7069 iter/s, 29.9277s/500 iters), loss = 0.146252
I0830 03:26:06.756584 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.146259 (* 1 = 0.146259 loss)
I0830 03:26:06.756594 916722 sgd_solver.cpp:106] Iteration 1076500, lr = 0.01
I0830 03:26:36.679317 916722 solver.cpp:218] Iteration 1077000 (16.7097 iter/s, 29.9227s/500 iters), loss = 0.0998009
I0830 03:26:36.679375 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0998083 (* 1 = 0.0998083 loss)
I0830 03:26:36.679383 916722 sgd_solver.cpp:106] Iteration 1077000, lr = 0.01
I0830 03:27:06.596189 916722 solver.cpp:218] Iteration 1077500 (16.713 iter/s, 29.9168s/500 iters), loss = 0.182423
I0830 03:27:06.596244 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.18243 (* 1 = 0.18243 loss)
I0830 03:27:06.596254 916722 sgd_solver.cpp:106] Iteration 1077500, lr = 0.01
I0830 03:27:36.541426 916722 solver.cpp:218] Iteration 1078000 (16.6972 iter/s, 29.9452s/500 iters), loss = 0.0467338
I0830 03:27:36.541488 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0467412 (* 1 = 0.0467412 loss)
I0830 03:27:36.541497 916722 sgd_solver.cpp:106] Iteration 1078000, lr = 0.01
I0830 03:28:06.462958 916722 solver.cpp:218] Iteration 1078500 (16.7104 iter/s, 29.9215s/500 iters), loss = 0.150214
I0830 03:28:06.463021 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.150221 (* 1 = 0.150221 loss)
I0830 03:28:06.463030 916722 sgd_solver.cpp:106] Iteration 1078500, lr = 0.01
I0830 03:28:36.386866 916722 solver.cpp:218] Iteration 1079000 (16.7091 iter/s, 29.9238s/500 iters), loss = 0.0898998
I0830 03:28:36.386938 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0899075 (* 1 = 0.0899075 loss)
I0830 03:28:36.386947 916722 sgd_solver.cpp:106] Iteration 1079000, lr = 0.01
I0830 03:29:06.289593 916722 solver.cpp:218] Iteration 1079500 (16.7209 iter/s, 29.9026s/500 iters), loss = 0.175294
I0830 03:29:06.289645 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.175302 (* 1 = 0.175302 loss)
I0830 03:29:06.289654 916722 sgd_solver.cpp:106] Iteration 1079500, lr = 0.01
I0830 03:29:36.186589 916722 solver.cpp:218] Iteration 1080000 (16.7241 iter/s, 29.8969s/500 iters), loss = 0.0384755
I0830 03:29:36.186646 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0384832 (* 1 = 0.0384832 loss)
I0830 03:29:36.186655 916722 sgd_solver.cpp:106] Iteration 1080000, lr = 0.01
I0830 03:30:06.076936 916722 solver.cpp:218] Iteration 1080500 (16.7278 iter/s, 29.8903s/500 iters), loss = 0.231709
I0830 03:30:06.076988 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.231717 (* 1 = 0.231717 loss)
I0830 03:30:06.076997 916722 sgd_solver.cpp:106] Iteration 1080500, lr = 0.01
I0830 03:30:35.971894 916722 solver.cpp:218] Iteration 1081000 (16.7253 iter/s, 29.8949s/500 iters), loss = 0.22173
I0830 03:30:35.971952 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.221738 (* 1 = 0.221738 loss)
I0830 03:30:35.971961 916722 sgd_solver.cpp:106] Iteration 1081000, lr = 0.01
I0830 03:31:05.854715 916722 solver.cpp:218] Iteration 1081500 (16.7321 iter/s, 29.8828s/500 iters), loss = 0.128463
I0830 03:31:05.854768 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128471 (* 1 = 0.128471 loss)
I0830 03:31:05.854776 916722 sgd_solver.cpp:106] Iteration 1081500, lr = 0.01
I0830 03:31:35.742758 916722 solver.cpp:218] Iteration 1082000 (16.7291 iter/s, 29.888s/500 iters), loss = 0.154544
I0830 03:31:35.742817 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.154552 (* 1 = 0.154552 loss)
I0830 03:31:35.742825 916722 sgd_solver.cpp:106] Iteration 1082000, lr = 0.01
I0830 03:32:05.636729 916722 solver.cpp:218] Iteration 1082500 (16.7258 iter/s, 29.8939s/500 iters), loss = 0.147729
I0830 03:32:05.636781 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.147736 (* 1 = 0.147736 loss)
I0830 03:32:05.636790 916722 sgd_solver.cpp:106] Iteration 1082500, lr = 0.01
I0830 03:32:35.523546 916722 solver.cpp:218] Iteration 1083000 (16.7298 iter/s, 29.8868s/500 iters), loss = 0.314537
I0830 03:32:35.523605 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.314545 (* 1 = 0.314545 loss)
I0830 03:32:35.523613 916722 sgd_solver.cpp:106] Iteration 1083000, lr = 0.01
I0830 03:33:05.424377 916722 solver.cpp:218] Iteration 1083500 (16.722 iter/s, 29.9008s/500 iters), loss = 0.194253
I0830 03:33:05.424436 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.194261 (* 1 = 0.194261 loss)
I0830 03:33:05.424448 916722 sgd_solver.cpp:106] Iteration 1083500, lr = 0.01
I0830 03:33:35.295382 916722 solver.cpp:218] Iteration 1084000 (16.7387 iter/s, 29.8709s/500 iters), loss = 0.0342197
I0830 03:33:35.295439 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0342277 (* 1 = 0.0342277 loss)
I0830 03:33:35.295449 916722 sgd_solver.cpp:106] Iteration 1084000, lr = 0.01
I0830 03:34:05.193125 916722 solver.cpp:218] Iteration 1084500 (16.7237 iter/s, 29.8977s/500 iters), loss = 0.25141
I0830 03:34:05.193173 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.251418 (* 1 = 0.251418 loss)
I0830 03:34:05.193184 916722 sgd_solver.cpp:106] Iteration 1084500, lr = 0.01
I0830 03:34:35.074831 916722 solver.cpp:218] Iteration 1085000 (16.7327 iter/s, 29.8817s/500 iters), loss = 0.474113
I0830 03:34:35.074898 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.474121 (* 1 = 0.474121 loss)
I0830 03:34:35.074909 916722 sgd_solver.cpp:106] Iteration 1085000, lr = 0.01
I0830 03:35:04.951668 916722 solver.cpp:218] Iteration 1085500 (16.7354 iter/s, 29.8768s/500 iters), loss = 0.345497
I0830 03:35:04.951720 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.345505 (* 1 = 0.345505 loss)
I0830 03:35:04.951730 916722 sgd_solver.cpp:106] Iteration 1085500, lr = 0.01
I0830 03:35:34.828891 916722 solver.cpp:218] Iteration 1086000 (16.7352 iter/s, 29.8772s/500 iters), loss = 0.225425
I0830 03:35:34.828948 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.225433 (* 1 = 0.225433 loss)
I0830 03:35:34.828956 916722 sgd_solver.cpp:106] Iteration 1086000, lr = 0.01
I0830 03:36:04.711742 916722 solver.cpp:218] Iteration 1086500 (16.7322 iter/s, 29.8825s/500 iters), loss = 0.216479
I0830 03:36:04.711794 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.216487 (* 1 = 0.216487 loss)
I0830 03:36:04.711804 916722 sgd_solver.cpp:106] Iteration 1086500, lr = 0.01
I0830 03:36:34.605195 916722 solver.cpp:218] Iteration 1087000 (16.7264 iter/s, 29.8929s/500 iters), loss = 0.0724199
I0830 03:36:34.605254 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0724281 (* 1 = 0.0724281 loss)
I0830 03:36:34.605263 916722 sgd_solver.cpp:106] Iteration 1087000, lr = 0.01
I0830 03:37:04.504223 916722 solver.cpp:218] Iteration 1087500 (16.7232 iter/s, 29.8985s/500 iters), loss = 0.115653
I0830 03:37:04.504273 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115661 (* 1 = 0.115661 loss)
I0830 03:37:04.504283 916722 sgd_solver.cpp:106] Iteration 1087500, lr = 0.01
I0830 03:37:34.403439 916722 solver.cpp:218] Iteration 1088000 (16.7231 iter/s, 29.8987s/500 iters), loss = 0.0781491
I0830 03:37:34.403496 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0781571 (* 1 = 0.0781571 loss)
I0830 03:37:34.403506 916722 sgd_solver.cpp:106] Iteration 1088000, lr = 0.01
I0830 03:38:04.262622 916722 solver.cpp:218] Iteration 1088500 (16.7455 iter/s, 29.8587s/500 iters), loss = 0.0920646
I0830 03:38:04.262674 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0920727 (* 1 = 0.0920727 loss)
I0830 03:38:04.262686 916722 sgd_solver.cpp:106] Iteration 1088500, lr = 0.01
I0830 03:38:34.134706 916722 solver.cpp:218] Iteration 1089000 (16.7383 iter/s, 29.8716s/500 iters), loss = 0.137967
I0830 03:38:34.134765 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.137975 (* 1 = 0.137975 loss)
I0830 03:38:34.134773 916722 sgd_solver.cpp:106] Iteration 1089000, lr = 0.01
I0830 03:39:04.019763 916722 solver.cpp:218] Iteration 1089500 (16.731 iter/s, 29.8846s/500 iters), loss = 0.131028
I0830 03:39:04.019815 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131036 (* 1 = 0.131036 loss)
I0830 03:39:04.019824 916722 sgd_solver.cpp:106] Iteration 1089500, lr = 0.01
I0830 03:39:33.933077 916722 solver.cpp:218] Iteration 1090000 (16.7152 iter/s, 29.9129s/500 iters), loss = 0.12419
I0830 03:39:33.933136 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.124198 (* 1 = 0.124198 loss)
I0830 03:39:33.933145 916722 sgd_solver.cpp:106] Iteration 1090000, lr = 0.01
I0830 03:40:03.827796 916722 solver.cpp:218] Iteration 1090500 (16.7256 iter/s, 29.8943s/500 iters), loss = 0.0493003
I0830 03:40:03.827847 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0493082 (* 1 = 0.0493082 loss)
I0830 03:40:03.827855 916722 sgd_solver.cpp:106] Iteration 1090500, lr = 0.01
I0830 03:40:33.742415 916722 solver.cpp:218] Iteration 1091000 (16.7145 iter/s, 29.9142s/500 iters), loss = 0.297685
I0830 03:40:33.742475 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.297693 (* 1 = 0.297693 loss)
I0830 03:40:33.742483 916722 sgd_solver.cpp:106] Iteration 1091000, lr = 0.01
I0830 03:41:03.648334 916722 solver.cpp:218] Iteration 1091500 (16.7193 iter/s, 29.9055s/500 iters), loss = 0.138104
I0830 03:41:03.648384 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.138112 (* 1 = 0.138112 loss)
I0830 03:41:03.648404 916722 sgd_solver.cpp:106] Iteration 1091500, lr = 0.01
I0830 03:41:33.509864 916722 solver.cpp:218] Iteration 1092000 (16.7441 iter/s, 29.8612s/500 iters), loss = 0.0255487
I0830 03:41:33.509938 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0255565 (* 1 = 0.0255565 loss)
I0830 03:41:33.509946 916722 sgd_solver.cpp:106] Iteration 1092000, lr = 0.01
I0830 03:42:03.376505 916722 solver.cpp:218] Iteration 1092500 (16.7413 iter/s, 29.8663s/500 iters), loss = 0.128629
I0830 03:42:03.376551 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128636 (* 1 = 0.128636 loss)
I0830 03:42:03.376560 916722 sgd_solver.cpp:106] Iteration 1092500, lr = 0.01
I0830 03:42:33.263027 916722 solver.cpp:218] Iteration 1093000 (16.7301 iter/s, 29.8862s/500 iters), loss = 0.145568
I0830 03:42:33.263085 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.145576 (* 1 = 0.145576 loss)
I0830 03:42:33.263093 916722 sgd_solver.cpp:106] Iteration 1093000, lr = 0.01
I0830 03:43:03.178814 916722 solver.cpp:218] Iteration 1093500 (16.7138 iter/s, 29.9155s/500 iters), loss = 0.179743
I0830 03:43:03.178866 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.17975 (* 1 = 0.17975 loss)
I0830 03:43:03.178875 916722 sgd_solver.cpp:106] Iteration 1093500, lr = 0.01
I0830 03:43:33.056082 916722 solver.cpp:218] Iteration 1094000 (16.7353 iter/s, 29.877s/500 iters), loss = 0.152882
I0830 03:43:33.056143 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152889 (* 1 = 0.152889 loss)
I0830 03:43:33.056150 916722 sgd_solver.cpp:106] Iteration 1094000, lr = 0.01
I0830 03:44:02.920471 916722 solver.cpp:218] Iteration 1094500 (16.7425 iter/s, 29.8641s/500 iters), loss = 0.0979506
I0830 03:44:02.920523 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.097958 (* 1 = 0.097958 loss)
I0830 03:44:02.920532 916722 sgd_solver.cpp:106] Iteration 1094500, lr = 0.01
I0830 03:44:32.795792 916722 solver.cpp:218] Iteration 1095000 (16.7364 iter/s, 29.875s/500 iters), loss = 0.0930114
I0830 03:44:32.795855 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0930189 (* 1 = 0.0930189 loss)
I0830 03:44:32.795862 916722 sgd_solver.cpp:106] Iteration 1095000, lr = 0.01
I0830 03:45:02.676841 916722 solver.cpp:218] Iteration 1095500 (16.7332 iter/s, 29.8808s/500 iters), loss = 0.155667
I0830 03:45:02.676890 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.155674 (* 1 = 0.155674 loss)
I0830 03:45:02.676899 916722 sgd_solver.cpp:106] Iteration 1095500, lr = 0.01
I0830 03:45:32.550958 916722 solver.cpp:218] Iteration 1096000 (16.737 iter/s, 29.8739s/500 iters), loss = 0.179756
I0830 03:45:32.551020 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.179763 (* 1 = 0.179763 loss)
I0830 03:45:32.551028 916722 sgd_solver.cpp:106] Iteration 1096000, lr = 0.01
I0830 03:46:02.415050 916722 solver.cpp:218] Iteration 1096500 (16.7427 iter/s, 29.8638s/500 iters), loss = 0.192031
I0830 03:46:02.415102 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.192038 (* 1 = 0.192038 loss)
I0830 03:46:02.415109 916722 sgd_solver.cpp:106] Iteration 1096500, lr = 0.01
I0830 03:46:32.286072 916722 solver.cpp:218] Iteration 1097000 (16.7388 iter/s, 29.8708s/500 iters), loss = 0.0235625
I0830 03:46:32.286132 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0235699 (* 1 = 0.0235699 loss)
I0830 03:46:32.286141 916722 sgd_solver.cpp:106] Iteration 1097000, lr = 0.01
I0830 03:47:02.151320 916722 solver.cpp:218] Iteration 1097500 (16.742 iter/s, 29.865s/500 iters), loss = 0.206402
I0830 03:47:02.151371 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.20641 (* 1 = 0.20641 loss)
I0830 03:47:02.151381 916722 sgd_solver.cpp:106] Iteration 1097500, lr = 0.01
I0830 03:47:32.021621 916722 solver.cpp:218] Iteration 1098000 (16.7392 iter/s, 29.8701s/500 iters), loss = 0.0850013
I0830 03:47:32.021692 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0850088 (* 1 = 0.0850088 loss)
I0830 03:47:32.021703 916722 sgd_solver.cpp:106] Iteration 1098000, lr = 0.01
I0830 03:48:01.881095 916722 solver.cpp:218] Iteration 1098500 (16.7452 iter/s, 29.8592s/500 iters), loss = 0.0916644
I0830 03:48:01.881147 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0916718 (* 1 = 0.0916718 loss)
I0830 03:48:01.881155 916722 sgd_solver.cpp:106] Iteration 1098500, lr = 0.01
I0830 03:48:31.745656 916722 solver.cpp:218] Iteration 1099000 (16.7424 iter/s, 29.8643s/500 iters), loss = 0.101464
I0830 03:48:31.745718 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101471 (* 1 = 0.101471 loss)
I0830 03:48:31.745726 916722 sgd_solver.cpp:106] Iteration 1099000, lr = 0.01
I0830 03:49:01.610412 916722 solver.cpp:218] Iteration 1099500 (16.7423 iter/s, 29.8645s/500 iters), loss = 0.190693
I0830 03:49:01.610466 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.190701 (* 1 = 0.190701 loss)
I0830 03:49:01.610476 916722 sgd_solver.cpp:106] Iteration 1099500, lr = 0.01
I0830 03:49:31.388554 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_1100000.caffemodel
I0830 03:49:31.407773 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_1100000.solverstate
I0830 03:49:31.414027 916722 solver.cpp:330] Iteration 1100000, Testing net (#0)
I0830 03:49:46.824957 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8326
I0830 03:49:46.824999 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.568634 (* 1 = 0.568634 loss)
I0830 03:49:46.883735 916722 solver.cpp:218] Iteration 1100000 (11.0441 iter/s, 45.273s/500 iters), loss = 0.319397
I0830 03:49:46.883764 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.319405 (* 1 = 0.319405 loss)
I0830 03:49:46.883771 916722 sgd_solver.cpp:106] Iteration 1100000, lr = 0.01
I0830 03:50:16.646855 916722 solver.cpp:218] Iteration 1100500 (16.7994 iter/s, 29.7629s/500 iters), loss = 0.137162
I0830 03:50:16.646914 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13717 (* 1 = 0.13717 loss)
I0830 03:50:16.646921 916722 sgd_solver.cpp:106] Iteration 1100500, lr = 0.01
I0830 03:50:46.454092 916722 solver.cpp:218] Iteration 1101000 (16.7746 iter/s, 29.807s/500 iters), loss = 0.156236
I0830 03:50:46.454145 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.156243 (* 1 = 0.156243 loss)
I0830 03:50:46.454155 916722 sgd_solver.cpp:106] Iteration 1101000, lr = 0.01
I0830 03:51:16.326683 916722 solver.cpp:218] Iteration 1101500 (16.7379 iter/s, 29.8724s/500 iters), loss = 0.5551
I0830 03:51:16.326742 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.555108 (* 1 = 0.555108 loss)
I0830 03:51:16.326751 916722 sgd_solver.cpp:106] Iteration 1101500, lr = 0.01
I0830 03:51:46.208770 916722 solver.cpp:218] Iteration 1102000 (16.7325 iter/s, 29.8819s/500 iters), loss = 0.160733
I0830 03:51:46.208824 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.160741 (* 1 = 0.160741 loss)
I0830 03:51:46.208834 916722 sgd_solver.cpp:106] Iteration 1102000, lr = 0.01
I0830 03:52:16.101641 916722 solver.cpp:218] Iteration 1102500 (16.7265 iter/s, 29.8927s/500 iters), loss = 0.127578
I0830 03:52:16.101701 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.127585 (* 1 = 0.127585 loss)
I0830 03:52:16.101711 916722 sgd_solver.cpp:106] Iteration 1102500, lr = 0.01
I0830 03:52:46.004755 916722 solver.cpp:218] Iteration 1103000 (16.7208 iter/s, 29.9029s/500 iters), loss = 0.0665702
I0830 03:52:46.004808 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0665776 (* 1 = 0.0665776 loss)
I0830 03:52:46.004819 916722 sgd_solver.cpp:106] Iteration 1103000, lr = 0.01
I0830 03:53:15.907714 916722 solver.cpp:218] Iteration 1103500 (16.7209 iter/s, 29.9028s/500 iters), loss = 0.0829711
I0830 03:53:15.907778 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0829784 (* 1 = 0.0829784 loss)
I0830 03:53:15.907786 916722 sgd_solver.cpp:106] Iteration 1103500, lr = 0.01
I0830 03:53:45.815006 916722 solver.cpp:218] Iteration 1104000 (16.7184 iter/s, 29.9071s/500 iters), loss = 0.0641089
I0830 03:53:45.815071 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0641162 (* 1 = 0.0641162 loss)
I0830 03:53:45.815080 916722 sgd_solver.cpp:106] Iteration 1104000, lr = 0.01
I0830 03:54:15.726128 916722 solver.cpp:218] Iteration 1104500 (16.7163 iter/s, 29.911s/500 iters), loss = 0.183064
I0830 03:54:15.726202 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.183072 (* 1 = 0.183072 loss)
I0830 03:54:15.726209 916722 sgd_solver.cpp:106] Iteration 1104500, lr = 0.01
I0830 03:54:45.635427 916722 solver.cpp:218] Iteration 1105000 (16.7173 iter/s, 29.9091s/500 iters), loss = 0.12234
I0830 03:54:45.635481 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.122347 (* 1 = 0.122347 loss)
I0830 03:54:45.635490 916722 sgd_solver.cpp:106] Iteration 1105000, lr = 0.01
I0830 03:55:15.551223 916722 solver.cpp:218] Iteration 1105500 (16.7137 iter/s, 29.9156s/500 iters), loss = 0.057742
I0830 03:55:15.551285 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0577493 (* 1 = 0.0577493 loss)
I0830 03:55:15.551292 916722 sgd_solver.cpp:106] Iteration 1105500, lr = 0.01
I0830 03:55:45.488368 916722 solver.cpp:218] Iteration 1106000 (16.7017 iter/s, 29.937s/500 iters), loss = 0.195293
I0830 03:55:45.488421 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.195301 (* 1 = 0.195301 loss)
I0830 03:55:45.488435 916722 sgd_solver.cpp:106] Iteration 1106000, lr = 0.01
I0830 03:56:15.405761 916722 solver.cpp:218] Iteration 1106500 (16.7128 iter/s, 29.9172s/500 iters), loss = 0.289053
I0830 03:56:15.405822 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.289061 (* 1 = 0.289061 loss)
I0830 03:56:15.405829 916722 sgd_solver.cpp:106] Iteration 1106500, lr = 0.01
I0830 03:56:45.329192 916722 solver.cpp:218] Iteration 1107000 (16.7094 iter/s, 29.9233s/500 iters), loss = 0.220501
I0830 03:56:45.329246 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.220508 (* 1 = 0.220508 loss)
I0830 03:56:45.329254 916722 sgd_solver.cpp:106] Iteration 1107000, lr = 0.01
I0830 03:57:15.250430 916722 solver.cpp:218] Iteration 1107500 (16.7106 iter/s, 29.9211s/500 iters), loss = 0.0783204
I0830 03:57:15.250491 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0783275 (* 1 = 0.0783275 loss)
I0830 03:57:15.250500 916722 sgd_solver.cpp:106] Iteration 1107500, lr = 0.01
I0830 03:57:45.152770 916722 solver.cpp:218] Iteration 1108000 (16.7212 iter/s, 29.9022s/500 iters), loss = 0.117975
I0830 03:57:45.152823 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.117982 (* 1 = 0.117982 loss)
I0830 03:57:45.152832 916722 sgd_solver.cpp:106] Iteration 1108000, lr = 0.01
I0830 03:58:15.046088 916722 solver.cpp:218] Iteration 1108500 (16.7262 iter/s, 29.8932s/500 iters), loss = 0.0871909
I0830 03:58:15.046146 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.087198 (* 1 = 0.087198 loss)
I0830 03:58:15.046155 916722 sgd_solver.cpp:106] Iteration 1108500, lr = 0.01
I0830 03:58:44.934316 916722 solver.cpp:218] Iteration 1109000 (16.7291 iter/s, 29.8881s/500 iters), loss = 0.210028
I0830 03:58:44.934368 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.210036 (* 1 = 0.210036 loss)
I0830 03:58:44.934377 916722 sgd_solver.cpp:106] Iteration 1109000, lr = 0.01
I0830 03:59:14.853682 916722 solver.cpp:218] Iteration 1109500 (16.7117 iter/s, 29.9192s/500 iters), loss = 0.0760953
I0830 03:59:14.853745 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0761026 (* 1 = 0.0761026 loss)
I0830 03:59:14.853754 916722 sgd_solver.cpp:106] Iteration 1109500, lr = 0.01
I0830 03:59:44.749941 916722 solver.cpp:218] Iteration 1110000 (16.7246 iter/s, 29.8961s/500 iters), loss = 0.0619503
I0830 03:59:44.749995 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0619576 (* 1 = 0.0619576 loss)
I0830 03:59:44.750005 916722 sgd_solver.cpp:106] Iteration 1110000, lr = 0.01
I0830 04:00:14.650125 916722 solver.cpp:218] Iteration 1110500 (16.7224 iter/s, 29.9s/500 iters), loss = 0.157063
I0830 04:00:14.650199 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.15707 (* 1 = 0.15707 loss)
I0830 04:00:14.650207 916722 sgd_solver.cpp:106] Iteration 1110500, lr = 0.01
I0830 04:00:44.541779 916722 solver.cpp:218] Iteration 1111000 (16.7272 iter/s, 29.8915s/500 iters), loss = 0.0238487
I0830 04:00:44.541833 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.023856 (* 1 = 0.023856 loss)
I0830 04:00:44.541842 916722 sgd_solver.cpp:106] Iteration 1111000, lr = 0.01
I0830 04:01:14.442920 916722 solver.cpp:218] Iteration 1111500 (16.7218 iter/s, 29.901s/500 iters), loss = 0.0821926
I0830 04:01:14.442981 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0821999 (* 1 = 0.0821999 loss)
I0830 04:01:14.442991 916722 sgd_solver.cpp:106] Iteration 1111500, lr = 0.01
I0830 04:01:44.353763 916722 solver.cpp:218] Iteration 1112000 (16.7164 iter/s, 29.9107s/500 iters), loss = 0.253946
I0830 04:01:44.353816 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.253953 (* 1 = 0.253953 loss)
I0830 04:01:44.353825 916722 sgd_solver.cpp:106] Iteration 1112000, lr = 0.01
I0830 04:02:14.271060 916722 solver.cpp:218] Iteration 1112500 (16.7128 iter/s, 29.9172s/500 iters), loss = 0.0964938
I0830 04:02:14.271121 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0965012 (* 1 = 0.0965012 loss)
I0830 04:02:14.271129 916722 sgd_solver.cpp:106] Iteration 1112500, lr = 0.01
I0830 04:02:44.203281 916722 solver.cpp:218] Iteration 1113000 (16.7045 iter/s, 29.9321s/500 iters), loss = 0.119272
I0830 04:02:44.203336 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.119279 (* 1 = 0.119279 loss)
I0830 04:02:44.203346 916722 sgd_solver.cpp:106] Iteration 1113000, lr = 0.01
I0830 04:03:14.121520 916722 solver.cpp:218] Iteration 1113500 (16.7123 iter/s, 29.9181s/500 iters), loss = 0.0647738
I0830 04:03:14.121580 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0647811 (* 1 = 0.0647811 loss)
I0830 04:03:14.121589 916722 sgd_solver.cpp:106] Iteration 1113500, lr = 0.01
I0830 04:03:44.034441 916722 solver.cpp:218] Iteration 1114000 (16.7153 iter/s, 29.9128s/500 iters), loss = 0.448857
I0830 04:03:44.034495 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.448864 (* 1 = 0.448864 loss)
I0830 04:03:44.034505 916722 sgd_solver.cpp:106] Iteration 1114000, lr = 0.01
I0830 04:04:13.965293 916722 solver.cpp:218] Iteration 1114500 (16.7052 iter/s, 29.9307s/500 iters), loss = 0.101292
I0830 04:04:13.965353 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.1013 (* 1 = 0.1013 loss)
I0830 04:04:13.965361 916722 sgd_solver.cpp:106] Iteration 1114500, lr = 0.01
I0830 04:04:43.882025 916722 solver.cpp:218] Iteration 1115000 (16.7131 iter/s, 29.9166s/500 iters), loss = 0.134841
I0830 04:04:43.882078 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.134849 (* 1 = 0.134849 loss)
I0830 04:04:43.882089 916722 sgd_solver.cpp:106] Iteration 1115000, lr = 0.01
I0830 04:05:13.809938 916722 solver.cpp:218] Iteration 1115500 (16.7069 iter/s, 29.9278s/500 iters), loss = 0.169293
I0830 04:05:13.809999 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.169301 (* 1 = 0.169301 loss)
I0830 04:05:13.810007 916722 sgd_solver.cpp:106] Iteration 1115500, lr = 0.01
I0830 04:05:43.727941 916722 solver.cpp:218] Iteration 1116000 (16.7124 iter/s, 29.9179s/500 iters), loss = 0.161996
I0830 04:05:43.727993 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.162003 (* 1 = 0.162003 loss)
I0830 04:05:43.728003 916722 sgd_solver.cpp:106] Iteration 1116000, lr = 0.01
I0830 04:06:13.616506 916722 solver.cpp:218] Iteration 1116500 (16.7289 iter/s, 29.8884s/500 iters), loss = 0.194354
I0830 04:06:13.616564 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.194362 (* 1 = 0.194362 loss)
I0830 04:06:13.616573 916722 sgd_solver.cpp:106] Iteration 1116500, lr = 0.01
I0830 04:06:43.537499 916722 solver.cpp:218] Iteration 1117000 (16.7107 iter/s, 29.9209s/500 iters), loss = 0.192702
I0830 04:06:43.537564 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.192709 (* 1 = 0.192709 loss)
I0830 04:06:43.537575 916722 sgd_solver.cpp:106] Iteration 1117000, lr = 0.01
I0830 04:07:13.463881 916722 solver.cpp:218] Iteration 1117500 (16.7077 iter/s, 29.9262s/500 iters), loss = 0.0839986
I0830 04:07:13.463950 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0840061 (* 1 = 0.0840061 loss)
I0830 04:07:13.463958 916722 sgd_solver.cpp:106] Iteration 1117500, lr = 0.01
I0830 04:07:43.377020 916722 solver.cpp:218] Iteration 1118000 (16.7151 iter/s, 29.913s/500 iters), loss = 0.0118912
I0830 04:07:43.377075 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0118987 (* 1 = 0.0118987 loss)
I0830 04:07:43.377085 916722 sgd_solver.cpp:106] Iteration 1118000, lr = 0.01
I0830 04:08:13.291719 916722 solver.cpp:218] Iteration 1118500 (16.7143 iter/s, 29.9146s/500 iters), loss = 0.0426578
I0830 04:08:13.291783 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0426655 (* 1 = 0.0426655 loss)
I0830 04:08:13.291791 916722 sgd_solver.cpp:106] Iteration 1118500, lr = 0.01
I0830 04:08:43.187525 916722 solver.cpp:218] Iteration 1119000 (16.7248 iter/s, 29.8957s/500 iters), loss = 0.181258
I0830 04:08:43.187577 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.181266 (* 1 = 0.181266 loss)
I0830 04:08:43.187585 916722 sgd_solver.cpp:106] Iteration 1119000, lr = 0.01
I0830 04:09:13.115123 916722 solver.cpp:218] Iteration 1119500 (16.7071 iter/s, 29.9275s/500 iters), loss = 0.0538006
I0830 04:09:13.115185 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0538083 (* 1 = 0.0538083 loss)
I0830 04:09:13.115193 916722 sgd_solver.cpp:106] Iteration 1119500, lr = 0.01
I0830 04:09:43.032454 916722 solver.cpp:218] Iteration 1120000 (16.7128 iter/s, 29.9172s/500 iters), loss = 0.0789303
I0830 04:09:43.032505 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.078938 (* 1 = 0.078938 loss)
I0830 04:09:43.032513 916722 sgd_solver.cpp:106] Iteration 1120000, lr = 0.01
I0830 04:10:12.919212 916722 solver.cpp:218] Iteration 1120500 (16.7298 iter/s, 29.8868s/500 iters), loss = 0.22169
I0830 04:10:12.919273 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.221698 (* 1 = 0.221698 loss)
I0830 04:10:12.919281 916722 sgd_solver.cpp:106] Iteration 1120500, lr = 0.01
I0830 04:10:42.816725 916722 solver.cpp:218] Iteration 1121000 (16.7237 iter/s, 29.8977s/500 iters), loss = 0.0448774
I0830 04:10:42.816789 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0448849 (* 1 = 0.0448849 loss)
I0830 04:10:42.816798 916722 sgd_solver.cpp:106] Iteration 1121000, lr = 0.01
I0830 04:11:12.717686 916722 solver.cpp:218] Iteration 1121500 (16.7218 iter/s, 29.9012s/500 iters), loss = 0.409732
I0830 04:11:12.717746 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.40974 (* 1 = 0.40974 loss)
I0830 04:11:12.717756 916722 sgd_solver.cpp:106] Iteration 1121500, lr = 0.01
I0830 04:11:42.622913 916722 solver.cpp:218] Iteration 1122000 (16.7194 iter/s, 29.9054s/500 iters), loss = 0.0255499
I0830 04:11:42.622969 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0255574 (* 1 = 0.0255574 loss)
I0830 04:11:42.622978 916722 sgd_solver.cpp:106] Iteration 1122000, lr = 0.01
I0830 04:12:12.540964 916722 solver.cpp:218] Iteration 1122500 (16.7122 iter/s, 29.9182s/500 iters), loss = 0.419359
I0830 04:12:12.541026 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.419367 (* 1 = 0.419367 loss)
I0830 04:12:12.541035 916722 sgd_solver.cpp:106] Iteration 1122500, lr = 0.01
I0830 04:12:42.478273 916722 solver.cpp:218] Iteration 1123000 (16.7015 iter/s, 29.9375s/500 iters), loss = 0.147892
I0830 04:12:42.478330 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.147899 (* 1 = 0.147899 loss)
I0830 04:12:42.478339 916722 sgd_solver.cpp:106] Iteration 1123000, lr = 0.01
I0830 04:13:12.417771 916722 solver.cpp:218] Iteration 1123500 (16.7003 iter/s, 29.9397s/500 iters), loss = 0.212872
I0830 04:13:12.417842 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.21288 (* 1 = 0.21288 loss)
I0830 04:13:12.417855 916722 sgd_solver.cpp:106] Iteration 1123500, lr = 0.01
I0830 04:13:42.358407 916722 solver.cpp:218] Iteration 1124000 (16.6996 iter/s, 29.9408s/500 iters), loss = 0.0870205
I0830 04:13:42.358461 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0870278 (* 1 = 0.0870278 loss)
I0830 04:13:42.358471 916722 sgd_solver.cpp:106] Iteration 1124000, lr = 0.01
I0830 04:14:12.290395 916722 solver.cpp:218] Iteration 1124500 (16.7045 iter/s, 29.9321s/500 iters), loss = 0.0744123
I0830 04:14:12.290455 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0744196 (* 1 = 0.0744196 loss)
I0830 04:14:12.290464 916722 sgd_solver.cpp:106] Iteration 1124500, lr = 0.01
I0830 04:14:42.229532 916722 solver.cpp:218] Iteration 1125000 (16.7005 iter/s, 29.9393s/500 iters), loss = 0.083703
I0830 04:14:42.229586 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0837102 (* 1 = 0.0837102 loss)
I0830 04:14:42.229596 916722 sgd_solver.cpp:106] Iteration 1125000, lr = 0.01
I0830 04:15:12.156016 916722 solver.cpp:218] Iteration 1125500 (16.7075 iter/s, 29.9266s/500 iters), loss = 0.191641
I0830 04:15:12.156075 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.191648 (* 1 = 0.191648 loss)
I0830 04:15:12.156085 916722 sgd_solver.cpp:106] Iteration 1125500, lr = 0.01
I0830 04:15:42.094081 916722 solver.cpp:218] Iteration 1126000 (16.7011 iter/s, 29.9382s/500 iters), loss = 0.0236399
I0830 04:15:42.094135 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0236473 (* 1 = 0.0236473 loss)
I0830 04:15:42.094146 916722 sgd_solver.cpp:106] Iteration 1126000, lr = 0.01
I0830 04:16:12.010372 916722 solver.cpp:218] Iteration 1126500 (16.7132 iter/s, 29.9164s/500 iters), loss = 0.328787
I0830 04:16:12.010430 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.328794 (* 1 = 0.328794 loss)
I0830 04:16:12.010438 916722 sgd_solver.cpp:106] Iteration 1126500, lr = 0.01
I0830 04:16:41.944208 916722 solver.cpp:218] Iteration 1127000 (16.7035 iter/s, 29.9339s/500 iters), loss = 0.287512
I0830 04:16:41.944262 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.287519 (* 1 = 0.287519 loss)
I0830 04:16:41.944272 916722 sgd_solver.cpp:106] Iteration 1127000, lr = 0.01
I0830 04:17:11.871081 916722 solver.cpp:218] Iteration 1127500 (16.7073 iter/s, 29.927s/500 iters), loss = 0.296345
I0830 04:17:11.871141 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.296353 (* 1 = 0.296353 loss)
I0830 04:17:11.871150 916722 sgd_solver.cpp:106] Iteration 1127500, lr = 0.01
I0830 04:17:41.783581 916722 solver.cpp:218] Iteration 1128000 (16.7154 iter/s, 29.9126s/500 iters), loss = 0.0989968
I0830 04:17:41.783632 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0990042 (* 1 = 0.0990042 loss)
I0830 04:17:41.783643 916722 sgd_solver.cpp:106] Iteration 1128000, lr = 0.01
I0830 04:18:11.709690 916722 solver.cpp:218] Iteration 1128500 (16.7078 iter/s, 29.9262s/500 iters), loss = 0.0725905
I0830 04:18:11.709745 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0725979 (* 1 = 0.0725979 loss)
I0830 04:18:11.709753 916722 sgd_solver.cpp:106] Iteration 1128500, lr = 0.01
I0830 04:18:41.638147 916722 solver.cpp:218] Iteration 1129000 (16.7065 iter/s, 29.9285s/500 iters), loss = 0.0949422
I0830 04:18:41.638201 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0949494 (* 1 = 0.0949494 loss)
I0830 04:18:41.638212 916722 sgd_solver.cpp:106] Iteration 1129000, lr = 0.01
I0830 04:19:11.549612 916722 solver.cpp:218] Iteration 1129500 (16.716 iter/s, 29.9115s/500 iters), loss = 0.152189
I0830 04:19:11.549676 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152196 (* 1 = 0.152196 loss)
I0830 04:19:11.549685 916722 sgd_solver.cpp:106] Iteration 1129500, lr = 0.01
I0830 04:19:41.462363 916722 solver.cpp:218] Iteration 1130000 (16.7153 iter/s, 29.9128s/500 iters), loss = 0.305588
I0830 04:19:41.462415 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.305595 (* 1 = 0.305595 loss)
I0830 04:19:41.462436 916722 sgd_solver.cpp:106] Iteration 1130000, lr = 0.01
I0830 04:20:11.398666 916722 solver.cpp:218] Iteration 1130500 (16.7021 iter/s, 29.9364s/500 iters), loss = 0.0195863
I0830 04:20:11.398737 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0195936 (* 1 = 0.0195936 loss)
I0830 04:20:11.398746 916722 sgd_solver.cpp:106] Iteration 1130500, lr = 0.01
I0830 04:20:41.311689 916722 solver.cpp:218] Iteration 1131000 (16.7151 iter/s, 29.913s/500 iters), loss = 0.0875786
I0830 04:20:41.311744 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0875861 (* 1 = 0.0875861 loss)
I0830 04:20:41.311754 916722 sgd_solver.cpp:106] Iteration 1131000, lr = 0.01
I0830 04:21:11.239933 916722 solver.cpp:218] Iteration 1131500 (16.7066 iter/s, 29.9283s/500 iters), loss = 0.0543037
I0830 04:21:11.239991 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0543111 (* 1 = 0.0543111 loss)
I0830 04:21:11.240000 916722 sgd_solver.cpp:106] Iteration 1131500, lr = 0.01
I0830 04:21:41.180399 916722 solver.cpp:218] Iteration 1132000 (16.6998 iter/s, 29.9405s/500 iters), loss = 0.0846763
I0830 04:21:41.180456 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0846837 (* 1 = 0.0846837 loss)
I0830 04:21:41.180465 916722 sgd_solver.cpp:106] Iteration 1132000, lr = 0.01
I0830 04:22:11.143743 916722 solver.cpp:218] Iteration 1132500 (16.687 iter/s, 29.9634s/500 iters), loss = 0.229594
I0830 04:22:11.143801 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.229601 (* 1 = 0.229601 loss)
I0830 04:22:11.143810 916722 sgd_solver.cpp:106] Iteration 1132500, lr = 0.01
I0830 04:22:41.039269 916722 solver.cpp:218] Iteration 1133000 (16.7249 iter/s, 29.8955s/500 iters), loss = 0.0533684
I0830 04:22:41.039319 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0533759 (* 1 = 0.0533759 loss)
I0830 04:22:41.039328 916722 sgd_solver.cpp:106] Iteration 1133000, lr = 0.01
I0830 04:23:10.938623 916722 solver.cpp:218] Iteration 1133500 (16.7228 iter/s, 29.8994s/500 iters), loss = 0.0733402
I0830 04:23:10.938685 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0733478 (* 1 = 0.0733478 loss)
I0830 04:23:10.938694 916722 sgd_solver.cpp:106] Iteration 1133500, lr = 0.01
I0830 04:23:40.843942 916722 solver.cpp:218] Iteration 1134000 (16.7194 iter/s, 29.9053s/500 iters), loss = 0.247948
I0830 04:23:40.843998 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.247956 (* 1 = 0.247956 loss)
I0830 04:23:40.844008 916722 sgd_solver.cpp:106] Iteration 1134000, lr = 0.01
I0830 04:24:10.743270 916722 solver.cpp:218] Iteration 1134500 (16.7228 iter/s, 29.8993s/500 iters), loss = 0.16725
I0830 04:24:10.743327 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.167257 (* 1 = 0.167257 loss)
I0830 04:24:10.743336 916722 sgd_solver.cpp:106] Iteration 1134500, lr = 0.01
I0830 04:24:40.642585 916722 solver.cpp:218] Iteration 1135000 (16.7228 iter/s, 29.8993s/500 iters), loss = 0.0372916
I0830 04:24:40.642639 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.037299 (* 1 = 0.037299 loss)
I0830 04:24:40.642649 916722 sgd_solver.cpp:106] Iteration 1135000, lr = 0.01
I0830 04:25:10.536104 916722 solver.cpp:218] Iteration 1135500 (16.726 iter/s, 29.8935s/500 iters), loss = 0.207912
I0830 04:25:10.536164 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.20792 (* 1 = 0.20792 loss)
I0830 04:25:10.536171 916722 sgd_solver.cpp:106] Iteration 1135500, lr = 0.01
I0830 04:25:40.477321 916722 solver.cpp:218] Iteration 1136000 (16.6994 iter/s, 29.9412s/500 iters), loss = 0.0279761
I0830 04:25:40.477375 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.027983 (* 1 = 0.027983 loss)
I0830 04:25:40.477385 916722 sgd_solver.cpp:106] Iteration 1136000, lr = 0.01
I0830 04:26:10.371805 916722 solver.cpp:218] Iteration 1136500 (16.7255 iter/s, 29.8945s/500 iters), loss = 0.319193
I0830 04:26:10.371872 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.3192 (* 1 = 0.3192 loss)
I0830 04:26:10.371886 916722 sgd_solver.cpp:106] Iteration 1136500, lr = 0.01
I0830 04:26:40.274360 916722 solver.cpp:218] Iteration 1137000 (16.721 iter/s, 29.9025s/500 iters), loss = 0.0935141
I0830 04:26:40.274413 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.093521 (* 1 = 0.093521 loss)
I0830 04:26:40.274423 916722 sgd_solver.cpp:106] Iteration 1137000, lr = 0.01
I0830 04:27:10.162371 916722 solver.cpp:218] Iteration 1137500 (16.7291 iter/s, 29.888s/500 iters), loss = 0.0708728
I0830 04:27:10.162427 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0708799 (* 1 = 0.0708799 loss)
I0830 04:27:10.162436 916722 sgd_solver.cpp:106] Iteration 1137500, lr = 0.01
I0830 04:27:40.071746 916722 solver.cpp:218] Iteration 1138000 (16.7172 iter/s, 29.9094s/500 iters), loss = 0.0755333
I0830 04:27:40.071799 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0755404 (* 1 = 0.0755404 loss)
I0830 04:27:40.071808 916722 sgd_solver.cpp:106] Iteration 1138000, lr = 0.01
I0830 04:28:09.977761 916722 solver.cpp:218] Iteration 1138500 (16.7191 iter/s, 29.906s/500 iters), loss = 0.183658
I0830 04:28:09.977820 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.183666 (* 1 = 0.183666 loss)
I0830 04:28:09.977828 916722 sgd_solver.cpp:106] Iteration 1138500, lr = 0.01
I0830 04:28:39.830945 916722 solver.cpp:218] Iteration 1139000 (16.7486 iter/s, 29.8532s/500 iters), loss = 0.0208443
I0830 04:28:39.830998 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0208513 (* 1 = 0.0208513 loss)
I0830 04:28:39.831008 916722 sgd_solver.cpp:106] Iteration 1139000, lr = 0.01
I0830 04:29:09.710361 916722 solver.cpp:218] Iteration 1139500 (16.7339 iter/s, 29.8794s/500 iters), loss = 0.156362
I0830 04:29:09.710422 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.156369 (* 1 = 0.156369 loss)
I0830 04:29:09.710430 916722 sgd_solver.cpp:106] Iteration 1139500, lr = 0.01
I0830 04:29:39.591832 916722 solver.cpp:218] Iteration 1140000 (16.7328 iter/s, 29.8814s/500 iters), loss = 0.128093
I0830 04:29:39.591886 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.1281 (* 1 = 0.1281 loss)
I0830 04:29:39.591895 916722 sgd_solver.cpp:106] Iteration 1140000, lr = 0.01
I0830 04:30:09.482970 916722 solver.cpp:218] Iteration 1140500 (16.7274 iter/s, 29.8911s/500 iters), loss = 0.176272
I0830 04:30:09.483031 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.17628 (* 1 = 0.17628 loss)
I0830 04:30:09.483039 916722 sgd_solver.cpp:106] Iteration 1140500, lr = 0.01
I0830 04:30:39.356305 916722 solver.cpp:218] Iteration 1141000 (16.7374 iter/s, 29.8733s/500 iters), loss = 0.290944
I0830 04:30:39.356353 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.290952 (* 1 = 0.290952 loss)
I0830 04:30:39.356361 916722 sgd_solver.cpp:106] Iteration 1141000, lr = 0.01
I0830 04:31:09.217110 916722 solver.cpp:218] Iteration 1141500 (16.7444 iter/s, 29.8608s/500 iters), loss = 0.239398
I0830 04:31:09.217167 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.239405 (* 1 = 0.239405 loss)
I0830 04:31:09.217175 916722 sgd_solver.cpp:106] Iteration 1141500, lr = 0.01
I0830 04:31:39.100850 916722 solver.cpp:218] Iteration 1142000 (16.7315 iter/s, 29.8837s/500 iters), loss = 0.19724
I0830 04:31:39.100899 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.197247 (* 1 = 0.197247 loss)
I0830 04:31:39.100909 916722 sgd_solver.cpp:106] Iteration 1142000, lr = 0.01
I0830 04:32:08.977378 916722 solver.cpp:218] Iteration 1142500 (16.7356 iter/s, 29.8765s/500 iters), loss = 0.0734319
I0830 04:32:08.977437 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0734389 (* 1 = 0.0734389 loss)
I0830 04:32:08.977447 916722 sgd_solver.cpp:106] Iteration 1142500, lr = 0.01
I0830 04:32:38.863404 916722 solver.cpp:218] Iteration 1143000 (16.7302 iter/s, 29.886s/500 iters), loss = 0.0780871
I0830 04:32:38.863458 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0780942 (* 1 = 0.0780942 loss)
I0830 04:32:38.863468 916722 sgd_solver.cpp:106] Iteration 1143000, lr = 0.01
I0830 04:33:08.741276 916722 solver.cpp:218] Iteration 1143500 (16.7348 iter/s, 29.8778s/500 iters), loss = 0.342805
I0830 04:33:08.741344 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.342812 (* 1 = 0.342812 loss)
I0830 04:33:08.741353 916722 sgd_solver.cpp:106] Iteration 1143500, lr = 0.01
I0830 04:33:38.622200 916722 solver.cpp:218] Iteration 1144000 (16.7331 iter/s, 29.8809s/500 iters), loss = 0.195178
I0830 04:33:38.622253 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.195186 (* 1 = 0.195186 loss)
I0830 04:33:38.622263 916722 sgd_solver.cpp:106] Iteration 1144000, lr = 0.01
I0830 04:34:08.500484 916722 solver.cpp:218] Iteration 1144500 (16.7346 iter/s, 29.8782s/500 iters), loss = 0.14237
I0830 04:34:08.500547 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.142377 (* 1 = 0.142377 loss)
I0830 04:34:08.500556 916722 sgd_solver.cpp:106] Iteration 1144500, lr = 0.01
I0830 04:34:38.388141 916722 solver.cpp:218] Iteration 1145000 (16.7293 iter/s, 29.8876s/500 iters), loss = 0.155829
I0830 04:34:38.388195 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.155836 (* 1 = 0.155836 loss)
I0830 04:34:38.388203 916722 sgd_solver.cpp:106] Iteration 1145000, lr = 0.01
I0830 04:35:08.256181 916722 solver.cpp:218] Iteration 1145500 (16.7403 iter/s, 29.868s/500 iters), loss = 0.0439928
I0830 04:35:08.256240 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0439998 (* 1 = 0.0439998 loss)
I0830 04:35:08.256249 916722 sgd_solver.cpp:106] Iteration 1145500, lr = 0.01
I0830 04:35:38.142172 916722 solver.cpp:218] Iteration 1146000 (16.7303 iter/s, 29.8859s/500 iters), loss = 0.1968
I0830 04:35:38.142223 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.196807 (* 1 = 0.196807 loss)
I0830 04:35:38.142231 916722 sgd_solver.cpp:106] Iteration 1146000, lr = 0.01
I0830 04:36:08.013492 916722 solver.cpp:218] Iteration 1146500 (16.7385 iter/s, 29.8713s/500 iters), loss = 0.0624867
I0830 04:36:08.013552 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0624938 (* 1 = 0.0624938 loss)
I0830 04:36:08.013561 916722 sgd_solver.cpp:106] Iteration 1146500, lr = 0.01
I0830 04:36:37.898535 916722 solver.cpp:218] Iteration 1147000 (16.7308 iter/s, 29.885s/500 iters), loss = 0.0815299
I0830 04:36:37.898588 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0815369 (* 1 = 0.0815369 loss)
I0830 04:36:37.898597 916722 sgd_solver.cpp:106] Iteration 1147000, lr = 0.01
I0830 04:37:07.780086 916722 solver.cpp:218] Iteration 1147500 (16.7328 iter/s, 29.8815s/500 iters), loss = 0.160423
I0830 04:37:07.780146 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.16043 (* 1 = 0.16043 loss)
I0830 04:37:07.780155 916722 sgd_solver.cpp:106] Iteration 1147500, lr = 0.01
I0830 04:37:37.673465 916722 solver.cpp:218] Iteration 1148000 (16.7261 iter/s, 29.8933s/500 iters), loss = 0.186003
I0830 04:37:37.673516 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.186009 (* 1 = 0.186009 loss)
I0830 04:37:37.673525 916722 sgd_solver.cpp:106] Iteration 1148000, lr = 0.01
I0830 04:38:07.574429 916722 solver.cpp:218] Iteration 1148500 (16.7219 iter/s, 29.9009s/500 iters), loss = 0.03842
I0830 04:38:07.574491 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0384269 (* 1 = 0.0384269 loss)
I0830 04:38:07.574499 916722 sgd_solver.cpp:106] Iteration 1148500, lr = 0.01
I0830 04:38:37.477236 916722 solver.cpp:218] Iteration 1149000 (16.7209 iter/s, 29.9028s/500 iters), loss = 0.185427
I0830 04:38:37.477289 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.185434 (* 1 = 0.185434 loss)
I0830 04:38:37.477299 916722 sgd_solver.cpp:106] Iteration 1149000, lr = 0.01
I0830 04:39:07.382845 916722 solver.cpp:218] Iteration 1149500 (16.7193 iter/s, 29.9056s/500 iters), loss = 0.0290707
I0830 04:39:07.382905 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0290776 (* 1 = 0.0290776 loss)
I0830 04:39:07.382915 916722 sgd_solver.cpp:106] Iteration 1149500, lr = 0.01
I0830 04:39:37.238149 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_1150000.caffemodel
I0830 04:39:37.257725 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_1150000.solverstate
I0830 04:39:37.264004 916722 solver.cpp:330] Iteration 1150000, Testing net (#0)
I0830 04:39:52.688585 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8914
I0830 04:39:52.688653 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.358905 (* 1 = 0.358905 loss)
I0830 04:39:52.747543 916722 solver.cpp:218] Iteration 1150000 (11.0218 iter/s, 45.3646s/500 iters), loss = 0.256494
I0830 04:39:52.747572 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.256501 (* 1 = 0.256501 loss)
I0830 04:39:52.747581 916722 sgd_solver.cpp:106] Iteration 1150000, lr = 0.01
I0830 04:40:22.531508 916722 solver.cpp:218] Iteration 1150500 (16.7876 iter/s, 29.7839s/500 iters), loss = 0.166741
I0830 04:40:22.531561 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.166748 (* 1 = 0.166748 loss)
I0830 04:40:22.531570 916722 sgd_solver.cpp:106] Iteration 1150500, lr = 0.01
I0830 04:40:52.393729 916722 solver.cpp:218] Iteration 1151000 (16.7436 iter/s, 29.8622s/500 iters), loss = 0.345125
I0830 04:40:52.393792 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.345132 (* 1 = 0.345132 loss)
I0830 04:40:52.393800 916722 sgd_solver.cpp:106] Iteration 1151000, lr = 0.01
I0830 04:41:22.277043 916722 solver.cpp:218] Iteration 1151500 (16.7318 iter/s, 29.8833s/500 iters), loss = 0.320816
I0830 04:41:22.277092 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.320822 (* 1 = 0.320822 loss)
I0830 04:41:22.277101 916722 sgd_solver.cpp:106] Iteration 1151500, lr = 0.01
I0830 04:41:52.165884 916722 solver.cpp:218] Iteration 1152000 (16.7287 iter/s, 29.8888s/500 iters), loss = 0.628597
I0830 04:41:52.165940 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.628604 (* 1 = 0.628604 loss)
I0830 04:41:52.165948 916722 sgd_solver.cpp:106] Iteration 1152000, lr = 0.01
I0830 04:42:22.037509 916722 solver.cpp:218] Iteration 1152500 (16.7383 iter/s, 29.8716s/500 iters), loss = 0.218795
I0830 04:42:22.037560 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.218801 (* 1 = 0.218801 loss)
I0830 04:42:22.037570 916722 sgd_solver.cpp:106] Iteration 1152500, lr = 0.01
I0830 04:42:51.915278 916722 solver.cpp:218] Iteration 1153000 (16.7349 iter/s, 29.8777s/500 iters), loss = 0.055749
I0830 04:42:51.915338 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0557557 (* 1 = 0.0557557 loss)
I0830 04:42:51.915345 916722 sgd_solver.cpp:106] Iteration 1153000, lr = 0.01
I0830 04:43:21.808238 916722 solver.cpp:218] Iteration 1153500 (16.7264 iter/s, 29.8929s/500 iters), loss = 0.251878
I0830 04:43:21.808291 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.251884 (* 1 = 0.251884 loss)
I0830 04:43:21.808301 916722 sgd_solver.cpp:106] Iteration 1153500, lr = 0.01
I0830 04:43:51.697824 916722 solver.cpp:218] Iteration 1154000 (16.7283 iter/s, 29.8895s/500 iters), loss = 0.0717354
I0830 04:43:51.697886 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0717424 (* 1 = 0.0717424 loss)
I0830 04:43:51.697894 916722 sgd_solver.cpp:106] Iteration 1154000, lr = 0.01
I0830 04:44:21.599355 916722 solver.cpp:218] Iteration 1154500 (16.7216 iter/s, 29.9014s/500 iters), loss = 0.26224
I0830 04:44:21.599407 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.262247 (* 1 = 0.262247 loss)
I0830 04:44:21.599416 916722 sgd_solver.cpp:106] Iteration 1154500, lr = 0.01
I0830 04:44:51.485488 916722 solver.cpp:218] Iteration 1155000 (16.7303 iter/s, 29.8859s/500 iters), loss = 0.235547
I0830 04:44:51.485548 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.235554 (* 1 = 0.235554 loss)
I0830 04:44:51.485558 916722 sgd_solver.cpp:106] Iteration 1155000, lr = 0.01
I0830 04:45:21.408936 916722 solver.cpp:218] Iteration 1155500 (16.7094 iter/s, 29.9232s/500 iters), loss = 0.0710743
I0830 04:45:21.408998 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0710815 (* 1 = 0.0710815 loss)
I0830 04:45:21.409008 916722 sgd_solver.cpp:106] Iteration 1155500, lr = 0.01
I0830 04:45:51.317387 916722 solver.cpp:218] Iteration 1156000 (16.7178 iter/s, 29.9082s/500 iters), loss = 0.116855
I0830 04:45:51.317457 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.116862 (* 1 = 0.116862 loss)
I0830 04:45:51.317466 916722 sgd_solver.cpp:106] Iteration 1156000, lr = 0.01
I0830 04:46:21.199184 916722 solver.cpp:218] Iteration 1156500 (16.7327 iter/s, 29.8816s/500 iters), loss = 0.207034
I0830 04:46:21.199235 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.207041 (* 1 = 0.207041 loss)
I0830 04:46:21.199244 916722 sgd_solver.cpp:106] Iteration 1156500, lr = 0.01
I0830 04:46:51.093963 916722 solver.cpp:218] Iteration 1157000 (16.7254 iter/s, 29.8946s/500 iters), loss = 0.0984708
I0830 04:46:51.094020 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0984778 (* 1 = 0.0984778 loss)
I0830 04:46:51.094028 916722 sgd_solver.cpp:106] Iteration 1157000, lr = 0.01
I0830 04:47:20.997545 916722 solver.cpp:218] Iteration 1157500 (16.7205 iter/s, 29.9034s/500 iters), loss = 0.0393158
I0830 04:47:20.997601 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0393228 (* 1 = 0.0393228 loss)
I0830 04:47:20.997610 916722 sgd_solver.cpp:106] Iteration 1157500, lr = 0.01
I0830 04:47:50.917277 916722 solver.cpp:218] Iteration 1158000 (16.7115 iter/s, 29.9196s/500 iters), loss = 0.246247
I0830 04:47:50.917337 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.246254 (* 1 = 0.246254 loss)
I0830 04:47:50.917346 916722 sgd_solver.cpp:106] Iteration 1158000, lr = 0.01
I0830 04:48:20.831916 916722 solver.cpp:218] Iteration 1158500 (16.7143 iter/s, 29.9145s/500 iters), loss = 0.0100903
I0830 04:48:20.831969 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0100974 (* 1 = 0.0100974 loss)
I0830 04:48:20.831979 916722 sgd_solver.cpp:106] Iteration 1158500, lr = 0.01
I0830 04:48:50.759244 916722 solver.cpp:218] Iteration 1159000 (16.7072 iter/s, 29.9272s/500 iters), loss = 0.147054
I0830 04:48:50.759306 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.147061 (* 1 = 0.147061 loss)
I0830 04:48:50.759315 916722 sgd_solver.cpp:106] Iteration 1159000, lr = 0.01
I0830 04:49:20.682596 916722 solver.cpp:218] Iteration 1159500 (16.7095 iter/s, 29.9232s/500 iters), loss = 0.206105
I0830 04:49:20.682652 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.206112 (* 1 = 0.206112 loss)
I0830 04:49:20.682662 916722 sgd_solver.cpp:106] Iteration 1159500, lr = 0.01
I0830 04:49:50.606968 916722 solver.cpp:218] Iteration 1160000 (16.7089 iter/s, 29.9242s/500 iters), loss = 0.310696
I0830 04:49:50.607026 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.310703 (* 1 = 0.310703 loss)
I0830 04:49:50.607035 916722 sgd_solver.cpp:106] Iteration 1160000, lr = 0.01
I0830 04:50:20.537497 916722 solver.cpp:218] Iteration 1160500 (16.7054 iter/s, 29.9304s/500 iters), loss = 0.0390243
I0830 04:50:20.537550 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0390311 (* 1 = 0.0390311 loss)
I0830 04:50:20.537560 916722 sgd_solver.cpp:106] Iteration 1160500, lr = 0.01
I0830 04:50:50.469132 916722 solver.cpp:218] Iteration 1161000 (16.7048 iter/s, 29.9315s/500 iters), loss = 0.135694
I0830 04:50:50.469187 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.135701 (* 1 = 0.135701 loss)
I0830 04:50:50.469197 916722 sgd_solver.cpp:106] Iteration 1161000, lr = 0.01
I0830 04:51:20.397990 916722 solver.cpp:218] Iteration 1161500 (16.7064 iter/s, 29.9287s/500 iters), loss = 0.119405
I0830 04:51:20.398038 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.119412 (* 1 = 0.119412 loss)
I0830 04:51:20.398048 916722 sgd_solver.cpp:106] Iteration 1161500, lr = 0.01
I0830 04:51:50.331508 916722 solver.cpp:218] Iteration 1162000 (16.7038 iter/s, 29.9334s/500 iters), loss = 0.085964
I0830 04:51:50.331579 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0859709 (* 1 = 0.0859709 loss)
I0830 04:51:50.331593 916722 sgd_solver.cpp:106] Iteration 1162000, lr = 0.01
I0830 04:52:20.262187 916722 solver.cpp:218] Iteration 1162500 (16.7054 iter/s, 29.9305s/500 iters), loss = 0.159344
I0830 04:52:20.262239 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159351 (* 1 = 0.159351 loss)
I0830 04:52:20.262250 916722 sgd_solver.cpp:106] Iteration 1162500, lr = 0.01
I0830 04:52:50.203339 916722 solver.cpp:218] Iteration 1163000 (16.6995 iter/s, 29.941s/500 iters), loss = 0.0603834
I0830 04:52:50.203400 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0603903 (* 1 = 0.0603903 loss)
I0830 04:52:50.203408 916722 sgd_solver.cpp:106] Iteration 1163000, lr = 0.01
I0830 04:53:20.146611 916722 solver.cpp:218] Iteration 1163500 (16.6983 iter/s, 29.9431s/500 iters), loss = 0.202085
I0830 04:53:20.146663 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.202092 (* 1 = 0.202092 loss)
I0830 04:53:20.146674 916722 sgd_solver.cpp:106] Iteration 1163500, lr = 0.01
I0830 04:53:50.066301 916722 solver.cpp:218] Iteration 1164000 (16.7115 iter/s, 29.9196s/500 iters), loss = 0.0718684
I0830 04:53:50.066360 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0718752 (* 1 = 0.0718752 loss)
I0830 04:53:50.066370 916722 sgd_solver.cpp:106] Iteration 1164000, lr = 0.01
I0830 04:54:20.006343 916722 solver.cpp:218] Iteration 1164500 (16.7001 iter/s, 29.9399s/500 iters), loss = 0.0286791
I0830 04:54:20.006397 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0286857 (* 1 = 0.0286857 loss)
I0830 04:54:20.006407 916722 sgd_solver.cpp:106] Iteration 1164500, lr = 0.01
I0830 04:54:49.931020 916722 solver.cpp:218] Iteration 1165000 (16.7087 iter/s, 29.9246s/500 iters), loss = 0.239323
I0830 04:54:49.931077 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.23933 (* 1 = 0.23933 loss)
I0830 04:54:49.931087 916722 sgd_solver.cpp:106] Iteration 1165000, lr = 0.01
I0830 04:55:19.867352 916722 solver.cpp:218] Iteration 1165500 (16.7022 iter/s, 29.9362s/500 iters), loss = 0.0843162
I0830 04:55:19.867403 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.084323 (* 1 = 0.084323 loss)
I0830 04:55:19.867413 916722 sgd_solver.cpp:106] Iteration 1165500, lr = 0.01
I0830 04:55:49.802958 916722 solver.cpp:218] Iteration 1166000 (16.7026 iter/s, 29.9355s/500 iters), loss = 0.183176
I0830 04:55:49.803015 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.183183 (* 1 = 0.183183 loss)
I0830 04:55:49.803023 916722 sgd_solver.cpp:106] Iteration 1166000, lr = 0.01
I0830 04:56:19.744626 916722 solver.cpp:218] Iteration 1166500 (16.6992 iter/s, 29.9416s/500 iters), loss = 0.465527
I0830 04:56:19.744680 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.465534 (* 1 = 0.465534 loss)
I0830 04:56:19.744691 916722 sgd_solver.cpp:106] Iteration 1166500, lr = 0.01
I0830 04:56:49.700326 916722 solver.cpp:218] Iteration 1167000 (16.6914 iter/s, 29.9556s/500 iters), loss = 0.0814298
I0830 04:56:49.700387 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0814367 (* 1 = 0.0814367 loss)
I0830 04:56:49.700395 916722 sgd_solver.cpp:106] Iteration 1167000, lr = 0.01
I0830 04:57:19.632894 916722 solver.cpp:218] Iteration 1167500 (16.7043 iter/s, 29.9325s/500 iters), loss = 0.175277
I0830 04:57:19.632947 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.175284 (* 1 = 0.175284 loss)
I0830 04:57:19.632957 916722 sgd_solver.cpp:106] Iteration 1167500, lr = 0.01
I0830 04:57:49.563419 916722 solver.cpp:218] Iteration 1168000 (16.7054 iter/s, 29.9304s/500 iters), loss = 0.0897582
I0830 04:57:49.563479 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.089765 (* 1 = 0.089765 loss)
I0830 04:57:49.563488 916722 sgd_solver.cpp:106] Iteration 1168000, lr = 0.01
I0830 04:58:19.503686 916722 solver.cpp:218] Iteration 1168500 (16.7 iter/s, 29.9402s/500 iters), loss = 0.185461
I0830 04:58:19.503739 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.185468 (* 1 = 0.185468 loss)
I0830 04:58:19.503765 916722 sgd_solver.cpp:106] Iteration 1168500, lr = 0.01
I0830 04:58:49.443075 916722 solver.cpp:218] Iteration 1169000 (16.7005 iter/s, 29.9393s/500 iters), loss = 0.0661728
I0830 04:58:49.443147 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0661794 (* 1 = 0.0661794 loss)
I0830 04:58:49.443156 916722 sgd_solver.cpp:106] Iteration 1169000, lr = 0.01
I0830 04:59:19.390285 916722 solver.cpp:218] Iteration 1169500 (16.6961 iter/s, 29.9471s/500 iters), loss = 0.0555464
I0830 04:59:19.390336 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.055553 (* 1 = 0.055553 loss)
I0830 04:59:19.390345 916722 sgd_solver.cpp:106] Iteration 1169500, lr = 0.01
I0830 04:59:49.341426 916722 solver.cpp:218] Iteration 1170000 (16.6939 iter/s, 29.9511s/500 iters), loss = 0.224716
I0830 04:59:49.341482 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.224723 (* 1 = 0.224723 loss)
I0830 04:59:49.341491 916722 sgd_solver.cpp:106] Iteration 1170000, lr = 0.01
I0830 05:00:19.283704 916722 solver.cpp:218] Iteration 1170500 (16.6988 iter/s, 29.9422s/500 iters), loss = 0.211085
I0830 05:00:19.283757 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.211092 (* 1 = 0.211092 loss)
I0830 05:00:19.283766 916722 sgd_solver.cpp:106] Iteration 1170500, lr = 0.01
I0830 05:00:49.220592 916722 solver.cpp:218] Iteration 1171000 (16.7019 iter/s, 29.9368s/500 iters), loss = 0.127556
I0830 05:00:49.220654 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.127563 (* 1 = 0.127563 loss)
I0830 05:00:49.220661 916722 sgd_solver.cpp:106] Iteration 1171000, lr = 0.01
I0830 05:01:19.159190 916722 solver.cpp:218] Iteration 1171500 (16.7009 iter/s, 29.9385s/500 iters), loss = 0.0421241
I0830 05:01:19.159243 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0421308 (* 1 = 0.0421308 loss)
I0830 05:01:19.159252 916722 sgd_solver.cpp:106] Iteration 1171500, lr = 0.01
I0830 05:01:49.091840 916722 solver.cpp:218] Iteration 1172000 (16.7042 iter/s, 29.9326s/500 iters), loss = 0.376222
I0830 05:01:49.091902 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.376229 (* 1 = 0.376229 loss)
I0830 05:01:49.091910 916722 sgd_solver.cpp:106] Iteration 1172000, lr = 0.01
I0830 05:02:19.020673 916722 solver.cpp:218] Iteration 1172500 (16.7064 iter/s, 29.9287s/500 iters), loss = 0.040269
I0830 05:02:19.020730 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0402758 (* 1 = 0.0402758 loss)
I0830 05:02:19.020749 916722 sgd_solver.cpp:106] Iteration 1172500, lr = 0.01
I0830 05:02:48.960316 916722 solver.cpp:218] Iteration 1173000 (16.7003 iter/s, 29.9396s/500 iters), loss = 0.226786
I0830 05:02:48.960376 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.226793 (* 1 = 0.226793 loss)
I0830 05:02:48.960384 916722 sgd_solver.cpp:106] Iteration 1173000, lr = 0.01
I0830 05:03:18.884678 916722 solver.cpp:218] Iteration 1173500 (16.7088 iter/s, 29.9243s/500 iters), loss = 0.0276678
I0830 05:03:18.884732 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0276747 (* 1 = 0.0276747 loss)
I0830 05:03:18.884752 916722 sgd_solver.cpp:106] Iteration 1173500, lr = 0.01
I0830 05:03:48.805058 916722 solver.cpp:218] Iteration 1174000 (16.7111 iter/s, 29.9203s/500 iters), loss = 0.313119
I0830 05:03:48.805119 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.313126 (* 1 = 0.313126 loss)
I0830 05:03:48.805126 916722 sgd_solver.cpp:106] Iteration 1174000, lr = 0.01
I0830 05:04:18.756316 916722 solver.cpp:218] Iteration 1174500 (16.6938 iter/s, 29.9512s/500 iters), loss = 0.21787
I0830 05:04:18.756367 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.217877 (* 1 = 0.217877 loss)
I0830 05:04:18.756377 916722 sgd_solver.cpp:106] Iteration 1174500, lr = 0.01
I0830 05:04:48.652235 916722 solver.cpp:218] Iteration 1175000 (16.7247 iter/s, 29.8958s/500 iters), loss = 0.264183
I0830 05:04:48.652309 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.26419 (* 1 = 0.26419 loss)
I0830 05:04:48.652323 916722 sgd_solver.cpp:106] Iteration 1175000, lr = 0.01
I0830 05:05:18.545658 916722 solver.cpp:218] Iteration 1175500 (16.7261 iter/s, 29.8933s/500 iters), loss = 0.14653
I0830 05:05:18.545708 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.146536 (* 1 = 0.146536 loss)
I0830 05:05:18.545718 916722 sgd_solver.cpp:106] Iteration 1175500, lr = 0.01
I0830 05:05:48.460048 916722 solver.cpp:218] Iteration 1176000 (16.7144 iter/s, 29.9143s/500 iters), loss = 0.116865
I0830 05:05:48.460108 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.116872 (* 1 = 0.116872 loss)
I0830 05:05:48.460117 916722 sgd_solver.cpp:106] Iteration 1176000, lr = 0.01
I0830 05:06:18.358764 916722 solver.cpp:218] Iteration 1176500 (16.7232 iter/s, 29.8986s/500 iters), loss = 0.09694
I0830 05:06:18.358817 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.096947 (* 1 = 0.096947 loss)
I0830 05:06:18.358829 916722 sgd_solver.cpp:106] Iteration 1176500, lr = 0.01
I0830 05:06:48.211310 916722 solver.cpp:218] Iteration 1177000 (16.749 iter/s, 29.8525s/500 iters), loss = 0.293684
I0830 05:06:48.211365 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.293691 (* 1 = 0.293691 loss)
I0830 05:06:48.211374 916722 sgd_solver.cpp:106] Iteration 1177000, lr = 0.01
I0830 05:07:18.072450 916722 solver.cpp:218] Iteration 1177500 (16.7442 iter/s, 29.8611s/500 iters), loss = 0.193158
I0830 05:07:18.072504 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.193165 (* 1 = 0.193165 loss)
I0830 05:07:18.072515 916722 sgd_solver.cpp:106] Iteration 1177500, lr = 0.01
I0830 05:07:47.932611 916722 solver.cpp:218] Iteration 1178000 (16.7448 iter/s, 29.8601s/500 iters), loss = 0.294583
I0830 05:07:47.932674 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.29459 (* 1 = 0.29459 loss)
I0830 05:07:47.932683 916722 sgd_solver.cpp:106] Iteration 1178000, lr = 0.01
I0830 05:08:17.809875 916722 solver.cpp:218] Iteration 1178500 (16.7352 iter/s, 29.8772s/500 iters), loss = 0.111854
I0830 05:08:17.809929 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111861 (* 1 = 0.111861 loss)
I0830 05:08:17.809939 916722 sgd_solver.cpp:106] Iteration 1178500, lr = 0.01
I0830 05:08:47.692806 916722 solver.cpp:218] Iteration 1179000 (16.732 iter/s, 29.8828s/500 iters), loss = 0.367859
I0830 05:08:47.692867 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.367867 (* 1 = 0.367867 loss)
I0830 05:08:47.692875 916722 sgd_solver.cpp:106] Iteration 1179000, lr = 0.01
I0830 05:09:17.587102 916722 solver.cpp:218] Iteration 1179500 (16.7256 iter/s, 29.8942s/500 iters), loss = 0.098371
I0830 05:09:17.587155 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0983786 (* 1 = 0.0983786 loss)
I0830 05:09:17.587165 916722 sgd_solver.cpp:106] Iteration 1179500, lr = 0.01
I0830 05:09:47.497171 916722 solver.cpp:218] Iteration 1180000 (16.7168 iter/s, 29.91s/500 iters), loss = 0.0784705
I0830 05:09:47.497236 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0784779 (* 1 = 0.0784779 loss)
I0830 05:09:47.497244 916722 sgd_solver.cpp:106] Iteration 1180000, lr = 0.01
I0830 05:10:17.400379 916722 solver.cpp:218] Iteration 1180500 (16.7207 iter/s, 29.9031s/500 iters), loss = 0.253604
I0830 05:10:17.400435 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.253612 (* 1 = 0.253612 loss)
I0830 05:10:17.400456 916722 sgd_solver.cpp:106] Iteration 1180500, lr = 0.01
I0830 05:10:47.314932 916722 solver.cpp:218] Iteration 1181000 (16.7143 iter/s, 29.9145s/500 iters), loss = 0.102874
I0830 05:10:47.314990 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.102882 (* 1 = 0.102882 loss)
I0830 05:10:47.314997 916722 sgd_solver.cpp:106] Iteration 1181000, lr = 0.01
I0830 05:11:17.218859 916722 solver.cpp:218] Iteration 1181500 (16.7203 iter/s, 29.9038s/500 iters), loss = 0.0971461
I0830 05:11:17.218910 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0971534 (* 1 = 0.0971534 loss)
I0830 05:11:17.218919 916722 sgd_solver.cpp:106] Iteration 1181500, lr = 0.01
I0830 05:11:47.136981 916722 solver.cpp:218] Iteration 1182000 (16.7123 iter/s, 29.918s/500 iters), loss = 0.0682828
I0830 05:11:47.137053 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0682902 (* 1 = 0.0682902 loss)
I0830 05:11:47.137063 916722 sgd_solver.cpp:106] Iteration 1182000, lr = 0.01
I0830 05:12:17.031354 916722 solver.cpp:218] Iteration 1182500 (16.7256 iter/s, 29.8943s/500 iters), loss = 0.139784
I0830 05:12:17.031409 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139792 (* 1 = 0.139792 loss)
I0830 05:12:17.031419 916722 sgd_solver.cpp:106] Iteration 1182500, lr = 0.01
I0830 05:12:46.944710 916722 solver.cpp:218] Iteration 1183000 (16.715 iter/s, 29.9133s/500 iters), loss = 0.112191
I0830 05:12:46.944772 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112199 (* 1 = 0.112199 loss)
I0830 05:12:46.944780 916722 sgd_solver.cpp:106] Iteration 1183000, lr = 0.01
I0830 05:13:16.840644 916722 solver.cpp:218] Iteration 1183500 (16.7247 iter/s, 29.8958s/500 iters), loss = 0.112641
I0830 05:13:16.840700 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112648 (* 1 = 0.112648 loss)
I0830 05:13:16.840709 916722 sgd_solver.cpp:106] Iteration 1183500, lr = 0.01
I0830 05:13:46.750386 916722 solver.cpp:218] Iteration 1184000 (16.717 iter/s, 29.9097s/500 iters), loss = 0.0694329
I0830 05:13:46.750447 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0694401 (* 1 = 0.0694401 loss)
I0830 05:13:46.750456 916722 sgd_solver.cpp:106] Iteration 1184000, lr = 0.01
I0830 05:14:16.647177 916722 solver.cpp:218] Iteration 1184500 (16.7243 iter/s, 29.8967s/500 iters), loss = 0.182445
I0830 05:14:16.647234 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.182452 (* 1 = 0.182452 loss)
I0830 05:14:16.647244 916722 sgd_solver.cpp:106] Iteration 1184500, lr = 0.01
I0830 05:14:46.542929 916722 solver.cpp:218] Iteration 1185000 (16.7248 iter/s, 29.8957s/500 iters), loss = 0.0380726
I0830 05:14:46.542989 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0380798 (* 1 = 0.0380798 loss)
I0830 05:14:46.542997 916722 sgd_solver.cpp:106] Iteration 1185000, lr = 0.01
I0830 05:15:16.442178 916722 solver.cpp:218] Iteration 1185500 (16.7229 iter/s, 29.8992s/500 iters), loss = 0.210143
I0830 05:15:16.442226 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.21015 (* 1 = 0.21015 loss)
I0830 05:15:16.442236 916722 sgd_solver.cpp:106] Iteration 1185500, lr = 0.01
I0830 05:15:46.365557 916722 solver.cpp:218] Iteration 1186000 (16.7094 iter/s, 29.9233s/500 iters), loss = 0.573917
I0830 05:15:46.365617 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.573925 (* 1 = 0.573925 loss)
I0830 05:15:46.365626 916722 sgd_solver.cpp:106] Iteration 1186000, lr = 0.01
I0830 05:16:16.256000 916722 solver.cpp:218] Iteration 1186500 (16.7278 iter/s, 29.8904s/500 iters), loss = 0.294683
I0830 05:16:16.256054 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.29469 (* 1 = 0.29469 loss)
I0830 05:16:16.256064 916722 sgd_solver.cpp:106] Iteration 1186500, lr = 0.01
I0830 05:16:46.144135 916722 solver.cpp:218] Iteration 1187000 (16.7291 iter/s, 29.8881s/500 iters), loss = 0.170638
I0830 05:16:46.144194 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.170646 (* 1 = 0.170646 loss)
I0830 05:16:46.144203 916722 sgd_solver.cpp:106] Iteration 1187000, lr = 0.01
I0830 05:17:16.041100 916722 solver.cpp:218] Iteration 1187500 (16.7241 iter/s, 29.8969s/500 iters), loss = 0.0725702
I0830 05:17:16.041154 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0725776 (* 1 = 0.0725776 loss)
I0830 05:17:16.041164 916722 sgd_solver.cpp:106] Iteration 1187500, lr = 0.01
I0830 05:17:45.937000 916722 solver.cpp:218] Iteration 1188000 (16.7247 iter/s, 29.8958s/500 iters), loss = 0.161207
I0830 05:17:45.937059 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.161214 (* 1 = 0.161214 loss)
I0830 05:17:45.937068 916722 sgd_solver.cpp:106] Iteration 1188000, lr = 0.01
I0830 05:18:15.825078 916722 solver.cpp:218] Iteration 1188500 (16.7291 iter/s, 29.888s/500 iters), loss = 0.309767
I0830 05:18:15.825139 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.309774 (* 1 = 0.309774 loss)
I0830 05:18:15.825150 916722 sgd_solver.cpp:106] Iteration 1188500, lr = 0.01
I0830 05:18:45.716333 916722 solver.cpp:218] Iteration 1189000 (16.7276 iter/s, 29.8908s/500 iters), loss = 0.127673
I0830 05:18:45.716403 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.12768 (* 1 = 0.12768 loss)
I0830 05:18:45.716411 916722 sgd_solver.cpp:106] Iteration 1189000, lr = 0.01
I0830 05:19:15.588449 916722 solver.cpp:218] Iteration 1189500 (16.7383 iter/s, 29.8717s/500 iters), loss = 0.166593
I0830 05:19:15.588501 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.166601 (* 1 = 0.166601 loss)
I0830 05:19:15.588511 916722 sgd_solver.cpp:106] Iteration 1189500, lr = 0.01
I0830 05:19:45.467442 916722 solver.cpp:218] Iteration 1190000 (16.7344 iter/s, 29.8786s/500 iters), loss = 0.0590537
I0830 05:19:45.467499 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0590614 (* 1 = 0.0590614 loss)
I0830 05:19:45.467506 916722 sgd_solver.cpp:106] Iteration 1190000, lr = 0.01
I0830 05:20:15.340225 916722 solver.cpp:218] Iteration 1190500 (16.7379 iter/s, 29.8724s/500 iters), loss = 0.153884
I0830 05:20:15.340279 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.153891 (* 1 = 0.153891 loss)
I0830 05:20:15.340289 916722 sgd_solver.cpp:106] Iteration 1190500, lr = 0.01
I0830 05:20:45.226267 916722 solver.cpp:218] Iteration 1191000 (16.7304 iter/s, 29.8857s/500 iters), loss = 0.226155
I0830 05:20:45.226330 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.226163 (* 1 = 0.226163 loss)
I0830 05:20:45.226337 916722 sgd_solver.cpp:106] Iteration 1191000, lr = 0.01
I0830 05:21:15.114657 916722 solver.cpp:218] Iteration 1191500 (16.7291 iter/s, 29.888s/500 iters), loss = 0.227036
I0830 05:21:15.114710 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.227044 (* 1 = 0.227044 loss)
I0830 05:21:15.114719 916722 sgd_solver.cpp:106] Iteration 1191500, lr = 0.01
I0830 05:21:44.983755 916722 solver.cpp:218] Iteration 1192000 (16.7399 iter/s, 29.8687s/500 iters), loss = 0.151573
I0830 05:21:44.983816 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.15158 (* 1 = 0.15158 loss)
I0830 05:21:44.983824 916722 sgd_solver.cpp:106] Iteration 1192000, lr = 0.01
I0830 05:22:14.858945 916722 solver.cpp:218] Iteration 1192500 (16.7365 iter/s, 29.8748s/500 iters), loss = 0.112511
I0830 05:22:14.858999 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112518 (* 1 = 0.112518 loss)
I0830 05:22:14.859009 916722 sgd_solver.cpp:106] Iteration 1192500, lr = 0.01
I0830 05:22:44.736608 916722 solver.cpp:218] Iteration 1193000 (16.7351 iter/s, 29.8773s/500 iters), loss = 0.165686
I0830 05:22:44.736668 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.165694 (* 1 = 0.165694 loss)
I0830 05:22:44.736676 916722 sgd_solver.cpp:106] Iteration 1193000, lr = 0.01
I0830 05:23:14.606180 916722 solver.cpp:218] Iteration 1193500 (16.7396 iter/s, 29.8692s/500 iters), loss = 0.162382
I0830 05:23:14.606233 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.16239 (* 1 = 0.16239 loss)
I0830 05:23:14.606241 916722 sgd_solver.cpp:106] Iteration 1193500, lr = 0.01
I0830 05:23:44.490754 916722 solver.cpp:218] Iteration 1194000 (16.7312 iter/s, 29.8843s/500 iters), loss = 0.127958
I0830 05:23:44.490814 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.127965 (* 1 = 0.127965 loss)
I0830 05:23:44.490823 916722 sgd_solver.cpp:106] Iteration 1194000, lr = 0.01
I0830 05:24:14.374596 916722 solver.cpp:218] Iteration 1194500 (16.7316 iter/s, 29.8835s/500 iters), loss = 0.275598
I0830 05:24:14.374645 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.275606 (* 1 = 0.275606 loss)
I0830 05:24:14.374655 916722 sgd_solver.cpp:106] Iteration 1194500, lr = 0.01
I0830 05:24:44.258857 916722 solver.cpp:218] Iteration 1195000 (16.7314 iter/s, 29.884s/500 iters), loss = 0.118872
I0830 05:24:44.258932 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.11888 (* 1 = 0.11888 loss)
I0830 05:24:44.258941 916722 sgd_solver.cpp:106] Iteration 1195000, lr = 0.01
I0830 05:25:14.151721 916722 solver.cpp:218] Iteration 1195500 (16.7266 iter/s, 29.8926s/500 iters), loss = 0.0500512
I0830 05:25:14.151777 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0500591 (* 1 = 0.0500591 loss)
I0830 05:25:14.151788 916722 sgd_solver.cpp:106] Iteration 1195500, lr = 0.01
I0830 05:25:44.043788 916722 solver.cpp:218] Iteration 1196000 (16.727 iter/s, 29.8918s/500 iters), loss = 0.0860231
I0830 05:25:44.043849 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0860309 (* 1 = 0.0860309 loss)
I0830 05:25:44.043859 916722 sgd_solver.cpp:106] Iteration 1196000, lr = 0.01
I0830 05:26:13.943856 916722 solver.cpp:218] Iteration 1196500 (16.7225 iter/s, 29.8998s/500 iters), loss = 0.213948
I0830 05:26:13.943909 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.213956 (* 1 = 0.213956 loss)
I0830 05:26:13.943919 916722 sgd_solver.cpp:106] Iteration 1196500, lr = 0.01
I0830 05:26:43.854174 916722 solver.cpp:218] Iteration 1197000 (16.7168 iter/s, 29.9101s/500 iters), loss = 0.12589
I0830 05:26:43.854233 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.125898 (* 1 = 0.125898 loss)
I0830 05:26:43.854243 916722 sgd_solver.cpp:106] Iteration 1197000, lr = 0.01
I0830 05:27:13.768611 916722 solver.cpp:218] Iteration 1197500 (16.7145 iter/s, 29.9142s/500 iters), loss = 0.0623403
I0830 05:27:13.768668 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0623483 (* 1 = 0.0623483 loss)
I0830 05:27:13.768678 916722 sgd_solver.cpp:106] Iteration 1197500, lr = 0.01
I0830 05:27:43.693199 916722 solver.cpp:218] Iteration 1198000 (16.7088 iter/s, 29.9243s/500 iters), loss = 0.285402
I0830 05:27:43.693257 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.28541 (* 1 = 0.28541 loss)
I0830 05:27:43.693265 916722 sgd_solver.cpp:106] Iteration 1198000, lr = 0.01
I0830 05:28:13.614574 916722 solver.cpp:218] Iteration 1198500 (16.7106 iter/s, 29.9211s/500 iters), loss = 0.237531
I0830 05:28:13.614624 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.237539 (* 1 = 0.237539 loss)
I0830 05:28:13.614634 916722 sgd_solver.cpp:106] Iteration 1198500, lr = 0.01
I0830 05:28:43.531390 916722 solver.cpp:218] Iteration 1199000 (16.7131 iter/s, 29.9166s/500 iters), loss = 0.27863
I0830 05:28:43.531443 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.278638 (* 1 = 0.278638 loss)
I0830 05:28:43.531451 916722 sgd_solver.cpp:106] Iteration 1199000, lr = 0.01
I0830 05:29:13.459559 916722 solver.cpp:218] Iteration 1199500 (16.7068 iter/s, 29.928s/500 iters), loss = 0.0149794
I0830 05:29:13.459614 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0149874 (* 1 = 0.0149874 loss)
I0830 05:29:13.459625 916722 sgd_solver.cpp:106] Iteration 1199500, lr = 0.01
I0830 05:29:43.324525 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_1200000.caffemodel
I0830 05:29:43.344223 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_1200000.solverstate
I0830 05:29:43.350505 916722 solver.cpp:330] Iteration 1200000, Testing net (#0)
I0830 05:29:58.792786 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8899
I0830 05:29:58.792835 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.36697 (* 1 = 0.36697 loss)
I0830 05:29:58.851547 916722 solver.cpp:218] Iteration 1200000 (11.0152 iter/s, 45.3917s/500 iters), loss = 0.219444
I0830 05:29:58.851573 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.219452 (* 1 = 0.219452 loss)
I0830 05:29:58.851581 916722 sgd_solver.cpp:106] Iteration 1200000, lr = 0.01
I0830 05:30:28.643095 916722 solver.cpp:218] Iteration 1200500 (16.7834 iter/s, 29.7913s/500 iters), loss = 0.0447597
I0830 05:30:28.643165 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0447677 (* 1 = 0.0447677 loss)
I0830 05:30:28.643178 916722 sgd_solver.cpp:106] Iteration 1200500, lr = 0.01
I0830 05:30:58.530854 916722 solver.cpp:218] Iteration 1201000 (16.7294 iter/s, 29.8875s/500 iters), loss = 0.226829
I0830 05:30:58.530901 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.226837 (* 1 = 0.226837 loss)
I0830 05:30:58.530911 916722 sgd_solver.cpp:106] Iteration 1201000, lr = 0.01
I0830 05:31:28.472368 916722 solver.cpp:218] Iteration 1201500 (16.6993 iter/s, 29.9413s/500 iters), loss = 0.260258
I0830 05:31:28.472432 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.260266 (* 1 = 0.260266 loss)
I0830 05:31:28.472442 916722 sgd_solver.cpp:106] Iteration 1201500, lr = 0.01
I0830 05:31:58.415916 916722 solver.cpp:218] Iteration 1202000 (16.6982 iter/s, 29.9434s/500 iters), loss = 0.140288
I0830 05:31:58.415971 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.140296 (* 1 = 0.140296 loss)
I0830 05:31:58.415982 916722 sgd_solver.cpp:106] Iteration 1202000, lr = 0.01
I0830 05:32:28.328933 916722 solver.cpp:218] Iteration 1202500 (16.7152 iter/s, 29.9128s/500 iters), loss = 0.096748
I0830 05:32:28.328994 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0967558 (* 1 = 0.0967558 loss)
I0830 05:32:28.329003 916722 sgd_solver.cpp:106] Iteration 1202500, lr = 0.01
I0830 05:32:58.246531 916722 solver.cpp:218] Iteration 1203000 (16.7127 iter/s, 29.9174s/500 iters), loss = 0.173846
I0830 05:32:58.246585 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.173854 (* 1 = 0.173854 loss)
I0830 05:32:58.246596 916722 sgd_solver.cpp:106] Iteration 1203000, lr = 0.01
I0830 05:33:28.172360 916722 solver.cpp:218] Iteration 1203500 (16.7081 iter/s, 29.9257s/500 iters), loss = 0.161964
I0830 05:33:28.172420 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.161972 (* 1 = 0.161972 loss)
I0830 05:33:28.172435 916722 sgd_solver.cpp:106] Iteration 1203500, lr = 0.01
I0830 05:33:58.087481 916722 solver.cpp:218] Iteration 1204000 (16.7141 iter/s, 29.915s/500 iters), loss = 0.111823
I0830 05:33:58.087535 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.11183 (* 1 = 0.11183 loss)
I0830 05:33:58.087545 916722 sgd_solver.cpp:106] Iteration 1204000, lr = 0.01
I0830 05:34:28.013713 916722 solver.cpp:218] Iteration 1204500 (16.7078 iter/s, 29.9261s/500 iters), loss = 0.317159
I0830 05:34:28.013772 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.317167 (* 1 = 0.317167 loss)
I0830 05:34:28.013780 916722 sgd_solver.cpp:106] Iteration 1204500, lr = 0.01
I0830 05:34:57.938803 916722 solver.cpp:218] Iteration 1205000 (16.7085 iter/s, 29.9249s/500 iters), loss = 0.251299
I0830 05:34:57.938858 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.251307 (* 1 = 0.251307 loss)
I0830 05:34:57.938867 916722 sgd_solver.cpp:106] Iteration 1205000, lr = 0.01
I0830 05:35:27.859308 916722 solver.cpp:218] Iteration 1205500 (16.711 iter/s, 29.9203s/500 iters), loss = 0.0620197
I0830 05:35:27.859373 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0620276 (* 1 = 0.0620276 loss)
I0830 05:35:27.859382 916722 sgd_solver.cpp:106] Iteration 1205500, lr = 0.01
I0830 05:35:57.779620 916722 solver.cpp:218] Iteration 1206000 (16.7112 iter/s, 29.9201s/500 iters), loss = 0.184342
I0830 05:35:57.779675 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.18435 (* 1 = 0.18435 loss)
I0830 05:35:57.779685 916722 sgd_solver.cpp:106] Iteration 1206000, lr = 0.01
I0830 05:36:27.694497 916722 solver.cpp:218] Iteration 1206500 (16.7142 iter/s, 29.9147s/500 iters), loss = 0.167685
I0830 05:36:27.694559 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.167692 (* 1 = 0.167692 loss)
I0830 05:36:27.694567 916722 sgd_solver.cpp:106] Iteration 1206500, lr = 0.01
I0830 05:36:57.614441 916722 solver.cpp:218] Iteration 1207000 (16.7114 iter/s, 29.9198s/500 iters), loss = 0.660582
I0830 05:36:57.614495 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.66059 (* 1 = 0.66059 loss)
I0830 05:36:57.614502 916722 sgd_solver.cpp:106] Iteration 1207000, lr = 0.01
I0830 05:37:27.521013 916722 solver.cpp:218] Iteration 1207500 (16.7188 iter/s, 29.9064s/500 iters), loss = 0.184788
I0830 05:37:27.521082 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.184796 (* 1 = 0.184796 loss)
I0830 05:37:27.521091 916722 sgd_solver.cpp:106] Iteration 1207500, lr = 0.01
I0830 05:37:57.445502 916722 solver.cpp:218] Iteration 1208000 (16.7088 iter/s, 29.9243s/500 iters), loss = 0.15165
I0830 05:37:57.445554 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.151658 (* 1 = 0.151658 loss)
I0830 05:37:57.445562 916722 sgd_solver.cpp:106] Iteration 1208000, lr = 0.01
I0830 05:38:27.353641 916722 solver.cpp:218] Iteration 1208500 (16.7179 iter/s, 29.908s/500 iters), loss = 0.0304309
I0830 05:38:27.353698 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0304388 (* 1 = 0.0304388 loss)
I0830 05:38:27.353708 916722 sgd_solver.cpp:106] Iteration 1208500, lr = 0.01
I0830 05:38:57.273802 916722 solver.cpp:218] Iteration 1209000 (16.7112 iter/s, 29.92s/500 iters), loss = 0.158402
I0830 05:38:57.273851 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.15841 (* 1 = 0.15841 loss)
I0830 05:38:57.273860 916722 sgd_solver.cpp:106] Iteration 1209000, lr = 0.01
I0830 05:39:27.189898 916722 solver.cpp:218] Iteration 1209500 (16.7135 iter/s, 29.916s/500 iters), loss = 0.0980651
I0830 05:39:27.189955 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0980731 (* 1 = 0.0980731 loss)
I0830 05:39:27.189963 916722 sgd_solver.cpp:106] Iteration 1209500, lr = 0.01
I0830 05:39:57.119201 916722 solver.cpp:218] Iteration 1210000 (16.7061 iter/s, 29.9292s/500 iters), loss = 0.649274
I0830 05:39:57.119251 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.649282 (* 1 = 0.649282 loss)
I0830 05:39:57.119261 916722 sgd_solver.cpp:106] Iteration 1210000, lr = 0.01
I0830 05:40:27.058604 916722 solver.cpp:218] Iteration 1210500 (16.7005 iter/s, 29.9393s/500 iters), loss = 0.128004
I0830 05:40:27.058663 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128012 (* 1 = 0.128012 loss)
I0830 05:40:27.058672 916722 sgd_solver.cpp:106] Iteration 1210500, lr = 0.01
I0830 05:40:56.990432 916722 solver.cpp:218] Iteration 1211000 (16.7047 iter/s, 29.9317s/500 iters), loss = 0.194314
I0830 05:40:56.990486 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.194323 (* 1 = 0.194323 loss)
I0830 05:40:56.990496 916722 sgd_solver.cpp:106] Iteration 1211000, lr = 0.01
I0830 05:41:26.926988 916722 solver.cpp:218] Iteration 1211500 (16.7021 iter/s, 29.9364s/500 iters), loss = 0.218928
I0830 05:41:26.927047 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.218936 (* 1 = 0.218936 loss)
I0830 05:41:26.927054 916722 sgd_solver.cpp:106] Iteration 1211500, lr = 0.01
I0830 05:41:56.848201 916722 solver.cpp:218] Iteration 1212000 (16.7106 iter/s, 29.9211s/500 iters), loss = 0.340716
I0830 05:41:56.848254 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.340724 (* 1 = 0.340724 loss)
I0830 05:41:56.848264 916722 sgd_solver.cpp:106] Iteration 1212000, lr = 0.01
I0830 05:42:26.771503 916722 solver.cpp:218] Iteration 1212500 (16.7095 iter/s, 29.9232s/500 iters), loss = 0.131556
I0830 05:42:26.771562 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131564 (* 1 = 0.131564 loss)
I0830 05:42:26.771570 916722 sgd_solver.cpp:106] Iteration 1212500, lr = 0.01
I0830 05:42:56.683894 916722 solver.cpp:218] Iteration 1213000 (16.7156 iter/s, 29.9123s/500 iters), loss = 0.17346
I0830 05:42:56.683946 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.173468 (* 1 = 0.173468 loss)
I0830 05:42:56.683956 916722 sgd_solver.cpp:106] Iteration 1213000, lr = 0.01
I0830 05:43:26.588169 916722 solver.cpp:218] Iteration 1213500 (16.7201 iter/s, 29.9041s/500 iters), loss = 0.0903115
I0830 05:43:26.588229 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0903194 (* 1 = 0.0903194 loss)
I0830 05:43:26.588238 916722 sgd_solver.cpp:106] Iteration 1213500, lr = 0.01
I0830 05:43:56.488509 916722 solver.cpp:218] Iteration 1214000 (16.7223 iter/s, 29.9002s/500 iters), loss = 0.247743
I0830 05:43:56.488559 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.247751 (* 1 = 0.247751 loss)
I0830 05:43:56.488569 916722 sgd_solver.cpp:106] Iteration 1214000, lr = 0.01
I0830 05:44:26.376364 916722 solver.cpp:218] Iteration 1214500 (16.7293 iter/s, 29.8877s/500 iters), loss = 0.265204
I0830 05:44:26.376451 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.265212 (* 1 = 0.265212 loss)
I0830 05:44:26.376461 916722 sgd_solver.cpp:106] Iteration 1214500, lr = 0.01
I0830 05:44:56.256906 916722 solver.cpp:218] Iteration 1215000 (16.7334 iter/s, 29.8804s/500 iters), loss = 0.0640527
I0830 05:44:56.256960 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0640608 (* 1 = 0.0640608 loss)
I0830 05:44:56.256970 916722 sgd_solver.cpp:106] Iteration 1215000, lr = 0.01
I0830 05:45:26.135200 916722 solver.cpp:218] Iteration 1215500 (16.7346 iter/s, 29.8782s/500 iters), loss = 0.0748426
I0830 05:45:26.135260 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0748506 (* 1 = 0.0748506 loss)
I0830 05:45:26.135268 916722 sgd_solver.cpp:106] Iteration 1215500, lr = 0.01
I0830 05:45:56.009758 916722 solver.cpp:218] Iteration 1216000 (16.7367 iter/s, 29.8744s/500 iters), loss = 0.178782
I0830 05:45:56.009810 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.17879 (* 1 = 0.17879 loss)
I0830 05:45:56.009821 916722 sgd_solver.cpp:106] Iteration 1216000, lr = 0.01
I0830 05:46:25.874564 916722 solver.cpp:218] Iteration 1216500 (16.7422 iter/s, 29.8647s/500 iters), loss = 0.232694
I0830 05:46:25.874625 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.232702 (* 1 = 0.232702 loss)
I0830 05:46:25.874634 916722 sgd_solver.cpp:106] Iteration 1216500, lr = 0.01
I0830 05:46:55.732326 916722 solver.cpp:218] Iteration 1217000 (16.7461 iter/s, 29.8576s/500 iters), loss = 0.589198
I0830 05:46:55.732378 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.589205 (* 1 = 0.589205 loss)
I0830 05:46:55.732385 916722 sgd_solver.cpp:106] Iteration 1217000, lr = 0.01
I0830 05:47:25.599459 916722 solver.cpp:218] Iteration 1217500 (16.7409 iter/s, 29.867s/500 iters), loss = 0.317291
I0830 05:47:25.599519 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.317299 (* 1 = 0.317299 loss)
I0830 05:47:25.599527 916722 sgd_solver.cpp:106] Iteration 1217500, lr = 0.01
I0830 05:47:55.439232 916722 solver.cpp:218] Iteration 1218000 (16.7562 iter/s, 29.8396s/500 iters), loss = 0.348313
I0830 05:47:55.439281 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.348321 (* 1 = 0.348321 loss)
I0830 05:47:55.439291 916722 sgd_solver.cpp:106] Iteration 1218000, lr = 0.01
I0830 05:48:25.278160 916722 solver.cpp:218] Iteration 1218500 (16.7567 iter/s, 29.8388s/500 iters), loss = 0.0471627
I0830 05:48:25.278213 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0471705 (* 1 = 0.0471705 loss)
I0830 05:48:25.278223 916722 sgd_solver.cpp:106] Iteration 1218500, lr = 0.01
I0830 05:48:55.132839 916722 solver.cpp:218] Iteration 1219000 (16.7479 iter/s, 29.8545s/500 iters), loss = 0.059812
I0830 05:48:55.132894 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0598197 (* 1 = 0.0598197 loss)
I0830 05:48:55.132902 916722 sgd_solver.cpp:106] Iteration 1219000, lr = 0.01
I0830 05:49:24.997541 916722 solver.cpp:218] Iteration 1219500 (16.7422 iter/s, 29.8646s/500 iters), loss = 0.189982
I0830 05:49:24.997603 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.189989 (* 1 = 0.189989 loss)
I0830 05:49:24.997612 916722 sgd_solver.cpp:106] Iteration 1219500, lr = 0.01
I0830 05:49:54.862797 916722 solver.cpp:218] Iteration 1220000 (16.7419 iter/s, 29.8651s/500 iters), loss = 0.138363
I0830 05:49:54.862851 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.138371 (* 1 = 0.138371 loss)
I0830 05:49:54.862860 916722 sgd_solver.cpp:106] Iteration 1220000, lr = 0.01
I0830 05:50:24.764506 916722 solver.cpp:218] Iteration 1220500 (16.7215 iter/s, 29.9016s/500 iters), loss = 0.253957
I0830 05:50:24.764581 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.253964 (* 1 = 0.253964 loss)
I0830 05:50:24.764590 916722 sgd_solver.cpp:106] Iteration 1220500, lr = 0.01
I0830 05:50:54.652639 916722 solver.cpp:218] Iteration 1221000 (16.7291 iter/s, 29.888s/500 iters), loss = 0.172397
I0830 05:50:54.652693 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.172405 (* 1 = 0.172405 loss)
I0830 05:50:54.652701 916722 sgd_solver.cpp:106] Iteration 1221000, lr = 0.01
I0830 05:51:24.554065 916722 solver.cpp:218] Iteration 1221500 (16.7217 iter/s, 29.9013s/500 iters), loss = 0.0656892
I0830 05:51:24.554127 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0656968 (* 1 = 0.0656968 loss)
I0830 05:51:24.554136 916722 sgd_solver.cpp:106] Iteration 1221500, lr = 0.01
I0830 05:51:54.446305 916722 solver.cpp:218] Iteration 1222000 (16.7268 iter/s, 29.8921s/500 iters), loss = 0.226517
I0830 05:51:54.446360 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.226525 (* 1 = 0.226525 loss)
I0830 05:51:54.446370 916722 sgd_solver.cpp:106] Iteration 1222000, lr = 0.01
I0830 05:52:24.338191 916722 solver.cpp:218] Iteration 1222500 (16.727 iter/s, 29.8918s/500 iters), loss = 0.297825
I0830 05:52:24.338245 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.297832 (* 1 = 0.297832 loss)
I0830 05:52:24.338254 916722 sgd_solver.cpp:106] Iteration 1222500, lr = 0.01
I0830 05:52:54.260818 916722 solver.cpp:218] Iteration 1223000 (16.7096 iter/s, 29.9228s/500 iters), loss = 0.167553
I0830 05:52:54.260869 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.167561 (* 1 = 0.167561 loss)
I0830 05:52:54.260877 916722 sgd_solver.cpp:106] Iteration 1223000, lr = 0.01
I0830 05:53:24.150820 916722 solver.cpp:218] Iteration 1223500 (16.7279 iter/s, 29.8902s/500 iters), loss = 0.174248
I0830 05:53:24.150879 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.174256 (* 1 = 0.174256 loss)
I0830 05:53:24.150887 916722 sgd_solver.cpp:106] Iteration 1223500, lr = 0.01
I0830 05:53:54.048049 916722 solver.cpp:218] Iteration 1224000 (16.7239 iter/s, 29.8974s/500 iters), loss = 0.31118
I0830 05:53:54.048103 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.311187 (* 1 = 0.311187 loss)
I0830 05:53:54.048113 916722 sgd_solver.cpp:106] Iteration 1224000, lr = 0.01
I0830 05:54:23.947659 916722 solver.cpp:218] Iteration 1224500 (16.7225 iter/s, 29.8998s/500 iters), loss = 0.167214
I0830 05:54:23.947715 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.167221 (* 1 = 0.167221 loss)
I0830 05:54:23.947724 916722 sgd_solver.cpp:106] Iteration 1224500, lr = 0.01
I0830 05:54:53.838131 916722 solver.cpp:218] Iteration 1225000 (16.7277 iter/s, 29.8906s/500 iters), loss = 0.0769021
I0830 05:54:53.838186 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0769097 (* 1 = 0.0769097 loss)
I0830 05:54:53.838196 916722 sgd_solver.cpp:106] Iteration 1225000, lr = 0.01
I0830 05:55:23.720885 916722 solver.cpp:218] Iteration 1225500 (16.732 iter/s, 29.8829s/500 iters), loss = 0.027059
I0830 05:55:23.720944 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0270666 (* 1 = 0.0270666 loss)
I0830 05:55:23.720953 916722 sgd_solver.cpp:106] Iteration 1225500, lr = 0.01
I0830 05:55:53.619232 916722 solver.cpp:218] Iteration 1226000 (16.7233 iter/s, 29.8985s/500 iters), loss = 0.1566
I0830 05:55:53.619285 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.156607 (* 1 = 0.156607 loss)
I0830 05:55:53.619297 916722 sgd_solver.cpp:106] Iteration 1226000, lr = 0.01
I0830 05:56:23.514485 916722 solver.cpp:218] Iteration 1226500 (16.725 iter/s, 29.8954s/500 iters), loss = 0.116266
I0830 05:56:23.514544 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.116273 (* 1 = 0.116273 loss)
I0830 05:56:23.514552 916722 sgd_solver.cpp:106] Iteration 1226500, lr = 0.01
I0830 05:56:53.390740 916722 solver.cpp:218] Iteration 1227000 (16.7356 iter/s, 29.8764s/500 iters), loss = 0.114283
I0830 05:56:53.390802 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.114291 (* 1 = 0.114291 loss)
I0830 05:56:53.390812 916722 sgd_solver.cpp:106] Iteration 1227000, lr = 0.01
I0830 05:57:23.271175 916722 solver.cpp:218] Iteration 1227500 (16.7333 iter/s, 29.8805s/500 iters), loss = 0.167015
I0830 05:57:23.271248 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.167022 (* 1 = 0.167022 loss)
I0830 05:57:23.271257 916722 sgd_solver.cpp:106] Iteration 1227500, lr = 0.01
I0830 05:57:53.148341 916722 solver.cpp:218] Iteration 1228000 (16.7352 iter/s, 29.8772s/500 iters), loss = 0.131559
I0830 05:57:53.148396 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131567 (* 1 = 0.131567 loss)
I0830 05:57:53.148403 916722 sgd_solver.cpp:106] Iteration 1228000, lr = 0.01
I0830 05:58:23.027927 916722 solver.cpp:218] Iteration 1228500 (16.7338 iter/s, 29.8797s/500 iters), loss = 0.0970544
I0830 05:58:23.027987 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0970621 (* 1 = 0.0970621 loss)
I0830 05:58:23.027997 916722 sgd_solver.cpp:106] Iteration 1228500, lr = 0.01
I0830 05:58:52.905400 916722 solver.cpp:218] Iteration 1229000 (16.735 iter/s, 29.8775s/500 iters), loss = 0.139353
I0830 05:58:52.905452 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139361 (* 1 = 0.139361 loss)
I0830 05:58:52.905460 916722 sgd_solver.cpp:106] Iteration 1229000, lr = 0.01
I0830 05:59:22.801192 916722 solver.cpp:218] Iteration 1229500 (16.7247 iter/s, 29.8959s/500 iters), loss = 0.115875
I0830 05:59:22.801251 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115882 (* 1 = 0.115882 loss)
I0830 05:59:22.801260 916722 sgd_solver.cpp:106] Iteration 1229500, lr = 0.01
I0830 05:59:52.681931 916722 solver.cpp:218] Iteration 1230000 (16.7332 iter/s, 29.8808s/500 iters), loss = 0.233805
I0830 05:59:52.681984 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.233813 (* 1 = 0.233813 loss)
I0830 05:59:52.681993 916722 sgd_solver.cpp:106] Iteration 1230000, lr = 0.01
I0830 06:00:22.550875 916722 solver.cpp:218] Iteration 1230500 (16.7398 iter/s, 29.869s/500 iters), loss = 0.242022
I0830 06:00:22.550935 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.24203 (* 1 = 0.24203 loss)
I0830 06:00:22.550945 916722 sgd_solver.cpp:106] Iteration 1230500, lr = 0.01
I0830 06:00:52.412976 916722 solver.cpp:218] Iteration 1231000 (16.7436 iter/s, 29.8621s/500 iters), loss = 0.174393
I0830 06:00:52.413028 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.1744 (* 1 = 0.1744 loss)
I0830 06:00:52.413036 916722 sgd_solver.cpp:106] Iteration 1231000, lr = 0.01
I0830 06:01:22.285545 916722 solver.cpp:218] Iteration 1231500 (16.7377 iter/s, 29.8726s/500 iters), loss = 0.0708065
I0830 06:01:22.285601 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0708141 (* 1 = 0.0708141 loss)
I0830 06:01:22.285609 916722 sgd_solver.cpp:106] Iteration 1231500, lr = 0.01
I0830 06:01:52.152213 916722 solver.cpp:218] Iteration 1232000 (16.7411 iter/s, 29.8667s/500 iters), loss = 0.13973
I0830 06:01:52.152267 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139738 (* 1 = 0.139738 loss)
I0830 06:01:52.152276 916722 sgd_solver.cpp:106] Iteration 1232000, lr = 0.01
I0830 06:02:22.029109 916722 solver.cpp:218] Iteration 1232500 (16.7353 iter/s, 29.8769s/500 iters), loss = 0.0849416
I0830 06:02:22.029170 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0849493 (* 1 = 0.0849493 loss)
I0830 06:02:22.029179 916722 sgd_solver.cpp:106] Iteration 1232500, lr = 0.01
I0830 06:02:51.873988 916722 solver.cpp:218] Iteration 1233000 (16.7533 iter/s, 29.8449s/500 iters), loss = 0.101122
I0830 06:02:51.874047 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101129 (* 1 = 0.101129 loss)
I0830 06:02:51.874056 916722 sgd_solver.cpp:106] Iteration 1233000, lr = 0.01
I0830 06:03:21.682525 916722 solver.cpp:218] Iteration 1233500 (16.7737 iter/s, 29.8085s/500 iters), loss = 0.198829
I0830 06:03:21.682595 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.198837 (* 1 = 0.198837 loss)
I0830 06:03:21.682606 916722 sgd_solver.cpp:106] Iteration 1233500, lr = 0.01
I0830 06:03:51.499099 916722 solver.cpp:218] Iteration 1234000 (16.7692 iter/s, 29.8166s/500 iters), loss = 0.0566794
I0830 06:03:51.499150 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0566872 (* 1 = 0.0566872 loss)
I0830 06:03:51.499159 916722 sgd_solver.cpp:106] Iteration 1234000, lr = 0.01
I0830 06:04:21.334048 916722 solver.cpp:218] Iteration 1234500 (16.7589 iter/s, 29.8349s/500 iters), loss = 0.234636
I0830 06:04:21.334107 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.234644 (* 1 = 0.234644 loss)
I0830 06:04:21.334115 916722 sgd_solver.cpp:106] Iteration 1234500, lr = 0.01
I0830 06:04:51.180529 916722 solver.cpp:218] Iteration 1235000 (16.7524 iter/s, 29.8465s/500 iters), loss = 0.131395
I0830 06:04:51.180584 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131403 (* 1 = 0.131403 loss)
I0830 06:04:51.180594 916722 sgd_solver.cpp:106] Iteration 1235000, lr = 0.01
I0830 06:05:21.029273 916722 solver.cpp:218] Iteration 1235500 (16.7511 iter/s, 29.8487s/500 iters), loss = 0.166366
I0830 06:05:21.029321 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.166373 (* 1 = 0.166373 loss)
I0830 06:05:21.029330 916722 sgd_solver.cpp:106] Iteration 1235500, lr = 0.01
I0830 06:05:50.893154 916722 solver.cpp:218] Iteration 1236000 (16.7426 iter/s, 29.8639s/500 iters), loss = 0.375675
I0830 06:05:50.893208 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.375683 (* 1 = 0.375683 loss)
I0830 06:05:50.893216 916722 sgd_solver.cpp:106] Iteration 1236000, lr = 0.01
I0830 06:06:20.750404 916722 solver.cpp:218] Iteration 1236500 (16.7464 iter/s, 29.8572s/500 iters), loss = 0.0634948
I0830 06:06:20.750466 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0635027 (* 1 = 0.0635027 loss)
I0830 06:06:20.750475 916722 sgd_solver.cpp:106] Iteration 1236500, lr = 0.01
I0830 06:06:50.598881 916722 solver.cpp:218] Iteration 1237000 (16.7513 iter/s, 29.8484s/500 iters), loss = 0.191994
I0830 06:06:50.598937 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.192002 (* 1 = 0.192002 loss)
I0830 06:06:50.598948 916722 sgd_solver.cpp:106] Iteration 1237000, lr = 0.01
I0830 06:07:20.486060 916722 solver.cpp:218] Iteration 1237500 (16.7296 iter/s, 29.8871s/500 iters), loss = 0.108839
I0830 06:07:20.486119 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.108847 (* 1 = 0.108847 loss)
I0830 06:07:20.486127 916722 sgd_solver.cpp:106] Iteration 1237500, lr = 0.01
I0830 06:07:50.376178 916722 solver.cpp:218] Iteration 1238000 (16.728 iter/s, 29.8901s/500 iters), loss = 0.389395
I0830 06:07:50.376231 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.389403 (* 1 = 0.389403 loss)
I0830 06:07:50.376242 916722 sgd_solver.cpp:106] Iteration 1238000, lr = 0.01
I0830 06:08:20.243746 916722 solver.cpp:218] Iteration 1238500 (16.7406 iter/s, 29.8675s/500 iters), loss = 0.072238
I0830 06:08:20.243806 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0722458 (* 1 = 0.0722458 loss)
I0830 06:08:20.243814 916722 sgd_solver.cpp:106] Iteration 1238500, lr = 0.01
I0830 06:08:50.114432 916722 solver.cpp:218] Iteration 1239000 (16.7388 iter/s, 29.8706s/500 iters), loss = 0.213062
I0830 06:08:50.114485 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.213069 (* 1 = 0.213069 loss)
I0830 06:08:50.114495 916722 sgd_solver.cpp:106] Iteration 1239000, lr = 0.01
I0830 06:09:19.979761 916722 solver.cpp:218] Iteration 1239500 (16.7418 iter/s, 29.8653s/500 iters), loss = 0.177503
I0830 06:09:19.979821 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.177511 (* 1 = 0.177511 loss)
I0830 06:09:19.979830 916722 sgd_solver.cpp:106] Iteration 1239500, lr = 0.01
I0830 06:09:49.864280 916722 solver.cpp:218] Iteration 1240000 (16.7311 iter/s, 29.8845s/500 iters), loss = 0.15814
I0830 06:09:49.864333 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.158148 (* 1 = 0.158148 loss)
I0830 06:09:49.864356 916722 sgd_solver.cpp:106] Iteration 1240000, lr = 0.01
I0830 06:10:19.735026 916722 solver.cpp:218] Iteration 1240500 (16.7388 iter/s, 29.8707s/500 iters), loss = 0.172816
I0830 06:10:19.735095 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.172824 (* 1 = 0.172824 loss)
I0830 06:10:19.735102 916722 sgd_solver.cpp:106] Iteration 1240500, lr = 0.01
I0830 06:10:49.612301 916722 solver.cpp:218] Iteration 1241000 (16.7352 iter/s, 29.8772s/500 iters), loss = 0.310423
I0830 06:10:49.612357 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.310431 (* 1 = 0.310431 loss)
I0830 06:10:49.612366 916722 sgd_solver.cpp:106] Iteration 1241000, lr = 0.01
I0830 06:11:19.467741 916722 solver.cpp:218] Iteration 1241500 (16.7474 iter/s, 29.8554s/500 iters), loss = 0.176089
I0830 06:11:19.467798 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.176096 (* 1 = 0.176096 loss)
I0830 06:11:19.467806 916722 sgd_solver.cpp:106] Iteration 1241500, lr = 0.01
I0830 06:11:49.344344 916722 solver.cpp:218] Iteration 1242000 (16.7355 iter/s, 29.8765s/500 iters), loss = 0.226648
I0830 06:11:49.344396 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.226656 (* 1 = 0.226656 loss)
I0830 06:11:49.344406 916722 sgd_solver.cpp:106] Iteration 1242000, lr = 0.01
I0830 06:12:19.187602 916722 solver.cpp:218] Iteration 1242500 (16.7542 iter/s, 29.8432s/500 iters), loss = 0.0391134
I0830 06:12:19.187659 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0391209 (* 1 = 0.0391209 loss)
I0830 06:12:19.187666 916722 sgd_solver.cpp:106] Iteration 1242500, lr = 0.01
I0830 06:12:49.051136 916722 solver.cpp:218] Iteration 1243000 (16.7429 iter/s, 29.8635s/500 iters), loss = 0.105166
I0830 06:12:49.051192 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105174 (* 1 = 0.105174 loss)
I0830 06:12:49.051201 916722 sgd_solver.cpp:106] Iteration 1243000, lr = 0.01
I0830 06:13:18.913647 916722 solver.cpp:218] Iteration 1243500 (16.7434 iter/s, 29.8624s/500 iters), loss = 0.236605
I0830 06:13:18.913710 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.236612 (* 1 = 0.236612 loss)
I0830 06:13:18.913719 916722 sgd_solver.cpp:106] Iteration 1243500, lr = 0.01
I0830 06:13:48.768285 916722 solver.cpp:218] Iteration 1244000 (16.7479 iter/s, 29.8546s/500 iters), loss = 0.146726
I0830 06:13:48.768338 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.146733 (* 1 = 0.146733 loss)
I0830 06:13:48.768347 916722 sgd_solver.cpp:106] Iteration 1244000, lr = 0.01
I0830 06:14:18.615330 916722 solver.cpp:218] Iteration 1244500 (16.7521 iter/s, 29.847s/500 iters), loss = 0.0939177
I0830 06:14:18.615391 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0939252 (* 1 = 0.0939252 loss)
I0830 06:14:18.615399 916722 sgd_solver.cpp:106] Iteration 1244500, lr = 0.01
I0830 06:14:48.479012 916722 solver.cpp:218] Iteration 1245000 (16.7428 iter/s, 29.8636s/500 iters), loss = 0.288254
I0830 06:14:48.479064 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.288261 (* 1 = 0.288261 loss)
I0830 06:14:48.479074 916722 sgd_solver.cpp:106] Iteration 1245000, lr = 0.01
I0830 06:15:18.343956 916722 solver.cpp:218] Iteration 1245500 (16.7421 iter/s, 29.8649s/500 iters), loss = 0.132749
I0830 06:15:18.344017 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.132756 (* 1 = 0.132756 loss)
I0830 06:15:18.344025 916722 sgd_solver.cpp:106] Iteration 1245500, lr = 0.01
I0830 06:15:48.197410 916722 solver.cpp:218] Iteration 1246000 (16.7485 iter/s, 29.8534s/500 iters), loss = 0.116499
I0830 06:15:48.197463 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.116507 (* 1 = 0.116507 loss)
I0830 06:15:48.197471 916722 sgd_solver.cpp:106] Iteration 1246000, lr = 0.01
I0830 06:16:18.044474 916722 solver.cpp:218] Iteration 1246500 (16.7521 iter/s, 29.847s/500 iters), loss = 0.0729556
I0830 06:16:18.044548 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0729631 (* 1 = 0.0729631 loss)
I0830 06:16:18.044564 916722 sgd_solver.cpp:106] Iteration 1246500, lr = 0.01
I0830 06:16:47.900745 916722 solver.cpp:218] Iteration 1247000 (16.747 iter/s, 29.8562s/500 iters), loss = 0.305768
I0830 06:16:47.900806 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.305775 (* 1 = 0.305775 loss)
I0830 06:16:47.900815 916722 sgd_solver.cpp:106] Iteration 1247000, lr = 0.01
I0830 06:17:17.787305 916722 solver.cpp:218] Iteration 1247500 (16.73 iter/s, 29.8865s/500 iters), loss = 0.333896
I0830 06:17:17.787367 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.333904 (* 1 = 0.333904 loss)
I0830 06:17:17.787375 916722 sgd_solver.cpp:106] Iteration 1247500, lr = 0.01
I0830 06:17:47.663156 916722 solver.cpp:218] Iteration 1248000 (16.736 iter/s, 29.8758s/500 iters), loss = 0.150917
I0830 06:17:47.663208 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.150924 (* 1 = 0.150924 loss)
I0830 06:17:47.663218 916722 sgd_solver.cpp:106] Iteration 1248000, lr = 0.01
I0830 06:18:17.565287 916722 solver.cpp:218] Iteration 1248500 (16.7213 iter/s, 29.9021s/500 iters), loss = 0.208012
I0830 06:18:17.565348 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.208019 (* 1 = 0.208019 loss)
I0830 06:18:17.565357 916722 sgd_solver.cpp:106] Iteration 1248500, lr = 0.01
I0830 06:18:47.455952 916722 solver.cpp:218] Iteration 1249000 (16.7277 iter/s, 29.8906s/500 iters), loss = 0.286382
I0830 06:18:47.456009 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.286389 (* 1 = 0.286389 loss)
I0830 06:18:47.456019 916722 sgd_solver.cpp:106] Iteration 1249000, lr = 0.01
I0830 06:19:17.359632 916722 solver.cpp:218] Iteration 1249500 (16.7204 iter/s, 29.9036s/500 iters), loss = 0.0714768
I0830 06:19:17.359690 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0714848 (* 1 = 0.0714848 loss)
I0830 06:19:17.359699 916722 sgd_solver.cpp:106] Iteration 1249500, lr = 0.01
I0830 06:19:47.203483 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_1250000.caffemodel
I0830 06:19:47.223132 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_1250000.solverstate
I0830 06:19:47.229478 916722 solver.cpp:330] Iteration 1250000, Testing net (#0)
I0830 06:20:02.704136 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8863
I0830 06:20:02.704187 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.367304 (* 1 = 0.367304 loss)
I0830 06:20:02.762892 916722 solver.cpp:218] Iteration 1250000 (11.0124 iter/s, 45.4032s/500 iters), loss = 0.105643
I0830 06:20:02.762920 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105651 (* 1 = 0.105651 loss)
I0830 06:20:02.762928 916722 sgd_solver.cpp:106] Iteration 1250000, lr = 0.01
I0830 06:20:32.550078 916722 solver.cpp:218] Iteration 1250500 (16.7858 iter/s, 29.7871s/500 iters), loss = 0.084807
I0830 06:20:32.550134 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0848151 (* 1 = 0.0848151 loss)
I0830 06:20:32.550143 916722 sgd_solver.cpp:106] Iteration 1250500, lr = 0.01
I0830 06:21:02.425928 916722 solver.cpp:218] Iteration 1251000 (16.736 iter/s, 29.8758s/500 iters), loss = 0.187701
I0830 06:21:02.425988 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.187709 (* 1 = 0.187709 loss)
I0830 06:21:02.425997 916722 sgd_solver.cpp:106] Iteration 1251000, lr = 0.01
I0830 06:21:32.341053 916722 solver.cpp:218] Iteration 1251500 (16.714 iter/s, 29.915s/500 iters), loss = 0.147786
I0830 06:21:32.341106 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.147794 (* 1 = 0.147794 loss)
I0830 06:21:32.341115 916722 sgd_solver.cpp:106] Iteration 1251500, lr = 0.01
I0830 06:22:02.251112 916722 solver.cpp:218] Iteration 1252000 (16.7168 iter/s, 29.91s/500 iters), loss = 0.0793098
I0830 06:22:02.251173 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0793179 (* 1 = 0.0793179 loss)
I0830 06:22:02.251181 916722 sgd_solver.cpp:106] Iteration 1252000, lr = 0.01
I0830 06:22:32.155226 916722 solver.cpp:218] Iteration 1252500 (16.7202 iter/s, 29.904s/500 iters), loss = 0.191664
I0830 06:22:32.155293 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.191672 (* 1 = 0.191672 loss)
I0830 06:22:32.155303 916722 sgd_solver.cpp:106] Iteration 1252500, lr = 0.01
I0830 06:23:02.053381 916722 solver.cpp:218] Iteration 1253000 (16.7235 iter/s, 29.8981s/500 iters), loss = 0.215849
I0830 06:23:02.053448 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.215857 (* 1 = 0.215857 loss)
I0830 06:23:02.053457 916722 sgd_solver.cpp:106] Iteration 1253000, lr = 0.01
I0830 06:23:31.966758 916722 solver.cpp:218] Iteration 1253500 (16.715 iter/s, 29.9133s/500 iters), loss = 0.301595
I0830 06:23:31.966809 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.301604 (* 1 = 0.301604 loss)
I0830 06:23:31.966820 916722 sgd_solver.cpp:106] Iteration 1253500, lr = 0.01
I0830 06:24:01.877207 916722 solver.cpp:218] Iteration 1254000 (16.7166 iter/s, 29.9104s/500 iters), loss = 0.0689215
I0830 06:24:01.877265 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0689295 (* 1 = 0.0689295 loss)
I0830 06:24:01.877274 916722 sgd_solver.cpp:106] Iteration 1254000, lr = 0.01
I0830 06:24:31.782197 916722 solver.cpp:218] Iteration 1254500 (16.7197 iter/s, 29.9049s/500 iters), loss = 0.250646
I0830 06:24:31.782253 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.250654 (* 1 = 0.250654 loss)
I0830 06:24:31.782263 916722 sgd_solver.cpp:106] Iteration 1254500, lr = 0.01
I0830 06:25:01.678926 916722 solver.cpp:218] Iteration 1255000 (16.7243 iter/s, 29.8967s/500 iters), loss = 0.122361
I0830 06:25:01.678982 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.122369 (* 1 = 0.122369 loss)
I0830 06:25:01.678990 916722 sgd_solver.cpp:106] Iteration 1255000, lr = 0.01
I0830 06:25:31.592993 916722 solver.cpp:218] Iteration 1255500 (16.7146 iter/s, 29.914s/500 iters), loss = 0.111737
I0830 06:25:31.593046 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111744 (* 1 = 0.111744 loss)
I0830 06:25:31.593056 916722 sgd_solver.cpp:106] Iteration 1255500, lr = 0.01
I0830 06:26:01.498073 916722 solver.cpp:218] Iteration 1256000 (16.7196 iter/s, 29.905s/500 iters), loss = 0.0423902
I0830 06:26:01.498129 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.042398 (* 1 = 0.042398 loss)
I0830 06:26:01.498138 916722 sgd_solver.cpp:106] Iteration 1256000, lr = 0.01
I0830 06:26:31.387955 916722 solver.cpp:218] Iteration 1256500 (16.7281 iter/s, 29.8898s/500 iters), loss = 0.0513224
I0830 06:26:31.388005 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0513302 (* 1 = 0.0513302 loss)
I0830 06:26:31.388015 916722 sgd_solver.cpp:106] Iteration 1256500, lr = 0.01
I0830 06:27:01.287966 916722 solver.cpp:218] Iteration 1257000 (16.7227 iter/s, 29.8995s/500 iters), loss = 0.205165
I0830 06:27:01.288023 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.205172 (* 1 = 0.205172 loss)
I0830 06:27:01.288031 916722 sgd_solver.cpp:106] Iteration 1257000, lr = 0.01
I0830 06:27:31.193193 916722 solver.cpp:218] Iteration 1257500 (16.7198 iter/s, 29.9047s/500 iters), loss = 0.194818
I0830 06:27:31.193245 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.194826 (* 1 = 0.194826 loss)
I0830 06:27:31.193255 916722 sgd_solver.cpp:106] Iteration 1257500, lr = 0.01
I0830 06:28:01.100666 916722 solver.cpp:218] Iteration 1258000 (16.7185 iter/s, 29.907s/500 iters), loss = 0.170713
I0830 06:28:01.100726 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.170721 (* 1 = 0.170721 loss)
I0830 06:28:01.100735 916722 sgd_solver.cpp:106] Iteration 1258000, lr = 0.01
I0830 06:28:31.015612 916722 solver.cpp:218] Iteration 1258500 (16.7143 iter/s, 29.9145s/500 iters), loss = 0.0342845
I0830 06:28:31.015667 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0342919 (* 1 = 0.0342919 loss)
I0830 06:28:31.015676 916722 sgd_solver.cpp:106] Iteration 1258500, lr = 0.01
I0830 06:29:00.906586 916722 solver.cpp:218] Iteration 1259000 (16.7277 iter/s, 29.8905s/500 iters), loss = 0.0485096
I0830 06:29:00.906657 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0485171 (* 1 = 0.0485171 loss)
I0830 06:29:00.906677 916722 sgd_solver.cpp:106] Iteration 1259000, lr = 0.01
I0830 06:29:30.814280 916722 solver.cpp:218] Iteration 1259500 (16.7184 iter/s, 29.9072s/500 iters), loss = 0.211186
I0830 06:29:30.814335 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.211194 (* 1 = 0.211194 loss)
I0830 06:29:30.814344 916722 sgd_solver.cpp:106] Iteration 1259500, lr = 0.01
I0830 06:30:00.724658 916722 solver.cpp:218] Iteration 1260000 (16.7168 iter/s, 29.91s/500 iters), loss = 0.159398
I0830 06:30:00.724714 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159405 (* 1 = 0.159405 loss)
I0830 06:30:00.724722 916722 sgd_solver.cpp:106] Iteration 1260000, lr = 0.01
I0830 06:30:30.616595 916722 solver.cpp:218] Iteration 1260500 (16.7271 iter/s, 29.8915s/500 iters), loss = 0.123064
I0830 06:30:30.616649 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.123071 (* 1 = 0.123071 loss)
I0830 06:30:30.616659 916722 sgd_solver.cpp:106] Iteration 1260500, lr = 0.01
I0830 06:31:00.513113 916722 solver.cpp:218] Iteration 1261000 (16.7246 iter/s, 29.8961s/500 iters), loss = 0.134275
I0830 06:31:00.513168 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.134283 (* 1 = 0.134283 loss)
I0830 06:31:00.513177 916722 sgd_solver.cpp:106] Iteration 1261000, lr = 0.01
I0830 06:31:30.414139 916722 solver.cpp:218] Iteration 1261500 (16.722 iter/s, 29.9007s/500 iters), loss = 0.274125
I0830 06:31:30.414192 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.274132 (* 1 = 0.274132 loss)
I0830 06:31:30.414201 916722 sgd_solver.cpp:106] Iteration 1261500, lr = 0.01
I0830 06:32:00.328508 916722 solver.cpp:218] Iteration 1262000 (16.7146 iter/s, 29.914s/500 iters), loss = 0.503385
I0830 06:32:00.328563 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.503392 (* 1 = 0.503392 loss)
I0830 06:32:00.328572 916722 sgd_solver.cpp:106] Iteration 1262000, lr = 0.01
I0830 06:32:30.225050 916722 solver.cpp:218] Iteration 1262500 (16.7245 iter/s, 29.8962s/500 iters), loss = 0.138464
I0830 06:32:30.225100 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.138471 (* 1 = 0.138471 loss)
I0830 06:32:30.225108 916722 sgd_solver.cpp:106] Iteration 1262500, lr = 0.01
I0830 06:33:00.149536 916722 solver.cpp:218] Iteration 1263000 (16.7089 iter/s, 29.9242s/500 iters), loss = 0.0324341
I0830 06:33:00.149596 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0324413 (* 1 = 0.0324413 loss)
I0830 06:33:00.149605 916722 sgd_solver.cpp:106] Iteration 1263000, lr = 0.01
I0830 06:33:30.046279 916722 solver.cpp:218] Iteration 1263500 (16.7244 iter/s, 29.8964s/500 iters), loss = 0.110479
I0830 06:33:30.046335 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110486 (* 1 = 0.110486 loss)
I0830 06:33:30.046346 916722 sgd_solver.cpp:106] Iteration 1263500, lr = 0.01
I0830 06:33:59.950728 916722 solver.cpp:218] Iteration 1264000 (16.7201 iter/s, 29.9041s/500 iters), loss = 0.106604
I0830 06:33:59.950790 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.106611 (* 1 = 0.106611 loss)
I0830 06:33:59.950799 916722 sgd_solver.cpp:106] Iteration 1264000, lr = 0.01
I0830 06:34:29.840365 916722 solver.cpp:218] Iteration 1264500 (16.7284 iter/s, 29.8893s/500 iters), loss = 0.158261
I0830 06:34:29.840420 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.158268 (* 1 = 0.158268 loss)
I0830 06:34:29.840436 916722 sgd_solver.cpp:106] Iteration 1264500, lr = 0.01
I0830 06:34:59.753931 916722 solver.cpp:218] Iteration 1265000 (16.715 iter/s, 29.9133s/500 iters), loss = 0.344107
I0830 06:34:59.753990 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.344114 (* 1 = 0.344114 loss)
I0830 06:34:59.753999 916722 sgd_solver.cpp:106] Iteration 1265000, lr = 0.01
I0830 06:35:29.683521 916722 solver.cpp:218] Iteration 1265500 (16.706 iter/s, 29.9293s/500 iters), loss = 0.112528
I0830 06:35:29.683593 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112535 (* 1 = 0.112535 loss)
I0830 06:35:29.683602 916722 sgd_solver.cpp:106] Iteration 1265500, lr = 0.01
I0830 06:35:59.599669 916722 solver.cpp:218] Iteration 1266000 (16.7135 iter/s, 29.9159s/500 iters), loss = 0.219358
I0830 06:35:59.599737 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.219365 (* 1 = 0.219365 loss)
I0830 06:35:59.599746 916722 sgd_solver.cpp:106] Iteration 1266000, lr = 0.01
I0830 06:36:29.518235 916722 solver.cpp:218] Iteration 1266500 (16.7122 iter/s, 29.9183s/500 iters), loss = 0.209396
I0830 06:36:29.518285 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.209403 (* 1 = 0.209403 loss)
I0830 06:36:29.518296 916722 sgd_solver.cpp:106] Iteration 1266500, lr = 0.01
I0830 06:36:59.461692 916722 solver.cpp:218] Iteration 1267000 (16.6983 iter/s, 29.9432s/500 iters), loss = 0.0900846
I0830 06:36:59.461748 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0900914 (* 1 = 0.0900914 loss)
I0830 06:36:59.461756 916722 sgd_solver.cpp:106] Iteration 1267000, lr = 0.01
I0830 06:37:29.400640 916722 solver.cpp:218] Iteration 1267500 (16.7008 iter/s, 29.9387s/500 iters), loss = 0.0739441
I0830 06:37:29.400696 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0739509 (* 1 = 0.0739509 loss)
I0830 06:37:29.400707 916722 sgd_solver.cpp:106] Iteration 1267500, lr = 0.01
I0830 06:37:59.353511 916722 solver.cpp:218] Iteration 1268000 (16.693 iter/s, 29.9526s/500 iters), loss = 0.258935
I0830 06:37:59.353574 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.258942 (* 1 = 0.258942 loss)
I0830 06:37:59.353582 916722 sgd_solver.cpp:106] Iteration 1268000, lr = 0.01
I0830 06:38:29.291736 916722 solver.cpp:218] Iteration 1268500 (16.7012 iter/s, 29.938s/500 iters), loss = 0.0670336
I0830 06:38:29.291790 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0670404 (* 1 = 0.0670404 loss)
I0830 06:38:29.291798 916722 sgd_solver.cpp:106] Iteration 1268500, lr = 0.01
I0830 06:38:59.223107 916722 solver.cpp:218] Iteration 1269000 (16.705 iter/s, 29.9311s/500 iters), loss = 0.248824
I0830 06:38:59.223166 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.248831 (* 1 = 0.248831 loss)
I0830 06:38:59.223176 916722 sgd_solver.cpp:106] Iteration 1269000, lr = 0.01
I0830 06:39:29.164965 916722 solver.cpp:218] Iteration 1269500 (16.6992 iter/s, 29.9416s/500 iters), loss = 0.140309
I0830 06:39:29.165019 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.140316 (* 1 = 0.140316 loss)
I0830 06:39:29.165028 916722 sgd_solver.cpp:106] Iteration 1269500, lr = 0.01
I0830 06:39:59.128661 916722 solver.cpp:218] Iteration 1270000 (16.687 iter/s, 29.9635s/500 iters), loss = 0.0871415
I0830 06:39:59.128720 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0871482 (* 1 = 0.0871482 loss)
I0830 06:39:59.128728 916722 sgd_solver.cpp:106] Iteration 1270000, lr = 0.01
I0830 06:40:29.066732 916722 solver.cpp:218] Iteration 1270500 (16.7013 iter/s, 29.9378s/500 iters), loss = 0.104906
I0830 06:40:29.066783 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104912 (* 1 = 0.104912 loss)
I0830 06:40:29.066792 916722 sgd_solver.cpp:106] Iteration 1270500, lr = 0.01
I0830 06:40:59.011950 916722 solver.cpp:218] Iteration 1271000 (16.6973 iter/s, 29.945s/500 iters), loss = 0.259466
I0830 06:40:59.012008 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.259473 (* 1 = 0.259473 loss)
I0830 06:40:59.012017 916722 sgd_solver.cpp:106] Iteration 1271000, lr = 0.01
I0830 06:41:28.953800 916722 solver.cpp:218] Iteration 1271500 (16.6992 iter/s, 29.9416s/500 iters), loss = 0.106506
I0830 06:41:28.953850 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.106513 (* 1 = 0.106513 loss)
I0830 06:41:28.953858 916722 sgd_solver.cpp:106] Iteration 1271500, lr = 0.01
I0830 06:41:58.893787 916722 solver.cpp:218] Iteration 1272000 (16.7002 iter/s, 29.9398s/500 iters), loss = 0.22842
I0830 06:41:58.893860 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.228427 (* 1 = 0.228427 loss)
I0830 06:41:58.893872 916722 sgd_solver.cpp:106] Iteration 1272000, lr = 0.01
I0830 06:42:28.827404 916722 solver.cpp:218] Iteration 1272500 (16.7038 iter/s, 29.9334s/500 iters), loss = 0.224965
I0830 06:42:28.827458 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.224972 (* 1 = 0.224972 loss)
I0830 06:42:28.827467 916722 sgd_solver.cpp:106] Iteration 1272500, lr = 0.01
I0830 06:42:58.771736 916722 solver.cpp:218] Iteration 1273000 (16.6978 iter/s, 29.9441s/500 iters), loss = 0.128795
I0830 06:42:58.771797 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128802 (* 1 = 0.128802 loss)
I0830 06:42:58.771806 916722 sgd_solver.cpp:106] Iteration 1273000, lr = 0.01
I0830 06:43:28.718786 916722 solver.cpp:218] Iteration 1273500 (16.6963 iter/s, 29.9468s/500 iters), loss = 0.290769
I0830 06:43:28.718839 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.290776 (* 1 = 0.290776 loss)
I0830 06:43:28.718849 916722 sgd_solver.cpp:106] Iteration 1273500, lr = 0.01
I0830 06:43:58.678210 916722 solver.cpp:218] Iteration 1274000 (16.6893 iter/s, 29.9592s/500 iters), loss = 0.181474
I0830 06:43:58.678267 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.181481 (* 1 = 0.181481 loss)
I0830 06:43:58.678277 916722 sgd_solver.cpp:106] Iteration 1274000, lr = 0.01
I0830 06:44:28.619213 916722 solver.cpp:218] Iteration 1274500 (16.6996 iter/s, 29.9408s/500 iters), loss = 0.0767905
I0830 06:44:28.619263 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0767972 (* 1 = 0.0767972 loss)
I0830 06:44:28.619273 916722 sgd_solver.cpp:106] Iteration 1274500, lr = 0.01
I0830 06:44:58.555331 916722 solver.cpp:218] Iteration 1275000 (16.7023 iter/s, 29.9359s/500 iters), loss = 0.20596
I0830 06:44:58.555390 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.205967 (* 1 = 0.205967 loss)
I0830 06:44:58.555399 916722 sgd_solver.cpp:106] Iteration 1275000, lr = 0.01
I0830 06:45:28.502612 916722 solver.cpp:218] Iteration 1275500 (16.6961 iter/s, 29.9471s/500 iters), loss = 0.113654
I0830 06:45:28.502663 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.113661 (* 1 = 0.113661 loss)
I0830 06:45:28.502673 916722 sgd_solver.cpp:106] Iteration 1275500, lr = 0.01
I0830 06:45:58.452661 916722 solver.cpp:218] Iteration 1276000 (16.6946 iter/s, 29.9499s/500 iters), loss = 0.154503
I0830 06:45:58.452715 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.154511 (* 1 = 0.154511 loss)
I0830 06:45:58.452723 916722 sgd_solver.cpp:106] Iteration 1276000, lr = 0.01
I0830 06:46:28.410504 916722 solver.cpp:218] Iteration 1276500 (16.6902 iter/s, 29.9577s/500 iters), loss = 0.0459595
I0830 06:46:28.410557 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0459668 (* 1 = 0.0459668 loss)
I0830 06:46:28.410567 916722 sgd_solver.cpp:106] Iteration 1276500, lr = 0.01
I0830 06:46:58.350473 916722 solver.cpp:218] Iteration 1277000 (16.7002 iter/s, 29.9398s/500 iters), loss = 0.327672
I0830 06:46:58.350533 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.327679 (* 1 = 0.327679 loss)
I0830 06:46:58.350541 916722 sgd_solver.cpp:106] Iteration 1277000, lr = 0.01
I0830 06:47:28.291674 916722 solver.cpp:218] Iteration 1277500 (16.6995 iter/s, 29.941s/500 iters), loss = 0.192272
I0830 06:47:28.291728 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.192279 (* 1 = 0.192279 loss)
I0830 06:47:28.291738 916722 sgd_solver.cpp:106] Iteration 1277500, lr = 0.01
I0830 06:47:58.260854 916722 solver.cpp:218] Iteration 1278000 (16.6839 iter/s, 29.969s/500 iters), loss = 0.115916
I0830 06:47:58.260911 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115923 (* 1 = 0.115923 loss)
I0830 06:47:58.260921 916722 sgd_solver.cpp:106] Iteration 1278000, lr = 0.01
I0830 06:48:28.178122 916722 solver.cpp:218] Iteration 1278500 (16.7129 iter/s, 29.9171s/500 iters), loss = 0.17733
I0830 06:48:28.178174 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.177337 (* 1 = 0.177337 loss)
I0830 06:48:28.178195 916722 sgd_solver.cpp:106] Iteration 1278500, lr = 0.01
I0830 06:48:58.121721 916722 solver.cpp:218] Iteration 1279000 (16.6982 iter/s, 29.9434s/500 iters), loss = 0.171064
I0830 06:48:58.121793 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.171072 (* 1 = 0.171072 loss)
I0830 06:48:58.121801 916722 sgd_solver.cpp:106] Iteration 1279000, lr = 0.01
I0830 06:49:28.060788 916722 solver.cpp:218] Iteration 1279500 (16.7007 iter/s, 29.9389s/500 iters), loss = 0.0205246
I0830 06:49:28.060840 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0205321 (* 1 = 0.0205321 loss)
I0830 06:49:28.060849 916722 sgd_solver.cpp:106] Iteration 1279500, lr = 0.01
I0830 06:49:57.993497 916722 solver.cpp:218] Iteration 1280000 (16.7042 iter/s, 29.9325s/500 iters), loss = 0.0954598
I0830 06:49:57.993553 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0954672 (* 1 = 0.0954672 loss)
I0830 06:49:57.993562 916722 sgd_solver.cpp:106] Iteration 1280000, lr = 0.01
I0830 06:50:27.905043 916722 solver.cpp:218] Iteration 1280500 (16.716 iter/s, 29.9114s/500 iters), loss = 0.201701
I0830 06:50:27.905089 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.201709 (* 1 = 0.201709 loss)
I0830 06:50:27.905098 916722 sgd_solver.cpp:106] Iteration 1280500, lr = 0.01
I0830 06:50:57.845086 916722 solver.cpp:218] Iteration 1281000 (16.7001 iter/s, 29.9399s/500 iters), loss = 0.17568
I0830 06:50:57.845147 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.175687 (* 1 = 0.175687 loss)
I0830 06:50:57.845156 916722 sgd_solver.cpp:106] Iteration 1281000, lr = 0.01
I0830 06:51:27.788674 916722 solver.cpp:218] Iteration 1281500 (16.6982 iter/s, 29.9434s/500 iters), loss = 0.0530884
I0830 06:51:27.788730 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0530955 (* 1 = 0.0530955 loss)
I0830 06:51:27.788740 916722 sgd_solver.cpp:106] Iteration 1281500, lr = 0.01
I0830 06:51:57.726826 916722 solver.cpp:218] Iteration 1282000 (16.7012 iter/s, 29.938s/500 iters), loss = 0.565422
I0830 06:51:57.726887 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.565429 (* 1 = 0.565429 loss)
I0830 06:51:57.726895 916722 sgd_solver.cpp:106] Iteration 1282000, lr = 0.01
I0830 06:52:27.636059 916722 solver.cpp:218] Iteration 1282500 (16.7173 iter/s, 29.9091s/500 iters), loss = 0.16795
I0830 06:52:27.636111 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.167957 (* 1 = 0.167957 loss)
I0830 06:52:27.636119 916722 sgd_solver.cpp:106] Iteration 1282500, lr = 0.01
I0830 06:52:57.553966 916722 solver.cpp:218] Iteration 1283000 (16.7125 iter/s, 29.9177s/500 iters), loss = 0.0233754
I0830 06:52:57.554025 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0233825 (* 1 = 0.0233825 loss)
I0830 06:52:57.554034 916722 sgd_solver.cpp:106] Iteration 1283000, lr = 0.01
I0830 06:53:27.487211 916722 solver.cpp:218] Iteration 1283500 (16.7039 iter/s, 29.9331s/500 iters), loss = 0.147359
I0830 06:53:27.487262 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.147366 (* 1 = 0.147366 loss)
I0830 06:53:27.487272 916722 sgd_solver.cpp:106] Iteration 1283500, lr = 0.01
I0830 06:53:57.398695 916722 solver.cpp:218] Iteration 1284000 (16.7161 iter/s, 29.9113s/500 iters), loss = 0.125973
I0830 06:53:57.398753 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.12598 (* 1 = 0.12598 loss)
I0830 06:53:57.398762 916722 sgd_solver.cpp:106] Iteration 1284000, lr = 0.01
I0830 06:54:27.305616 916722 solver.cpp:218] Iteration 1284500 (16.7186 iter/s, 29.9067s/500 iters), loss = 0.0489089
I0830 06:54:27.305670 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0489158 (* 1 = 0.0489158 loss)
I0830 06:54:27.305680 916722 sgd_solver.cpp:106] Iteration 1284500, lr = 0.01
I0830 06:54:57.214516 916722 solver.cpp:218] Iteration 1285000 (16.7175 iter/s, 29.9087s/500 iters), loss = 0.317878
I0830 06:54:57.214570 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.317885 (* 1 = 0.317885 loss)
I0830 06:54:57.214578 916722 sgd_solver.cpp:106] Iteration 1285000, lr = 0.01
I0830 06:55:27.114948 916722 solver.cpp:218] Iteration 1285500 (16.7223 iter/s, 29.9003s/500 iters), loss = 0.228041
I0830 06:55:27.115001 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.228048 (* 1 = 0.228048 loss)
I0830 06:55:27.115010 916722 sgd_solver.cpp:106] Iteration 1285500, lr = 0.01
I0830 06:55:57.023818 916722 solver.cpp:218] Iteration 1286000 (16.7175 iter/s, 29.9087s/500 iters), loss = 0.0961954
I0830 06:55:57.023890 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0962023 (* 1 = 0.0962023 loss)
I0830 06:55:57.023900 916722 sgd_solver.cpp:106] Iteration 1286000, lr = 0.01
I0830 06:56:26.947288 916722 solver.cpp:218] Iteration 1286500 (16.7094 iter/s, 29.9233s/500 iters), loss = 0.0541775
I0830 06:56:26.947340 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0541846 (* 1 = 0.0541846 loss)
I0830 06:56:26.947350 916722 sgd_solver.cpp:106] Iteration 1286500, lr = 0.01
I0830 06:56:56.861059 916722 solver.cpp:218] Iteration 1287000 (16.7148 iter/s, 29.9136s/500 iters), loss = 0.0734039
I0830 06:56:56.861119 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.073411 (* 1 = 0.073411 loss)
I0830 06:56:56.861128 916722 sgd_solver.cpp:106] Iteration 1287000, lr = 0.01
I0830 06:57:26.799898 916722 solver.cpp:218] Iteration 1287500 (16.7008 iter/s, 29.9387s/500 iters), loss = 0.1787
I0830 06:57:26.799952 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.178707 (* 1 = 0.178707 loss)
I0830 06:57:26.799960 916722 sgd_solver.cpp:106] Iteration 1287500, lr = 0.01
I0830 06:57:56.739676 916722 solver.cpp:218] Iteration 1288000 (16.7003 iter/s, 29.9396s/500 iters), loss = 0.122622
I0830 06:57:56.739734 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.122629 (* 1 = 0.122629 loss)
I0830 06:57:56.739742 916722 sgd_solver.cpp:106] Iteration 1288000, lr = 0.01
I0830 06:58:26.725457 916722 solver.cpp:218] Iteration 1288500 (16.6747 iter/s, 29.9856s/500 iters), loss = 0.0664013
I0830 06:58:26.725508 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0664085 (* 1 = 0.0664085 loss)
I0830 06:58:26.725517 916722 sgd_solver.cpp:106] Iteration 1288500, lr = 0.01
I0830 06:58:56.656807 916722 solver.cpp:218] Iteration 1289000 (16.705 iter/s, 29.9312s/500 iters), loss = 0.173047
I0830 06:58:56.656863 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.173054 (* 1 = 0.173054 loss)
I0830 06:58:56.656872 916722 sgd_solver.cpp:106] Iteration 1289000, lr = 0.01
I0830 06:59:26.593129 916722 solver.cpp:218] Iteration 1289500 (16.7022 iter/s, 29.9362s/500 iters), loss = 0.223096
I0830 06:59:26.593186 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.223103 (* 1 = 0.223103 loss)
I0830 06:59:26.593196 916722 sgd_solver.cpp:106] Iteration 1289500, lr = 0.01
I0830 06:59:56.501268 916722 solver.cpp:218] Iteration 1290000 (16.7179 iter/s, 29.908s/500 iters), loss = 0.308985
I0830 06:59:56.501327 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.308992 (* 1 = 0.308992 loss)
I0830 06:59:56.501335 916722 sgd_solver.cpp:106] Iteration 1290000, lr = 0.01
I0830 07:00:26.430837 916722 solver.cpp:218] Iteration 1290500 (16.706 iter/s, 29.9294s/500 iters), loss = 0.0673525
I0830 07:00:26.430891 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0673596 (* 1 = 0.0673596 loss)
I0830 07:00:26.430902 916722 sgd_solver.cpp:106] Iteration 1290500, lr = 0.01
I0830 07:00:56.348649 916722 solver.cpp:218] Iteration 1291000 (16.7125 iter/s, 29.9178s/500 iters), loss = 0.102676
I0830 07:00:56.348707 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.102682 (* 1 = 0.102682 loss)
I0830 07:00:56.348717 916722 sgd_solver.cpp:106] Iteration 1291000, lr = 0.01
I0830 07:01:26.276854 916722 solver.cpp:218] Iteration 1291500 (16.7066 iter/s, 29.9282s/500 iters), loss = 0.170067
I0830 07:01:26.276904 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.170074 (* 1 = 0.170074 loss)
I0830 07:01:26.276914 916722 sgd_solver.cpp:106] Iteration 1291500, lr = 0.01
I0830 07:01:56.195768 916722 solver.cpp:218] Iteration 1292000 (16.7118 iter/s, 29.919s/500 iters), loss = 0.340277
I0830 07:01:56.195835 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.340284 (* 1 = 0.340284 loss)
I0830 07:01:56.195844 916722 sgd_solver.cpp:106] Iteration 1292000, lr = 0.01
I0830 07:02:26.144920 916722 solver.cpp:218] Iteration 1292500 (16.695 iter/s, 29.9492s/500 iters), loss = 0.064503
I0830 07:02:26.144976 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0645098 (* 1 = 0.0645098 loss)
I0830 07:02:26.144986 916722 sgd_solver.cpp:106] Iteration 1292500, lr = 0.01
I0830 07:02:56.095504 916722 solver.cpp:218] Iteration 1293000 (16.6942 iter/s, 29.9506s/500 iters), loss = 0.213383
I0830 07:02:56.095563 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.21339 (* 1 = 0.21339 loss)
I0830 07:02:56.095571 916722 sgd_solver.cpp:106] Iteration 1293000, lr = 0.01
I0830 07:03:26.068148 916722 solver.cpp:218] Iteration 1293500 (16.6819 iter/s, 29.9727s/500 iters), loss = 0.0639921
I0830 07:03:26.068203 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0639989 (* 1 = 0.0639989 loss)
I0830 07:03:26.068214 916722 sgd_solver.cpp:106] Iteration 1293500, lr = 0.01
I0830 07:03:56.046469 916722 solver.cpp:218] Iteration 1294000 (16.6787 iter/s, 29.9783s/500 iters), loss = 0.389713
I0830 07:03:56.046528 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.389719 (* 1 = 0.389719 loss)
I0830 07:03:56.046537 916722 sgd_solver.cpp:106] Iteration 1294000, lr = 0.01
I0830 07:04:26.037068 916722 solver.cpp:218] Iteration 1294500 (16.6719 iter/s, 29.9906s/500 iters), loss = 0.138865
I0830 07:04:26.037122 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.138872 (* 1 = 0.138872 loss)
I0830 07:04:26.037132 916722 sgd_solver.cpp:106] Iteration 1294500, lr = 0.01
I0830 07:04:56.013650 916722 solver.cpp:218] Iteration 1295000 (16.6797 iter/s, 29.9766s/500 iters), loss = 0.236911
I0830 07:04:56.013710 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.236918 (* 1 = 0.236918 loss)
I0830 07:04:56.013720 916722 sgd_solver.cpp:106] Iteration 1295000, lr = 0.01
I0830 07:05:25.997763 916722 solver.cpp:218] Iteration 1295500 (16.6755 iter/s, 29.9841s/500 iters), loss = 0.313196
I0830 07:05:25.997814 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.313203 (* 1 = 0.313203 loss)
I0830 07:05:25.997823 916722 sgd_solver.cpp:106] Iteration 1295500, lr = 0.01
I0830 07:05:55.983307 916722 solver.cpp:218] Iteration 1296000 (16.6747 iter/s, 29.9855s/500 iters), loss = 0.133659
I0830 07:05:55.983363 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133666 (* 1 = 0.133666 loss)
I0830 07:05:55.983372 916722 sgd_solver.cpp:106] Iteration 1296000, lr = 0.01
I0830 07:06:25.936901 916722 solver.cpp:218] Iteration 1296500 (16.6925 iter/s, 29.9536s/500 iters), loss = 0.135669
I0830 07:06:25.936954 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.135676 (* 1 = 0.135676 loss)
I0830 07:06:25.936962 916722 sgd_solver.cpp:106] Iteration 1296500, lr = 0.01
I0830 07:06:55.929455 916722 solver.cpp:218] Iteration 1297000 (16.6708 iter/s, 29.9925s/500 iters), loss = 0.152482
I0830 07:06:55.929514 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152489 (* 1 = 0.152489 loss)
I0830 07:06:55.929522 916722 sgd_solver.cpp:106] Iteration 1297000, lr = 0.01
I0830 07:07:25.881979 916722 solver.cpp:218] Iteration 1297500 (16.6931 iter/s, 29.9525s/500 iters), loss = 0.28159
I0830 07:07:25.882035 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.281597 (* 1 = 0.281597 loss)
I0830 07:07:25.882043 916722 sgd_solver.cpp:106] Iteration 1297500, lr = 0.01
I0830 07:07:55.850980 916722 solver.cpp:218] Iteration 1298000 (16.6839 iter/s, 29.969s/500 iters), loss = 0.245817
I0830 07:07:55.851040 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.245824 (* 1 = 0.245824 loss)
I0830 07:07:55.851049 916722 sgd_solver.cpp:106] Iteration 1298000, lr = 0.01
I0830 07:08:25.817775 916722 solver.cpp:218] Iteration 1298500 (16.6852 iter/s, 29.9667s/500 iters), loss = 0.0520405
I0830 07:08:25.817839 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0520474 (* 1 = 0.0520474 loss)
I0830 07:08:25.817848 916722 sgd_solver.cpp:106] Iteration 1298500, lr = 0.01
I0830 07:08:55.775900 916722 solver.cpp:218] Iteration 1299000 (16.69 iter/s, 29.9581s/500 iters), loss = 0.246718
I0830 07:08:55.775969 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.246724 (* 1 = 0.246724 loss)
I0830 07:08:55.775977 916722 sgd_solver.cpp:106] Iteration 1299000, lr = 0.01
I0830 07:09:25.759044 916722 solver.cpp:218] Iteration 1299500 (16.6761 iter/s, 29.9831s/500 iters), loss = 0.469451
I0830 07:09:25.759095 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.469457 (* 1 = 0.469457 loss)
I0830 07:09:25.759104 916722 sgd_solver.cpp:106] Iteration 1299500, lr = 0.01
I0830 07:09:55.660758 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_1300000.caffemodel
I0830 07:09:55.680439 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_1300000.solverstate
I0830 07:09:55.686648 916722 solver.cpp:330] Iteration 1300000, Testing net (#0)
I0830 07:10:11.123581 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8889
I0830 07:10:11.123629 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.365379 (* 1 = 0.365379 loss)
I0830 07:10:11.182415 916722 solver.cpp:218] Iteration 1300000 (11.0076 iter/s, 45.4233s/500 iters), loss = 0.159007
I0830 07:10:11.182446 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159014 (* 1 = 0.159014 loss)
I0830 07:10:11.182454 916722 sgd_solver.cpp:106] Iteration 1300000, lr = 0.01
I0830 07:10:41.007494 916722 solver.cpp:218] Iteration 1300500 (16.7645 iter/s, 29.825s/500 iters), loss = 0.0274884
I0830 07:10:41.007555 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.027495 (* 1 = 0.027495 loss)
I0830 07:10:41.007563 916722 sgd_solver.cpp:106] Iteration 1300500, lr = 0.01
I0830 07:11:10.949240 916722 solver.cpp:218] Iteration 1301000 (16.6991 iter/s, 29.9417s/500 iters), loss = 0.0211568
I0830 07:11:10.949292 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0211632 (* 1 = 0.0211632 loss)
I0830 07:11:10.949301 916722 sgd_solver.cpp:106] Iteration 1301000, lr = 0.01
I0830 07:11:40.915732 916722 solver.cpp:218] Iteration 1301500 (16.6853 iter/s, 29.9664s/500 iters), loss = 0.107073
I0830 07:11:40.915792 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.107079 (* 1 = 0.107079 loss)
I0830 07:11:40.915802 916722 sgd_solver.cpp:106] Iteration 1301500, lr = 0.01
I0830 07:12:10.888527 916722 solver.cpp:218] Iteration 1302000 (16.6818 iter/s, 29.9727s/500 iters), loss = 0.195788
I0830 07:12:10.888578 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.195794 (* 1 = 0.195794 loss)
I0830 07:12:10.888587 916722 sgd_solver.cpp:106] Iteration 1302000, lr = 0.01
I0830 07:12:40.878346 916722 solver.cpp:218] Iteration 1302500 (16.6724 iter/s, 29.9897s/500 iters), loss = 0.24603
I0830 07:12:40.878405 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.246036 (* 1 = 0.246036 loss)
I0830 07:12:40.878413 916722 sgd_solver.cpp:106] Iteration 1302500, lr = 0.01
I0830 07:13:10.843994 916722 solver.cpp:218] Iteration 1303000 (16.6858 iter/s, 29.9656s/500 iters), loss = 0.0803696
I0830 07:13:10.844049 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0803759 (* 1 = 0.0803759 loss)
I0830 07:13:10.844059 916722 sgd_solver.cpp:106] Iteration 1303000, lr = 0.01
I0830 07:13:40.820813 916722 solver.cpp:218] Iteration 1303500 (16.6796 iter/s, 29.9767s/500 iters), loss = 0.221485
I0830 07:13:40.820871 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.221491 (* 1 = 0.221491 loss)
I0830 07:13:40.820879 916722 sgd_solver.cpp:106] Iteration 1303500, lr = 0.01
I0830 07:14:10.794989 916722 solver.cpp:218] Iteration 1304000 (16.6811 iter/s, 29.9741s/500 iters), loss = 0.134949
I0830 07:14:10.795042 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.134955 (* 1 = 0.134955 loss)
I0830 07:14:10.795063 916722 sgd_solver.cpp:106] Iteration 1304000, lr = 0.01
I0830 07:14:40.775653 916722 solver.cpp:218] Iteration 1304500 (16.6775 iter/s, 29.9806s/500 iters), loss = 0.214779
I0830 07:14:40.775722 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.214785 (* 1 = 0.214785 loss)
I0830 07:14:40.775732 916722 sgd_solver.cpp:106] Iteration 1304500, lr = 0.01
I0830 07:15:10.759431 916722 solver.cpp:218] Iteration 1305000 (16.6757 iter/s, 29.9837s/500 iters), loss = 0.173585
I0830 07:15:10.759482 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.173591 (* 1 = 0.173591 loss)
I0830 07:15:10.759492 916722 sgd_solver.cpp:106] Iteration 1305000, lr = 0.01
I0830 07:15:40.735164 916722 solver.cpp:218] Iteration 1305500 (16.6802 iter/s, 29.9756s/500 iters), loss = 0.105858
I0830 07:15:40.735224 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105864 (* 1 = 0.105864 loss)
I0830 07:15:40.735231 916722 sgd_solver.cpp:106] Iteration 1305500, lr = 0.01
I0830 07:16:10.715505 916722 solver.cpp:218] Iteration 1306000 (16.6776 iter/s, 29.9803s/500 iters), loss = 0.0307595
I0830 07:16:10.715556 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0307654 (* 1 = 0.0307654 loss)
I0830 07:16:10.715567 916722 sgd_solver.cpp:106] Iteration 1306000, lr = 0.01
I0830 07:16:40.689674 916722 solver.cpp:218] Iteration 1306500 (16.6811 iter/s, 29.9741s/500 iters), loss = 0.277612
I0830 07:16:40.689734 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.277618 (* 1 = 0.277618 loss)
I0830 07:16:40.689743 916722 sgd_solver.cpp:106] Iteration 1306500, lr = 0.01
I0830 07:17:10.678515 916722 solver.cpp:218] Iteration 1307000 (16.6729 iter/s, 29.9888s/500 iters), loss = 0.252645
I0830 07:17:10.678560 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.252651 (* 1 = 0.252651 loss)
I0830 07:17:10.678568 916722 sgd_solver.cpp:106] Iteration 1307000, lr = 0.01
I0830 07:17:40.660356 916722 solver.cpp:218] Iteration 1307500 (16.6768 iter/s, 29.9818s/500 iters), loss = 0.392207
I0830 07:17:40.660406 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.392213 (* 1 = 0.392213 loss)
I0830 07:17:40.660414 916722 sgd_solver.cpp:106] Iteration 1307500, lr = 0.01
I0830 07:18:10.659752 916722 solver.cpp:218] Iteration 1308000 (16.667 iter/s, 29.9993s/500 iters), loss = 0.597502
I0830 07:18:10.659804 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.597507 (* 1 = 0.597507 loss)
I0830 07:18:10.659814 916722 sgd_solver.cpp:106] Iteration 1308000, lr = 0.01
I0830 07:18:40.672668 916722 solver.cpp:218] Iteration 1308500 (16.6595 iter/s, 30.0128s/500 iters), loss = 0.043203
I0830 07:18:40.672732 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0432087 (* 1 = 0.0432087 loss)
I0830 07:18:40.672741 916722 sgd_solver.cpp:106] Iteration 1308500, lr = 0.01
I0830 07:19:10.676915 916722 solver.cpp:218] Iteration 1309000 (16.6644 iter/s, 30.0041s/500 iters), loss = 0.186468
I0830 07:19:10.676971 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.186474 (* 1 = 0.186474 loss)
I0830 07:19:10.676980 916722 sgd_solver.cpp:106] Iteration 1309000, lr = 0.01
I0830 07:19:40.665627 916722 solver.cpp:218] Iteration 1309500 (16.673 iter/s, 29.9886s/500 iters), loss = 0.224621
I0830 07:19:40.665679 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.224627 (* 1 = 0.224627 loss)
I0830 07:19:40.665688 916722 sgd_solver.cpp:106] Iteration 1309500, lr = 0.01
I0830 07:20:10.668969 916722 solver.cpp:218] Iteration 1310000 (16.6649 iter/s, 30.0032s/500 iters), loss = 0.239687
I0830 07:20:10.669026 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.239692 (* 1 = 0.239692 loss)
I0830 07:20:10.669034 916722 sgd_solver.cpp:106] Iteration 1310000, lr = 0.01
I0830 07:20:40.657019 916722 solver.cpp:218] Iteration 1310500 (16.6734 iter/s, 29.988s/500 iters), loss = 0.0784716
I0830 07:20:40.657070 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0784772 (* 1 = 0.0784772 loss)
I0830 07:20:40.657092 916722 sgd_solver.cpp:106] Iteration 1310500, lr = 0.01
I0830 07:21:10.635695 916722 solver.cpp:218] Iteration 1311000 (16.6786 iter/s, 29.9786s/500 iters), loss = 0.107734
I0830 07:21:10.635763 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.10774 (* 1 = 0.10774 loss)
I0830 07:21:10.635772 916722 sgd_solver.cpp:106] Iteration 1311000, lr = 0.01
I0830 07:21:40.634694 916722 solver.cpp:218] Iteration 1311500 (16.6673 iter/s, 29.9989s/500 iters), loss = 0.219042
I0830 07:21:40.634744 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.219047 (* 1 = 0.219047 loss)
I0830 07:21:40.634754 916722 sgd_solver.cpp:106] Iteration 1311500, lr = 0.01
I0830 07:22:10.616957 916722 solver.cpp:218] Iteration 1312000 (16.6766 iter/s, 29.9822s/500 iters), loss = 0.101456
I0830 07:22:10.617010 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101461 (* 1 = 0.101461 loss)
I0830 07:22:10.617019 916722 sgd_solver.cpp:106] Iteration 1312000, lr = 0.01
I0830 07:22:40.621403 916722 solver.cpp:218] Iteration 1312500 (16.6643 iter/s, 30.0043s/500 iters), loss = 0.114352
I0830 07:22:40.621462 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.114357 (* 1 = 0.114357 loss)
I0830 07:22:40.621470 916722 sgd_solver.cpp:106] Iteration 1312500, lr = 0.01
I0830 07:23:10.593014 916722 solver.cpp:218] Iteration 1313000 (16.6825 iter/s, 29.9715s/500 iters), loss = 0.491049
I0830 07:23:10.593066 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.491054 (* 1 = 0.491054 loss)
I0830 07:23:10.593076 916722 sgd_solver.cpp:106] Iteration 1313000, lr = 0.01
I0830 07:23:40.573563 916722 solver.cpp:218] Iteration 1313500 (16.6775 iter/s, 29.9804s/500 iters), loss = 0.156268
I0830 07:23:40.573624 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.156273 (* 1 = 0.156273 loss)
I0830 07:23:40.573633 916722 sgd_solver.cpp:106] Iteration 1313500, lr = 0.01
I0830 07:24:10.598814 916722 solver.cpp:218] Iteration 1314000 (16.6527 iter/s, 30.0251s/500 iters), loss = 0.0351524
I0830 07:24:10.598872 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0351576 (* 1 = 0.0351576 loss)
I0830 07:24:10.598881 916722 sgd_solver.cpp:106] Iteration 1314000, lr = 0.01
I0830 07:24:40.577186 916722 solver.cpp:218] Iteration 1314500 (16.6788 iter/s, 29.9783s/500 iters), loss = 0.155857
I0830 07:24:40.577237 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.155862 (* 1 = 0.155862 loss)
I0830 07:24:40.577248 916722 sgd_solver.cpp:106] Iteration 1314500, lr = 0.01
I0830 07:25:10.561296 916722 solver.cpp:218] Iteration 1315000 (16.6756 iter/s, 29.984s/500 iters), loss = 0.094909
I0830 07:25:10.561357 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0949143 (* 1 = 0.0949143 loss)
I0830 07:25:10.561365 916722 sgd_solver.cpp:106] Iteration 1315000, lr = 0.01
I0830 07:25:40.570569 916722 solver.cpp:218] Iteration 1315500 (16.6616 iter/s, 30.0092s/500 iters), loss = 0.236559
I0830 07:25:40.570624 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.236564 (* 1 = 0.236564 loss)
I0830 07:25:40.570633 916722 sgd_solver.cpp:106] Iteration 1315500, lr = 0.01
I0830 07:26:10.571012 916722 solver.cpp:218] Iteration 1316000 (16.6665 iter/s, 30.0003s/500 iters), loss = 0.0910019
I0830 07:26:10.571069 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0910071 (* 1 = 0.0910071 loss)
I0830 07:26:10.571076 916722 sgd_solver.cpp:106] Iteration 1316000, lr = 0.01
I0830 07:26:40.547435 916722 solver.cpp:218] Iteration 1316500 (16.6798 iter/s, 29.9763s/500 iters), loss = 0.0340441
I0830 07:26:40.547482 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0340494 (* 1 = 0.0340494 loss)
I0830 07:26:40.547492 916722 sgd_solver.cpp:106] Iteration 1316500, lr = 0.01
I0830 07:27:10.551124 916722 solver.cpp:218] Iteration 1317000 (16.6647 iter/s, 30.0036s/500 iters), loss = 0.330287
I0830 07:27:10.551192 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.330293 (* 1 = 0.330293 loss)
I0830 07:27:10.551211 916722 sgd_solver.cpp:106] Iteration 1317000, lr = 0.01
I0830 07:27:40.529225 916722 solver.cpp:218] Iteration 1317500 (16.6789 iter/s, 29.978s/500 iters), loss = 0.111674
I0830 07:27:40.529280 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111679 (* 1 = 0.111679 loss)
I0830 07:27:40.529289 916722 sgd_solver.cpp:106] Iteration 1317500, lr = 0.01
I0830 07:28:10.525771 916722 solver.cpp:218] Iteration 1318000 (16.6686 iter/s, 29.9964s/500 iters), loss = 0.0673235
I0830 07:28:10.525828 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0673289 (* 1 = 0.0673289 loss)
I0830 07:28:10.525836 916722 sgd_solver.cpp:106] Iteration 1318000, lr = 0.01
I0830 07:28:40.519188 916722 solver.cpp:218] Iteration 1318500 (16.6704 iter/s, 29.9933s/500 iters), loss = 0.0542001
I0830 07:28:40.519237 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0542053 (* 1 = 0.0542053 loss)
I0830 07:28:40.519248 916722 sgd_solver.cpp:106] Iteration 1318500, lr = 0.01
I0830 07:29:10.531885 916722 solver.cpp:218] Iteration 1319000 (16.6597 iter/s, 30.0126s/500 iters), loss = 0.0743622
I0830 07:29:10.531944 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0743675 (* 1 = 0.0743675 loss)
I0830 07:29:10.531951 916722 sgd_solver.cpp:106] Iteration 1319000, lr = 0.01
I0830 07:29:40.534974 916722 solver.cpp:218] Iteration 1319500 (16.665 iter/s, 30.003s/500 iters), loss = 0.0622396
I0830 07:29:40.535030 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.062245 (* 1 = 0.062245 loss)
I0830 07:29:40.535038 916722 sgd_solver.cpp:106] Iteration 1319500, lr = 0.01
I0830 07:30:10.540419 916722 solver.cpp:218] Iteration 1320000 (16.6637 iter/s, 30.0053s/500 iters), loss = 0.16031
I0830 07:30:10.540493 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.160316 (* 1 = 0.160316 loss)
I0830 07:30:10.540503 916722 sgd_solver.cpp:106] Iteration 1320000, lr = 0.01
I0830 07:30:40.563622 916722 solver.cpp:218] Iteration 1320500 (16.6539 iter/s, 30.0231s/500 iters), loss = 0.0755158
I0830 07:30:40.563676 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0755215 (* 1 = 0.0755215 loss)
I0830 07:30:40.563684 916722 sgd_solver.cpp:106] Iteration 1320500, lr = 0.01
I0830 07:31:10.556882 916722 solver.cpp:218] Iteration 1321000 (16.6705 iter/s, 29.9931s/500 iters), loss = 0.0652948
I0830 07:31:10.556931 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0653006 (* 1 = 0.0653006 loss)
I0830 07:31:10.556941 916722 sgd_solver.cpp:106] Iteration 1321000, lr = 0.01
I0830 07:31:40.562248 916722 solver.cpp:218] Iteration 1321500 (16.6637 iter/s, 30.0053s/500 iters), loss = 0.0541526
I0830 07:31:40.562309 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0541584 (* 1 = 0.0541584 loss)
I0830 07:31:40.562317 916722 sgd_solver.cpp:106] Iteration 1321500, lr = 0.01
I0830 07:32:10.555466 916722 solver.cpp:218] Iteration 1322000 (16.6705 iter/s, 29.9931s/500 iters), loss = 0.123981
I0830 07:32:10.555521 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.123987 (* 1 = 0.123987 loss)
I0830 07:32:10.555531 916722 sgd_solver.cpp:106] Iteration 1322000, lr = 0.01
I0830 07:32:40.558503 916722 solver.cpp:218] Iteration 1322500 (16.665 iter/s, 30.0029s/500 iters), loss = 0.0254647
I0830 07:32:40.558559 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0254705 (* 1 = 0.0254705 loss)
I0830 07:32:40.558568 916722 sgd_solver.cpp:106] Iteration 1322500, lr = 0.01
I0830 07:33:10.554945 916722 solver.cpp:218] Iteration 1323000 (16.6687 iter/s, 29.9963s/500 iters), loss = 0.0709365
I0830 07:33:10.554996 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0709424 (* 1 = 0.0709424 loss)
I0830 07:33:10.555006 916722 sgd_solver.cpp:106] Iteration 1323000, lr = 0.01
I0830 07:33:40.582106 916722 solver.cpp:218] Iteration 1323500 (16.6517 iter/s, 30.027s/500 iters), loss = 0.0905344
I0830 07:33:40.582161 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0905402 (* 1 = 0.0905402 loss)
I0830 07:33:40.582170 916722 sgd_solver.cpp:106] Iteration 1323500, lr = 0.01
I0830 07:34:10.567883 916722 solver.cpp:218] Iteration 1324000 (16.6746 iter/s, 29.9857s/500 iters), loss = 0.0916946
I0830 07:34:10.567934 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0917005 (* 1 = 0.0917005 loss)
I0830 07:34:10.567943 916722 sgd_solver.cpp:106] Iteration 1324000, lr = 0.01
I0830 07:34:40.557788 916722 solver.cpp:218] Iteration 1324500 (16.6723 iter/s, 29.9898s/500 iters), loss = 0.0653623
I0830 07:34:40.557854 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0653683 (* 1 = 0.0653683 loss)
I0830 07:34:40.557863 916722 sgd_solver.cpp:106] Iteration 1324500, lr = 0.01
I0830 07:35:10.530648 916722 solver.cpp:218] Iteration 1325000 (16.6816 iter/s, 29.9731s/500 iters), loss = 0.215423
I0830 07:35:10.530695 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.215429 (* 1 = 0.215429 loss)
I0830 07:35:10.530705 916722 sgd_solver.cpp:106] Iteration 1325000, lr = 0.01
I0830 07:35:40.521123 916722 solver.cpp:218] Iteration 1325500 (16.6718 iter/s, 29.9908s/500 iters), loss = 0.0725191
I0830 07:35:40.521178 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0725249 (* 1 = 0.0725249 loss)
I0830 07:35:40.521188 916722 sgd_solver.cpp:106] Iteration 1325500, lr = 0.01
I0830 07:36:10.478971 916722 solver.cpp:218] Iteration 1326000 (16.69 iter/s, 29.9581s/500 iters), loss = 0.313734
I0830 07:36:10.479022 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.31374 (* 1 = 0.31374 loss)
I0830 07:36:10.479032 916722 sgd_solver.cpp:106] Iteration 1326000, lr = 0.01
I0830 07:36:40.431767 916722 solver.cpp:218] Iteration 1326500 (16.6928 iter/s, 29.9531s/500 iters), loss = 0.178989
I0830 07:36:40.431828 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.178995 (* 1 = 0.178995 loss)
I0830 07:36:40.431836 916722 sgd_solver.cpp:106] Iteration 1326500, lr = 0.01
I0830 07:37:10.382210 916722 solver.cpp:218] Iteration 1327000 (16.6941 iter/s, 29.9507s/500 iters), loss = 0.225601
I0830 07:37:10.382259 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.225607 (* 1 = 0.225607 loss)
I0830 07:37:10.382268 916722 sgd_solver.cpp:106] Iteration 1327000, lr = 0.01
I0830 07:37:40.332352 916722 solver.cpp:218] Iteration 1327500 (16.6943 iter/s, 29.9504s/500 iters), loss = 0.075443
I0830 07:37:40.332414 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0754489 (* 1 = 0.0754489 loss)
I0830 07:37:40.332422 916722 sgd_solver.cpp:106] Iteration 1327500, lr = 0.01
I0830 07:38:10.285393 916722 solver.cpp:218] Iteration 1328000 (16.6927 iter/s, 29.9532s/500 iters), loss = 0.147948
I0830 07:38:10.285444 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.147954 (* 1 = 0.147954 loss)
I0830 07:38:10.285452 916722 sgd_solver.cpp:106] Iteration 1328000, lr = 0.01
I0830 07:38:40.246273 916722 solver.cpp:218] Iteration 1328500 (16.6883 iter/s, 29.9611s/500 iters), loss = 0.278084
I0830 07:38:40.246330 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.27809 (* 1 = 0.27809 loss)
I0830 07:38:40.246340 916722 sgd_solver.cpp:106] Iteration 1328500, lr = 0.01
I0830 07:39:10.196362 916722 solver.cpp:218] Iteration 1329000 (16.6943 iter/s, 29.9503s/500 iters), loss = 0.129784
I0830 07:39:10.196411 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.12979 (* 1 = 0.12979 loss)
I0830 07:39:10.196419 916722 sgd_solver.cpp:106] Iteration 1329000, lr = 0.01
I0830 07:39:40.177139 916722 solver.cpp:218] Iteration 1329500 (16.6773 iter/s, 29.981s/500 iters), loss = 0.0948513
I0830 07:39:40.177196 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0948575 (* 1 = 0.0948575 loss)
I0830 07:39:40.177203 916722 sgd_solver.cpp:106] Iteration 1329500, lr = 0.01
I0830 07:40:10.149847 916722 solver.cpp:218] Iteration 1330000 (16.6818 iter/s, 29.9729s/500 iters), loss = 0.155644
I0830 07:40:10.149894 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.15565 (* 1 = 0.15565 loss)
I0830 07:40:10.149902 916722 sgd_solver.cpp:106] Iteration 1330000, lr = 0.01
I0830 07:40:40.107656 916722 solver.cpp:218] Iteration 1330500 (16.6901 iter/s, 29.958s/500 iters), loss = 0.102172
I0830 07:40:40.107728 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.102178 (* 1 = 0.102178 loss)
I0830 07:40:40.107736 916722 sgd_solver.cpp:106] Iteration 1330500, lr = 0.01
I0830 07:41:10.075989 916722 solver.cpp:218] Iteration 1331000 (16.6842 iter/s, 29.9684s/500 iters), loss = 0.155851
I0830 07:41:10.076042 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.155857 (* 1 = 0.155857 loss)
I0830 07:41:10.076052 916722 sgd_solver.cpp:106] Iteration 1331000, lr = 0.01
I0830 07:41:40.038341 916722 solver.cpp:218] Iteration 1331500 (16.6875 iter/s, 29.9625s/500 iters), loss = 0.0937154
I0830 07:41:40.038396 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0937218 (* 1 = 0.0937218 loss)
I0830 07:41:40.038404 916722 sgd_solver.cpp:106] Iteration 1331500, lr = 0.01
I0830 07:42:09.990489 916722 solver.cpp:218] Iteration 1332000 (16.6932 iter/s, 29.9523s/500 iters), loss = 0.11892
I0830 07:42:09.990541 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.118927 (* 1 = 0.118927 loss)
I0830 07:42:09.990551 916722 sgd_solver.cpp:106] Iteration 1332000, lr = 0.01
I0830 07:42:39.950553 916722 solver.cpp:218] Iteration 1332500 (16.6888 iter/s, 29.9602s/500 iters), loss = 0.187213
I0830 07:42:39.950609 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.187219 (* 1 = 0.187219 loss)
I0830 07:42:39.950618 916722 sgd_solver.cpp:106] Iteration 1332500, lr = 0.01
I0830 07:43:09.911415 916722 solver.cpp:218] Iteration 1333000 (16.6884 iter/s, 29.961s/500 iters), loss = 0.0351856
I0830 07:43:09.911468 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0351918 (* 1 = 0.0351918 loss)
I0830 07:43:09.911479 916722 sgd_solver.cpp:106] Iteration 1333000, lr = 0.01
I0830 07:43:39.890753 916722 solver.cpp:218] Iteration 1333500 (16.6781 iter/s, 29.9794s/500 iters), loss = 0.159588
I0830 07:43:39.890810 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159594 (* 1 = 0.159594 loss)
I0830 07:43:39.890820 916722 sgd_solver.cpp:106] Iteration 1333500, lr = 0.01
I0830 07:44:09.842612 916722 solver.cpp:218] Iteration 1334000 (16.6934 iter/s, 29.9519s/500 iters), loss = 0.0945219
I0830 07:44:09.842662 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0945281 (* 1 = 0.0945281 loss)
I0830 07:44:09.842674 916722 sgd_solver.cpp:106] Iteration 1334000, lr = 0.01
I0830 07:44:39.793387 916722 solver.cpp:218] Iteration 1334500 (16.694 iter/s, 29.9508s/500 iters), loss = 0.338323
I0830 07:44:39.793442 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.338329 (* 1 = 0.338329 loss)
I0830 07:44:39.793452 916722 sgd_solver.cpp:106] Iteration 1334500, lr = 0.01
I0830 07:45:09.747867 916722 solver.cpp:218] Iteration 1335000 (16.692 iter/s, 29.9545s/500 iters), loss = 0.152913
I0830 07:45:09.747917 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152919 (* 1 = 0.152919 loss)
I0830 07:45:09.747927 916722 sgd_solver.cpp:106] Iteration 1335000, lr = 0.01
I0830 07:45:39.706193 916722 solver.cpp:218] Iteration 1335500 (16.6898 iter/s, 29.9584s/500 iters), loss = 0.109488
I0830 07:45:39.706251 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109495 (* 1 = 0.109495 loss)
I0830 07:45:39.706259 916722 sgd_solver.cpp:106] Iteration 1335500, lr = 0.01
I0830 07:46:09.624532 916722 solver.cpp:218] Iteration 1336000 (16.7121 iter/s, 29.9184s/500 iters), loss = 0.0983628
I0830 07:46:09.624586 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0983695 (* 1 = 0.0983695 loss)
I0830 07:46:09.624596 916722 sgd_solver.cpp:106] Iteration 1336000, lr = 0.01
I0830 07:46:39.540403 916722 solver.cpp:218] Iteration 1336500 (16.7135 iter/s, 29.9159s/500 iters), loss = 0.481658
I0830 07:46:39.540475 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.481665 (* 1 = 0.481665 loss)
I0830 07:46:39.540484 916722 sgd_solver.cpp:106] Iteration 1336500, lr = 0.01
I0830 07:47:09.466625 916722 solver.cpp:218] Iteration 1337000 (16.7077 iter/s, 29.9262s/500 iters), loss = 0.160968
I0830 07:47:09.466686 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.160975 (* 1 = 0.160975 loss)
I0830 07:47:09.466696 916722 sgd_solver.cpp:106] Iteration 1337000, lr = 0.01
I0830 07:47:39.401600 916722 solver.cpp:218] Iteration 1337500 (16.7029 iter/s, 29.935s/500 iters), loss = 0.0748334
I0830 07:47:39.401671 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0748402 (* 1 = 0.0748402 loss)
I0830 07:47:39.401679 916722 sgd_solver.cpp:106] Iteration 1337500, lr = 0.01
I0830 07:48:09.358705 916722 solver.cpp:218] Iteration 1338000 (16.6905 iter/s, 29.9571s/500 iters), loss = 0.301863
I0830 07:48:09.358755 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.301869 (* 1 = 0.301869 loss)
I0830 07:48:09.358764 916722 sgd_solver.cpp:106] Iteration 1338000, lr = 0.01
I0830 07:48:39.316769 916722 solver.cpp:218] Iteration 1338500 (16.69 iter/s, 29.9581s/500 iters), loss = 0.0714825
I0830 07:48:39.316824 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0714893 (* 1 = 0.0714893 loss)
I0830 07:48:39.316833 916722 sgd_solver.cpp:106] Iteration 1338500, lr = 0.01
I0830 07:49:09.255168 916722 solver.cpp:218] Iteration 1339000 (16.701 iter/s, 29.9384s/500 iters), loss = 0.184861
I0830 07:49:09.255216 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.184868 (* 1 = 0.184868 loss)
I0830 07:49:09.255225 916722 sgd_solver.cpp:106] Iteration 1339000, lr = 0.01
I0830 07:49:39.211270 916722 solver.cpp:218] Iteration 1339500 (16.6911 iter/s, 29.9561s/500 iters), loss = 0.0503343
I0830 07:49:39.211329 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0503411 (* 1 = 0.0503411 loss)
I0830 07:49:39.211338 916722 sgd_solver.cpp:106] Iteration 1339500, lr = 0.01
I0830 07:50:09.170231 916722 solver.cpp:218] Iteration 1340000 (16.6895 iter/s, 29.959s/500 iters), loss = 0.411884
I0830 07:50:09.170282 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.411891 (* 1 = 0.411891 loss)
I0830 07:50:09.170290 916722 sgd_solver.cpp:106] Iteration 1340000, lr = 0.01
I0830 07:50:39.123683 916722 solver.cpp:218] Iteration 1340500 (16.6926 iter/s, 29.9535s/500 iters), loss = 0.379124
I0830 07:50:39.123741 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.379131 (* 1 = 0.379131 loss)
I0830 07:50:39.123749 916722 sgd_solver.cpp:106] Iteration 1340500, lr = 0.01
I0830 07:51:09.100193 916722 solver.cpp:218] Iteration 1341000 (16.6797 iter/s, 29.9765s/500 iters), loss = 0.0482685
I0830 07:51:09.100244 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0482754 (* 1 = 0.0482754 loss)
I0830 07:51:09.100252 916722 sgd_solver.cpp:106] Iteration 1341000, lr = 0.01
I0830 07:51:39.043375 916722 solver.cpp:218] Iteration 1341500 (16.6983 iter/s, 29.9432s/500 iters), loss = 0.199708
I0830 07:51:39.043431 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.199715 (* 1 = 0.199715 loss)
I0830 07:51:39.043439 916722 sgd_solver.cpp:106] Iteration 1341500, lr = 0.01
I0830 07:52:09.018368 916722 solver.cpp:218] Iteration 1342000 (16.6806 iter/s, 29.975s/500 iters), loss = 0.0151674
I0830 07:52:09.018419 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0151743 (* 1 = 0.0151743 loss)
I0830 07:52:09.018427 916722 sgd_solver.cpp:106] Iteration 1342000, lr = 0.01
I0830 07:52:38.966203 916722 solver.cpp:218] Iteration 1342500 (16.6957 iter/s, 29.9478s/500 iters), loss = 0.51686
I0830 07:52:38.966259 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.516867 (* 1 = 0.516867 loss)
I0830 07:52:38.966269 916722 sgd_solver.cpp:106] Iteration 1342500, lr = 0.01
I0830 07:53:08.908499 916722 solver.cpp:218] Iteration 1343000 (16.6988 iter/s, 29.9423s/500 iters), loss = 0.145297
I0830 07:53:08.908548 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.145304 (* 1 = 0.145304 loss)
I0830 07:53:08.908557 916722 sgd_solver.cpp:106] Iteration 1343000, lr = 0.01
I0830 07:53:38.859899 916722 solver.cpp:218] Iteration 1343500 (16.6937 iter/s, 29.9514s/500 iters), loss = 0.0414392
I0830 07:53:38.859966 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0414462 (* 1 = 0.0414462 loss)
I0830 07:53:38.859975 916722 sgd_solver.cpp:106] Iteration 1343500, lr = 0.01
I0830 07:54:08.815611 916722 solver.cpp:218] Iteration 1344000 (16.6913 iter/s, 29.9557s/500 iters), loss = 0.245123
I0830 07:54:08.815661 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.24513 (* 1 = 0.24513 loss)
I0830 07:54:08.815670 916722 sgd_solver.cpp:106] Iteration 1344000, lr = 0.01
I0830 07:54:38.791576 916722 solver.cpp:218] Iteration 1344500 (16.68 iter/s, 29.9759s/500 iters), loss = 0.215345
I0830 07:54:38.791636 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.215352 (* 1 = 0.215352 loss)
I0830 07:54:38.791644 916722 sgd_solver.cpp:106] Iteration 1344500, lr = 0.01
I0830 07:55:08.760704 916722 solver.cpp:218] Iteration 1345000 (16.6839 iter/s, 29.9691s/500 iters), loss = 0.235179
I0830 07:55:08.760756 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.235186 (* 1 = 0.235186 loss)
I0830 07:55:08.760766 916722 sgd_solver.cpp:106] Iteration 1345000, lr = 0.01
I0830 07:55:38.709324 916722 solver.cpp:218] Iteration 1345500 (16.6953 iter/s, 29.9486s/500 iters), loss = 0.323487
I0830 07:55:38.709385 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.323494 (* 1 = 0.323494 loss)
I0830 07:55:38.709394 916722 sgd_solver.cpp:106] Iteration 1345500, lr = 0.01
I0830 07:56:08.662163 916722 solver.cpp:218] Iteration 1346000 (16.6929 iter/s, 29.9528s/500 iters), loss = 0.256689
I0830 07:56:08.662214 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.256696 (* 1 = 0.256696 loss)
I0830 07:56:08.662225 916722 sgd_solver.cpp:106] Iteration 1346000, lr = 0.01
I0830 07:56:38.606119 916722 solver.cpp:218] Iteration 1346500 (16.6979 iter/s, 29.9439s/500 iters), loss = 0.0887739
I0830 07:56:38.606178 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0887808 (* 1 = 0.0887808 loss)
I0830 07:56:38.606187 916722 sgd_solver.cpp:106] Iteration 1346500, lr = 0.01
I0830 07:57:08.542227 916722 solver.cpp:218] Iteration 1347000 (16.7023 iter/s, 29.9361s/500 iters), loss = 0.181966
I0830 07:57:08.542280 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.181973 (* 1 = 0.181973 loss)
I0830 07:57:08.542290 916722 sgd_solver.cpp:106] Iteration 1347000, lr = 0.01
I0830 07:57:38.492511 916722 solver.cpp:218] Iteration 1347500 (16.6944 iter/s, 29.9502s/500 iters), loss = 0.226329
I0830 07:57:38.492568 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.226336 (* 1 = 0.226336 loss)
I0830 07:57:38.492576 916722 sgd_solver.cpp:106] Iteration 1347500, lr = 0.01
I0830 07:58:08.463122 916722 solver.cpp:218] Iteration 1348000 (16.683 iter/s, 29.9706s/500 iters), loss = 0.218618
I0830 07:58:08.463171 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.218624 (* 1 = 0.218624 loss)
I0830 07:58:08.463182 916722 sgd_solver.cpp:106] Iteration 1348000, lr = 0.01
I0830 07:58:38.405275 916722 solver.cpp:218] Iteration 1348500 (16.6989 iter/s, 29.9421s/500 iters), loss = 0.114557
I0830 07:58:38.405329 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.114564 (* 1 = 0.114564 loss)
I0830 07:58:38.405337 916722 sgd_solver.cpp:106] Iteration 1348500, lr = 0.01
I0830 07:59:08.345261 916722 solver.cpp:218] Iteration 1349000 (16.7001 iter/s, 29.9399s/500 iters), loss = 0.133571
I0830 07:59:08.345312 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133578 (* 1 = 0.133578 loss)
I0830 07:59:08.345322 916722 sgd_solver.cpp:106] Iteration 1349000, lr = 0.01
I0830 07:59:38.298750 916722 solver.cpp:218] Iteration 1349500 (16.6926 iter/s, 29.9534s/500 iters), loss = 0.143956
I0830 07:59:38.298807 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.143962 (* 1 = 0.143962 loss)
I0830 07:59:38.298815 916722 sgd_solver.cpp:106] Iteration 1349500, lr = 0.01
I0830 08:00:08.199810 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_1350000.caffemodel
I0830 08:00:08.219274 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_1350000.solverstate
I0830 08:00:08.225432 916722 solver.cpp:330] Iteration 1350000, Testing net (#0)
I0830 08:00:23.570871 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8785
I0830 08:00:23.570940 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.410328 (* 1 = 0.410328 loss)
I0830 08:00:23.629726 916722 solver.cpp:218] Iteration 1350000 (11.03 iter/s, 45.3309s/500 iters), loss = 0.0668077
I0830 08:00:23.629755 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0668141 (* 1 = 0.0668141 loss)
I0830 08:00:23.629763 916722 sgd_solver.cpp:106] Iteration 1350000, lr = 0.01
I0830 08:00:53.406888 916722 solver.cpp:218] Iteration 1350500 (16.7914 iter/s, 29.7771s/500 iters), loss = 0.144436
I0830 08:00:53.406937 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.144443 (* 1 = 0.144443 loss)
I0830 08:00:53.406946 916722 sgd_solver.cpp:106] Iteration 1350500, lr = 0.01
I0830 08:01:23.299250 916722 solver.cpp:218] Iteration 1351000 (16.7267 iter/s, 29.8923s/500 iters), loss = 0.128733
I0830 08:01:23.299306 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.12874 (* 1 = 0.12874 loss)
I0830 08:01:23.299314 916722 sgd_solver.cpp:106] Iteration 1351000, lr = 0.01
I0830 08:01:53.242022 916722 solver.cpp:218] Iteration 1351500 (16.6985 iter/s, 29.9427s/500 iters), loss = 0.099928
I0830 08:01:53.242071 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0999345 (* 1 = 0.0999345 loss)
I0830 08:01:53.242081 916722 sgd_solver.cpp:106] Iteration 1351500, lr = 0.01
I0830 08:02:23.159804 916722 solver.cpp:218] Iteration 1352000 (16.7125 iter/s, 29.9177s/500 iters), loss = 0.14703
I0830 08:02:23.159858 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.147037 (* 1 = 0.147037 loss)
I0830 08:02:23.159868 916722 sgd_solver.cpp:106] Iteration 1352000, lr = 0.01
I0830 08:02:53.081195 916722 solver.cpp:218] Iteration 1352500 (16.7105 iter/s, 29.9213s/500 iters), loss = 0.218742
I0830 08:02:53.081243 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.218748 (* 1 = 0.218748 loss)
I0830 08:02:53.081254 916722 sgd_solver.cpp:106] Iteration 1352500, lr = 0.01
I0830 08:03:23.006920 916722 solver.cpp:218] Iteration 1353000 (16.7081 iter/s, 29.9257s/500 iters), loss = 0.134089
I0830 08:03:23.006978 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.134096 (* 1 = 0.134096 loss)
I0830 08:03:23.006986 916722 sgd_solver.cpp:106] Iteration 1353000, lr = 0.01
I0830 08:03:52.914680 916722 solver.cpp:218] Iteration 1353500 (16.7181 iter/s, 29.9077s/500 iters), loss = 0.072433
I0830 08:03:52.914732 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0724395 (* 1 = 0.0724395 loss)
I0830 08:03:52.914742 916722 sgd_solver.cpp:106] Iteration 1353500, lr = 0.01
I0830 08:04:22.833467 916722 solver.cpp:218] Iteration 1354000 (16.7119 iter/s, 29.9187s/500 iters), loss = 0.231856
I0830 08:04:22.833528 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.231862 (* 1 = 0.231862 loss)
I0830 08:04:22.833536 916722 sgd_solver.cpp:106] Iteration 1354000, lr = 0.01
I0830 08:04:52.778182 916722 solver.cpp:218] Iteration 1354500 (16.6975 iter/s, 29.9447s/500 iters), loss = 0.0552084
I0830 08:04:52.778232 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0552148 (* 1 = 0.0552148 loss)
I0830 08:04:52.778241 916722 sgd_solver.cpp:106] Iteration 1354500, lr = 0.01
I0830 08:05:22.726572 916722 solver.cpp:218] Iteration 1355000 (16.6954 iter/s, 29.9483s/500 iters), loss = 0.170632
I0830 08:05:22.726631 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.170638 (* 1 = 0.170638 loss)
I0830 08:05:22.726639 916722 sgd_solver.cpp:106] Iteration 1355000, lr = 0.01
I0830 08:05:52.670629 916722 solver.cpp:218] Iteration 1355500 (16.6978 iter/s, 29.944s/500 iters), loss = 0.207638
I0830 08:05:52.670677 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.207644 (* 1 = 0.207644 loss)
I0830 08:05:52.670686 916722 sgd_solver.cpp:106] Iteration 1355500, lr = 0.01
I0830 08:06:22.611583 916722 solver.cpp:218] Iteration 1356000 (16.6996 iter/s, 29.9409s/500 iters), loss = 0.23804
I0830 08:06:22.611649 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.238046 (* 1 = 0.238046 loss)
I0830 08:06:22.611658 916722 sgd_solver.cpp:106] Iteration 1356000, lr = 0.01
I0830 08:06:52.526829 916722 solver.cpp:218] Iteration 1356500 (16.7139 iter/s, 29.9152s/500 iters), loss = 0.298559
I0830 08:06:52.526881 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.298566 (* 1 = 0.298566 loss)
I0830 08:06:52.526890 916722 sgd_solver.cpp:106] Iteration 1356500, lr = 0.01
I0830 08:07:22.450949 916722 solver.cpp:218] Iteration 1357000 (16.709 iter/s, 29.9241s/500 iters), loss = 0.241879
I0830 08:07:22.451002 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.241885 (* 1 = 0.241885 loss)
I0830 08:07:22.451010 916722 sgd_solver.cpp:106] Iteration 1357000, lr = 0.01
I0830 08:07:52.356760 916722 solver.cpp:218] Iteration 1357500 (16.7192 iter/s, 29.9058s/500 iters), loss = 0.174273
I0830 08:07:52.356814 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.174279 (* 1 = 0.174279 loss)
I0830 08:07:52.356823 916722 sgd_solver.cpp:106] Iteration 1357500, lr = 0.01
I0830 08:08:22.249361 916722 solver.cpp:218] Iteration 1358000 (16.7266 iter/s, 29.8925s/500 iters), loss = 0.181066
I0830 08:08:22.249421 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.181072 (* 1 = 0.181072 loss)
I0830 08:08:22.249430 916722 sgd_solver.cpp:106] Iteration 1358000, lr = 0.01
I0830 08:08:52.155997 916722 solver.cpp:218] Iteration 1358500 (16.7187 iter/s, 29.9066s/500 iters), loss = 0.138718
I0830 08:08:52.156049 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.138725 (* 1 = 0.138725 loss)
I0830 08:08:52.156057 916722 sgd_solver.cpp:106] Iteration 1358500, lr = 0.01
I0830 08:09:22.068608 916722 solver.cpp:218] Iteration 1359000 (16.7161 iter/s, 29.9114s/500 iters), loss = 0.155577
I0830 08:09:22.068665 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.155584 (* 1 = 0.155584 loss)
I0830 08:09:22.068675 916722 sgd_solver.cpp:106] Iteration 1359000, lr = 0.01
I0830 08:09:51.968173 916722 solver.cpp:218] Iteration 1359500 (16.7234 iter/s, 29.8982s/500 iters), loss = 0.131049
I0830 08:09:51.968225 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131055 (* 1 = 0.131055 loss)
I0830 08:09:51.968235 916722 sgd_solver.cpp:106] Iteration 1359500, lr = 0.01
I0830 08:10:21.872969 916722 solver.cpp:218] Iteration 1360000 (16.7205 iter/s, 29.9035s/500 iters), loss = 0.250027
I0830 08:10:21.873026 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.250033 (* 1 = 0.250033 loss)
I0830 08:10:21.873035 916722 sgd_solver.cpp:106] Iteration 1360000, lr = 0.01
I0830 08:10:51.757508 916722 solver.cpp:218] Iteration 1360500 (16.7318 iter/s, 29.8833s/500 iters), loss = 0.677803
I0830 08:10:51.757552 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.67781 (* 1 = 0.67781 loss)
I0830 08:10:51.757560 916722 sgd_solver.cpp:106] Iteration 1360500, lr = 0.01
I0830 08:11:21.655222 916722 solver.cpp:218] Iteration 1361000 (16.7243 iter/s, 29.8965s/500 iters), loss = 0.255365
I0830 08:11:21.655277 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.255372 (* 1 = 0.255372 loss)
I0830 08:11:21.655285 916722 sgd_solver.cpp:106] Iteration 1361000, lr = 0.01
I0830 08:11:51.558557 916722 solver.cpp:218] Iteration 1361500 (16.7212 iter/s, 29.9022s/500 iters), loss = 0.0815142
I0830 08:11:51.558604 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0815206 (* 1 = 0.0815206 loss)
I0830 08:11:51.558612 916722 sgd_solver.cpp:106] Iteration 1361500, lr = 0.01
I0830 08:12:21.494743 916722 solver.cpp:218] Iteration 1362000 (16.7028 iter/s, 29.9351s/500 iters), loss = 0.0332755
I0830 08:12:21.494802 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0332819 (* 1 = 0.0332819 loss)
I0830 08:12:21.494812 916722 sgd_solver.cpp:106] Iteration 1362000, lr = 0.01
I0830 08:12:51.453608 916722 solver.cpp:218] Iteration 1362500 (16.6901 iter/s, 29.9578s/500 iters), loss = 0.290133
I0830 08:12:51.453657 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.290139 (* 1 = 0.290139 loss)
I0830 08:12:51.453666 916722 sgd_solver.cpp:106] Iteration 1362500, lr = 0.01
I0830 08:13:21.418174 916722 solver.cpp:218] Iteration 1363000 (16.6869 iter/s, 29.9636s/500 iters), loss = 0.0926993
I0830 08:13:21.418241 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0927056 (* 1 = 0.0927056 loss)
I0830 08:13:21.418251 916722 sgd_solver.cpp:106] Iteration 1363000, lr = 0.01
I0830 08:13:51.360371 916722 solver.cpp:218] Iteration 1363500 (16.6994 iter/s, 29.9412s/500 iters), loss = 0.106502
I0830 08:13:51.360420 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.106508 (* 1 = 0.106508 loss)
I0830 08:13:51.360445 916722 sgd_solver.cpp:106] Iteration 1363500, lr = 0.01
I0830 08:14:21.310062 916722 solver.cpp:218] Iteration 1364000 (16.6952 iter/s, 29.9488s/500 iters), loss = 0.350151
I0830 08:14:21.310124 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.350157 (* 1 = 0.350157 loss)
I0830 08:14:21.310133 916722 sgd_solver.cpp:106] Iteration 1364000, lr = 0.01
I0830 08:14:51.269718 916722 solver.cpp:218] Iteration 1364500 (16.6896 iter/s, 29.9588s/500 iters), loss = 0.238295
I0830 08:14:51.269769 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.238301 (* 1 = 0.238301 loss)
I0830 08:14:51.269780 916722 sgd_solver.cpp:106] Iteration 1364500, lr = 0.01
I0830 08:15:21.211194 916722 solver.cpp:218] Iteration 1365000 (16.6997 iter/s, 29.9406s/500 iters), loss = 0.036926
I0830 08:15:21.211249 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0369322 (* 1 = 0.0369322 loss)
I0830 08:15:21.211257 916722 sgd_solver.cpp:106] Iteration 1365000, lr = 0.01
I0830 08:15:51.160290 916722 solver.cpp:218] Iteration 1365500 (16.6954 iter/s, 29.9483s/500 iters), loss = 0.248852
I0830 08:15:51.160337 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.248858 (* 1 = 0.248858 loss)
I0830 08:15:51.160347 916722 sgd_solver.cpp:106] Iteration 1365500, lr = 0.01
I0830 08:16:21.102187 916722 solver.cpp:218] Iteration 1366000 (16.6994 iter/s, 29.9411s/500 iters), loss = 0.10322
I0830 08:16:21.102238 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.103226 (* 1 = 0.103226 loss)
I0830 08:16:21.102246 916722 sgd_solver.cpp:106] Iteration 1366000, lr = 0.01
I0830 08:16:51.071713 916722 solver.cpp:218] Iteration 1366500 (16.684 iter/s, 29.9688s/500 iters), loss = 0.153462
I0830 08:16:51.071763 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.153468 (* 1 = 0.153468 loss)
I0830 08:16:51.071774 916722 sgd_solver.cpp:106] Iteration 1366500, lr = 0.01
I0830 08:17:21.027649 916722 solver.cpp:218] Iteration 1367000 (16.6916 iter/s, 29.9552s/500 iters), loss = 0.375722
I0830 08:17:21.027707 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.375728 (* 1 = 0.375728 loss)
I0830 08:17:21.027716 916722 sgd_solver.cpp:106] Iteration 1367000, lr = 0.01
I0830 08:17:50.974314 916722 solver.cpp:218] Iteration 1367500 (16.6967 iter/s, 29.946s/500 iters), loss = 0.0916088
I0830 08:17:50.974364 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.091615 (* 1 = 0.091615 loss)
I0830 08:17:50.974375 916722 sgd_solver.cpp:106] Iteration 1367500, lr = 0.01
I0830 08:18:20.920022 916722 solver.cpp:218] Iteration 1368000 (16.6972 iter/s, 29.9451s/500 iters), loss = 0.204757
I0830 08:18:20.920080 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.204764 (* 1 = 0.204764 loss)
I0830 08:18:20.920089 916722 sgd_solver.cpp:106] Iteration 1368000, lr = 0.01
I0830 08:18:50.876544 916722 solver.cpp:218] Iteration 1368500 (16.6912 iter/s, 29.9559s/500 iters), loss = 0.164133
I0830 08:18:50.876595 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.164139 (* 1 = 0.164139 loss)
I0830 08:18:50.876603 916722 sgd_solver.cpp:106] Iteration 1368500, lr = 0.01
I0830 08:19:20.851675 916722 solver.cpp:218] Iteration 1369000 (16.6808 iter/s, 29.9745s/500 iters), loss = 0.0651209
I0830 08:19:20.851749 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0651271 (* 1 = 0.0651271 loss)
I0830 08:19:20.851758 916722 sgd_solver.cpp:106] Iteration 1369000, lr = 0.01
I0830 08:19:50.822445 916722 solver.cpp:218] Iteration 1369500 (16.6833 iter/s, 29.9702s/500 iters), loss = 0.241706
I0830 08:19:50.822495 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.241712 (* 1 = 0.241712 loss)
I0830 08:19:50.822504 916722 sgd_solver.cpp:106] Iteration 1369500, lr = 0.01
I0830 08:20:20.808270 916722 solver.cpp:218] Iteration 1370000 (16.6749 iter/s, 29.9853s/500 iters), loss = 0.329763
I0830 08:20:20.808327 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.329769 (* 1 = 0.329769 loss)
I0830 08:20:20.808336 916722 sgd_solver.cpp:106] Iteration 1370000, lr = 0.01
I0830 08:20:50.798292 916722 solver.cpp:218] Iteration 1370500 (16.6725 iter/s, 29.9895s/500 iters), loss = 0.0376389
I0830 08:20:50.798341 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0376449 (* 1 = 0.0376449 loss)
I0830 08:20:50.798348 916722 sgd_solver.cpp:106] Iteration 1370500, lr = 0.01
I0830 08:21:20.783560 916722 solver.cpp:218] Iteration 1371000 (16.6751 iter/s, 29.9848s/500 iters), loss = 0.0950319
I0830 08:21:20.783618 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0950378 (* 1 = 0.0950378 loss)
I0830 08:21:20.783627 916722 sgd_solver.cpp:106] Iteration 1371000, lr = 0.01
I0830 08:21:50.789451 916722 solver.cpp:218] Iteration 1371500 (16.6637 iter/s, 30.0054s/500 iters), loss = 0.0914829
I0830 08:21:50.789507 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0914887 (* 1 = 0.0914887 loss)
I0830 08:21:50.789516 916722 sgd_solver.cpp:106] Iteration 1371500, lr = 0.01
I0830 08:22:20.786901 916722 solver.cpp:218] Iteration 1372000 (16.6684 iter/s, 29.997s/500 iters), loss = 0.186463
I0830 08:22:20.786954 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.186469 (* 1 = 0.186469 loss)
I0830 08:22:20.786964 916722 sgd_solver.cpp:106] Iteration 1372000, lr = 0.01
I0830 08:22:50.791404 916722 solver.cpp:218] Iteration 1372500 (16.6644 iter/s, 30.004s/500 iters), loss = 0.0541892
I0830 08:22:50.791462 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0541951 (* 1 = 0.0541951 loss)
I0830 08:22:50.791471 916722 sgd_solver.cpp:106] Iteration 1372500, lr = 0.01
I0830 08:23:20.789134 916722 solver.cpp:218] Iteration 1373000 (16.6682 iter/s, 29.9973s/500 iters), loss = 0.27454
I0830 08:23:20.789186 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.274546 (* 1 = 0.274546 loss)
I0830 08:23:20.789196 916722 sgd_solver.cpp:106] Iteration 1373000, lr = 0.01
I0830 08:23:50.785030 916722 solver.cpp:218] Iteration 1373500 (16.6692 iter/s, 29.9955s/500 iters), loss = 0.147038
I0830 08:23:50.785087 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.147044 (* 1 = 0.147044 loss)
I0830 08:23:50.785096 916722 sgd_solver.cpp:106] Iteration 1373500, lr = 0.01
I0830 08:24:20.805641 916722 solver.cpp:218] Iteration 1374000 (16.6555 iter/s, 30.0202s/500 iters), loss = 0.147677
I0830 08:24:20.805698 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.147683 (* 1 = 0.147683 loss)
I0830 08:24:20.805706 916722 sgd_solver.cpp:106] Iteration 1374000, lr = 0.01
I0830 08:24:50.823117 916722 solver.cpp:218] Iteration 1374500 (16.6572 iter/s, 30.0171s/500 iters), loss = 0.327867
I0830 08:24:50.823175 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.327873 (* 1 = 0.327873 loss)
I0830 08:24:50.823184 916722 sgd_solver.cpp:106] Iteration 1374500, lr = 0.01
I0830 08:25:20.837293 916722 solver.cpp:218] Iteration 1375000 (16.659 iter/s, 30.0138s/500 iters), loss = 0.113349
I0830 08:25:20.837349 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.113355 (* 1 = 0.113355 loss)
I0830 08:25:20.837357 916722 sgd_solver.cpp:106] Iteration 1375000, lr = 0.01
I0830 08:25:50.879914 916722 solver.cpp:218] Iteration 1375500 (16.6432 iter/s, 30.0422s/500 iters), loss = 0.175416
I0830 08:25:50.879985 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.175422 (* 1 = 0.175422 loss)
I0830 08:25:50.879994 916722 sgd_solver.cpp:106] Iteration 1375500, lr = 0.01
I0830 08:26:20.880705 916722 solver.cpp:218] Iteration 1376000 (16.6664 iter/s, 30.0004s/500 iters), loss = 0.0756352
I0830 08:26:20.880764 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0756411 (* 1 = 0.0756411 loss)
I0830 08:26:20.880771 916722 sgd_solver.cpp:106] Iteration 1376000, lr = 0.01
I0830 08:26:50.872874 916722 solver.cpp:218] Iteration 1376500 (16.6712 iter/s, 29.9918s/500 iters), loss = 0.160125
I0830 08:26:50.872925 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.160131 (* 1 = 0.160131 loss)
I0830 08:26:50.872934 916722 sgd_solver.cpp:106] Iteration 1376500, lr = 0.01
I0830 08:27:20.869642 916722 solver.cpp:218] Iteration 1377000 (16.6687 iter/s, 29.9964s/500 iters), loss = 0.277327
I0830 08:27:20.869699 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.277332 (* 1 = 0.277332 loss)
I0830 08:27:20.869707 916722 sgd_solver.cpp:106] Iteration 1377000, lr = 0.01
I0830 08:27:50.873178 916722 solver.cpp:218] Iteration 1377500 (16.6649 iter/s, 30.0032s/500 iters), loss = 0.0792679
I0830 08:27:50.873232 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0792739 (* 1 = 0.0792739 loss)
I0830 08:27:50.873240 916722 sgd_solver.cpp:106] Iteration 1377500, lr = 0.01
I0830 08:28:20.878865 916722 solver.cpp:218] Iteration 1378000 (16.6637 iter/s, 30.0053s/500 iters), loss = 0.0802635
I0830 08:28:20.878921 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0802693 (* 1 = 0.0802693 loss)
I0830 08:28:20.878928 916722 sgd_solver.cpp:106] Iteration 1378000, lr = 0.01
I0830 08:28:50.898986 916722 solver.cpp:218] Iteration 1378500 (16.6557 iter/s, 30.0198s/500 iters), loss = 0.13084
I0830 08:28:50.899041 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130846 (* 1 = 0.130846 loss)
I0830 08:28:50.899049 916722 sgd_solver.cpp:106] Iteration 1378500, lr = 0.01
I0830 08:29:20.898577 916722 solver.cpp:218] Iteration 1379000 (16.6671 iter/s, 29.9993s/500 iters), loss = 0.144239
I0830 08:29:20.898633 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.144245 (* 1 = 0.144245 loss)
I0830 08:29:20.898643 916722 sgd_solver.cpp:106] Iteration 1379000, lr = 0.01
I0830 08:29:50.905115 916722 solver.cpp:218] Iteration 1379500 (16.6632 iter/s, 30.0062s/500 iters), loss = 0.175135
I0830 08:29:50.905166 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.175141 (* 1 = 0.175141 loss)
I0830 08:29:50.905174 916722 sgd_solver.cpp:106] Iteration 1379500, lr = 0.01
I0830 08:30:20.916375 916722 solver.cpp:218] Iteration 1380000 (16.6606 iter/s, 30.0109s/500 iters), loss = 0.336183
I0830 08:30:20.916437 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.336188 (* 1 = 0.336188 loss)
I0830 08:30:20.916447 916722 sgd_solver.cpp:106] Iteration 1380000, lr = 0.01
I0830 08:30:50.932981 916722 solver.cpp:218] Iteration 1380500 (16.6576 iter/s, 30.0163s/500 iters), loss = 0.190268
I0830 08:30:50.933041 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.190274 (* 1 = 0.190274 loss)
I0830 08:30:50.933050 916722 sgd_solver.cpp:106] Iteration 1380500, lr = 0.01
I0830 08:31:20.948266 916722 solver.cpp:218] Iteration 1381000 (16.6584 iter/s, 30.015s/500 iters), loss = 0.371882
I0830 08:31:20.948323 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.371888 (* 1 = 0.371888 loss)
I0830 08:31:20.948331 916722 sgd_solver.cpp:106] Iteration 1381000, lr = 0.01
I0830 08:31:50.964280 916722 solver.cpp:218] Iteration 1381500 (16.6579 iter/s, 30.0157s/500 iters), loss = 0.108216
I0830 08:31:50.964339 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.108221 (* 1 = 0.108221 loss)
I0830 08:31:50.964349 916722 sgd_solver.cpp:106] Iteration 1381500, lr = 0.01
I0830 08:32:20.995715 916722 solver.cpp:218] Iteration 1382000 (16.6494 iter/s, 30.0311s/500 iters), loss = 0.0965322
I0830 08:32:20.995782 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0965375 (* 1 = 0.0965375 loss)
I0830 08:32:20.995795 916722 sgd_solver.cpp:106] Iteration 1382000, lr = 0.01
I0830 08:32:51.003804 916722 solver.cpp:218] Iteration 1382500 (16.6623 iter/s, 30.0078s/500 iters), loss = 0.121857
I0830 08:32:51.003859 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.121862 (* 1 = 0.121862 loss)
I0830 08:32:51.003867 916722 sgd_solver.cpp:106] Iteration 1382500, lr = 0.01
I0830 08:33:21.005259 916722 solver.cpp:218] Iteration 1383000 (16.666 iter/s, 30.0012s/500 iters), loss = 0.0612806
I0830 08:33:21.005318 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.061286 (* 1 = 0.061286 loss)
I0830 08:33:21.005327 916722 sgd_solver.cpp:106] Iteration 1383000, lr = 0.01
I0830 08:33:51.023165 916722 solver.cpp:218] Iteration 1383500 (16.6569 iter/s, 30.0176s/500 iters), loss = 0.275309
I0830 08:33:51.023221 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.275314 (* 1 = 0.275314 loss)
I0830 08:33:51.023231 916722 sgd_solver.cpp:106] Iteration 1383500, lr = 0.01
I0830 08:34:21.036756 916722 solver.cpp:218] Iteration 1384000 (16.6593 iter/s, 30.0133s/500 iters), loss = 0.062626
I0830 08:34:21.036809 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0626312 (* 1 = 0.0626312 loss)
I0830 08:34:21.036818 916722 sgd_solver.cpp:106] Iteration 1384000, lr = 0.01
I0830 08:34:51.057821 916722 solver.cpp:218] Iteration 1384500 (16.6551 iter/s, 30.0208s/500 iters), loss = 0.23776
I0830 08:34:51.057879 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.237766 (* 1 = 0.237766 loss)
I0830 08:34:51.057888 916722 sgd_solver.cpp:106] Iteration 1384500, lr = 0.01
I0830 08:35:21.077721 916722 solver.cpp:218] Iteration 1385000 (16.6558 iter/s, 30.0196s/500 iters), loss = 0.159652
I0830 08:35:21.077780 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159657 (* 1 = 0.159657 loss)
I0830 08:35:21.077790 916722 sgd_solver.cpp:106] Iteration 1385000, lr = 0.01
I0830 08:35:51.069499 916722 solver.cpp:218] Iteration 1385500 (16.6714 iter/s, 29.9915s/500 iters), loss = 0.16379
I0830 08:35:51.069548 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.163795 (* 1 = 0.163795 loss)
I0830 08:35:51.069559 916722 sgd_solver.cpp:106] Iteration 1385500, lr = 0.01
I0830 08:36:21.075409 916722 solver.cpp:218] Iteration 1386000 (16.6635 iter/s, 30.0057s/500 iters), loss = 0.0661429
I0830 08:36:21.075470 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0661482 (* 1 = 0.0661482 loss)
I0830 08:36:21.075479 916722 sgd_solver.cpp:106] Iteration 1386000, lr = 0.01
I0830 08:36:51.084746 916722 solver.cpp:218] Iteration 1386500 (16.6616 iter/s, 30.0091s/500 iters), loss = 0.173579
I0830 08:36:51.084802 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.173584 (* 1 = 0.173584 loss)
I0830 08:36:51.084810 916722 sgd_solver.cpp:106] Iteration 1386500, lr = 0.01
I0830 08:37:21.102211 916722 solver.cpp:218] Iteration 1387000 (16.6571 iter/s, 30.0172s/500 iters), loss = 0.282768
I0830 08:37:21.102268 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.282773 (* 1 = 0.282773 loss)
I0830 08:37:21.102277 916722 sgd_solver.cpp:106] Iteration 1387000, lr = 0.01
I0830 08:37:51.129212 916722 solver.cpp:218] Iteration 1387500 (16.6518 iter/s, 30.0267s/500 iters), loss = 0.111129
I0830 08:37:51.129266 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111134 (* 1 = 0.111134 loss)
I0830 08:37:51.129274 916722 sgd_solver.cpp:106] Iteration 1387500, lr = 0.01
I0830 08:38:21.135493 916722 solver.cpp:218] Iteration 1388000 (16.6633 iter/s, 30.006s/500 iters), loss = 0.0755289
I0830 08:38:21.135550 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0755342 (* 1 = 0.0755342 loss)
I0830 08:38:21.135558 916722 sgd_solver.cpp:106] Iteration 1388000, lr = 0.01
I0830 08:38:51.171954 916722 solver.cpp:218] Iteration 1388500 (16.6466 iter/s, 30.0362s/500 iters), loss = 0.369463
I0830 08:38:51.172021 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.369468 (* 1 = 0.369468 loss)
I0830 08:38:51.172034 916722 sgd_solver.cpp:106] Iteration 1388500, lr = 0.01
I0830 08:39:21.192710 916722 solver.cpp:218] Iteration 1389000 (16.6553 iter/s, 30.0205s/500 iters), loss = 0.375389
I0830 08:39:21.192766 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.375394 (* 1 = 0.375394 loss)
I0830 08:39:21.192775 916722 sgd_solver.cpp:106] Iteration 1389000, lr = 0.01
I0830 08:39:51.208281 916722 solver.cpp:218] Iteration 1389500 (16.6582 iter/s, 30.0153s/500 iters), loss = 0.113825
I0830 08:39:51.208339 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.11383 (* 1 = 0.11383 loss)
I0830 08:39:51.208348 916722 sgd_solver.cpp:106] Iteration 1389500, lr = 0.01
I0830 08:40:21.228727 916722 solver.cpp:218] Iteration 1390000 (16.6555 iter/s, 30.0202s/500 iters), loss = 0.101058
I0830 08:40:21.228807 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101063 (* 1 = 0.101063 loss)
I0830 08:40:21.228816 916722 sgd_solver.cpp:106] Iteration 1390000, lr = 0.01
I0830 08:40:51.246495 916722 solver.cpp:218] Iteration 1390500 (16.6569 iter/s, 30.0175s/500 iters), loss = 0.13621
I0830 08:40:51.246551 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.136215 (* 1 = 0.136215 loss)
I0830 08:40:51.246559 916722 sgd_solver.cpp:106] Iteration 1390500, lr = 0.01
I0830 08:41:21.251749 916722 solver.cpp:218] Iteration 1391000 (16.6639 iter/s, 30.005s/500 iters), loss = 0.219284
I0830 08:41:21.251807 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.219289 (* 1 = 0.219289 loss)
I0830 08:41:21.251816 916722 sgd_solver.cpp:106] Iteration 1391000, lr = 0.01
I0830 08:41:51.253203 916722 solver.cpp:218] Iteration 1391500 (16.666 iter/s, 30.0012s/500 iters), loss = 0.260119
I0830 08:41:51.253257 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.260124 (* 1 = 0.260124 loss)
I0830 08:41:51.253265 916722 sgd_solver.cpp:106] Iteration 1391500, lr = 0.01
I0830 08:42:21.230747 916722 solver.cpp:218] Iteration 1392000 (16.6793 iter/s, 29.9773s/500 iters), loss = 0.16714
I0830 08:42:21.230796 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.167145 (* 1 = 0.167145 loss)
I0830 08:42:21.230808 916722 sgd_solver.cpp:106] Iteration 1392000, lr = 0.01
I0830 08:42:51.224269 916722 solver.cpp:218] Iteration 1392500 (16.6704 iter/s, 29.9933s/500 iters), loss = 0.183363
I0830 08:42:51.224326 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.183369 (* 1 = 0.183369 loss)
I0830 08:42:51.224335 916722 sgd_solver.cpp:106] Iteration 1392500, lr = 0.01
I0830 08:43:21.226445 916722 solver.cpp:218] Iteration 1393000 (16.6656 iter/s, 30.0019s/500 iters), loss = 0.250579
I0830 08:43:21.226501 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.250585 (* 1 = 0.250585 loss)
I0830 08:43:21.226511 916722 sgd_solver.cpp:106] Iteration 1393000, lr = 0.01
I0830 08:43:51.237495 916722 solver.cpp:218] Iteration 1393500 (16.6607 iter/s, 30.0108s/500 iters), loss = 0.181955
I0830 08:43:51.237553 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.18196 (* 1 = 0.18196 loss)
I0830 08:43:51.237562 916722 sgd_solver.cpp:106] Iteration 1393500, lr = 0.01
I0830 08:44:21.242338 916722 solver.cpp:218] Iteration 1394000 (16.6641 iter/s, 30.0046s/500 iters), loss = 0.298892
I0830 08:44:21.242398 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.298897 (* 1 = 0.298897 loss)
I0830 08:44:21.242406 916722 sgd_solver.cpp:106] Iteration 1394000, lr = 0.01
I0830 08:44:51.261756 916722 solver.cpp:218] Iteration 1394500 (16.656 iter/s, 30.0192s/500 iters), loss = 0.00897753
I0830 08:44:51.261816 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.00898286 (* 1 = 0.00898286 loss)
I0830 08:44:51.261823 916722 sgd_solver.cpp:106] Iteration 1394500, lr = 0.01
I0830 08:45:21.261348 916722 solver.cpp:218] Iteration 1395000 (16.667 iter/s, 29.9994s/500 iters), loss = 0.0444027
I0830 08:45:21.261400 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.044408 (* 1 = 0.044408 loss)
I0830 08:45:21.261410 916722 sgd_solver.cpp:106] Iteration 1395000, lr = 0.01
I0830 08:45:51.268079 916722 solver.cpp:218] Iteration 1395500 (16.6631 iter/s, 30.0065s/500 iters), loss = 0.102569
I0830 08:45:51.268151 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.102575 (* 1 = 0.102575 loss)
I0830 08:45:51.268159 916722 sgd_solver.cpp:106] Iteration 1395500, lr = 0.01
I0830 08:46:21.277302 916722 solver.cpp:218] Iteration 1396000 (16.6617 iter/s, 30.009s/500 iters), loss = 0.171067
I0830 08:46:21.277359 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.171072 (* 1 = 0.171072 loss)
I0830 08:46:21.277367 916722 sgd_solver.cpp:106] Iteration 1396000, lr = 0.01
I0830 08:46:51.297763 916722 solver.cpp:218] Iteration 1396500 (16.6554 iter/s, 30.0202s/500 iters), loss = 0.181267
I0830 08:46:51.297819 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.181273 (* 1 = 0.181273 loss)
I0830 08:46:51.297827 916722 sgd_solver.cpp:106] Iteration 1396500, lr = 0.01
I0830 08:47:21.324860 916722 solver.cpp:218] Iteration 1397000 (16.6518 iter/s, 30.0269s/500 iters), loss = 0.198807
I0830 08:47:21.324920 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.198812 (* 1 = 0.198812 loss)
I0830 08:47:21.324929 916722 sgd_solver.cpp:106] Iteration 1397000, lr = 0.01
I0830 08:47:51.342459 916722 solver.cpp:218] Iteration 1397500 (16.657 iter/s, 30.0174s/500 iters), loss = 0.0850448
I0830 08:47:51.342519 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.08505 (* 1 = 0.08505 loss)
I0830 08:47:51.342527 916722 sgd_solver.cpp:106] Iteration 1397500, lr = 0.01
I0830 08:48:21.362741 916722 solver.cpp:218] Iteration 1398000 (16.6555 iter/s, 30.0201s/500 iters), loss = 0.155066
I0830 08:48:21.362799 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.155072 (* 1 = 0.155072 loss)
I0830 08:48:21.362807 916722 sgd_solver.cpp:106] Iteration 1398000, lr = 0.01
I0830 08:48:51.376168 916722 solver.cpp:218] Iteration 1398500 (16.6593 iter/s, 30.0132s/500 iters), loss = 0.193988
I0830 08:48:51.376226 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.193994 (* 1 = 0.193994 loss)
I0830 08:48:51.376235 916722 sgd_solver.cpp:106] Iteration 1398500, lr = 0.01
I0830 08:49:21.390934 916722 solver.cpp:218] Iteration 1399000 (16.6586 iter/s, 30.0145s/500 iters), loss = 0.260376
I0830 08:49:21.390993 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.260382 (* 1 = 0.260382 loss)
I0830 08:49:21.391001 916722 sgd_solver.cpp:106] Iteration 1399000, lr = 0.01
I0830 08:49:51.369374 916722 solver.cpp:218] Iteration 1399500 (16.6788 iter/s, 29.9782s/500 iters), loss = 0.0386497
I0830 08:49:51.369424 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0386553 (* 1 = 0.0386553 loss)
I0830 08:49:51.369434 916722 sgd_solver.cpp:106] Iteration 1399500, lr = 0.01
I0830 08:50:21.311802 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_1400000.caffemodel
I0830 08:50:21.331192 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_1400000.solverstate
I0830 08:50:21.337342 916722 solver.cpp:330] Iteration 1400000, Testing net (#0)
I0830 08:50:36.738904 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8538
I0830 08:50:36.738945 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.508601 (* 1 = 0.508601 loss)
I0830 08:50:36.797703 916722 solver.cpp:218] Iteration 1400000 (11.0064 iter/s, 45.428s/500 iters), loss = 0.248266
I0830 08:50:36.797729 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.248271 (* 1 = 0.248271 loss)
I0830 08:50:36.797736 916722 sgd_solver.cpp:106] Iteration 1400000, lr = 0.01
I0830 08:51:06.631448 916722 solver.cpp:218] Iteration 1400500 (16.7597 iter/s, 29.8335s/500 iters), loss = 0.154304
I0830 08:51:06.631503 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.15431 (* 1 = 0.15431 loss)
I0830 08:51:06.631512 916722 sgd_solver.cpp:106] Iteration 1400500, lr = 0.01
I0830 08:51:36.567368 916722 solver.cpp:218] Iteration 1401000 (16.7025 iter/s, 29.9357s/500 iters), loss = 0.123991
I0830 08:51:36.567431 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.123997 (* 1 = 0.123997 loss)
I0830 08:51:36.567441 916722 sgd_solver.cpp:106] Iteration 1401000, lr = 0.01
I0830 08:52:06.525952 916722 solver.cpp:218] Iteration 1401500 (16.6898 iter/s, 29.9583s/500 iters), loss = 0.129773
I0830 08:52:06.526021 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.129779 (* 1 = 0.129779 loss)
I0830 08:52:06.526031 916722 sgd_solver.cpp:106] Iteration 1401500, lr = 0.01
I0830 08:52:36.468313 916722 solver.cpp:218] Iteration 1402000 (16.6989 iter/s, 29.9421s/500 iters), loss = 0.0828294
I0830 08:52:36.468362 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0828354 (* 1 = 0.0828354 loss)
I0830 08:52:36.468370 916722 sgd_solver.cpp:106] Iteration 1402000, lr = 0.01
I0830 08:53:06.428421 916722 solver.cpp:218] Iteration 1402500 (16.689 iter/s, 29.9599s/500 iters), loss = 0.0855015
I0830 08:53:06.428483 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0855074 (* 1 = 0.0855074 loss)
I0830 08:53:06.428491 916722 sgd_solver.cpp:106] Iteration 1402500, lr = 0.01
I0830 08:53:36.389008 916722 solver.cpp:218] Iteration 1403000 (16.6887 iter/s, 29.9604s/500 iters), loss = 0.0679953
I0830 08:53:36.389056 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0680012 (* 1 = 0.0680012 loss)
I0830 08:53:36.389065 916722 sgd_solver.cpp:106] Iteration 1403000, lr = 0.01
I0830 08:54:06.362887 916722 solver.cpp:218] Iteration 1403500 (16.6813 iter/s, 29.9737s/500 iters), loss = 0.0122968
I0830 08:54:06.362946 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0123028 (* 1 = 0.0123028 loss)
I0830 08:54:06.362954 916722 sgd_solver.cpp:106] Iteration 1403500, lr = 0.01
I0830 08:54:36.333276 916722 solver.cpp:218] Iteration 1404000 (16.6833 iter/s, 29.9702s/500 iters), loss = 0.119635
I0830 08:54:36.333324 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.119641 (* 1 = 0.119641 loss)
I0830 08:54:36.333333 916722 sgd_solver.cpp:106] Iteration 1404000, lr = 0.01
I0830 08:55:06.294991 916722 solver.cpp:218] Iteration 1404500 (16.6881 iter/s, 29.9615s/500 iters), loss = 0.173731
I0830 08:55:06.295047 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.173737 (* 1 = 0.173737 loss)
I0830 08:55:06.295055 916722 sgd_solver.cpp:106] Iteration 1404500, lr = 0.01
I0830 08:55:36.283170 916722 solver.cpp:218] Iteration 1405000 (16.6734 iter/s, 29.988s/500 iters), loss = 0.0318439
I0830 08:55:36.283218 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.03185 (* 1 = 0.03185 loss)
I0830 08:55:36.283226 916722 sgd_solver.cpp:106] Iteration 1405000, lr = 0.01
I0830 08:56:06.272591 916722 solver.cpp:218] Iteration 1405500 (16.6727 iter/s, 29.9892s/500 iters), loss = 0.257289
I0830 08:56:06.272665 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.257295 (* 1 = 0.257295 loss)
I0830 08:56:06.272678 916722 sgd_solver.cpp:106] Iteration 1405500, lr = 0.01
I0830 08:56:36.272173 916722 solver.cpp:218] Iteration 1406000 (16.667 iter/s, 29.9993s/500 iters), loss = 0.0563009
I0830 08:56:36.272222 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0563067 (* 1 = 0.0563067 loss)
I0830 08:56:36.272233 916722 sgd_solver.cpp:106] Iteration 1406000, lr = 0.01
I0830 08:57:06.275646 916722 solver.cpp:218] Iteration 1406500 (16.6649 iter/s, 30.0033s/500 iters), loss = 0.174014
I0830 08:57:06.275699 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.17402 (* 1 = 0.17402 loss)
I0830 08:57:06.275708 916722 sgd_solver.cpp:106] Iteration 1406500, lr = 0.01
I0830 08:57:36.305099 916722 solver.cpp:218] Iteration 1407000 (16.6504 iter/s, 30.0292s/500 iters), loss = 0.117189
I0830 08:57:36.305158 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.117195 (* 1 = 0.117195 loss)
I0830 08:57:36.305167 916722 sgd_solver.cpp:106] Iteration 1407000, lr = 0.01
I0830 08:58:06.325546 916722 solver.cpp:218] Iteration 1407500 (16.6554 iter/s, 30.0202s/500 iters), loss = 0.026103
I0830 08:58:06.325618 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0261093 (* 1 = 0.0261093 loss)
I0830 08:58:06.325626 916722 sgd_solver.cpp:106] Iteration 1407500, lr = 0.01
I0830 08:58:36.348819 916722 solver.cpp:218] Iteration 1408000 (16.6539 iter/s, 30.023s/500 iters), loss = 0.233671
I0830 08:58:36.348872 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.233677 (* 1 = 0.233677 loss)
I0830 08:58:36.348881 916722 sgd_solver.cpp:106] Iteration 1408000, lr = 0.01
I0830 08:59:06.395155 916722 solver.cpp:218] Iteration 1408500 (16.6411 iter/s, 30.0461s/500 iters), loss = 0.0403159
I0830 08:59:06.395211 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0403222 (* 1 = 0.0403222 loss)
I0830 08:59:06.395220 916722 sgd_solver.cpp:106] Iteration 1408500, lr = 0.01
I0830 08:59:36.439407 916722 solver.cpp:218] Iteration 1409000 (16.6422 iter/s, 30.044s/500 iters), loss = 0.180274
I0830 08:59:36.439461 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.18028 (* 1 = 0.18028 loss)
I0830 08:59:36.439469 916722 sgd_solver.cpp:106] Iteration 1409000, lr = 0.01
I0830 09:00:06.480278 916722 solver.cpp:218] Iteration 1409500 (16.6441 iter/s, 30.0407s/500 iters), loss = 0.0824714
I0830 09:00:06.480334 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0824777 (* 1 = 0.0824777 loss)
I0830 09:00:06.480341 916722 sgd_solver.cpp:106] Iteration 1409500, lr = 0.01
I0830 09:00:36.531502 916722 solver.cpp:218] Iteration 1410000 (16.6384 iter/s, 30.051s/500 iters), loss = 0.101148
I0830 09:00:36.531556 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101154 (* 1 = 0.101154 loss)
I0830 09:00:36.531564 916722 sgd_solver.cpp:106] Iteration 1410000, lr = 0.01
I0830 09:01:06.555052 916722 solver.cpp:218] Iteration 1410500 (16.6537 iter/s, 30.0233s/500 iters), loss = 0.0829916
I0830 09:01:06.555109 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0829975 (* 1 = 0.0829975 loss)
I0830 09:01:06.555116 916722 sgd_solver.cpp:106] Iteration 1410500, lr = 0.01
I0830 09:01:36.581239 916722 solver.cpp:218] Iteration 1411000 (16.6522 iter/s, 30.026s/500 iters), loss = 0.0256643
I0830 09:01:36.581291 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0256703 (* 1 = 0.0256703 loss)
I0830 09:01:36.581300 916722 sgd_solver.cpp:106] Iteration 1411000, lr = 0.01
I0830 09:02:06.593485 916722 solver.cpp:218] Iteration 1411500 (16.66 iter/s, 30.012s/500 iters), loss = 0.113058
I0830 09:02:06.593544 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.113064 (* 1 = 0.113064 loss)
I0830 09:02:06.593551 916722 sgd_solver.cpp:106] Iteration 1411500, lr = 0.01
I0830 09:02:36.606379 916722 solver.cpp:218] Iteration 1412000 (16.6596 iter/s, 30.0127s/500 iters), loss = 0.128553
I0830 09:02:36.606436 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128559 (* 1 = 0.128559 loss)
I0830 09:02:36.606443 916722 sgd_solver.cpp:106] Iteration 1412000, lr = 0.01
I0830 09:03:06.606662 916722 solver.cpp:218] Iteration 1412500 (16.6666 iter/s, 30.0001s/500 iters), loss = 0.109823
I0830 09:03:06.606720 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109829 (* 1 = 0.109829 loss)
I0830 09:03:06.606729 916722 sgd_solver.cpp:106] Iteration 1412500, lr = 0.01
I0830 09:03:36.608367 916722 solver.cpp:218] Iteration 1413000 (16.6658 iter/s, 30.0015s/500 iters), loss = 0.344046
I0830 09:03:36.608420 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.344052 (* 1 = 0.344052 loss)
I0830 09:03:36.608446 916722 sgd_solver.cpp:106] Iteration 1413000, lr = 0.01
I0830 09:04:06.612617 916722 solver.cpp:218] Iteration 1413500 (16.6644 iter/s, 30.004s/500 iters), loss = 0.145499
I0830 09:04:06.612679 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.145505 (* 1 = 0.145505 loss)
I0830 09:04:06.612689 916722 sgd_solver.cpp:106] Iteration 1413500, lr = 0.01
I0830 09:04:36.632537 916722 solver.cpp:218] Iteration 1414000 (16.6557 iter/s, 30.0197s/500 iters), loss = 0.18006
I0830 09:04:36.632599 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.180066 (* 1 = 0.180066 loss)
I0830 09:04:36.632611 916722 sgd_solver.cpp:106] Iteration 1414000, lr = 0.01
I0830 09:05:06.642248 916722 solver.cpp:218] Iteration 1414500 (16.6614 iter/s, 30.0095s/500 iters), loss = 0.115
I0830 09:05:06.642305 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115006 (* 1 = 0.115006 loss)
I0830 09:05:06.642313 916722 sgd_solver.cpp:106] Iteration 1414500, lr = 0.01
I0830 09:05:36.660488 916722 solver.cpp:218] Iteration 1415000 (16.6567 iter/s, 30.018s/500 iters), loss = 0.065877
I0830 09:05:36.660544 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.065883 (* 1 = 0.065883 loss)
I0830 09:05:36.660553 916722 sgd_solver.cpp:106] Iteration 1415000, lr = 0.01
I0830 09:06:06.674274 916722 solver.cpp:218] Iteration 1415500 (16.6591 iter/s, 30.0136s/500 iters), loss = 0.133471
I0830 09:06:06.674325 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133477 (* 1 = 0.133477 loss)
I0830 09:06:06.674335 916722 sgd_solver.cpp:106] Iteration 1415500, lr = 0.01
I0830 09:06:36.688311 916722 solver.cpp:218] Iteration 1416000 (16.659 iter/s, 30.0138s/500 iters), loss = 0.0770715
I0830 09:06:36.688369 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0770776 (* 1 = 0.0770776 loss)
I0830 09:06:36.688376 916722 sgd_solver.cpp:106] Iteration 1416000, lr = 0.01
I0830 09:07:06.672564 916722 solver.cpp:218] Iteration 1416500 (16.6755 iter/s, 29.984s/500 iters), loss = 0.0831584
I0830 09:07:06.672621 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0831646 (* 1 = 0.0831646 loss)
I0830 09:07:06.672631 916722 sgd_solver.cpp:106] Iteration 1416500, lr = 0.01
I0830 09:07:36.672225 916722 solver.cpp:218] Iteration 1417000 (16.667 iter/s, 29.9994s/500 iters), loss = 0.198481
I0830 09:07:36.672283 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.198487 (* 1 = 0.198487 loss)
I0830 09:07:36.672291 916722 sgd_solver.cpp:106] Iteration 1417000, lr = 0.01
I0830 09:08:06.671228 916722 solver.cpp:218] Iteration 1417500 (16.6673 iter/s, 29.9988s/500 iters), loss = 0.201824
I0830 09:08:06.671279 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.20183 (* 1 = 0.20183 loss)
I0830 09:08:06.671290 916722 sgd_solver.cpp:106] Iteration 1417500, lr = 0.01
I0830 09:08:36.662238 916722 solver.cpp:218] Iteration 1418000 (16.6718 iter/s, 29.9908s/500 iters), loss = 0.0392267
I0830 09:08:36.662299 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0392327 (* 1 = 0.0392327 loss)
I0830 09:08:36.662308 916722 sgd_solver.cpp:106] Iteration 1418000, lr = 0.01
I0830 09:09:06.677008 916722 solver.cpp:218] Iteration 1418500 (16.6586 iter/s, 30.0146s/500 iters), loss = 0.177861
I0830 09:09:06.677064 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.177867 (* 1 = 0.177867 loss)
I0830 09:09:06.677073 916722 sgd_solver.cpp:106] Iteration 1418500, lr = 0.01
I0830 09:09:36.666049 916722 solver.cpp:218] Iteration 1419000 (16.6729 iter/s, 29.9888s/500 iters), loss = 0.310851
I0830 09:09:36.666098 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.310857 (* 1 = 0.310857 loss)
I0830 09:09:36.666108 916722 sgd_solver.cpp:106] Iteration 1419000, lr = 0.01
I0830 09:10:06.666349 916722 solver.cpp:218] Iteration 1419500 (16.6666 iter/s, 30.0001s/500 iters), loss = 0.141798
I0830 09:10:06.666406 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.141804 (* 1 = 0.141804 loss)
I0830 09:10:06.666414 916722 sgd_solver.cpp:106] Iteration 1419500, lr = 0.01
I0830 09:10:36.695969 916722 solver.cpp:218] Iteration 1420000 (16.6503 iter/s, 30.0294s/500 iters), loss = 0.182338
I0830 09:10:36.696022 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.182344 (* 1 = 0.182344 loss)
I0830 09:10:36.696030 916722 sgd_solver.cpp:106] Iteration 1420000, lr = 0.01
I0830 09:11:06.698195 916722 solver.cpp:218] Iteration 1420500 (16.6655 iter/s, 30.002s/500 iters), loss = 0.206924
I0830 09:11:06.698259 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.20693 (* 1 = 0.20693 loss)
I0830 09:11:06.698272 916722 sgd_solver.cpp:106] Iteration 1420500, lr = 0.01
I0830 09:11:36.712850 916722 solver.cpp:218] Iteration 1421000 (16.6587 iter/s, 30.0144s/500 iters), loss = 0.12422
I0830 09:11:36.712906 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.124226 (* 1 = 0.124226 loss)
I0830 09:11:36.712913 916722 sgd_solver.cpp:106] Iteration 1421000, lr = 0.01
I0830 09:12:06.723353 916722 solver.cpp:218] Iteration 1421500 (16.661 iter/s, 30.0103s/500 iters), loss = 0.118485
I0830 09:12:06.723412 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.118491 (* 1 = 0.118491 loss)
I0830 09:12:06.723420 916722 sgd_solver.cpp:106] Iteration 1421500, lr = 0.01
I0830 09:12:36.728781 916722 solver.cpp:218] Iteration 1422000 (16.6638 iter/s, 30.0052s/500 iters), loss = 0.139137
I0830 09:12:36.728840 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139143 (* 1 = 0.139143 loss)
I0830 09:12:36.728849 916722 sgd_solver.cpp:106] Iteration 1422000, lr = 0.01
I0830 09:13:06.733297 916722 solver.cpp:218] Iteration 1422500 (16.6643 iter/s, 30.0043s/500 iters), loss = 0.234308
I0830 09:13:06.733355 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.234314 (* 1 = 0.234314 loss)
I0830 09:13:06.733364 916722 sgd_solver.cpp:106] Iteration 1422500, lr = 0.01
I0830 09:13:36.744539 916722 solver.cpp:218] Iteration 1423000 (16.6605 iter/s, 30.011s/500 iters), loss = 0.0913626
I0830 09:13:36.744594 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0913685 (* 1 = 0.0913685 loss)
I0830 09:13:36.744603 916722 sgd_solver.cpp:106] Iteration 1423000, lr = 0.01
I0830 09:14:06.749675 916722 solver.cpp:218] Iteration 1423500 (16.6639 iter/s, 30.0049s/500 iters), loss = 0.178147
I0830 09:14:06.749730 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.178153 (* 1 = 0.178153 loss)
I0830 09:14:06.749738 916722 sgd_solver.cpp:106] Iteration 1423500, lr = 0.01
I0830 09:14:36.783435 916722 solver.cpp:218] Iteration 1424000 (16.648 iter/s, 30.0336s/500 iters), loss = 0.168775
I0830 09:14:36.783489 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.16878 (* 1 = 0.16878 loss)
I0830 09:14:36.783497 916722 sgd_solver.cpp:106] Iteration 1424000, lr = 0.01
I0830 09:15:06.832545 916722 solver.cpp:218] Iteration 1424500 (16.6395 iter/s, 30.0489s/500 iters), loss = 0.239515
I0830 09:15:06.832598 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.239521 (* 1 = 0.239521 loss)
I0830 09:15:06.832607 916722 sgd_solver.cpp:106] Iteration 1424500, lr = 0.01
I0830 09:15:36.864689 916722 solver.cpp:218] Iteration 1425000 (16.6489 iter/s, 30.0319s/500 iters), loss = 0.427858
I0830 09:15:36.864756 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.427863 (* 1 = 0.427863 loss)
I0830 09:15:36.864775 916722 sgd_solver.cpp:106] Iteration 1425000, lr = 0.01
I0830 09:16:06.898352 916722 solver.cpp:218] Iteration 1425500 (16.6481 iter/s, 30.0334s/500 iters), loss = 0.14778
I0830 09:16:06.898409 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.147786 (* 1 = 0.147786 loss)
I0830 09:16:06.898417 916722 sgd_solver.cpp:106] Iteration 1425500, lr = 0.01
I0830 09:16:36.929677 916722 solver.cpp:218] Iteration 1426000 (16.6494 iter/s, 30.0311s/500 iters), loss = 0.123317
I0830 09:16:36.929735 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.123323 (* 1 = 0.123323 loss)
I0830 09:16:36.929744 916722 sgd_solver.cpp:106] Iteration 1426000, lr = 0.01
I0830 09:17:06.962209 916722 solver.cpp:218] Iteration 1426500 (16.6487 iter/s, 30.0323s/500 iters), loss = 0.14209
I0830 09:17:06.962270 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.142096 (* 1 = 0.142096 loss)
I0830 09:17:06.962278 916722 sgd_solver.cpp:106] Iteration 1426500, lr = 0.01
I0830 09:17:36.997550 916722 solver.cpp:218] Iteration 1427000 (16.6463 iter/s, 30.0368s/500 iters), loss = 0.239825
I0830 09:17:36.997614 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.239831 (* 1 = 0.239831 loss)
I0830 09:17:36.997622 916722 sgd_solver.cpp:106] Iteration 1427000, lr = 0.01
I0830 09:18:07.041364 916722 solver.cpp:218] Iteration 1427500 (16.6414 iter/s, 30.0455s/500 iters), loss = 0.0805522
I0830 09:18:07.041422 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0805578 (* 1 = 0.0805578 loss)
I0830 09:18:07.041431 916722 sgd_solver.cpp:106] Iteration 1427500, lr = 0.01
I0830 09:18:37.111702 916722 solver.cpp:218] Iteration 1428000 (16.6268 iter/s, 30.072s/500 iters), loss = 0.290566
I0830 09:18:37.111755 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.290571 (* 1 = 0.290571 loss)
I0830 09:18:37.111764 916722 sgd_solver.cpp:106] Iteration 1428000, lr = 0.01
I0830 09:19:07.156203 916722 solver.cpp:218] Iteration 1428500 (16.6411 iter/s, 30.0461s/500 iters), loss = 0.090269
I0830 09:19:07.156260 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0902745 (* 1 = 0.0902745 loss)
I0830 09:19:07.156268 916722 sgd_solver.cpp:106] Iteration 1428500, lr = 0.01
I0830 09:19:37.219017 916722 solver.cpp:218] Iteration 1429000 (16.631 iter/s, 30.0643s/500 iters), loss = 0.0875937
I0830 09:19:37.219069 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0875992 (* 1 = 0.0875992 loss)
I0830 09:19:37.219077 916722 sgd_solver.cpp:106] Iteration 1429000, lr = 0.01
I0830 09:20:07.273931 916722 solver.cpp:218] Iteration 1429500 (16.6354 iter/s, 30.0563s/500 iters), loss = 0.147107
I0830 09:20:07.273986 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.147112 (* 1 = 0.147112 loss)
I0830 09:20:07.273995 916722 sgd_solver.cpp:106] Iteration 1429500, lr = 0.01
I0830 09:20:37.319801 916722 solver.cpp:218] Iteration 1430000 (16.6405 iter/s, 30.0472s/500 iters), loss = 0.254165
I0830 09:20:37.319855 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.25417 (* 1 = 0.25417 loss)
I0830 09:20:37.319864 916722 sgd_solver.cpp:106] Iteration 1430000, lr = 0.01
I0830 09:21:07.388167 916722 solver.cpp:218] Iteration 1430500 (16.6281 iter/s, 30.0696s/500 iters), loss = 0.227656
I0830 09:21:07.388222 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.227662 (* 1 = 0.227662 loss)
I0830 09:21:07.388231 916722 sgd_solver.cpp:106] Iteration 1430500, lr = 0.01
I0830 09:21:37.434415 916722 solver.cpp:218] Iteration 1431000 (16.6404 iter/s, 30.0474s/500 iters), loss = 0.0207241
I0830 09:21:37.434468 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0207297 (* 1 = 0.0207297 loss)
I0830 09:21:37.434476 916722 sgd_solver.cpp:106] Iteration 1431000, lr = 0.01
I0830 09:22:07.509987 916722 solver.cpp:218] Iteration 1431500 (16.6242 iter/s, 30.0767s/500 iters), loss = 0.166152
I0830 09:22:07.510043 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.166158 (* 1 = 0.166158 loss)
I0830 09:22:07.510052 916722 sgd_solver.cpp:106] Iteration 1431500, lr = 0.01
I0830 09:22:37.561539 916722 solver.cpp:218] Iteration 1432000 (16.6375 iter/s, 30.0526s/500 iters), loss = 0.106524
I0830 09:22:37.561595 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.10653 (* 1 = 0.10653 loss)
I0830 09:22:37.561604 916722 sgd_solver.cpp:106] Iteration 1432000, lr = 0.01
I0830 09:23:07.631811 916722 solver.cpp:218] Iteration 1432500 (16.6272 iter/s, 30.0713s/500 iters), loss = 0.190444
I0830 09:23:07.631868 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.19045 (* 1 = 0.19045 loss)
I0830 09:23:07.631876 916722 sgd_solver.cpp:106] Iteration 1432500, lr = 0.01
I0830 09:23:37.698606 916722 solver.cpp:218] Iteration 1433000 (16.6291 iter/s, 30.0677s/500 iters), loss = 0.454632
I0830 09:23:37.698659 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.454637 (* 1 = 0.454637 loss)
I0830 09:23:37.698668 916722 sgd_solver.cpp:106] Iteration 1433000, lr = 0.01
I0830 09:24:07.774641 916722 solver.cpp:218] Iteration 1433500 (16.624 iter/s, 30.0769s/500 iters), loss = 0.301138
I0830 09:24:07.774696 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.301144 (* 1 = 0.301144 loss)
I0830 09:24:07.774705 916722 sgd_solver.cpp:106] Iteration 1433500, lr = 0.01
I0830 09:24:37.857743 916722 solver.cpp:218] Iteration 1434000 (16.6202 iter/s, 30.084s/500 iters), loss = 0.0258326
I0830 09:24:37.857805 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0258378 (* 1 = 0.0258378 loss)
I0830 09:24:37.857811 916722 sgd_solver.cpp:106] Iteration 1434000, lr = 0.01
I0830 09:25:07.927405 916722 solver.cpp:218] Iteration 1434500 (16.6276 iter/s, 30.0705s/500 iters), loss = 0.140911
I0830 09:25:07.927462 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.140916 (* 1 = 0.140916 loss)
I0830 09:25:07.927470 916722 sgd_solver.cpp:106] Iteration 1434500, lr = 0.01
I0830 09:25:37.982831 916722 solver.cpp:218] Iteration 1435000 (16.6355 iter/s, 30.0562s/500 iters), loss = 0.303615
I0830 09:25:37.982882 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.30362 (* 1 = 0.30362 loss)
I0830 09:25:37.982892 916722 sgd_solver.cpp:106] Iteration 1435000, lr = 0.01
I0830 09:26:08.057770 916722 solver.cpp:218] Iteration 1435500 (16.6247 iter/s, 30.0757s/500 iters), loss = 0.206548
I0830 09:26:08.057827 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.206554 (* 1 = 0.206554 loss)
I0830 09:26:08.057837 916722 sgd_solver.cpp:106] Iteration 1435500, lr = 0.01
I0830 09:26:38.145223 916722 solver.cpp:218] Iteration 1436000 (16.6178 iter/s, 30.0881s/500 iters), loss = 0.178616
I0830 09:26:38.145279 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.178621 (* 1 = 0.178621 loss)
I0830 09:26:38.145287 916722 sgd_solver.cpp:106] Iteration 1436000, lr = 0.01
I0830 09:27:08.205487 916722 solver.cpp:218] Iteration 1436500 (16.6329 iter/s, 30.0609s/500 iters), loss = 0.219319
I0830 09:27:08.205543 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.219325 (* 1 = 0.219325 loss)
I0830 09:27:08.205550 916722 sgd_solver.cpp:106] Iteration 1436500, lr = 0.01
I0830 09:27:38.260818 916722 solver.cpp:218] Iteration 1437000 (16.6356 iter/s, 30.056s/500 iters), loss = 0.128291
I0830 09:27:38.260869 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128297 (* 1 = 0.128297 loss)
I0830 09:27:38.260877 916722 sgd_solver.cpp:106] Iteration 1437000, lr = 0.01
I0830 09:28:08.345547 916722 solver.cpp:218] Iteration 1437500 (16.6194 iter/s, 30.0853s/500 iters), loss = 0.125231
I0830 09:28:08.345602 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.125237 (* 1 = 0.125237 loss)
I0830 09:28:08.345611 916722 sgd_solver.cpp:106] Iteration 1437500, lr = 0.01
I0830 09:28:38.418766 916722 solver.cpp:218] Iteration 1438000 (16.6258 iter/s, 30.0738s/500 iters), loss = 0.180294
I0830 09:28:38.418817 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.180299 (* 1 = 0.180299 loss)
I0830 09:28:38.418823 916722 sgd_solver.cpp:106] Iteration 1438000, lr = 0.01
I0830 09:29:08.499207 916722 solver.cpp:218] Iteration 1438500 (16.6218 iter/s, 30.081s/500 iters), loss = 0.0517761
I0830 09:29:08.499258 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0517817 (* 1 = 0.0517817 loss)
I0830 09:29:08.499266 916722 sgd_solver.cpp:106] Iteration 1438500, lr = 0.01
I0830 09:29:38.589598 916722 solver.cpp:218] Iteration 1439000 (16.6163 iter/s, 30.0909s/500 iters), loss = 0.0804508
I0830 09:29:38.589653 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0804564 (* 1 = 0.0804564 loss)
I0830 09:29:38.589661 916722 sgd_solver.cpp:106] Iteration 1439000, lr = 0.01
I0830 09:30:08.651051 916722 solver.cpp:218] Iteration 1439500 (16.6323 iter/s, 30.0619s/500 iters), loss = 0.0841022
I0830 09:30:08.651106 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0841077 (* 1 = 0.0841077 loss)
I0830 09:30:08.651114 916722 sgd_solver.cpp:106] Iteration 1439500, lr = 0.01
I0830 09:30:38.716109 916722 solver.cpp:218] Iteration 1440000 (16.6303 iter/s, 30.0655s/500 iters), loss = 0.0317046
I0830 09:30:38.716162 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0317101 (* 1 = 0.0317101 loss)
I0830 09:30:38.716171 916722 sgd_solver.cpp:106] Iteration 1440000, lr = 0.01
I0830 09:31:08.782618 916722 solver.cpp:218] Iteration 1440500 (16.6296 iter/s, 30.0669s/500 iters), loss = 0.218214
I0830 09:31:08.782685 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.21822 (* 1 = 0.21822 loss)
I0830 09:31:08.782692 916722 sgd_solver.cpp:106] Iteration 1440500, lr = 0.01
I0830 09:31:38.848513 916722 solver.cpp:218] Iteration 1441000 (16.6299 iter/s, 30.0663s/500 iters), loss = 0.0384718
I0830 09:31:38.848564 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0384773 (* 1 = 0.0384773 loss)
I0830 09:31:38.848572 916722 sgd_solver.cpp:106] Iteration 1441000, lr = 0.01
I0830 09:32:08.903543 916722 solver.cpp:218] Iteration 1441500 (16.6359 iter/s, 30.0554s/500 iters), loss = 0.0541
I0830 09:32:08.903601 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0541055 (* 1 = 0.0541055 loss)
I0830 09:32:08.903609 916722 sgd_solver.cpp:106] Iteration 1441500, lr = 0.01
I0830 09:32:38.950095 916722 solver.cpp:218] Iteration 1442000 (16.6406 iter/s, 30.0469s/500 iters), loss = 0.0515301
I0830 09:32:38.950150 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0515354 (* 1 = 0.0515354 loss)
I0830 09:32:38.950157 916722 sgd_solver.cpp:106] Iteration 1442000, lr = 0.01
I0830 09:33:08.995433 916722 solver.cpp:218] Iteration 1442500 (16.6413 iter/s, 30.0457s/500 iters), loss = 0.153347
I0830 09:33:08.995488 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.153352 (* 1 = 0.153352 loss)
I0830 09:33:08.995497 916722 sgd_solver.cpp:106] Iteration 1442500, lr = 0.01
I0830 09:33:39.050431 916722 solver.cpp:218] Iteration 1443000 (16.636 iter/s, 30.0553s/500 iters), loss = 0.147851
I0830 09:33:39.050480 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.147857 (* 1 = 0.147857 loss)
I0830 09:33:39.050488 916722 sgd_solver.cpp:106] Iteration 1443000, lr = 0.01
I0830 09:34:09.079623 916722 solver.cpp:218] Iteration 1443500 (16.6503 iter/s, 30.0295s/500 iters), loss = 0.387925
I0830 09:34:09.079680 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.38793 (* 1 = 0.38793 loss)
I0830 09:34:09.079689 916722 sgd_solver.cpp:106] Iteration 1443500, lr = 0.01
I0830 09:34:39.106915 916722 solver.cpp:218] Iteration 1444000 (16.6513 iter/s, 30.0276s/500 iters), loss = 0.111703
I0830 09:34:39.106969 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111708 (* 1 = 0.111708 loss)
I0830 09:34:39.106977 916722 sgd_solver.cpp:106] Iteration 1444000, lr = 0.01
I0830 09:35:09.154345 916722 solver.cpp:218] Iteration 1444500 (16.6402 iter/s, 30.0477s/500 iters), loss = 0.0116688
I0830 09:35:09.154402 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0116743 (* 1 = 0.0116743 loss)
I0830 09:35:09.154410 916722 sgd_solver.cpp:106] Iteration 1444500, lr = 0.01
I0830 09:35:39.201524 916722 solver.cpp:218] Iteration 1445000 (16.6403 iter/s, 30.0475s/500 iters), loss = 0.0175447
I0830 09:35:39.201577 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0175502 (* 1 = 0.0175502 loss)
I0830 09:35:39.201586 916722 sgd_solver.cpp:106] Iteration 1445000, lr = 0.01
I0830 09:36:09.232406 916722 solver.cpp:218] Iteration 1445500 (16.6494 iter/s, 30.0312s/500 iters), loss = 0.100664
I0830 09:36:09.232472 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.10067 (* 1 = 0.10067 loss)
I0830 09:36:09.232481 916722 sgd_solver.cpp:106] Iteration 1445500, lr = 0.01
I0830 09:36:39.288365 916722 solver.cpp:218] Iteration 1446000 (16.6355 iter/s, 30.0562s/500 iters), loss = 0.160518
I0830 09:36:39.288429 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.160523 (* 1 = 0.160523 loss)
I0830 09:36:39.288437 916722 sgd_solver.cpp:106] Iteration 1446000, lr = 0.01
I0830 09:37:09.336683 916722 solver.cpp:218] Iteration 1446500 (16.6397 iter/s, 30.0486s/500 iters), loss = 0.102172
I0830 09:37:09.336740 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.102177 (* 1 = 0.102177 loss)
I0830 09:37:09.336760 916722 sgd_solver.cpp:106] Iteration 1446500, lr = 0.01
I0830 09:37:39.360391 916722 solver.cpp:218] Iteration 1447000 (16.6534 iter/s, 30.024s/500 iters), loss = 0.172653
I0830 09:37:39.360463 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.172659 (* 1 = 0.172659 loss)
I0830 09:37:39.360471 916722 sgd_solver.cpp:106] Iteration 1447000, lr = 0.01
I0830 09:38:09.408835 916722 solver.cpp:218] Iteration 1447500 (16.6397 iter/s, 30.0487s/500 iters), loss = 0.284903
I0830 09:38:09.408886 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.284908 (* 1 = 0.284908 loss)
I0830 09:38:09.408895 916722 sgd_solver.cpp:106] Iteration 1447500, lr = 0.01
I0830 09:38:39.465464 916722 solver.cpp:218] Iteration 1448000 (16.6351 iter/s, 30.0569s/500 iters), loss = 0.197683
I0830 09:38:39.465517 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.197688 (* 1 = 0.197688 loss)
I0830 09:38:39.465524 916722 sgd_solver.cpp:106] Iteration 1448000, lr = 0.01
I0830 09:39:09.533741 916722 solver.cpp:218] Iteration 1448500 (16.6287 iter/s, 30.0685s/500 iters), loss = 0.167029
I0830 09:39:09.533797 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.167035 (* 1 = 0.167035 loss)
I0830 09:39:09.533807 916722 sgd_solver.cpp:106] Iteration 1448500, lr = 0.01
I0830 09:39:39.606992 916722 solver.cpp:218] Iteration 1449000 (16.626 iter/s, 30.0735s/500 iters), loss = 0.024598
I0830 09:39:39.607046 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0246034 (* 1 = 0.0246034 loss)
I0830 09:39:39.607055 916722 sgd_solver.cpp:106] Iteration 1449000, lr = 0.01
I0830 09:40:09.689561 916722 solver.cpp:218] Iteration 1449500 (16.6208 iter/s, 30.0828s/500 iters), loss = 0.412241
I0830 09:40:09.689616 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.412247 (* 1 = 0.412247 loss)
I0830 09:40:09.689625 916722 sgd_solver.cpp:106] Iteration 1449500, lr = 0.01
I0830 09:40:39.723664 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_1450000.caffemodel
I0830 09:40:39.743161 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_1450000.solverstate
I0830 09:40:39.749277 916722 solver.cpp:330] Iteration 1450000, Testing net (#0)
I0830 09:40:55.115507 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8899
I0830 09:40:55.115550 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.364432 (* 1 = 0.364432 loss)
I0830 09:40:55.174175 916722 solver.cpp:218] Iteration 1450000 (10.9927 iter/s, 45.4849s/500 iters), loss = 0.130187
I0830 09:40:55.174201 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130193 (* 1 = 0.130193 loss)
I0830 09:40:55.174208 916722 sgd_solver.cpp:106] Iteration 1450000, lr = 0.01
I0830 09:41:25.106235 916722 solver.cpp:218] Iteration 1450500 (16.7044 iter/s, 29.9322s/500 iters), loss = 0.327627
I0830 09:41:25.106293 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.327633 (* 1 = 0.327633 loss)
I0830 09:41:25.106302 916722 sgd_solver.cpp:106] Iteration 1450500, lr = 0.01
I0830 09:41:55.140254 916722 solver.cpp:218] Iteration 1451000 (16.6477 iter/s, 30.0342s/500 iters), loss = 0.32584
I0830 09:41:55.140309 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.325845 (* 1 = 0.325845 loss)
I0830 09:41:55.140318 916722 sgd_solver.cpp:106] Iteration 1451000, lr = 0.01
I0830 09:42:25.232440 916722 solver.cpp:218] Iteration 1451500 (16.6155 iter/s, 30.0924s/500 iters), loss = 0.0166389
I0830 09:42:25.232494 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0166442 (* 1 = 0.0166442 loss)
I0830 09:42:25.232502 916722 sgd_solver.cpp:106] Iteration 1451500, lr = 0.01
I0830 09:42:55.321841 916722 solver.cpp:218] Iteration 1452000 (16.6171 iter/s, 30.0896s/500 iters), loss = 0.0405797
I0830 09:42:55.321897 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.040585 (* 1 = 0.040585 loss)
I0830 09:42:55.321904 916722 sgd_solver.cpp:106] Iteration 1452000, lr = 0.01
I0830 09:43:25.403781 916722 solver.cpp:218] Iteration 1452500 (16.6212 iter/s, 30.0821s/500 iters), loss = 0.220837
I0830 09:43:25.403848 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.220842 (* 1 = 0.220842 loss)
I0830 09:43:25.403861 916722 sgd_solver.cpp:106] Iteration 1452500, lr = 0.01
I0830 09:43:55.489251 916722 solver.cpp:218] Iteration 1453000 (16.6192 iter/s, 30.0856s/500 iters), loss = 0.12941
I0830 09:43:55.489305 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.129415 (* 1 = 0.129415 loss)
I0830 09:43:55.489312 916722 sgd_solver.cpp:106] Iteration 1453000, lr = 0.01
I0830 09:44:25.589583 916722 solver.cpp:218] Iteration 1453500 (16.611 iter/s, 30.1005s/500 iters), loss = 0.0325926
I0830 09:44:25.589639 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0325976 (* 1 = 0.0325976 loss)
I0830 09:44:25.589648 916722 sgd_solver.cpp:106] Iteration 1453500, lr = 0.01
I0830 09:44:55.679466 916722 solver.cpp:218] Iteration 1454000 (16.6168 iter/s, 30.09s/500 iters), loss = 0.0867465
I0830 09:44:55.679517 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0867515 (* 1 = 0.0867515 loss)
I0830 09:44:55.679524 916722 sgd_solver.cpp:106] Iteration 1454000, lr = 0.01
I0830 09:45:25.799782 916722 solver.cpp:218] Iteration 1454500 (16.6 iter/s, 30.1205s/500 iters), loss = 0.128319
I0830 09:45:25.799839 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128324 (* 1 = 0.128324 loss)
I0830 09:45:25.799849 916722 sgd_solver.cpp:106] Iteration 1454500, lr = 0.01
I0830 09:45:55.901278 916722 solver.cpp:218] Iteration 1455000 (16.6104 iter/s, 30.1016s/500 iters), loss = 0.073902
I0830 09:45:55.901333 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0739067 (* 1 = 0.0739067 loss)
I0830 09:45:55.901341 916722 sgd_solver.cpp:106] Iteration 1455000, lr = 0.01
I0830 09:46:25.983783 916722 solver.cpp:218] Iteration 1455500 (16.6209 iter/s, 30.0826s/500 iters), loss = 0.308103
I0830 09:46:25.983840 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.308107 (* 1 = 0.308107 loss)
I0830 09:46:25.983848 916722 sgd_solver.cpp:106] Iteration 1455500, lr = 0.01
I0830 09:46:56.063881 916722 solver.cpp:218] Iteration 1456000 (16.6222 iter/s, 30.0802s/500 iters), loss = 0.0353477
I0830 09:46:56.063941 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0353526 (* 1 = 0.0353526 loss)
I0830 09:46:56.063948 916722 sgd_solver.cpp:106] Iteration 1456000, lr = 0.01
I0830 09:47:26.162899 916722 solver.cpp:218] Iteration 1456500 (16.6118 iter/s, 30.0991s/500 iters), loss = 0.170886
I0830 09:47:26.162955 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.170891 (* 1 = 0.170891 loss)
I0830 09:47:26.162964 916722 sgd_solver.cpp:106] Iteration 1456500, lr = 0.01
I0830 09:47:56.234472 916722 solver.cpp:218] Iteration 1457000 (16.6269 iter/s, 30.0717s/500 iters), loss = 0.0258366
I0830 09:47:56.234526 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0258416 (* 1 = 0.0258416 loss)
I0830 09:47:56.234534 916722 sgd_solver.cpp:106] Iteration 1457000, lr = 0.01
I0830 09:48:26.320008 916722 solver.cpp:218] Iteration 1457500 (16.6192 iter/s, 30.0857s/500 iters), loss = 0.220396
I0830 09:48:26.320062 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.220401 (* 1 = 0.220401 loss)
I0830 09:48:26.320071 916722 sgd_solver.cpp:106] Iteration 1457500, lr = 0.01
I0830 09:48:56.394523 916722 solver.cpp:218] Iteration 1458000 (16.6253 iter/s, 30.0746s/500 iters), loss = 0.030829
I0830 09:48:56.394577 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0308338 (* 1 = 0.0308338 loss)
I0830 09:48:56.394584 916722 sgd_solver.cpp:106] Iteration 1458000, lr = 0.01
I0830 09:49:26.428525 916722 solver.cpp:218] Iteration 1458500 (16.6477 iter/s, 30.0341s/500 iters), loss = 0.221386
I0830 09:49:26.428582 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.22139 (* 1 = 0.22139 loss)
I0830 09:49:26.428591 916722 sgd_solver.cpp:106] Iteration 1458500, lr = 0.01
I0830 09:49:56.466163 916722 solver.cpp:218] Iteration 1459000 (16.6457 iter/s, 30.0378s/500 iters), loss = 0.166892
I0830 09:49:56.466229 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.166896 (* 1 = 0.166896 loss)
I0830 09:49:56.466241 916722 sgd_solver.cpp:106] Iteration 1459000, lr = 0.01
I0830 09:50:26.515539 916722 solver.cpp:218] Iteration 1459500 (16.6392 iter/s, 30.0495s/500 iters), loss = 0.174056
I0830 09:50:26.515596 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.17406 (* 1 = 0.17406 loss)
I0830 09:50:26.515604 916722 sgd_solver.cpp:106] Iteration 1459500, lr = 0.01
I0830 09:50:56.579360 916722 solver.cpp:218] Iteration 1460000 (16.6312 iter/s, 30.0639s/500 iters), loss = 0.048886
I0830 09:50:56.579414 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0488909 (* 1 = 0.0488909 loss)
I0830 09:50:56.579422 916722 sgd_solver.cpp:106] Iteration 1460000, lr = 0.01
I0830 09:51:26.680174 916722 solver.cpp:218] Iteration 1460500 (16.6108 iter/s, 30.1009s/500 iters), loss = 0.157382
I0830 09:51:26.680225 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.157386 (* 1 = 0.157386 loss)
I0830 09:51:26.680234 916722 sgd_solver.cpp:106] Iteration 1460500, lr = 0.01
I0830 09:51:56.777124 916722 solver.cpp:218] Iteration 1461000 (16.6131 iter/s, 30.0968s/500 iters), loss = 0.198878
I0830 09:51:56.777173 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.198882 (* 1 = 0.198882 loss)
I0830 09:51:56.777181 916722 sgd_solver.cpp:106] Iteration 1461000, lr = 0.01
I0830 09:52:26.878737 916722 solver.cpp:218] Iteration 1461500 (16.6105 iter/s, 30.1015s/500 iters), loss = 0.114223
I0830 09:52:26.878793 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.114227 (* 1 = 0.114227 loss)
I0830 09:52:26.878801 916722 sgd_solver.cpp:106] Iteration 1461500, lr = 0.01
I0830 09:52:56.976246 916722 solver.cpp:218] Iteration 1462000 (16.6128 iter/s, 30.0974s/500 iters), loss = 0.206467
I0830 09:52:56.976296 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.206472 (* 1 = 0.206472 loss)
I0830 09:52:56.976305 916722 sgd_solver.cpp:106] Iteration 1462000, lr = 0.01
I0830 09:53:27.096215 916722 solver.cpp:218] Iteration 1462500 (16.6004 iter/s, 30.1198s/500 iters), loss = 0.242105
I0830 09:53:27.096268 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.24211 (* 1 = 0.24211 loss)
I0830 09:53:27.096277 916722 sgd_solver.cpp:106] Iteration 1462500, lr = 0.01
I0830 09:53:57.218680 916722 solver.cpp:218] Iteration 1463000 (16.599 iter/s, 30.1223s/500 iters), loss = 0.0635324
I0830 09:53:57.218732 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0635372 (* 1 = 0.0635372 loss)
I0830 09:53:57.218740 916722 sgd_solver.cpp:106] Iteration 1463000, lr = 0.01
I0830 09:54:27.320924 916722 solver.cpp:218] Iteration 1463500 (16.6101 iter/s, 30.1021s/500 iters), loss = 0.216554
I0830 09:54:27.320981 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.216559 (* 1 = 0.216559 loss)
I0830 09:54:27.320988 916722 sgd_solver.cpp:106] Iteration 1463500, lr = 0.01
I0830 09:54:57.429970 916722 solver.cpp:218] Iteration 1464000 (16.6064 iter/s, 30.1089s/500 iters), loss = 0.15671
I0830 09:54:57.430028 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.156714 (* 1 = 0.156714 loss)
I0830 09:54:57.430037 916722 sgd_solver.cpp:106] Iteration 1464000, lr = 0.01
I0830 09:55:27.508987 916722 solver.cpp:218] Iteration 1464500 (16.6229 iter/s, 30.0789s/500 iters), loss = 0.0903626
I0830 09:55:27.509047 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0903673 (* 1 = 0.0903673 loss)
I0830 09:55:27.509055 916722 sgd_solver.cpp:106] Iteration 1464500, lr = 0.01
I0830 09:55:57.591007 916722 solver.cpp:218] Iteration 1465000 (16.6213 iter/s, 30.0819s/500 iters), loss = 0.183656
I0830 09:55:57.591061 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.183661 (* 1 = 0.183661 loss)
I0830 09:55:57.591069 916722 sgd_solver.cpp:106] Iteration 1465000, lr = 0.01
I0830 09:56:27.684070 916722 solver.cpp:218] Iteration 1465500 (16.6152 iter/s, 30.093s/500 iters), loss = 0.197204
I0830 09:56:27.684127 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.197208 (* 1 = 0.197208 loss)
I0830 09:56:27.684135 916722 sgd_solver.cpp:106] Iteration 1465500, lr = 0.01
I0830 09:56:57.772401 916722 solver.cpp:218] Iteration 1466000 (16.6178 iter/s, 30.0882s/500 iters), loss = 0.0687714
I0830 09:56:57.772485 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.068776 (* 1 = 0.068776 loss)
I0830 09:56:57.772495 916722 sgd_solver.cpp:106] Iteration 1466000, lr = 0.01
I0830 09:57:27.856629 916722 solver.cpp:218] Iteration 1466500 (16.6201 iter/s, 30.0841s/500 iters), loss = 0.0773472
I0830 09:57:27.856688 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0773519 (* 1 = 0.0773519 loss)
I0830 09:57:27.856698 916722 sgd_solver.cpp:106] Iteration 1466500, lr = 0.01
I0830 09:57:58.018102 916722 solver.cpp:218] Iteration 1467000 (16.5775 iter/s, 30.1614s/500 iters), loss = 0.10496
I0830 09:57:58.018162 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104964 (* 1 = 0.104964 loss)
I0830 09:57:58.018169 916722 sgd_solver.cpp:106] Iteration 1467000, lr = 0.01
I0830 09:58:28.186597 916722 solver.cpp:218] Iteration 1467500 (16.5736 iter/s, 30.1684s/500 iters), loss = 0.0694969
I0830 09:58:28.186655 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0695012 (* 1 = 0.0695012 loss)
I0830 09:58:28.186662 916722 sgd_solver.cpp:106] Iteration 1467500, lr = 0.01
I0830 09:58:58.364496 916722 solver.cpp:218] Iteration 1468000 (16.5684 iter/s, 30.1778s/500 iters), loss = 0.0421655
I0830 09:58:58.364555 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0421699 (* 1 = 0.0421699 loss)
I0830 09:58:58.364564 916722 sgd_solver.cpp:106] Iteration 1468000, lr = 0.01
I0830 09:59:28.566001 916722 solver.cpp:218] Iteration 1468500 (16.5555 iter/s, 30.2015s/500 iters), loss = 0.17607
I0830 09:59:28.566056 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.176074 (* 1 = 0.176074 loss)
I0830 09:59:28.566063 916722 sgd_solver.cpp:106] Iteration 1468500, lr = 0.01
I0830 09:59:58.771709 916722 solver.cpp:218] Iteration 1469000 (16.5532 iter/s, 30.2057s/500 iters), loss = 0.0356683
I0830 09:59:58.771768 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0356727 (* 1 = 0.0356727 loss)
I0830 09:59:58.771776 916722 sgd_solver.cpp:106] Iteration 1469000, lr = 0.01
I0830 10:00:28.990950 916722 solver.cpp:218] Iteration 1469500 (16.5458 iter/s, 30.2192s/500 iters), loss = 0.210599
I0830 10:00:28.991006 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.210603 (* 1 = 0.210603 loss)
I0830 10:00:28.991015 916722 sgd_solver.cpp:106] Iteration 1469500, lr = 0.01
I0830 10:00:59.209498 916722 solver.cpp:218] Iteration 1470000 (16.5461 iter/s, 30.2185s/500 iters), loss = 0.196745
I0830 10:00:59.209554 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.19675 (* 1 = 0.19675 loss)
I0830 10:00:59.209563 916722 sgd_solver.cpp:106] Iteration 1470000, lr = 0.01
I0830 10:01:29.429936 916722 solver.cpp:218] Iteration 1470500 (16.5451 iter/s, 30.2204s/500 iters), loss = 0.355218
I0830 10:01:29.429989 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.355223 (* 1 = 0.355223 loss)
I0830 10:01:29.429997 916722 sgd_solver.cpp:106] Iteration 1470500, lr = 0.01
I0830 10:01:59.638492 916722 solver.cpp:218] Iteration 1471000 (16.5516 iter/s, 30.2085s/500 iters), loss = 0.135647
I0830 10:01:59.638552 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.135651 (* 1 = 0.135651 loss)
I0830 10:01:59.638561 916722 sgd_solver.cpp:106] Iteration 1471000, lr = 0.01
I0830 10:02:29.822427 916722 solver.cpp:218] Iteration 1471500 (16.5651 iter/s, 30.1839s/500 iters), loss = 0.0897217
I0830 10:02:29.822489 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0897264 (* 1 = 0.0897264 loss)
I0830 10:02:29.822496 916722 sgd_solver.cpp:106] Iteration 1471500, lr = 0.01
I0830 10:03:00.063330 916722 solver.cpp:218] Iteration 1472000 (16.5339 iter/s, 30.2409s/500 iters), loss = 0.193241
I0830 10:03:00.063387 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.193246 (* 1 = 0.193246 loss)
I0830 10:03:00.063395 916722 sgd_solver.cpp:106] Iteration 1472000, lr = 0.01
I0830 10:03:30.276702 916722 solver.cpp:218] Iteration 1472500 (16.549 iter/s, 30.2134s/500 iters), loss = 0.433319
I0830 10:03:30.276777 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.433324 (* 1 = 0.433324 loss)
I0830 10:03:30.276787 916722 sgd_solver.cpp:106] Iteration 1472500, lr = 0.01
I0830 10:04:00.510015 916722 solver.cpp:218] Iteration 1473000 (16.5381 iter/s, 30.2333s/500 iters), loss = 0.0629067
I0830 10:04:00.510069 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0629115 (* 1 = 0.0629115 loss)
I0830 10:04:00.510077 916722 sgd_solver.cpp:106] Iteration 1473000, lr = 0.01
I0830 10:04:30.729946 916722 solver.cpp:218] Iteration 1473500 (16.5454 iter/s, 30.2199s/500 iters), loss = 0.272447
I0830 10:04:30.730002 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.272451 (* 1 = 0.272451 loss)
I0830 10:04:30.730011 916722 sgd_solver.cpp:106] Iteration 1473500, lr = 0.01
I0830 10:05:00.958135 916722 solver.cpp:218] Iteration 1474000 (16.5409 iter/s, 30.2282s/500 iters), loss = 0.101879
I0830 10:05:00.958191 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101884 (* 1 = 0.101884 loss)
I0830 10:05:00.958200 916722 sgd_solver.cpp:106] Iteration 1474000, lr = 0.01
I0830 10:05:31.182886 916722 solver.cpp:218] Iteration 1474500 (16.5427 iter/s, 30.2248s/500 iters), loss = 0.0903838
I0830 10:05:31.182940 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0903886 (* 1 = 0.0903886 loss)
I0830 10:05:31.182948 916722 sgd_solver.cpp:106] Iteration 1474500, lr = 0.01
I0830 10:06:01.388929 916722 solver.cpp:218] Iteration 1475000 (16.553 iter/s, 30.2061s/500 iters), loss = 0.09179
I0830 10:06:01.388988 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0917948 (* 1 = 0.0917948 loss)
I0830 10:06:01.388995 916722 sgd_solver.cpp:106] Iteration 1475000, lr = 0.01
I0830 10:06:31.617647 916722 solver.cpp:218] Iteration 1475500 (16.5406 iter/s, 30.2287s/500 iters), loss = 0.194376
I0830 10:06:31.617702 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.194381 (* 1 = 0.194381 loss)
I0830 10:06:31.617710 916722 sgd_solver.cpp:106] Iteration 1475500, lr = 0.01
I0830 10:07:01.810077 916722 solver.cpp:218] Iteration 1476000 (16.5604 iter/s, 30.1924s/500 iters), loss = 0.0613348
I0830 10:07:01.810134 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0613397 (* 1 = 0.0613397 loss)
I0830 10:07:01.810142 916722 sgd_solver.cpp:106] Iteration 1476000, lr = 0.01
I0830 10:07:32.007437 916722 solver.cpp:218] Iteration 1476500 (16.5577 iter/s, 30.1974s/500 iters), loss = 0.0662036
I0830 10:07:32.007491 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0662085 (* 1 = 0.0662085 loss)
I0830 10:07:32.007500 916722 sgd_solver.cpp:106] Iteration 1476500, lr = 0.01
I0830 10:08:02.240458 916722 solver.cpp:218] Iteration 1477000 (16.5382 iter/s, 30.233s/500 iters), loss = 0.310024
I0830 10:08:02.240528 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.310029 (* 1 = 0.310029 loss)
I0830 10:08:02.240536 916722 sgd_solver.cpp:106] Iteration 1477000, lr = 0.01
I0830 10:08:32.424059 916722 solver.cpp:218] Iteration 1477500 (16.5653 iter/s, 30.1836s/500 iters), loss = 0.239366
I0830 10:08:32.424119 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.239371 (* 1 = 0.239371 loss)
I0830 10:08:32.424127 916722 sgd_solver.cpp:106] Iteration 1477500, lr = 0.01
I0830 10:09:02.632431 916722 solver.cpp:218] Iteration 1478000 (16.5517 iter/s, 30.2084s/500 iters), loss = 0.355537
I0830 10:09:02.632485 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.355542 (* 1 = 0.355542 loss)
I0830 10:09:02.632493 916722 sgd_solver.cpp:106] Iteration 1478000, lr = 0.01
I0830 10:09:32.851861 916722 solver.cpp:218] Iteration 1478500 (16.5456 iter/s, 30.2195s/500 iters), loss = 0.26768
I0830 10:09:32.851917 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.267685 (* 1 = 0.267685 loss)
I0830 10:09:32.851927 916722 sgd_solver.cpp:106] Iteration 1478500, lr = 0.01
I0830 10:10:03.091117 916722 solver.cpp:218] Iteration 1479000 (16.5348 iter/s, 30.2393s/500 iters), loss = 0.150235
I0830 10:10:03.091185 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.15024 (* 1 = 0.15024 loss)
I0830 10:10:03.091193 916722 sgd_solver.cpp:106] Iteration 1479000, lr = 0.01
I0830 10:10:33.329041 916722 solver.cpp:218] Iteration 1479500 (16.5355 iter/s, 30.2379s/500 iters), loss = 0.138822
I0830 10:10:33.329094 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.138827 (* 1 = 0.138827 loss)
I0830 10:10:33.329102 916722 sgd_solver.cpp:106] Iteration 1479500, lr = 0.01
I0830 10:11:03.554157 916722 solver.cpp:218] Iteration 1480000 (16.5425 iter/s, 30.2251s/500 iters), loss = 0.0390534
I0830 10:11:03.554212 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0390583 (* 1 = 0.0390583 loss)
I0830 10:11:03.554220 916722 sgd_solver.cpp:106] Iteration 1480000, lr = 0.01
I0830 10:11:33.770442 916722 solver.cpp:218] Iteration 1480500 (16.5473 iter/s, 30.2163s/500 iters), loss = 0.283108
I0830 10:11:33.770494 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.283113 (* 1 = 0.283113 loss)
I0830 10:11:33.770503 916722 sgd_solver.cpp:106] Iteration 1480500, lr = 0.01
I0830 10:12:03.980171 916722 solver.cpp:218] Iteration 1481000 (16.5509 iter/s, 30.2098s/500 iters), loss = 0.0696681
I0830 10:12:03.980227 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0696731 (* 1 = 0.0696731 loss)
I0830 10:12:03.980235 916722 sgd_solver.cpp:106] Iteration 1481000, lr = 0.01
I0830 10:12:34.195359 916722 solver.cpp:218] Iteration 1481500 (16.548 iter/s, 30.2152s/500 iters), loss = 0.046155
I0830 10:12:34.195412 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.04616 (* 1 = 0.04616 loss)
I0830 10:12:34.195420 916722 sgd_solver.cpp:106] Iteration 1481500, lr = 0.01
I0830 10:13:04.390026 916722 solver.cpp:218] Iteration 1482000 (16.5592 iter/s, 30.1947s/500 iters), loss = 0.121837
I0830 10:13:04.390081 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.121842 (* 1 = 0.121842 loss)
I0830 10:13:04.390090 916722 sgd_solver.cpp:106] Iteration 1482000, lr = 0.01
I0830 10:13:34.592834 916722 solver.cpp:218] Iteration 1482500 (16.5547 iter/s, 30.2028s/500 iters), loss = 0.0581998
I0830 10:13:34.592888 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0582049 (* 1 = 0.0582049 loss)
I0830 10:13:34.592897 916722 sgd_solver.cpp:106] Iteration 1482500, lr = 0.01
I0830 10:14:04.800200 916722 solver.cpp:218] Iteration 1483000 (16.5522 iter/s, 30.2074s/500 iters), loss = 0.279538
I0830 10:14:04.800254 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.279543 (* 1 = 0.279543 loss)
I0830 10:14:04.800262 916722 sgd_solver.cpp:106] Iteration 1483000, lr = 0.01
I0830 10:14:34.995298 916722 solver.cpp:218] Iteration 1483500 (16.559 iter/s, 30.1951s/500 iters), loss = 0.0741571
I0830 10:14:34.995352 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0741623 (* 1 = 0.0741623 loss)
I0830 10:14:34.995359 916722 sgd_solver.cpp:106] Iteration 1483500, lr = 0.01
I0830 10:15:05.209719 916722 solver.cpp:218] Iteration 1484000 (16.5484 iter/s, 30.2145s/500 iters), loss = 0.230335
I0830 10:15:05.209774 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.23034 (* 1 = 0.23034 loss)
I0830 10:15:05.209782 916722 sgd_solver.cpp:106] Iteration 1484000, lr = 0.01
I0830 10:15:35.423295 916722 solver.cpp:218] Iteration 1484500 (16.5488 iter/s, 30.2136s/500 iters), loss = 0.189039
I0830 10:15:35.423344 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.189044 (* 1 = 0.189044 loss)
I0830 10:15:35.423352 916722 sgd_solver.cpp:106] Iteration 1484500, lr = 0.01
I0830 10:16:05.649762 916722 solver.cpp:218] Iteration 1485000 (16.5418 iter/s, 30.2265s/500 iters), loss = 0.232085
I0830 10:16:05.649823 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.23209 (* 1 = 0.23209 loss)
I0830 10:16:05.649832 916722 sgd_solver.cpp:106] Iteration 1485000, lr = 0.01
I0830 10:16:35.875941 916722 solver.cpp:218] Iteration 1485500 (16.5419 iter/s, 30.2262s/500 iters), loss = 0.0446664
I0830 10:16:35.876011 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0446714 (* 1 = 0.0446714 loss)
I0830 10:16:35.876019 916722 sgd_solver.cpp:106] Iteration 1485500, lr = 0.01
I0830 10:17:06.091959 916722 solver.cpp:218] Iteration 1486000 (16.5475 iter/s, 30.216s/500 iters), loss = 0.174269
I0830 10:17:06.092015 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.174274 (* 1 = 0.174274 loss)
I0830 10:17:06.092023 916722 sgd_solver.cpp:106] Iteration 1486000, lr = 0.01
I0830 10:17:36.327847 916722 solver.cpp:218] Iteration 1486500 (16.5366 iter/s, 30.2359s/500 iters), loss = 0.0694148
I0830 10:17:36.327898 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0694196 (* 1 = 0.0694196 loss)
I0830 10:17:36.327905 916722 sgd_solver.cpp:106] Iteration 1486500, lr = 0.01
I0830 10:18:06.552306 916722 solver.cpp:218] Iteration 1487000 (16.5429 iter/s, 30.2245s/500 iters), loss = 0.103443
I0830 10:18:06.552361 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.103448 (* 1 = 0.103448 loss)
I0830 10:18:06.552369 916722 sgd_solver.cpp:106] Iteration 1487000, lr = 0.01
I0830 10:18:36.780979 916722 solver.cpp:218] Iteration 1487500 (16.5406 iter/s, 30.2287s/500 iters), loss = 0.236925
I0830 10:18:36.781035 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.23693 (* 1 = 0.23693 loss)
I0830 10:18:36.781044 916722 sgd_solver.cpp:106] Iteration 1487500, lr = 0.01
I0830 10:19:06.997823 916722 solver.cpp:218] Iteration 1488000 (16.547 iter/s, 30.2169s/500 iters), loss = 0.174306
I0830 10:19:06.997875 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.174311 (* 1 = 0.174311 loss)
I0830 10:19:06.997884 916722 sgd_solver.cpp:106] Iteration 1488000, lr = 0.01
I0830 10:19:37.198405 916722 solver.cpp:218] Iteration 1488500 (16.556 iter/s, 30.2006s/500 iters), loss = 0.208784
I0830 10:19:37.198458 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.208789 (* 1 = 0.208789 loss)
I0830 10:19:37.198467 916722 sgd_solver.cpp:106] Iteration 1488500, lr = 0.01
I0830 10:20:07.411111 916722 solver.cpp:218] Iteration 1489000 (16.5493 iter/s, 30.2128s/500 iters), loss = 0.121495
I0830 10:20:07.411166 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.1215 (* 1 = 0.1215 loss)
I0830 10:20:07.411175 916722 sgd_solver.cpp:106] Iteration 1489000, lr = 0.01
I0830 10:20:37.599594 916722 solver.cpp:218] Iteration 1489500 (16.5626 iter/s, 30.1885s/500 iters), loss = 0.0337074
I0830 10:20:37.599648 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0337121 (* 1 = 0.0337121 loss)
I0830 10:20:37.599656 916722 sgd_solver.cpp:106] Iteration 1489500, lr = 0.01
I0830 10:21:07.794662 916722 solver.cpp:218] Iteration 1490000 (16.559 iter/s, 30.1951s/500 iters), loss = 0.135748
I0830 10:21:07.794723 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.135752 (* 1 = 0.135752 loss)
I0830 10:21:07.794732 916722 sgd_solver.cpp:106] Iteration 1490000, lr = 0.01
I0830 10:21:37.994424 916722 solver.cpp:218] Iteration 1490500 (16.5564 iter/s, 30.1998s/500 iters), loss = 0.433751
I0830 10:21:37.994483 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.433756 (* 1 = 0.433756 loss)
I0830 10:21:37.994491 916722 sgd_solver.cpp:106] Iteration 1490500, lr = 0.01
I0830 10:22:08.205024 916722 solver.cpp:218] Iteration 1491000 (16.5505 iter/s, 30.2106s/500 iters), loss = 0.384222
I0830 10:22:08.205077 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.384226 (* 1 = 0.384226 loss)
I0830 10:22:08.205086 916722 sgd_solver.cpp:106] Iteration 1491000, lr = 0.01
I0830 10:22:38.435668 916722 solver.cpp:218] Iteration 1491500 (16.5395 iter/s, 30.2307s/500 iters), loss = 0.540424
I0830 10:22:38.435726 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.540429 (* 1 = 0.540429 loss)
I0830 10:22:38.435734 916722 sgd_solver.cpp:106] Iteration 1491500, lr = 0.01
I0830 10:23:08.661049 916722 solver.cpp:218] Iteration 1492000 (16.5424 iter/s, 30.2254s/500 iters), loss = 0.283741
I0830 10:23:08.661118 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.283745 (* 1 = 0.283745 loss)
I0830 10:23:08.661131 916722 sgd_solver.cpp:106] Iteration 1492000, lr = 0.01
I0830 10:23:38.892166 916722 solver.cpp:218] Iteration 1492500 (16.5392 iter/s, 30.2312s/500 iters), loss = 0.144922
I0830 10:23:38.892222 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.144926 (* 1 = 0.144926 loss)
I0830 10:23:38.892230 916722 sgd_solver.cpp:106] Iteration 1492500, lr = 0.01
I0830 10:24:09.100381 916722 solver.cpp:218] Iteration 1493000 (16.5518 iter/s, 30.2083s/500 iters), loss = 0.0738534
I0830 10:24:09.100454 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0738576 (* 1 = 0.0738576 loss)
I0830 10:24:09.100464 916722 sgd_solver.cpp:106] Iteration 1493000, lr = 0.01
I0830 10:24:39.300258 916722 solver.cpp:218] Iteration 1493500 (16.5563 iter/s, 30.1999s/500 iters), loss = 0.0706996
I0830 10:24:39.300313 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0707037 (* 1 = 0.0707037 loss)
I0830 10:24:39.300323 916722 sgd_solver.cpp:106] Iteration 1493500, lr = 0.01
I0830 10:25:09.548460 916722 solver.cpp:218] Iteration 1494000 (16.5299 iter/s, 30.2482s/500 iters), loss = 0.174899
I0830 10:25:09.548511 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.174903 (* 1 = 0.174903 loss)
I0830 10:25:09.548521 916722 sgd_solver.cpp:106] Iteration 1494000, lr = 0.01
I0830 10:25:39.761642 916722 solver.cpp:218] Iteration 1494500 (16.5492 iter/s, 30.2129s/500 iters), loss = 0.158856
I0830 10:25:39.761693 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.158861 (* 1 = 0.158861 loss)
I0830 10:25:39.761701 916722 sgd_solver.cpp:106] Iteration 1494500, lr = 0.01
I0830 10:26:09.972348 916722 solver.cpp:218] Iteration 1495000 (16.5509 iter/s, 30.2099s/500 iters), loss = 0.369827
I0830 10:26:09.972405 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.369832 (* 1 = 0.369832 loss)
I0830 10:26:09.972414 916722 sgd_solver.cpp:106] Iteration 1495000, lr = 0.01
I0830 10:26:40.205094 916722 solver.cpp:218] Iteration 1495500 (16.5388 iter/s, 30.232s/500 iters), loss = 0.120013
I0830 10:26:40.205148 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.120017 (* 1 = 0.120017 loss)
I0830 10:26:40.205157 916722 sgd_solver.cpp:106] Iteration 1495500, lr = 0.01
I0830 10:27:10.414240 916722 solver.cpp:218] Iteration 1496000 (16.5517 iter/s, 30.2084s/500 iters), loss = 0.059426
I0830 10:27:10.414297 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0594303 (* 1 = 0.0594303 loss)
I0830 10:27:10.414305 916722 sgd_solver.cpp:106] Iteration 1496000, lr = 0.01
I0830 10:27:40.602097 916722 solver.cpp:218] Iteration 1496500 (16.5633 iter/s, 30.1872s/500 iters), loss = 0.0968837
I0830 10:27:40.602147 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.096888 (* 1 = 0.096888 loss)
I0830 10:27:40.602156 916722 sgd_solver.cpp:106] Iteration 1496500, lr = 0.01
I0830 10:28:10.801431 916722 solver.cpp:218] Iteration 1497000 (16.557 iter/s, 30.1987s/500 iters), loss = 0.150993
I0830 10:28:10.801487 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.150998 (* 1 = 0.150998 loss)
I0830 10:28:10.801496 916722 sgd_solver.cpp:106] Iteration 1497000, lr = 0.01
I0830 10:28:41.017760 916722 solver.cpp:218] Iteration 1497500 (16.5477 iter/s, 30.2157s/500 iters), loss = 0.159509
I0830 10:28:41.017812 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159513 (* 1 = 0.159513 loss)
I0830 10:28:41.017820 916722 sgd_solver.cpp:106] Iteration 1497500, lr = 0.01
I0830 10:29:11.194250 916722 solver.cpp:218] Iteration 1498000 (16.5695 iter/s, 30.1759s/500 iters), loss = 0.0625519
I0830 10:29:11.194304 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0625562 (* 1 = 0.0625562 loss)
I0830 10:29:11.194312 916722 sgd_solver.cpp:106] Iteration 1498000, lr = 0.01
I0830 10:29:41.386008 916722 solver.cpp:218] Iteration 1498500 (16.5611 iter/s, 30.1912s/500 iters), loss = 0.143376
I0830 10:29:41.386073 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.14338 (* 1 = 0.14338 loss)
I0830 10:29:41.386090 916722 sgd_solver.cpp:106] Iteration 1498500, lr = 0.01
I0830 10:30:11.576737 916722 solver.cpp:218] Iteration 1499000 (16.5617 iter/s, 30.1902s/500 iters), loss = 0.106081
I0830 10:30:11.576789 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.106085 (* 1 = 0.106085 loss)
I0830 10:30:11.576797 916722 sgd_solver.cpp:106] Iteration 1499000, lr = 0.01
I0830 10:30:41.757488 916722 solver.cpp:218] Iteration 1499500 (16.5671 iter/s, 30.1803s/500 iters), loss = 0.20865
I0830 10:30:41.757542 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.208654 (* 1 = 0.208654 loss)
I0830 10:30:41.757551 916722 sgd_solver.cpp:106] Iteration 1499500, lr = 0.01
I0830 10:31:11.919323 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_1500000.caffemodel
I0830 10:31:11.938477 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_1500000.solverstate
I0830 10:31:11.944607 916722 solver.cpp:330] Iteration 1500000, Testing net (#0)
I0830 10:31:27.354749 916722 solver.cpp:397]     Test net output #0: accuracy = 0.891
I0830 10:31:27.354797 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.363483 (* 1 = 0.363483 loss)
I0830 10:31:27.413637 916722 solver.cpp:218] Iteration 1500000 (10.9516 iter/s, 45.6555s/500 iters), loss = 0.20946
I0830 10:31:27.413666 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.209464 (* 1 = 0.209464 loss)
I0830 10:31:27.413673 916722 sgd_solver.cpp:106] Iteration 1500000, lr = 0.01
I0830 10:31:57.376067 916722 solver.cpp:218] Iteration 1500500 (16.6878 iter/s, 29.962s/500 iters), loss = 0.0656168
I0830 10:31:57.376125 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0656212 (* 1 = 0.0656212 loss)
I0830 10:31:57.376134 916722 sgd_solver.cpp:106] Iteration 1500500, lr = 0.01
I0830 10:32:27.464844 916722 solver.cpp:218] Iteration 1501000 (16.6177 iter/s, 30.0884s/500 iters), loss = 0.270699
I0830 10:32:27.464897 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.270703 (* 1 = 0.270703 loss)
I0830 10:32:27.464905 916722 sgd_solver.cpp:106] Iteration 1501000, lr = 0.01
I0830 10:32:57.619989 916722 solver.cpp:218] Iteration 1501500 (16.5811 iter/s, 30.1548s/500 iters), loss = 0.133944
I0830 10:32:57.620050 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133948 (* 1 = 0.133948 loss)
I0830 10:32:57.620059 916722 sgd_solver.cpp:106] Iteration 1501500, lr = 0.01
I0830 10:33:27.755146 916722 solver.cpp:218] Iteration 1502000 (16.5921 iter/s, 30.1348s/500 iters), loss = 0.124587
I0830 10:33:27.755203 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.124591 (* 1 = 0.124591 loss)
I0830 10:33:27.755211 916722 sgd_solver.cpp:106] Iteration 1502000, lr = 0.01
I0830 10:33:57.897224 916722 solver.cpp:218] Iteration 1502500 (16.5883 iter/s, 30.1417s/500 iters), loss = 0.0363877
I0830 10:33:57.897285 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.036392 (* 1 = 0.036392 loss)
I0830 10:33:57.897294 916722 sgd_solver.cpp:106] Iteration 1502500, lr = 0.01
I0830 10:34:28.044055 916722 solver.cpp:218] Iteration 1503000 (16.5857 iter/s, 30.1465s/500 iters), loss = 0.0837221
I0830 10:34:28.044118 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0837265 (* 1 = 0.0837265 loss)
I0830 10:34:28.044127 916722 sgd_solver.cpp:106] Iteration 1503000, lr = 0.01
I0830 10:34:58.214437 916722 solver.cpp:218] Iteration 1503500 (16.5727 iter/s, 30.1701s/500 iters), loss = 0.0639592
I0830 10:34:58.214495 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0639634 (* 1 = 0.0639634 loss)
I0830 10:34:58.214504 916722 sgd_solver.cpp:106] Iteration 1503500, lr = 0.01
I0830 10:35:28.372413 916722 solver.cpp:218] Iteration 1504000 (16.5795 iter/s, 30.1577s/500 iters), loss = 0.0567247
I0830 10:35:28.372473 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0567289 (* 1 = 0.0567289 loss)
I0830 10:35:28.372480 916722 sgd_solver.cpp:106] Iteration 1504000, lr = 0.01
I0830 10:35:58.539304 916722 solver.cpp:218] Iteration 1504500 (16.5746 iter/s, 30.1666s/500 iters), loss = 0.136986
I0830 10:35:58.539374 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13699 (* 1 = 0.13699 loss)
I0830 10:35:58.539382 916722 sgd_solver.cpp:106] Iteration 1504500, lr = 0.01
I0830 10:36:28.686708 916722 solver.cpp:218] Iteration 1505000 (16.5853 iter/s, 30.1471s/500 iters), loss = 0.15647
I0830 10:36:28.686756 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.156474 (* 1 = 0.156474 loss)
I0830 10:36:28.686764 916722 sgd_solver.cpp:106] Iteration 1505000, lr = 0.01
I0830 10:36:58.825089 916722 solver.cpp:218] Iteration 1505500 (16.5903 iter/s, 30.1381s/500 iters), loss = 0.0911612
I0830 10:36:58.825145 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0911653 (* 1 = 0.0911653 loss)
I0830 10:36:58.825153 916722 sgd_solver.cpp:106] Iteration 1505500, lr = 0.01
I0830 10:37:28.949494 916722 solver.cpp:218] Iteration 1506000 (16.598 iter/s, 30.1242s/500 iters), loss = 0.111977
I0830 10:37:28.949543 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111981 (* 1 = 0.111981 loss)
I0830 10:37:28.949553 916722 sgd_solver.cpp:106] Iteration 1506000, lr = 0.01
I0830 10:37:59.063581 916722 solver.cpp:218] Iteration 1506500 (16.6037 iter/s, 30.1139s/500 iters), loss = 0.150705
I0830 10:37:59.063640 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.15071 (* 1 = 0.15071 loss)
I0830 10:37:59.063649 916722 sgd_solver.cpp:106] Iteration 1506500, lr = 0.01
I0830 10:38:29.201179 916722 solver.cpp:218] Iteration 1507000 (16.5907 iter/s, 30.1374s/500 iters), loss = 0.166833
I0830 10:38:29.201238 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.166838 (* 1 = 0.166838 loss)
I0830 10:38:29.201247 916722 sgd_solver.cpp:106] Iteration 1507000, lr = 0.01
I0830 10:38:59.332039 916722 solver.cpp:218] Iteration 1507500 (16.5944 iter/s, 30.1306s/500 iters), loss = 0.103023
I0830 10:38:59.332099 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.103027 (* 1 = 0.103027 loss)
I0830 10:38:59.332108 916722 sgd_solver.cpp:106] Iteration 1507500, lr = 0.01
I0830 10:39:29.462316 916722 solver.cpp:218] Iteration 1508000 (16.5947 iter/s, 30.1301s/500 iters), loss = 0.168314
I0830 10:39:29.462370 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.168318 (* 1 = 0.168318 loss)
I0830 10:39:29.462378 916722 sgd_solver.cpp:106] Iteration 1508000, lr = 0.01
I0830 10:39:59.610287 916722 solver.cpp:218] Iteration 1508500 (16.585 iter/s, 30.1478s/500 iters), loss = 0.0802284
I0830 10:39:59.610348 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0802325 (* 1 = 0.0802325 loss)
I0830 10:39:59.610356 916722 sgd_solver.cpp:106] Iteration 1508500, lr = 0.01
I0830 10:40:29.784852 916722 solver.cpp:218] Iteration 1509000 (16.5704 iter/s, 30.1744s/500 iters), loss = 0.196557
I0830 10:40:29.784911 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.196561 (* 1 = 0.196561 loss)
I0830 10:40:29.784920 916722 sgd_solver.cpp:106] Iteration 1509000, lr = 0.01
I0830 10:40:59.923424 916722 solver.cpp:218] Iteration 1509500 (16.5901 iter/s, 30.1384s/500 iters), loss = 0.132362
I0830 10:40:59.923481 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.132366 (* 1 = 0.132366 loss)
I0830 10:40:59.923491 916722 sgd_solver.cpp:106] Iteration 1509500, lr = 0.01
I0830 10:41:30.059552 916722 solver.cpp:218] Iteration 1510000 (16.5915 iter/s, 30.136s/500 iters), loss = 0.241487
I0830 10:41:30.059607 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.241491 (* 1 = 0.241491 loss)
I0830 10:41:30.059617 916722 sgd_solver.cpp:106] Iteration 1510000, lr = 0.01
I0830 10:42:00.207639 916722 solver.cpp:218] Iteration 1510500 (16.5849 iter/s, 30.1479s/500 iters), loss = 0.241277
I0830 10:42:00.207693 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.241281 (* 1 = 0.241281 loss)
I0830 10:42:00.207701 916722 sgd_solver.cpp:106] Iteration 1510500, lr = 0.01
I0830 10:42:30.349058 916722 solver.cpp:218] Iteration 1511000 (16.5886 iter/s, 30.1413s/500 iters), loss = 0.221257
I0830 10:42:30.349131 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.221261 (* 1 = 0.221261 loss)
I0830 10:42:30.349139 916722 sgd_solver.cpp:106] Iteration 1511000, lr = 0.01
I0830 10:43:00.588454 916722 solver.cpp:218] Iteration 1511500 (16.5348 iter/s, 30.2392s/500 iters), loss = 0.212125
I0830 10:43:00.588512 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.212129 (* 1 = 0.212129 loss)
I0830 10:43:00.588521 916722 sgd_solver.cpp:106] Iteration 1511500, lr = 0.01
I0830 10:43:30.872288 916722 solver.cpp:218] Iteration 1512000 (16.5105 iter/s, 30.2837s/500 iters), loss = 0.0971324
I0830 10:43:30.872344 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0971366 (* 1 = 0.0971366 loss)
I0830 10:43:30.872352 916722 sgd_solver.cpp:106] Iteration 1512000, lr = 0.01
I0830 10:44:01.147007 916722 solver.cpp:218] Iteration 1512500 (16.5155 iter/s, 30.2746s/500 iters), loss = 0.09033
I0830 10:44:01.147063 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0903342 (* 1 = 0.0903342 loss)
I0830 10:44:01.147070 916722 sgd_solver.cpp:106] Iteration 1512500, lr = 0.01
I0830 10:44:31.419479 916722 solver.cpp:218] Iteration 1513000 (16.5167 iter/s, 30.2723s/500 iters), loss = 0.0498635
I0830 10:44:31.419534 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0498675 (* 1 = 0.0498675 loss)
I0830 10:44:31.419543 916722 sgd_solver.cpp:106] Iteration 1513000, lr = 0.01
I0830 10:45:01.695194 916722 solver.cpp:218] Iteration 1513500 (16.515 iter/s, 30.2756s/500 iters), loss = 0.125407
I0830 10:45:01.695250 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.125411 (* 1 = 0.125411 loss)
I0830 10:45:01.695258 916722 sgd_solver.cpp:106] Iteration 1513500, lr = 0.01
I0830 10:45:31.932446 916722 solver.cpp:218] Iteration 1514000 (16.536 iter/s, 30.2371s/500 iters), loss = 0.225802
I0830 10:45:31.932518 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.225806 (* 1 = 0.225806 loss)
I0830 10:45:31.932528 916722 sgd_solver.cpp:106] Iteration 1514000, lr = 0.01
I0830 10:46:02.130844 916722 solver.cpp:218] Iteration 1514500 (16.5572 iter/s, 30.1983s/500 iters), loss = 0.146785
I0830 10:46:02.130903 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.146789 (* 1 = 0.146789 loss)
I0830 10:46:02.130910 916722 sgd_solver.cpp:106] Iteration 1514500, lr = 0.01
I0830 10:46:32.316182 916722 solver.cpp:218] Iteration 1515000 (16.5644 iter/s, 30.1852s/500 iters), loss = 0.773819
I0830 10:46:32.316234 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.773823 (* 1 = 0.773823 loss)
I0830 10:46:32.316242 916722 sgd_solver.cpp:106] Iteration 1515000, lr = 0.01
I0830 10:47:02.474874 916722 solver.cpp:218] Iteration 1515500 (16.579 iter/s, 30.1586s/500 iters), loss = 0.297478
I0830 10:47:02.474929 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.297481 (* 1 = 0.297481 loss)
I0830 10:47:02.474937 916722 sgd_solver.cpp:106] Iteration 1515500, lr = 0.01
I0830 10:47:32.614001 916722 solver.cpp:218] Iteration 1516000 (16.5898 iter/s, 30.139s/500 iters), loss = 0.0140242
I0830 10:47:32.614053 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.014028 (* 1 = 0.014028 loss)
I0830 10:47:32.614060 916722 sgd_solver.cpp:106] Iteration 1516000, lr = 0.01
I0830 10:48:02.774211 916722 solver.cpp:218] Iteration 1516500 (16.5782 iter/s, 30.1601s/500 iters), loss = 0.0877902
I0830 10:48:02.774271 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0877939 (* 1 = 0.0877939 loss)
I0830 10:48:02.774279 916722 sgd_solver.cpp:106] Iteration 1516500, lr = 0.01
I0830 10:48:32.924842 916722 solver.cpp:218] Iteration 1517000 (16.5835 iter/s, 30.1505s/500 iters), loss = 0.064814
I0830 10:48:32.924898 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0648179 (* 1 = 0.0648179 loss)
I0830 10:48:32.924906 916722 sgd_solver.cpp:106] Iteration 1517000, lr = 0.01
I0830 10:49:03.041007 916722 solver.cpp:218] Iteration 1517500 (16.6024 iter/s, 30.116s/500 iters), loss = 0.00444447
I0830 10:49:03.041085 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.00444825 (* 1 = 0.00444825 loss)
I0830 10:49:03.041093 916722 sgd_solver.cpp:106] Iteration 1517500, lr = 0.01
I0830 10:49:33.138809 916722 solver.cpp:218] Iteration 1518000 (16.6126 iter/s, 30.0977s/500 iters), loss = 0.27721
I0830 10:49:33.138864 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.277213 (* 1 = 0.277213 loss)
I0830 10:49:33.138872 916722 sgd_solver.cpp:106] Iteration 1518000, lr = 0.01
I0830 10:50:03.232951 916722 solver.cpp:218] Iteration 1518500 (16.6146 iter/s, 30.094s/500 iters), loss = 0.1151
I0830 10:50:03.233012 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115103 (* 1 = 0.115103 loss)
I0830 10:50:03.233021 916722 sgd_solver.cpp:106] Iteration 1518500, lr = 0.01
I0830 10:50:33.311167 916722 solver.cpp:218] Iteration 1519000 (16.6234 iter/s, 30.0781s/500 iters), loss = 0.118501
I0830 10:50:33.311221 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.118504 (* 1 = 0.118504 loss)
I0830 10:50:33.311229 916722 sgd_solver.cpp:106] Iteration 1519000, lr = 0.01
I0830 10:51:03.385047 916722 solver.cpp:218] Iteration 1519500 (16.6258 iter/s, 30.0738s/500 iters), loss = 0.190523
I0830 10:51:03.385103 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.190527 (* 1 = 0.190527 loss)
I0830 10:51:03.385111 916722 sgd_solver.cpp:106] Iteration 1519500, lr = 0.01
I0830 10:51:33.446772 916722 solver.cpp:218] Iteration 1520000 (16.6325 iter/s, 30.0616s/500 iters), loss = 0.0873409
I0830 10:51:33.446827 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0873443 (* 1 = 0.0873443 loss)
I0830 10:51:33.446835 916722 sgd_solver.cpp:106] Iteration 1520000, lr = 0.01
I0830 10:52:03.502492 916722 solver.cpp:218] Iteration 1520500 (16.6358 iter/s, 30.0556s/500 iters), loss = 0.030737
I0830 10:52:03.502547 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0307402 (* 1 = 0.0307402 loss)
I0830 10:52:03.502555 916722 sgd_solver.cpp:106] Iteration 1520500, lr = 0.01
I0830 10:52:33.543182 916722 solver.cpp:218] Iteration 1521000 (16.6442 iter/s, 30.0406s/500 iters), loss = 0.194118
I0830 10:52:33.543238 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.194121 (* 1 = 0.194121 loss)
I0830 10:52:33.543246 916722 sgd_solver.cpp:106] Iteration 1521000, lr = 0.01
I0830 10:53:03.582548 916722 solver.cpp:218] Iteration 1521500 (16.6449 iter/s, 30.0393s/500 iters), loss = 0.127156
I0830 10:53:03.582605 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.127159 (* 1 = 0.127159 loss)
I0830 10:53:03.582614 916722 sgd_solver.cpp:106] Iteration 1521500, lr = 0.01
I0830 10:53:33.613960 916722 solver.cpp:218] Iteration 1522000 (16.6493 iter/s, 30.0313s/500 iters), loss = 0.149759
I0830 10:53:33.614017 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.149762 (* 1 = 0.149762 loss)
I0830 10:53:33.614024 916722 sgd_solver.cpp:106] Iteration 1522000, lr = 0.01
I0830 10:54:03.616132 916722 solver.cpp:218] Iteration 1522500 (16.6655 iter/s, 30.0021s/500 iters), loss = 0.366505
I0830 10:54:03.616189 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.366509 (* 1 = 0.366509 loss)
I0830 10:54:03.616199 916722 sgd_solver.cpp:106] Iteration 1522500, lr = 0.01
I0830 10:54:33.618352 916722 solver.cpp:218] Iteration 1523000 (16.6655 iter/s, 30.0021s/500 iters), loss = 0.118275
I0830 10:54:33.618412 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.118278 (* 1 = 0.118278 loss)
I0830 10:54:33.618420 916722 sgd_solver.cpp:106] Iteration 1523000, lr = 0.01
I0830 10:55:03.615500 916722 solver.cpp:218] Iteration 1523500 (16.6683 iter/s, 29.997s/500 iters), loss = 0.0473338
I0830 10:55:03.615550 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0473371 (* 1 = 0.0473371 loss)
I0830 10:55:03.615561 916722 sgd_solver.cpp:106] Iteration 1523500, lr = 0.01
I0830 10:55:33.614969 916722 solver.cpp:218] Iteration 1524000 (16.667 iter/s, 29.9994s/500 iters), loss = 0.179351
I0830 10:55:33.615036 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.179355 (* 1 = 0.179355 loss)
I0830 10:55:33.615048 916722 sgd_solver.cpp:106] Iteration 1524000, lr = 0.01
I0830 10:56:03.617292 916722 solver.cpp:218] Iteration 1524500 (16.6654 iter/s, 30.0022s/500 iters), loss = 0.0469636
I0830 10:56:03.617348 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.046967 (* 1 = 0.046967 loss)
I0830 10:56:03.617357 916722 sgd_solver.cpp:106] Iteration 1524500, lr = 0.01
I0830 10:56:33.615851 916722 solver.cpp:218] Iteration 1525000 (16.6675 iter/s, 29.9984s/500 iters), loss = 0.154417
I0830 10:56:33.615901 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.15442 (* 1 = 0.15442 loss)
I0830 10:56:33.615911 916722 sgd_solver.cpp:106] Iteration 1525000, lr = 0.01
I0830 10:57:03.585767 916722 solver.cpp:218] Iteration 1525500 (16.6835 iter/s, 29.9698s/500 iters), loss = 0.116651
I0830 10:57:03.585827 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.116655 (* 1 = 0.116655 loss)
I0830 10:57:03.585835 916722 sgd_solver.cpp:106] Iteration 1525500, lr = 0.01
I0830 10:57:33.584137 916722 solver.cpp:218] Iteration 1526000 (16.6676 iter/s, 29.9983s/500 iters), loss = 0.0703007
I0830 10:57:33.584185 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0703041 (* 1 = 0.0703041 loss)
I0830 10:57:33.584195 916722 sgd_solver.cpp:106] Iteration 1526000, lr = 0.01
I0830 10:58:03.554016 916722 solver.cpp:218] Iteration 1526500 (16.6835 iter/s, 29.9698s/500 iters), loss = 0.139177
I0830 10:58:03.554073 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139181 (* 1 = 0.139181 loss)
I0830 10:58:03.554081 916722 sgd_solver.cpp:106] Iteration 1526500, lr = 0.01
I0830 10:58:33.522096 916722 solver.cpp:218] Iteration 1527000 (16.6845 iter/s, 29.968s/500 iters), loss = 0.146178
I0830 10:58:33.522143 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.146182 (* 1 = 0.146182 loss)
I0830 10:58:33.522153 916722 sgd_solver.cpp:106] Iteration 1527000, lr = 0.01
I0830 10:59:03.495118 916722 solver.cpp:218] Iteration 1527500 (16.6817 iter/s, 29.9729s/500 iters), loss = 0.130869
I0830 10:59:03.495173 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130873 (* 1 = 0.130873 loss)
I0830 10:59:03.495182 916722 sgd_solver.cpp:106] Iteration 1527500, lr = 0.01
I0830 10:59:33.466548 916722 solver.cpp:218] Iteration 1528000 (16.6826 iter/s, 29.9713s/500 iters), loss = 0.0839068
I0830 10:59:33.466596 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0839102 (* 1 = 0.0839102 loss)
I0830 10:59:33.466606 916722 sgd_solver.cpp:106] Iteration 1528000, lr = 0.01
I0830 11:00:03.408005 916722 solver.cpp:218] Iteration 1528500 (16.6995 iter/s, 29.941s/500 iters), loss = 0.0566351
I0830 11:00:03.408059 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0566384 (* 1 = 0.0566384 loss)
I0830 11:00:03.408068 916722 sgd_solver.cpp:106] Iteration 1528500, lr = 0.01
I0830 11:00:33.357286 916722 solver.cpp:218] Iteration 1529000 (16.6952 iter/s, 29.9487s/500 iters), loss = 0.26782
I0830 11:00:33.357336 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.267823 (* 1 = 0.267823 loss)
I0830 11:00:33.357347 916722 sgd_solver.cpp:106] Iteration 1529000, lr = 0.01
I0830 11:01:03.309068 916722 solver.cpp:218] Iteration 1529500 (16.6938 iter/s, 29.9513s/500 iters), loss = 0.338321
I0830 11:01:03.309129 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.338324 (* 1 = 0.338324 loss)
I0830 11:01:03.309137 916722 sgd_solver.cpp:106] Iteration 1529500, lr = 0.01
I0830 11:01:33.228498 916722 solver.cpp:218] Iteration 1530000 (16.7118 iter/s, 29.9189s/500 iters), loss = 0.167347
I0830 11:01:33.228547 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.16735 (* 1 = 0.16735 loss)
I0830 11:01:33.228556 916722 sgd_solver.cpp:106] Iteration 1530000, lr = 0.01
I0830 11:02:03.170321 916722 solver.cpp:218] Iteration 1530500 (16.6993 iter/s, 29.9414s/500 iters), loss = 0.336192
I0830 11:02:03.170389 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.336196 (* 1 = 0.336196 loss)
I0830 11:02:03.170403 916722 sgd_solver.cpp:106] Iteration 1530500, lr = 0.01
I0830 11:02:33.113072 916722 solver.cpp:218] Iteration 1531000 (16.6988 iter/s, 29.9423s/500 iters), loss = 0.268077
I0830 11:02:33.113121 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.268081 (* 1 = 0.268081 loss)
I0830 11:02:33.113129 916722 sgd_solver.cpp:106] Iteration 1531000, lr = 0.01
I0830 11:03:03.034688 916722 solver.cpp:218] Iteration 1531500 (16.7106 iter/s, 29.9212s/500 iters), loss = 0.149365
I0830 11:03:03.034744 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.149368 (* 1 = 0.149368 loss)
I0830 11:03:03.034752 916722 sgd_solver.cpp:106] Iteration 1531500, lr = 0.01
I0830 11:03:32.971807 916722 solver.cpp:218] Iteration 1532000 (16.7019 iter/s, 29.9367s/500 iters), loss = 0.0437482
I0830 11:03:32.971856 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0437519 (* 1 = 0.0437519 loss)
I0830 11:03:32.971865 916722 sgd_solver.cpp:106] Iteration 1532000, lr = 0.01
I0830 11:04:02.880982 916722 solver.cpp:218] Iteration 1532500 (16.7175 iter/s, 29.9088s/500 iters), loss = 0.25114
I0830 11:04:02.881042 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.251143 (* 1 = 0.251143 loss)
I0830 11:04:02.881050 916722 sgd_solver.cpp:106] Iteration 1532500, lr = 0.01
I0830 11:04:32.794781 916722 solver.cpp:218] Iteration 1533000 (16.7149 iter/s, 29.9134s/500 iters), loss = 0.251839
I0830 11:04:32.794831 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.251843 (* 1 = 0.251843 loss)
I0830 11:04:32.794838 916722 sgd_solver.cpp:106] Iteration 1533000, lr = 0.01
I0830 11:05:02.693449 916722 solver.cpp:218] Iteration 1533500 (16.7234 iter/s, 29.8983s/500 iters), loss = 0.152218
I0830 11:05:02.693507 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152221 (* 1 = 0.152221 loss)
I0830 11:05:02.693516 916722 sgd_solver.cpp:106] Iteration 1533500, lr = 0.01
I0830 11:05:32.582482 916722 solver.cpp:218] Iteration 1534000 (16.7288 iter/s, 29.8887s/500 iters), loss = 0.0317259
I0830 11:05:32.582535 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0317296 (* 1 = 0.0317296 loss)
I0830 11:05:32.582542 916722 sgd_solver.cpp:106] Iteration 1534000, lr = 0.01
I0830 11:06:02.487030 916722 solver.cpp:218] Iteration 1534500 (16.7201 iter/s, 29.9042s/500 iters), loss = 0.22255
I0830 11:06:02.487084 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.222553 (* 1 = 0.222553 loss)
I0830 11:06:02.487093 916722 sgd_solver.cpp:106] Iteration 1534500, lr = 0.01
I0830 11:06:32.389824 916722 solver.cpp:218] Iteration 1535000 (16.721 iter/s, 29.9024s/500 iters), loss = 0.111189
I0830 11:06:32.389873 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111192 (* 1 = 0.111192 loss)
I0830 11:06:32.389881 916722 sgd_solver.cpp:106] Iteration 1535000, lr = 0.01
I0830 11:07:02.280025 916722 solver.cpp:218] Iteration 1535500 (16.7281 iter/s, 29.8899s/500 iters), loss = 0.0759802
I0830 11:07:02.280083 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.075984 (* 1 = 0.075984 loss)
I0830 11:07:02.280092 916722 sgd_solver.cpp:106] Iteration 1535500, lr = 0.01
I0830 11:07:32.174263 916722 solver.cpp:218] Iteration 1536000 (16.7258 iter/s, 29.8939s/500 iters), loss = 0.0807817
I0830 11:07:32.174312 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0807854 (* 1 = 0.0807854 loss)
I0830 11:07:32.174320 916722 sgd_solver.cpp:106] Iteration 1536000, lr = 0.01
I0830 11:08:02.066370 916722 solver.cpp:218] Iteration 1536500 (16.727 iter/s, 29.8918s/500 iters), loss = 0.0321261
I0830 11:08:02.066428 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0321299 (* 1 = 0.0321299 loss)
I0830 11:08:02.066437 916722 sgd_solver.cpp:106] Iteration 1536500, lr = 0.01
I0830 11:08:31.948446 916722 solver.cpp:218] Iteration 1537000 (16.7326 iter/s, 29.8817s/500 iters), loss = 0.173589
I0830 11:08:31.948498 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.173592 (* 1 = 0.173592 loss)
I0830 11:08:31.948523 916722 sgd_solver.cpp:106] Iteration 1537000, lr = 0.01
I0830 11:09:01.854158 916722 solver.cpp:218] Iteration 1537500 (16.7194 iter/s, 29.9054s/500 iters), loss = 0.0456394
I0830 11:09:01.854228 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.045643 (* 1 = 0.045643 loss)
I0830 11:09:01.854236 916722 sgd_solver.cpp:106] Iteration 1537500, lr = 0.01
I0830 11:09:31.740326 916722 solver.cpp:218] Iteration 1538000 (16.7303 iter/s, 29.8858s/500 iters), loss = 0.0159138
I0830 11:09:31.740376 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0159172 (* 1 = 0.0159172 loss)
I0830 11:09:31.740384 916722 sgd_solver.cpp:106] Iteration 1538000, lr = 0.01
I0830 11:10:01.631140 916722 solver.cpp:218] Iteration 1538500 (16.7277 iter/s, 29.8905s/500 iters), loss = 0.16359
I0830 11:10:01.631196 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.163594 (* 1 = 0.163594 loss)
I0830 11:10:01.631203 916722 sgd_solver.cpp:106] Iteration 1538500, lr = 0.01
I0830 11:10:31.518630 916722 solver.cpp:218] Iteration 1539000 (16.7296 iter/s, 29.8872s/500 iters), loss = 0.0674427
I0830 11:10:31.518683 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0674463 (* 1 = 0.0674463 loss)
I0830 11:10:31.518694 916722 sgd_solver.cpp:106] Iteration 1539000, lr = 0.01
I0830 11:11:01.387454 916722 solver.cpp:218] Iteration 1539500 (16.74 iter/s, 29.8685s/500 iters), loss = 0.144335
I0830 11:11:01.387507 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.144338 (* 1 = 0.144338 loss)
I0830 11:11:01.387516 916722 sgd_solver.cpp:106] Iteration 1539500, lr = 0.01
I0830 11:11:31.263365 916722 solver.cpp:218] Iteration 1540000 (16.736 iter/s, 29.8756s/500 iters), loss = 0.058246
I0830 11:11:31.263415 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0582495 (* 1 = 0.0582495 loss)
I0830 11:11:31.263425 916722 sgd_solver.cpp:106] Iteration 1540000, lr = 0.01
I0830 11:12:01.134585 916722 solver.cpp:218] Iteration 1540500 (16.7387 iter/s, 29.8709s/500 iters), loss = 0.0632888
I0830 11:12:01.134644 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0632923 (* 1 = 0.0632923 loss)
I0830 11:12:01.134652 916722 sgd_solver.cpp:106] Iteration 1540500, lr = 0.01
I0830 11:12:31.020372 916722 solver.cpp:218] Iteration 1541000 (16.7305 iter/s, 29.8855s/500 iters), loss = 0.255867
I0830 11:12:31.020428 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.255871 (* 1 = 0.255871 loss)
I0830 11:12:31.020439 916722 sgd_solver.cpp:106] Iteration 1541000, lr = 0.01
I0830 11:13:00.879184 916722 solver.cpp:218] Iteration 1541500 (16.7456 iter/s, 29.8585s/500 iters), loss = 0.127795
I0830 11:13:00.879245 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.127799 (* 1 = 0.127799 loss)
I0830 11:13:00.879253 916722 sgd_solver.cpp:106] Iteration 1541500, lr = 0.01
I0830 11:13:30.754484 916722 solver.cpp:218] Iteration 1542000 (16.7364 iter/s, 29.875s/500 iters), loss = 0.186804
I0830 11:13:30.754534 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.186807 (* 1 = 0.186807 loss)
I0830 11:13:30.754544 916722 sgd_solver.cpp:106] Iteration 1542000, lr = 0.01
I0830 11:14:00.614917 916722 solver.cpp:218] Iteration 1542500 (16.7447 iter/s, 29.8602s/500 iters), loss = 0.210058
I0830 11:14:00.614974 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.210061 (* 1 = 0.210061 loss)
I0830 11:14:00.614984 916722 sgd_solver.cpp:106] Iteration 1542500, lr = 0.01
I0830 11:14:30.470703 916722 solver.cpp:218] Iteration 1543000 (16.7473 iter/s, 29.8555s/500 iters), loss = 0.15226
I0830 11:14:30.470753 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152264 (* 1 = 0.152264 loss)
I0830 11:14:30.470763 916722 sgd_solver.cpp:106] Iteration 1543000, lr = 0.01
I0830 11:15:00.342217 916722 solver.cpp:218] Iteration 1543500 (16.7385 iter/s, 29.8713s/500 iters), loss = 0.187696
I0830 11:15:00.342273 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.187699 (* 1 = 0.187699 loss)
I0830 11:15:00.342281 916722 sgd_solver.cpp:106] Iteration 1543500, lr = 0.01
I0830 11:15:30.215163 916722 solver.cpp:218] Iteration 1544000 (16.7377 iter/s, 29.8727s/500 iters), loss = 0.167456
I0830 11:15:30.215214 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.167459 (* 1 = 0.167459 loss)
I0830 11:15:30.215224 916722 sgd_solver.cpp:106] Iteration 1544000, lr = 0.01
I0830 11:16:00.086918 916722 solver.cpp:218] Iteration 1544500 (16.7384 iter/s, 29.8715s/500 iters), loss = 0.184132
I0830 11:16:00.086993 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.184136 (* 1 = 0.184136 loss)
I0830 11:16:00.087002 916722 sgd_solver.cpp:106] Iteration 1544500, lr = 0.01
I0830 11:16:29.958021 916722 solver.cpp:218] Iteration 1545000 (16.7387 iter/s, 29.8708s/500 iters), loss = 0.147799
I0830 11:16:29.958072 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.147802 (* 1 = 0.147802 loss)
I0830 11:16:29.958081 916722 sgd_solver.cpp:106] Iteration 1545000, lr = 0.01
I0830 11:16:59.830758 916722 solver.cpp:218] Iteration 1545500 (16.7378 iter/s, 29.8725s/500 iters), loss = 0.282748
I0830 11:16:59.830818 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.282751 (* 1 = 0.282751 loss)
I0830 11:16:59.830827 916722 sgd_solver.cpp:106] Iteration 1545500, lr = 0.01
I0830 11:17:29.698288 916722 solver.cpp:218] Iteration 1546000 (16.7407 iter/s, 29.8673s/500 iters), loss = 0.04317
I0830 11:17:29.698339 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0431733 (* 1 = 0.0431733 loss)
I0830 11:17:29.698348 916722 sgd_solver.cpp:106] Iteration 1546000, lr = 0.01
I0830 11:17:59.565069 916722 solver.cpp:218] Iteration 1546500 (16.7411 iter/s, 29.8666s/500 iters), loss = 0.494
I0830 11:17:59.565129 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.494003 (* 1 = 0.494003 loss)
I0830 11:17:59.565138 916722 sgd_solver.cpp:106] Iteration 1546500, lr = 0.01
I0830 11:18:29.417721 916722 solver.cpp:218] Iteration 1547000 (16.7491 iter/s, 29.8524s/500 iters), loss = 0.0275917
I0830 11:18:29.417771 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0275948 (* 1 = 0.0275948 loss)
I0830 11:18:29.417780 916722 sgd_solver.cpp:106] Iteration 1547000, lr = 0.01
I0830 11:18:59.266945 916722 solver.cpp:218] Iteration 1547500 (16.751 iter/s, 29.849s/500 iters), loss = 0.314438
I0830 11:18:59.267002 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.314441 (* 1 = 0.314441 loss)
I0830 11:18:59.267011 916722 sgd_solver.cpp:106] Iteration 1547500, lr = 0.01
I0830 11:19:29.118638 916722 solver.cpp:218] Iteration 1548000 (16.7496 iter/s, 29.8515s/500 iters), loss = 0.0869763
I0830 11:19:29.118688 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0869795 (* 1 = 0.0869795 loss)
I0830 11:19:29.118697 916722 sgd_solver.cpp:106] Iteration 1548000, lr = 0.01
I0830 11:19:58.969825 916722 solver.cpp:218] Iteration 1548500 (16.7499 iter/s, 29.851s/500 iters), loss = 0.211183
I0830 11:19:58.969887 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.211186 (* 1 = 0.211186 loss)
I0830 11:19:58.969895 916722 sgd_solver.cpp:106] Iteration 1548500, lr = 0.01
I0830 11:20:28.822976 916722 solver.cpp:218] Iteration 1549000 (16.7488 iter/s, 29.8529s/500 iters), loss = 0.133772
I0830 11:20:28.823027 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133775 (* 1 = 0.133775 loss)
I0830 11:20:28.823035 916722 sgd_solver.cpp:106] Iteration 1549000, lr = 0.01
I0830 11:20:58.676967 916722 solver.cpp:218] Iteration 1549500 (16.7483 iter/s, 29.8538s/500 iters), loss = 0.102225
I0830 11:20:58.677028 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.102228 (* 1 = 0.102228 loss)
I0830 11:20:58.677037 916722 sgd_solver.cpp:106] Iteration 1549500, lr = 0.01
I0830 11:21:28.474639 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_1550000.caffemodel
I0830 11:21:28.493876 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_1550000.solverstate
I0830 11:21:28.499979 916722 solver.cpp:330] Iteration 1550000, Testing net (#0)
I0830 11:21:43.964550 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8922
I0830 11:21:43.964622 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.350512 (* 1 = 0.350512 loss)
I0830 11:21:44.023285 916722 solver.cpp:218] Iteration 1550000 (11.0263 iter/s, 45.346s/500 iters), loss = 0.573846
I0830 11:21:44.023312 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.573849 (* 1 = 0.573849 loss)
I0830 11:21:44.023320 916722 sgd_solver.cpp:106] Iteration 1550000, lr = 0.01
I0830 11:22:13.771498 916722 solver.cpp:218] Iteration 1550500 (16.8079 iter/s, 29.748s/500 iters), loss = 0.0623478
I0830 11:22:13.771548 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0623508 (* 1 = 0.0623508 loss)
I0830 11:22:13.771557 916722 sgd_solver.cpp:106] Iteration 1550500, lr = 0.01
I0830 11:22:43.540693 916722 solver.cpp:218] Iteration 1551000 (16.796 iter/s, 29.769s/500 iters), loss = 0.0469457
I0830 11:22:43.540752 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0469485 (* 1 = 0.0469485 loss)
I0830 11:22:43.540761 916722 sgd_solver.cpp:106] Iteration 1551000, lr = 0.01
I0830 11:23:13.319437 916722 solver.cpp:218] Iteration 1551500 (16.7906 iter/s, 29.7785s/500 iters), loss = 0.106495
I0830 11:23:13.319487 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.106498 (* 1 = 0.106498 loss)
I0830 11:23:13.319496 916722 sgd_solver.cpp:106] Iteration 1551500, lr = 0.01
I0830 11:23:43.109581 916722 solver.cpp:218] Iteration 1552000 (16.7842 iter/s, 29.7899s/500 iters), loss = 0.420181
I0830 11:23:43.109638 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.420184 (* 1 = 0.420184 loss)
I0830 11:23:43.109647 916722 sgd_solver.cpp:106] Iteration 1552000, lr = 0.01
I0830 11:24:12.902453 916722 solver.cpp:218] Iteration 1552500 (16.7827 iter/s, 29.7927s/500 iters), loss = 0.37224
I0830 11:24:12.902505 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.372243 (* 1 = 0.372243 loss)
I0830 11:24:12.902516 916722 sgd_solver.cpp:106] Iteration 1552500, lr = 0.01
I0830 11:24:42.700426 916722 solver.cpp:218] Iteration 1553000 (16.7798 iter/s, 29.7978s/500 iters), loss = 0.153915
I0830 11:24:42.700484 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.153918 (* 1 = 0.153918 loss)
I0830 11:24:42.700492 916722 sgd_solver.cpp:106] Iteration 1553000, lr = 0.01
I0830 11:25:12.500489 916722 solver.cpp:218] Iteration 1553500 (16.7786 iter/s, 29.7999s/500 iters), loss = 0.508511
I0830 11:25:12.500540 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.508514 (* 1 = 0.508514 loss)
I0830 11:25:12.500550 916722 sgd_solver.cpp:106] Iteration 1553500, lr = 0.01
I0830 11:25:42.300861 916722 solver.cpp:218] Iteration 1554000 (16.7784 iter/s, 29.8002s/500 iters), loss = 0.0359742
I0830 11:25:42.300915 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0359769 (* 1 = 0.0359769 loss)
I0830 11:25:42.300923 916722 sgd_solver.cpp:106] Iteration 1554000, lr = 0.01
I0830 11:26:12.089949 916722 solver.cpp:218] Iteration 1554500 (16.7848 iter/s, 29.7889s/500 iters), loss = 0.161053
I0830 11:26:12.089999 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.161056 (* 1 = 0.161056 loss)
I0830 11:26:12.090009 916722 sgd_solver.cpp:106] Iteration 1554500, lr = 0.01
I0830 11:26:41.879012 916722 solver.cpp:218] Iteration 1555000 (16.7848 iter/s, 29.7889s/500 iters), loss = 0.0695583
I0830 11:26:41.879072 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0695612 (* 1 = 0.0695612 loss)
I0830 11:26:41.879081 916722 sgd_solver.cpp:106] Iteration 1555000, lr = 0.01
I0830 11:27:11.678172 916722 solver.cpp:218] Iteration 1555500 (16.7791 iter/s, 29.799s/500 iters), loss = 0.106258
I0830 11:27:11.678223 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.106261 (* 1 = 0.106261 loss)
I0830 11:27:11.678233 916722 sgd_solver.cpp:106] Iteration 1555500, lr = 0.01
I0830 11:27:41.475136 916722 solver.cpp:218] Iteration 1556000 (16.7803 iter/s, 29.7968s/500 iters), loss = 0.219686
I0830 11:27:41.475208 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.219689 (* 1 = 0.219689 loss)
I0830 11:27:41.475215 916722 sgd_solver.cpp:106] Iteration 1556000, lr = 0.01
I0830 11:28:11.262919 916722 solver.cpp:218] Iteration 1556500 (16.7855 iter/s, 29.7876s/500 iters), loss = 0.134597
I0830 11:28:11.262970 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.1346 (* 1 = 0.1346 loss)
I0830 11:28:11.262980 916722 sgd_solver.cpp:106] Iteration 1556500, lr = 0.01
I0830 11:28:41.058333 916722 solver.cpp:218] Iteration 1557000 (16.7812 iter/s, 29.7952s/500 iters), loss = 0.0841205
I0830 11:28:41.058393 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0841234 (* 1 = 0.0841234 loss)
I0830 11:28:41.058403 916722 sgd_solver.cpp:106] Iteration 1557000, lr = 0.01
I0830 11:29:10.852034 916722 solver.cpp:218] Iteration 1557500 (16.7822 iter/s, 29.7935s/500 iters), loss = 0.128952
I0830 11:29:10.852085 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128955 (* 1 = 0.128955 loss)
I0830 11:29:10.852094 916722 sgd_solver.cpp:106] Iteration 1557500, lr = 0.01
I0830 11:29:40.641331 916722 solver.cpp:218] Iteration 1558000 (16.7847 iter/s, 29.7891s/500 iters), loss = 0.122235
I0830 11:29:40.641386 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.122237 (* 1 = 0.122237 loss)
I0830 11:29:40.641394 916722 sgd_solver.cpp:106] Iteration 1558000, lr = 0.01
I0830 11:30:10.443018 916722 solver.cpp:218] Iteration 1558500 (16.7777 iter/s, 29.8015s/500 iters), loss = 0.116189
I0830 11:30:10.443069 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.116192 (* 1 = 0.116192 loss)
I0830 11:30:10.443078 916722 sgd_solver.cpp:106] Iteration 1558500, lr = 0.01
I0830 11:30:40.247727 916722 solver.cpp:218] Iteration 1559000 (16.776 iter/s, 29.8045s/500 iters), loss = 0.192269
I0830 11:30:40.247786 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.192272 (* 1 = 0.192272 loss)
I0830 11:30:40.247795 916722 sgd_solver.cpp:106] Iteration 1559000, lr = 0.01
I0830 11:31:10.039629 916722 solver.cpp:218] Iteration 1559500 (16.7832 iter/s, 29.7917s/500 iters), loss = 0.409157
I0830 11:31:10.039678 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.409159 (* 1 = 0.409159 loss)
I0830 11:31:10.039687 916722 sgd_solver.cpp:106] Iteration 1559500, lr = 0.01
I0830 11:31:39.836813 916722 solver.cpp:218] Iteration 1560000 (16.7802 iter/s, 29.797s/500 iters), loss = 0.135744
I0830 11:31:39.836872 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.135747 (* 1 = 0.135747 loss)
I0830 11:31:39.836881 916722 sgd_solver.cpp:106] Iteration 1560000, lr = 0.01
I0830 11:32:09.634552 916722 solver.cpp:218] Iteration 1560500 (16.7799 iter/s, 29.7975s/500 iters), loss = 0.0747582
I0830 11:32:09.634601 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0747611 (* 1 = 0.0747611 loss)
I0830 11:32:09.634610 916722 sgd_solver.cpp:106] Iteration 1560500, lr = 0.01
I0830 11:32:39.426095 916722 solver.cpp:218] Iteration 1561000 (16.7834 iter/s, 29.7913s/500 iters), loss = 0.0741031
I0830 11:32:39.426151 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0741059 (* 1 = 0.0741059 loss)
I0830 11:32:39.426160 916722 sgd_solver.cpp:106] Iteration 1561000, lr = 0.01
I0830 11:33:09.221117 916722 solver.cpp:218] Iteration 1561500 (16.7814 iter/s, 29.7948s/500 iters), loss = 0.132789
I0830 11:33:09.221168 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.132792 (* 1 = 0.132792 loss)
I0830 11:33:09.221176 916722 sgd_solver.cpp:106] Iteration 1561500, lr = 0.01
I0830 11:33:39.021323 916722 solver.cpp:218] Iteration 1562000 (16.7785 iter/s, 29.8s/500 iters), loss = 0.0362349
I0830 11:33:39.021382 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0362379 (* 1 = 0.0362379 loss)
I0830 11:33:39.021397 916722 sgd_solver.cpp:106] Iteration 1562000, lr = 0.01
I0830 11:34:08.817546 916722 solver.cpp:218] Iteration 1562500 (16.7806 iter/s, 29.7964s/500 iters), loss = 0.0377004
I0830 11:34:08.817597 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0377036 (* 1 = 0.0377036 loss)
I0830 11:34:08.817620 916722 sgd_solver.cpp:106] Iteration 1562500, lr = 0.01
I0830 11:34:38.616019 916722 solver.cpp:218] Iteration 1563000 (16.7792 iter/s, 29.7987s/500 iters), loss = 0.202693
I0830 11:34:38.616088 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.202696 (* 1 = 0.202696 loss)
I0830 11:34:38.616097 916722 sgd_solver.cpp:106] Iteration 1563000, lr = 0.01
I0830 11:35:08.407670 916722 solver.cpp:218] Iteration 1563500 (16.7831 iter/s, 29.7919s/500 iters), loss = 0.152407
I0830 11:35:08.407721 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152411 (* 1 = 0.152411 loss)
I0830 11:35:08.407730 916722 sgd_solver.cpp:106] Iteration 1563500, lr = 0.01
I0830 11:35:38.205046 916722 solver.cpp:218] Iteration 1564000 (16.7799 iter/s, 29.7976s/500 iters), loss = 0.0458711
I0830 11:35:38.205103 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0458744 (* 1 = 0.0458744 loss)
I0830 11:35:38.205112 916722 sgd_solver.cpp:106] Iteration 1564000, lr = 0.01
I0830 11:36:07.996012 916722 solver.cpp:218] Iteration 1564500 (16.7835 iter/s, 29.7912s/500 iters), loss = 0.139751
I0830 11:36:07.996059 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139754 (* 1 = 0.139754 loss)
I0830 11:36:07.996069 916722 sgd_solver.cpp:106] Iteration 1564500, lr = 0.01
I0830 11:36:37.792546 916722 solver.cpp:218] Iteration 1565000 (16.7804 iter/s, 29.7967s/500 iters), loss = 0.135071
I0830 11:36:37.792603 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.135074 (* 1 = 0.135074 loss)
I0830 11:36:37.792613 916722 sgd_solver.cpp:106] Iteration 1565000, lr = 0.01
I0830 11:37:07.590783 916722 solver.cpp:218] Iteration 1565500 (16.7794 iter/s, 29.7984s/500 iters), loss = 0.103086
I0830 11:37:07.590833 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.103089 (* 1 = 0.103089 loss)
I0830 11:37:07.590843 916722 sgd_solver.cpp:106] Iteration 1565500, lr = 0.01
I0830 11:37:37.386379 916722 solver.cpp:218] Iteration 1566000 (16.7809 iter/s, 29.7957s/500 iters), loss = 0.209756
I0830 11:37:37.386435 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.209759 (* 1 = 0.209759 loss)
I0830 11:37:37.386443 916722 sgd_solver.cpp:106] Iteration 1566000, lr = 0.01
I0830 11:38:07.181389 916722 solver.cpp:218] Iteration 1566500 (16.7813 iter/s, 29.7951s/500 iters), loss = 0.050569
I0830 11:38:07.181437 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0505724 (* 1 = 0.0505724 loss)
I0830 11:38:07.181447 916722 sgd_solver.cpp:106] Iteration 1566500, lr = 0.01
I0830 11:38:36.974429 916722 solver.cpp:218] Iteration 1567000 (16.7824 iter/s, 29.7932s/500 iters), loss = 0.23615
I0830 11:38:36.974481 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.236153 (* 1 = 0.236153 loss)
I0830 11:38:36.974489 916722 sgd_solver.cpp:106] Iteration 1567000, lr = 0.01
I0830 11:39:06.773137 916722 solver.cpp:218] Iteration 1567500 (16.7792 iter/s, 29.7988s/500 iters), loss = 0.0886975
I0830 11:39:06.773187 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0887007 (* 1 = 0.0887007 loss)
I0830 11:39:06.773197 916722 sgd_solver.cpp:106] Iteration 1567500, lr = 0.01
I0830 11:39:36.569360 916722 solver.cpp:218] Iteration 1568000 (16.7806 iter/s, 29.7963s/500 iters), loss = 0.118315
I0830 11:39:36.569420 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.118318 (* 1 = 0.118318 loss)
I0830 11:39:36.569428 916722 sgd_solver.cpp:106] Iteration 1568000, lr = 0.01
I0830 11:40:06.364470 916722 solver.cpp:218] Iteration 1568500 (16.7812 iter/s, 29.7952s/500 iters), loss = 0.36433
I0830 11:40:06.364519 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.364333 (* 1 = 0.364333 loss)
I0830 11:40:06.364528 916722 sgd_solver.cpp:106] Iteration 1568500, lr = 0.01
I0830 11:40:36.158177 916722 solver.cpp:218] Iteration 1569000 (16.782 iter/s, 29.7938s/500 iters), loss = 0.101807
I0830 11:40:36.158246 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.10181 (* 1 = 0.10181 loss)
I0830 11:40:36.158259 916722 sgd_solver.cpp:106] Iteration 1569000, lr = 0.01
I0830 11:41:05.953688 916722 solver.cpp:218] Iteration 1569500 (16.781 iter/s, 29.7955s/500 iters), loss = 0.175886
I0830 11:41:05.953740 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.175889 (* 1 = 0.175889 loss)
I0830 11:41:05.953748 916722 sgd_solver.cpp:106] Iteration 1569500, lr = 0.01
I0830 11:41:35.743932 916722 solver.cpp:218] Iteration 1570000 (16.784 iter/s, 29.7903s/500 iters), loss = 0.117875
I0830 11:41:35.743988 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.117878 (* 1 = 0.117878 loss)
I0830 11:41:35.743996 916722 sgd_solver.cpp:106] Iteration 1570000, lr = 0.01
I0830 11:42:05.533802 916722 solver.cpp:218] Iteration 1570500 (16.7842 iter/s, 29.7899s/500 iters), loss = 0.18149
I0830 11:42:05.533851 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.181493 (* 1 = 0.181493 loss)
I0830 11:42:05.533860 916722 sgd_solver.cpp:106] Iteration 1570500, lr = 0.01
I0830 11:42:35.323709 916722 solver.cpp:218] Iteration 1571000 (16.7842 iter/s, 29.7899s/500 iters), loss = 0.288825
I0830 11:42:35.323765 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.288828 (* 1 = 0.288828 loss)
I0830 11:42:35.323772 916722 sgd_solver.cpp:106] Iteration 1571000, lr = 0.01
I0830 11:43:05.109680 916722 solver.cpp:218] Iteration 1571500 (16.7864 iter/s, 29.786s/500 iters), loss = 0.0252018
I0830 11:43:05.109731 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.025205 (* 1 = 0.025205 loss)
I0830 11:43:05.109740 916722 sgd_solver.cpp:106] Iteration 1571500, lr = 0.01
I0830 11:43:34.893999 916722 solver.cpp:218] Iteration 1572000 (16.7874 iter/s, 29.7843s/500 iters), loss = 0.145909
I0830 11:43:34.894054 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.145912 (* 1 = 0.145912 loss)
I0830 11:43:34.894062 916722 sgd_solver.cpp:106] Iteration 1572000, lr = 0.01
I0830 11:44:04.680205 916722 solver.cpp:218] Iteration 1572500 (16.7863 iter/s, 29.7862s/500 iters), loss = 0.20797
I0830 11:44:04.680253 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.207974 (* 1 = 0.207974 loss)
I0830 11:44:04.680263 916722 sgd_solver.cpp:106] Iteration 1572500, lr = 0.01
I0830 11:44:34.467376 916722 solver.cpp:218] Iteration 1573000 (16.7858 iter/s, 29.7872s/500 iters), loss = 0.140376
I0830 11:44:34.467432 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.140379 (* 1 = 0.140379 loss)
I0830 11:44:34.467442 916722 sgd_solver.cpp:106] Iteration 1573000, lr = 0.01
I0830 11:45:04.259049 916722 solver.cpp:218] Iteration 1573500 (16.7832 iter/s, 29.7916s/500 iters), loss = 0.122129
I0830 11:45:04.259102 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.122132 (* 1 = 0.122132 loss)
I0830 11:45:04.259111 916722 sgd_solver.cpp:106] Iteration 1573500, lr = 0.01
I0830 11:45:34.050604 916722 solver.cpp:218] Iteration 1574000 (16.7833 iter/s, 29.7915s/500 iters), loss = 0.141935
I0830 11:45:34.050660 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.141938 (* 1 = 0.141938 loss)
I0830 11:45:34.050668 916722 sgd_solver.cpp:106] Iteration 1574000, lr = 0.01
I0830 11:46:03.838198 916722 solver.cpp:218] Iteration 1574500 (16.7855 iter/s, 29.7876s/500 iters), loss = 0.24257
I0830 11:46:03.838248 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.242574 (* 1 = 0.242574 loss)
I0830 11:46:03.838258 916722 sgd_solver.cpp:106] Iteration 1574500, lr = 0.01
I0830 11:46:33.631304 916722 solver.cpp:218] Iteration 1575000 (16.7824 iter/s, 29.7931s/500 iters), loss = 0.173234
I0830 11:46:33.631361 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.173237 (* 1 = 0.173237 loss)
I0830 11:46:33.631369 916722 sgd_solver.cpp:106] Iteration 1575000, lr = 0.01
I0830 11:47:03.418215 916722 solver.cpp:218] Iteration 1575500 (16.7859 iter/s, 29.7869s/500 iters), loss = 0.127115
I0830 11:47:03.418258 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.127118 (* 1 = 0.127118 loss)
I0830 11:47:03.418267 916722 sgd_solver.cpp:106] Iteration 1575500, lr = 0.01
I0830 11:47:33.205693 916722 solver.cpp:218] Iteration 1576000 (16.7856 iter/s, 29.7874s/500 iters), loss = 0.245335
I0830 11:47:33.205760 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.245339 (* 1 = 0.245339 loss)
I0830 11:47:33.205770 916722 sgd_solver.cpp:106] Iteration 1576000, lr = 0.01
I0830 11:48:02.996153 916722 solver.cpp:218] Iteration 1576500 (16.7839 iter/s, 29.7904s/500 iters), loss = 0.0975443
I0830 11:48:02.996201 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0975475 (* 1 = 0.0975475 loss)
I0830 11:48:02.996210 916722 sgd_solver.cpp:106] Iteration 1576500, lr = 0.01
I0830 11:48:32.783804 916722 solver.cpp:218] Iteration 1577000 (16.7855 iter/s, 29.7876s/500 iters), loss = 0.117243
I0830 11:48:32.783859 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.117246 (* 1 = 0.117246 loss)
I0830 11:48:32.783867 916722 sgd_solver.cpp:106] Iteration 1577000, lr = 0.01
I0830 11:49:02.573073 916722 solver.cpp:218] Iteration 1577500 (16.7846 iter/s, 29.7892s/500 iters), loss = 0.285952
I0830 11:49:02.573122 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.285955 (* 1 = 0.285955 loss)
I0830 11:49:02.573132 916722 sgd_solver.cpp:106] Iteration 1577500, lr = 0.01
I0830 11:49:32.362777 916722 solver.cpp:218] Iteration 1578000 (16.7844 iter/s, 29.7896s/500 iters), loss = 0.158699
I0830 11:49:32.362829 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.158702 (* 1 = 0.158702 loss)
I0830 11:49:32.362838 916722 sgd_solver.cpp:106] Iteration 1578000, lr = 0.01
I0830 11:50:02.153252 916722 solver.cpp:218] Iteration 1578500 (16.7839 iter/s, 29.7904s/500 iters), loss = 0.179857
I0830 11:50:02.153306 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.179861 (* 1 = 0.179861 loss)
I0830 11:50:02.153316 916722 sgd_solver.cpp:106] Iteration 1578500, lr = 0.01
I0830 11:50:31.946987 916722 solver.cpp:218] Iteration 1579000 (16.7821 iter/s, 29.7937s/500 iters), loss = 0.247266
I0830 11:50:31.947048 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.247269 (* 1 = 0.247269 loss)
I0830 11:50:31.947057 916722 sgd_solver.cpp:106] Iteration 1579000, lr = 0.01
I0830 11:51:01.739617 916722 solver.cpp:218] Iteration 1579500 (16.7827 iter/s, 29.7925s/500 iters), loss = 0.208155
I0830 11:51:01.739667 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.208158 (* 1 = 0.208158 loss)
I0830 11:51:01.739677 916722 sgd_solver.cpp:106] Iteration 1579500, lr = 0.01
I0830 11:51:31.528870 916722 solver.cpp:218] Iteration 1580000 (16.7846 iter/s, 29.7892s/500 iters), loss = 0.105272
I0830 11:51:31.528930 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105276 (* 1 = 0.105276 loss)
I0830 11:51:31.528939 916722 sgd_solver.cpp:106] Iteration 1580000, lr = 0.01
I0830 11:52:01.316239 916722 solver.cpp:218] Iteration 1580500 (16.7857 iter/s, 29.7873s/500 iters), loss = 0.134048
I0830 11:52:01.316288 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.134052 (* 1 = 0.134052 loss)
I0830 11:52:01.316298 916722 sgd_solver.cpp:106] Iteration 1580500, lr = 0.01
I0830 11:52:31.101363 916722 solver.cpp:218] Iteration 1581000 (16.787 iter/s, 29.785s/500 iters), loss = 0.124385
I0830 11:52:31.101423 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.124389 (* 1 = 0.124389 loss)
I0830 11:52:31.101431 916722 sgd_solver.cpp:106] Iteration 1581000, lr = 0.01
I0830 11:53:00.885614 916722 solver.cpp:218] Iteration 1581500 (16.7875 iter/s, 29.7842s/500 iters), loss = 0.113704
I0830 11:53:00.885663 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.113708 (* 1 = 0.113708 loss)
I0830 11:53:00.885673 916722 sgd_solver.cpp:106] Iteration 1581500, lr = 0.01
I0830 11:53:30.669286 916722 solver.cpp:218] Iteration 1582000 (16.7878 iter/s, 29.7836s/500 iters), loss = 0.178634
I0830 11:53:30.669342 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.178638 (* 1 = 0.178638 loss)
I0830 11:53:30.669350 916722 sgd_solver.cpp:106] Iteration 1582000, lr = 0.01
I0830 11:54:00.453570 916722 solver.cpp:218] Iteration 1582500 (16.7874 iter/s, 29.7842s/500 iters), loss = 0.0590988
I0830 11:54:00.453631 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0591022 (* 1 = 0.0591022 loss)
I0830 11:54:00.453641 916722 sgd_solver.cpp:106] Iteration 1582500, lr = 0.01
I0830 11:54:30.239347 916722 solver.cpp:218] Iteration 1583000 (16.7866 iter/s, 29.7857s/500 iters), loss = 0.0579496
I0830 11:54:30.239419 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.057953 (* 1 = 0.057953 loss)
I0830 11:54:30.239428 916722 sgd_solver.cpp:106] Iteration 1583000, lr = 0.01
I0830 11:55:00.028930 916722 solver.cpp:218] Iteration 1583500 (16.7845 iter/s, 29.7895s/500 iters), loss = 0.0109916
I0830 11:55:00.028985 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.010995 (* 1 = 0.010995 loss)
I0830 11:55:00.028995 916722 sgd_solver.cpp:106] Iteration 1583500, lr = 0.01
I0830 11:55:29.817234 916722 solver.cpp:218] Iteration 1584000 (16.7852 iter/s, 29.7882s/500 iters), loss = 0.105294
I0830 11:55:29.817296 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105297 (* 1 = 0.105297 loss)
I0830 11:55:29.817304 916722 sgd_solver.cpp:106] Iteration 1584000, lr = 0.01
I0830 11:55:59.603489 916722 solver.cpp:218] Iteration 1584500 (16.7863 iter/s, 29.7861s/500 iters), loss = 0.252043
I0830 11:55:59.603543 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.252046 (* 1 = 0.252046 loss)
I0830 11:55:59.603551 916722 sgd_solver.cpp:106] Iteration 1584500, lr = 0.01
I0830 11:56:29.387284 916722 solver.cpp:218] Iteration 1585000 (16.7877 iter/s, 29.7837s/500 iters), loss = 0.119385
I0830 11:56:29.387341 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.119389 (* 1 = 0.119389 loss)
I0830 11:56:29.387349 916722 sgd_solver.cpp:106] Iteration 1585000, lr = 0.01
I0830 11:56:59.179098 916722 solver.cpp:218] Iteration 1585500 (16.7832 iter/s, 29.7917s/500 iters), loss = 0.348005
I0830 11:56:59.179150 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.348009 (* 1 = 0.348009 loss)
I0830 11:56:59.179158 916722 sgd_solver.cpp:106] Iteration 1585500, lr = 0.01
I0830 11:57:28.966347 916722 solver.cpp:218] Iteration 1586000 (16.7858 iter/s, 29.7871s/500 iters), loss = 0.121503
I0830 11:57:28.966403 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.121506 (* 1 = 0.121506 loss)
I0830 11:57:28.966411 916722 sgd_solver.cpp:106] Iteration 1586000, lr = 0.01
I0830 11:57:58.752564 916722 solver.cpp:218] Iteration 1586500 (16.7864 iter/s, 29.7861s/500 iters), loss = 0.297596
I0830 11:57:58.752614 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.297599 (* 1 = 0.297599 loss)
I0830 11:57:58.752622 916722 sgd_solver.cpp:106] Iteration 1586500, lr = 0.01
I0830 11:58:28.539958 916722 solver.cpp:218] Iteration 1587000 (16.7857 iter/s, 29.7873s/500 iters), loss = 0.0736532
I0830 11:58:28.540019 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0736562 (* 1 = 0.0736562 loss)
I0830 11:58:28.540027 916722 sgd_solver.cpp:106] Iteration 1587000, lr = 0.01
I0830 11:58:58.327780 916722 solver.cpp:218] Iteration 1587500 (16.7855 iter/s, 29.7877s/500 iters), loss = 0.116158
I0830 11:58:58.327833 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.116161 (* 1 = 0.116161 loss)
I0830 11:58:58.327843 916722 sgd_solver.cpp:106] Iteration 1587500, lr = 0.01
I0830 11:59:28.116945 916722 solver.cpp:218] Iteration 1588000 (16.7847 iter/s, 29.789s/500 iters), loss = 0.243332
I0830 11:59:28.117004 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.243336 (* 1 = 0.243336 loss)
I0830 11:59:28.117012 916722 sgd_solver.cpp:106] Iteration 1588000, lr = 0.01
I0830 11:59:57.904629 916722 solver.cpp:218] Iteration 1588500 (16.7855 iter/s, 29.7876s/500 iters), loss = 0.0824936
I0830 11:59:57.904682 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0824969 (* 1 = 0.0824969 loss)
I0830 11:59:57.904691 916722 sgd_solver.cpp:106] Iteration 1588500, lr = 0.01
I0830 12:00:27.695665 916722 solver.cpp:218] Iteration 1589000 (16.7836 iter/s, 29.7909s/500 iters), loss = 0.18561
I0830 12:00:27.695737 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.185613 (* 1 = 0.185613 loss)
I0830 12:00:27.695746 916722 sgd_solver.cpp:106] Iteration 1589000, lr = 0.01
I0830 12:00:57.486425 916722 solver.cpp:218] Iteration 1589500 (16.7838 iter/s, 29.7906s/500 iters), loss = 0.240128
I0830 12:00:57.486479 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.240131 (* 1 = 0.240131 loss)
I0830 12:00:57.486488 916722 sgd_solver.cpp:106] Iteration 1589500, lr = 0.01
I0830 12:01:27.278888 916722 solver.cpp:218] Iteration 1590000 (16.7828 iter/s, 29.7923s/500 iters), loss = 0.396578
I0830 12:01:27.278944 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.396581 (* 1 = 0.396581 loss)
I0830 12:01:27.278952 916722 sgd_solver.cpp:106] Iteration 1590000, lr = 0.01
I0830 12:01:57.063223 916722 solver.cpp:218] Iteration 1590500 (16.7874 iter/s, 29.7842s/500 iters), loss = 0.0147976
I0830 12:01:57.063271 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0148008 (* 1 = 0.0148008 loss)
I0830 12:01:57.063282 916722 sgd_solver.cpp:106] Iteration 1590500, lr = 0.01
I0830 12:02:26.848062 916722 solver.cpp:218] Iteration 1591000 (16.7871 iter/s, 29.7847s/500 iters), loss = 0.249741
I0830 12:02:26.848117 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.249744 (* 1 = 0.249744 loss)
I0830 12:02:26.848125 916722 sgd_solver.cpp:106] Iteration 1591000, lr = 0.01
I0830 12:02:56.634479 916722 solver.cpp:218] Iteration 1591500 (16.7862 iter/s, 29.7863s/500 iters), loss = 0.264255
I0830 12:02:56.634531 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.264259 (* 1 = 0.264259 loss)
I0830 12:02:56.634541 916722 sgd_solver.cpp:106] Iteration 1591500, lr = 0.01
I0830 12:03:26.422524 916722 solver.cpp:218] Iteration 1592000 (16.7853 iter/s, 29.7879s/500 iters), loss = 0.260357
I0830 12:03:26.422585 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.26036 (* 1 = 0.26036 loss)
I0830 12:03:26.422593 916722 sgd_solver.cpp:106] Iteration 1592000, lr = 0.01
I0830 12:03:56.210579 916722 solver.cpp:218] Iteration 1592500 (16.7853 iter/s, 29.7879s/500 iters), loss = 0.144547
I0830 12:03:56.210630 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.14455 (* 1 = 0.14455 loss)
I0830 12:03:56.210640 916722 sgd_solver.cpp:106] Iteration 1592500, lr = 0.01
I0830 12:04:26.000336 916722 solver.cpp:218] Iteration 1593000 (16.7844 iter/s, 29.7896s/500 iters), loss = 0.0838961
I0830 12:04:26.000396 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0838996 (* 1 = 0.0838996 loss)
I0830 12:04:26.000404 916722 sgd_solver.cpp:106] Iteration 1593000, lr = 0.01
I0830 12:04:55.786360 916722 solver.cpp:218] Iteration 1593500 (16.7865 iter/s, 29.7859s/500 iters), loss = 0.0543456
I0830 12:04:55.786410 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0543491 (* 1 = 0.0543491 loss)
I0830 12:04:55.786420 916722 sgd_solver.cpp:106] Iteration 1593500, lr = 0.01
I0830 12:05:25.575546 916722 solver.cpp:218] Iteration 1594000 (16.7847 iter/s, 29.7891s/500 iters), loss = 0.132594
I0830 12:05:25.575604 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.132597 (* 1 = 0.132597 loss)
I0830 12:05:25.575613 916722 sgd_solver.cpp:106] Iteration 1594000, lr = 0.01
I0830 12:05:55.363986 916722 solver.cpp:218] Iteration 1594500 (16.7851 iter/s, 29.7883s/500 iters), loss = 0.121866
I0830 12:05:55.364035 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.121869 (* 1 = 0.121869 loss)
I0830 12:05:55.364045 916722 sgd_solver.cpp:106] Iteration 1594500, lr = 0.01
I0830 12:06:25.152252 916722 solver.cpp:218] Iteration 1595000 (16.7852 iter/s, 29.7881s/500 iters), loss = 0.21677
I0830 12:06:25.152312 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.216773 (* 1 = 0.216773 loss)
I0830 12:06:25.152319 916722 sgd_solver.cpp:106] Iteration 1595000, lr = 0.01
I0830 12:06:54.942999 916722 solver.cpp:218] Iteration 1595500 (16.7838 iter/s, 29.7906s/500 iters), loss = 0.153284
I0830 12:06:54.943059 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.153288 (* 1 = 0.153288 loss)
I0830 12:06:54.943068 916722 sgd_solver.cpp:106] Iteration 1595500, lr = 0.01
I0830 12:07:24.733109 916722 solver.cpp:218] Iteration 1596000 (16.7842 iter/s, 29.79s/500 iters), loss = 0.0206442
I0830 12:07:24.733184 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0206477 (* 1 = 0.0206477 loss)
I0830 12:07:24.733193 916722 sgd_solver.cpp:106] Iteration 1596000, lr = 0.01
I0830 12:07:54.522909 916722 solver.cpp:218] Iteration 1596500 (16.7844 iter/s, 29.7896s/500 iters), loss = 0.153619
I0830 12:07:54.522959 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.153623 (* 1 = 0.153623 loss)
I0830 12:07:54.522967 916722 sgd_solver.cpp:106] Iteration 1596500, lr = 0.01
I0830 12:08:24.308722 916722 solver.cpp:218] Iteration 1597000 (16.7866 iter/s, 29.7857s/500 iters), loss = 0.149597
I0830 12:08:24.308791 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.1496 (* 1 = 0.1496 loss)
I0830 12:08:24.308800 916722 sgd_solver.cpp:106] Iteration 1597000, lr = 0.01
I0830 12:08:54.102969 916722 solver.cpp:218] Iteration 1597500 (16.7818 iter/s, 29.7941s/500 iters), loss = 0.336905
I0830 12:08:54.103020 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.336908 (* 1 = 0.336908 loss)
I0830 12:08:54.103029 916722 sgd_solver.cpp:106] Iteration 1597500, lr = 0.01
I0830 12:09:23.901551 916722 solver.cpp:218] Iteration 1598000 (16.7794 iter/s, 29.7985s/500 iters), loss = 0.148844
I0830 12:09:23.901609 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.148848 (* 1 = 0.148848 loss)
I0830 12:09:23.901618 916722 sgd_solver.cpp:106] Iteration 1598000, lr = 0.01
I0830 12:09:53.703162 916722 solver.cpp:218] Iteration 1598500 (16.7777 iter/s, 29.8015s/500 iters), loss = 0.289694
I0830 12:09:53.703212 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.289697 (* 1 = 0.289697 loss)
I0830 12:09:53.703220 916722 sgd_solver.cpp:106] Iteration 1598500, lr = 0.01
I0830 12:10:23.501338 916722 solver.cpp:218] Iteration 1599000 (16.7796 iter/s, 29.7981s/500 iters), loss = 0.116969
I0830 12:10:23.501394 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.116972 (* 1 = 0.116972 loss)
I0830 12:10:23.501403 916722 sgd_solver.cpp:106] Iteration 1599000, lr = 0.01
I0830 12:10:53.297101 916722 solver.cpp:218] Iteration 1599500 (16.781 iter/s, 29.7956s/500 iters), loss = 0.265417
I0830 12:10:53.297152 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.265421 (* 1 = 0.265421 loss)
I0830 12:10:53.297163 916722 sgd_solver.cpp:106] Iteration 1599500, lr = 0.01
I0830 12:11:23.033155 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_1600000.caffemodel
I0830 12:11:23.052311 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_1600000.solverstate
I0830 12:11:23.058512 916722 solver.cpp:330] Iteration 1600000, Testing net (#0)
I0830 12:11:38.531827 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8776
I0830 12:11:38.531872 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.429737 (* 1 = 0.429737 loss)
I0830 12:11:38.590451 916722 solver.cpp:218] Iteration 1600000 (11.0392 iter/s, 45.2932s/500 iters), loss = 0.169255
I0830 12:11:38.590478 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.169258 (* 1 = 0.169258 loss)
I0830 12:11:38.590487 916722 sgd_solver.cpp:106] Iteration 1600000, lr = 0.01
I0830 12:12:08.348773 916722 solver.cpp:218] Iteration 1600500 (16.8021 iter/s, 29.7582s/500 iters), loss = 0.0669093
I0830 12:12:08.348829 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0669127 (* 1 = 0.0669127 loss)
I0830 12:12:08.348837 916722 sgd_solver.cpp:106] Iteration 1600500, lr = 0.01
I0830 12:12:38.114166 916722 solver.cpp:218] Iteration 1601000 (16.7981 iter/s, 29.7653s/500 iters), loss = 0.136789
I0830 12:12:38.114215 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.136792 (* 1 = 0.136792 loss)
I0830 12:12:38.114239 916722 sgd_solver.cpp:106] Iteration 1601000, lr = 0.01
I0830 12:13:07.892899 916722 solver.cpp:218] Iteration 1601500 (16.7906 iter/s, 29.7786s/500 iters), loss = 0.181697
I0830 12:13:07.892966 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.1817 (* 1 = 0.1817 loss)
I0830 12:13:07.892975 916722 sgd_solver.cpp:106] Iteration 1601500, lr = 0.01
I0830 12:13:37.673935 916722 solver.cpp:218] Iteration 1602000 (16.7893 iter/s, 29.7809s/500 iters), loss = 0.133879
I0830 12:13:37.673983 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133882 (* 1 = 0.133882 loss)
I0830 12:13:37.673993 916722 sgd_solver.cpp:106] Iteration 1602000, lr = 0.01
I0830 12:14:07.459692 916722 solver.cpp:218] Iteration 1602500 (16.7866 iter/s, 29.7856s/500 iters), loss = 0.0450426
I0830 12:14:07.459748 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.045046 (* 1 = 0.045046 loss)
I0830 12:14:07.459758 916722 sgd_solver.cpp:106] Iteration 1602500, lr = 0.01
I0830 12:14:37.246604 916722 solver.cpp:218] Iteration 1603000 (16.786 iter/s, 29.7868s/500 iters), loss = 0.142121
I0830 12:14:37.246652 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.142124 (* 1 = 0.142124 loss)
I0830 12:14:37.246662 916722 sgd_solver.cpp:106] Iteration 1603000, lr = 0.01
I0830 12:15:07.040475 916722 solver.cpp:218] Iteration 1603500 (16.7821 iter/s, 29.7937s/500 iters), loss = 0.135223
I0830 12:15:07.040536 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.135226 (* 1 = 0.135226 loss)
I0830 12:15:07.040545 916722 sgd_solver.cpp:106] Iteration 1603500, lr = 0.01
I0830 12:15:36.831575 916722 solver.cpp:218] Iteration 1604000 (16.7836 iter/s, 29.791s/500 iters), loss = 0.38943
I0830 12:15:36.831625 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.389433 (* 1 = 0.389433 loss)
I0830 12:15:36.831635 916722 sgd_solver.cpp:106] Iteration 1604000, lr = 0.01
I0830 12:16:06.624081 916722 solver.cpp:218] Iteration 1604500 (16.7828 iter/s, 29.7924s/500 iters), loss = 0.451091
I0830 12:16:06.624137 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.451094 (* 1 = 0.451094 loss)
I0830 12:16:06.624146 916722 sgd_solver.cpp:106] Iteration 1604500, lr = 0.01
I0830 12:16:36.409911 916722 solver.cpp:218] Iteration 1605000 (16.7866 iter/s, 29.7857s/500 iters), loss = 0.13271
I0830 12:16:36.409960 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.132714 (* 1 = 0.132714 loss)
I0830 12:16:36.409970 916722 sgd_solver.cpp:106] Iteration 1605000, lr = 0.01
I0830 12:17:06.194583 916722 solver.cpp:218] Iteration 1605500 (16.7872 iter/s, 29.7845s/500 iters), loss = 0.0591221
I0830 12:17:06.194640 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0591254 (* 1 = 0.0591254 loss)
I0830 12:17:06.194649 916722 sgd_solver.cpp:106] Iteration 1605500, lr = 0.01
I0830 12:17:35.981835 916722 solver.cpp:218] Iteration 1606000 (16.7858 iter/s, 29.7871s/500 iters), loss = 0.548979
I0830 12:17:35.981881 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.548982 (* 1 = 0.548982 loss)
I0830 12:17:35.981891 916722 sgd_solver.cpp:106] Iteration 1606000, lr = 0.01
I0830 12:18:05.757930 916722 solver.cpp:218] Iteration 1606500 (16.7921 iter/s, 29.776s/500 iters), loss = 0.184111
I0830 12:18:05.757989 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.184114 (* 1 = 0.184114 loss)
I0830 12:18:05.757997 916722 sgd_solver.cpp:106] Iteration 1606500, lr = 0.01
I0830 12:18:35.542816 916722 solver.cpp:218] Iteration 1607000 (16.7871 iter/s, 29.7847s/500 iters), loss = 0.239109
I0830 12:18:35.542865 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.239113 (* 1 = 0.239113 loss)
I0830 12:18:35.542873 916722 sgd_solver.cpp:106] Iteration 1607000, lr = 0.01
I0830 12:19:05.329890 916722 solver.cpp:218] Iteration 1607500 (16.7859 iter/s, 29.7869s/500 iters), loss = 0.366196
I0830 12:19:05.329950 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.366199 (* 1 = 0.366199 loss)
I0830 12:19:05.329958 916722 sgd_solver.cpp:106] Iteration 1607500, lr = 0.01
I0830 12:19:35.112946 916722 solver.cpp:218] Iteration 1608000 (16.7881 iter/s, 29.7829s/500 iters), loss = 0.223213
I0830 12:19:35.112994 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.223217 (* 1 = 0.223217 loss)
I0830 12:19:35.113003 916722 sgd_solver.cpp:106] Iteration 1608000, lr = 0.01
I0830 12:20:04.899155 916722 solver.cpp:218] Iteration 1608500 (16.7864 iter/s, 29.7861s/500 iters), loss = 0.184889
I0830 12:20:04.899230 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.184893 (* 1 = 0.184893 loss)
I0830 12:20:04.899238 916722 sgd_solver.cpp:106] Iteration 1608500, lr = 0.01
I0830 12:20:34.670068 916722 solver.cpp:218] Iteration 1609000 (16.795 iter/s, 29.7708s/500 iters), loss = 0.219112
I0830 12:20:34.670116 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.219115 (* 1 = 0.219115 loss)
I0830 12:20:34.670125 916722 sgd_solver.cpp:106] Iteration 1609000, lr = 0.01
I0830 12:21:04.443136 916722 solver.cpp:218] Iteration 1609500 (16.7938 iter/s, 29.7729s/500 iters), loss = 0.0393475
I0830 12:21:04.443193 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0393508 (* 1 = 0.0393508 loss)
I0830 12:21:04.443202 916722 sgd_solver.cpp:106] Iteration 1609500, lr = 0.01
I0830 12:21:34.208202 916722 solver.cpp:218] Iteration 1610000 (16.7983 iter/s, 29.7649s/500 iters), loss = 0.18517
I0830 12:21:34.208247 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.185173 (* 1 = 0.185173 loss)
I0830 12:21:34.208256 916722 sgd_solver.cpp:106] Iteration 1610000, lr = 0.01
I0830 12:22:03.978803 916722 solver.cpp:218] Iteration 1610500 (16.7952 iter/s, 29.7705s/500 iters), loss = 0.134297
I0830 12:22:03.978860 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.134301 (* 1 = 0.134301 loss)
I0830 12:22:03.978869 916722 sgd_solver.cpp:106] Iteration 1610500, lr = 0.01
I0830 12:22:33.752318 916722 solver.cpp:218] Iteration 1611000 (16.7935 iter/s, 29.7734s/500 iters), loss = 0.11382
I0830 12:22:33.752362 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.113823 (* 1 = 0.113823 loss)
I0830 12:22:33.752372 916722 sgd_solver.cpp:106] Iteration 1611000, lr = 0.01
I0830 12:23:03.523604 916722 solver.cpp:218] Iteration 1611500 (16.7948 iter/s, 29.7712s/500 iters), loss = 0.209444
I0830 12:23:03.523663 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.209448 (* 1 = 0.209448 loss)
I0830 12:23:03.523670 916722 sgd_solver.cpp:106] Iteration 1611500, lr = 0.01
I0830 12:23:33.293866 916722 solver.cpp:218] Iteration 1612000 (16.7954 iter/s, 29.7701s/500 iters), loss = 0.117308
I0830 12:23:33.293915 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.117311 (* 1 = 0.117311 loss)
I0830 12:23:33.293923 916722 sgd_solver.cpp:106] Iteration 1612000, lr = 0.01
I0830 12:24:03.062520 916722 solver.cpp:218] Iteration 1612500 (16.7963 iter/s, 29.7685s/500 iters), loss = 0.057946
I0830 12:24:03.062578 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0579492 (* 1 = 0.0579492 loss)
I0830 12:24:03.062587 916722 sgd_solver.cpp:106] Iteration 1612500, lr = 0.01
I0830 12:24:32.831692 916722 solver.cpp:218] Iteration 1613000 (16.796 iter/s, 29.769s/500 iters), loss = 0.2899
I0830 12:24:32.831745 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.289903 (* 1 = 0.289903 loss)
I0830 12:24:32.831755 916722 sgd_solver.cpp:106] Iteration 1613000, lr = 0.01
I0830 12:25:02.603677 916722 solver.cpp:218] Iteration 1613500 (16.7944 iter/s, 29.7718s/500 iters), loss = 0.304564
I0830 12:25:02.603734 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.304567 (* 1 = 0.304567 loss)
I0830 12:25:02.603742 916722 sgd_solver.cpp:106] Iteration 1613500, lr = 0.01
I0830 12:25:32.373068 916722 solver.cpp:218] Iteration 1614000 (16.7959 iter/s, 29.7693s/500 iters), loss = 0.15972
I0830 12:25:32.373121 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159723 (* 1 = 0.159723 loss)
I0830 12:25:32.373131 916722 sgd_solver.cpp:106] Iteration 1614000, lr = 0.01
I0830 12:26:02.141764 916722 solver.cpp:218] Iteration 1614500 (16.7962 iter/s, 29.7686s/500 iters), loss = 0.0554256
I0830 12:26:02.141834 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0554286 (* 1 = 0.0554286 loss)
I0830 12:26:02.141841 916722 sgd_solver.cpp:106] Iteration 1614500, lr = 0.01
I0830 12:26:31.904165 916722 solver.cpp:218] Iteration 1615000 (16.7998 iter/s, 29.7622s/500 iters), loss = 0.0842632
I0830 12:26:31.904211 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0842662 (* 1 = 0.0842662 loss)
I0830 12:26:31.904222 916722 sgd_solver.cpp:106] Iteration 1615000, lr = 0.01
I0830 12:27:01.671236 916722 solver.cpp:218] Iteration 1615500 (16.7972 iter/s, 29.7669s/500 iters), loss = 0.117267
I0830 12:27:01.671293 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.11727 (* 1 = 0.11727 loss)
I0830 12:27:01.671303 916722 sgd_solver.cpp:106] Iteration 1615500, lr = 0.01
I0830 12:27:31.439800 916722 solver.cpp:218] Iteration 1616000 (16.7963 iter/s, 29.7684s/500 iters), loss = 0.010989
I0830 12:27:31.439852 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.010992 (* 1 = 0.010992 loss)
I0830 12:27:31.439862 916722 sgd_solver.cpp:106] Iteration 1616000, lr = 0.01
I0830 12:28:01.199004 916722 solver.cpp:218] Iteration 1616500 (16.8016 iter/s, 29.7591s/500 iters), loss = 0.131806
I0830 12:28:01.199060 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131809 (* 1 = 0.131809 loss)
I0830 12:28:01.199069 916722 sgd_solver.cpp:106] Iteration 1616500, lr = 0.01
I0830 12:28:30.963519 916722 solver.cpp:218] Iteration 1617000 (16.7986 iter/s, 29.7644s/500 iters), loss = 0.33452
I0830 12:28:30.963569 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.334523 (* 1 = 0.334523 loss)
I0830 12:28:30.963578 916722 sgd_solver.cpp:106] Iteration 1617000, lr = 0.01
I0830 12:29:00.735340 916722 solver.cpp:218] Iteration 1617500 (16.7945 iter/s, 29.7717s/500 iters), loss = 0.0844504
I0830 12:29:00.735396 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0844535 (* 1 = 0.0844535 loss)
I0830 12:29:00.735405 916722 sgd_solver.cpp:106] Iteration 1617500, lr = 0.01
I0830 12:29:30.510159 916722 solver.cpp:218] Iteration 1618000 (16.7928 iter/s, 29.7747s/500 iters), loss = 0.113791
I0830 12:29:30.510210 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.113794 (* 1 = 0.113794 loss)
I0830 12:29:30.510219 916722 sgd_solver.cpp:106] Iteration 1618000, lr = 0.01
I0830 12:30:00.274669 916722 solver.cpp:218] Iteration 1618500 (16.7986 iter/s, 29.7644s/500 iters), loss = 0.0724086
I0830 12:30:00.274724 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0724117 (* 1 = 0.0724117 loss)
I0830 12:30:00.274731 916722 sgd_solver.cpp:106] Iteration 1618500, lr = 0.01
I0830 12:30:30.046075 916722 solver.cpp:218] Iteration 1619000 (16.7947 iter/s, 29.7713s/500 iters), loss = 0.175318
I0830 12:30:30.046124 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.175321 (* 1 = 0.175321 loss)
I0830 12:30:30.046133 916722 sgd_solver.cpp:106] Iteration 1619000, lr = 0.01
I0830 12:30:59.812983 916722 solver.cpp:218] Iteration 1619500 (16.7973 iter/s, 29.7668s/500 iters), loss = 0.120224
I0830 12:30:59.813037 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.120227 (* 1 = 0.120227 loss)
I0830 12:30:59.813045 916722 sgd_solver.cpp:106] Iteration 1619500, lr = 0.01
I0830 12:31:29.582171 916722 solver.cpp:218] Iteration 1620000 (16.796 iter/s, 29.769s/500 iters), loss = 0.0665751
I0830 12:31:29.582222 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0665781 (* 1 = 0.0665781 loss)
I0830 12:31:29.582232 916722 sgd_solver.cpp:106] Iteration 1620000, lr = 0.01
I0830 12:31:59.352108 916722 solver.cpp:218] Iteration 1620500 (16.7956 iter/s, 29.7698s/500 iters), loss = 0.0977252
I0830 12:31:59.352169 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0977283 (* 1 = 0.0977283 loss)
I0830 12:31:59.352177 916722 sgd_solver.cpp:106] Iteration 1620500, lr = 0.01
I0830 12:32:29.123683 916722 solver.cpp:218] Iteration 1621000 (16.7946 iter/s, 29.7714s/500 iters), loss = 0.0489785
I0830 12:32:29.123747 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0489816 (* 1 = 0.0489816 loss)
I0830 12:32:29.123757 916722 sgd_solver.cpp:106] Iteration 1621000, lr = 0.01
I0830 12:32:58.892395 916722 solver.cpp:218] Iteration 1621500 (16.7962 iter/s, 29.7686s/500 iters), loss = 0.147551
I0830 12:32:58.892474 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.147554 (* 1 = 0.147554 loss)
I0830 12:32:58.892484 916722 sgd_solver.cpp:106] Iteration 1621500, lr = 0.01
I0830 12:33:28.663672 916722 solver.cpp:218] Iteration 1622000 (16.7948 iter/s, 29.7711s/500 iters), loss = 0.130523
I0830 12:33:28.663720 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130526 (* 1 = 0.130526 loss)
I0830 12:33:28.663729 916722 sgd_solver.cpp:106] Iteration 1622000, lr = 0.01
I0830 12:33:58.430752 916722 solver.cpp:218] Iteration 1622500 (16.7972 iter/s, 29.7669s/500 iters), loss = 0.104801
I0830 12:33:58.430809 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104804 (* 1 = 0.104804 loss)
I0830 12:33:58.430816 916722 sgd_solver.cpp:106] Iteration 1622500, lr = 0.01
I0830 12:34:28.200057 916722 solver.cpp:218] Iteration 1623000 (16.7959 iter/s, 29.7692s/500 iters), loss = 0.145142
I0830 12:34:28.200103 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.145145 (* 1 = 0.145145 loss)
I0830 12:34:28.200111 916722 sgd_solver.cpp:106] Iteration 1623000, lr = 0.01
I0830 12:34:57.964329 916722 solver.cpp:218] Iteration 1623500 (16.7987 iter/s, 29.7641s/500 iters), loss = 0.0420076
I0830 12:34:57.964386 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0420109 (* 1 = 0.0420109 loss)
I0830 12:34:57.964395 916722 sgd_solver.cpp:106] Iteration 1623500, lr = 0.01
I0830 12:35:27.736616 916722 solver.cpp:218] Iteration 1624000 (16.7942 iter/s, 29.7721s/500 iters), loss = 0.442964
I0830 12:35:27.736663 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.442967 (* 1 = 0.442967 loss)
I0830 12:35:27.736672 916722 sgd_solver.cpp:106] Iteration 1624000, lr = 0.01
I0830 12:35:57.506228 916722 solver.cpp:218] Iteration 1624500 (16.7957 iter/s, 29.7695s/500 iters), loss = 0.0325388
I0830 12:35:57.506289 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0325421 (* 1 = 0.0325421 loss)
I0830 12:35:57.506297 916722 sgd_solver.cpp:106] Iteration 1624500, lr = 0.01
I0830 12:36:27.275789 916722 solver.cpp:218] Iteration 1625000 (16.7958 iter/s, 29.7694s/500 iters), loss = 0.177335
I0830 12:36:27.275840 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.177339 (* 1 = 0.177339 loss)
I0830 12:36:27.275848 916722 sgd_solver.cpp:106] Iteration 1625000, lr = 0.01
I0830 12:36:57.042835 916722 solver.cpp:218] Iteration 1625500 (16.7972 iter/s, 29.7669s/500 iters), loss = 0.173512
I0830 12:36:57.042894 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.173515 (* 1 = 0.173515 loss)
I0830 12:36:57.042903 916722 sgd_solver.cpp:106] Iteration 1625500, lr = 0.01
I0830 12:37:26.815815 916722 solver.cpp:218] Iteration 1626000 (16.7938 iter/s, 29.7728s/500 iters), loss = 0.210642
I0830 12:37:26.815865 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.210645 (* 1 = 0.210645 loss)
I0830 12:37:26.815873 916722 sgd_solver.cpp:106] Iteration 1626000, lr = 0.01
I0830 12:37:56.585894 916722 solver.cpp:218] Iteration 1626500 (16.7955 iter/s, 29.7699s/500 iters), loss = 0.13189
I0830 12:37:56.585953 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131893 (* 1 = 0.131893 loss)
I0830 12:37:56.585963 916722 sgd_solver.cpp:106] Iteration 1626500, lr = 0.01
I0830 12:38:26.364289 916722 solver.cpp:218] Iteration 1627000 (16.7908 iter/s, 29.7782s/500 iters), loss = 0.0804294
I0830 12:38:26.364343 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0804326 (* 1 = 0.0804326 loss)
I0830 12:38:26.364353 916722 sgd_solver.cpp:106] Iteration 1627000, lr = 0.01
I0830 12:38:56.125664 916722 solver.cpp:218] Iteration 1627500 (16.8004 iter/s, 29.7612s/500 iters), loss = 0.154217
I0830 12:38:56.125733 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.15422 (* 1 = 0.15422 loss)
I0830 12:38:56.125742 916722 sgd_solver.cpp:106] Iteration 1627500, lr = 0.01
I0830 12:39:25.890466 916722 solver.cpp:218] Iteration 1628000 (16.7985 iter/s, 29.7646s/500 iters), loss = 0.086113
I0830 12:39:25.890516 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.086116 (* 1 = 0.086116 loss)
I0830 12:39:25.890525 916722 sgd_solver.cpp:106] Iteration 1628000, lr = 0.01
I0830 12:39:55.659070 916722 solver.cpp:218] Iteration 1628500 (16.7963 iter/s, 29.7685s/500 iters), loss = 0.163617
I0830 12:39:55.659127 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.16362 (* 1 = 0.16362 loss)
I0830 12:39:55.659137 916722 sgd_solver.cpp:106] Iteration 1628500, lr = 0.01
I0830 12:40:25.421581 916722 solver.cpp:218] Iteration 1629000 (16.7997 iter/s, 29.7624s/500 iters), loss = 0.117374
I0830 12:40:25.421628 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.117377 (* 1 = 0.117377 loss)
I0830 12:40:25.421638 916722 sgd_solver.cpp:106] Iteration 1629000, lr = 0.01
I0830 12:40:55.190208 916722 solver.cpp:218] Iteration 1629500 (16.7963 iter/s, 29.7685s/500 iters), loss = 0.34374
I0830 12:40:55.190276 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.343743 (* 1 = 0.343743 loss)
I0830 12:40:55.190287 916722 sgd_solver.cpp:106] Iteration 1629500, lr = 0.01
I0830 12:41:24.962131 916722 solver.cpp:218] Iteration 1630000 (16.7944 iter/s, 29.7718s/500 iters), loss = 0.118516
I0830 12:41:24.962172 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.118519 (* 1 = 0.118519 loss)
I0830 12:41:24.962180 916722 sgd_solver.cpp:106] Iteration 1630000, lr = 0.01
I0830 12:41:54.733398 916722 solver.cpp:218] Iteration 1630500 (16.7948 iter/s, 29.7711s/500 iters), loss = 0.39765
I0830 12:41:54.733455 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.397653 (* 1 = 0.397653 loss)
I0830 12:41:54.733464 916722 sgd_solver.cpp:106] Iteration 1630500, lr = 0.01
I0830 12:42:24.508286 916722 solver.cpp:218] Iteration 1631000 (16.7926 iter/s, 29.775s/500 iters), loss = 0.254312
I0830 12:42:24.508334 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.254315 (* 1 = 0.254315 loss)
I0830 12:42:24.508344 916722 sgd_solver.cpp:106] Iteration 1631000, lr = 0.01
I0830 12:42:54.286201 916722 solver.cpp:218] Iteration 1631500 (16.7908 iter/s, 29.7782s/500 iters), loss = 0.0495885
I0830 12:42:54.286262 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0495918 (* 1 = 0.0495918 loss)
I0830 12:42:54.286270 916722 sgd_solver.cpp:106] Iteration 1631500, lr = 0.01
I0830 12:43:24.055897 916722 solver.cpp:218] Iteration 1632000 (16.7955 iter/s, 29.7699s/500 iters), loss = 0.0848163
I0830 12:43:24.055948 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0848194 (* 1 = 0.0848194 loss)
I0830 12:43:24.055958 916722 sgd_solver.cpp:106] Iteration 1632000, lr = 0.01
I0830 12:43:53.821142 916722 solver.cpp:218] Iteration 1632500 (16.798 iter/s, 29.7654s/500 iters), loss = 0.150076
I0830 12:43:53.821202 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.150079 (* 1 = 0.150079 loss)
I0830 12:43:53.821210 916722 sgd_solver.cpp:106] Iteration 1632500, lr = 0.01
I0830 12:44:23.584472 916722 solver.cpp:218] Iteration 1633000 (16.7991 iter/s, 29.7635s/500 iters), loss = 0.329793
I0830 12:44:23.584524 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.329796 (* 1 = 0.329796 loss)
I0830 12:44:23.584535 916722 sgd_solver.cpp:106] Iteration 1633000, lr = 0.01
I0830 12:44:53.352294 916722 solver.cpp:218] Iteration 1633500 (16.7966 iter/s, 29.768s/500 iters), loss = 0.169253
I0830 12:44:53.352351 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.169256 (* 1 = 0.169256 loss)
I0830 12:44:53.352360 916722 sgd_solver.cpp:106] Iteration 1633500, lr = 0.01
I0830 12:45:23.115274 916722 solver.cpp:218] Iteration 1634000 (16.7993 iter/s, 29.7631s/500 iters), loss = 0.0159981
I0830 12:45:23.115322 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0160012 (* 1 = 0.0160012 loss)
I0830 12:45:23.115345 916722 sgd_solver.cpp:106] Iteration 1634000, lr = 0.01
I0830 12:45:52.873890 916722 solver.cpp:218] Iteration 1634500 (16.8018 iter/s, 29.7588s/500 iters), loss = 0.385981
I0830 12:45:52.873955 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.385984 (* 1 = 0.385984 loss)
I0830 12:45:52.873963 916722 sgd_solver.cpp:106] Iteration 1634500, lr = 0.01
I0830 12:46:22.638315 916722 solver.cpp:218] Iteration 1635000 (16.7985 iter/s, 29.7645s/500 iters), loss = 0.211628
I0830 12:46:22.638363 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.211631 (* 1 = 0.211631 loss)
I0830 12:46:22.638373 916722 sgd_solver.cpp:106] Iteration 1635000, lr = 0.01
I0830 12:46:52.399085 916722 solver.cpp:218] Iteration 1635500 (16.8006 iter/s, 29.7609s/500 iters), loss = 0.189884
I0830 12:46:52.399145 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.189887 (* 1 = 0.189887 loss)
I0830 12:46:52.399154 916722 sgd_solver.cpp:106] Iteration 1635500, lr = 0.01
I0830 12:47:22.163780 916722 solver.cpp:218] Iteration 1636000 (16.7984 iter/s, 29.7648s/500 iters), loss = 0.231236
I0830 12:47:22.163831 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.23124 (* 1 = 0.23124 loss)
I0830 12:47:22.163841 916722 sgd_solver.cpp:106] Iteration 1636000, lr = 0.01
I0830 12:47:51.934697 916722 solver.cpp:218] Iteration 1636500 (16.7949 iter/s, 29.771s/500 iters), loss = 0.0981422
I0830 12:47:51.934759 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0981456 (* 1 = 0.0981456 loss)
I0830 12:47:51.934768 916722 sgd_solver.cpp:106] Iteration 1636500, lr = 0.01
I0830 12:48:21.698423 916722 solver.cpp:218] Iteration 1637000 (16.7989 iter/s, 29.7638s/500 iters), loss = 0.235554
I0830 12:48:21.698474 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.235557 (* 1 = 0.235557 loss)
I0830 12:48:21.698482 916722 sgd_solver.cpp:106] Iteration 1637000, lr = 0.01
I0830 12:48:51.467198 916722 solver.cpp:218] Iteration 1637500 (16.7961 iter/s, 29.7689s/500 iters), loss = 0.111015
I0830 12:48:51.467262 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111019 (* 1 = 0.111019 loss)
I0830 12:48:51.467270 916722 sgd_solver.cpp:106] Iteration 1637500, lr = 0.01
I0830 12:49:21.233232 916722 solver.cpp:218] Iteration 1638000 (16.7976 iter/s, 29.7661s/500 iters), loss = 0.0661017
I0830 12:49:21.233281 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0661052 (* 1 = 0.0661052 loss)
I0830 12:49:21.233289 916722 sgd_solver.cpp:106] Iteration 1638000, lr = 0.01
I0830 12:49:50.997893 916722 solver.cpp:218] Iteration 1638500 (16.7984 iter/s, 29.7647s/500 iters), loss = 0.106199
I0830 12:49:50.997954 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.106202 (* 1 = 0.106202 loss)
I0830 12:49:50.997963 916722 sgd_solver.cpp:106] Iteration 1638500, lr = 0.01
I0830 12:50:20.764281 916722 solver.cpp:218] Iteration 1639000 (16.7975 iter/s, 29.7664s/500 iters), loss = 0.238267
I0830 12:50:20.764328 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.23827 (* 1 = 0.23827 loss)
I0830 12:50:20.764338 916722 sgd_solver.cpp:106] Iteration 1639000, lr = 0.01
I0830 12:50:50.532816 916722 solver.cpp:218] Iteration 1639500 (16.7962 iter/s, 29.7686s/500 iters), loss = 0.0655279
I0830 12:50:50.532874 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0655314 (* 1 = 0.0655314 loss)
I0830 12:50:50.532882 916722 sgd_solver.cpp:106] Iteration 1639500, lr = 0.01
I0830 12:51:20.297650 916722 solver.cpp:218] Iteration 1640000 (16.7983 iter/s, 29.7649s/500 iters), loss = 0.0633867
I0830 12:51:20.297701 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0633903 (* 1 = 0.0633903 loss)
I0830 12:51:20.297710 916722 sgd_solver.cpp:106] Iteration 1640000, lr = 0.01
I0830 12:51:50.060389 916722 solver.cpp:218] Iteration 1640500 (16.7995 iter/s, 29.7628s/500 iters), loss = 0.201789
I0830 12:51:50.060473 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.201792 (* 1 = 0.201792 loss)
I0830 12:51:50.060487 916722 sgd_solver.cpp:106] Iteration 1640500, lr = 0.01
I0830 12:52:19.823784 916722 solver.cpp:218] Iteration 1641000 (16.7992 iter/s, 29.7634s/500 iters), loss = 0.246377
I0830 12:52:19.823837 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.246381 (* 1 = 0.246381 loss)
I0830 12:52:19.823848 916722 sgd_solver.cpp:106] Iteration 1641000, lr = 0.01
I0830 12:52:49.591761 916722 solver.cpp:218] Iteration 1641500 (16.7966 iter/s, 29.768s/500 iters), loss = 0.240652
I0830 12:52:49.591820 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.240655 (* 1 = 0.240655 loss)
I0830 12:52:49.591830 916722 sgd_solver.cpp:106] Iteration 1641500, lr = 0.01
I0830 12:53:19.361423 916722 solver.cpp:218] Iteration 1642000 (16.7956 iter/s, 29.7697s/500 iters), loss = 0.0787985
I0830 12:53:19.361472 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0788024 (* 1 = 0.0788024 loss)
I0830 12:53:19.361482 916722 sgd_solver.cpp:106] Iteration 1642000, lr = 0.01
I0830 12:53:49.143074 916722 solver.cpp:218] Iteration 1642500 (16.7889 iter/s, 29.7816s/500 iters), loss = 0.139174
I0830 12:53:49.143136 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139178 (* 1 = 0.139178 loss)
I0830 12:53:49.143144 916722 sgd_solver.cpp:106] Iteration 1642500, lr = 0.01
I0830 12:54:18.913931 916722 solver.cpp:218] Iteration 1643000 (16.795 iter/s, 29.7708s/500 iters), loss = 0.0585647
I0830 12:54:18.913980 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0585686 (* 1 = 0.0585686 loss)
I0830 12:54:18.913990 916722 sgd_solver.cpp:106] Iteration 1643000, lr = 0.01
I0830 12:54:48.679595 916722 solver.cpp:218] Iteration 1643500 (16.7979 iter/s, 29.7656s/500 iters), loss = 0.239065
I0830 12:54:48.679653 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.239068 (* 1 = 0.239068 loss)
I0830 12:54:48.679662 916722 sgd_solver.cpp:106] Iteration 1643500, lr = 0.01
I0830 12:55:18.423406 916722 solver.cpp:218] Iteration 1644000 (16.8102 iter/s, 29.7438s/500 iters), loss = 0.0645482
I0830 12:55:18.423453 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.064552 (* 1 = 0.064552 loss)
I0830 12:55:18.423462 916722 sgd_solver.cpp:106] Iteration 1644000, lr = 0.01
I0830 12:55:48.163753 916722 solver.cpp:218] Iteration 1644500 (16.8122 iter/s, 29.7403s/500 iters), loss = 0.244856
I0830 12:55:48.163811 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.24486 (* 1 = 0.24486 loss)
I0830 12:55:48.163820 916722 sgd_solver.cpp:106] Iteration 1644500, lr = 0.01
I0830 12:56:17.905087 916722 solver.cpp:218] Iteration 1645000 (16.8116 iter/s, 29.7413s/500 iters), loss = 0.204454
I0830 12:56:17.905135 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.204458 (* 1 = 0.204458 loss)
I0830 12:56:17.905145 916722 sgd_solver.cpp:106] Iteration 1645000, lr = 0.01
I0830 12:56:47.650228 916722 solver.cpp:218] Iteration 1645500 (16.8095 iter/s, 29.7451s/500 iters), loss = 0.0976727
I0830 12:56:47.650291 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0976763 (* 1 = 0.0976763 loss)
I0830 12:56:47.650300 916722 sgd_solver.cpp:106] Iteration 1645500, lr = 0.01
I0830 12:57:17.396593 916722 solver.cpp:218] Iteration 1646000 (16.8088 iter/s, 29.7463s/500 iters), loss = 0.324614
I0830 12:57:17.396642 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.324618 (* 1 = 0.324618 loss)
I0830 12:57:17.396651 916722 sgd_solver.cpp:106] Iteration 1646000, lr = 0.01
I0830 12:57:47.135133 916722 solver.cpp:218] Iteration 1646500 (16.8132 iter/s, 29.7385s/500 iters), loss = 0.115555
I0830 12:57:47.135191 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115559 (* 1 = 0.115559 loss)
I0830 12:57:47.135200 916722 sgd_solver.cpp:106] Iteration 1646500, lr = 0.01
I0830 12:58:16.878635 916722 solver.cpp:218] Iteration 1647000 (16.8104 iter/s, 29.7434s/500 iters), loss = 0.254093
I0830 12:58:16.878685 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.254096 (* 1 = 0.254096 loss)
I0830 12:58:16.878693 916722 sgd_solver.cpp:106] Iteration 1647000, lr = 0.01
I0830 12:58:46.612794 916722 solver.cpp:218] Iteration 1647500 (16.8157 iter/s, 29.7341s/500 iters), loss = 0.0395807
I0830 12:58:46.612862 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0395842 (* 1 = 0.0395842 loss)
I0830 12:58:46.612871 916722 sgd_solver.cpp:106] Iteration 1647500, lr = 0.01
I0830 12:59:16.356829 916722 solver.cpp:218] Iteration 1648000 (16.8101 iter/s, 29.744s/500 iters), loss = 0.160968
I0830 12:59:16.356878 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.160972 (* 1 = 0.160972 loss)
I0830 12:59:16.356885 916722 sgd_solver.cpp:106] Iteration 1648000, lr = 0.01
I0830 12:59:46.101541 916722 solver.cpp:218] Iteration 1648500 (16.8097 iter/s, 29.7447s/500 iters), loss = 0.161922
I0830 12:59:46.101608 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.161925 (* 1 = 0.161925 loss)
I0830 12:59:46.101616 916722 sgd_solver.cpp:106] Iteration 1648500, lr = 0.01
I0830 13:00:15.836138 916722 solver.cpp:218] Iteration 1649000 (16.8155 iter/s, 29.7345s/500 iters), loss = 0.121543
I0830 13:00:15.836187 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.121546 (* 1 = 0.121546 loss)
I0830 13:00:15.836195 916722 sgd_solver.cpp:106] Iteration 1649000, lr = 0.01
I0830 13:00:45.574345 916722 solver.cpp:218] Iteration 1649500 (16.8134 iter/s, 29.7382s/500 iters), loss = 0.227849
I0830 13:00:45.574404 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.227853 (* 1 = 0.227853 loss)
I0830 13:00:45.574414 916722 sgd_solver.cpp:106] Iteration 1649500, lr = 0.01
I0830 13:01:15.253461 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_1650000.caffemodel
I0830 13:01:15.272473 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_1650000.solverstate
I0830 13:01:15.278618 916722 solver.cpp:330] Iteration 1650000, Testing net (#0)
I0830 13:01:30.669109 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8729
I0830 13:01:30.669160 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.416133 (* 1 = 0.416133 loss)
I0830 13:01:30.727560 916722 solver.cpp:218] Iteration 1650000 (11.0734 iter/s, 45.1531s/500 iters), loss = 0.157095
I0830 13:01:30.727586 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.157099 (* 1 = 0.157099 loss)
I0830 13:01:30.727594 916722 sgd_solver.cpp:106] Iteration 1650000, lr = 0.01
I0830 13:02:00.457507 916722 solver.cpp:218] Iteration 1650500 (16.8181 iter/s, 29.7299s/500 iters), loss = 0.12929
I0830 13:02:00.457553 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.129294 (* 1 = 0.129294 loss)
I0830 13:02:00.457561 916722 sgd_solver.cpp:106] Iteration 1650500, lr = 0.01
I0830 13:02:30.198177 916722 solver.cpp:218] Iteration 1651000 (16.812 iter/s, 29.7406s/500 iters), loss = 0.11964
I0830 13:02:30.198235 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.119643 (* 1 = 0.119643 loss)
I0830 13:02:30.198243 916722 sgd_solver.cpp:106] Iteration 1651000, lr = 0.01
I0830 13:02:59.935328 916722 solver.cpp:218] Iteration 1651500 (16.814 iter/s, 29.7371s/500 iters), loss = 0.27178
I0830 13:02:59.935379 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.271784 (* 1 = 0.271784 loss)
I0830 13:02:59.935387 916722 sgd_solver.cpp:106] Iteration 1651500, lr = 0.01
I0830 13:03:29.672916 916722 solver.cpp:218] Iteration 1652000 (16.8138 iter/s, 29.7375s/500 iters), loss = 0.0826351
I0830 13:03:29.672976 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0826388 (* 1 = 0.0826388 loss)
I0830 13:03:29.672986 916722 sgd_solver.cpp:106] Iteration 1652000, lr = 0.01
I0830 13:03:59.421942 916722 solver.cpp:218] Iteration 1652500 (16.8073 iter/s, 29.7489s/500 iters), loss = 0.119369
I0830 13:03:59.421993 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.119373 (* 1 = 0.119373 loss)
I0830 13:03:59.422001 916722 sgd_solver.cpp:106] Iteration 1652500, lr = 0.01
I0830 13:04:29.167768 916722 solver.cpp:218] Iteration 1653000 (16.8091 iter/s, 29.7458s/500 iters), loss = 0.178938
I0830 13:04:29.167842 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.178942 (* 1 = 0.178942 loss)
I0830 13:04:29.167850 916722 sgd_solver.cpp:106] Iteration 1653000, lr = 0.01
I0830 13:04:58.933936 916722 solver.cpp:218] Iteration 1653500 (16.7976 iter/s, 29.7661s/500 iters), loss = 0.267068
I0830 13:04:58.933988 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.267071 (* 1 = 0.267071 loss)
I0830 13:04:58.933997 916722 sgd_solver.cpp:106] Iteration 1653500, lr = 0.01
I0830 13:05:28.690467 916722 solver.cpp:218] Iteration 1654000 (16.8031 iter/s, 29.7565s/500 iters), loss = 0.127918
I0830 13:05:28.690526 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.127922 (* 1 = 0.127922 loss)
I0830 13:05:28.690534 916722 sgd_solver.cpp:106] Iteration 1654000, lr = 0.01
I0830 13:05:58.438457 916722 solver.cpp:218] Iteration 1654500 (16.8079 iter/s, 29.7479s/500 iters), loss = 0.210192
I0830 13:05:58.438503 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.210196 (* 1 = 0.210196 loss)
I0830 13:05:58.438510 916722 sgd_solver.cpp:106] Iteration 1654500, lr = 0.01
I0830 13:06:28.191025 916722 solver.cpp:218] Iteration 1655000 (16.8053 iter/s, 29.7525s/500 iters), loss = 0.281605
I0830 13:06:28.191083 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.281608 (* 1 = 0.281608 loss)
I0830 13:06:28.191092 916722 sgd_solver.cpp:106] Iteration 1655000, lr = 0.01
I0830 13:06:57.942559 916722 solver.cpp:218] Iteration 1655500 (16.8059 iter/s, 29.7514s/500 iters), loss = 0.502254
I0830 13:06:57.942608 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.502258 (* 1 = 0.502258 loss)
I0830 13:06:57.942616 916722 sgd_solver.cpp:106] Iteration 1655500, lr = 0.01
I0830 13:07:27.690361 916722 solver.cpp:218] Iteration 1656000 (16.808 iter/s, 29.7477s/500 iters), loss = 0.0761609
I0830 13:07:27.690421 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0761648 (* 1 = 0.0761648 loss)
I0830 13:07:27.690430 916722 sgd_solver.cpp:106] Iteration 1656000, lr = 0.01
I0830 13:07:57.433611 916722 solver.cpp:218] Iteration 1656500 (16.8106 iter/s, 29.7432s/500 iters), loss = 0.0146968
I0830 13:07:57.433665 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0147006 (* 1 = 0.0147006 loss)
I0830 13:07:57.433676 916722 sgd_solver.cpp:106] Iteration 1656500, lr = 0.01
I0830 13:08:27.184701 916722 solver.cpp:218] Iteration 1657000 (16.8062 iter/s, 29.751s/500 iters), loss = 0.0123196
I0830 13:08:27.184785 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0123235 (* 1 = 0.0123235 loss)
I0830 13:08:27.184793 916722 sgd_solver.cpp:106] Iteration 1657000, lr = 0.01
I0830 13:08:56.935196 916722 solver.cpp:218] Iteration 1657500 (16.8065 iter/s, 29.7504s/500 iters), loss = 0.22086
I0830 13:08:56.935246 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.220864 (* 1 = 0.220864 loss)
I0830 13:08:56.935256 916722 sgd_solver.cpp:106] Iteration 1657500, lr = 0.01
I0830 13:09:26.684461 916722 solver.cpp:218] Iteration 1658000 (16.8072 iter/s, 29.7492s/500 iters), loss = 0.220114
I0830 13:09:26.684520 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.220117 (* 1 = 0.220117 loss)
I0830 13:09:26.684528 916722 sgd_solver.cpp:106] Iteration 1658000, lr = 0.01
I0830 13:09:56.430672 916722 solver.cpp:218] Iteration 1658500 (16.8089 iter/s, 29.7461s/500 iters), loss = 0.112111
I0830 13:09:56.430721 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112115 (* 1 = 0.112115 loss)
I0830 13:09:56.430732 916722 sgd_solver.cpp:106] Iteration 1658500, lr = 0.01
I0830 13:10:26.174508 916722 solver.cpp:218] Iteration 1659000 (16.8103 iter/s, 29.7437s/500 iters), loss = 0.19232
I0830 13:10:26.174562 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.192324 (* 1 = 0.192324 loss)
I0830 13:10:26.174571 916722 sgd_solver.cpp:106] Iteration 1659000, lr = 0.01
I0830 13:10:55.919780 916722 solver.cpp:218] Iteration 1659500 (16.8094 iter/s, 29.7452s/500 iters), loss = 0.248712
I0830 13:10:55.919842 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.248715 (* 1 = 0.248715 loss)
I0830 13:10:55.919852 916722 sgd_solver.cpp:106] Iteration 1659500, lr = 0.01
I0830 13:11:25.666828 916722 solver.cpp:218] Iteration 1660000 (16.8084 iter/s, 29.7469s/500 iters), loss = 0.0305021
I0830 13:11:25.666898 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0305058 (* 1 = 0.0305058 loss)
I0830 13:11:25.666906 916722 sgd_solver.cpp:106] Iteration 1660000, lr = 0.01
I0830 13:11:55.419814 916722 solver.cpp:218] Iteration 1660500 (16.8051 iter/s, 29.7529s/500 iters), loss = 0.18326
I0830 13:11:55.419865 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.183264 (* 1 = 0.183264 loss)
I0830 13:11:55.419875 916722 sgd_solver.cpp:106] Iteration 1660500, lr = 0.01
I0830 13:12:25.168946 916722 solver.cpp:218] Iteration 1661000 (16.8073 iter/s, 29.749s/500 iters), loss = 0.0966175
I0830 13:12:25.169006 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0966215 (* 1 = 0.0966215 loss)
I0830 13:12:25.169014 916722 sgd_solver.cpp:106] Iteration 1661000, lr = 0.01
I0830 13:12:54.910718 916722 solver.cpp:218] Iteration 1661500 (16.8114 iter/s, 29.7417s/500 iters), loss = 0.233462
I0830 13:12:54.910768 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.233466 (* 1 = 0.233466 loss)
I0830 13:12:54.910778 916722 sgd_solver.cpp:106] Iteration 1661500, lr = 0.01
I0830 13:13:24.658321 916722 solver.cpp:218] Iteration 1662000 (16.8081 iter/s, 29.7475s/500 iters), loss = 0.0283486
I0830 13:13:24.658385 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0283525 (* 1 = 0.0283525 loss)
I0830 13:13:24.658392 916722 sgd_solver.cpp:106] Iteration 1662000, lr = 0.01
I0830 13:13:54.399282 916722 solver.cpp:218] Iteration 1662500 (16.8119 iter/s, 29.7409s/500 iters), loss = 0.203247
I0830 13:13:54.399331 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.203251 (* 1 = 0.203251 loss)
I0830 13:13:54.399340 916722 sgd_solver.cpp:106] Iteration 1662500, lr = 0.01
I0830 13:14:24.143738 916722 solver.cpp:218] Iteration 1663000 (16.8099 iter/s, 29.7444s/500 iters), loss = 0.304115
I0830 13:14:24.143795 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.304119 (* 1 = 0.304119 loss)
I0830 13:14:24.143803 916722 sgd_solver.cpp:106] Iteration 1663000, lr = 0.01
I0830 13:14:53.886229 916722 solver.cpp:218] Iteration 1663500 (16.811 iter/s, 29.7424s/500 iters), loss = 0.0520852
I0830 13:14:53.886274 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0520892 (* 1 = 0.0520892 loss)
I0830 13:14:53.886283 916722 sgd_solver.cpp:106] Iteration 1663500, lr = 0.01
I0830 13:15:23.631994 916722 solver.cpp:218] Iteration 1664000 (16.8092 iter/s, 29.7457s/500 iters), loss = 0.2757
I0830 13:15:23.632052 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.275705 (* 1 = 0.275705 loss)
I0830 13:15:23.632061 916722 sgd_solver.cpp:106] Iteration 1664000, lr = 0.01
I0830 13:15:53.374367 916722 solver.cpp:218] Iteration 1664500 (16.8111 iter/s, 29.7423s/500 iters), loss = 0.24305
I0830 13:15:53.374416 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.243054 (* 1 = 0.243054 loss)
I0830 13:15:53.374424 916722 sgd_solver.cpp:106] Iteration 1664500, lr = 0.01
I0830 13:16:23.117849 916722 solver.cpp:218] Iteration 1665000 (16.8105 iter/s, 29.7434s/500 iters), loss = 0.0645751
I0830 13:16:23.117908 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0645791 (* 1 = 0.0645791 loss)
I0830 13:16:23.117918 916722 sgd_solver.cpp:106] Iteration 1665000, lr = 0.01
I0830 13:16:52.860112 916722 solver.cpp:218] Iteration 1665500 (16.8112 iter/s, 29.7421s/500 iters), loss = 0.0327565
I0830 13:16:52.860162 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0327605 (* 1 = 0.0327605 loss)
I0830 13:16:52.860170 916722 sgd_solver.cpp:106] Iteration 1665500, lr = 0.01
I0830 13:17:22.599750 916722 solver.cpp:218] Iteration 1666000 (16.8127 iter/s, 29.7395s/500 iters), loss = 0.227064
I0830 13:17:22.599819 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.227068 (* 1 = 0.227068 loss)
I0830 13:17:22.599833 916722 sgd_solver.cpp:106] Iteration 1666000, lr = 0.01
I0830 13:17:52.340523 916722 solver.cpp:218] Iteration 1666500 (16.8121 iter/s, 29.7406s/500 iters), loss = 0.241752
I0830 13:17:52.340577 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.241756 (* 1 = 0.241756 loss)
I0830 13:17:52.340587 916722 sgd_solver.cpp:106] Iteration 1666500, lr = 0.01
I0830 13:18:22.088428 916722 solver.cpp:218] Iteration 1667000 (16.808 iter/s, 29.7477s/500 iters), loss = 0.423518
I0830 13:18:22.088497 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.423522 (* 1 = 0.423522 loss)
I0830 13:18:22.088506 916722 sgd_solver.cpp:106] Iteration 1667000, lr = 0.01
I0830 13:18:51.827633 916722 solver.cpp:218] Iteration 1667500 (16.8129 iter/s, 29.739s/500 iters), loss = 0.0633902
I0830 13:18:51.827682 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0633942 (* 1 = 0.0633942 loss)
I0830 13:18:51.827692 916722 sgd_solver.cpp:106] Iteration 1667500, lr = 0.01
I0830 13:19:21.568621 916722 solver.cpp:218] Iteration 1668000 (16.8119 iter/s, 29.7408s/500 iters), loss = 0.166632
I0830 13:19:21.568675 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.166636 (* 1 = 0.166636 loss)
I0830 13:19:21.568684 916722 sgd_solver.cpp:106] Iteration 1668000, lr = 0.01
I0830 13:19:51.305003 916722 solver.cpp:218] Iteration 1668500 (16.8145 iter/s, 29.7362s/500 iters), loss = 0.25258
I0830 13:19:51.305052 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.252584 (* 1 = 0.252584 loss)
I0830 13:19:51.305061 916722 sgd_solver.cpp:106] Iteration 1668500, lr = 0.01
I0830 13:20:21.046841 916722 solver.cpp:218] Iteration 1669000 (16.8114 iter/s, 29.7417s/500 iters), loss = 0.0358217
I0830 13:20:21.046898 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0358258 (* 1 = 0.0358258 loss)
I0830 13:20:21.046906 916722 sgd_solver.cpp:106] Iteration 1669000, lr = 0.01
I0830 13:20:50.786898 916722 solver.cpp:218] Iteration 1669500 (16.8124 iter/s, 29.7399s/500 iters), loss = 0.301293
I0830 13:20:50.786947 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.301297 (* 1 = 0.301297 loss)
I0830 13:20:50.786957 916722 sgd_solver.cpp:106] Iteration 1669500, lr = 0.01
I0830 13:21:20.528156 916722 solver.cpp:218] Iteration 1670000 (16.8118 iter/s, 29.7411s/500 iters), loss = 0.197264
I0830 13:21:20.528211 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.197269 (* 1 = 0.197269 loss)
I0830 13:21:20.528219 916722 sgd_solver.cpp:106] Iteration 1670000, lr = 0.01
I0830 13:21:50.270604 916722 solver.cpp:218] Iteration 1670500 (16.8111 iter/s, 29.7423s/500 iters), loss = 0.0595385
I0830 13:21:50.270654 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0595428 (* 1 = 0.0595428 loss)
I0830 13:21:50.270664 916722 sgd_solver.cpp:106] Iteration 1670500, lr = 0.01
I0830 13:22:20.011309 916722 solver.cpp:218] Iteration 1671000 (16.8121 iter/s, 29.7406s/500 iters), loss = 0.0843172
I0830 13:22:20.011368 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0843216 (* 1 = 0.0843216 loss)
I0830 13:22:20.011377 916722 sgd_solver.cpp:106] Iteration 1671000, lr = 0.01
I0830 13:22:49.753746 916722 solver.cpp:218] Iteration 1671500 (16.8111 iter/s, 29.7423s/500 iters), loss = 0.157765
I0830 13:22:49.753795 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.157769 (* 1 = 0.157769 loss)
I0830 13:22:49.753805 916722 sgd_solver.cpp:106] Iteration 1671500, lr = 0.01
I0830 13:23:19.483892 916722 solver.cpp:218] Iteration 1672000 (16.818 iter/s, 29.73s/500 iters), loss = 0.155332
I0830 13:23:19.483949 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.155337 (* 1 = 0.155337 loss)
I0830 13:23:19.483958 916722 sgd_solver.cpp:106] Iteration 1672000, lr = 0.01
I0830 13:23:49.212958 916722 solver.cpp:218] Iteration 1672500 (16.8186 iter/s, 29.7289s/500 iters), loss = 0.104255
I0830 13:23:49.213007 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104259 (* 1 = 0.104259 loss)
I0830 13:23:49.213029 916722 sgd_solver.cpp:106] Iteration 1672500, lr = 0.01
I0830 13:24:18.942864 916722 solver.cpp:218] Iteration 1673000 (16.8182 iter/s, 29.7298s/500 iters), loss = 0.0638384
I0830 13:24:18.942934 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0638428 (* 1 = 0.0638428 loss)
I0830 13:24:18.942943 916722 sgd_solver.cpp:106] Iteration 1673000, lr = 0.01
I0830 13:24:48.673627 916722 solver.cpp:218] Iteration 1673500 (16.8177 iter/s, 29.7306s/500 iters), loss = 0.170267
I0830 13:24:48.673676 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.170272 (* 1 = 0.170272 loss)
I0830 13:24:48.673683 916722 sgd_solver.cpp:106] Iteration 1673500, lr = 0.01
I0830 13:25:18.404227 916722 solver.cpp:218] Iteration 1674000 (16.8178 iter/s, 29.7305s/500 iters), loss = 0.11078
I0830 13:25:18.404285 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110784 (* 1 = 0.110784 loss)
I0830 13:25:18.404294 916722 sgd_solver.cpp:106] Iteration 1674000, lr = 0.01
I0830 13:25:48.133177 916722 solver.cpp:218] Iteration 1674500 (16.8187 iter/s, 29.7288s/500 iters), loss = 0.108818
I0830 13:25:48.133226 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.108823 (* 1 = 0.108823 loss)
I0830 13:25:48.133234 916722 sgd_solver.cpp:106] Iteration 1674500, lr = 0.01
I0830 13:26:17.867446 916722 solver.cpp:218] Iteration 1675000 (16.8157 iter/s, 29.7341s/500 iters), loss = 0.177029
I0830 13:26:17.867504 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.177033 (* 1 = 0.177033 loss)
I0830 13:26:17.867513 916722 sgd_solver.cpp:106] Iteration 1675000, lr = 0.01
I0830 13:26:47.596218 916722 solver.cpp:218] Iteration 1675500 (16.8188 iter/s, 29.7286s/500 iters), loss = 0.107223
I0830 13:26:47.596266 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.107228 (* 1 = 0.107228 loss)
I0830 13:26:47.596274 916722 sgd_solver.cpp:106] Iteration 1675500, lr = 0.01
I0830 13:27:17.319586 916722 solver.cpp:218] Iteration 1676000 (16.8219 iter/s, 29.7232s/500 iters), loss = 0.200054
I0830 13:27:17.319644 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.200059 (* 1 = 0.200059 loss)
I0830 13:27:17.319653 916722 sgd_solver.cpp:106] Iteration 1676000, lr = 0.01
I0830 13:27:47.045840 916722 solver.cpp:218] Iteration 1676500 (16.8202 iter/s, 29.7261s/500 iters), loss = 0.208816
I0830 13:27:47.045887 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.208821 (* 1 = 0.208821 loss)
I0830 13:27:47.045895 916722 sgd_solver.cpp:106] Iteration 1676500, lr = 0.01
I0830 13:28:16.770330 916722 solver.cpp:218] Iteration 1677000 (16.8212 iter/s, 29.7244s/500 iters), loss = 0.413344
I0830 13:28:16.770390 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.413349 (* 1 = 0.413349 loss)
I0830 13:28:16.770398 916722 sgd_solver.cpp:106] Iteration 1677000, lr = 0.01
I0830 13:28:46.500154 916722 solver.cpp:218] Iteration 1677500 (16.8182 iter/s, 29.7297s/500 iters), loss = 0.195483
I0830 13:28:46.500205 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.195488 (* 1 = 0.195488 loss)
I0830 13:28:46.500216 916722 sgd_solver.cpp:106] Iteration 1677500, lr = 0.01
I0830 13:29:16.230008 916722 solver.cpp:218] Iteration 1678000 (16.8182 iter/s, 29.7297s/500 iters), loss = 0.0485136
I0830 13:29:16.230062 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0485183 (* 1 = 0.0485183 loss)
I0830 13:29:16.230069 916722 sgd_solver.cpp:106] Iteration 1678000, lr = 0.01
I0830 13:29:45.960775 916722 solver.cpp:218] Iteration 1678500 (16.8177 iter/s, 29.7306s/500 iters), loss = 0.311623
I0830 13:29:45.960834 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.311628 (* 1 = 0.311628 loss)
I0830 13:29:45.960841 916722 sgd_solver.cpp:106] Iteration 1678500, lr = 0.01
I0830 13:30:15.686966 916722 solver.cpp:218] Iteration 1679000 (16.8203 iter/s, 29.7261s/500 iters), loss = 0.0798451
I0830 13:30:15.687037 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0798496 (* 1 = 0.0798496 loss)
I0830 13:30:15.687049 916722 sgd_solver.cpp:106] Iteration 1679000, lr = 0.01
I0830 13:30:45.418439 916722 solver.cpp:218] Iteration 1679500 (16.8173 iter/s, 29.7313s/500 iters), loss = 0.31557
I0830 13:30:45.418486 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.315574 (* 1 = 0.315574 loss)
I0830 13:30:45.418494 916722 sgd_solver.cpp:106] Iteration 1679500, lr = 0.01
I0830 13:31:15.149016 916722 solver.cpp:218] Iteration 1680000 (16.8178 iter/s, 29.7305s/500 iters), loss = 0.0487885
I0830 13:31:15.149073 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0487929 (* 1 = 0.0487929 loss)
I0830 13:31:15.149082 916722 sgd_solver.cpp:106] Iteration 1680000, lr = 0.01
I0830 13:31:44.878137 916722 solver.cpp:218] Iteration 1680500 (16.8186 iter/s, 29.729s/500 iters), loss = 0.183836
I0830 13:31:44.878186 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.18384 (* 1 = 0.18384 loss)
I0830 13:31:44.878194 916722 sgd_solver.cpp:106] Iteration 1680500, lr = 0.01
I0830 13:32:14.606310 916722 solver.cpp:218] Iteration 1681000 (16.8191 iter/s, 29.728s/500 iters), loss = 0.0393104
I0830 13:32:14.606366 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0393146 (* 1 = 0.0393146 loss)
I0830 13:32:14.606374 916722 sgd_solver.cpp:106] Iteration 1681000, lr = 0.01
I0830 13:32:44.335850 916722 solver.cpp:218] Iteration 1681500 (16.8184 iter/s, 29.7294s/500 iters), loss = 0.119388
I0830 13:32:44.335901 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.119392 (* 1 = 0.119392 loss)
I0830 13:32:44.335909 916722 sgd_solver.cpp:106] Iteration 1681500, lr = 0.01
I0830 13:33:14.067256 916722 solver.cpp:218] Iteration 1682000 (16.8173 iter/s, 29.7313s/500 iters), loss = 0.0490098
I0830 13:33:14.067315 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0490142 (* 1 = 0.0490142 loss)
I0830 13:33:14.067323 916722 sgd_solver.cpp:106] Iteration 1682000, lr = 0.01
I0830 13:33:43.797413 916722 solver.cpp:218] Iteration 1682500 (16.818 iter/s, 29.73s/500 iters), loss = 0.0719298
I0830 13:33:43.797461 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0719342 (* 1 = 0.0719342 loss)
I0830 13:33:43.797470 916722 sgd_solver.cpp:106] Iteration 1682500, lr = 0.01
I0830 13:34:13.532030 916722 solver.cpp:218] Iteration 1683000 (16.8155 iter/s, 29.7345s/500 iters), loss = 0.330525
I0830 13:34:13.532088 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.330529 (* 1 = 0.330529 loss)
I0830 13:34:13.532096 916722 sgd_solver.cpp:106] Iteration 1683000, lr = 0.01
I0830 13:34:43.267774 916722 solver.cpp:218] Iteration 1683500 (16.8149 iter/s, 29.7356s/500 iters), loss = 0.0587463
I0830 13:34:43.267827 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0587507 (* 1 = 0.0587507 loss)
I0830 13:34:43.267834 916722 sgd_solver.cpp:106] Iteration 1683500, lr = 0.01
I0830 13:35:12.995055 916722 solver.cpp:218] Iteration 1684000 (16.8196 iter/s, 29.7272s/500 iters), loss = 0.172913
I0830 13:35:12.995112 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.172917 (* 1 = 0.172917 loss)
I0830 13:35:12.995121 916722 sgd_solver.cpp:106] Iteration 1684000, lr = 0.01
I0830 13:35:42.721024 916722 solver.cpp:218] Iteration 1684500 (16.8204 iter/s, 29.7258s/500 iters), loss = 0.291812
I0830 13:35:42.721072 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.291817 (* 1 = 0.291817 loss)
I0830 13:35:42.721081 916722 sgd_solver.cpp:106] Iteration 1684500, lr = 0.01
I0830 13:36:12.451992 916722 solver.cpp:218] Iteration 1685000 (16.8175 iter/s, 29.7308s/500 iters), loss = 0.0477366
I0830 13:36:12.452050 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0477411 (* 1 = 0.0477411 loss)
I0830 13:36:12.452059 916722 sgd_solver.cpp:106] Iteration 1685000, lr = 0.01
I0830 13:36:42.177634 916722 solver.cpp:218] Iteration 1685500 (16.8206 iter/s, 29.7255s/500 iters), loss = 0.227507
I0830 13:36:42.177685 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.227512 (* 1 = 0.227512 loss)
I0830 13:36:42.177693 916722 sgd_solver.cpp:106] Iteration 1685500, lr = 0.01
I0830 13:37:11.909248 916722 solver.cpp:218] Iteration 1686000 (16.8172 iter/s, 29.7315s/500 iters), loss = 0.171059
I0830 13:37:11.909317 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.171063 (* 1 = 0.171063 loss)
I0830 13:37:11.909325 916722 sgd_solver.cpp:106] Iteration 1686000, lr = 0.01
I0830 13:37:41.644240 916722 solver.cpp:218] Iteration 1686500 (16.8153 iter/s, 29.7348s/500 iters), loss = 0.441684
I0830 13:37:41.644289 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.441688 (* 1 = 0.441688 loss)
I0830 13:37:41.644299 916722 sgd_solver.cpp:106] Iteration 1686500, lr = 0.01
I0830 13:38:11.374914 916722 solver.cpp:218] Iteration 1687000 (16.8177 iter/s, 29.7306s/500 iters), loss = 0.163512
I0830 13:38:11.374972 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.163517 (* 1 = 0.163517 loss)
I0830 13:38:11.374980 916722 sgd_solver.cpp:106] Iteration 1687000, lr = 0.01
I0830 13:38:41.105387 916722 solver.cpp:218] Iteration 1687500 (16.8178 iter/s, 29.7303s/500 iters), loss = 0.392716
I0830 13:38:41.105437 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.392721 (* 1 = 0.392721 loss)
I0830 13:38:41.105445 916722 sgd_solver.cpp:106] Iteration 1687500, lr = 0.01
I0830 13:39:10.836477 916722 solver.cpp:218] Iteration 1688000 (16.8175 iter/s, 29.731s/500 iters), loss = 0.0850335
I0830 13:39:10.836549 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0850384 (* 1 = 0.0850384 loss)
I0830 13:39:10.836557 916722 sgd_solver.cpp:106] Iteration 1688000, lr = 0.01
I0830 13:39:40.569011 916722 solver.cpp:218] Iteration 1688500 (16.8167 iter/s, 29.7324s/500 iters), loss = 0.215269
I0830 13:39:40.569062 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.215274 (* 1 = 0.215274 loss)
I0830 13:39:40.569072 916722 sgd_solver.cpp:106] Iteration 1688500, lr = 0.01
I0830 13:40:10.301767 916722 solver.cpp:218] Iteration 1689000 (16.8165 iter/s, 29.7326s/500 iters), loss = 0.0273859
I0830 13:40:10.301826 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0273906 (* 1 = 0.0273906 loss)
I0830 13:40:10.301833 916722 sgd_solver.cpp:106] Iteration 1689000, lr = 0.01
I0830 13:40:40.035207 916722 solver.cpp:218] Iteration 1689500 (16.8162 iter/s, 29.7333s/500 iters), loss = 0.175238
I0830 13:40:40.035255 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.175243 (* 1 = 0.175243 loss)
I0830 13:40:40.035265 916722 sgd_solver.cpp:106] Iteration 1689500, lr = 0.01
I0830 13:41:09.767258 916722 solver.cpp:218] Iteration 1690000 (16.8169 iter/s, 29.7319s/500 iters), loss = 0.106432
I0830 13:41:09.767318 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.106437 (* 1 = 0.106437 loss)
I0830 13:41:09.767326 916722 sgd_solver.cpp:106] Iteration 1690000, lr = 0.01
I0830 13:41:39.498243 916722 solver.cpp:218] Iteration 1690500 (16.8175 iter/s, 29.7309s/500 iters), loss = 0.126582
I0830 13:41:39.498294 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.126587 (* 1 = 0.126587 loss)
I0830 13:41:39.498303 916722 sgd_solver.cpp:106] Iteration 1690500, lr = 0.01
I0830 13:42:09.228538 916722 solver.cpp:218] Iteration 1691000 (16.8179 iter/s, 29.7302s/500 iters), loss = 0.15034
I0830 13:42:09.228596 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.150344 (* 1 = 0.150344 loss)
I0830 13:42:09.228605 916722 sgd_solver.cpp:106] Iteration 1691000, lr = 0.01
I0830 13:42:38.960254 916722 solver.cpp:218] Iteration 1691500 (16.8171 iter/s, 29.7316s/500 iters), loss = 0.112096
I0830 13:42:38.960304 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.1121 (* 1 = 0.1121 loss)
I0830 13:42:38.960314 916722 sgd_solver.cpp:106] Iteration 1691500, lr = 0.01
I0830 13:43:08.696476 916722 solver.cpp:218] Iteration 1692000 (16.8146 iter/s, 29.7361s/500 iters), loss = 0.227059
I0830 13:43:08.696532 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.227064 (* 1 = 0.227064 loss)
I0830 13:43:08.696540 916722 sgd_solver.cpp:106] Iteration 1692000, lr = 0.01
I0830 13:43:38.426445 916722 solver.cpp:218] Iteration 1692500 (16.8181 iter/s, 29.7298s/500 iters), loss = 0.0174722
I0830 13:43:38.426496 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0174769 (* 1 = 0.0174769 loss)
I0830 13:43:38.426506 916722 sgd_solver.cpp:106] Iteration 1692500, lr = 0.01
I0830 13:44:08.153659 916722 solver.cpp:218] Iteration 1693000 (16.8197 iter/s, 29.7271s/500 iters), loss = 0.32884
I0830 13:44:08.153733 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.328845 (* 1 = 0.328845 loss)
I0830 13:44:08.153740 916722 sgd_solver.cpp:106] Iteration 1693000, lr = 0.01
I0830 13:44:37.886912 916722 solver.cpp:218] Iteration 1693500 (16.8163 iter/s, 29.7331s/500 iters), loss = 0.179125
I0830 13:44:37.886963 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.17913 (* 1 = 0.17913 loss)
I0830 13:44:37.886972 916722 sgd_solver.cpp:106] Iteration 1693500, lr = 0.01
I0830 13:45:07.616518 916722 solver.cpp:218] Iteration 1694000 (16.8183 iter/s, 29.7295s/500 iters), loss = 0.159799
I0830 13:45:07.616578 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159804 (* 1 = 0.159804 loss)
I0830 13:45:07.616587 916722 sgd_solver.cpp:106] Iteration 1694000, lr = 0.01
I0830 13:45:37.349464 916722 solver.cpp:218] Iteration 1694500 (16.8164 iter/s, 29.7328s/500 iters), loss = 0.0992761
I0830 13:45:37.349515 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0992808 (* 1 = 0.0992808 loss)
I0830 13:45:37.349524 916722 sgd_solver.cpp:106] Iteration 1694500, lr = 0.01
I0830 13:46:07.080817 916722 solver.cpp:218] Iteration 1695000 (16.8173 iter/s, 29.7312s/500 iters), loss = 0.299866
I0830 13:46:07.080876 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.299871 (* 1 = 0.299871 loss)
I0830 13:46:07.080885 916722 sgd_solver.cpp:106] Iteration 1695000, lr = 0.01
I0830 13:46:36.813326 916722 solver.cpp:218] Iteration 1695500 (16.8167 iter/s, 29.7324s/500 iters), loss = 0.118268
I0830 13:46:36.813375 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.118273 (* 1 = 0.118273 loss)
I0830 13:46:36.813385 916722 sgd_solver.cpp:106] Iteration 1695500, lr = 0.01
I0830 13:47:06.543233 916722 solver.cpp:218] Iteration 1696000 (16.8181 iter/s, 29.7298s/500 iters), loss = 0.0704241
I0830 13:47:06.543292 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0704289 (* 1 = 0.0704289 loss)
I0830 13:47:06.543300 916722 sgd_solver.cpp:106] Iteration 1696000, lr = 0.01
I0830 13:47:36.272543 916722 solver.cpp:218] Iteration 1696500 (16.8185 iter/s, 29.7292s/500 iters), loss = 0.0849538
I0830 13:47:36.272590 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0849586 (* 1 = 0.0849586 loss)
I0830 13:47:36.272598 916722 sgd_solver.cpp:106] Iteration 1696500, lr = 0.01
I0830 13:48:06.000242 916722 solver.cpp:218] Iteration 1697000 (16.8194 iter/s, 29.7276s/500 iters), loss = 0.14955
I0830 13:48:06.000300 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.149555 (* 1 = 0.149555 loss)
I0830 13:48:06.000309 916722 sgd_solver.cpp:106] Iteration 1697000, lr = 0.01
I0830 13:48:35.732668 916722 solver.cpp:218] Iteration 1697500 (16.8167 iter/s, 29.7323s/500 iters), loss = 0.103137
I0830 13:48:35.732718 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.103142 (* 1 = 0.103142 loss)
I0830 13:48:35.732728 916722 sgd_solver.cpp:106] Iteration 1697500, lr = 0.01
I0830 13:49:05.465389 916722 solver.cpp:218] Iteration 1698000 (16.8166 iter/s, 29.7326s/500 iters), loss = 0.0926885
I0830 13:49:05.465449 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0926933 (* 1 = 0.0926933 loss)
I0830 13:49:05.465457 916722 sgd_solver.cpp:106] Iteration 1698000, lr = 0.01
I0830 13:49:35.193962 916722 solver.cpp:218] Iteration 1698500 (16.8189 iter/s, 29.7284s/500 iters), loss = 0.0488902
I0830 13:49:35.194015 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0488951 (* 1 = 0.0488951 loss)
I0830 13:49:35.194025 916722 sgd_solver.cpp:106] Iteration 1698500, lr = 0.01
I0830 13:50:04.925465 916722 solver.cpp:218] Iteration 1699000 (16.8172 iter/s, 29.7314s/500 iters), loss = 0.100179
I0830 13:50:04.925539 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.100184 (* 1 = 0.100184 loss)
I0830 13:50:04.925546 916722 sgd_solver.cpp:106] Iteration 1699000, lr = 0.01
I0830 13:50:34.660491 916722 solver.cpp:218] Iteration 1699500 (16.8153 iter/s, 29.7349s/500 iters), loss = 0.219498
I0830 13:50:34.660542 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.219503 (* 1 = 0.219503 loss)
I0830 13:50:34.660550 916722 sgd_solver.cpp:106] Iteration 1699500, lr = 0.01
I0830 13:51:04.332265 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_1700000.caffemodel
I0830 13:51:04.351287 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_1700000.solverstate
I0830 13:51:04.357484 916722 solver.cpp:330] Iteration 1700000, Testing net (#0)
I0830 13:51:19.676163 916722 solver.cpp:397]     Test net output #0: accuracy = 0.896
I0830 13:51:19.676214 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.363622 (* 1 = 0.363622 loss)
I0830 13:51:19.734700 916722 solver.cpp:218] Iteration 1700000 (11.0929 iter/s, 45.074s/500 iters), loss = 0.147052
I0830 13:51:19.734727 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.147057 (* 1 = 0.147057 loss)
I0830 13:51:19.734736 916722 sgd_solver.cpp:106] Iteration 1700000, lr = 0.01
I0830 13:51:49.443701 916722 solver.cpp:218] Iteration 1700500 (16.83 iter/s, 29.7088s/500 iters), loss = 0.0480355
I0830 13:51:49.443763 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0480408 (* 1 = 0.0480408 loss)
I0830 13:51:49.443771 916722 sgd_solver.cpp:106] Iteration 1700500, lr = 0.01
I0830 13:52:19.160539 916722 solver.cpp:218] Iteration 1701000 (16.8256 iter/s, 29.7167s/500 iters), loss = 0.0687773
I0830 13:52:19.160586 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0687827 (* 1 = 0.0687827 loss)
I0830 13:52:19.160594 916722 sgd_solver.cpp:106] Iteration 1701000, lr = 0.01
I0830 13:52:48.883432 916722 solver.cpp:218] Iteration 1701500 (16.8221 iter/s, 29.7227s/500 iters), loss = 0.133455
I0830 13:52:48.883493 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13346 (* 1 = 0.13346 loss)
I0830 13:52:48.883502 916722 sgd_solver.cpp:106] Iteration 1701500, lr = 0.01
I0830 13:53:18.606613 916722 solver.cpp:218] Iteration 1702000 (16.822 iter/s, 29.723s/500 iters), loss = 0.0532275
I0830 13:53:18.606662 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0532328 (* 1 = 0.0532328 loss)
I0830 13:53:18.606671 916722 sgd_solver.cpp:106] Iteration 1702000, lr = 0.01
I0830 13:53:48.332183 916722 solver.cpp:218] Iteration 1702500 (16.8206 iter/s, 29.7254s/500 iters), loss = 0.0556131
I0830 13:53:48.332242 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0556184 (* 1 = 0.0556184 loss)
I0830 13:53:48.332250 916722 sgd_solver.cpp:106] Iteration 1702500, lr = 0.01
I0830 13:54:18.061283 916722 solver.cpp:218] Iteration 1703000 (16.8186 iter/s, 29.7289s/500 iters), loss = 0.172374
I0830 13:54:18.061336 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.17238 (* 1 = 0.17238 loss)
I0830 13:54:18.061345 916722 sgd_solver.cpp:106] Iteration 1703000, lr = 0.01
I0830 13:54:47.792738 916722 solver.cpp:218] Iteration 1703500 (16.8173 iter/s, 29.7313s/500 iters), loss = 0.298761
I0830 13:54:47.792807 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.298767 (* 1 = 0.298767 loss)
I0830 13:54:47.792816 916722 sgd_solver.cpp:106] Iteration 1703500, lr = 0.01
I0830 13:55:17.531499 916722 solver.cpp:218] Iteration 1704000 (16.8132 iter/s, 29.7386s/500 iters), loss = 0.019983
I0830 13:55:17.531549 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0199883 (* 1 = 0.0199883 loss)
I0830 13:55:17.531559 916722 sgd_solver.cpp:106] Iteration 1704000, lr = 0.01
I0830 13:55:47.267088 916722 solver.cpp:218] Iteration 1704500 (16.815 iter/s, 29.7354s/500 iters), loss = 0.146544
I0830 13:55:47.267159 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.14655 (* 1 = 0.14655 loss)
I0830 13:55:47.267171 916722 sgd_solver.cpp:106] Iteration 1704500, lr = 0.01
I0830 13:56:17.008831 916722 solver.cpp:218] Iteration 1705000 (16.8115 iter/s, 29.7416s/500 iters), loss = 0.149963
I0830 13:56:17.008881 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.149968 (* 1 = 0.149968 loss)
I0830 13:56:17.008890 916722 sgd_solver.cpp:106] Iteration 1705000, lr = 0.01
I0830 13:56:46.741394 916722 solver.cpp:218] Iteration 1705500 (16.8167 iter/s, 29.7324s/500 iters), loss = 0.0867755
I0830 13:56:46.741453 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0867807 (* 1 = 0.0867807 loss)
I0830 13:56:46.741462 916722 sgd_solver.cpp:106] Iteration 1705500, lr = 0.01
I0830 13:57:16.479051 916722 solver.cpp:218] Iteration 1706000 (16.8138 iter/s, 29.7375s/500 iters), loss = 0.117304
I0830 13:57:16.479100 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.117309 (* 1 = 0.117309 loss)
I0830 13:57:16.479110 916722 sgd_solver.cpp:106] Iteration 1706000, lr = 0.01
I0830 13:57:46.212729 916722 solver.cpp:218] Iteration 1706500 (16.816 iter/s, 29.7335s/500 iters), loss = 0.0323258
I0830 13:57:46.212796 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0323312 (* 1 = 0.0323312 loss)
I0830 13:57:46.212805 916722 sgd_solver.cpp:106] Iteration 1706500, lr = 0.01
I0830 13:58:15.946801 916722 solver.cpp:218] Iteration 1707000 (16.8158 iter/s, 29.7339s/500 iters), loss = 0.264431
I0830 13:58:15.946848 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.264436 (* 1 = 0.264436 loss)
I0830 13:58:15.946858 916722 sgd_solver.cpp:106] Iteration 1707000, lr = 0.01
I0830 13:58:45.684329 916722 solver.cpp:218] Iteration 1707500 (16.8139 iter/s, 29.7374s/500 iters), loss = 0.0776073
I0830 13:58:45.684391 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.077613 (* 1 = 0.077613 loss)
I0830 13:58:45.684399 916722 sgd_solver.cpp:106] Iteration 1707500, lr = 0.01
I0830 13:59:15.419694 916722 solver.cpp:218] Iteration 1708000 (16.8151 iter/s, 29.7352s/500 iters), loss = 0.184214
I0830 13:59:15.419744 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.184219 (* 1 = 0.184219 loss)
I0830 13:59:15.419752 916722 sgd_solver.cpp:106] Iteration 1708000, lr = 0.01
I0830 13:59:45.158138 916722 solver.cpp:218] Iteration 1708500 (16.8133 iter/s, 29.7383s/500 iters), loss = 0.0536903
I0830 13:59:45.158197 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.053696 (* 1 = 0.053696 loss)
I0830 13:59:45.158205 916722 sgd_solver.cpp:106] Iteration 1708500, lr = 0.01
I0830 14:00:14.896589 916722 solver.cpp:218] Iteration 1709000 (16.8133 iter/s, 29.7383s/500 iters), loss = 0.176719
I0830 14:00:14.896638 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.176725 (* 1 = 0.176725 loss)
I0830 14:00:14.896647 916722 sgd_solver.cpp:106] Iteration 1709000, lr = 0.01
I0830 14:00:44.632768 916722 solver.cpp:218] Iteration 1709500 (16.8146 iter/s, 29.736s/500 iters), loss = 0.10141
I0830 14:00:44.632827 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101415 (* 1 = 0.101415 loss)
I0830 14:00:44.632836 916722 sgd_solver.cpp:106] Iteration 1709500, lr = 0.01
I0830 14:01:14.367094 916722 solver.cpp:218] Iteration 1710000 (16.8157 iter/s, 29.7342s/500 iters), loss = 0.0959666
I0830 14:01:14.367144 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0959722 (* 1 = 0.0959722 loss)
I0830 14:01:14.367153 916722 sgd_solver.cpp:106] Iteration 1710000, lr = 0.01
I0830 14:01:44.099628 916722 solver.cpp:218] Iteration 1710500 (16.8167 iter/s, 29.7324s/500 iters), loss = 0.289246
I0830 14:01:44.099685 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.289251 (* 1 = 0.289251 loss)
I0830 14:01:44.099694 916722 sgd_solver.cpp:106] Iteration 1710500, lr = 0.01
I0830 14:02:13.837227 916722 solver.cpp:218] Iteration 1711000 (16.8138 iter/s, 29.7375s/500 iters), loss = 0.304164
I0830 14:02:13.837276 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.304169 (* 1 = 0.304169 loss)
I0830 14:02:13.837297 916722 sgd_solver.cpp:106] Iteration 1711000, lr = 0.01
I0830 14:02:43.574936 916722 solver.cpp:218] Iteration 1711500 (16.8137 iter/s, 29.7376s/500 iters), loss = 0.0649743
I0830 14:02:43.575007 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0649797 (* 1 = 0.0649797 loss)
I0830 14:02:43.575016 916722 sgd_solver.cpp:106] Iteration 1711500, lr = 0.01
I0830 14:03:13.310158 916722 solver.cpp:218] Iteration 1712000 (16.8152 iter/s, 29.7351s/500 iters), loss = 0.0433276
I0830 14:03:13.310206 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.043333 (* 1 = 0.043333 loss)
I0830 14:03:13.310215 916722 sgd_solver.cpp:106] Iteration 1712000, lr = 0.01
I0830 14:03:43.047740 916722 solver.cpp:218] Iteration 1712500 (16.8138 iter/s, 29.7375s/500 iters), loss = 0.110079
I0830 14:03:43.047801 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110084 (* 1 = 0.110084 loss)
I0830 14:03:43.047808 916722 sgd_solver.cpp:106] Iteration 1712500, lr = 0.01
I0830 14:04:12.789513 916722 solver.cpp:218] Iteration 1713000 (16.8115 iter/s, 29.7416s/500 iters), loss = 0.14117
I0830 14:04:12.789566 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.141176 (* 1 = 0.141176 loss)
I0830 14:04:12.789577 916722 sgd_solver.cpp:106] Iteration 1713000, lr = 0.01
I0830 14:04:42.527953 916722 solver.cpp:218] Iteration 1713500 (16.8133 iter/s, 29.7383s/500 iters), loss = 0.0289774
I0830 14:04:42.528012 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0289827 (* 1 = 0.0289827 loss)
I0830 14:04:42.528020 916722 sgd_solver.cpp:106] Iteration 1713500, lr = 0.01
I0830 14:05:12.268296 916722 solver.cpp:218] Iteration 1714000 (16.8123 iter/s, 29.7402s/500 iters), loss = 0.0740763
I0830 14:05:12.268347 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0740816 (* 1 = 0.0740816 loss)
I0830 14:05:12.268357 916722 sgd_solver.cpp:106] Iteration 1714000, lr = 0.01
I0830 14:05:42.006130 916722 solver.cpp:218] Iteration 1714500 (16.8137 iter/s, 29.7377s/500 iters), loss = 0.281135
I0830 14:05:42.006188 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.28114 (* 1 = 0.28114 loss)
I0830 14:05:42.006196 916722 sgd_solver.cpp:106] Iteration 1714500, lr = 0.01
I0830 14:06:11.745043 916722 solver.cpp:218] Iteration 1715000 (16.8131 iter/s, 29.7388s/500 iters), loss = 0.185637
I0830 14:06:11.745092 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.185642 (* 1 = 0.185642 loss)
I0830 14:06:11.745102 916722 sgd_solver.cpp:106] Iteration 1715000, lr = 0.01
I0830 14:06:41.483078 916722 solver.cpp:218] Iteration 1715500 (16.8136 iter/s, 29.7379s/500 iters), loss = 0.3115
I0830 14:06:41.483134 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.311505 (* 1 = 0.311505 loss)
I0830 14:06:41.483141 916722 sgd_solver.cpp:106] Iteration 1715500, lr = 0.01
I0830 14:07:11.221855 916722 solver.cpp:218] Iteration 1716000 (16.8131 iter/s, 29.7386s/500 iters), loss = 0.25061
I0830 14:07:11.221902 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.250615 (* 1 = 0.250615 loss)
I0830 14:07:11.221912 916722 sgd_solver.cpp:106] Iteration 1716000, lr = 0.01
I0830 14:07:40.957803 916722 solver.cpp:218] Iteration 1716500 (16.8147 iter/s, 29.7358s/500 iters), loss = 0.243029
I0830 14:07:40.957861 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.243035 (* 1 = 0.243035 loss)
I0830 14:07:40.957870 916722 sgd_solver.cpp:106] Iteration 1716500, lr = 0.01
I0830 14:08:10.697569 916722 solver.cpp:218] Iteration 1717000 (16.8126 iter/s, 29.7396s/500 iters), loss = 0.0997926
I0830 14:08:10.697621 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0997978 (* 1 = 0.0997978 loss)
I0830 14:08:10.697630 916722 sgd_solver.cpp:106] Iteration 1717000, lr = 0.01
I0830 14:08:40.437088 916722 solver.cpp:218] Iteration 1717500 (16.8127 iter/s, 29.7394s/500 iters), loss = 0.172474
I0830 14:08:40.437161 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.172479 (* 1 = 0.172479 loss)
I0830 14:08:40.437175 916722 sgd_solver.cpp:106] Iteration 1717500, lr = 0.01
I0830 14:09:10.179750 916722 solver.cpp:218] Iteration 1718000 (16.811 iter/s, 29.7425s/500 iters), loss = 0.136347
I0830 14:09:10.179798 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.136352 (* 1 = 0.136352 loss)
I0830 14:09:10.179806 916722 sgd_solver.cpp:106] Iteration 1718000, lr = 0.01
I0830 14:09:39.921576 916722 solver.cpp:218] Iteration 1718500 (16.8114 iter/s, 29.7417s/500 iters), loss = 0.119875
I0830 14:09:39.921633 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.119881 (* 1 = 0.119881 loss)
I0830 14:09:39.921641 916722 sgd_solver.cpp:106] Iteration 1718500, lr = 0.01
I0830 14:10:09.663744 916722 solver.cpp:218] Iteration 1719000 (16.8112 iter/s, 29.742s/500 iters), loss = 0.0531151
I0830 14:10:09.663795 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0531204 (* 1 = 0.0531204 loss)
I0830 14:10:09.663803 916722 sgd_solver.cpp:106] Iteration 1719000, lr = 0.01
I0830 14:10:39.406432 916722 solver.cpp:218] Iteration 1719500 (16.8109 iter/s, 29.7426s/500 iters), loss = 0.111126
I0830 14:10:39.406491 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111131 (* 1 = 0.111131 loss)
I0830 14:10:39.406498 916722 sgd_solver.cpp:106] Iteration 1719500, lr = 0.01
I0830 14:11:09.146621 916722 solver.cpp:218] Iteration 1720000 (16.8123 iter/s, 29.7401s/500 iters), loss = 0.0411753
I0830 14:11:09.146667 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0411808 (* 1 = 0.0411808 loss)
I0830 14:11:09.146675 916722 sgd_solver.cpp:106] Iteration 1720000, lr = 0.01
I0830 14:11:38.882529 916722 solver.cpp:218] Iteration 1720500 (16.8148 iter/s, 29.7358s/500 iters), loss = 0.187706
I0830 14:11:38.882589 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.187711 (* 1 = 0.187711 loss)
I0830 14:11:38.882597 916722 sgd_solver.cpp:106] Iteration 1720500, lr = 0.01
I0830 14:12:08.617839 916722 solver.cpp:218] Iteration 1721000 (16.8151 iter/s, 29.7352s/500 iters), loss = 0.131766
I0830 14:12:08.617902 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131772 (* 1 = 0.131772 loss)
I0830 14:12:08.617910 916722 sgd_solver.cpp:106] Iteration 1721000, lr = 0.01
I0830 14:12:38.356947 916722 solver.cpp:218] Iteration 1721500 (16.813 iter/s, 29.739s/500 iters), loss = 0.358318
I0830 14:12:38.357007 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.358324 (* 1 = 0.358324 loss)
I0830 14:12:38.357015 916722 sgd_solver.cpp:106] Iteration 1721500, lr = 0.01
I0830 14:13:08.096912 916722 solver.cpp:218] Iteration 1722000 (16.8125 iter/s, 29.7398s/500 iters), loss = 0.0741246
I0830 14:13:08.096961 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.07413 (* 1 = 0.07413 loss)
I0830 14:13:08.096971 916722 sgd_solver.cpp:106] Iteration 1722000, lr = 0.01
I0830 14:13:37.836700 916722 solver.cpp:218] Iteration 1722500 (16.8126 iter/s, 29.7397s/500 iters), loss = 0.0840787
I0830 14:13:37.836771 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0840842 (* 1 = 0.0840842 loss)
I0830 14:13:37.836779 916722 sgd_solver.cpp:106] Iteration 1722500, lr = 0.01
I0830 14:14:07.574631 916722 solver.cpp:218] Iteration 1723000 (16.8136 iter/s, 29.7378s/500 iters), loss = 0.222466
I0830 14:14:07.574682 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.222471 (* 1 = 0.222471 loss)
I0830 14:14:07.574692 916722 sgd_solver.cpp:106] Iteration 1723000, lr = 0.01
I0830 14:14:37.313067 916722 solver.cpp:218] Iteration 1723500 (16.8133 iter/s, 29.7383s/500 iters), loss = 0.259197
I0830 14:14:37.313124 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.259202 (* 1 = 0.259202 loss)
I0830 14:14:37.313133 916722 sgd_solver.cpp:106] Iteration 1723500, lr = 0.01
I0830 14:15:07.053730 916722 solver.cpp:218] Iteration 1724000 (16.8121 iter/s, 29.7405s/500 iters), loss = 0.303623
I0830 14:15:07.053779 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.303628 (* 1 = 0.303628 loss)
I0830 14:15:07.053789 916722 sgd_solver.cpp:106] Iteration 1724000, lr = 0.01
I0830 14:15:36.794533 916722 solver.cpp:218] Iteration 1724500 (16.812 iter/s, 29.7407s/500 iters), loss = 0.151641
I0830 14:15:36.794598 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.151647 (* 1 = 0.151647 loss)
I0830 14:15:36.794607 916722 sgd_solver.cpp:106] Iteration 1724500, lr = 0.01
I0830 14:16:06.529415 916722 solver.cpp:218] Iteration 1725000 (16.8153 iter/s, 29.7347s/500 iters), loss = 0.490456
I0830 14:16:06.529464 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.490461 (* 1 = 0.490461 loss)
I0830 14:16:06.529474 916722 sgd_solver.cpp:106] Iteration 1725000, lr = 0.01
I0830 14:16:36.264461 916722 solver.cpp:218] Iteration 1725500 (16.8152 iter/s, 29.7349s/500 iters), loss = 0.0397268
I0830 14:16:36.264537 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0397325 (* 1 = 0.0397325 loss)
I0830 14:16:36.264564 916722 sgd_solver.cpp:106] Iteration 1725500, lr = 0.01
I0830 14:17:05.999150 916722 solver.cpp:218] Iteration 1726000 (16.8155 iter/s, 29.7345s/500 iters), loss = 0.0198131
I0830 14:17:05.999199 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0198187 (* 1 = 0.0198187 loss)
I0830 14:17:05.999208 916722 sgd_solver.cpp:106] Iteration 1726000, lr = 0.01
I0830 14:17:35.736799 916722 solver.cpp:218] Iteration 1726500 (16.8138 iter/s, 29.7375s/500 iters), loss = 0.21336
I0830 14:17:35.736857 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.213366 (* 1 = 0.213366 loss)
I0830 14:17:35.736865 916722 sgd_solver.cpp:106] Iteration 1726500, lr = 0.01
I0830 14:18:05.477600 916722 solver.cpp:218] Iteration 1727000 (16.812 iter/s, 29.7407s/500 iters), loss = 0.323755
I0830 14:18:05.477650 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.32376 (* 1 = 0.32376 loss)
I0830 14:18:05.477660 916722 sgd_solver.cpp:106] Iteration 1727000, lr = 0.01
I0830 14:18:35.218015 916722 solver.cpp:218] Iteration 1727500 (16.8122 iter/s, 29.7403s/500 iters), loss = 0.0801541
I0830 14:18:35.218073 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0801597 (* 1 = 0.0801597 loss)
I0830 14:18:35.218081 916722 sgd_solver.cpp:106] Iteration 1727500, lr = 0.01
I0830 14:19:04.951506 916722 solver.cpp:218] Iteration 1728000 (16.8161 iter/s, 29.7334s/500 iters), loss = 0.313613
I0830 14:19:04.951555 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.313619 (* 1 = 0.313619 loss)
I0830 14:19:04.951563 916722 sgd_solver.cpp:106] Iteration 1728000, lr = 0.01
I0830 14:19:34.689507 916722 solver.cpp:218] Iteration 1728500 (16.8136 iter/s, 29.7379s/500 iters), loss = 0.362952
I0830 14:19:34.689566 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.362958 (* 1 = 0.362958 loss)
I0830 14:19:34.689574 916722 sgd_solver.cpp:106] Iteration 1728500, lr = 0.01
I0830 14:20:04.422268 916722 solver.cpp:218] Iteration 1729000 (16.8165 iter/s, 29.7326s/500 iters), loss = 0.1167
I0830 14:20:04.422314 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.116706 (* 1 = 0.116706 loss)
I0830 14:20:04.422324 916722 sgd_solver.cpp:106] Iteration 1729000, lr = 0.01
I0830 14:20:34.158143 916722 solver.cpp:218] Iteration 1729500 (16.8148 iter/s, 29.7358s/500 iters), loss = 0.0830962
I0830 14:20:34.158201 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.083102 (* 1 = 0.083102 loss)
I0830 14:20:34.158210 916722 sgd_solver.cpp:106] Iteration 1729500, lr = 0.01
I0830 14:21:03.894973 916722 solver.cpp:218] Iteration 1730000 (16.8142 iter/s, 29.7367s/500 iters), loss = 0.213974
I0830 14:21:03.895022 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.21398 (* 1 = 0.21398 loss)
I0830 14:21:03.895031 916722 sgd_solver.cpp:106] Iteration 1730000, lr = 0.01
I0830 14:21:33.631776 916722 solver.cpp:218] Iteration 1730500 (16.8143 iter/s, 29.7367s/500 iters), loss = 0.170597
I0830 14:21:33.631835 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.170603 (* 1 = 0.170603 loss)
I0830 14:21:33.631844 916722 sgd_solver.cpp:106] Iteration 1730500, lr = 0.01
I0830 14:22:03.370363 916722 solver.cpp:218] Iteration 1731000 (16.8132 iter/s, 29.7385s/500 iters), loss = 0.331663
I0830 14:22:03.370424 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.331668 (* 1 = 0.331668 loss)
I0830 14:22:03.370446 916722 sgd_solver.cpp:106] Iteration 1731000, lr = 0.01
I0830 14:22:33.109973 916722 solver.cpp:218] Iteration 1731500 (16.8127 iter/s, 29.7395s/500 iters), loss = 0.363647
I0830 14:22:33.110044 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.363653 (* 1 = 0.363653 loss)
I0830 14:22:33.110052 916722 sgd_solver.cpp:106] Iteration 1731500, lr = 0.01
I0830 14:23:02.847515 916722 solver.cpp:218] Iteration 1732000 (16.8138 iter/s, 29.7374s/500 iters), loss = 0.0283065
I0830 14:23:02.847563 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0283122 (* 1 = 0.0283122 loss)
I0830 14:23:02.847573 916722 sgd_solver.cpp:106] Iteration 1732000, lr = 0.01
I0830 14:23:32.582703 916722 solver.cpp:218] Iteration 1732500 (16.8152 iter/s, 29.7351s/500 iters), loss = 0.129923
I0830 14:23:32.582762 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.129928 (* 1 = 0.129928 loss)
I0830 14:23:32.582770 916722 sgd_solver.cpp:106] Iteration 1732500, lr = 0.01
I0830 14:24:02.320192 916722 solver.cpp:218] Iteration 1733000 (16.8139 iter/s, 29.7374s/500 iters), loss = 0.292095
I0830 14:24:02.320240 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.292101 (* 1 = 0.292101 loss)
I0830 14:24:02.320250 916722 sgd_solver.cpp:106] Iteration 1733000, lr = 0.01
I0830 14:24:32.063685 916722 solver.cpp:218] Iteration 1733500 (16.8105 iter/s, 29.7434s/500 iters), loss = 0.239269
I0830 14:24:32.063747 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.239275 (* 1 = 0.239275 loss)
I0830 14:24:32.063755 916722 sgd_solver.cpp:106] Iteration 1733500, lr = 0.01
I0830 14:25:01.804620 916722 solver.cpp:218] Iteration 1734000 (16.812 iter/s, 29.7407s/500 iters), loss = 0.0729555
I0830 14:25:01.804669 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0729612 (* 1 = 0.0729612 loss)
I0830 14:25:01.804677 916722 sgd_solver.cpp:106] Iteration 1734000, lr = 0.01
I0830 14:25:31.544109 916722 solver.cpp:218] Iteration 1734500 (16.8128 iter/s, 29.7393s/500 iters), loss = 0.0705968
I0830 14:25:31.544168 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0706024 (* 1 = 0.0706024 loss)
I0830 14:25:31.544178 916722 sgd_solver.cpp:106] Iteration 1734500, lr = 0.01
I0830 14:26:01.285605 916722 solver.cpp:218] Iteration 1735000 (16.8116 iter/s, 29.7413s/500 iters), loss = 0.198937
I0830 14:26:01.285652 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.198943 (* 1 = 0.198943 loss)
I0830 14:26:01.285660 916722 sgd_solver.cpp:106] Iteration 1735000, lr = 0.01
I0830 14:26:31.023864 916722 solver.cpp:218] Iteration 1735500 (16.8134 iter/s, 29.7381s/500 iters), loss = 0.419959
I0830 14:26:31.023923 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.419964 (* 1 = 0.419964 loss)
I0830 14:26:31.023931 916722 sgd_solver.cpp:106] Iteration 1735500, lr = 0.01
I0830 14:27:00.764032 916722 solver.cpp:218] Iteration 1736000 (16.8124 iter/s, 29.74s/500 iters), loss = 0.0326364
I0830 14:27:00.764078 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.032642 (* 1 = 0.032642 loss)
I0830 14:27:00.764086 916722 sgd_solver.cpp:106] Iteration 1736000, lr = 0.01
I0830 14:27:30.505793 916722 solver.cpp:218] Iteration 1736500 (16.8115 iter/s, 29.7416s/500 iters), loss = 0.107902
I0830 14:27:30.505853 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.107908 (* 1 = 0.107908 loss)
I0830 14:27:30.505862 916722 sgd_solver.cpp:106] Iteration 1736500, lr = 0.01
I0830 14:28:00.248356 916722 solver.cpp:218] Iteration 1737000 (16.811 iter/s, 29.7424s/500 iters), loss = 0.223387
I0830 14:28:00.248405 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.223392 (* 1 = 0.223392 loss)
I0830 14:28:00.248414 916722 sgd_solver.cpp:106] Iteration 1737000, lr = 0.01
I0830 14:28:29.988776 916722 solver.cpp:218] Iteration 1737500 (16.8122 iter/s, 29.7403s/500 iters), loss = 0.320994
I0830 14:28:29.988844 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.321 (* 1 = 0.321 loss)
I0830 14:28:29.988853 916722 sgd_solver.cpp:106] Iteration 1737500, lr = 0.01
I0830 14:28:59.735718 916722 solver.cpp:218] Iteration 1738000 (16.8085 iter/s, 29.7468s/500 iters), loss = 0.0823893
I0830 14:28:59.735760 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0823949 (* 1 = 0.0823949 loss)
I0830 14:28:59.735769 916722 sgd_solver.cpp:106] Iteration 1738000, lr = 0.01
I0830 14:29:29.482743 916722 solver.cpp:218] Iteration 1738500 (16.8085 iter/s, 29.7469s/500 iters), loss = 0.0482769
I0830 14:29:29.482802 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0482826 (* 1 = 0.0482826 loss)
I0830 14:29:29.482810 916722 sgd_solver.cpp:106] Iteration 1738500, lr = 0.01
I0830 14:29:59.225795 916722 solver.cpp:218] Iteration 1739000 (16.8107 iter/s, 29.7429s/500 iters), loss = 0.354442
I0830 14:29:59.225845 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.354447 (* 1 = 0.354447 loss)
I0830 14:29:59.225855 916722 sgd_solver.cpp:106] Iteration 1739000, lr = 0.01
I0830 14:30:28.964761 916722 solver.cpp:218] Iteration 1739500 (16.813 iter/s, 29.7388s/500 iters), loss = 0.0749825
I0830 14:30:28.964820 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.074988 (* 1 = 0.074988 loss)
I0830 14:30:28.964829 916722 sgd_solver.cpp:106] Iteration 1739500, lr = 0.01
I0830 14:30:58.711551 916722 solver.cpp:218] Iteration 1740000 (16.8086 iter/s, 29.7466s/500 iters), loss = 0.0856965
I0830 14:30:58.711601 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0857019 (* 1 = 0.0857019 loss)
I0830 14:30:58.711611 916722 sgd_solver.cpp:106] Iteration 1740000, lr = 0.01
I0830 14:31:28.458920 916722 solver.cpp:218] Iteration 1740500 (16.8083 iter/s, 29.7472s/500 iters), loss = 0.166736
I0830 14:31:28.458974 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.166742 (* 1 = 0.166742 loss)
I0830 14:31:28.458982 916722 sgd_solver.cpp:106] Iteration 1740500, lr = 0.01
I0830 14:31:58.210539 916722 solver.cpp:218] Iteration 1741000 (16.8059 iter/s, 29.7515s/500 iters), loss = 0.0846933
I0830 14:31:58.210587 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0846987 (* 1 = 0.0846987 loss)
I0830 14:31:58.210595 916722 sgd_solver.cpp:106] Iteration 1741000, lr = 0.01
I0830 14:32:27.959349 916722 solver.cpp:218] Iteration 1741500 (16.8075 iter/s, 29.7487s/500 iters), loss = 0.0414009
I0830 14:32:27.959406 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0414062 (* 1 = 0.0414062 loss)
I0830 14:32:27.959415 916722 sgd_solver.cpp:106] Iteration 1741500, lr = 0.01
I0830 14:32:57.708268 916722 solver.cpp:218] Iteration 1742000 (16.8074 iter/s, 29.7488s/500 iters), loss = 0.114498
I0830 14:32:57.708314 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.114503 (* 1 = 0.114503 loss)
I0830 14:32:57.708323 916722 sgd_solver.cpp:106] Iteration 1742000, lr = 0.01
I0830 14:33:27.460933 916722 solver.cpp:218] Iteration 1742500 (16.8053 iter/s, 29.7525s/500 iters), loss = 0.299081
I0830 14:33:27.460985 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.299086 (* 1 = 0.299086 loss)
I0830 14:33:27.460994 916722 sgd_solver.cpp:106] Iteration 1742500, lr = 0.01
I0830 14:33:57.202862 916722 solver.cpp:218] Iteration 1743000 (16.8114 iter/s, 29.7418s/500 iters), loss = 0.222148
I0830 14:33:57.202908 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.222154 (* 1 = 0.222154 loss)
I0830 14:33:57.202917 916722 sgd_solver.cpp:106] Iteration 1743000, lr = 0.01
I0830 14:34:26.935210 916722 solver.cpp:218] Iteration 1743500 (16.8168 iter/s, 29.7322s/500 iters), loss = 0.225438
I0830 14:34:26.935267 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.225443 (* 1 = 0.225443 loss)
I0830 14:34:26.935276 916722 sgd_solver.cpp:106] Iteration 1743500, lr = 0.01
I0830 14:34:56.688114 916722 solver.cpp:218] Iteration 1744000 (16.8052 iter/s, 29.7528s/500 iters), loss = 0.100956
I0830 14:34:56.688172 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.100962 (* 1 = 0.100962 loss)
I0830 14:34:56.688181 916722 sgd_solver.cpp:106] Iteration 1744000, lr = 0.01
I0830 14:35:26.444082 916722 solver.cpp:218] Iteration 1744500 (16.8034 iter/s, 29.7558s/500 iters), loss = 0.168659
I0830 14:35:26.444137 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.168664 (* 1 = 0.168664 loss)
I0830 14:35:26.444146 916722 sgd_solver.cpp:106] Iteration 1744500, lr = 0.01
I0830 14:35:56.202260 916722 solver.cpp:218] Iteration 1745000 (16.8022 iter/s, 29.758s/500 iters), loss = 0.108883
I0830 14:35:56.202304 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.108888 (* 1 = 0.108888 loss)
I0830 14:35:56.202313 916722 sgd_solver.cpp:106] Iteration 1745000, lr = 0.01
I0830 14:36:25.957401 916722 solver.cpp:218] Iteration 1745500 (16.8039 iter/s, 29.755s/500 iters), loss = 0.168151
I0830 14:36:25.957455 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.168157 (* 1 = 0.168157 loss)
I0830 14:36:25.957464 916722 sgd_solver.cpp:106] Iteration 1745500, lr = 0.01
I0830 14:36:55.713861 916722 solver.cpp:218] Iteration 1746000 (16.8032 iter/s, 29.7563s/500 iters), loss = 0.0689486
I0830 14:36:55.713907 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.068954 (* 1 = 0.068954 loss)
I0830 14:36:55.713914 916722 sgd_solver.cpp:106] Iteration 1746000, lr = 0.01
I0830 14:37:25.467747 916722 solver.cpp:218] Iteration 1746500 (16.8046 iter/s, 29.7538s/500 iters), loss = 0.296707
I0830 14:37:25.467803 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.296712 (* 1 = 0.296712 loss)
I0830 14:37:25.467813 916722 sgd_solver.cpp:106] Iteration 1746500, lr = 0.01
I0830 14:37:55.216189 916722 solver.cpp:218] Iteration 1747000 (16.8077 iter/s, 29.7483s/500 iters), loss = 0.206222
I0830 14:37:55.216239 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.206228 (* 1 = 0.206228 loss)
I0830 14:37:55.216248 916722 sgd_solver.cpp:106] Iteration 1747000, lr = 0.01
I0830 14:38:24.962373 916722 solver.cpp:218] Iteration 1747500 (16.809 iter/s, 29.7461s/500 iters), loss = 0.130726
I0830 14:38:24.962433 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130732 (* 1 = 0.130732 loss)
I0830 14:38:24.962441 916722 sgd_solver.cpp:106] Iteration 1747500, lr = 0.01
I0830 14:38:54.710340 916722 solver.cpp:218] Iteration 1748000 (16.808 iter/s, 29.7478s/500 iters), loss = 0.267637
I0830 14:38:54.710391 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.267642 (* 1 = 0.267642 loss)
I0830 14:38:54.710400 916722 sgd_solver.cpp:106] Iteration 1748000, lr = 0.01
I0830 14:39:24.456183 916722 solver.cpp:218] Iteration 1748500 (16.8091 iter/s, 29.7457s/500 iters), loss = 0.175295
I0830 14:39:24.456235 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.1753 (* 1 = 0.1753 loss)
I0830 14:39:24.456243 916722 sgd_solver.cpp:106] Iteration 1748500, lr = 0.01
I0830 14:39:54.203171 916722 solver.cpp:218] Iteration 1749000 (16.8085 iter/s, 29.7469s/500 iters), loss = 0.0695086
I0830 14:39:54.203218 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0695141 (* 1 = 0.0695141 loss)
I0830 14:39:54.203227 916722 sgd_solver.cpp:106] Iteration 1749000, lr = 0.01
I0830 14:40:23.953357 916722 solver.cpp:218] Iteration 1749500 (16.8067 iter/s, 29.7501s/500 iters), loss = 0.206489
I0830 14:40:23.953420 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.206495 (* 1 = 0.206495 loss)
I0830 14:40:23.953429 916722 sgd_solver.cpp:106] Iteration 1749500, lr = 0.01
I0830 14:40:53.643580 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_1750000.caffemodel
I0830 14:40:53.662575 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_1750000.solverstate
I0830 14:40:53.668697 916722 solver.cpp:330] Iteration 1750000, Testing net (#0)
I0830 14:41:09.031252 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8545
I0830 14:41:09.031317 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.486672 (* 1 = 0.486672 loss)
I0830 14:41:09.089846 916722 solver.cpp:218] Iteration 1750000 (11.0776 iter/s, 45.1363s/500 iters), loss = 0.0694867
I0830 14:41:09.089871 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0694921 (* 1 = 0.0694921 loss)
I0830 14:41:09.089879 916722 sgd_solver.cpp:106] Iteration 1750000, lr = 0.01
I0830 14:41:38.802047 916722 solver.cpp:218] Iteration 1750500 (16.8282 iter/s, 29.7121s/500 iters), loss = 0.0889443
I0830 14:41:38.802096 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0889496 (* 1 = 0.0889496 loss)
I0830 14:41:38.802104 916722 sgd_solver.cpp:106] Iteration 1750500, lr = 0.01
I0830 14:42:08.523145 916722 solver.cpp:218] Iteration 1751000 (16.8231 iter/s, 29.721s/500 iters), loss = 0.074746
I0830 14:42:08.523206 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0747515 (* 1 = 0.0747515 loss)
I0830 14:42:08.523216 916722 sgd_solver.cpp:106] Iteration 1751000, lr = 0.01
I0830 14:42:38.251953 916722 solver.cpp:218] Iteration 1751500 (16.8188 iter/s, 29.7287s/500 iters), loss = 0.203338
I0830 14:42:38.252007 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.203344 (* 1 = 0.203344 loss)
I0830 14:42:38.252015 916722 sgd_solver.cpp:106] Iteration 1751500, lr = 0.01
I0830 14:43:07.984002 916722 solver.cpp:218] Iteration 1752000 (16.8169 iter/s, 29.7319s/500 iters), loss = 0.0332618
I0830 14:43:07.984059 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0332677 (* 1 = 0.0332677 loss)
I0830 14:43:07.984067 916722 sgd_solver.cpp:106] Iteration 1752000, lr = 0.01
I0830 14:43:37.727694 916722 solver.cpp:218] Iteration 1752500 (16.8104 iter/s, 29.7436s/500 iters), loss = 0.111734
I0830 14:43:37.727748 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.11174 (* 1 = 0.11174 loss)
I0830 14:43:37.727756 916722 sgd_solver.cpp:106] Iteration 1752500, lr = 0.01
I0830 14:44:07.493899 916722 solver.cpp:218] Iteration 1753000 (16.7976 iter/s, 29.7661s/500 iters), loss = 0.108186
I0830 14:44:07.493959 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.108192 (* 1 = 0.108192 loss)
I0830 14:44:07.493968 916722 sgd_solver.cpp:106] Iteration 1753000, lr = 0.01
I0830 14:44:37.264881 916722 solver.cpp:218] Iteration 1753500 (16.795 iter/s, 29.7709s/500 iters), loss = 0.280674
I0830 14:44:37.264935 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.28068 (* 1 = 0.28068 loss)
I0830 14:44:37.264943 916722 sgd_solver.cpp:106] Iteration 1753500, lr = 0.01
I0830 14:45:07.033232 916722 solver.cpp:218] Iteration 1754000 (16.7964 iter/s, 29.7682s/500 iters), loss = 0.0754571
I0830 14:45:07.033293 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0754632 (* 1 = 0.0754632 loss)
I0830 14:45:07.033301 916722 sgd_solver.cpp:106] Iteration 1754000, lr = 0.01
I0830 14:45:36.802996 916722 solver.cpp:218] Iteration 1754500 (16.7956 iter/s, 29.7696s/500 iters), loss = 0.076424
I0830 14:45:36.803050 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0764301 (* 1 = 0.0764301 loss)
I0830 14:45:36.803057 916722 sgd_solver.cpp:106] Iteration 1754500, lr = 0.01
I0830 14:46:06.571468 916722 solver.cpp:218] Iteration 1755000 (16.7964 iter/s, 29.7684s/500 iters), loss = 0.205952
I0830 14:46:06.571527 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.205958 (* 1 = 0.205958 loss)
I0830 14:46:06.571535 916722 sgd_solver.cpp:106] Iteration 1755000, lr = 0.01
I0830 14:46:36.333840 916722 solver.cpp:218] Iteration 1755500 (16.7998 iter/s, 29.7622s/500 iters), loss = 0.215657
I0830 14:46:36.333890 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.215663 (* 1 = 0.215663 loss)
I0830 14:46:36.333899 916722 sgd_solver.cpp:106] Iteration 1755500, lr = 0.01
I0830 14:47:06.097646 916722 solver.cpp:218] Iteration 1756000 (16.799 iter/s, 29.7637s/500 iters), loss = 0.496591
I0830 14:47:06.097707 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.496597 (* 1 = 0.496597 loss)
I0830 14:47:06.097714 916722 sgd_solver.cpp:106] Iteration 1756000, lr = 0.01
I0830 14:47:35.862100 916722 solver.cpp:218] Iteration 1756500 (16.7986 iter/s, 29.7643s/500 iters), loss = 0.217504
I0830 14:47:35.862156 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.21751 (* 1 = 0.21751 loss)
I0830 14:47:35.862166 916722 sgd_solver.cpp:106] Iteration 1756500, lr = 0.01
I0830 14:48:05.625252 916722 solver.cpp:218] Iteration 1757000 (16.7994 iter/s, 29.763s/500 iters), loss = 0.0506157
I0830 14:48:05.625322 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0506214 (* 1 = 0.0506214 loss)
I0830 14:48:05.625330 916722 sgd_solver.cpp:106] Iteration 1757000, lr = 0.01
I0830 14:48:35.386952 916722 solver.cpp:218] Iteration 1757500 (16.8002 iter/s, 29.7616s/500 iters), loss = 0.282154
I0830 14:48:35.387007 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.28216 (* 1 = 0.28216 loss)
I0830 14:48:35.387017 916722 sgd_solver.cpp:106] Iteration 1757500, lr = 0.01
I0830 14:49:05.154145 916722 solver.cpp:218] Iteration 1758000 (16.7971 iter/s, 29.7671s/500 iters), loss = 0.0707099
I0830 14:49:05.154201 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0707158 (* 1 = 0.0707158 loss)
I0830 14:49:05.154209 916722 sgd_solver.cpp:106] Iteration 1758000, lr = 0.01
I0830 14:49:34.918598 916722 solver.cpp:218] Iteration 1758500 (16.7986 iter/s, 29.7643s/500 iters), loss = 0.108869
I0830 14:49:34.918651 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.108875 (* 1 = 0.108875 loss)
I0830 14:49:34.918661 916722 sgd_solver.cpp:106] Iteration 1758500, lr = 0.01
I0830 14:50:04.678535 916722 solver.cpp:218] Iteration 1759000 (16.8012 iter/s, 29.7598s/500 iters), loss = 0.300816
I0830 14:50:04.678591 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.300822 (* 1 = 0.300822 loss)
I0830 14:50:04.678599 916722 sgd_solver.cpp:106] Iteration 1759000, lr = 0.01
I0830 14:50:34.440018 916722 solver.cpp:218] Iteration 1759500 (16.8003 iter/s, 29.7614s/500 iters), loss = 0.124216
I0830 14:50:34.440068 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.124222 (* 1 = 0.124222 loss)
I0830 14:50:34.440078 916722 sgd_solver.cpp:106] Iteration 1759500, lr = 0.01
I0830 14:51:04.208406 916722 solver.cpp:218] Iteration 1760000 (16.7964 iter/s, 29.7683s/500 iters), loss = 0.116084
I0830 14:51:04.208465 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.11609 (* 1 = 0.11609 loss)
I0830 14:51:04.208473 916722 sgd_solver.cpp:106] Iteration 1760000, lr = 0.01
I0830 14:51:33.971534 916722 solver.cpp:218] Iteration 1760500 (16.7994 iter/s, 29.763s/500 iters), loss = 0.105791
I0830 14:51:33.971586 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105798 (* 1 = 0.105798 loss)
I0830 14:51:33.971596 916722 sgd_solver.cpp:106] Iteration 1760500, lr = 0.01
I0830 14:52:03.733842 916722 solver.cpp:218] Iteration 1761000 (16.7998 iter/s, 29.7622s/500 iters), loss = 0.164363
I0830 14:52:03.733897 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.164369 (* 1 = 0.164369 loss)
I0830 14:52:03.733906 916722 sgd_solver.cpp:106] Iteration 1761000, lr = 0.01
I0830 14:52:33.497424 916722 solver.cpp:218] Iteration 1761500 (16.7991 iter/s, 29.7635s/500 iters), loss = 0.0539973
I0830 14:52:33.497478 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0540035 (* 1 = 0.0540035 loss)
I0830 14:52:33.497488 916722 sgd_solver.cpp:106] Iteration 1761500, lr = 0.01
I0830 14:53:03.259099 916722 solver.cpp:218] Iteration 1762000 (16.8002 iter/s, 29.7616s/500 iters), loss = 0.268407
I0830 14:53:03.259160 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.268413 (* 1 = 0.268413 loss)
I0830 14:53:03.259167 916722 sgd_solver.cpp:106] Iteration 1762000, lr = 0.01
I0830 14:53:33.031137 916722 solver.cpp:218] Iteration 1762500 (16.7944 iter/s, 29.7719s/500 iters), loss = 0.0646895
I0830 14:53:33.031190 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0646957 (* 1 = 0.0646957 loss)
I0830 14:53:33.031198 916722 sgd_solver.cpp:106] Iteration 1762500, lr = 0.01
I0830 14:54:02.798727 916722 solver.cpp:218] Iteration 1763000 (16.7969 iter/s, 29.7675s/500 iters), loss = 0.183034
I0830 14:54:02.798797 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.18304 (* 1 = 0.18304 loss)
I0830 14:54:02.798806 916722 sgd_solver.cpp:106] Iteration 1763000, lr = 0.01
I0830 14:54:32.564859 916722 solver.cpp:218] Iteration 1763500 (16.7977 iter/s, 29.766s/500 iters), loss = 0.0838493
I0830 14:54:32.564910 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0838554 (* 1 = 0.0838554 loss)
I0830 14:54:32.564919 916722 sgd_solver.cpp:106] Iteration 1763500, lr = 0.01
I0830 14:55:02.327574 916722 solver.cpp:218] Iteration 1764000 (16.7996 iter/s, 29.7626s/500 iters), loss = 0.199783
I0830 14:55:02.327630 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.199789 (* 1 = 0.199789 loss)
I0830 14:55:02.327638 916722 sgd_solver.cpp:106] Iteration 1764000, lr = 0.01
I0830 14:55:32.094247 916722 solver.cpp:218] Iteration 1764500 (16.7974 iter/s, 29.7665s/500 iters), loss = 0.101501
I0830 14:55:32.094300 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101508 (* 1 = 0.101508 loss)
I0830 14:55:32.094308 916722 sgd_solver.cpp:106] Iteration 1764500, lr = 0.01
I0830 14:56:01.860342 916722 solver.cpp:218] Iteration 1765000 (16.7977 iter/s, 29.766s/500 iters), loss = 0.20045
I0830 14:56:01.860399 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.200457 (* 1 = 0.200457 loss)
I0830 14:56:01.860407 916722 sgd_solver.cpp:106] Iteration 1765000, lr = 0.01
I0830 14:56:31.624910 916722 solver.cpp:218] Iteration 1765500 (16.7986 iter/s, 29.7644s/500 iters), loss = 0.204444
I0830 14:56:31.624965 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.204451 (* 1 = 0.204451 loss)
I0830 14:56:31.624974 916722 sgd_solver.cpp:106] Iteration 1765500, lr = 0.01
I0830 14:57:01.392324 916722 solver.cpp:218] Iteration 1766000 (16.797 iter/s, 29.7673s/500 iters), loss = 0.0453392
I0830 14:57:01.392381 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0453457 (* 1 = 0.0453457 loss)
I0830 14:57:01.392390 916722 sgd_solver.cpp:106] Iteration 1766000, lr = 0.01
I0830 14:57:31.158381 916722 solver.cpp:218] Iteration 1766500 (16.7977 iter/s, 29.7659s/500 iters), loss = 0.247031
I0830 14:57:31.158435 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.247038 (* 1 = 0.247038 loss)
I0830 14:57:31.158443 916722 sgd_solver.cpp:106] Iteration 1766500, lr = 0.01
I0830 14:58:00.925092 916722 solver.cpp:218] Iteration 1767000 (16.7974 iter/s, 29.7666s/500 iters), loss = 0.0955391
I0830 14:58:00.925148 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0955457 (* 1 = 0.0955457 loss)
I0830 14:58:00.925158 916722 sgd_solver.cpp:106] Iteration 1767000, lr = 0.01
I0830 14:58:30.692998 916722 solver.cpp:218] Iteration 1767500 (16.7967 iter/s, 29.7678s/500 iters), loss = 0.220355
I0830 14:58:30.693050 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.220361 (* 1 = 0.220361 loss)
I0830 14:58:30.693059 916722 sgd_solver.cpp:106] Iteration 1767500, lr = 0.01
I0830 14:59:00.456262 916722 solver.cpp:218] Iteration 1768000 (16.7995 iter/s, 29.7628s/500 iters), loss = 0.0775709
I0830 14:59:00.456319 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0775773 (* 1 = 0.0775773 loss)
I0830 14:59:00.456328 916722 sgd_solver.cpp:106] Iteration 1768000, lr = 0.01
I0830 14:59:30.219800 916722 solver.cpp:218] Iteration 1768500 (16.7994 iter/s, 29.763s/500 iters), loss = 0.138893
I0830 14:59:30.219848 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.138899 (* 1 = 0.138899 loss)
I0830 14:59:30.219856 916722 sgd_solver.cpp:106] Iteration 1768500, lr = 0.01
I0830 14:59:59.982935 916722 solver.cpp:218] Iteration 1769000 (16.7996 iter/s, 29.7627s/500 iters), loss = 0.0487377
I0830 14:59:59.982996 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.048744 (* 1 = 0.048744 loss)
I0830 14:59:59.983006 916722 sgd_solver.cpp:106] Iteration 1769000, lr = 0.01
I0830 15:00:29.747686 916722 solver.cpp:218] Iteration 1769500 (16.7987 iter/s, 29.7643s/500 iters), loss = 0.0456582
I0830 15:00:29.747751 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0456646 (* 1 = 0.0456646 loss)
I0830 15:00:29.747759 916722 sgd_solver.cpp:106] Iteration 1769500, lr = 0.01
I0830 15:00:59.515018 916722 solver.cpp:218] Iteration 1770000 (16.7972 iter/s, 29.7669s/500 iters), loss = 0.103495
I0830 15:00:59.515091 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.103501 (* 1 = 0.103501 loss)
I0830 15:00:59.515100 916722 sgd_solver.cpp:106] Iteration 1770000, lr = 0.01
I0830 15:01:29.278524 916722 solver.cpp:218] Iteration 1770500 (16.7993 iter/s, 29.7631s/500 iters), loss = 0.0504948
I0830 15:01:29.278579 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.050501 (* 1 = 0.050501 loss)
I0830 15:01:29.278589 916722 sgd_solver.cpp:106] Iteration 1770500, lr = 0.01
I0830 15:01:59.042785 916722 solver.cpp:218] Iteration 1771000 (16.7989 iter/s, 29.7638s/500 iters), loss = 0.183464
I0830 15:01:59.042843 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.18347 (* 1 = 0.18347 loss)
I0830 15:01:59.042852 916722 sgd_solver.cpp:106] Iteration 1771000, lr = 0.01
I0830 15:02:28.808811 916722 solver.cpp:218] Iteration 1771500 (16.7979 iter/s, 29.7656s/500 iters), loss = 0.211948
I0830 15:02:28.808866 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.211954 (* 1 = 0.211954 loss)
I0830 15:02:28.808876 916722 sgd_solver.cpp:106] Iteration 1771500, lr = 0.01
I0830 15:02:58.574667 916722 solver.cpp:218] Iteration 1772000 (16.798 iter/s, 29.7655s/500 iters), loss = 0.195843
I0830 15:02:58.574725 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.195849 (* 1 = 0.195849 loss)
I0830 15:02:58.574733 916722 sgd_solver.cpp:106] Iteration 1772000, lr = 0.01
I0830 15:03:28.339324 916722 solver.cpp:218] Iteration 1772500 (16.7987 iter/s, 29.7643s/500 iters), loss = 0.158865
I0830 15:03:28.339386 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.158871 (* 1 = 0.158871 loss)
I0830 15:03:28.339397 916722 sgd_solver.cpp:106] Iteration 1772500, lr = 0.01
I0830 15:03:58.102398 916722 solver.cpp:218] Iteration 1773000 (16.7995 iter/s, 29.7627s/500 iters), loss = 0.06868
I0830 15:03:58.102452 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0686857 (* 1 = 0.0686857 loss)
I0830 15:03:58.102460 916722 sgd_solver.cpp:106] Iteration 1773000, lr = 0.01
I0830 15:04:27.866115 916722 solver.cpp:218] Iteration 1773500 (16.7992 iter/s, 29.7634s/500 iters), loss = 0.0975203
I0830 15:04:27.866168 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.097526 (* 1 = 0.097526 loss)
I0830 15:04:27.866178 916722 sgd_solver.cpp:106] Iteration 1773500, lr = 0.01
I0830 15:04:57.628455 916722 solver.cpp:218] Iteration 1774000 (16.7999 iter/s, 29.762s/500 iters), loss = 0.0410373
I0830 15:04:57.628517 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0410431 (* 1 = 0.0410431 loss)
I0830 15:04:57.628525 916722 sgd_solver.cpp:106] Iteration 1774000, lr = 0.01
I0830 15:05:27.384042 916722 solver.cpp:218] Iteration 1774500 (16.8038 iter/s, 29.7552s/500 iters), loss = 0.279198
I0830 15:05:27.384095 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.279204 (* 1 = 0.279204 loss)
I0830 15:05:27.384104 916722 sgd_solver.cpp:106] Iteration 1774500, lr = 0.01
I0830 15:05:57.144783 916722 solver.cpp:218] Iteration 1775000 (16.8008 iter/s, 29.7604s/500 iters), loss = 0.0777592
I0830 15:05:57.144845 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0777651 (* 1 = 0.0777651 loss)
I0830 15:05:57.144852 916722 sgd_solver.cpp:106] Iteration 1775000, lr = 0.01
I0830 15:06:26.910064 916722 solver.cpp:218] Iteration 1775500 (16.7983 iter/s, 29.765s/500 iters), loss = 0.0600334
I0830 15:06:26.910120 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0600393 (* 1 = 0.0600393 loss)
I0830 15:06:26.910130 916722 sgd_solver.cpp:106] Iteration 1775500, lr = 0.01
I0830 15:06:56.675588 916722 solver.cpp:218] Iteration 1776000 (16.7981 iter/s, 29.7652s/500 iters), loss = 0.0259948
I0830 15:06:56.675663 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0260006 (* 1 = 0.0260006 loss)
I0830 15:06:56.675671 916722 sgd_solver.cpp:106] Iteration 1776000, lr = 0.01
I0830 15:07:26.440965 916722 solver.cpp:218] Iteration 1776500 (16.7982 iter/s, 29.7651s/500 iters), loss = 0.134594
I0830 15:07:26.441020 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.1346 (* 1 = 0.1346 loss)
I0830 15:07:26.441030 916722 sgd_solver.cpp:106] Iteration 1776500, lr = 0.01
I0830 15:07:56.202896 916722 solver.cpp:218] Iteration 1777000 (16.8001 iter/s, 29.7616s/500 iters), loss = 0.0594558
I0830 15:07:56.202951 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0594618 (* 1 = 0.0594618 loss)
I0830 15:07:56.202960 916722 sgd_solver.cpp:106] Iteration 1777000, lr = 0.01
I0830 15:08:25.962657 916722 solver.cpp:218] Iteration 1777500 (16.8014 iter/s, 29.7595s/500 iters), loss = 0.0650643
I0830 15:08:25.962707 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0650702 (* 1 = 0.0650702 loss)
I0830 15:08:25.962718 916722 sgd_solver.cpp:106] Iteration 1777500, lr = 0.01
I0830 15:08:55.722332 916722 solver.cpp:218] Iteration 1778000 (16.8014 iter/s, 29.7594s/500 iters), loss = 0.0532986
I0830 15:08:55.722393 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0533045 (* 1 = 0.0533045 loss)
I0830 15:08:55.722401 916722 sgd_solver.cpp:106] Iteration 1778000, lr = 0.01
I0830 15:09:25.481253 916722 solver.cpp:218] Iteration 1778500 (16.8018 iter/s, 29.7586s/500 iters), loss = 0.249161
I0830 15:09:25.481302 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.249167 (* 1 = 0.249167 loss)
I0830 15:09:25.481310 916722 sgd_solver.cpp:106] Iteration 1778500, lr = 0.01
I0830 15:09:55.243265 916722 solver.cpp:218] Iteration 1779000 (16.8001 iter/s, 29.7618s/500 iters), loss = 0.0312886
I0830 15:09:55.243325 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0312943 (* 1 = 0.0312943 loss)
I0830 15:09:55.243333 916722 sgd_solver.cpp:106] Iteration 1779000, lr = 0.01
I0830 15:10:25.009871 916722 solver.cpp:218] Iteration 1779500 (16.7975 iter/s, 29.7663s/500 iters), loss = 0.0995978
I0830 15:10:25.009925 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0996035 (* 1 = 0.0996035 loss)
I0830 15:10:25.009935 916722 sgd_solver.cpp:106] Iteration 1779500, lr = 0.01
I0830 15:10:54.777309 916722 solver.cpp:218] Iteration 1780000 (16.797 iter/s, 29.7672s/500 iters), loss = 0.221576
I0830 15:10:54.777369 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.221582 (* 1 = 0.221582 loss)
I0830 15:10:54.777377 916722 sgd_solver.cpp:106] Iteration 1780000, lr = 0.01
I0830 15:11:24.539717 916722 solver.cpp:218] Iteration 1780500 (16.7999 iter/s, 29.7622s/500 iters), loss = 0.0938967
I0830 15:11:24.539770 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0939024 (* 1 = 0.0939024 loss)
I0830 15:11:24.539780 916722 sgd_solver.cpp:106] Iteration 1780500, lr = 0.01
I0830 15:11:54.307315 916722 solver.cpp:218] Iteration 1781000 (16.7969 iter/s, 29.7674s/500 iters), loss = 0.275452
I0830 15:11:54.307374 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.275457 (* 1 = 0.275457 loss)
I0830 15:11:54.307384 916722 sgd_solver.cpp:106] Iteration 1781000, lr = 0.01
I0830 15:12:24.072901 916722 solver.cpp:218] Iteration 1781500 (16.7981 iter/s, 29.7653s/500 iters), loss = 0.11062
I0830 15:12:24.072953 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110625 (* 1 = 0.110625 loss)
I0830 15:12:24.072962 916722 sgd_solver.cpp:106] Iteration 1781500, lr = 0.01
I0830 15:12:53.841239 916722 solver.cpp:218] Iteration 1782000 (16.7965 iter/s, 29.7681s/500 iters), loss = 0.194552
I0830 15:12:53.841295 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.194558 (* 1 = 0.194558 loss)
I0830 15:12:53.841303 916722 sgd_solver.cpp:106] Iteration 1782000, lr = 0.01
I0830 15:13:23.606657 916722 solver.cpp:218] Iteration 1782500 (16.7981 iter/s, 29.7652s/500 iters), loss = 0.0928231
I0830 15:13:23.606709 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0928287 (* 1 = 0.0928287 loss)
I0830 15:13:23.606730 916722 sgd_solver.cpp:106] Iteration 1782500, lr = 0.01
I0830 15:13:53.372221 916722 solver.cpp:218] Iteration 1783000 (16.7981 iter/s, 29.7653s/500 iters), loss = 0.2775
I0830 15:13:53.372292 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.277505 (* 1 = 0.277505 loss)
I0830 15:13:53.372299 916722 sgd_solver.cpp:106] Iteration 1783000, lr = 0.01
I0830 15:14:23.135859 916722 solver.cpp:218] Iteration 1783500 (16.7992 iter/s, 29.7634s/500 iters), loss = 0.214993
I0830 15:14:23.135910 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.214999 (* 1 = 0.214999 loss)
I0830 15:14:23.135919 916722 sgd_solver.cpp:106] Iteration 1783500, lr = 0.01
I0830 15:14:52.902398 916722 solver.cpp:218] Iteration 1784000 (16.7975 iter/s, 29.7663s/500 iters), loss = 0.213127
I0830 15:14:52.902459 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.213133 (* 1 = 0.213133 loss)
I0830 15:14:52.902467 916722 sgd_solver.cpp:106] Iteration 1784000, lr = 0.01
I0830 15:15:22.674243 916722 solver.cpp:218] Iteration 1784500 (16.7945 iter/s, 29.7716s/500 iters), loss = 0.116027
I0830 15:15:22.674295 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.116033 (* 1 = 0.116033 loss)
I0830 15:15:22.674304 916722 sgd_solver.cpp:106] Iteration 1784500, lr = 0.01
I0830 15:15:52.446220 916722 solver.cpp:218] Iteration 1785000 (16.7944 iter/s, 29.7718s/500 iters), loss = 0.216437
I0830 15:15:52.446280 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.216443 (* 1 = 0.216443 loss)
I0830 15:15:52.446288 916722 sgd_solver.cpp:106] Iteration 1785000, lr = 0.01
I0830 15:16:22.216212 916722 solver.cpp:218] Iteration 1785500 (16.7956 iter/s, 29.7698s/500 iters), loss = 0.232856
I0830 15:16:22.216261 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.232862 (* 1 = 0.232862 loss)
I0830 15:16:22.216269 916722 sgd_solver.cpp:106] Iteration 1785500, lr = 0.01
I0830 15:16:51.989571 916722 solver.cpp:218] Iteration 1786000 (16.7936 iter/s, 29.7732s/500 iters), loss = 0.16426
I0830 15:16:51.989629 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.164265 (* 1 = 0.164265 loss)
I0830 15:16:51.989636 916722 sgd_solver.cpp:106] Iteration 1786000, lr = 0.01
I0830 15:17:21.757848 916722 solver.cpp:218] Iteration 1786500 (16.7965 iter/s, 29.7681s/500 iters), loss = 0.0739731
I0830 15:17:21.757897 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0739787 (* 1 = 0.0739787 loss)
I0830 15:17:21.757905 916722 sgd_solver.cpp:106] Iteration 1786500, lr = 0.01
I0830 15:17:51.530741 916722 solver.cpp:218] Iteration 1787000 (16.7939 iter/s, 29.7727s/500 iters), loss = 0.0785066
I0830 15:17:51.530802 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0785123 (* 1 = 0.0785123 loss)
I0830 15:17:51.530812 916722 sgd_solver.cpp:106] Iteration 1787000, lr = 0.01
I0830 15:18:21.303745 916722 solver.cpp:218] Iteration 1787500 (16.7939 iter/s, 29.7728s/500 iters), loss = 0.163018
I0830 15:18:21.303798 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.163024 (* 1 = 0.163024 loss)
I0830 15:18:21.303807 916722 sgd_solver.cpp:106] Iteration 1787500, lr = 0.01
I0830 15:18:51.072715 916722 solver.cpp:218] Iteration 1788000 (16.7961 iter/s, 29.7688s/500 iters), loss = 0.122624
I0830 15:18:51.072793 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.122629 (* 1 = 0.122629 loss)
I0830 15:18:51.072800 916722 sgd_solver.cpp:106] Iteration 1788000, lr = 0.01
I0830 15:19:20.842864 916722 solver.cpp:218] Iteration 1788500 (16.7955 iter/s, 29.7699s/500 iters), loss = 0.0767638
I0830 15:19:20.842919 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0767693 (* 1 = 0.0767693 loss)
I0830 15:19:20.842927 916722 sgd_solver.cpp:106] Iteration 1788500, lr = 0.01
I0830 15:19:50.609362 916722 solver.cpp:218] Iteration 1789000 (16.7975 iter/s, 29.7663s/500 iters), loss = 0.174841
I0830 15:19:50.609433 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.174846 (* 1 = 0.174846 loss)
I0830 15:19:50.609445 916722 sgd_solver.cpp:106] Iteration 1789000, lr = 0.01
I0830 15:20:20.374969 916722 solver.cpp:218] Iteration 1789500 (16.798 iter/s, 29.7654s/500 iters), loss = 0.0484268
I0830 15:20:20.375021 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0484324 (* 1 = 0.0484324 loss)
I0830 15:20:20.375030 916722 sgd_solver.cpp:106] Iteration 1789500, lr = 0.01
I0830 15:20:50.142962 916722 solver.cpp:218] Iteration 1790000 (16.7967 iter/s, 29.7678s/500 iters), loss = 0.0885413
I0830 15:20:50.143021 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0885468 (* 1 = 0.0885468 loss)
I0830 15:20:50.143029 916722 sgd_solver.cpp:106] Iteration 1790000, lr = 0.01
I0830 15:21:19.911111 916722 solver.cpp:218] Iteration 1790500 (16.7966 iter/s, 29.768s/500 iters), loss = 0.047747
I0830 15:21:19.911162 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0477524 (* 1 = 0.0477524 loss)
I0830 15:21:19.911172 916722 sgd_solver.cpp:106] Iteration 1790500, lr = 0.01
I0830 15:21:49.678424 916722 solver.cpp:218] Iteration 1791000 (16.7971 iter/s, 29.7671s/500 iters), loss = 0.209494
I0830 15:21:49.678478 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.209499 (* 1 = 0.209499 loss)
I0830 15:21:49.678485 916722 sgd_solver.cpp:106] Iteration 1791000, lr = 0.01
I0830 15:22:19.444756 916722 solver.cpp:218] Iteration 1791500 (16.7976 iter/s, 29.7661s/500 iters), loss = 0.121507
I0830 15:22:19.444809 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.121512 (* 1 = 0.121512 loss)
I0830 15:22:19.444819 916722 sgd_solver.cpp:106] Iteration 1791500, lr = 0.01
I0830 15:22:49.207360 916722 solver.cpp:218] Iteration 1792000 (16.7997 iter/s, 29.7624s/500 iters), loss = 0.0838056
I0830 15:22:49.207420 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0838111 (* 1 = 0.0838111 loss)
I0830 15:22:49.207428 916722 sgd_solver.cpp:106] Iteration 1792000, lr = 0.01
I0830 15:23:18.976555 916722 solver.cpp:218] Iteration 1792500 (16.796 iter/s, 29.769s/500 iters), loss = 0.0510295
I0830 15:23:18.976610 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0510349 (* 1 = 0.0510349 loss)
I0830 15:23:18.976620 916722 sgd_solver.cpp:106] Iteration 1792500, lr = 0.01
I0830 15:23:48.740949 916722 solver.cpp:218] Iteration 1793000 (16.7987 iter/s, 29.7642s/500 iters), loss = 0.0751739
I0830 15:23:48.741006 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0751795 (* 1 = 0.0751795 loss)
I0830 15:23:48.741015 916722 sgd_solver.cpp:106] Iteration 1793000, lr = 0.01
I0830 15:24:18.509354 916722 solver.cpp:218] Iteration 1793500 (16.7964 iter/s, 29.7682s/500 iters), loss = 0.0459691
I0830 15:24:18.509407 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0459745 (* 1 = 0.0459745 loss)
I0830 15:24:18.509416 916722 sgd_solver.cpp:106] Iteration 1793500, lr = 0.01
I0830 15:24:48.280647 916722 solver.cpp:218] Iteration 1794000 (16.7948 iter/s, 29.7711s/500 iters), loss = 0.0385377
I0830 15:24:48.280706 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0385432 (* 1 = 0.0385432 loss)
I0830 15:24:48.280714 916722 sgd_solver.cpp:106] Iteration 1794000, lr = 0.01
I0830 15:25:18.045214 916722 solver.cpp:218] Iteration 1794500 (16.7986 iter/s, 29.7644s/500 iters), loss = 0.472449
I0830 15:25:18.045264 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.472455 (* 1 = 0.472455 loss)
I0830 15:25:18.045274 916722 sgd_solver.cpp:106] Iteration 1794500, lr = 0.01
I0830 15:25:47.812345 916722 solver.cpp:218] Iteration 1795000 (16.7972 iter/s, 29.767s/500 iters), loss = 0.164383
I0830 15:25:47.812402 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.164388 (* 1 = 0.164388 loss)
I0830 15:25:47.812410 916722 sgd_solver.cpp:106] Iteration 1795000, lr = 0.01
I0830 15:26:17.576969 916722 solver.cpp:218] Iteration 1795500 (16.7986 iter/s, 29.7644s/500 iters), loss = 0.199751
I0830 15:26:17.577014 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.199756 (* 1 = 0.199756 loss)
I0830 15:26:17.577033 916722 sgd_solver.cpp:106] Iteration 1795500, lr = 0.01
I0830 15:26:47.343691 916722 solver.cpp:218] Iteration 1796000 (16.7974 iter/s, 29.7666s/500 iters), loss = 0.0535458
I0830 15:26:47.343762 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0535512 (* 1 = 0.0535512 loss)
I0830 15:26:47.343771 916722 sgd_solver.cpp:106] Iteration 1796000, lr = 0.01
I0830 15:27:17.108108 916722 solver.cpp:218] Iteration 1796500 (16.7987 iter/s, 29.7642s/500 iters), loss = 0.108116
I0830 15:27:17.108161 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.108121 (* 1 = 0.108121 loss)
I0830 15:27:17.108170 916722 sgd_solver.cpp:106] Iteration 1796500, lr = 0.01
I0830 15:27:46.871594 916722 solver.cpp:218] Iteration 1797000 (16.7992 iter/s, 29.7633s/500 iters), loss = 0.257331
I0830 15:27:46.871651 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.257336 (* 1 = 0.257336 loss)
I0830 15:27:46.871659 916722 sgd_solver.cpp:106] Iteration 1797000, lr = 0.01
I0830 15:28:16.633721 916722 solver.cpp:218] Iteration 1797500 (16.8 iter/s, 29.7619s/500 iters), loss = 0.157315
I0830 15:28:16.633774 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.15732 (* 1 = 0.15732 loss)
I0830 15:28:16.633781 916722 sgd_solver.cpp:106] Iteration 1797500, lr = 0.01
I0830 15:28:46.396525 916722 solver.cpp:218] Iteration 1798000 (16.7996 iter/s, 29.7626s/500 iters), loss = 0.0767498
I0830 15:28:46.396595 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0767552 (* 1 = 0.0767552 loss)
I0830 15:28:46.396605 916722 sgd_solver.cpp:106] Iteration 1798000, lr = 0.01
I0830 15:29:16.160658 916722 solver.cpp:218] Iteration 1798500 (16.7989 iter/s, 29.7639s/500 iters), loss = 0.153559
I0830 15:29:16.160712 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.153564 (* 1 = 0.153564 loss)
I0830 15:29:16.160722 916722 sgd_solver.cpp:106] Iteration 1798500, lr = 0.01
I0830 15:29:45.920002 916722 solver.cpp:218] Iteration 1799000 (16.8015 iter/s, 29.7592s/500 iters), loss = 0.165954
I0830 15:29:45.920061 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.165959 (* 1 = 0.165959 loss)
I0830 15:29:45.920070 916722 sgd_solver.cpp:106] Iteration 1799000, lr = 0.01
I0830 15:30:15.684693 916722 solver.cpp:218] Iteration 1799500 (16.7985 iter/s, 29.7645s/500 iters), loss = 0.0575682
I0830 15:30:15.684756 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0575735 (* 1 = 0.0575735 loss)
I0830 15:30:15.684764 916722 sgd_solver.cpp:106] Iteration 1799500, lr = 0.01
I0830 15:30:45.389051 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_1800000.caffemodel
I0830 15:30:45.408038 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_1800000.solverstate
I0830 15:30:45.414148 916722 solver.cpp:330] Iteration 1800000, Testing net (#0)
I0830 15:31:00.784607 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8718
I0830 15:31:00.784652 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.426829 (* 1 = 0.426829 loss)
I0830 15:31:00.843245 916722 solver.cpp:218] Iteration 1800000 (11.0722 iter/s, 45.1583s/500 iters), loss = 0.248839
I0830 15:31:00.843271 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.248845 (* 1 = 0.248845 loss)
I0830 15:31:00.843279 916722 sgd_solver.cpp:106] Iteration 1800000, lr = 0.01
I0830 15:31:30.569164 916722 solver.cpp:218] Iteration 1800500 (16.8204 iter/s, 29.7257s/500 iters), loss = 0.00962372
I0830 15:31:30.569226 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.00962885 (* 1 = 0.00962885 loss)
I0830 15:31:30.569234 916722 sgd_solver.cpp:106] Iteration 1800500, lr = 0.01
I0830 15:32:00.306599 916722 solver.cpp:218] Iteration 1801000 (16.8139 iter/s, 29.7372s/500 iters), loss = 0.189376
I0830 15:32:00.306653 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.189381 (* 1 = 0.189381 loss)
I0830 15:32:00.306661 916722 sgd_solver.cpp:106] Iteration 1801000, lr = 0.01
I0830 15:32:30.053910 916722 solver.cpp:218] Iteration 1801500 (16.8083 iter/s, 29.7471s/500 iters), loss = 0.0877484
I0830 15:32:30.053984 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0877536 (* 1 = 0.0877536 loss)
I0830 15:32:30.053993 916722 sgd_solver.cpp:106] Iteration 1801500, lr = 0.01
I0830 15:32:59.803742 916722 solver.cpp:218] Iteration 1802000 (16.8068 iter/s, 29.7499s/500 iters), loss = 0.0510205
I0830 15:32:59.803797 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0510259 (* 1 = 0.0510259 loss)
I0830 15:32:59.803805 916722 sgd_solver.cpp:106] Iteration 1802000, lr = 0.01
I0830 15:33:29.556246 916722 solver.cpp:218] Iteration 1802500 (16.8051 iter/s, 29.7529s/500 iters), loss = 0.190851
I0830 15:33:29.556305 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.190857 (* 1 = 0.190857 loss)
I0830 15:33:29.556313 916722 sgd_solver.cpp:106] Iteration 1802500, lr = 0.01
I0830 15:33:59.317732 916722 solver.cpp:218] Iteration 1803000 (16.8 iter/s, 29.7618s/500 iters), loss = 0.211573
I0830 15:33:59.317787 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.211578 (* 1 = 0.211578 loss)
I0830 15:33:59.317796 916722 sgd_solver.cpp:106] Iteration 1803000, lr = 0.01
I0830 15:34:29.082844 916722 solver.cpp:218] Iteration 1803500 (16.798 iter/s, 29.7654s/500 iters), loss = 0.0760467
I0830 15:34:29.082902 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0760521 (* 1 = 0.0760521 loss)
I0830 15:34:29.082911 916722 sgd_solver.cpp:106] Iteration 1803500, lr = 0.01
I0830 15:34:58.844506 916722 solver.cpp:218] Iteration 1804000 (16.8 iter/s, 29.762s/500 iters), loss = 0.0714536
I0830 15:34:58.844554 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.071459 (* 1 = 0.071459 loss)
I0830 15:34:58.844564 916722 sgd_solver.cpp:106] Iteration 1804000, lr = 0.01
I0830 15:35:28.626205 916722 solver.cpp:218] Iteration 1804500 (16.7887 iter/s, 29.782s/500 iters), loss = 0.118546
I0830 15:35:28.626271 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.118551 (* 1 = 0.118551 loss)
I0830 15:35:28.626281 916722 sgd_solver.cpp:106] Iteration 1804500, lr = 0.01
I0830 15:35:58.419703 916722 solver.cpp:218] Iteration 1805000 (16.782 iter/s, 29.7937s/500 iters), loss = 0.0517692
I0830 15:35:58.419759 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0517746 (* 1 = 0.0517746 loss)
I0830 15:35:58.419768 916722 sgd_solver.cpp:106] Iteration 1805000, lr = 0.01
I0830 15:36:28.212610 916722 solver.cpp:218] Iteration 1805500 (16.7824 iter/s, 29.7931s/500 iters), loss = 0.184209
I0830 15:36:28.212675 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.184215 (* 1 = 0.184215 loss)
I0830 15:36:28.212684 916722 sgd_solver.cpp:106] Iteration 1805500, lr = 0.01
I0830 15:36:58.002566 916722 solver.cpp:218] Iteration 1806000 (16.7841 iter/s, 29.7902s/500 iters), loss = 0.106246
I0830 15:36:58.002620 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.106252 (* 1 = 0.106252 loss)
I0830 15:36:58.002630 916722 sgd_solver.cpp:106] Iteration 1806000, lr = 0.01
I0830 15:37:27.795401 916722 solver.cpp:218] Iteration 1806500 (16.7824 iter/s, 29.793s/500 iters), loss = 0.231974
I0830 15:37:27.795462 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.231979 (* 1 = 0.231979 loss)
I0830 15:37:27.795470 916722 sgd_solver.cpp:106] Iteration 1806500, lr = 0.01
I0830 15:37:57.586277 916722 solver.cpp:218] Iteration 1807000 (16.7836 iter/s, 29.791s/500 iters), loss = 0.154708
I0830 15:37:57.586331 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.154714 (* 1 = 0.154714 loss)
I0830 15:37:57.586341 916722 sgd_solver.cpp:106] Iteration 1807000, lr = 0.01
I0830 15:38:27.376240 916722 solver.cpp:218] Iteration 1807500 (16.7841 iter/s, 29.7901s/500 iters), loss = 0.0407924
I0830 15:38:27.376299 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0407979 (* 1 = 0.0407979 loss)
I0830 15:38:27.376307 916722 sgd_solver.cpp:106] Iteration 1807500, lr = 0.01
I0830 15:38:57.162559 916722 solver.cpp:218] Iteration 1808000 (16.7861 iter/s, 29.7865s/500 iters), loss = 0.075746
I0830 15:38:57.162624 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0757515 (* 1 = 0.0757515 loss)
I0830 15:38:57.162636 916722 sgd_solver.cpp:106] Iteration 1808000, lr = 0.01
I0830 15:39:26.953433 916722 solver.cpp:218] Iteration 1808500 (16.7836 iter/s, 29.791s/500 iters), loss = 0.0305432
I0830 15:39:26.953505 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0305486 (* 1 = 0.0305486 loss)
I0830 15:39:26.953513 916722 sgd_solver.cpp:106] Iteration 1808500, lr = 0.01
I0830 15:39:56.744881 916722 solver.cpp:218] Iteration 1809000 (16.7833 iter/s, 29.7916s/500 iters), loss = 0.0393386
I0830 15:39:56.744936 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0393439 (* 1 = 0.0393439 loss)
I0830 15:39:56.744946 916722 sgd_solver.cpp:106] Iteration 1809000, lr = 0.01
I0830 15:40:26.532586 916722 solver.cpp:218] Iteration 1809500 (16.7854 iter/s, 29.7878s/500 iters), loss = 0.171713
I0830 15:40:26.532649 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.171718 (* 1 = 0.171718 loss)
I0830 15:40:26.532657 916722 sgd_solver.cpp:106] Iteration 1809500, lr = 0.01
I0830 15:40:56.319065 916722 solver.cpp:218] Iteration 1810000 (16.7861 iter/s, 29.7866s/500 iters), loss = 0.0942442
I0830 15:40:56.319120 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0942494 (* 1 = 0.0942494 loss)
I0830 15:40:56.319128 916722 sgd_solver.cpp:106] Iteration 1810000, lr = 0.01
I0830 15:41:26.108150 916722 solver.cpp:218] Iteration 1810500 (16.7846 iter/s, 29.7892s/500 iters), loss = 0.0975098
I0830 15:41:26.108211 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0975149 (* 1 = 0.0975149 loss)
I0830 15:41:26.108218 916722 sgd_solver.cpp:106] Iteration 1810500, lr = 0.01
I0830 15:41:55.897073 916722 solver.cpp:218] Iteration 1811000 (16.7847 iter/s, 29.789s/500 iters), loss = 0.220428
I0830 15:41:55.897125 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.220433 (* 1 = 0.220433 loss)
I0830 15:41:55.897135 916722 sgd_solver.cpp:106] Iteration 1811000, lr = 0.01
I0830 15:42:25.681073 916722 solver.cpp:218] Iteration 1811500 (16.7875 iter/s, 29.7841s/500 iters), loss = 0.130281
I0830 15:42:25.681133 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130286 (* 1 = 0.130286 loss)
I0830 15:42:25.681141 916722 sgd_solver.cpp:106] Iteration 1811500, lr = 0.01
I0830 15:42:55.473601 916722 solver.cpp:218] Iteration 1812000 (16.7827 iter/s, 29.7926s/500 iters), loss = 0.155631
I0830 15:42:55.473652 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.155636 (* 1 = 0.155636 loss)
I0830 15:42:55.473660 916722 sgd_solver.cpp:106] Iteration 1812000, lr = 0.01
I0830 15:43:25.266062 916722 solver.cpp:218] Iteration 1812500 (16.7827 iter/s, 29.7925s/500 iters), loss = 0.132566
I0830 15:43:25.266122 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.132571 (* 1 = 0.132571 loss)
I0830 15:43:25.266131 916722 sgd_solver.cpp:106] Iteration 1812500, lr = 0.01
I0830 15:43:55.060590 916722 solver.cpp:218] Iteration 1813000 (16.7816 iter/s, 29.7946s/500 iters), loss = 0.0709461
I0830 15:43:55.060642 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.070951 (* 1 = 0.070951 loss)
I0830 15:43:55.060652 916722 sgd_solver.cpp:106] Iteration 1813000, lr = 0.01
I0830 15:44:24.853212 916722 solver.cpp:218] Iteration 1813500 (16.7827 iter/s, 29.7927s/500 iters), loss = 0.0346381
I0830 15:44:24.853274 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.034643 (* 1 = 0.034643 loss)
I0830 15:44:24.853283 916722 sgd_solver.cpp:106] Iteration 1813500, lr = 0.01
I0830 15:44:54.642627 916722 solver.cpp:218] Iteration 1814000 (16.7845 iter/s, 29.7894s/500 iters), loss = 0.0829251
I0830 15:44:54.642683 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0829301 (* 1 = 0.0829301 loss)
I0830 15:44:54.642693 916722 sgd_solver.cpp:106] Iteration 1814000, lr = 0.01
I0830 15:45:24.431911 916722 solver.cpp:218] Iteration 1814500 (16.7845 iter/s, 29.7893s/500 iters), loss = 0.183029
I0830 15:45:24.431986 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.183034 (* 1 = 0.183034 loss)
I0830 15:45:24.431994 916722 sgd_solver.cpp:106] Iteration 1814500, lr = 0.01
I0830 15:45:54.223695 916722 solver.cpp:218] Iteration 1815000 (16.7831 iter/s, 29.7918s/500 iters), loss = 0.182611
I0830 15:45:54.223748 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.182616 (* 1 = 0.182616 loss)
I0830 15:45:54.223759 916722 sgd_solver.cpp:106] Iteration 1815000, lr = 0.01
I0830 15:46:24.016134 916722 solver.cpp:218] Iteration 1815500 (16.7828 iter/s, 29.7925s/500 iters), loss = 0.145277
I0830 15:46:24.016194 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.145282 (* 1 = 0.145282 loss)
I0830 15:46:24.016202 916722 sgd_solver.cpp:106] Iteration 1815500, lr = 0.01
I0830 15:46:53.803969 916722 solver.cpp:218] Iteration 1816000 (16.7854 iter/s, 29.7878s/500 iters), loss = 0.0281084
I0830 15:46:53.804023 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0281135 (* 1 = 0.0281135 loss)
I0830 15:46:53.804033 916722 sgd_solver.cpp:106] Iteration 1816000, lr = 0.01
I0830 15:47:23.606884 916722 solver.cpp:218] Iteration 1816500 (16.7769 iter/s, 29.8029s/500 iters), loss = 0.0717612
I0830 15:47:23.606942 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0717662 (* 1 = 0.0717662 loss)
I0830 15:47:23.606950 916722 sgd_solver.cpp:106] Iteration 1816500, lr = 0.01
I0830 15:47:53.398890 916722 solver.cpp:218] Iteration 1817000 (16.783 iter/s, 29.792s/500 iters), loss = 0.270114
I0830 15:47:53.398941 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.270119 (* 1 = 0.270119 loss)
I0830 15:47:53.398950 916722 sgd_solver.cpp:106] Iteration 1817000, lr = 0.01
I0830 15:48:23.196943 916722 solver.cpp:218] Iteration 1817500 (16.7796 iter/s, 29.798s/500 iters), loss = 0.185776
I0830 15:48:23.197000 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.185781 (* 1 = 0.185781 loss)
I0830 15:48:23.197007 916722 sgd_solver.cpp:106] Iteration 1817500, lr = 0.01
I0830 15:48:52.978533 916722 solver.cpp:218] Iteration 1818000 (16.7889 iter/s, 29.7816s/500 iters), loss = 0.0616424
I0830 15:48:52.978588 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0616473 (* 1 = 0.0616473 loss)
I0830 15:48:52.978598 916722 sgd_solver.cpp:106] Iteration 1818000, lr = 0.01
I0830 15:49:22.758059 916722 solver.cpp:218] Iteration 1818500 (16.7901 iter/s, 29.7795s/500 iters), loss = 0.235086
I0830 15:49:22.758119 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.235091 (* 1 = 0.235091 loss)
I0830 15:49:22.758127 916722 sgd_solver.cpp:106] Iteration 1818500, lr = 0.01
I0830 15:49:52.538637 916722 solver.cpp:218] Iteration 1819000 (16.7895 iter/s, 29.7806s/500 iters), loss = 0.0746359
I0830 15:49:52.538692 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0746406 (* 1 = 0.0746406 loss)
I0830 15:49:52.538703 916722 sgd_solver.cpp:106] Iteration 1819000, lr = 0.01
I0830 15:50:22.322193 916722 solver.cpp:218] Iteration 1819500 (16.7878 iter/s, 29.7835s/500 iters), loss = 0.1995
I0830 15:50:22.322249 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.199505 (* 1 = 0.199505 loss)
I0830 15:50:22.322257 916722 sgd_solver.cpp:106] Iteration 1819500, lr = 0.01
I0830 15:50:52.105509 916722 solver.cpp:218] Iteration 1820000 (16.7879 iter/s, 29.7833s/500 iters), loss = 0.118264
I0830 15:50:52.105562 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.118268 (* 1 = 0.118268 loss)
I0830 15:50:52.105572 916722 sgd_solver.cpp:106] Iteration 1820000, lr = 0.01
I0830 15:51:21.888046 916722 solver.cpp:218] Iteration 1820500 (16.7884 iter/s, 29.7825s/500 iters), loss = 0.0669646
I0830 15:51:21.888104 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0669692 (* 1 = 0.0669692 loss)
I0830 15:51:21.888113 916722 sgd_solver.cpp:106] Iteration 1820500, lr = 0.01
I0830 15:51:51.668604 916722 solver.cpp:218] Iteration 1821000 (16.7895 iter/s, 29.7805s/500 iters), loss = 0.114837
I0830 15:51:51.668658 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.114841 (* 1 = 0.114841 loss)
I0830 15:51:51.668681 916722 sgd_solver.cpp:106] Iteration 1821000, lr = 0.01
I0830 15:52:21.448341 916722 solver.cpp:218] Iteration 1821500 (16.79 iter/s, 29.7797s/500 iters), loss = 0.0538071
I0830 15:52:21.448410 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0538116 (* 1 = 0.0538116 loss)
I0830 15:52:21.448419 916722 sgd_solver.cpp:106] Iteration 1821500, lr = 0.01
I0830 15:52:51.232534 916722 solver.cpp:218] Iteration 1822000 (16.7875 iter/s, 29.7841s/500 iters), loss = 0.213042
I0830 15:52:51.232584 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.213047 (* 1 = 0.213047 loss)
I0830 15:52:51.232594 916722 sgd_solver.cpp:106] Iteration 1822000, lr = 0.01
I0830 15:53:21.013279 916722 solver.cpp:218] Iteration 1822500 (16.7894 iter/s, 29.7807s/500 iters), loss = 0.146316
I0830 15:53:21.013343 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.146321 (* 1 = 0.146321 loss)
I0830 15:53:21.013351 916722 sgd_solver.cpp:106] Iteration 1822500, lr = 0.01
I0830 15:53:50.796972 916722 solver.cpp:218] Iteration 1823000 (16.7877 iter/s, 29.7836s/500 iters), loss = 0.150119
I0830 15:53:50.797026 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.150123 (* 1 = 0.150123 loss)
I0830 15:53:50.797035 916722 sgd_solver.cpp:106] Iteration 1823000, lr = 0.01
I0830 15:54:20.585994 916722 solver.cpp:218] Iteration 1823500 (16.7847 iter/s, 29.789s/500 iters), loss = 0.0466893
I0830 15:54:20.586055 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0466938 (* 1 = 0.0466938 loss)
I0830 15:54:20.586063 916722 sgd_solver.cpp:106] Iteration 1823500, lr = 0.01
I0830 15:54:50.367938 916722 solver.cpp:218] Iteration 1824000 (16.7887 iter/s, 29.7819s/500 iters), loss = 0.179292
I0830 15:54:50.367990 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.179296 (* 1 = 0.179296 loss)
I0830 15:54:50.367998 916722 sgd_solver.cpp:106] Iteration 1824000, lr = 0.01
I0830 15:55:20.152248 916722 solver.cpp:218] Iteration 1824500 (16.7874 iter/s, 29.7843s/500 iters), loss = 0.0549784
I0830 15:55:20.152309 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.054983 (* 1 = 0.054983 loss)
I0830 15:55:20.152318 916722 sgd_solver.cpp:106] Iteration 1824500, lr = 0.01
I0830 15:55:49.931195 916722 solver.cpp:218] Iteration 1825000 (16.7904 iter/s, 29.7789s/500 iters), loss = 0.370403
I0830 15:55:49.931248 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.370408 (* 1 = 0.370408 loss)
I0830 15:55:49.931257 916722 sgd_solver.cpp:106] Iteration 1825000, lr = 0.01
I0830 15:56:19.708945 916722 solver.cpp:218] Iteration 1825500 (16.7911 iter/s, 29.7777s/500 iters), loss = 0.250961
I0830 15:56:19.709004 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.250966 (* 1 = 0.250966 loss)
I0830 15:56:19.709013 916722 sgd_solver.cpp:106] Iteration 1825500, lr = 0.01
I0830 15:56:49.488615 916722 solver.cpp:218] Iteration 1826000 (16.79 iter/s, 29.7796s/500 iters), loss = 0.267633
I0830 15:56:49.488667 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.267638 (* 1 = 0.267638 loss)
I0830 15:56:49.488674 916722 sgd_solver.cpp:106] Iteration 1826000, lr = 0.01
I0830 15:57:19.265930 916722 solver.cpp:218] Iteration 1826500 (16.7913 iter/s, 29.7773s/500 iters), loss = 0.0960034
I0830 15:57:19.265991 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.096008 (* 1 = 0.096008 loss)
I0830 15:57:19.266000 916722 sgd_solver.cpp:106] Iteration 1826500, lr = 0.01
I0830 15:57:49.049108 916722 solver.cpp:218] Iteration 1827000 (16.788 iter/s, 29.7831s/500 iters), loss = 0.1601
I0830 15:57:49.049160 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.160105 (* 1 = 0.160105 loss)
I0830 15:57:49.049170 916722 sgd_solver.cpp:106] Iteration 1827000, lr = 0.01
I0830 15:58:18.827291 916722 solver.cpp:218] Iteration 1827500 (16.7908 iter/s, 29.7781s/500 iters), loss = 0.270737
I0830 15:58:18.827363 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.270742 (* 1 = 0.270742 loss)
I0830 15:58:18.827375 916722 sgd_solver.cpp:106] Iteration 1827500, lr = 0.01
I0830 15:58:48.608155 916722 solver.cpp:218] Iteration 1828000 (16.7894 iter/s, 29.7808s/500 iters), loss = 0.0700603
I0830 15:58:48.608208 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0700647 (* 1 = 0.0700647 loss)
I0830 15:58:48.608217 916722 sgd_solver.cpp:106] Iteration 1828000, lr = 0.01
I0830 15:59:18.391396 916722 solver.cpp:218] Iteration 1828500 (16.788 iter/s, 29.7832s/500 iters), loss = 0.0378719
I0830 15:59:18.391458 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0378763 (* 1 = 0.0378763 loss)
I0830 15:59:18.391466 916722 sgd_solver.cpp:106] Iteration 1828500, lr = 0.01
I0830 15:59:48.170779 916722 solver.cpp:218] Iteration 1829000 (16.7902 iter/s, 29.7793s/500 iters), loss = 0.0850899
I0830 15:59:48.170837 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0850943 (* 1 = 0.0850943 loss)
I0830 15:59:48.170847 916722 sgd_solver.cpp:106] Iteration 1829000, lr = 0.01
I0830 16:00:17.947052 916722 solver.cpp:218] Iteration 1829500 (16.7919 iter/s, 29.7762s/500 iters), loss = 0.398862
I0830 16:00:17.947118 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.398867 (* 1 = 0.398867 loss)
I0830 16:00:17.947127 916722 sgd_solver.cpp:106] Iteration 1829500, lr = 0.01
I0830 16:00:47.729282 916722 solver.cpp:218] Iteration 1830000 (16.7886 iter/s, 29.7822s/500 iters), loss = 0.134726
I0830 16:00:47.729336 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13473 (* 1 = 0.13473 loss)
I0830 16:00:47.729346 916722 sgd_solver.cpp:106] Iteration 1830000, lr = 0.01
I0830 16:01:17.508313 916722 solver.cpp:218] Iteration 1830500 (16.7904 iter/s, 29.779s/500 iters), loss = 0.20385
I0830 16:01:17.508369 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.203854 (* 1 = 0.203854 loss)
I0830 16:01:17.508378 916722 sgd_solver.cpp:106] Iteration 1830500, lr = 0.01
I0830 16:01:47.283105 916722 solver.cpp:218] Iteration 1831000 (16.7928 iter/s, 29.7747s/500 iters), loss = 0.155955
I0830 16:01:47.283159 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.155959 (* 1 = 0.155959 loss)
I0830 16:01:47.283169 916722 sgd_solver.cpp:106] Iteration 1831000, lr = 0.01
I0830 16:02:17.060945 916722 solver.cpp:218] Iteration 1831500 (16.791 iter/s, 29.7778s/500 iters), loss = 0.0866864
I0830 16:02:17.061005 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0866904 (* 1 = 0.0866904 loss)
I0830 16:02:17.061014 916722 sgd_solver.cpp:106] Iteration 1831500, lr = 0.01
I0830 16:02:46.839289 916722 solver.cpp:218] Iteration 1832000 (16.7908 iter/s, 29.7783s/500 iters), loss = 0.160843
I0830 16:02:46.839342 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.160848 (* 1 = 0.160848 loss)
I0830 16:02:46.839352 916722 sgd_solver.cpp:106] Iteration 1832000, lr = 0.01
I0830 16:03:16.616346 916722 solver.cpp:218] Iteration 1832500 (16.7915 iter/s, 29.777s/500 iters), loss = 0.118203
I0830 16:03:16.616407 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.118207 (* 1 = 0.118207 loss)
I0830 16:03:16.616415 916722 sgd_solver.cpp:106] Iteration 1832500, lr = 0.01
I0830 16:03:46.392655 916722 solver.cpp:218] Iteration 1833000 (16.7919 iter/s, 29.7762s/500 iters), loss = 0.111453
I0830 16:03:46.392711 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111458 (* 1 = 0.111458 loss)
I0830 16:03:46.392721 916722 sgd_solver.cpp:106] Iteration 1833000, lr = 0.01
I0830 16:04:16.171447 916722 solver.cpp:218] Iteration 1833500 (16.7905 iter/s, 29.7787s/500 iters), loss = 0.0123655
I0830 16:04:16.171506 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0123697 (* 1 = 0.0123697 loss)
I0830 16:04:16.171515 916722 sgd_solver.cpp:106] Iteration 1833500, lr = 0.01
I0830 16:04:45.947425 916722 solver.cpp:218] Iteration 1834000 (16.7921 iter/s, 29.7759s/500 iters), loss = 0.0292079
I0830 16:04:45.947479 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0292121 (* 1 = 0.0292121 loss)
I0830 16:04:45.947500 916722 sgd_solver.cpp:106] Iteration 1834000, lr = 0.01
I0830 16:05:15.722548 916722 solver.cpp:218] Iteration 1834500 (16.7926 iter/s, 29.775s/500 iters), loss = 0.221859
I0830 16:05:15.722616 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.221863 (* 1 = 0.221863 loss)
I0830 16:05:15.722625 916722 sgd_solver.cpp:106] Iteration 1834500, lr = 0.01
I0830 16:05:45.498509 916722 solver.cpp:218] Iteration 1835000 (16.7921 iter/s, 29.7759s/500 iters), loss = 0.071814
I0830 16:05:45.498559 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0718183 (* 1 = 0.0718183 loss)
I0830 16:05:45.498569 916722 sgd_solver.cpp:106] Iteration 1835000, lr = 0.01
I0830 16:06:15.276809 916722 solver.cpp:218] Iteration 1835500 (16.7908 iter/s, 29.7782s/500 iters), loss = 0.219294
I0830 16:06:15.276870 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.219299 (* 1 = 0.219299 loss)
I0830 16:06:15.276877 916722 sgd_solver.cpp:106] Iteration 1835500, lr = 0.01
I0830 16:06:45.055259 916722 solver.cpp:218] Iteration 1836000 (16.7907 iter/s, 29.7784s/500 iters), loss = 0.428682
I0830 16:06:45.055313 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.428686 (* 1 = 0.428686 loss)
I0830 16:06:45.055323 916722 sgd_solver.cpp:106] Iteration 1836000, lr = 0.01
I0830 16:07:14.832284 916722 solver.cpp:218] Iteration 1836500 (16.7915 iter/s, 29.7769s/500 iters), loss = 0.19511
I0830 16:07:14.832345 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.195114 (* 1 = 0.195114 loss)
I0830 16:07:14.832352 916722 sgd_solver.cpp:106] Iteration 1836500, lr = 0.01
I0830 16:07:44.608124 916722 solver.cpp:218] Iteration 1837000 (16.7922 iter/s, 29.7758s/500 iters), loss = 0.26401
I0830 16:07:44.608178 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.264015 (* 1 = 0.264015 loss)
I0830 16:07:44.608188 916722 sgd_solver.cpp:106] Iteration 1837000, lr = 0.01
I0830 16:08:14.390456 916722 solver.cpp:218] Iteration 1837500 (16.7885 iter/s, 29.7823s/500 iters), loss = 0.111861
I0830 16:08:14.390519 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111865 (* 1 = 0.111865 loss)
I0830 16:08:14.390528 916722 sgd_solver.cpp:106] Iteration 1837500, lr = 0.01
I0830 16:08:44.180884 916722 solver.cpp:218] Iteration 1838000 (16.784 iter/s, 29.7903s/500 iters), loss = 0.0144827
I0830 16:08:44.180938 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0144871 (* 1 = 0.0144871 loss)
I0830 16:08:44.180949 916722 sgd_solver.cpp:106] Iteration 1838000, lr = 0.01
I0830 16:09:13.968495 916722 solver.cpp:218] Iteration 1838500 (16.7855 iter/s, 29.7875s/500 iters), loss = 0.318286
I0830 16:09:13.968572 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.31829 (* 1 = 0.31829 loss)
I0830 16:09:13.968581 916722 sgd_solver.cpp:106] Iteration 1838500, lr = 0.01
I0830 16:09:43.760175 916722 solver.cpp:218] Iteration 1839000 (16.7833 iter/s, 29.7916s/500 iters), loss = 0.14411
I0830 16:09:43.760228 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.144115 (* 1 = 0.144115 loss)
I0830 16:09:43.760237 916722 sgd_solver.cpp:106] Iteration 1839000, lr = 0.01
I0830 16:10:13.552292 916722 solver.cpp:218] Iteration 1839500 (16.783 iter/s, 29.792s/500 iters), loss = 0.195472
I0830 16:10:13.552350 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.195477 (* 1 = 0.195477 loss)
I0830 16:10:13.552357 916722 sgd_solver.cpp:106] Iteration 1839500, lr = 0.01
I0830 16:10:43.344463 916722 solver.cpp:218] Iteration 1840000 (16.783 iter/s, 29.7921s/500 iters), loss = 0.155498
I0830 16:10:43.344519 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.155502 (* 1 = 0.155502 loss)
I0830 16:10:43.344528 916722 sgd_solver.cpp:106] Iteration 1840000, lr = 0.01
I0830 16:11:13.136720 916722 solver.cpp:218] Iteration 1840500 (16.7829 iter/s, 29.7922s/500 iters), loss = 0.0719314
I0830 16:11:13.136802 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0719357 (* 1 = 0.0719357 loss)
I0830 16:11:13.136811 916722 sgd_solver.cpp:106] Iteration 1840500, lr = 0.01
I0830 16:11:42.929512 916722 solver.cpp:218] Iteration 1841000 (16.7826 iter/s, 29.7927s/500 iters), loss = 0.184657
I0830 16:11:42.929566 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.184661 (* 1 = 0.184661 loss)
I0830 16:11:42.929574 916722 sgd_solver.cpp:106] Iteration 1841000, lr = 0.01
I0830 16:12:12.720538 916722 solver.cpp:218] Iteration 1841500 (16.7836 iter/s, 29.7909s/500 iters), loss = 0.132498
I0830 16:12:12.720610 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.132502 (* 1 = 0.132502 loss)
I0830 16:12:12.720619 916722 sgd_solver.cpp:106] Iteration 1841500, lr = 0.01
I0830 16:12:42.513927 916722 solver.cpp:218] Iteration 1842000 (16.7823 iter/s, 29.7933s/500 iters), loss = 0.158141
I0830 16:12:42.513981 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.158146 (* 1 = 0.158146 loss)
I0830 16:12:42.513989 916722 sgd_solver.cpp:106] Iteration 1842000, lr = 0.01
I0830 16:13:12.310350 916722 solver.cpp:218] Iteration 1842500 (16.7806 iter/s, 29.7963s/500 iters), loss = 0.188101
I0830 16:13:12.310410 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.188106 (* 1 = 0.188106 loss)
I0830 16:13:12.310418 916722 sgd_solver.cpp:106] Iteration 1842500, lr = 0.01
I0830 16:13:42.107833 916722 solver.cpp:218] Iteration 1843000 (16.78 iter/s, 29.7974s/500 iters), loss = 0.0798707
I0830 16:13:42.107888 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0798751 (* 1 = 0.0798751 loss)
I0830 16:13:42.107898 916722 sgd_solver.cpp:106] Iteration 1843000, lr = 0.01
I0830 16:14:11.898608 916722 solver.cpp:218] Iteration 1843500 (16.7838 iter/s, 29.7907s/500 iters), loss = 0.0506054
I0830 16:14:11.898666 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0506098 (* 1 = 0.0506098 loss)
I0830 16:14:11.898675 916722 sgd_solver.cpp:106] Iteration 1843500, lr = 0.01
I0830 16:14:41.690990 916722 solver.cpp:218] Iteration 1844000 (16.7829 iter/s, 29.7923s/500 iters), loss = 0.118987
I0830 16:14:41.691040 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.118991 (* 1 = 0.118991 loss)
I0830 16:14:41.691049 916722 sgd_solver.cpp:106] Iteration 1844000, lr = 0.01
I0830 16:15:11.487248 916722 solver.cpp:218] Iteration 1844500 (16.7807 iter/s, 29.7962s/500 iters), loss = 0.0621611
I0830 16:15:11.487309 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0621653 (* 1 = 0.0621653 loss)
I0830 16:15:11.487318 916722 sgd_solver.cpp:106] Iteration 1844500, lr = 0.01
I0830 16:15:41.275080 916722 solver.cpp:218] Iteration 1845000 (16.7854 iter/s, 29.7877s/500 iters), loss = 0.0589458
I0830 16:15:41.275135 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0589501 (* 1 = 0.0589501 loss)
I0830 16:15:41.275144 916722 sgd_solver.cpp:106] Iteration 1845000, lr = 0.01
I0830 16:16:11.066923 916722 solver.cpp:218] Iteration 1845500 (16.7832 iter/s, 29.7918s/500 iters), loss = 0.0696772
I0830 16:16:11.066984 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0696815 (* 1 = 0.0696815 loss)
I0830 16:16:11.066993 916722 sgd_solver.cpp:106] Iteration 1845500, lr = 0.01
I0830 16:16:40.858817 916722 solver.cpp:218] Iteration 1846000 (16.7831 iter/s, 29.7918s/500 iters), loss = 0.0250549
I0830 16:16:40.858871 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0250592 (* 1 = 0.0250592 loss)
I0830 16:16:40.858881 916722 sgd_solver.cpp:106] Iteration 1846000, lr = 0.01
I0830 16:17:10.650131 916722 solver.cpp:218] Iteration 1846500 (16.7835 iter/s, 29.7912s/500 iters), loss = 0.044085
I0830 16:17:10.650189 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0440894 (* 1 = 0.0440894 loss)
I0830 16:17:10.650197 916722 sgd_solver.cpp:106] Iteration 1846500, lr = 0.01
I0830 16:17:40.445586 916722 solver.cpp:218] Iteration 1847000 (16.7811 iter/s, 29.7954s/500 iters), loss = 0.185867
I0830 16:17:40.445641 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.185872 (* 1 = 0.185872 loss)
I0830 16:17:40.445652 916722 sgd_solver.cpp:106] Iteration 1847000, lr = 0.01
I0830 16:18:10.245679 916722 solver.cpp:218] Iteration 1847500 (16.7785 iter/s, 29.8s/500 iters), loss = 0.0778788
I0830 16:18:10.245748 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0778831 (* 1 = 0.0778831 loss)
I0830 16:18:10.245757 916722 sgd_solver.cpp:106] Iteration 1847500, lr = 0.01
I0830 16:18:40.038727 916722 solver.cpp:218] Iteration 1848000 (16.7825 iter/s, 29.793s/500 iters), loss = 0.267451
I0830 16:18:40.038780 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.267455 (* 1 = 0.267455 loss)
I0830 16:18:40.038790 916722 sgd_solver.cpp:106] Iteration 1848000, lr = 0.01
I0830 16:19:09.841156 916722 solver.cpp:218] Iteration 1848500 (16.7772 iter/s, 29.8023s/500 iters), loss = 0.0514523
I0830 16:19:09.841217 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0514566 (* 1 = 0.0514566 loss)
I0830 16:19:09.841225 916722 sgd_solver.cpp:106] Iteration 1848500, lr = 0.01
I0830 16:19:39.644829 916722 solver.cpp:218] Iteration 1849000 (16.7765 iter/s, 29.8036s/500 iters), loss = 0.0608636
I0830 16:19:39.644881 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0608678 (* 1 = 0.0608678 loss)
I0830 16:19:39.644891 916722 sgd_solver.cpp:106] Iteration 1849000, lr = 0.01
I0830 16:20:09.442824 916722 solver.cpp:218] Iteration 1849500 (16.7797 iter/s, 29.7979s/500 iters), loss = 0.280126
I0830 16:20:09.442883 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.28013 (* 1 = 0.28013 loss)
I0830 16:20:09.442893 916722 sgd_solver.cpp:106] Iteration 1849500, lr = 0.01
I0830 16:20:39.177978 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_1850000.caffemodel
I0830 16:20:39.197587 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_1850000.solverstate
I0830 16:20:39.203764 916722 solver.cpp:330] Iteration 1850000, Testing net (#0)
I0830 16:20:54.653681 916722 solver.cpp:397]     Test net output #0: accuracy = 0.845
I0830 16:20:54.653735 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.52741 (* 1 = 0.52741 loss)
I0830 16:20:54.712391 916722 solver.cpp:218] Iteration 1850000 (11.045 iter/s, 45.2695s/500 iters), loss = 0.177584
I0830 16:20:54.712420 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.177588 (* 1 = 0.177588 loss)
I0830 16:20:54.712446 916722 sgd_solver.cpp:106] Iteration 1850000, lr = 0.01
I0830 16:21:24.459260 916722 solver.cpp:218] Iteration 1850500 (16.8085 iter/s, 29.7468s/500 iters), loss = 0.324505
I0830 16:21:24.459311 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.324509 (* 1 = 0.324509 loss)
I0830 16:21:24.459318 916722 sgd_solver.cpp:106] Iteration 1850500, lr = 0.01
I0830 16:21:54.223924 916722 solver.cpp:218] Iteration 1851000 (16.7985 iter/s, 29.7646s/500 iters), loss = 0.0559168
I0830 16:21:54.223986 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0559208 (* 1 = 0.0559208 loss)
I0830 16:21:54.223995 916722 sgd_solver.cpp:106] Iteration 1851000, lr = 0.01
I0830 16:22:23.997792 916722 solver.cpp:218] Iteration 1851500 (16.7933 iter/s, 29.7738s/500 iters), loss = 0.133392
I0830 16:22:23.997846 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133396 (* 1 = 0.133396 loss)
I0830 16:22:23.997855 916722 sgd_solver.cpp:106] Iteration 1851500, lr = 0.01
I0830 16:22:53.774904 916722 solver.cpp:218] Iteration 1852000 (16.7915 iter/s, 29.777s/500 iters), loss = 0.278389
I0830 16:22:53.774966 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.278393 (* 1 = 0.278393 loss)
I0830 16:22:53.774974 916722 sgd_solver.cpp:106] Iteration 1852000, lr = 0.01
I0830 16:23:23.558514 916722 solver.cpp:218] Iteration 1852500 (16.7878 iter/s, 29.7835s/500 iters), loss = 0.183597
I0830 16:23:23.558570 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.183601 (* 1 = 0.183601 loss)
I0830 16:23:23.558580 916722 sgd_solver.cpp:106] Iteration 1852500, lr = 0.01
I0830 16:23:53.336840 916722 solver.cpp:218] Iteration 1853000 (16.7908 iter/s, 29.7782s/500 iters), loss = 0.115454
I0830 16:23:53.336911 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115458 (* 1 = 0.115458 loss)
I0830 16:23:53.336920 916722 sgd_solver.cpp:106] Iteration 1853000, lr = 0.01
I0830 16:24:23.126874 916722 solver.cpp:218] Iteration 1853500 (16.7842 iter/s, 29.7899s/500 iters), loss = 0.198362
I0830 16:24:23.126929 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.198366 (* 1 = 0.198366 loss)
I0830 16:24:23.126938 916722 sgd_solver.cpp:106] Iteration 1853500, lr = 0.01
I0830 16:24:52.916265 916722 solver.cpp:218] Iteration 1854000 (16.7845 iter/s, 29.7893s/500 iters), loss = 0.115952
I0830 16:24:52.916321 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115956 (* 1 = 0.115956 loss)
I0830 16:24:52.916329 916722 sgd_solver.cpp:106] Iteration 1854000, lr = 0.01
I0830 16:25:22.702934 916722 solver.cpp:218] Iteration 1854500 (16.7861 iter/s, 29.7866s/500 iters), loss = 0.167258
I0830 16:25:22.702988 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.167262 (* 1 = 0.167262 loss)
I0830 16:25:22.702997 916722 sgd_solver.cpp:106] Iteration 1854500, lr = 0.01
I0830 16:25:52.494835 916722 solver.cpp:218] Iteration 1855000 (16.7831 iter/s, 29.7918s/500 iters), loss = 0.061729
I0830 16:25:52.494896 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0617327 (* 1 = 0.0617327 loss)
I0830 16:25:52.494904 916722 sgd_solver.cpp:106] Iteration 1855000, lr = 0.01
I0830 16:26:22.282533 916722 solver.cpp:218] Iteration 1855500 (16.7855 iter/s, 29.7876s/500 iters), loss = 0.193026
I0830 16:26:22.282588 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.19303 (* 1 = 0.19303 loss)
I0830 16:26:22.282596 916722 sgd_solver.cpp:106] Iteration 1855500, lr = 0.01
I0830 16:26:52.072697 916722 solver.cpp:218] Iteration 1856000 (16.7841 iter/s, 29.7901s/500 iters), loss = 0.234836
I0830 16:26:52.072757 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.23484 (* 1 = 0.23484 loss)
I0830 16:26:52.072767 916722 sgd_solver.cpp:106] Iteration 1856000, lr = 0.01
I0830 16:27:21.861837 916722 solver.cpp:218] Iteration 1856500 (16.7847 iter/s, 29.789s/500 iters), loss = 0.0788493
I0830 16:27:21.861891 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0788533 (* 1 = 0.0788533 loss)
I0830 16:27:21.861899 916722 sgd_solver.cpp:106] Iteration 1856500, lr = 0.01
I0830 16:27:51.651844 916722 solver.cpp:218] Iteration 1857000 (16.7842 iter/s, 29.7899s/500 iters), loss = 0.136571
I0830 16:27:51.651902 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.136575 (* 1 = 0.136575 loss)
I0830 16:27:51.651911 916722 sgd_solver.cpp:106] Iteration 1857000, lr = 0.01
I0830 16:28:21.437042 916722 solver.cpp:218] Iteration 1857500 (16.7869 iter/s, 29.7851s/500 iters), loss = 0.0639995
I0830 16:28:21.437098 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0640037 (* 1 = 0.0640037 loss)
I0830 16:28:21.437109 916722 sgd_solver.cpp:106] Iteration 1857500, lr = 0.01
I0830 16:28:51.232203 916722 solver.cpp:218] Iteration 1858000 (16.7813 iter/s, 29.7951s/500 iters), loss = 0.035411
I0830 16:28:51.232264 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0354151 (* 1 = 0.0354151 loss)
I0830 16:28:51.232273 916722 sgd_solver.cpp:106] Iteration 1858000, lr = 0.01
I0830 16:29:21.016028 916722 solver.cpp:218] Iteration 1858500 (16.7877 iter/s, 29.7837s/500 iters), loss = 0.0789712
I0830 16:29:21.016083 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0789751 (* 1 = 0.0789751 loss)
I0830 16:29:21.016093 916722 sgd_solver.cpp:106] Iteration 1858500, lr = 0.01
I0830 16:29:50.798100 916722 solver.cpp:218] Iteration 1859000 (16.7887 iter/s, 29.782s/500 iters), loss = 0.239856
I0830 16:29:50.798161 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.239859 (* 1 = 0.239859 loss)
I0830 16:29:50.798171 916722 sgd_solver.cpp:106] Iteration 1859000, lr = 0.01
I0830 16:30:20.611343 916722 solver.cpp:218] Iteration 1859500 (16.7711 iter/s, 29.8132s/500 iters), loss = 0.312949
I0830 16:30:20.611400 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.312953 (* 1 = 0.312953 loss)
I0830 16:30:20.611424 916722 sgd_solver.cpp:106] Iteration 1859500, lr = 0.01
I0830 16:30:50.412508 916722 solver.cpp:218] Iteration 1860000 (16.7779 iter/s, 29.8011s/500 iters), loss = 0.347648
I0830 16:30:50.412585 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.347652 (* 1 = 0.347652 loss)
I0830 16:30:50.412593 916722 sgd_solver.cpp:106] Iteration 1860000, lr = 0.01
I0830 16:31:20.211905 916722 solver.cpp:218] Iteration 1860500 (16.7789 iter/s, 29.7993s/500 iters), loss = 0.0358535
I0830 16:31:20.211958 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0358574 (* 1 = 0.0358574 loss)
I0830 16:31:20.211968 916722 sgd_solver.cpp:106] Iteration 1860500, lr = 0.01
I0830 16:31:50.015136 916722 solver.cpp:218] Iteration 1861000 (16.7768 iter/s, 29.8031s/500 iters), loss = 0.182518
I0830 16:31:50.015194 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.182522 (* 1 = 0.182522 loss)
I0830 16:31:50.015203 916722 sgd_solver.cpp:106] Iteration 1861000, lr = 0.01
I0830 16:32:19.816910 916722 solver.cpp:218] Iteration 1861500 (16.7776 iter/s, 29.8017s/500 iters), loss = 0.296479
I0830 16:32:19.816963 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.296483 (* 1 = 0.296483 loss)
I0830 16:32:19.816973 916722 sgd_solver.cpp:106] Iteration 1861500, lr = 0.01
I0830 16:32:49.620805 916722 solver.cpp:218] Iteration 1862000 (16.7764 iter/s, 29.8038s/500 iters), loss = 0.119809
I0830 16:32:49.620862 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.119813 (* 1 = 0.119813 loss)
I0830 16:32:49.620872 916722 sgd_solver.cpp:106] Iteration 1862000, lr = 0.01
I0830 16:33:19.422957 916722 solver.cpp:218] Iteration 1862500 (16.7774 iter/s, 29.8021s/500 iters), loss = 0.0751298
I0830 16:33:19.423012 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0751337 (* 1 = 0.0751337 loss)
I0830 16:33:19.423022 916722 sgd_solver.cpp:106] Iteration 1862500, lr = 0.01
I0830 16:33:49.220860 916722 solver.cpp:218] Iteration 1863000 (16.7798 iter/s, 29.7978s/500 iters), loss = 0.101678
I0830 16:33:49.220922 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101682 (* 1 = 0.101682 loss)
I0830 16:33:49.220932 916722 sgd_solver.cpp:106] Iteration 1863000, lr = 0.01
I0830 16:34:19.018492 916722 solver.cpp:218] Iteration 1863500 (16.7799 iter/s, 29.7975s/500 iters), loss = 0.0686165
I0830 16:34:19.018548 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0686206 (* 1 = 0.0686206 loss)
I0830 16:34:19.018556 916722 sgd_solver.cpp:106] Iteration 1863500, lr = 0.01
I0830 16:34:48.820158 916722 solver.cpp:218] Iteration 1864000 (16.7776 iter/s, 29.8016s/500 iters), loss = 0.166167
I0830 16:34:48.820219 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.166171 (* 1 = 0.166171 loss)
I0830 16:34:48.820227 916722 sgd_solver.cpp:106] Iteration 1864000, lr = 0.01
I0830 16:35:18.616353 916722 solver.cpp:218] Iteration 1864500 (16.7807 iter/s, 29.7961s/500 iters), loss = 0.218613
I0830 16:35:18.616407 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.218617 (* 1 = 0.218617 loss)
I0830 16:35:18.616415 916722 sgd_solver.cpp:106] Iteration 1864500, lr = 0.01
I0830 16:35:48.411307 916722 solver.cpp:218] Iteration 1865000 (16.7814 iter/s, 29.7949s/500 iters), loss = 0.121059
I0830 16:35:48.411367 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.121063 (* 1 = 0.121063 loss)
I0830 16:35:48.411375 916722 sgd_solver.cpp:106] Iteration 1865000, lr = 0.01
I0830 16:36:18.210116 916722 solver.cpp:218] Iteration 1865500 (16.7792 iter/s, 29.7987s/500 iters), loss = 0.235652
I0830 16:36:18.210166 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.235656 (* 1 = 0.235656 loss)
I0830 16:36:18.210175 916722 sgd_solver.cpp:106] Iteration 1865500, lr = 0.01
I0830 16:36:48.008671 916722 solver.cpp:218] Iteration 1866000 (16.7794 iter/s, 29.7985s/500 iters), loss = 0.0713861
I0830 16:36:48.008744 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0713905 (* 1 = 0.0713905 loss)
I0830 16:36:48.008759 916722 sgd_solver.cpp:106] Iteration 1866000, lr = 0.01
I0830 16:37:17.804023 916722 solver.cpp:218] Iteration 1866500 (16.7812 iter/s, 29.7952s/500 iters), loss = 0.197474
I0830 16:37:17.804078 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.197478 (* 1 = 0.197478 loss)
I0830 16:37:17.804086 916722 sgd_solver.cpp:106] Iteration 1866500, lr = 0.01
I0830 16:37:47.602648 916722 solver.cpp:218] Iteration 1867000 (16.7793 iter/s, 29.7985s/500 iters), loss = 0.0699645
I0830 16:37:47.602711 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0699686 (* 1 = 0.0699686 loss)
I0830 16:37:47.602720 916722 sgd_solver.cpp:106] Iteration 1867000, lr = 0.01
I0830 16:38:17.401929 916722 solver.cpp:218] Iteration 1867500 (16.779 iter/s, 29.7992s/500 iters), loss = 0.168344
I0830 16:38:17.401983 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.168348 (* 1 = 0.168348 loss)
I0830 16:38:17.401993 916722 sgd_solver.cpp:106] Iteration 1867500, lr = 0.01
I0830 16:38:47.199571 916722 solver.cpp:218] Iteration 1868000 (16.7799 iter/s, 29.7976s/500 iters), loss = 0.247215
I0830 16:38:47.199631 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.247219 (* 1 = 0.247219 loss)
I0830 16:38:47.199640 916722 sgd_solver.cpp:106] Iteration 1868000, lr = 0.01
I0830 16:39:17.001509 916722 solver.cpp:218] Iteration 1868500 (16.7775 iter/s, 29.8018s/500 iters), loss = 0.119381
I0830 16:39:17.001565 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.119385 (* 1 = 0.119385 loss)
I0830 16:39:17.001575 916722 sgd_solver.cpp:106] Iteration 1868500, lr = 0.01
I0830 16:39:46.803109 916722 solver.cpp:218] Iteration 1869000 (16.7777 iter/s, 29.8015s/500 iters), loss = 0.0759837
I0830 16:39:46.803174 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0759877 (* 1 = 0.0759877 loss)
I0830 16:39:46.803182 916722 sgd_solver.cpp:106] Iteration 1869000, lr = 0.01
I0830 16:40:16.605613 916722 solver.cpp:218] Iteration 1869500 (16.7772 iter/s, 29.8024s/500 iters), loss = 0.330312
I0830 16:40:16.605665 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.330316 (* 1 = 0.330316 loss)
I0830 16:40:16.605675 916722 sgd_solver.cpp:106] Iteration 1869500, lr = 0.01
I0830 16:40:46.405104 916722 solver.cpp:218] Iteration 1870000 (16.7789 iter/s, 29.7994s/500 iters), loss = 0.384725
I0830 16:40:46.405162 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.384729 (* 1 = 0.384729 loss)
I0830 16:40:46.405170 916722 sgd_solver.cpp:106] Iteration 1870000, lr = 0.01
I0830 16:41:16.194197 916722 solver.cpp:218] Iteration 1870500 (16.785 iter/s, 29.7885s/500 iters), loss = 0.0135462
I0830 16:41:16.194252 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0135506 (* 1 = 0.0135506 loss)
I0830 16:41:16.194262 916722 sgd_solver.cpp:106] Iteration 1870500, lr = 0.01
I0830 16:41:45.989889 916722 solver.cpp:218] Iteration 1871000 (16.7815 iter/s, 29.7948s/500 iters), loss = 0.182914
I0830 16:41:45.989948 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.182918 (* 1 = 0.182918 loss)
I0830 16:41:45.989957 916722 sgd_solver.cpp:106] Iteration 1871000, lr = 0.01
I0830 16:42:15.782267 916722 solver.cpp:218] Iteration 1871500 (16.7833 iter/s, 29.7915s/500 iters), loss = 0.121012
I0830 16:42:15.782320 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.121016 (* 1 = 0.121016 loss)
I0830 16:42:15.782330 916722 sgd_solver.cpp:106] Iteration 1871500, lr = 0.01
I0830 16:42:45.579890 916722 solver.cpp:218] Iteration 1872000 (16.7803 iter/s, 29.7968s/500 iters), loss = 0.123048
I0830 16:42:45.579949 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.123053 (* 1 = 0.123053 loss)
I0830 16:42:45.579957 916722 sgd_solver.cpp:106] Iteration 1872000, lr = 0.01
I0830 16:43:15.370851 916722 solver.cpp:218] Iteration 1872500 (16.7841 iter/s, 29.7902s/500 iters), loss = 0.151329
I0830 16:43:15.370903 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.151333 (* 1 = 0.151333 loss)
I0830 16:43:15.370913 916722 sgd_solver.cpp:106] Iteration 1872500, lr = 0.01
I0830 16:43:45.159631 916722 solver.cpp:218] Iteration 1873000 (16.7853 iter/s, 29.788s/500 iters), loss = 0.111357
I0830 16:43:45.159699 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111361 (* 1 = 0.111361 loss)
I0830 16:43:45.159708 916722 sgd_solver.cpp:106] Iteration 1873000, lr = 0.01
I0830 16:44:14.953287 916722 solver.cpp:218] Iteration 1873500 (16.7825 iter/s, 29.7929s/500 iters), loss = 0.234238
I0830 16:44:14.953341 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.234242 (* 1 = 0.234242 loss)
I0830 16:44:14.953351 916722 sgd_solver.cpp:106] Iteration 1873500, lr = 0.01
I0830 16:44:44.751176 916722 solver.cpp:218] Iteration 1874000 (16.7801 iter/s, 29.7972s/500 iters), loss = 0.050991
I0830 16:44:44.751243 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0509952 (* 1 = 0.0509952 loss)
I0830 16:44:44.751252 916722 sgd_solver.cpp:106] Iteration 1874000, lr = 0.01
I0830 16:45:14.538069 916722 solver.cpp:218] Iteration 1874500 (16.7863 iter/s, 29.7862s/500 iters), loss = 0.0673786
I0830 16:45:14.538123 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.067383 (* 1 = 0.067383 loss)
I0830 16:45:14.538132 916722 sgd_solver.cpp:106] Iteration 1874500, lr = 0.01
I0830 16:45:44.332347 916722 solver.cpp:218] Iteration 1875000 (16.7821 iter/s, 29.7936s/500 iters), loss = 0.213818
I0830 16:45:44.332408 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.213822 (* 1 = 0.213822 loss)
I0830 16:45:44.332417 916722 sgd_solver.cpp:106] Iteration 1875000, lr = 0.01
I0830 16:46:14.129593 916722 solver.cpp:218] Iteration 1875500 (16.7804 iter/s, 29.7966s/500 iters), loss = 0.0671603
I0830 16:46:14.129648 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0671648 (* 1 = 0.0671648 loss)
I0830 16:46:14.129657 916722 sgd_solver.cpp:106] Iteration 1875500, lr = 0.01
I0830 16:46:43.935581 916722 solver.cpp:218] Iteration 1876000 (16.7755 iter/s, 29.8054s/500 iters), loss = 0.125581
I0830 16:46:43.935642 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.125585 (* 1 = 0.125585 loss)
I0830 16:46:43.935650 916722 sgd_solver.cpp:106] Iteration 1876000, lr = 0.01
I0830 16:47:13.728487 916722 solver.cpp:218] Iteration 1876500 (16.7828 iter/s, 29.7923s/500 iters), loss = 0.270593
I0830 16:47:13.728543 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.270597 (* 1 = 0.270597 loss)
I0830 16:47:13.728554 916722 sgd_solver.cpp:106] Iteration 1876500, lr = 0.01
I0830 16:47:43.501603 916722 solver.cpp:218] Iteration 1877000 (16.794 iter/s, 29.7726s/500 iters), loss = 0.0806918
I0830 16:47:43.501663 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0806962 (* 1 = 0.0806962 loss)
I0830 16:47:43.501672 916722 sgd_solver.cpp:106] Iteration 1877000, lr = 0.01
I0830 16:48:13.272619 916722 solver.cpp:218] Iteration 1877500 (16.7952 iter/s, 29.7705s/500 iters), loss = 0.0142499
I0830 16:48:13.272675 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0142543 (* 1 = 0.0142543 loss)
I0830 16:48:13.272686 916722 sgd_solver.cpp:106] Iteration 1877500, lr = 0.01
I0830 16:48:43.055459 916722 solver.cpp:218] Iteration 1878000 (16.7885 iter/s, 29.7823s/500 iters), loss = 0.0461661
I0830 16:48:43.055524 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0461707 (* 1 = 0.0461707 loss)
I0830 16:48:43.055533 916722 sgd_solver.cpp:106] Iteration 1878000, lr = 0.01
I0830 16:49:12.830256 916722 solver.cpp:218] Iteration 1878500 (16.793 iter/s, 29.7743s/500 iters), loss = 0.117189
I0830 16:49:12.830310 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.117194 (* 1 = 0.117194 loss)
I0830 16:49:12.830320 916722 sgd_solver.cpp:106] Iteration 1878500, lr = 0.01
I0830 16:49:42.607371 916722 solver.cpp:218] Iteration 1879000 (16.7917 iter/s, 29.7766s/500 iters), loss = 0.014238
I0830 16:49:42.607432 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0142425 (* 1 = 0.0142425 loss)
I0830 16:49:42.607441 916722 sgd_solver.cpp:106] Iteration 1879000, lr = 0.01
I0830 16:50:12.383349 916722 solver.cpp:218] Iteration 1879500 (16.7923 iter/s, 29.7755s/500 iters), loss = 0.232243
I0830 16:50:12.383402 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.232247 (* 1 = 0.232247 loss)
I0830 16:50:12.383412 916722 sgd_solver.cpp:106] Iteration 1879500, lr = 0.01
I0830 16:50:42.160967 916722 solver.cpp:218] Iteration 1880000 (16.7914 iter/s, 29.7772s/500 iters), loss = 0.0818303
I0830 16:50:42.161038 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0818346 (* 1 = 0.0818346 loss)
I0830 16:50:42.161046 916722 sgd_solver.cpp:106] Iteration 1880000, lr = 0.01
I0830 16:51:11.935462 916722 solver.cpp:218] Iteration 1880500 (16.7931 iter/s, 29.774s/500 iters), loss = 0.332257
I0830 16:51:11.935514 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.332261 (* 1 = 0.332261 loss)
I0830 16:51:11.935524 916722 sgd_solver.cpp:106] Iteration 1880500, lr = 0.01
I0830 16:51:41.709784 916722 solver.cpp:218] Iteration 1881000 (16.7932 iter/s, 29.7739s/500 iters), loss = 0.107495
I0830 16:51:41.709839 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.1075 (* 1 = 0.1075 loss)
I0830 16:51:41.709848 916722 sgd_solver.cpp:106] Iteration 1881000, lr = 0.01
I0830 16:52:11.481966 916722 solver.cpp:218] Iteration 1881500 (16.7944 iter/s, 29.7718s/500 iters), loss = 0.196097
I0830 16:52:11.482019 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.196101 (* 1 = 0.196101 loss)
I0830 16:52:11.482029 916722 sgd_solver.cpp:106] Iteration 1881500, lr = 0.01
I0830 16:52:41.256897 916722 solver.cpp:218] Iteration 1882000 (16.7929 iter/s, 29.7745s/500 iters), loss = 0.327299
I0830 16:52:41.256956 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.327303 (* 1 = 0.327303 loss)
I0830 16:52:41.256965 916722 sgd_solver.cpp:106] Iteration 1882000, lr = 0.01
I0830 16:53:11.034111 916722 solver.cpp:218] Iteration 1882500 (16.7916 iter/s, 29.7768s/500 iters), loss = 0.230203
I0830 16:53:11.034159 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.230207 (* 1 = 0.230207 loss)
I0830 16:53:11.034168 916722 sgd_solver.cpp:106] Iteration 1882500, lr = 0.01
I0830 16:53:40.808311 916722 solver.cpp:218] Iteration 1883000 (16.7933 iter/s, 29.7738s/500 iters), loss = 0.361364
I0830 16:53:40.808372 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.361368 (* 1 = 0.361368 loss)
I0830 16:53:40.808380 916722 sgd_solver.cpp:106] Iteration 1883000, lr = 0.01
I0830 16:54:10.582408 916722 solver.cpp:218] Iteration 1883500 (16.7933 iter/s, 29.7737s/500 iters), loss = 0.0376168
I0830 16:54:10.582460 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0376209 (* 1 = 0.0376209 loss)
I0830 16:54:10.582469 916722 sgd_solver.cpp:106] Iteration 1883500, lr = 0.01
I0830 16:54:40.360823 916722 solver.cpp:218] Iteration 1884000 (16.7909 iter/s, 29.7781s/500 iters), loss = 0.261228
I0830 16:54:40.360883 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.261232 (* 1 = 0.261232 loss)
I0830 16:54:40.360891 916722 sgd_solver.cpp:106] Iteration 1884000, lr = 0.01
I0830 16:55:10.134011 916722 solver.cpp:218] Iteration 1884500 (16.7938 iter/s, 29.7728s/500 iters), loss = 0.113617
I0830 16:55:10.134064 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.113621 (* 1 = 0.113621 loss)
I0830 16:55:10.134074 916722 sgd_solver.cpp:106] Iteration 1884500, lr = 0.01
I0830 16:55:39.909996 916722 solver.cpp:218] Iteration 1885000 (16.7922 iter/s, 29.7756s/500 iters), loss = 0.272456
I0830 16:55:39.910053 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.27246 (* 1 = 0.27246 loss)
I0830 16:55:39.910063 916722 sgd_solver.cpp:106] Iteration 1885000, lr = 0.01
I0830 16:56:09.685577 916722 solver.cpp:218] Iteration 1885500 (16.7925 iter/s, 29.7752s/500 iters), loss = 0.0889249
I0830 16:56:09.685631 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0889287 (* 1 = 0.0889287 loss)
I0830 16:56:09.685642 916722 sgd_solver.cpp:106] Iteration 1885500, lr = 0.01
I0830 16:56:39.462275 916722 solver.cpp:218] Iteration 1886000 (16.7918 iter/s, 29.7764s/500 iters), loss = 0.082181
I0830 16:56:39.462348 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0821849 (* 1 = 0.0821849 loss)
I0830 16:56:39.462357 916722 sgd_solver.cpp:106] Iteration 1886000, lr = 0.01
I0830 16:57:09.238461 916722 solver.cpp:218] Iteration 1886500 (16.7921 iter/s, 29.7759s/500 iters), loss = 0.0667408
I0830 16:57:09.238514 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0667446 (* 1 = 0.0667446 loss)
I0830 16:57:09.238524 916722 sgd_solver.cpp:106] Iteration 1886500, lr = 0.01
I0830 16:57:39.011086 916722 solver.cpp:218] Iteration 1887000 (16.7941 iter/s, 29.7723s/500 iters), loss = 0.0843227
I0830 16:57:39.011145 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0843266 (* 1 = 0.0843266 loss)
I0830 16:57:39.011153 916722 sgd_solver.cpp:106] Iteration 1887000, lr = 0.01
I0830 16:58:08.786425 916722 solver.cpp:218] Iteration 1887500 (16.7926 iter/s, 29.775s/500 iters), loss = 0.0448389
I0830 16:58:08.786479 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0448428 (* 1 = 0.0448428 loss)
I0830 16:58:08.786489 916722 sgd_solver.cpp:106] Iteration 1887500, lr = 0.01
I0830 16:58:38.557566 916722 solver.cpp:218] Iteration 1888000 (16.795 iter/s, 29.7708s/500 iters), loss = 0.256828
I0830 16:58:38.557623 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.256832 (* 1 = 0.256832 loss)
I0830 16:58:38.557631 916722 sgd_solver.cpp:106] Iteration 1888000, lr = 0.01
I0830 16:59:08.329380 916722 solver.cpp:218] Iteration 1888500 (16.7946 iter/s, 29.7715s/500 iters), loss = 0.319855
I0830 16:59:08.329428 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.319858 (* 1 = 0.319858 loss)
I0830 16:59:08.329438 916722 sgd_solver.cpp:106] Iteration 1888500, lr = 0.01
I0830 16:59:38.100788 916722 solver.cpp:218] Iteration 1889000 (16.7948 iter/s, 29.7711s/500 iters), loss = 0.324673
I0830 16:59:38.100847 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.324677 (* 1 = 0.324677 loss)
I0830 16:59:38.100857 916722 sgd_solver.cpp:106] Iteration 1889000, lr = 0.01
I0830 17:00:07.869900 916722 solver.cpp:218] Iteration 1889500 (16.7961 iter/s, 29.7688s/500 iters), loss = 0.192833
I0830 17:00:07.869952 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.192837 (* 1 = 0.192837 loss)
I0830 17:00:07.869963 916722 sgd_solver.cpp:106] Iteration 1889500, lr = 0.01
I0830 17:00:37.641731 916722 solver.cpp:218] Iteration 1890000 (16.7946 iter/s, 29.7715s/500 iters), loss = 0.109987
I0830 17:00:37.641793 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109991 (* 1 = 0.109991 loss)
I0830 17:00:37.641800 916722 sgd_solver.cpp:106] Iteration 1890000, lr = 0.01
I0830 17:01:07.414645 916722 solver.cpp:218] Iteration 1890500 (16.7939 iter/s, 29.7726s/500 iters), loss = 0.162478
I0830 17:01:07.414697 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.162481 (* 1 = 0.162481 loss)
I0830 17:01:07.414706 916722 sgd_solver.cpp:106] Iteration 1890500, lr = 0.01
I0830 17:01:37.184504 916722 solver.cpp:218] Iteration 1891000 (16.7957 iter/s, 29.7696s/500 iters), loss = 0.0552425
I0830 17:01:37.184566 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0552463 (* 1 = 0.0552463 loss)
I0830 17:01:37.184574 916722 sgd_solver.cpp:106] Iteration 1891000, lr = 0.01
I0830 17:02:06.953449 916722 solver.cpp:218] Iteration 1891500 (16.7962 iter/s, 29.7687s/500 iters), loss = 0.08284
I0830 17:02:06.953500 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0828438 (* 1 = 0.0828438 loss)
I0830 17:02:06.953508 916722 sgd_solver.cpp:106] Iteration 1891500, lr = 0.01
I0830 17:02:36.725651 916722 solver.cpp:218] Iteration 1892000 (16.7943 iter/s, 29.7719s/500 iters), loss = 0.0247391
I0830 17:02:36.725708 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.024743 (* 1 = 0.024743 loss)
I0830 17:02:36.725718 916722 sgd_solver.cpp:106] Iteration 1892000, lr = 0.01
I0830 17:03:06.499141 916722 solver.cpp:218] Iteration 1892500 (16.7936 iter/s, 29.7732s/500 iters), loss = 0.0312825
I0830 17:03:06.499203 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0312864 (* 1 = 0.0312864 loss)
I0830 17:03:06.499213 916722 sgd_solver.cpp:106] Iteration 1892500, lr = 0.01
I0830 17:03:36.270593 916722 solver.cpp:218] Iteration 1893000 (16.7948 iter/s, 29.7712s/500 iters), loss = 0.0727292
I0830 17:03:36.270663 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0727331 (* 1 = 0.0727331 loss)
I0830 17:03:36.270670 916722 sgd_solver.cpp:106] Iteration 1893000, lr = 0.01
I0830 17:04:06.040958 916722 solver.cpp:218] Iteration 1893500 (16.7954 iter/s, 29.7701s/500 iters), loss = 0.147898
I0830 17:04:06.041013 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.147902 (* 1 = 0.147902 loss)
I0830 17:04:06.041021 916722 sgd_solver.cpp:106] Iteration 1893500, lr = 0.01
I0830 17:04:35.813040 916722 solver.cpp:218] Iteration 1894000 (16.7944 iter/s, 29.7718s/500 iters), loss = 0.0677995
I0830 17:04:35.813098 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0678032 (* 1 = 0.0678032 loss)
I0830 17:04:35.813107 916722 sgd_solver.cpp:106] Iteration 1894000, lr = 0.01
I0830 17:05:05.583397 916722 solver.cpp:218] Iteration 1894500 (16.7954 iter/s, 29.7701s/500 iters), loss = 0.231412
I0830 17:05:05.583448 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.231416 (* 1 = 0.231416 loss)
I0830 17:05:05.583457 916722 sgd_solver.cpp:106] Iteration 1894500, lr = 0.01
I0830 17:05:35.354398 916722 solver.cpp:218] Iteration 1895000 (16.795 iter/s, 29.7708s/500 iters), loss = 0.101418
I0830 17:05:35.354458 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101422 (* 1 = 0.101422 loss)
I0830 17:05:35.354466 916722 sgd_solver.cpp:106] Iteration 1895000, lr = 0.01
I0830 17:06:05.129549 916722 solver.cpp:218] Iteration 1895500 (16.7927 iter/s, 29.7749s/500 iters), loss = 0.201821
I0830 17:06:05.129601 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.201825 (* 1 = 0.201825 loss)
I0830 17:06:05.129611 916722 sgd_solver.cpp:106] Iteration 1895500, lr = 0.01
I0830 17:06:34.899578 916722 solver.cpp:218] Iteration 1896000 (16.7956 iter/s, 29.7698s/500 iters), loss = 0.1457
I0830 17:06:34.899634 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.145704 (* 1 = 0.145704 loss)
I0830 17:06:34.899642 916722 sgd_solver.cpp:106] Iteration 1896000, lr = 0.01
I0830 17:07:04.666054 916722 solver.cpp:218] Iteration 1896500 (16.7976 iter/s, 29.7662s/500 iters), loss = 0.200994
I0830 17:07:04.666103 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.200998 (* 1 = 0.200998 loss)
I0830 17:07:04.666113 916722 sgd_solver.cpp:106] Iteration 1896500, lr = 0.01
I0830 17:07:34.442899 916722 solver.cpp:218] Iteration 1897000 (16.7917 iter/s, 29.7766s/500 iters), loss = 0.400084
I0830 17:07:34.442955 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.400088 (* 1 = 0.400088 loss)
I0830 17:07:34.442963 916722 sgd_solver.cpp:106] Iteration 1897000, lr = 0.01
I0830 17:08:04.212828 916722 solver.cpp:218] Iteration 1897500 (16.7956 iter/s, 29.7697s/500 iters), loss = 0.267563
I0830 17:08:04.212878 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.267567 (* 1 = 0.267567 loss)
I0830 17:08:04.212888 916722 sgd_solver.cpp:106] Iteration 1897500, lr = 0.01
I0830 17:08:33.982483 916722 solver.cpp:218] Iteration 1898000 (16.7958 iter/s, 29.7694s/500 iters), loss = 0.401371
I0830 17:08:33.982542 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.401375 (* 1 = 0.401375 loss)
I0830 17:08:33.982550 916722 sgd_solver.cpp:106] Iteration 1898000, lr = 0.01
I0830 17:09:03.750959 916722 solver.cpp:218] Iteration 1898500 (16.7964 iter/s, 29.7682s/500 iters), loss = 0.045948
I0830 17:09:03.751010 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0459518 (* 1 = 0.0459518 loss)
I0830 17:09:03.751020 916722 sgd_solver.cpp:106] Iteration 1898500, lr = 0.01
I0830 17:09:33.523335 916722 solver.cpp:218] Iteration 1899000 (16.7942 iter/s, 29.7721s/500 iters), loss = 0.229593
I0830 17:09:33.523406 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.229597 (* 1 = 0.229597 loss)
I0830 17:09:33.523416 916722 sgd_solver.cpp:106] Iteration 1899000, lr = 0.01
I0830 17:10:03.294907 916722 solver.cpp:218] Iteration 1899500 (16.7947 iter/s, 29.7713s/500 iters), loss = 0.252415
I0830 17:10:03.294957 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.252419 (* 1 = 0.252419 loss)
I0830 17:10:03.294967 916722 sgd_solver.cpp:106] Iteration 1899500, lr = 0.01
I0830 17:10:33.005743 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_1900000.caffemodel
I0830 17:10:33.025251 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_1900000.solverstate
I0830 17:10:33.031376 916722 solver.cpp:330] Iteration 1900000, Testing net (#0)
I0830 17:10:48.517735 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8502
I0830 17:10:48.517778 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.531976 (* 1 = 0.531976 loss)
I0830 17:10:48.576352 916722 solver.cpp:218] Iteration 1900000 (11.0421 iter/s, 45.2811s/500 iters), loss = 0.114258
I0830 17:10:48.576380 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.114262 (* 1 = 0.114262 loss)
I0830 17:10:48.576390 916722 sgd_solver.cpp:106] Iteration 1900000, lr = 0.01
I0830 17:11:18.318809 916722 solver.cpp:218] Iteration 1900500 (16.8111 iter/s, 29.7422s/500 iters), loss = 0.143827
I0830 17:11:18.318868 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.143831 (* 1 = 0.143831 loss)
I0830 17:11:18.318876 916722 sgd_solver.cpp:106] Iteration 1900500, lr = 0.01
I0830 17:11:48.078594 916722 solver.cpp:218] Iteration 1901000 (16.8013 iter/s, 29.7595s/500 iters), loss = 0.286369
I0830 17:11:48.078649 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.286373 (* 1 = 0.286373 loss)
I0830 17:11:48.078660 916722 sgd_solver.cpp:106] Iteration 1901000, lr = 0.01
I0830 17:12:17.836514 916722 solver.cpp:218] Iteration 1901500 (16.8024 iter/s, 29.7577s/500 iters), loss = 0.194696
I0830 17:12:17.836576 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.1947 (* 1 = 0.1947 loss)
I0830 17:12:17.836585 916722 sgd_solver.cpp:106] Iteration 1901500, lr = 0.01
I0830 17:12:47.598971 916722 solver.cpp:218] Iteration 1902000 (16.7998 iter/s, 29.7622s/500 iters), loss = 0.131812
I0830 17:12:47.599025 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131816 (* 1 = 0.131816 loss)
I0830 17:12:47.599035 916722 sgd_solver.cpp:106] Iteration 1902000, lr = 0.01
I0830 17:13:17.363610 916722 solver.cpp:218] Iteration 1902500 (16.7986 iter/s, 29.7644s/500 iters), loss = 0.0768262
I0830 17:13:17.363667 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0768296 (* 1 = 0.0768296 loss)
I0830 17:13:17.363675 916722 sgd_solver.cpp:106] Iteration 1902500, lr = 0.01
I0830 17:13:47.130548 916722 solver.cpp:218] Iteration 1903000 (16.7973 iter/s, 29.7667s/500 iters), loss = 0.083395
I0830 17:13:47.130600 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0833983 (* 1 = 0.0833983 loss)
I0830 17:13:47.130610 916722 sgd_solver.cpp:106] Iteration 1903000, lr = 0.01
I0830 17:14:16.902876 916722 solver.cpp:218] Iteration 1903500 (16.7942 iter/s, 29.7721s/500 iters), loss = 0.274663
I0830 17:14:16.902937 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.274666 (* 1 = 0.274666 loss)
I0830 17:14:16.902945 916722 sgd_solver.cpp:106] Iteration 1903500, lr = 0.01
I0830 17:14:46.670176 916722 solver.cpp:218] Iteration 1904000 (16.7971 iter/s, 29.7671s/500 iters), loss = 0.0810476
I0830 17:14:46.670229 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0810509 (* 1 = 0.0810509 loss)
I0830 17:14:46.670239 916722 sgd_solver.cpp:106] Iteration 1904000, lr = 0.01
I0830 17:15:16.441565 916722 solver.cpp:218] Iteration 1904500 (16.7947 iter/s, 29.7713s/500 iters), loss = 0.250893
I0830 17:15:16.441643 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.250897 (* 1 = 0.250897 loss)
I0830 17:15:16.441656 916722 sgd_solver.cpp:106] Iteration 1904500, lr = 0.01
I0830 17:15:46.215543 916722 solver.cpp:218] Iteration 1905000 (16.793 iter/s, 29.7743s/500 iters), loss = 0.0946295
I0830 17:15:46.215598 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0946328 (* 1 = 0.0946328 loss)
I0830 17:15:46.215607 916722 sgd_solver.cpp:106] Iteration 1905000, lr = 0.01
I0830 17:16:15.988003 916722 solver.cpp:218] Iteration 1905500 (16.7938 iter/s, 29.7728s/500 iters), loss = 0.175501
I0830 17:16:15.988061 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.175504 (* 1 = 0.175504 loss)
I0830 17:16:15.988070 916722 sgd_solver.cpp:106] Iteration 1905500, lr = 0.01
I0830 17:16:45.760942 916722 solver.cpp:218] Iteration 1906000 (16.7936 iter/s, 29.7733s/500 iters), loss = 0.0346332
I0830 17:16:45.760995 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0346363 (* 1 = 0.0346363 loss)
I0830 17:16:45.761004 916722 sgd_solver.cpp:106] Iteration 1906000, lr = 0.01
I0830 17:17:15.532940 916722 solver.cpp:218] Iteration 1906500 (16.7941 iter/s, 29.7723s/500 iters), loss = 0.0759198
I0830 17:17:15.533000 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0759228 (* 1 = 0.0759228 loss)
I0830 17:17:15.533008 916722 sgd_solver.cpp:106] Iteration 1906500, lr = 0.01
I0830 17:17:45.298379 916722 solver.cpp:218] Iteration 1907000 (16.7979 iter/s, 29.7657s/500 iters), loss = 0.158457
I0830 17:17:45.298430 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.158461 (* 1 = 0.158461 loss)
I0830 17:17:45.298439 916722 sgd_solver.cpp:106] Iteration 1907000, lr = 0.01
I0830 17:18:15.066531 916722 solver.cpp:218] Iteration 1907500 (16.7963 iter/s, 29.7684s/500 iters), loss = 0.341361
I0830 17:18:15.066592 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.341364 (* 1 = 0.341364 loss)
I0830 17:18:15.066601 916722 sgd_solver.cpp:106] Iteration 1907500, lr = 0.01
I0830 17:18:44.839848 916722 solver.cpp:218] Iteration 1908000 (16.7934 iter/s, 29.7735s/500 iters), loss = 0.172562
I0830 17:18:44.839900 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.172565 (* 1 = 0.172565 loss)
I0830 17:18:44.839910 916722 sgd_solver.cpp:106] Iteration 1908000, lr = 0.01
I0830 17:19:14.606158 916722 solver.cpp:218] Iteration 1908500 (16.7974 iter/s, 29.7665s/500 iters), loss = 0.199642
I0830 17:19:14.606213 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.199645 (* 1 = 0.199645 loss)
I0830 17:19:14.606221 916722 sgd_solver.cpp:106] Iteration 1908500, lr = 0.01
I0830 17:19:44.375097 916722 solver.cpp:218] Iteration 1909000 (16.7959 iter/s, 29.7691s/500 iters), loss = 0.127383
I0830 17:19:44.375150 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.127386 (* 1 = 0.127386 loss)
I0830 17:19:44.375161 916722 sgd_solver.cpp:106] Iteration 1909000, lr = 0.01
I0830 17:20:14.146358 916722 solver.cpp:218] Iteration 1909500 (16.7946 iter/s, 29.7714s/500 iters), loss = 0.146586
I0830 17:20:14.146420 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.146589 (* 1 = 0.146589 loss)
I0830 17:20:14.146428 916722 sgd_solver.cpp:106] Iteration 1909500, lr = 0.01
I0830 17:20:43.917063 916722 solver.cpp:218] Iteration 1910000 (16.795 iter/s, 29.7708s/500 iters), loss = 0.21559
I0830 17:20:43.917117 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.215594 (* 1 = 0.215594 loss)
I0830 17:20:43.917126 916722 sgd_solver.cpp:106] Iteration 1910000, lr = 0.01
I0830 17:21:13.685854 916722 solver.cpp:218] Iteration 1910500 (16.796 iter/s, 29.7689s/500 iters), loss = 0.400844
I0830 17:21:13.685915 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.400847 (* 1 = 0.400847 loss)
I0830 17:21:13.685923 916722 sgd_solver.cpp:106] Iteration 1910500, lr = 0.01
I0830 17:21:43.452805 916722 solver.cpp:218] Iteration 1911000 (16.7971 iter/s, 29.7671s/500 iters), loss = 0.0829535
I0830 17:21:43.452860 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0829564 (* 1 = 0.0829564 loss)
I0830 17:21:43.452869 916722 sgd_solver.cpp:106] Iteration 1911000, lr = 0.01
I0830 17:22:13.218870 916722 solver.cpp:218] Iteration 1911500 (16.7976 iter/s, 29.7662s/500 iters), loss = 0.113031
I0830 17:22:13.218942 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.113034 (* 1 = 0.113034 loss)
I0830 17:22:13.218951 916722 sgd_solver.cpp:106] Iteration 1911500, lr = 0.01
I0830 17:22:42.984578 916722 solver.cpp:218] Iteration 1912000 (16.7978 iter/s, 29.7658s/500 iters), loss = 0.0310383
I0830 17:22:42.984634 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0310413 (* 1 = 0.0310413 loss)
I0830 17:22:42.984645 916722 sgd_solver.cpp:106] Iteration 1912000, lr = 0.01
I0830 17:23:12.750515 916722 solver.cpp:218] Iteration 1912500 (16.7977 iter/s, 29.766s/500 iters), loss = 0.290549
I0830 17:23:12.750572 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.290552 (* 1 = 0.290552 loss)
I0830 17:23:12.750581 916722 sgd_solver.cpp:106] Iteration 1912500, lr = 0.01
I0830 17:23:42.516129 916722 solver.cpp:218] Iteration 1913000 (16.7979 iter/s, 29.7657s/500 iters), loss = 0.0714138
I0830 17:23:42.516183 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0714168 (* 1 = 0.0714168 loss)
I0830 17:23:42.516192 916722 sgd_solver.cpp:106] Iteration 1913000, lr = 0.01
I0830 17:24:12.286983 916722 solver.cpp:218] Iteration 1913500 (16.7949 iter/s, 29.7709s/500 iters), loss = 0.15239
I0830 17:24:12.287042 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152393 (* 1 = 0.152393 loss)
I0830 17:24:12.287051 916722 sgd_solver.cpp:106] Iteration 1913500, lr = 0.01
I0830 17:24:42.055011 916722 solver.cpp:218] Iteration 1914000 (16.7965 iter/s, 29.7681s/500 iters), loss = 0.0563576
I0830 17:24:42.055063 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0563605 (* 1 = 0.0563605 loss)
I0830 17:24:42.055071 916722 sgd_solver.cpp:106] Iteration 1914000, lr = 0.01
I0830 17:25:11.822012 916722 solver.cpp:218] Iteration 1914500 (16.7971 iter/s, 29.767s/500 iters), loss = 0.0802419
I0830 17:25:11.822073 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0802447 (* 1 = 0.0802447 loss)
I0830 17:25:11.822082 916722 sgd_solver.cpp:106] Iteration 1914500, lr = 0.01
I0830 17:25:41.590224 916722 solver.cpp:218] Iteration 1915000 (16.7964 iter/s, 29.7682s/500 iters), loss = 0.246449
I0830 17:25:41.590278 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.246452 (* 1 = 0.246452 loss)
I0830 17:25:41.590289 916722 sgd_solver.cpp:106] Iteration 1915000, lr = 0.01
I0830 17:26:11.372582 916722 solver.cpp:218] Iteration 1915500 (16.7885 iter/s, 29.7824s/500 iters), loss = 0.129051
I0830 17:26:11.372646 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.129053 (* 1 = 0.129053 loss)
I0830 17:26:11.372655 916722 sgd_solver.cpp:106] Iteration 1915500, lr = 0.01
I0830 17:26:41.141716 916722 solver.cpp:218] Iteration 1916000 (16.7959 iter/s, 29.7691s/500 iters), loss = 0.133481
I0830 17:26:41.141772 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133484 (* 1 = 0.133484 loss)
I0830 17:26:41.141782 916722 sgd_solver.cpp:106] Iteration 1916000, lr = 0.01
I0830 17:27:10.910202 916722 solver.cpp:218] Iteration 1916500 (16.7963 iter/s, 29.7685s/500 iters), loss = 0.102252
I0830 17:27:10.910264 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.102255 (* 1 = 0.102255 loss)
I0830 17:27:10.910272 916722 sgd_solver.cpp:106] Iteration 1916500, lr = 0.01
I0830 17:27:40.679044 916722 solver.cpp:218] Iteration 1917000 (16.7961 iter/s, 29.7688s/500 iters), loss = 0.133502
I0830 17:27:40.679096 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133504 (* 1 = 0.133504 loss)
I0830 17:27:40.679106 916722 sgd_solver.cpp:106] Iteration 1917000, lr = 0.01
I0830 17:28:10.446565 916722 solver.cpp:218] Iteration 1917500 (16.7968 iter/s, 29.7675s/500 iters), loss = 0.120602
I0830 17:28:10.446626 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.120605 (* 1 = 0.120605 loss)
I0830 17:28:10.446635 916722 sgd_solver.cpp:106] Iteration 1917500, lr = 0.01
I0830 17:28:40.214928 916722 solver.cpp:218] Iteration 1918000 (16.7964 iter/s, 29.7683s/500 iters), loss = 0.0916163
I0830 17:28:40.214982 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0916188 (* 1 = 0.0916188 loss)
I0830 17:28:40.214993 916722 sgd_solver.cpp:106] Iteration 1918000, lr = 0.01
I0830 17:29:09.983870 916722 solver.cpp:218] Iteration 1918500 (16.7961 iter/s, 29.7689s/500 iters), loss = 0.249564
I0830 17:29:09.983937 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.249567 (* 1 = 0.249567 loss)
I0830 17:29:09.983945 916722 sgd_solver.cpp:106] Iteration 1918500, lr = 0.01
I0830 17:29:39.748000 916722 solver.cpp:218] Iteration 1919000 (16.7988 iter/s, 29.7641s/500 iters), loss = 0.155454
I0830 17:29:39.748054 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.155456 (* 1 = 0.155456 loss)
I0830 17:29:39.748065 916722 sgd_solver.cpp:106] Iteration 1919000, lr = 0.01
I0830 17:30:09.515448 916722 solver.cpp:218] Iteration 1919500 (16.7969 iter/s, 29.7674s/500 iters), loss = 0.165794
I0830 17:30:09.515508 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.165797 (* 1 = 0.165797 loss)
I0830 17:30:09.515517 916722 sgd_solver.cpp:106] Iteration 1919500, lr = 0.01
I0830 17:30:39.285933 916722 solver.cpp:218] Iteration 1920000 (16.7952 iter/s, 29.7704s/500 iters), loss = 0.11056
I0830 17:30:39.285987 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110563 (* 1 = 0.110563 loss)
I0830 17:30:39.285997 916722 sgd_solver.cpp:106] Iteration 1920000, lr = 0.01
I0830 17:31:09.060022 916722 solver.cpp:218] Iteration 1920500 (16.7932 iter/s, 29.774s/500 iters), loss = 0.0613947
I0830 17:31:09.060086 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0613971 (* 1 = 0.0613971 loss)
I0830 17:31:09.060094 916722 sgd_solver.cpp:106] Iteration 1920500, lr = 0.01
I0830 17:31:38.825696 916722 solver.cpp:218] Iteration 1921000 (16.7979 iter/s, 29.7656s/500 iters), loss = 0.177199
I0830 17:31:38.825744 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.177201 (* 1 = 0.177201 loss)
I0830 17:31:38.825753 916722 sgd_solver.cpp:106] Iteration 1921000, lr = 0.01
I0830 17:32:08.591642 916722 solver.cpp:218] Iteration 1921500 (16.7978 iter/s, 29.7659s/500 iters), loss = 0.174208
I0830 17:32:08.591701 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.17421 (* 1 = 0.17421 loss)
I0830 17:32:08.591711 916722 sgd_solver.cpp:106] Iteration 1921500, lr = 0.01
I0830 17:32:38.768489 916722 solver.cpp:218] Iteration 1922000 (16.569 iter/s, 30.1768s/500 iters), loss = 0.196573
I0830 17:32:38.768554 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.196576 (* 1 = 0.196576 loss)
I0830 17:32:38.768564 916722 sgd_solver.cpp:106] Iteration 1922000, lr = 0.01
I0830 17:33:08.760282 916722 solver.cpp:218] Iteration 1922500 (16.6713 iter/s, 29.9917s/500 iters), loss = 0.0903652
I0830 17:33:08.760344 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0903674 (* 1 = 0.0903674 loss)
I0830 17:33:08.760357 916722 sgd_solver.cpp:106] Iteration 1922500, lr = 0.01
I0830 17:33:38.729506 916722 solver.cpp:218] Iteration 1923000 (16.6838 iter/s, 29.9691s/500 iters), loss = 0.141377
I0830 17:33:38.729576 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.141379 (* 1 = 0.141379 loss)
I0830 17:33:38.729588 916722 sgd_solver.cpp:106] Iteration 1923000, lr = 0.01
I0830 17:34:08.619100 916722 solver.cpp:218] Iteration 1923500 (16.7283 iter/s, 29.8895s/500 iters), loss = 0.277757
I0830 17:34:08.619158 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.277759 (* 1 = 0.277759 loss)
I0830 17:34:08.619169 916722 sgd_solver.cpp:106] Iteration 1923500, lr = 0.01
I0830 17:34:38.400712 916722 solver.cpp:218] Iteration 1924000 (16.7889 iter/s, 29.7815s/500 iters), loss = 0.250136
I0830 17:34:38.400787 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.250138 (* 1 = 0.250138 loss)
I0830 17:34:38.400795 916722 sgd_solver.cpp:106] Iteration 1924000, lr = 0.01
I0830 17:35:08.189098 916722 solver.cpp:218] Iteration 1924500 (16.7851 iter/s, 29.7883s/500 iters), loss = 0.0255613
I0830 17:35:08.189169 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0255633 (* 1 = 0.0255633 loss)
I0830 17:35:08.189180 916722 sgd_solver.cpp:106] Iteration 1924500, lr = 0.01
I0830 17:35:37.944245 916722 solver.cpp:218] Iteration 1925000 (16.8039 iter/s, 29.755s/500 iters), loss = 0.0566471
I0830 17:35:37.944320 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0566492 (* 1 = 0.0566492 loss)
I0830 17:35:37.944329 916722 sgd_solver.cpp:106] Iteration 1925000, lr = 0.01
I0830 17:36:07.698137 916722 solver.cpp:218] Iteration 1925500 (16.8046 iter/s, 29.7538s/500 iters), loss = 0.0985634
I0830 17:36:07.698194 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0985657 (* 1 = 0.0985657 loss)
I0830 17:36:07.698204 916722 sgd_solver.cpp:106] Iteration 1925500, lr = 0.01
I0830 17:36:37.457415 916722 solver.cpp:218] Iteration 1926000 (16.8015 iter/s, 29.7592s/500 iters), loss = 0.12136
I0830 17:36:37.457479 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.121363 (* 1 = 0.121363 loss)
I0830 17:36:37.457487 916722 sgd_solver.cpp:106] Iteration 1926000, lr = 0.01
I0830 17:37:07.213285 916722 solver.cpp:218] Iteration 1926500 (16.8035 iter/s, 29.7558s/500 iters), loss = 0.191884
I0830 17:37:07.213338 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.191886 (* 1 = 0.191886 loss)
I0830 17:37:07.213348 916722 sgd_solver.cpp:106] Iteration 1926500, lr = 0.01
I0830 17:37:36.969815 916722 solver.cpp:218] Iteration 1927000 (16.8031 iter/s, 29.7564s/500 iters), loss = 0.138962
I0830 17:37:36.969877 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.138964 (* 1 = 0.138964 loss)
I0830 17:37:36.969885 916722 sgd_solver.cpp:106] Iteration 1927000, lr = 0.01
I0830 17:38:06.727671 916722 solver.cpp:218] Iteration 1927500 (16.8024 iter/s, 29.7577s/500 iters), loss = 0.239215
I0830 17:38:06.727727 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.239217 (* 1 = 0.239217 loss)
I0830 17:38:06.727737 916722 sgd_solver.cpp:106] Iteration 1927500, lr = 0.01
I0830 17:38:36.483865 916722 solver.cpp:218] Iteration 1928000 (16.8033 iter/s, 29.7561s/500 iters), loss = 0.204733
I0830 17:38:36.483929 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.204736 (* 1 = 0.204736 loss)
I0830 17:38:36.483938 916722 sgd_solver.cpp:106] Iteration 1928000, lr = 0.01
I0830 17:39:06.238682 916722 solver.cpp:218] Iteration 1928500 (16.8041 iter/s, 29.7547s/500 iters), loss = 0.31853
I0830 17:39:06.238734 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.318532 (* 1 = 0.318532 loss)
I0830 17:39:06.238744 916722 sgd_solver.cpp:106] Iteration 1928500, lr = 0.01
I0830 17:39:35.992359 916722 solver.cpp:218] Iteration 1929000 (16.8047 iter/s, 29.7536s/500 iters), loss = 0.163946
I0830 17:39:35.992422 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.163948 (* 1 = 0.163948 loss)
I0830 17:39:35.992436 916722 sgd_solver.cpp:106] Iteration 1929000, lr = 0.01
I0830 17:40:05.746609 916722 solver.cpp:218] Iteration 1929500 (16.8044 iter/s, 29.7541s/500 iters), loss = 0.317606
I0830 17:40:05.746663 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.317608 (* 1 = 0.317608 loss)
I0830 17:40:05.746675 916722 sgd_solver.cpp:106] Iteration 1929500, lr = 0.01
I0830 17:40:35.497200 916722 solver.cpp:218] Iteration 1930000 (16.8065 iter/s, 29.7505s/500 iters), loss = 0.107375
I0830 17:40:35.497262 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.107377 (* 1 = 0.107377 loss)
I0830 17:40:35.497269 916722 sgd_solver.cpp:106] Iteration 1930000, lr = 0.01
I0830 17:41:05.251021 916722 solver.cpp:218] Iteration 1930500 (16.8046 iter/s, 29.7537s/500 iters), loss = 0.0975487
I0830 17:41:05.251075 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0975507 (* 1 = 0.0975507 loss)
I0830 17:41:05.251085 916722 sgd_solver.cpp:106] Iteration 1930500, lr = 0.01
I0830 17:41:35.004091 916722 solver.cpp:218] Iteration 1931000 (16.8051 iter/s, 29.7529s/500 iters), loss = 0.268497
I0830 17:41:35.004163 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.268499 (* 1 = 0.268499 loss)
I0830 17:41:35.004170 916722 sgd_solver.cpp:106] Iteration 1931000, lr = 0.01
I0830 17:42:04.757643 916722 solver.cpp:218] Iteration 1931500 (16.8048 iter/s, 29.7534s/500 iters), loss = 0.0148903
I0830 17:42:04.757696 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0148924 (* 1 = 0.0148924 loss)
I0830 17:42:04.757706 916722 sgd_solver.cpp:106] Iteration 1931500, lr = 0.01
I0830 17:42:34.509783 916722 solver.cpp:218] Iteration 1932000 (16.8056 iter/s, 29.752s/500 iters), loss = 0.0816648
I0830 17:42:34.509847 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0816671 (* 1 = 0.0816671 loss)
I0830 17:42:34.509856 916722 sgd_solver.cpp:106] Iteration 1932000, lr = 0.01
I0830 17:43:04.264250 916722 solver.cpp:218] Iteration 1932500 (16.8043 iter/s, 29.7543s/500 iters), loss = 0.0748133
I0830 17:43:04.264303 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0748155 (* 1 = 0.0748155 loss)
I0830 17:43:04.264312 916722 sgd_solver.cpp:106] Iteration 1932500, lr = 0.01
I0830 17:43:34.020109 916722 solver.cpp:218] Iteration 1933000 (16.8035 iter/s, 29.7557s/500 iters), loss = 0.0646103
I0830 17:43:34.020171 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0646126 (* 1 = 0.0646126 loss)
I0830 17:43:34.020179 916722 sgd_solver.cpp:106] Iteration 1933000, lr = 0.01
I0830 17:44:03.772680 916722 solver.cpp:218] Iteration 1933500 (16.8053 iter/s, 29.7524s/500 iters), loss = 0.199521
I0830 17:44:03.772732 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.199523 (* 1 = 0.199523 loss)
I0830 17:44:03.772751 916722 sgd_solver.cpp:106] Iteration 1933500, lr = 0.01
I0830 17:44:33.526054 916722 solver.cpp:218] Iteration 1934000 (16.8049 iter/s, 29.7533s/500 iters), loss = 0.257839
I0830 17:44:33.526116 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.257841 (* 1 = 0.257841 loss)
I0830 17:44:33.526125 916722 sgd_solver.cpp:106] Iteration 1934000, lr = 0.01
I0830 17:45:03.282953 916722 solver.cpp:218] Iteration 1934500 (16.8029 iter/s, 29.7568s/500 iters), loss = 0.161089
I0830 17:45:03.283011 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.161091 (* 1 = 0.161091 loss)
I0830 17:45:03.283021 916722 sgd_solver.cpp:106] Iteration 1934500, lr = 0.01
I0830 17:45:33.037072 916722 solver.cpp:218] Iteration 1935000 (16.8045 iter/s, 29.754s/500 iters), loss = 0.317535
I0830 17:45:33.037128 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.317538 (* 1 = 0.317538 loss)
I0830 17:45:33.037137 916722 sgd_solver.cpp:106] Iteration 1935000, lr = 0.01
I0830 17:46:02.790822 916722 solver.cpp:218] Iteration 1935500 (16.8047 iter/s, 29.7536s/500 iters), loss = 0.106684
I0830 17:46:02.790872 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.106687 (* 1 = 0.106687 loss)
I0830 17:46:02.790881 916722 sgd_solver.cpp:106] Iteration 1935500, lr = 0.01
I0830 17:46:32.547432 916722 solver.cpp:218] Iteration 1936000 (16.8031 iter/s, 29.7565s/500 iters), loss = 0.0661014
I0830 17:46:32.547492 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0661037 (* 1 = 0.0661037 loss)
I0830 17:46:32.547500 916722 sgd_solver.cpp:106] Iteration 1936000, lr = 0.01
I0830 17:47:02.301649 916722 solver.cpp:218] Iteration 1936500 (16.8044 iter/s, 29.7541s/500 iters), loss = 0.0857577
I0830 17:47:02.301702 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.08576 (* 1 = 0.08576 loss)
I0830 17:47:02.301710 916722 sgd_solver.cpp:106] Iteration 1936500, lr = 0.01
I0830 17:47:32.055251 916722 solver.cpp:218] Iteration 1937000 (16.8048 iter/s, 29.7535s/500 iters), loss = 0.168421
I0830 17:47:32.055315 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.168423 (* 1 = 0.168423 loss)
I0830 17:47:32.055322 916722 sgd_solver.cpp:106] Iteration 1937000, lr = 0.01
I0830 17:48:01.805681 916722 solver.cpp:218] Iteration 1937500 (16.8066 iter/s, 29.7503s/500 iters), loss = 0.108563
I0830 17:48:01.805743 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.108566 (* 1 = 0.108566 loss)
I0830 17:48:01.805752 916722 sgd_solver.cpp:106] Iteration 1937500, lr = 0.01
I0830 17:48:31.557796 916722 solver.cpp:218] Iteration 1938000 (16.8056 iter/s, 29.752s/500 iters), loss = 0.0500846
I0830 17:48:31.557871 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0500868 (* 1 = 0.0500868 loss)
I0830 17:48:31.557880 916722 sgd_solver.cpp:106] Iteration 1938000, lr = 0.01
I0830 17:49:01.312960 916722 solver.cpp:218] Iteration 1938500 (16.8039 iter/s, 29.755s/500 iters), loss = 0.326869
I0830 17:49:01.313012 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.326871 (* 1 = 0.326871 loss)
I0830 17:49:01.313021 916722 sgd_solver.cpp:106] Iteration 1938500, lr = 0.01
I0830 17:49:31.065464 916722 solver.cpp:218] Iteration 1939000 (16.8054 iter/s, 29.7524s/500 iters), loss = 0.182558
I0830 17:49:31.065524 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.18256 (* 1 = 0.18256 loss)
I0830 17:49:31.065533 916722 sgd_solver.cpp:106] Iteration 1939000, lr = 0.01
I0830 17:50:00.819177 916722 solver.cpp:218] Iteration 1939500 (16.8047 iter/s, 29.7536s/500 iters), loss = 0.0830667
I0830 17:50:00.819231 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.083069 (* 1 = 0.083069 loss)
I0830 17:50:00.819240 916722 sgd_solver.cpp:106] Iteration 1939500, lr = 0.01
I0830 17:50:30.570500 916722 solver.cpp:218] Iteration 1940000 (16.8061 iter/s, 29.7512s/500 iters), loss = 0.299273
I0830 17:50:30.570559 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.299276 (* 1 = 0.299276 loss)
I0830 17:50:30.570567 916722 sgd_solver.cpp:106] Iteration 1940000, lr = 0.01
I0830 17:51:00.326541 916722 solver.cpp:218] Iteration 1940500 (16.8034 iter/s, 29.7559s/500 iters), loss = 0.190512
I0830 17:51:00.326591 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.190514 (* 1 = 0.190514 loss)
I0830 17:51:00.326601 916722 sgd_solver.cpp:106] Iteration 1940500, lr = 0.01
I0830 17:51:30.077497 916722 solver.cpp:218] Iteration 1941000 (16.8063 iter/s, 29.7508s/500 iters), loss = 0.132177
I0830 17:51:30.077558 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13218 (* 1 = 0.13218 loss)
I0830 17:51:30.077566 916722 sgd_solver.cpp:106] Iteration 1941000, lr = 0.01
I0830 17:51:59.827726 916722 solver.cpp:218] Iteration 1941500 (16.8067 iter/s, 29.7501s/500 iters), loss = 0.261133
I0830 17:51:59.827782 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.261135 (* 1 = 0.261135 loss)
I0830 17:51:59.827792 916722 sgd_solver.cpp:106] Iteration 1941500, lr = 0.01
I0830 17:52:29.579607 916722 solver.cpp:218] Iteration 1942000 (16.8057 iter/s, 29.7517s/500 iters), loss = 0.275938
I0830 17:52:29.579669 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.275941 (* 1 = 0.275941 loss)
I0830 17:52:29.579677 916722 sgd_solver.cpp:106] Iteration 1942000, lr = 0.01
I0830 17:52:59.328186 916722 solver.cpp:218] Iteration 1942500 (16.8076 iter/s, 29.7484s/500 iters), loss = 0.0615862
I0830 17:52:59.328241 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0615886 (* 1 = 0.0615886 loss)
I0830 17:52:59.328251 916722 sgd_solver.cpp:106] Iteration 1942500, lr = 0.01
I0830 17:53:29.080142 916722 solver.cpp:218] Iteration 1943000 (16.8057 iter/s, 29.7518s/500 iters), loss = 0.0483004
I0830 17:53:29.080204 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0483031 (* 1 = 0.0483031 loss)
I0830 17:53:29.080212 916722 sgd_solver.cpp:106] Iteration 1943000, lr = 0.01
I0830 17:53:58.829937 916722 solver.cpp:218] Iteration 1943500 (16.8069 iter/s, 29.7496s/500 iters), loss = 0.224036
I0830 17:53:58.829990 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.224039 (* 1 = 0.224039 loss)
I0830 17:53:58.830000 916722 sgd_solver.cpp:106] Iteration 1943500, lr = 0.01
I0830 17:54:28.582983 916722 solver.cpp:218] Iteration 1944000 (16.8051 iter/s, 29.7529s/500 iters), loss = 0.118131
I0830 17:54:28.583053 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.118134 (* 1 = 0.118134 loss)
I0830 17:54:28.583065 916722 sgd_solver.cpp:106] Iteration 1944000, lr = 0.01
I0830 17:54:58.336973 916722 solver.cpp:218] Iteration 1944500 (16.8046 iter/s, 29.7538s/500 iters), loss = 0.134607
I0830 17:54:58.337026 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13461 (* 1 = 0.13461 loss)
I0830 17:54:58.337036 916722 sgd_solver.cpp:106] Iteration 1944500, lr = 0.01
I0830 17:55:28.089391 916722 solver.cpp:218] Iteration 1945000 (16.8054 iter/s, 29.7523s/500 iters), loss = 0.202191
I0830 17:55:28.089452 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.202194 (* 1 = 0.202194 loss)
I0830 17:55:28.089459 916722 sgd_solver.cpp:106] Iteration 1945000, lr = 0.01
I0830 17:55:57.843006 916722 solver.cpp:218] Iteration 1945500 (16.8048 iter/s, 29.7535s/500 iters), loss = 0.0377594
I0830 17:55:57.843061 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0377619 (* 1 = 0.0377619 loss)
I0830 17:55:57.843070 916722 sgd_solver.cpp:106] Iteration 1945500, lr = 0.01
I0830 17:56:27.591425 916722 solver.cpp:218] Iteration 1946000 (16.8077 iter/s, 29.7483s/500 iters), loss = 0.0629256
I0830 17:56:27.591486 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0629281 (* 1 = 0.0629281 loss)
I0830 17:56:27.591495 916722 sgd_solver.cpp:106] Iteration 1946000, lr = 0.01
I0830 17:56:57.366544 916722 solver.cpp:218] Iteration 1946500 (16.7926 iter/s, 29.775s/500 iters), loss = 0.170961
I0830 17:56:57.366602 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.170964 (* 1 = 0.170964 loss)
I0830 17:56:57.366612 916722 sgd_solver.cpp:106] Iteration 1946500, lr = 0.01
I0830 17:57:27.139382 916722 solver.cpp:218] Iteration 1947000 (16.7939 iter/s, 29.7727s/500 iters), loss = 0.225577
I0830 17:57:27.139447 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.225579 (* 1 = 0.225579 loss)
I0830 17:57:27.139456 916722 sgd_solver.cpp:106] Iteration 1947000, lr = 0.01
I0830 17:57:56.904546 916722 solver.cpp:218] Iteration 1947500 (16.7983 iter/s, 29.765s/500 iters), loss = 0.221519
I0830 17:57:56.904601 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.221521 (* 1 = 0.221521 loss)
I0830 17:57:56.904609 916722 sgd_solver.cpp:106] Iteration 1947500, lr = 0.01
I0830 17:58:26.671860 916722 solver.cpp:218] Iteration 1948000 (16.797 iter/s, 29.7672s/500 iters), loss = 0.0827979
I0830 17:58:26.671921 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0828006 (* 1 = 0.0828006 loss)
I0830 17:58:26.671931 916722 sgd_solver.cpp:106] Iteration 1948000, lr = 0.01
I0830 17:58:56.439391 916722 solver.cpp:218] Iteration 1948500 (16.7969 iter/s, 29.7674s/500 iters), loss = 0.422438
I0830 17:58:56.439445 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.422441 (* 1 = 0.422441 loss)
I0830 17:58:56.439453 916722 sgd_solver.cpp:106] Iteration 1948500, lr = 0.01
I0830 17:59:26.201927 916722 solver.cpp:218] Iteration 1949000 (16.7997 iter/s, 29.7624s/500 iters), loss = 0.15886
I0830 17:59:26.201984 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.158863 (* 1 = 0.158863 loss)
I0830 17:59:26.201992 916722 sgd_solver.cpp:106] Iteration 1949000, lr = 0.01
I0830 17:59:55.972353 916722 solver.cpp:218] Iteration 1949500 (16.7953 iter/s, 29.7703s/500 iters), loss = 0.185618
I0830 17:59:55.972406 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.185622 (* 1 = 0.185622 loss)
I0830 17:59:55.972415 916722 sgd_solver.cpp:106] Iteration 1949500, lr = 0.01
I0830 18:00:25.679910 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_1950000.caffemodel
I0830 18:00:25.699407 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_1950000.solverstate
I0830 18:00:25.705580 916722 solver.cpp:330] Iteration 1950000, Testing net (#0)
I0830 18:00:41.090632 916722 solver.cpp:397]     Test net output #0: accuracy = 0.879
I0830 18:00:41.090679 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.435954 (* 1 = 0.435954 loss)
I0830 18:00:41.149216 916722 solver.cpp:218] Iteration 1950000 (11.0677 iter/s, 45.1767s/500 iters), loss = 0.163446
I0830 18:00:41.149245 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.163449 (* 1 = 0.163449 loss)
I0830 18:00:41.149252 916722 sgd_solver.cpp:106] Iteration 1950000, lr = 0.01
I0830 18:01:10.829412 916722 solver.cpp:218] Iteration 1950500 (16.8463 iter/s, 29.68s/500 iters), loss = 0.182538
I0830 18:01:10.829483 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.182541 (* 1 = 0.182541 loss)
I0830 18:01:10.829492 916722 sgd_solver.cpp:106] Iteration 1950500, lr = 0.01
I0830 18:01:40.556087 916722 solver.cpp:218] Iteration 1951000 (16.82 iter/s, 29.7265s/500 iters), loss = 0.353795
I0830 18:01:40.556138 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.353798 (* 1 = 0.353798 loss)
I0830 18:01:40.556145 916722 sgd_solver.cpp:106] Iteration 1951000, lr = 0.01
I0830 18:02:10.280669 916722 solver.cpp:218] Iteration 1951500 (16.8212 iter/s, 29.7244s/500 iters), loss = 0.0688007
I0830 18:02:10.280728 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0688035 (* 1 = 0.0688035 loss)
I0830 18:02:10.280737 916722 sgd_solver.cpp:106] Iteration 1951500, lr = 0.01
I0830 18:02:40.006220 916722 solver.cpp:218] Iteration 1952000 (16.8206 iter/s, 29.7254s/500 iters), loss = 0.0670629
I0830 18:02:40.006275 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0670657 (* 1 = 0.0670657 loss)
I0830 18:02:40.006283 916722 sgd_solver.cpp:106] Iteration 1952000, lr = 0.01
I0830 18:03:09.735972 916722 solver.cpp:218] Iteration 1952500 (16.8183 iter/s, 29.7296s/500 iters), loss = 0.0839291
I0830 18:03:09.736030 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0839318 (* 1 = 0.0839318 loss)
I0830 18:03:09.736039 916722 sgd_solver.cpp:106] Iteration 1952500, lr = 0.01
I0830 18:03:39.467483 916722 solver.cpp:218] Iteration 1953000 (16.8173 iter/s, 29.7314s/500 iters), loss = 0.058327
I0830 18:03:39.467535 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0583298 (* 1 = 0.0583298 loss)
I0830 18:03:39.467543 916722 sgd_solver.cpp:106] Iteration 1953000, lr = 0.01
I0830 18:04:09.201356 916722 solver.cpp:218] Iteration 1953500 (16.8159 iter/s, 29.7337s/500 iters), loss = 0.0650476
I0830 18:04:09.201416 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0650503 (* 1 = 0.0650503 loss)
I0830 18:04:09.201424 916722 sgd_solver.cpp:106] Iteration 1953500, lr = 0.01
I0830 18:04:38.934489 916722 solver.cpp:218] Iteration 1954000 (16.8163 iter/s, 29.733s/500 iters), loss = 0.204277
I0830 18:04:38.934545 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.20428 (* 1 = 0.20428 loss)
I0830 18:04:38.934556 916722 sgd_solver.cpp:106] Iteration 1954000, lr = 0.01
I0830 18:05:08.660058 916722 solver.cpp:218] Iteration 1954500 (16.8206 iter/s, 29.7254s/500 iters), loss = 0.230873
I0830 18:05:08.660115 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.230875 (* 1 = 0.230875 loss)
I0830 18:05:08.660125 916722 sgd_solver.cpp:106] Iteration 1954500, lr = 0.01
I0830 18:05:38.391204 916722 solver.cpp:218] Iteration 1955000 (16.8175 iter/s, 29.731s/500 iters), loss = 0.0439239
I0830 18:05:38.391258 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0439268 (* 1 = 0.0439268 loss)
I0830 18:05:38.391268 916722 sgd_solver.cpp:106] Iteration 1955000, lr = 0.01
I0830 18:06:08.123618 916722 solver.cpp:218] Iteration 1955500 (16.8167 iter/s, 29.7323s/500 iters), loss = 0.0581599
I0830 18:06:08.123677 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0581628 (* 1 = 0.0581628 loss)
I0830 18:06:08.123685 916722 sgd_solver.cpp:106] Iteration 1955500, lr = 0.01
I0830 18:06:37.856060 916722 solver.cpp:218] Iteration 1956000 (16.8167 iter/s, 29.7323s/500 iters), loss = 0.172653
I0830 18:06:37.856110 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.172656 (* 1 = 0.172656 loss)
I0830 18:06:37.856119 916722 sgd_solver.cpp:106] Iteration 1956000, lr = 0.01
I0830 18:07:07.586176 916722 solver.cpp:218] Iteration 1956500 (16.8182 iter/s, 29.7298s/500 iters), loss = 0.160032
I0830 18:07:07.586243 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.160035 (* 1 = 0.160035 loss)
I0830 18:07:07.586252 916722 sgd_solver.cpp:106] Iteration 1956500, lr = 0.01
I0830 18:07:37.320981 916722 solver.cpp:218] Iteration 1957000 (16.8156 iter/s, 29.7343s/500 iters), loss = 0.110671
I0830 18:07:37.321035 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110674 (* 1 = 0.110674 loss)
I0830 18:07:37.321045 916722 sgd_solver.cpp:106] Iteration 1957000, lr = 0.01
I0830 18:08:07.048952 916722 solver.cpp:218] Iteration 1957500 (16.8195 iter/s, 29.7275s/500 iters), loss = 0.286721
I0830 18:08:07.049010 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.286723 (* 1 = 0.286723 loss)
I0830 18:08:07.049019 916722 sgd_solver.cpp:106] Iteration 1957500, lr = 0.01
I0830 18:08:36.778695 916722 solver.cpp:218] Iteration 1958000 (16.8185 iter/s, 29.7292s/500 iters), loss = 0.29435
I0830 18:08:36.778746 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.294353 (* 1 = 0.294353 loss)
I0830 18:08:36.778756 916722 sgd_solver.cpp:106] Iteration 1958000, lr = 0.01
I0830 18:09:06.507424 916722 solver.cpp:218] Iteration 1958500 (16.819 iter/s, 29.7282s/500 iters), loss = 0.0190641
I0830 18:09:06.507481 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.019067 (* 1 = 0.019067 loss)
I0830 18:09:06.507489 916722 sgd_solver.cpp:106] Iteration 1958500, lr = 0.01
I0830 18:09:36.241421 916722 solver.cpp:218] Iteration 1959000 (16.816 iter/s, 29.7335s/500 iters), loss = 0.273326
I0830 18:09:36.241473 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.273329 (* 1 = 0.273329 loss)
I0830 18:09:36.241483 916722 sgd_solver.cpp:106] Iteration 1959000, lr = 0.01
I0830 18:10:05.977164 916722 solver.cpp:218] Iteration 1959500 (16.815 iter/s, 29.7353s/500 iters), loss = 0.192076
I0830 18:10:05.977221 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.192079 (* 1 = 0.192079 loss)
I0830 18:10:05.977229 916722 sgd_solver.cpp:106] Iteration 1959500, lr = 0.01
I0830 18:10:35.705492 916722 solver.cpp:218] Iteration 1960000 (16.8192 iter/s, 29.7279s/500 iters), loss = 0.240901
I0830 18:10:35.705543 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.240904 (* 1 = 0.240904 loss)
I0830 18:10:35.705552 916722 sgd_solver.cpp:106] Iteration 1960000, lr = 0.01
I0830 18:11:05.435509 916722 solver.cpp:218] Iteration 1960500 (16.8183 iter/s, 29.7296s/500 iters), loss = 0.201929
I0830 18:11:05.435567 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.201932 (* 1 = 0.201932 loss)
I0830 18:11:05.435575 916722 sgd_solver.cpp:106] Iteration 1960500, lr = 0.01
I0830 18:11:35.167213 916722 solver.cpp:218] Iteration 1961000 (16.8173 iter/s, 29.7313s/500 iters), loss = 0.295776
I0830 18:11:35.167266 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.295779 (* 1 = 0.295779 loss)
I0830 18:11:35.167276 916722 sgd_solver.cpp:106] Iteration 1961000, lr = 0.01
I0830 18:12:04.898622 916722 solver.cpp:218] Iteration 1961500 (16.8175 iter/s, 29.731s/500 iters), loss = 0.128787
I0830 18:12:04.898680 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128789 (* 1 = 0.128789 loss)
I0830 18:12:04.898689 916722 sgd_solver.cpp:106] Iteration 1961500, lr = 0.01
I0830 18:12:34.631762 916722 solver.cpp:218] Iteration 1962000 (16.8165 iter/s, 29.7327s/500 iters), loss = 0.354862
I0830 18:12:34.631817 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.354864 (* 1 = 0.354864 loss)
I0830 18:12:34.631827 916722 sgd_solver.cpp:106] Iteration 1962000, lr = 0.01
I0830 18:13:04.357404 916722 solver.cpp:218] Iteration 1962500 (16.8207 iter/s, 29.7253s/500 iters), loss = 0.141069
I0830 18:13:04.357461 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.141071 (* 1 = 0.141071 loss)
I0830 18:13:04.357470 916722 sgd_solver.cpp:106] Iteration 1962500, lr = 0.01
I0830 18:13:34.086939 916722 solver.cpp:218] Iteration 1963000 (16.8185 iter/s, 29.7292s/500 iters), loss = 0.220908
I0830 18:13:34.087005 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.220911 (* 1 = 0.220911 loss)
I0830 18:13:34.087015 916722 sgd_solver.cpp:106] Iteration 1963000, lr = 0.01
I0830 18:14:03.814885 916722 solver.cpp:218] Iteration 1963500 (16.8194 iter/s, 29.7276s/500 iters), loss = 0.144393
I0830 18:14:03.814952 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.144396 (* 1 = 0.144396 loss)
I0830 18:14:03.814961 916722 sgd_solver.cpp:106] Iteration 1963500, lr = 0.01
I0830 18:14:33.546010 916722 solver.cpp:218] Iteration 1964000 (16.8176 iter/s, 29.7308s/500 iters), loss = 0.191088
I0830 18:14:33.546063 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.19109 (* 1 = 0.19109 loss)
I0830 18:14:33.546073 916722 sgd_solver.cpp:106] Iteration 1964000, lr = 0.01
I0830 18:15:03.271378 916722 solver.cpp:218] Iteration 1964500 (16.8208 iter/s, 29.725s/500 iters), loss = 0.27739
I0830 18:15:03.271435 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.277393 (* 1 = 0.277393 loss)
I0830 18:15:03.271443 916722 sgd_solver.cpp:106] Iteration 1964500, lr = 0.01
I0830 18:15:32.999315 916722 solver.cpp:218] Iteration 1965000 (16.8194 iter/s, 29.7276s/500 iters), loss = 0.112091
I0830 18:15:32.999366 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112094 (* 1 = 0.112094 loss)
I0830 18:15:32.999373 916722 sgd_solver.cpp:106] Iteration 1965000, lr = 0.01
I0830 18:16:02.729501 916722 solver.cpp:218] Iteration 1965500 (16.8181 iter/s, 29.7299s/500 iters), loss = 0.149537
I0830 18:16:02.729559 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.14954 (* 1 = 0.14954 loss)
I0830 18:16:02.729568 916722 sgd_solver.cpp:106] Iteration 1965500, lr = 0.01
I0830 18:16:32.463191 916722 solver.cpp:218] Iteration 1966000 (16.8161 iter/s, 29.7334s/500 iters), loss = 0.347081
I0830 18:16:32.463244 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.347083 (* 1 = 0.347083 loss)
I0830 18:16:32.463253 916722 sgd_solver.cpp:106] Iteration 1966000, lr = 0.01
I0830 18:17:02.191478 916722 solver.cpp:218] Iteration 1966500 (16.8192 iter/s, 29.728s/500 iters), loss = 0.156088
I0830 18:17:02.191536 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.15609 (* 1 = 0.15609 loss)
I0830 18:17:02.191545 916722 sgd_solver.cpp:106] Iteration 1966500, lr = 0.01
I0830 18:17:31.918021 916722 solver.cpp:218] Iteration 1967000 (16.8202 iter/s, 29.7262s/500 iters), loss = 0.0581162
I0830 18:17:31.918073 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0581186 (* 1 = 0.0581186 loss)
I0830 18:17:31.918082 916722 sgd_solver.cpp:106] Iteration 1967000, lr = 0.01
I0830 18:18:01.644979 916722 solver.cpp:218] Iteration 1967500 (16.8199 iter/s, 29.7267s/500 iters), loss = 0.0377631
I0830 18:18:01.645037 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0377655 (* 1 = 0.0377655 loss)
I0830 18:18:01.645045 916722 sgd_solver.cpp:106] Iteration 1967500, lr = 0.01
I0830 18:18:31.372906 916722 solver.cpp:218] Iteration 1968000 (16.8194 iter/s, 29.7276s/500 iters), loss = 0.237715
I0830 18:18:31.372961 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.237717 (* 1 = 0.237717 loss)
I0830 18:18:31.372970 916722 sgd_solver.cpp:106] Iteration 1968000, lr = 0.01
I0830 18:19:01.104977 916722 solver.cpp:218] Iteration 1968500 (16.817 iter/s, 29.7318s/500 iters), loss = 0.391138
I0830 18:19:01.105036 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.391141 (* 1 = 0.391141 loss)
I0830 18:19:01.105044 916722 sgd_solver.cpp:106] Iteration 1968500, lr = 0.01
I0830 18:19:30.832609 916722 solver.cpp:218] Iteration 1969000 (16.8195 iter/s, 29.7273s/500 iters), loss = 0.0428738
I0830 18:19:30.832665 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0428762 (* 1 = 0.0428762 loss)
I0830 18:19:30.832674 916722 sgd_solver.cpp:106] Iteration 1969000, lr = 0.01
I0830 18:20:00.560214 916722 solver.cpp:218] Iteration 1969500 (16.8195 iter/s, 29.7273s/500 iters), loss = 0.126669
I0830 18:20:00.560286 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.126671 (* 1 = 0.126671 loss)
I0830 18:20:00.560293 916722 sgd_solver.cpp:106] Iteration 1969500, lr = 0.01
I0830 18:20:30.284288 916722 solver.cpp:218] Iteration 1970000 (16.8216 iter/s, 29.7238s/500 iters), loss = 0.0649622
I0830 18:20:30.284346 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0649647 (* 1 = 0.0649647 loss)
I0830 18:20:30.284356 916722 sgd_solver.cpp:106] Iteration 1970000, lr = 0.01
I0830 18:21:00.000741 916722 solver.cpp:218] Iteration 1970500 (16.8259 iter/s, 29.7162s/500 iters), loss = 0.0222182
I0830 18:21:00.000800 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0222206 (* 1 = 0.0222206 loss)
I0830 18:21:00.000809 916722 sgd_solver.cpp:106] Iteration 1970500, lr = 0.01
I0830 18:21:29.730664 916722 solver.cpp:218] Iteration 1971000 (16.8182 iter/s, 29.7296s/500 iters), loss = 0.0986003
I0830 18:21:29.730715 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0986026 (* 1 = 0.0986026 loss)
I0830 18:21:29.730726 916722 sgd_solver.cpp:106] Iteration 1971000, lr = 0.01
I0830 18:21:59.459197 916722 solver.cpp:218] Iteration 1971500 (16.819 iter/s, 29.7283s/500 iters), loss = 0.0848998
I0830 18:21:59.459259 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0849024 (* 1 = 0.0849024 loss)
I0830 18:21:59.459266 916722 sgd_solver.cpp:106] Iteration 1971500, lr = 0.01
I0830 18:22:29.187260 916722 solver.cpp:218] Iteration 1972000 (16.8193 iter/s, 29.7278s/500 iters), loss = 0.107019
I0830 18:22:29.187306 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.107021 (* 1 = 0.107021 loss)
I0830 18:22:29.187315 916722 sgd_solver.cpp:106] Iteration 1972000, lr = 0.01
I0830 18:22:58.915391 916722 solver.cpp:218] Iteration 1972500 (16.8192 iter/s, 29.7279s/500 iters), loss = 0.0677259
I0830 18:22:58.915453 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0677284 (* 1 = 0.0677284 loss)
I0830 18:22:58.915462 916722 sgd_solver.cpp:106] Iteration 1972500, lr = 0.01
I0830 18:23:28.643405 916722 solver.cpp:218] Iteration 1973000 (16.8193 iter/s, 29.7278s/500 iters), loss = 0.104091
I0830 18:23:28.643458 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104093 (* 1 = 0.104093 loss)
I0830 18:23:28.643468 916722 sgd_solver.cpp:106] Iteration 1973000, lr = 0.01
I0830 18:23:58.371218 916722 solver.cpp:218] Iteration 1973500 (16.8194 iter/s, 29.7276s/500 iters), loss = 0.191643
I0830 18:23:58.371280 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.191645 (* 1 = 0.191645 loss)
I0830 18:23:58.371289 916722 sgd_solver.cpp:106] Iteration 1973500, lr = 0.01
I0830 18:24:28.103068 916722 solver.cpp:218] Iteration 1974000 (16.8171 iter/s, 29.7316s/500 iters), loss = 0.14554
I0830 18:24:28.103122 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.145543 (* 1 = 0.145543 loss)
I0830 18:24:28.103132 916722 sgd_solver.cpp:106] Iteration 1974000, lr = 0.01
I0830 18:24:57.830461 916722 solver.cpp:218] Iteration 1974500 (16.8196 iter/s, 29.7271s/500 iters), loss = 0.204682
I0830 18:24:57.830521 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.204685 (* 1 = 0.204685 loss)
I0830 18:24:57.830529 916722 sgd_solver.cpp:106] Iteration 1974500, lr = 0.01
I0830 18:25:27.560828 916722 solver.cpp:218] Iteration 1975000 (16.818 iter/s, 29.7301s/500 iters), loss = 0.320618
I0830 18:25:27.560881 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.320621 (* 1 = 0.320621 loss)
I0830 18:25:27.560891 916722 sgd_solver.cpp:106] Iteration 1975000, lr = 0.01
I0830 18:25:57.289652 916722 solver.cpp:218] Iteration 1975500 (16.8188 iter/s, 29.7286s/500 iters), loss = 0.0312455
I0830 18:25:57.289714 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0312479 (* 1 = 0.0312479 loss)
I0830 18:25:57.289722 916722 sgd_solver.cpp:106] Iteration 1975500, lr = 0.01
I0830 18:26:27.020437 916722 solver.cpp:218] Iteration 1976000 (16.8177 iter/s, 29.7305s/500 iters), loss = 0.00712211
I0830 18:26:27.020488 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.00712459 (* 1 = 0.00712459 loss)
I0830 18:26:27.020507 916722 sgd_solver.cpp:106] Iteration 1976000, lr = 0.01
I0830 18:26:56.748050 916722 solver.cpp:218] Iteration 1976500 (16.8195 iter/s, 29.7274s/500 iters), loss = 0.0498114
I0830 18:26:56.748116 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.049814 (* 1 = 0.049814 loss)
I0830 18:26:56.748124 916722 sgd_solver.cpp:106] Iteration 1976500, lr = 0.01
I0830 18:27:26.473577 916722 solver.cpp:218] Iteration 1977000 (16.8207 iter/s, 29.7253s/500 iters), loss = 0.216232
I0830 18:27:26.473631 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.216234 (* 1 = 0.216234 loss)
I0830 18:27:26.473639 916722 sgd_solver.cpp:106] Iteration 1977000, lr = 0.01
I0830 18:27:56.198123 916722 solver.cpp:218] Iteration 1977500 (16.8212 iter/s, 29.7243s/500 iters), loss = 0.111843
I0830 18:27:56.198185 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111846 (* 1 = 0.111846 loss)
I0830 18:27:56.198194 916722 sgd_solver.cpp:106] Iteration 1977500, lr = 0.01
I0830 18:28:25.928509 916722 solver.cpp:218] Iteration 1978000 (16.818 iter/s, 29.7301s/500 iters), loss = 0.0828368
I0830 18:28:25.928565 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0828392 (* 1 = 0.0828392 loss)
I0830 18:28:25.928573 916722 sgd_solver.cpp:106] Iteration 1978000, lr = 0.01
I0830 18:28:55.659968 916722 solver.cpp:218] Iteration 1978500 (16.8173 iter/s, 29.7312s/500 iters), loss = 0.237816
I0830 18:28:55.660029 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.237818 (* 1 = 0.237818 loss)
I0830 18:28:55.660038 916722 sgd_solver.cpp:106] Iteration 1978500, lr = 0.01
I0830 18:29:25.388056 916722 solver.cpp:218] Iteration 1979000 (16.8193 iter/s, 29.7278s/500 iters), loss = 0.136376
I0830 18:29:25.388109 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.136378 (* 1 = 0.136378 loss)
I0830 18:29:25.388118 916722 sgd_solver.cpp:106] Iteration 1979000, lr = 0.01
I0830 18:29:55.116192 916722 solver.cpp:218] Iteration 1979500 (16.8192 iter/s, 29.7279s/500 iters), loss = 0.068505
I0830 18:29:55.116255 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0685074 (* 1 = 0.0685074 loss)
I0830 18:29:55.116262 916722 sgd_solver.cpp:106] Iteration 1979500, lr = 0.01
I0830 18:30:24.843437 916722 solver.cpp:218] Iteration 1980000 (16.8197 iter/s, 29.727s/500 iters), loss = 0.203467
I0830 18:30:24.843487 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.20347 (* 1 = 0.20347 loss)
I0830 18:30:24.843495 916722 sgd_solver.cpp:106] Iteration 1980000, lr = 0.01
I0830 18:30:54.570901 916722 solver.cpp:218] Iteration 1980500 (16.8196 iter/s, 29.7272s/500 iters), loss = 0.0910235
I0830 18:30:54.570958 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0910261 (* 1 = 0.0910261 loss)
I0830 18:30:54.570966 916722 sgd_solver.cpp:106] Iteration 1980500, lr = 0.01
I0830 18:31:24.299043 916722 solver.cpp:218] Iteration 1981000 (16.8192 iter/s, 29.7279s/500 iters), loss = 0.0690446
I0830 18:31:24.299099 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0690473 (* 1 = 0.0690473 loss)
I0830 18:31:24.299109 916722 sgd_solver.cpp:106] Iteration 1981000, lr = 0.01
I0830 18:31:54.029907 916722 solver.cpp:218] Iteration 1981500 (16.8185 iter/s, 29.7292s/500 iters), loss = 0.213361
I0830 18:31:54.029979 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.213364 (* 1 = 0.213364 loss)
I0830 18:31:54.029990 916722 sgd_solver.cpp:106] Iteration 1981500, lr = 0.01
I0830 18:32:23.754976 916722 solver.cpp:218] Iteration 1982000 (16.821 iter/s, 29.7248s/500 iters), loss = 0.319025
I0830 18:32:23.755028 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.319027 (* 1 = 0.319027 loss)
I0830 18:32:23.755038 916722 sgd_solver.cpp:106] Iteration 1982000, lr = 0.01
I0830 18:32:53.477732 916722 solver.cpp:218] Iteration 1982500 (16.8223 iter/s, 29.7225s/500 iters), loss = 0.0986764
I0830 18:32:53.477803 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0986789 (* 1 = 0.0986789 loss)
I0830 18:32:53.477816 916722 sgd_solver.cpp:106] Iteration 1982500, lr = 0.01
I0830 18:33:23.192286 916722 solver.cpp:218] Iteration 1983000 (16.8269 iter/s, 29.7143s/500 iters), loss = 0.206465
I0830 18:33:23.192338 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.206468 (* 1 = 0.206468 loss)
I0830 18:33:23.192348 916722 sgd_solver.cpp:106] Iteration 1983000, lr = 0.01
I0830 18:33:52.908949 916722 solver.cpp:218] Iteration 1983500 (16.8257 iter/s, 29.7164s/500 iters), loss = 0.302209
I0830 18:33:52.909008 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.302212 (* 1 = 0.302212 loss)
I0830 18:33:52.909018 916722 sgd_solver.cpp:106] Iteration 1983500, lr = 0.01
I0830 18:34:22.626595 916722 solver.cpp:218] Iteration 1984000 (16.8251 iter/s, 29.7174s/500 iters), loss = 0.276558
I0830 18:34:22.626646 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.276561 (* 1 = 0.276561 loss)
I0830 18:34:22.626657 916722 sgd_solver.cpp:106] Iteration 1984000, lr = 0.01
I0830 18:34:52.348058 916722 solver.cpp:218] Iteration 1984500 (16.823 iter/s, 29.7212s/500 iters), loss = 0.0526424
I0830 18:34:52.348116 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0526448 (* 1 = 0.0526448 loss)
I0830 18:34:52.348124 916722 sgd_solver.cpp:106] Iteration 1984500, lr = 0.01
I0830 18:35:22.064695 916722 solver.cpp:218] Iteration 1985000 (16.8257 iter/s, 29.7164s/500 iters), loss = 0.0382499
I0830 18:35:22.064757 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0382523 (* 1 = 0.0382523 loss)
I0830 18:35:22.064767 916722 sgd_solver.cpp:106] Iteration 1985000, lr = 0.01
I0830 18:35:51.783681 916722 solver.cpp:218] Iteration 1985500 (16.8244 iter/s, 29.7188s/500 iters), loss = 0.0365801
I0830 18:35:51.783741 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0365823 (* 1 = 0.0365823 loss)
I0830 18:35:51.783749 916722 sgd_solver.cpp:106] Iteration 1985500, lr = 0.01
I0830 18:36:21.502514 916722 solver.cpp:218] Iteration 1986000 (16.8245 iter/s, 29.7186s/500 iters), loss = 0.249651
I0830 18:36:21.502565 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.249654 (* 1 = 0.249654 loss)
I0830 18:36:21.502576 916722 sgd_solver.cpp:106] Iteration 1986000, lr = 0.01
I0830 18:36:51.219213 916722 solver.cpp:218] Iteration 1986500 (16.8257 iter/s, 29.7165s/500 iters), loss = 0.0946898
I0830 18:36:51.219272 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0946925 (* 1 = 0.0946925 loss)
I0830 18:36:51.219280 916722 sgd_solver.cpp:106] Iteration 1986500, lr = 0.01
I0830 18:37:20.934404 916722 solver.cpp:218] Iteration 1987000 (16.8265 iter/s, 29.715s/500 iters), loss = 0.100405
I0830 18:37:20.934458 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.100408 (* 1 = 0.100408 loss)
I0830 18:37:20.934468 916722 sgd_solver.cpp:106] Iteration 1987000, lr = 0.01
I0830 18:37:50.650359 916722 solver.cpp:218] Iteration 1987500 (16.8261 iter/s, 29.7157s/500 iters), loss = 0.277234
I0830 18:37:50.650421 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.277236 (* 1 = 0.277236 loss)
I0830 18:37:50.650429 916722 sgd_solver.cpp:106] Iteration 1987500, lr = 0.01
I0830 18:38:20.367219 916722 solver.cpp:218] Iteration 1988000 (16.8256 iter/s, 29.7166s/500 iters), loss = 0.0680721
I0830 18:38:20.367272 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0680745 (* 1 = 0.0680745 loss)
I0830 18:38:20.367281 916722 sgd_solver.cpp:106] Iteration 1988000, lr = 0.01
I0830 18:38:50.085376 916722 solver.cpp:218] Iteration 1988500 (16.8249 iter/s, 29.7179s/500 iters), loss = 0.13447
I0830 18:38:50.085431 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.134473 (* 1 = 0.134473 loss)
I0830 18:38:50.085439 916722 sgd_solver.cpp:106] Iteration 1988500, lr = 0.01
I0830 18:39:19.801139 916722 solver.cpp:218] Iteration 1989000 (16.8262 iter/s, 29.7155s/500 iters), loss = 0.276279
I0830 18:39:19.801190 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.276282 (* 1 = 0.276282 loss)
I0830 18:39:19.801211 916722 sgd_solver.cpp:106] Iteration 1989000, lr = 0.01
I0830 18:39:49.517284 916722 solver.cpp:218] Iteration 1989500 (16.826 iter/s, 29.7159s/500 iters), loss = 0.250203
I0830 18:39:49.517351 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.250205 (* 1 = 0.250205 loss)
I0830 18:39:49.517359 916722 sgd_solver.cpp:106] Iteration 1989500, lr = 0.01
I0830 18:40:19.237970 916722 solver.cpp:218] Iteration 1990000 (16.8234 iter/s, 29.7205s/500 iters), loss = 0.361162
I0830 18:40:19.238023 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.361165 (* 1 = 0.361165 loss)
I0830 18:40:19.238030 916722 sgd_solver.cpp:106] Iteration 1990000, lr = 0.01
I0830 18:40:48.954573 916722 solver.cpp:218] Iteration 1990500 (16.8257 iter/s, 29.7164s/500 iters), loss = 0.366829
I0830 18:40:48.954633 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.366831 (* 1 = 0.366831 loss)
I0830 18:40:48.954641 916722 sgd_solver.cpp:106] Iteration 1990500, lr = 0.01
I0830 18:41:18.671197 916722 solver.cpp:218] Iteration 1991000 (16.8255 iter/s, 29.7168s/500 iters), loss = 0.0397016
I0830 18:41:18.671252 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0397039 (* 1 = 0.0397039 loss)
I0830 18:41:18.671260 916722 sgd_solver.cpp:106] Iteration 1991000, lr = 0.01
I0830 18:41:48.388717 916722 solver.cpp:218] Iteration 1991500 (16.8248 iter/s, 29.718s/500 iters), loss = 0.0582891
I0830 18:41:48.388777 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0582916 (* 1 = 0.0582916 loss)
I0830 18:41:48.388787 916722 sgd_solver.cpp:106] Iteration 1991500, lr = 0.01
I0830 18:42:18.105182 916722 solver.cpp:218] Iteration 1992000 (16.8254 iter/s, 29.7169s/500 iters), loss = 0.135651
I0830 18:42:18.105242 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.135653 (* 1 = 0.135653 loss)
I0830 18:42:18.105250 916722 sgd_solver.cpp:106] Iteration 1992000, lr = 0.01
I0830 18:42:47.819401 916722 solver.cpp:218] Iteration 1992500 (16.8267 iter/s, 29.7147s/500 iters), loss = 0.033265
I0830 18:42:47.819461 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0332673 (* 1 = 0.0332673 loss)
I0830 18:42:47.819470 916722 sgd_solver.cpp:106] Iteration 1992500, lr = 0.01
I0830 18:43:17.534013 916722 solver.cpp:218] Iteration 1993000 (16.8265 iter/s, 29.715s/500 iters), loss = 0.145474
I0830 18:43:17.534067 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.145476 (* 1 = 0.145476 loss)
I0830 18:43:17.534078 916722 sgd_solver.cpp:106] Iteration 1993000, lr = 0.01
I0830 18:43:47.247081 916722 solver.cpp:218] Iteration 1993500 (16.8274 iter/s, 29.7135s/500 iters), loss = 0.084713
I0830 18:43:47.247140 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0847154 (* 1 = 0.0847154 loss)
I0830 18:43:47.247148 916722 sgd_solver.cpp:106] Iteration 1993500, lr = 0.01
I0830 18:44:16.963438 916722 solver.cpp:218] Iteration 1994000 (16.8255 iter/s, 29.7167s/500 iters), loss = 0.544146
I0830 18:44:16.963488 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.544148 (* 1 = 0.544148 loss)
I0830 18:44:16.963498 916722 sgd_solver.cpp:106] Iteration 1994000, lr = 0.01
I0830 18:44:46.678421 916722 solver.cpp:218] Iteration 1994500 (16.8263 iter/s, 29.7153s/500 iters), loss = 0.116347
I0830 18:44:46.678481 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.116349 (* 1 = 0.116349 loss)
I0830 18:44:46.678490 916722 sgd_solver.cpp:106] Iteration 1994500, lr = 0.01
I0830 18:45:16.393049 916722 solver.cpp:218] Iteration 1995000 (16.8265 iter/s, 29.7149s/500 iters), loss = 0.0940204
I0830 18:45:16.393102 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0940229 (* 1 = 0.0940229 loss)
I0830 18:45:16.393112 916722 sgd_solver.cpp:106] Iteration 1995000, lr = 0.01
I0830 18:45:46.110605 916722 solver.cpp:218] Iteration 1995500 (16.8249 iter/s, 29.7179s/500 iters), loss = 0.234087
I0830 18:45:46.110666 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.234089 (* 1 = 0.234089 loss)
I0830 18:45:46.110673 916722 sgd_solver.cpp:106] Iteration 1995500, lr = 0.01
I0830 18:46:15.826879 916722 solver.cpp:218] Iteration 1996000 (16.8256 iter/s, 29.7165s/500 iters), loss = 0.152636
I0830 18:46:15.826930 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152639 (* 1 = 0.152639 loss)
I0830 18:46:15.826941 916722 sgd_solver.cpp:106] Iteration 1996000, lr = 0.01
I0830 18:46:45.542609 916722 solver.cpp:218] Iteration 1996500 (16.826 iter/s, 29.716s/500 iters), loss = 0.206093
I0830 18:46:45.542680 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.206095 (* 1 = 0.206095 loss)
I0830 18:46:45.542688 916722 sgd_solver.cpp:106] Iteration 1996500, lr = 0.01
I0830 18:47:15.258734 916722 solver.cpp:218] Iteration 1997000 (16.8258 iter/s, 29.7163s/500 iters), loss = 0.213747
I0830 18:47:15.258787 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.21375 (* 1 = 0.21375 loss)
I0830 18:47:15.258798 916722 sgd_solver.cpp:106] Iteration 1997000, lr = 0.01
I0830 18:47:44.977290 916722 solver.cpp:218] Iteration 1997500 (16.8244 iter/s, 29.7188s/500 iters), loss = 0.0517483
I0830 18:47:44.977349 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0517507 (* 1 = 0.0517507 loss)
I0830 18:47:44.977357 916722 sgd_solver.cpp:106] Iteration 1997500, lr = 0.01
I0830 18:48:14.693960 916722 solver.cpp:218] Iteration 1998000 (16.8255 iter/s, 29.7169s/500 iters), loss = 0.086439
I0830 18:48:14.694013 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0864413 (* 1 = 0.0864413 loss)
I0830 18:48:14.694023 916722 sgd_solver.cpp:106] Iteration 1998000, lr = 0.01
I0830 18:48:44.406919 916722 solver.cpp:218] Iteration 1998500 (16.8276 iter/s, 29.7131s/500 iters), loss = 0.0179418
I0830 18:48:44.406975 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.017944 (* 1 = 0.017944 loss)
I0830 18:48:44.406983 916722 sgd_solver.cpp:106] Iteration 1998500, lr = 0.01
I0830 18:49:14.123435 916722 solver.cpp:218] Iteration 1999000 (16.8256 iter/s, 29.7167s/500 iters), loss = 0.0823566
I0830 18:49:14.123487 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.082359 (* 1 = 0.082359 loss)
I0830 18:49:14.123495 916722 sgd_solver.cpp:106] Iteration 1999000, lr = 0.01
I0830 18:49:43.840725 916722 solver.cpp:218] Iteration 1999500 (16.8251 iter/s, 29.7174s/500 iters), loss = 0.215516
I0830 18:49:43.840785 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.215518 (* 1 = 0.215518 loss)
I0830 18:49:43.840795 916722 sgd_solver.cpp:106] Iteration 1999500, lr = 0.01
I0830 18:50:13.495587 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_2000000.caffemodel
I0830 18:50:13.514858 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_2000000.solverstate
I0830 18:50:13.521008 916722 solver.cpp:330] Iteration 2000000, Testing net (#0)
I0830 18:50:28.833721 916722 solver.cpp:397]     Test net output #0: accuracy = 0.872
I0830 18:50:28.833775 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.447172 (* 1 = 0.447172 loss)
I0830 18:50:28.892374 916722 solver.cpp:218] Iteration 2000000 (11.0983 iter/s, 45.0519s/500 iters), loss = 0.104411
I0830 18:50:28.892400 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104414 (* 1 = 0.104414 loss)
I0830 18:50:28.892407 916722 sgd_solver.cpp:106] Iteration 2000000, lr = 0.01
I0830 18:50:58.511344 916722 solver.cpp:218] Iteration 2000500 (16.881 iter/s, 29.6191s/500 iters), loss = 0.0549301
I0830 18:50:58.511394 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0549322 (* 1 = 0.0549322 loss)
I0830 18:50:58.511404 916722 sgd_solver.cpp:106] Iteration 2000500, lr = 0.01
I0830 18:51:28.213327 916722 solver.cpp:218] Iteration 2001000 (16.8338 iter/s, 29.7021s/500 iters), loss = 0.192829
I0830 18:51:28.213389 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.192831 (* 1 = 0.192831 loss)
I0830 18:51:28.213398 916722 sgd_solver.cpp:106] Iteration 2001000, lr = 0.01
I0830 18:51:57.925910 916722 solver.cpp:218] Iteration 2001500 (16.8278 iter/s, 29.7127s/500 iters), loss = 0.0710084
I0830 18:51:57.925983 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0710107 (* 1 = 0.0710107 loss)
I0830 18:51:57.925993 916722 sgd_solver.cpp:106] Iteration 2001500, lr = 0.01
I0830 18:52:27.640430 916722 solver.cpp:218] Iteration 2002000 (16.8268 iter/s, 29.7146s/500 iters), loss = 0.289537
I0830 18:52:27.640514 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.289539 (* 1 = 0.289539 loss)
I0830 18:52:27.640523 916722 sgd_solver.cpp:106] Iteration 2002000, lr = 0.01
I0830 18:52:57.355582 916722 solver.cpp:218] Iteration 2002500 (16.8264 iter/s, 29.7152s/500 iters), loss = 0.0725596
I0830 18:52:57.355636 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0725616 (* 1 = 0.0725616 loss)
I0830 18:52:57.355646 916722 sgd_solver.cpp:106] Iteration 2002500, lr = 0.01
I0830 18:53:27.074543 916722 solver.cpp:218] Iteration 2003000 (16.8242 iter/s, 29.719s/500 iters), loss = 0.413811
I0830 18:53:27.074601 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.413813 (* 1 = 0.413813 loss)
I0830 18:53:27.074609 916722 sgd_solver.cpp:106] Iteration 2003000, lr = 0.01
I0830 18:53:56.790858 916722 solver.cpp:218] Iteration 2003500 (16.8257 iter/s, 29.7164s/500 iters), loss = 0.39483
I0830 18:53:56.790908 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.394832 (* 1 = 0.394832 loss)
I0830 18:53:56.790916 916722 sgd_solver.cpp:106] Iteration 2003500, lr = 0.01
I0830 18:54:26.508111 916722 solver.cpp:218] Iteration 2004000 (16.8252 iter/s, 29.7173s/500 iters), loss = 0.151714
I0830 18:54:26.508169 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.151716 (* 1 = 0.151716 loss)
I0830 18:54:26.508177 916722 sgd_solver.cpp:106] Iteration 2004000, lr = 0.01
I0830 18:54:56.224269 916722 solver.cpp:218] Iteration 2004500 (16.8258 iter/s, 29.7162s/500 iters), loss = 0.131581
I0830 18:54:56.224320 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131583 (* 1 = 0.131583 loss)
I0830 18:54:56.224328 916722 sgd_solver.cpp:106] Iteration 2004500, lr = 0.01
I0830 18:55:25.945387 916722 solver.cpp:218] Iteration 2005000 (16.823 iter/s, 29.7212s/500 iters), loss = 0.21026
I0830 18:55:25.945444 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.210261 (* 1 = 0.210261 loss)
I0830 18:55:25.945452 916722 sgd_solver.cpp:106] Iteration 2005000, lr = 0.01
I0830 18:55:55.662914 916722 solver.cpp:218] Iteration 2005500 (16.8251 iter/s, 29.7175s/500 iters), loss = 0.11438
I0830 18:55:55.662971 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.114381 (* 1 = 0.114381 loss)
I0830 18:55:55.662981 916722 sgd_solver.cpp:106] Iteration 2005500, lr = 0.01
I0830 18:56:25.380618 916722 solver.cpp:218] Iteration 2006000 (16.825 iter/s, 29.7177s/500 iters), loss = 0.180666
I0830 18:56:25.380676 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.180668 (* 1 = 0.180668 loss)
I0830 18:56:25.380686 916722 sgd_solver.cpp:106] Iteration 2006000, lr = 0.01
I0830 18:56:55.108479 916722 solver.cpp:218] Iteration 2006500 (16.8192 iter/s, 29.7279s/500 iters), loss = 0.185564
I0830 18:56:55.108538 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.185566 (* 1 = 0.185566 loss)
I0830 18:56:55.108548 916722 sgd_solver.cpp:106] Iteration 2006500, lr = 0.01
I0830 18:57:24.830098 916722 solver.cpp:218] Iteration 2007000 (16.8228 iter/s, 29.7216s/500 iters), loss = 0.127112
I0830 18:57:24.830159 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.127114 (* 1 = 0.127114 loss)
I0830 18:57:24.830168 916722 sgd_solver.cpp:106] Iteration 2007000, lr = 0.01
I0830 18:57:54.547536 916722 solver.cpp:218] Iteration 2007500 (16.8251 iter/s, 29.7174s/500 iters), loss = 0.259146
I0830 18:57:54.547590 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.259147 (* 1 = 0.259147 loss)
I0830 18:57:54.547600 916722 sgd_solver.cpp:106] Iteration 2007500, lr = 0.01
I0830 18:58:24.260211 916722 solver.cpp:218] Iteration 2008000 (16.8278 iter/s, 29.7127s/500 iters), loss = 0.0991903
I0830 18:58:24.260286 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0991918 (* 1 = 0.0991918 loss)
I0830 18:58:24.260295 916722 sgd_solver.cpp:106] Iteration 2008000, lr = 0.01
I0830 18:58:53.977834 916722 solver.cpp:218] Iteration 2008500 (16.825 iter/s, 29.7176s/500 iters), loss = 0.0614187
I0830 18:58:53.977887 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0614202 (* 1 = 0.0614202 loss)
I0830 18:58:53.977896 916722 sgd_solver.cpp:106] Iteration 2008500, lr = 0.01
I0830 18:59:23.694437 916722 solver.cpp:218] Iteration 2009000 (16.8256 iter/s, 29.7166s/500 iters), loss = 0.0604195
I0830 18:59:23.694492 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0604211 (* 1 = 0.0604211 loss)
I0830 18:59:23.694500 916722 sgd_solver.cpp:106] Iteration 2009000, lr = 0.01
I0830 18:59:53.409199 916722 solver.cpp:218] Iteration 2009500 (16.8267 iter/s, 29.7147s/500 iters), loss = 0.0987944
I0830 18:59:53.409248 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0987961 (* 1 = 0.0987961 loss)
I0830 18:59:53.409258 916722 sgd_solver.cpp:106] Iteration 2009500, lr = 0.01
I0830 19:00:23.125021 916722 solver.cpp:218] Iteration 2010000 (16.8261 iter/s, 29.7158s/500 iters), loss = 0.338125
I0830 19:00:23.125080 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.338126 (* 1 = 0.338126 loss)
I0830 19:00:23.125088 916722 sgd_solver.cpp:106] Iteration 2010000, lr = 0.01
I0830 19:00:52.841276 916722 solver.cpp:218] Iteration 2010500 (16.8258 iter/s, 29.7162s/500 iters), loss = 0.0420741
I0830 19:00:52.841332 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0420759 (* 1 = 0.0420759 loss)
I0830 19:00:52.841342 916722 sgd_solver.cpp:106] Iteration 2010500, lr = 0.01
I0830 19:01:22.557539 916722 solver.cpp:218] Iteration 2011000 (16.8258 iter/s, 29.7162s/500 iters), loss = 0.387365
I0830 19:01:22.557598 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.387367 (* 1 = 0.387367 loss)
I0830 19:01:22.557606 916722 sgd_solver.cpp:106] Iteration 2011000, lr = 0.01
I0830 19:01:52.272493 916722 solver.cpp:218] Iteration 2011500 (16.8266 iter/s, 29.7149s/500 iters), loss = 0.126211
I0830 19:01:52.272548 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.126212 (* 1 = 0.126212 loss)
I0830 19:01:52.272559 916722 sgd_solver.cpp:106] Iteration 2011500, lr = 0.01
I0830 19:02:21.990310 916722 solver.cpp:218] Iteration 2012000 (16.8249 iter/s, 29.7178s/500 iters), loss = 0.0531758
I0830 19:02:21.990373 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0531775 (* 1 = 0.0531775 loss)
I0830 19:02:21.990382 916722 sgd_solver.cpp:106] Iteration 2012000, lr = 0.01
I0830 19:02:51.705595 916722 solver.cpp:218] Iteration 2012500 (16.8264 iter/s, 29.7152s/500 iters), loss = 0.247608
I0830 19:02:51.705648 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.247609 (* 1 = 0.247609 loss)
I0830 19:02:51.705657 916722 sgd_solver.cpp:106] Iteration 2012500, lr = 0.01
I0830 19:03:21.420498 916722 solver.cpp:218] Iteration 2013000 (16.8266 iter/s, 29.7149s/500 iters), loss = 0.308298
I0830 19:03:21.420558 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.3083 (* 1 = 0.3083 loss)
I0830 19:03:21.420567 916722 sgd_solver.cpp:106] Iteration 2013000, lr = 0.01
I0830 19:03:51.136276 916722 solver.cpp:218] Iteration 2013500 (16.8261 iter/s, 29.7157s/500 iters), loss = 0.0707575
I0830 19:03:51.136329 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.070759 (* 1 = 0.070759 loss)
I0830 19:03:51.136338 916722 sgd_solver.cpp:106] Iteration 2013500, lr = 0.01
I0830 19:04:20.857537 916722 solver.cpp:218] Iteration 2014000 (16.823 iter/s, 29.7212s/500 iters), loss = 0.0628233
I0830 19:04:20.857597 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0628249 (* 1 = 0.0628249 loss)
I0830 19:04:20.857606 916722 sgd_solver.cpp:106] Iteration 2014000, lr = 0.01
I0830 19:04:50.579313 916722 solver.cpp:218] Iteration 2014500 (16.8227 iter/s, 29.7217s/500 iters), loss = 0.066321
I0830 19:04:50.579367 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0663226 (* 1 = 0.0663226 loss)
I0830 19:04:50.579388 916722 sgd_solver.cpp:106] Iteration 2014500, lr = 0.01
I0830 19:05:20.296823 916722 solver.cpp:218] Iteration 2015000 (16.8251 iter/s, 29.7175s/500 iters), loss = 0.199159
I0830 19:05:20.296895 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.19916 (* 1 = 0.19916 loss)
I0830 19:05:20.296902 916722 sgd_solver.cpp:106] Iteration 2015000, lr = 0.01
I0830 19:05:50.008713 916722 solver.cpp:218] Iteration 2015500 (16.8283 iter/s, 29.7118s/500 iters), loss = 0.0622843
I0830 19:05:50.008785 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.062286 (* 1 = 0.062286 loss)
I0830 19:05:50.008793 916722 sgd_solver.cpp:106] Iteration 2015500, lr = 0.01
I0830 19:06:19.727059 916722 solver.cpp:218] Iteration 2016000 (16.8247 iter/s, 29.7183s/500 iters), loss = 0.0698206
I0830 19:06:19.727120 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0698224 (* 1 = 0.0698224 loss)
I0830 19:06:19.727128 916722 sgd_solver.cpp:106] Iteration 2016000, lr = 0.01
I0830 19:06:49.438951 916722 solver.cpp:218] Iteration 2016500 (16.8283 iter/s, 29.7118s/500 iters), loss = 0.069919
I0830 19:06:49.439004 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0699209 (* 1 = 0.0699209 loss)
I0830 19:06:49.439013 916722 sgd_solver.cpp:106] Iteration 2016500, lr = 0.01
I0830 19:07:19.150405 916722 solver.cpp:218] Iteration 2017000 (16.8286 iter/s, 29.7114s/500 iters), loss = 0.0701318
I0830 19:07:19.150465 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0701339 (* 1 = 0.0701339 loss)
I0830 19:07:19.150472 916722 sgd_solver.cpp:106] Iteration 2017000, lr = 0.01
I0830 19:07:48.864658 916722 solver.cpp:218] Iteration 2017500 (16.827 iter/s, 29.7142s/500 iters), loss = 0.16349
I0830 19:07:48.864713 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.163492 (* 1 = 0.163492 loss)
I0830 19:07:48.864723 916722 sgd_solver.cpp:106] Iteration 2017500, lr = 0.01
I0830 19:08:18.577790 916722 solver.cpp:218] Iteration 2018000 (16.8276 iter/s, 29.7131s/500 iters), loss = 0.0221677
I0830 19:08:18.577843 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0221697 (* 1 = 0.0221697 loss)
I0830 19:08:18.577852 916722 sgd_solver.cpp:106] Iteration 2018000, lr = 0.01
I0830 19:08:48.293680 916722 solver.cpp:218] Iteration 2018500 (16.8261 iter/s, 29.7158s/500 iters), loss = 0.223771
I0830 19:08:48.293735 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.223773 (* 1 = 0.223773 loss)
I0830 19:08:48.293745 916722 sgd_solver.cpp:106] Iteration 2018500, lr = 0.01
I0830 19:09:18.007536 916722 solver.cpp:218] Iteration 2019000 (16.8272 iter/s, 29.7138s/500 iters), loss = 0.0789794
I0830 19:09:18.007597 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0789814 (* 1 = 0.0789814 loss)
I0830 19:09:18.007606 916722 sgd_solver.cpp:106] Iteration 2019000, lr = 0.01
I0830 19:09:47.722522 916722 solver.cpp:218] Iteration 2019500 (16.8266 iter/s, 29.7149s/500 iters), loss = 0.288334
I0830 19:09:47.722574 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.288336 (* 1 = 0.288336 loss)
I0830 19:09:47.722584 916722 sgd_solver.cpp:106] Iteration 2019500, lr = 0.01
I0830 19:10:17.435263 916722 solver.cpp:218] Iteration 2020000 (16.8278 iter/s, 29.7127s/500 iters), loss = 0.27713
I0830 19:10:17.435322 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.277132 (* 1 = 0.277132 loss)
I0830 19:10:17.435330 916722 sgd_solver.cpp:106] Iteration 2020000, lr = 0.01
I0830 19:10:47.150557 916722 solver.cpp:218] Iteration 2020500 (16.8264 iter/s, 29.7152s/500 iters), loss = 0.0660901
I0830 19:10:47.150609 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0660919 (* 1 = 0.0660919 loss)
I0830 19:10:47.150619 916722 sgd_solver.cpp:106] Iteration 2020500, lr = 0.01
I0830 19:11:16.863989 916722 solver.cpp:218] Iteration 2021000 (16.8274 iter/s, 29.7134s/500 iters), loss = 0.184225
I0830 19:11:16.864058 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.184227 (* 1 = 0.184227 loss)
I0830 19:11:16.864070 916722 sgd_solver.cpp:106] Iteration 2021000, lr = 0.01
I0830 19:11:46.579831 916722 solver.cpp:218] Iteration 2021500 (16.8261 iter/s, 29.7158s/500 iters), loss = 0.134226
I0830 19:11:46.579886 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.134228 (* 1 = 0.134228 loss)
I0830 19:11:46.579895 916722 sgd_solver.cpp:106] Iteration 2021500, lr = 0.01
I0830 19:12:16.294055 916722 solver.cpp:218] Iteration 2022000 (16.827 iter/s, 29.7141s/500 iters), loss = 0.129842
I0830 19:12:16.294114 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.129844 (* 1 = 0.129844 loss)
I0830 19:12:16.294122 916722 sgd_solver.cpp:106] Iteration 2022000, lr = 0.01
I0830 19:12:46.012285 916722 solver.cpp:218] Iteration 2022500 (16.8247 iter/s, 29.7181s/500 iters), loss = 0.0952037
I0830 19:12:46.012337 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0952056 (* 1 = 0.0952056 loss)
I0830 19:12:46.012347 916722 sgd_solver.cpp:106] Iteration 2022500, lr = 0.01
I0830 19:13:15.728296 916722 solver.cpp:218] Iteration 2023000 (16.826 iter/s, 29.7159s/500 iters), loss = 0.0659562
I0830 19:13:15.728359 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0659583 (* 1 = 0.0659583 loss)
I0830 19:13:15.728368 916722 sgd_solver.cpp:106] Iteration 2023000, lr = 0.01
I0830 19:13:45.441751 916722 solver.cpp:218] Iteration 2023500 (16.8274 iter/s, 29.7134s/500 iters), loss = 0.204497
I0830 19:13:45.441802 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.204499 (* 1 = 0.204499 loss)
I0830 19:13:45.441812 916722 sgd_solver.cpp:106] Iteration 2023500, lr = 0.01
I0830 19:14:15.157198 916722 solver.cpp:218] Iteration 2024000 (16.8263 iter/s, 29.7154s/500 iters), loss = 0.0972926
I0830 19:14:15.157258 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0972948 (* 1 = 0.0972948 loss)
I0830 19:14:15.157265 916722 sgd_solver.cpp:106] Iteration 2024000, lr = 0.01
I0830 19:14:44.868551 916722 solver.cpp:218] Iteration 2024500 (16.8286 iter/s, 29.7113s/500 iters), loss = 0.158548
I0830 19:14:44.868605 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.15855 (* 1 = 0.15855 loss)
I0830 19:14:44.868614 916722 sgd_solver.cpp:106] Iteration 2024500, lr = 0.01
I0830 19:15:14.587432 916722 solver.cpp:218] Iteration 2025000 (16.8244 iter/s, 29.7187s/500 iters), loss = 0.243791
I0830 19:15:14.587491 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.243793 (* 1 = 0.243793 loss)
I0830 19:15:14.587498 916722 sgd_solver.cpp:106] Iteration 2025000, lr = 0.01
I0830 19:15:44.301168 916722 solver.cpp:218] Iteration 2025500 (16.8275 iter/s, 29.7133s/500 iters), loss = 0.0582979
I0830 19:15:44.301223 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0583001 (* 1 = 0.0583001 loss)
I0830 19:15:44.301231 916722 sgd_solver.cpp:106] Iteration 2025500, lr = 0.01
I0830 19:16:14.011787 916722 solver.cpp:218] Iteration 2026000 (16.8293 iter/s, 29.7102s/500 iters), loss = 0.0413197
I0830 19:16:14.011847 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0413217 (* 1 = 0.0413217 loss)
I0830 19:16:14.011855 916722 sgd_solver.cpp:106] Iteration 2026000, lr = 0.01
I0830 19:16:43.725942 916722 solver.cpp:218] Iteration 2026500 (16.8273 iter/s, 29.7137s/500 iters), loss = 0.253176
I0830 19:16:43.725994 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.253178 (* 1 = 0.253178 loss)
I0830 19:16:43.726003 916722 sgd_solver.cpp:106] Iteration 2026500, lr = 0.01
I0830 19:17:13.442445 916722 solver.cpp:218] Iteration 2027000 (16.8259 iter/s, 29.7161s/500 iters), loss = 0.1455
I0830 19:17:13.442503 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.145502 (* 1 = 0.145502 loss)
I0830 19:17:13.442512 916722 sgd_solver.cpp:106] Iteration 2027000, lr = 0.01
I0830 19:17:43.158661 916722 solver.cpp:218] Iteration 2027500 (16.8261 iter/s, 29.7158s/500 iters), loss = 0.094952
I0830 19:17:43.158715 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0949539 (* 1 = 0.0949539 loss)
I0830 19:17:43.158741 916722 sgd_solver.cpp:106] Iteration 2027500, lr = 0.01
I0830 19:18:12.875005 916722 solver.cpp:218] Iteration 2028000 (16.826 iter/s, 29.716s/500 iters), loss = 0.0939274
I0830 19:18:12.875074 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0939291 (* 1 = 0.0939291 loss)
I0830 19:18:12.875083 916722 sgd_solver.cpp:106] Iteration 2028000, lr = 0.01
I0830 19:18:42.592833 916722 solver.cpp:218] Iteration 2028500 (16.8251 iter/s, 29.7174s/500 iters), loss = 0.187742
I0830 19:18:42.592887 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.187744 (* 1 = 0.187744 loss)
I0830 19:18:42.592897 916722 sgd_solver.cpp:106] Iteration 2028500, lr = 0.01
I0830 19:19:12.311420 916722 solver.cpp:218] Iteration 2029000 (16.8247 iter/s, 29.7182s/500 iters), loss = 0.130211
I0830 19:19:12.311478 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130213 (* 1 = 0.130213 loss)
I0830 19:19:12.311486 916722 sgd_solver.cpp:106] Iteration 2029000, lr = 0.01
I0830 19:19:42.028369 916722 solver.cpp:218] Iteration 2029500 (16.8256 iter/s, 29.7166s/500 iters), loss = 0.0417287
I0830 19:19:42.028420 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0417302 (* 1 = 0.0417302 loss)
I0830 19:19:42.028435 916722 sgd_solver.cpp:106] Iteration 2029500, lr = 0.01
I0830 19:20:11.741247 916722 solver.cpp:218] Iteration 2030000 (16.8279 iter/s, 29.7125s/500 iters), loss = 0.118333
I0830 19:20:11.741304 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.118335 (* 1 = 0.118335 loss)
I0830 19:20:11.741313 916722 sgd_solver.cpp:106] Iteration 2030000, lr = 0.01
I0830 19:20:41.460827 916722 solver.cpp:218] Iteration 2030500 (16.8241 iter/s, 29.7193s/500 iters), loss = 0.131309
I0830 19:20:41.460880 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13131 (* 1 = 0.13131 loss)
I0830 19:20:41.460889 916722 sgd_solver.cpp:106] Iteration 2030500, lr = 0.01
I0830 19:21:11.179080 916722 solver.cpp:218] Iteration 2031000 (16.8249 iter/s, 29.7179s/500 iters), loss = 0.0835516
I0830 19:21:11.179137 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0835534 (* 1 = 0.0835534 loss)
I0830 19:21:11.179147 916722 sgd_solver.cpp:106] Iteration 2031000, lr = 0.01
I0830 19:21:40.890452 916722 solver.cpp:218] Iteration 2031500 (16.8287 iter/s, 29.7111s/500 iters), loss = 0.136951
I0830 19:21:40.890506 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.136953 (* 1 = 0.136953 loss)
I0830 19:21:40.890516 916722 sgd_solver.cpp:106] Iteration 2031500, lr = 0.01
I0830 19:22:10.603586 916722 solver.cpp:218] Iteration 2032000 (16.8277 iter/s, 29.7128s/500 iters), loss = 0.171736
I0830 19:22:10.603643 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.171738 (* 1 = 0.171738 loss)
I0830 19:22:10.603652 916722 sgd_solver.cpp:106] Iteration 2032000, lr = 0.01
I0830 19:22:40.318538 916722 solver.cpp:218] Iteration 2032500 (16.8267 iter/s, 29.7147s/500 iters), loss = 0.296046
I0830 19:22:40.318591 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.296048 (* 1 = 0.296048 loss)
I0830 19:22:40.318601 916722 sgd_solver.cpp:106] Iteration 2032500, lr = 0.01
I0830 19:23:10.031684 916722 solver.cpp:218] Iteration 2033000 (16.8277 iter/s, 29.7129s/500 iters), loss = 0.112487
I0830 19:23:10.031740 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112489 (* 1 = 0.112489 loss)
I0830 19:23:10.031749 916722 sgd_solver.cpp:106] Iteration 2033000, lr = 0.01
I0830 19:23:39.746155 916722 solver.cpp:218] Iteration 2033500 (16.827 iter/s, 29.7142s/500 iters), loss = 0.0334588
I0830 19:23:39.746206 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0334609 (* 1 = 0.0334609 loss)
I0830 19:23:39.746215 916722 sgd_solver.cpp:106] Iteration 2033500, lr = 0.01
I0830 19:24:09.470960 916722 solver.cpp:218] Iteration 2034000 (16.8211 iter/s, 29.7245s/500 iters), loss = 0.141956
I0830 19:24:09.471022 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.141958 (* 1 = 0.141958 loss)
I0830 19:24:09.471030 916722 sgd_solver.cpp:106] Iteration 2034000, lr = 0.01
I0830 19:24:39.184643 916722 solver.cpp:218] Iteration 2034500 (16.8274 iter/s, 29.7134s/500 iters), loss = 0.0772405
I0830 19:24:39.184693 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0772427 (* 1 = 0.0772427 loss)
I0830 19:24:39.184701 916722 sgd_solver.cpp:106] Iteration 2034500, lr = 0.01
I0830 19:25:08.900918 916722 solver.cpp:218] Iteration 2035000 (16.8259 iter/s, 29.716s/500 iters), loss = 0.0407602
I0830 19:25:08.900987 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0407625 (* 1 = 0.0407625 loss)
I0830 19:25:08.900996 916722 sgd_solver.cpp:106] Iteration 2035000, lr = 0.01
I0830 19:25:38.617384 916722 solver.cpp:218] Iteration 2035500 (16.8258 iter/s, 29.7162s/500 iters), loss = 0.143928
I0830 19:25:38.617436 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.14393 (* 1 = 0.14393 loss)
I0830 19:25:38.617444 916722 sgd_solver.cpp:106] Iteration 2035500, lr = 0.01
I0830 19:26:08.329658 916722 solver.cpp:218] Iteration 2036000 (16.8282 iter/s, 29.712s/500 iters), loss = 0.116335
I0830 19:26:08.329718 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.116338 (* 1 = 0.116338 loss)
I0830 19:26:08.329726 916722 sgd_solver.cpp:106] Iteration 2036000, lr = 0.01
I0830 19:26:38.040589 916722 solver.cpp:218] Iteration 2036500 (16.829 iter/s, 29.7107s/500 iters), loss = 0.255618
I0830 19:26:38.040642 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.255621 (* 1 = 0.255621 loss)
I0830 19:26:38.040652 916722 sgd_solver.cpp:106] Iteration 2036500, lr = 0.01
I0830 19:27:07.756714 916722 solver.cpp:218] Iteration 2037000 (16.826 iter/s, 29.7159s/500 iters), loss = 0.176877
I0830 19:27:07.756783 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.176879 (* 1 = 0.176879 loss)
I0830 19:27:07.756793 916722 sgd_solver.cpp:106] Iteration 2037000, lr = 0.01
I0830 19:27:37.476058 916722 solver.cpp:218] Iteration 2037500 (16.8242 iter/s, 29.7191s/500 iters), loss = 0.097417
I0830 19:27:37.476114 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0974193 (* 1 = 0.0974193 loss)
I0830 19:27:37.476122 916722 sgd_solver.cpp:106] Iteration 2037500, lr = 0.01
I0830 19:28:07.191989 916722 solver.cpp:218] Iteration 2038000 (16.8261 iter/s, 29.7157s/500 iters), loss = 0.192762
I0830 19:28:07.192046 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.192765 (* 1 = 0.192765 loss)
I0830 19:28:07.192054 916722 sgd_solver.cpp:106] Iteration 2038000, lr = 0.01
I0830 19:28:36.904767 916722 solver.cpp:218] Iteration 2038500 (16.8279 iter/s, 29.7126s/500 iters), loss = 0.205566
I0830 19:28:36.904815 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.205568 (* 1 = 0.205568 loss)
I0830 19:28:36.904824 916722 sgd_solver.cpp:106] Iteration 2038500, lr = 0.01
I0830 19:29:06.620102 916722 solver.cpp:218] Iteration 2039000 (16.8264 iter/s, 29.7151s/500 iters), loss = 0.148822
I0830 19:29:06.620162 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.148824 (* 1 = 0.148824 loss)
I0830 19:29:06.620170 916722 sgd_solver.cpp:106] Iteration 2039000, lr = 0.01
I0830 19:29:36.333758 916722 solver.cpp:218] Iteration 2039500 (16.8274 iter/s, 29.7134s/500 iters), loss = 0.0503134
I0830 19:29:36.333811 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0503158 (* 1 = 0.0503158 loss)
I0830 19:29:36.333818 916722 sgd_solver.cpp:106] Iteration 2039500, lr = 0.01
I0830 19:30:06.046308 916722 solver.cpp:218] Iteration 2040000 (16.828 iter/s, 29.7124s/500 iters), loss = 0.0436147
I0830 19:30:06.046367 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0436171 (* 1 = 0.0436171 loss)
I0830 19:30:06.046376 916722 sgd_solver.cpp:106] Iteration 2040000, lr = 0.01
I0830 19:30:35.759088 916722 solver.cpp:218] Iteration 2040500 (16.8279 iter/s, 29.7126s/500 iters), loss = 0.206381
I0830 19:30:35.759137 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.206383 (* 1 = 0.206383 loss)
I0830 19:30:35.759146 916722 sgd_solver.cpp:106] Iteration 2040500, lr = 0.01
I0830 19:31:05.473148 916722 solver.cpp:218] Iteration 2041000 (16.8272 iter/s, 29.7139s/500 iters), loss = 0.179224
I0830 19:31:05.473222 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.179226 (* 1 = 0.179226 loss)
I0830 19:31:05.473235 916722 sgd_solver.cpp:106] Iteration 2041000, lr = 0.01
I0830 19:31:35.186304 916722 solver.cpp:218] Iteration 2041500 (16.8277 iter/s, 29.7129s/500 iters), loss = 0.11132
I0830 19:31:35.186358 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111322 (* 1 = 0.111322 loss)
I0830 19:31:35.186367 916722 sgd_solver.cpp:106] Iteration 2041500, lr = 0.01
I0830 19:32:04.903589 916722 solver.cpp:218] Iteration 2042000 (16.8253 iter/s, 29.7171s/500 iters), loss = 0.0347856
I0830 19:32:04.903646 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0347882 (* 1 = 0.0347882 loss)
I0830 19:32:04.903654 916722 sgd_solver.cpp:106] Iteration 2042000, lr = 0.01
I0830 19:32:34.617868 916722 solver.cpp:218] Iteration 2042500 (16.827 iter/s, 29.7141s/500 iters), loss = 0.238517
I0830 19:32:34.617918 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.238519 (* 1 = 0.238519 loss)
I0830 19:32:34.617926 916722 sgd_solver.cpp:106] Iteration 2042500, lr = 0.01
I0830 19:33:04.330186 916722 solver.cpp:218] Iteration 2043000 (16.8281 iter/s, 29.7121s/500 iters), loss = 0.0940728
I0830 19:33:04.330245 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.094075 (* 1 = 0.094075 loss)
I0830 19:33:04.330252 916722 sgd_solver.cpp:106] Iteration 2043000, lr = 0.01
I0830 19:33:34.042702 916722 solver.cpp:218] Iteration 2043500 (16.828 iter/s, 29.7123s/500 iters), loss = 0.133704
I0830 19:33:34.042757 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133706 (* 1 = 0.133706 loss)
I0830 19:33:34.042766 916722 sgd_solver.cpp:106] Iteration 2043500, lr = 0.01
I0830 19:34:03.755261 916722 solver.cpp:218] Iteration 2044000 (16.828 iter/s, 29.7124s/500 iters), loss = 0.189284
I0830 19:34:03.755317 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.189286 (* 1 = 0.189286 loss)
I0830 19:34:03.755326 916722 sgd_solver.cpp:106] Iteration 2044000, lr = 0.01
I0830 19:34:33.469295 916722 solver.cpp:218] Iteration 2044500 (16.8272 iter/s, 29.7139s/500 iters), loss = 0.201264
I0830 19:34:33.469347 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.201266 (* 1 = 0.201266 loss)
I0830 19:34:33.469357 916722 sgd_solver.cpp:106] Iteration 2044500, lr = 0.01
I0830 19:35:03.180996 916722 solver.cpp:218] Iteration 2045000 (16.8285 iter/s, 29.7115s/500 iters), loss = 0.216491
I0830 19:35:03.181054 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.216493 (* 1 = 0.216493 loss)
I0830 19:35:03.181062 916722 sgd_solver.cpp:106] Iteration 2045000, lr = 0.01
I0830 19:35:32.894052 916722 solver.cpp:218] Iteration 2045500 (16.8277 iter/s, 29.7129s/500 iters), loss = 0.020413
I0830 19:35:32.894105 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0204152 (* 1 = 0.0204152 loss)
I0830 19:35:32.894115 916722 sgd_solver.cpp:106] Iteration 2045500, lr = 0.01
I0830 19:36:02.605046 916722 solver.cpp:218] Iteration 2046000 (16.8289 iter/s, 29.7108s/500 iters), loss = 0.19401
I0830 19:36:02.605101 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.194012 (* 1 = 0.194012 loss)
I0830 19:36:02.605109 916722 sgd_solver.cpp:106] Iteration 2046000, lr = 0.01
I0830 19:36:32.318744 916722 solver.cpp:218] Iteration 2046500 (16.8274 iter/s, 29.7135s/500 iters), loss = 0.0386087
I0830 19:36:32.318795 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0386108 (* 1 = 0.0386108 loss)
I0830 19:36:32.318804 916722 sgd_solver.cpp:106] Iteration 2046500, lr = 0.01
I0830 19:37:02.032681 916722 solver.cpp:218] Iteration 2047000 (16.8272 iter/s, 29.7138s/500 iters), loss = 0.144908
I0830 19:37:02.032750 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.144911 (* 1 = 0.144911 loss)
I0830 19:37:02.032768 916722 sgd_solver.cpp:106] Iteration 2047000, lr = 0.01
I0830 19:37:31.744117 916722 solver.cpp:218] Iteration 2047500 (16.8286 iter/s, 29.7113s/500 iters), loss = 0.168243
I0830 19:37:31.744180 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.168245 (* 1 = 0.168245 loss)
I0830 19:37:31.744190 916722 sgd_solver.cpp:106] Iteration 2047500, lr = 0.01
I0830 19:38:01.456703 916722 solver.cpp:218] Iteration 2048000 (16.828 iter/s, 29.7124s/500 iters), loss = 0.397325
I0830 19:38:01.456780 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.397328 (* 1 = 0.397328 loss)
I0830 19:38:01.456789 916722 sgd_solver.cpp:106] Iteration 2048000, lr = 0.01
I0830 19:38:31.171777 916722 solver.cpp:218] Iteration 2048500 (16.8266 iter/s, 29.7149s/500 iters), loss = 0.0201838
I0830 19:38:31.171830 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0201862 (* 1 = 0.0201862 loss)
I0830 19:38:31.171840 916722 sgd_solver.cpp:106] Iteration 2048500, lr = 0.01
I0830 19:39:00.883288 916722 solver.cpp:218] Iteration 2049000 (16.8286 iter/s, 29.7113s/500 iters), loss = 0.185715
I0830 19:39:00.883347 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.185718 (* 1 = 0.185718 loss)
I0830 19:39:00.883355 916722 sgd_solver.cpp:106] Iteration 2049000, lr = 0.01
I0830 19:39:30.599750 916722 solver.cpp:218] Iteration 2049500 (16.8258 iter/s, 29.7163s/500 iters), loss = 0.0977649
I0830 19:39:30.599802 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0977674 (* 1 = 0.0977674 loss)
I0830 19:39:30.599810 916722 sgd_solver.cpp:106] Iteration 2049500, lr = 0.01
I0830 19:40:00.255808 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_2050000.caffemodel
I0830 19:40:00.274886 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_2050000.solverstate
I0830 19:40:00.280989 916722 solver.cpp:330] Iteration 2050000, Testing net (#0)
I0830 19:40:15.598381 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8805
I0830 19:40:15.598425 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.403125 (* 1 = 0.403125 loss)
I0830 19:40:15.656795 916722 solver.cpp:218] Iteration 2050000 (11.0971 iter/s, 45.0568s/500 iters), loss = 0.245713
I0830 19:40:15.656822 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.245715 (* 1 = 0.245715 loss)
I0830 19:40:15.656831 916722 sgd_solver.cpp:106] Iteration 2050000, lr = 0.01
I0830 19:40:45.267268 916722 solver.cpp:218] Iteration 2050500 (16.886 iter/s, 29.6103s/500 iters), loss = 0.0828828
I0830 19:40:45.267329 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0828852 (* 1 = 0.0828852 loss)
I0830 19:40:45.267338 916722 sgd_solver.cpp:106] Iteration 2050500, lr = 0.01
I0830 19:41:14.951393 916722 solver.cpp:218] Iteration 2051000 (16.8441 iter/s, 29.6839s/500 iters), loss = 0.29645
I0830 19:41:14.951447 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.296452 (* 1 = 0.296452 loss)
I0830 19:41:14.951457 916722 sgd_solver.cpp:106] Iteration 2051000, lr = 0.01
I0830 19:41:44.661754 916722 solver.cpp:218] Iteration 2051500 (16.8292 iter/s, 29.7102s/500 iters), loss = 0.476134
I0830 19:41:44.661813 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.476137 (* 1 = 0.476137 loss)
I0830 19:41:44.661821 916722 sgd_solver.cpp:106] Iteration 2051500, lr = 0.01
I0830 19:42:14.372913 916722 solver.cpp:218] Iteration 2052000 (16.8288 iter/s, 29.711s/500 iters), loss = 0.0383158
I0830 19:42:14.372969 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0383184 (* 1 = 0.0383184 loss)
I0830 19:42:14.372979 916722 sgd_solver.cpp:106] Iteration 2052000, lr = 0.01
I0830 19:42:44.136328 916722 solver.cpp:218] Iteration 2052500 (16.7992 iter/s, 29.7632s/500 iters), loss = 0.0248931
I0830 19:42:44.136392 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0248958 (* 1 = 0.0248958 loss)
I0830 19:42:44.136402 916722 sgd_solver.cpp:106] Iteration 2052500, lr = 0.01
I0830 19:43:13.891803 916722 solver.cpp:218] Iteration 2053000 (16.8037 iter/s, 29.7553s/500 iters), loss = 0.291121
I0830 19:43:13.891855 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.291124 (* 1 = 0.291124 loss)
I0830 19:43:13.891875 916722 sgd_solver.cpp:106] Iteration 2053000, lr = 0.01
I0830 19:43:43.648348 916722 solver.cpp:218] Iteration 2053500 (16.8031 iter/s, 29.7564s/500 iters), loss = 0.0995691
I0830 19:43:43.648418 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0995716 (* 1 = 0.0995716 loss)
I0830 19:43:43.648432 916722 sgd_solver.cpp:106] Iteration 2053500, lr = 0.01
I0830 19:44:13.399279 916722 solver.cpp:218] Iteration 2054000 (16.8063 iter/s, 29.7508s/500 iters), loss = 0.175815
I0830 19:44:13.399333 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.175817 (* 1 = 0.175817 loss)
I0830 19:44:13.399343 916722 sgd_solver.cpp:106] Iteration 2054000, lr = 0.01
I0830 19:44:43.150442 916722 solver.cpp:218] Iteration 2054500 (16.8062 iter/s, 29.751s/500 iters), loss = 0.0828495
I0830 19:44:43.150504 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.082852 (* 1 = 0.082852 loss)
I0830 19:44:43.150512 916722 sgd_solver.cpp:106] Iteration 2054500, lr = 0.01
I0830 19:45:12.900463 916722 solver.cpp:218] Iteration 2055000 (16.8068 iter/s, 29.7499s/500 iters), loss = 0.135128
I0830 19:45:12.900517 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13513 (* 1 = 0.13513 loss)
I0830 19:45:12.900527 916722 sgd_solver.cpp:106] Iteration 2055000, lr = 0.01
I0830 19:45:42.653319 916722 solver.cpp:218] Iteration 2055500 (16.8052 iter/s, 29.7527s/500 iters), loss = 0.224425
I0830 19:45:42.653379 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.224428 (* 1 = 0.224428 loss)
I0830 19:45:42.653388 916722 sgd_solver.cpp:106] Iteration 2055500, lr = 0.01
I0830 19:46:12.402391 916722 solver.cpp:218] Iteration 2056000 (16.8073 iter/s, 29.7489s/500 iters), loss = 0.205442
I0830 19:46:12.402446 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.205444 (* 1 = 0.205444 loss)
I0830 19:46:12.402453 916722 sgd_solver.cpp:106] Iteration 2056000, lr = 0.01
I0830 19:46:42.154139 916722 solver.cpp:218] Iteration 2056500 (16.8058 iter/s, 29.7516s/500 iters), loss = 0.128443
I0830 19:46:42.154199 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128445 (* 1 = 0.128445 loss)
I0830 19:46:42.154208 916722 sgd_solver.cpp:106] Iteration 2056500, lr = 0.01
I0830 19:47:11.902884 916722 solver.cpp:218] Iteration 2057000 (16.8075 iter/s, 29.7486s/500 iters), loss = 0.0501113
I0830 19:47:11.902936 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0501138 (* 1 = 0.0501138 loss)
I0830 19:47:11.902945 916722 sgd_solver.cpp:106] Iteration 2057000, lr = 0.01
I0830 19:47:41.653769 916722 solver.cpp:218] Iteration 2057500 (16.8063 iter/s, 29.7507s/500 iters), loss = 0.199855
I0830 19:47:41.653829 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.199858 (* 1 = 0.199858 loss)
I0830 19:47:41.653838 916722 sgd_solver.cpp:106] Iteration 2057500, lr = 0.01
I0830 19:48:11.405403 916722 solver.cpp:218] Iteration 2058000 (16.8059 iter/s, 29.7515s/500 iters), loss = 0.0933077
I0830 19:48:11.405457 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.09331 (* 1 = 0.09331 loss)
I0830 19:48:11.405467 916722 sgd_solver.cpp:106] Iteration 2058000, lr = 0.01
I0830 19:48:41.152818 916722 solver.cpp:218] Iteration 2058500 (16.8083 iter/s, 29.7473s/500 iters), loss = 0.240949
I0830 19:48:41.152882 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.240951 (* 1 = 0.240951 loss)
I0830 19:48:41.152891 916722 sgd_solver.cpp:106] Iteration 2058500, lr = 0.01
I0830 19:49:10.899232 916722 solver.cpp:218] Iteration 2059000 (16.8088 iter/s, 29.7463s/500 iters), loss = 0.325332
I0830 19:49:10.899284 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.325335 (* 1 = 0.325335 loss)
I0830 19:49:10.899294 916722 sgd_solver.cpp:106] Iteration 2059000, lr = 0.01
I0830 19:49:40.648118 916722 solver.cpp:218] Iteration 2059500 (16.8074 iter/s, 29.7489s/500 iters), loss = 0.0899499
I0830 19:49:40.648188 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0899523 (* 1 = 0.0899523 loss)
I0830 19:49:40.648201 916722 sgd_solver.cpp:106] Iteration 2059500, lr = 0.01
I0830 19:50:10.391647 916722 solver.cpp:218] Iteration 2060000 (16.8104 iter/s, 29.7435s/500 iters), loss = 0.135258
I0830 19:50:10.391700 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13526 (* 1 = 0.13526 loss)
I0830 19:50:10.391710 916722 sgd_solver.cpp:106] Iteration 2060000, lr = 0.01
I0830 19:50:40.139892 916722 solver.cpp:218] Iteration 2060500 (16.8077 iter/s, 29.7482s/500 iters), loss = 0.0539896
I0830 19:50:40.139951 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0539919 (* 1 = 0.0539919 loss)
I0830 19:50:40.139961 916722 sgd_solver.cpp:106] Iteration 2060500, lr = 0.01
I0830 19:51:09.890691 916722 solver.cpp:218] Iteration 2061000 (16.8063 iter/s, 29.7508s/500 iters), loss = 0.0679155
I0830 19:51:09.890743 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0679177 (* 1 = 0.0679177 loss)
I0830 19:51:09.890753 916722 sgd_solver.cpp:106] Iteration 2061000, lr = 0.01
I0830 19:51:39.640267 916722 solver.cpp:218] Iteration 2061500 (16.807 iter/s, 29.7496s/500 iters), loss = 0.189569
I0830 19:51:39.640327 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.189571 (* 1 = 0.189571 loss)
I0830 19:51:39.640336 916722 sgd_solver.cpp:106] Iteration 2061500, lr = 0.01
I0830 19:52:09.389792 916722 solver.cpp:218] Iteration 2062000 (16.807 iter/s, 29.7495s/500 iters), loss = 0.0308307
I0830 19:52:09.389844 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0308328 (* 1 = 0.0308328 loss)
I0830 19:52:09.389854 916722 sgd_solver.cpp:106] Iteration 2062000, lr = 0.01
I0830 19:52:39.137845 916722 solver.cpp:218] Iteration 2062500 (16.8078 iter/s, 29.748s/500 iters), loss = 0.199767
I0830 19:52:39.137902 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.199769 (* 1 = 0.199769 loss)
I0830 19:52:39.137912 916722 sgd_solver.cpp:106] Iteration 2062500, lr = 0.01
I0830 19:53:08.887250 916722 solver.cpp:218] Iteration 2063000 (16.8071 iter/s, 29.7494s/500 iters), loss = 0.0465455
I0830 19:53:08.887305 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0465477 (* 1 = 0.0465477 loss)
I0830 19:53:08.887315 916722 sgd_solver.cpp:106] Iteration 2063000, lr = 0.01
I0830 19:53:38.640483 916722 solver.cpp:218] Iteration 2063500 (16.8049 iter/s, 29.7532s/500 iters), loss = 0.0662814
I0830 19:53:38.640547 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0662837 (* 1 = 0.0662837 loss)
I0830 19:53:38.640555 916722 sgd_solver.cpp:106] Iteration 2063500, lr = 0.01
I0830 19:54:08.388636 916722 solver.cpp:218] Iteration 2064000 (16.8078 iter/s, 29.7481s/500 iters), loss = 0.0248996
I0830 19:54:08.388689 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0249019 (* 1 = 0.0249019 loss)
I0830 19:54:08.388698 916722 sgd_solver.cpp:106] Iteration 2064000, lr = 0.01
I0830 19:54:38.139838 916722 solver.cpp:218] Iteration 2064500 (16.8061 iter/s, 29.7512s/500 iters), loss = 0.133617
I0830 19:54:38.139899 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133619 (* 1 = 0.133619 loss)
I0830 19:54:38.139907 916722 sgd_solver.cpp:106] Iteration 2064500, lr = 0.01
I0830 19:55:07.891458 916722 solver.cpp:218] Iteration 2065000 (16.8058 iter/s, 29.7516s/500 iters), loss = 0.0503792
I0830 19:55:07.891511 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0503815 (* 1 = 0.0503815 loss)
I0830 19:55:07.891520 916722 sgd_solver.cpp:106] Iteration 2065000, lr = 0.01
I0830 19:55:37.643220 916722 solver.cpp:218] Iteration 2065500 (16.8058 iter/s, 29.7517s/500 iters), loss = 0.0935421
I0830 19:55:37.643280 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0935445 (* 1 = 0.0935445 loss)
I0830 19:55:37.643290 916722 sgd_solver.cpp:106] Iteration 2065500, lr = 0.01
I0830 19:56:07.393975 916722 solver.cpp:218] Iteration 2066000 (16.8063 iter/s, 29.7507s/500 iters), loss = 0.353466
I0830 19:56:07.394027 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.353468 (* 1 = 0.353468 loss)
I0830 19:56:07.394037 916722 sgd_solver.cpp:106] Iteration 2066000, lr = 0.01
I0830 19:56:37.141867 916722 solver.cpp:218] Iteration 2066500 (16.808 iter/s, 29.7478s/500 iters), loss = 0.0344453
I0830 19:56:37.141938 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0344476 (* 1 = 0.0344476 loss)
I0830 19:56:37.141952 916722 sgd_solver.cpp:106] Iteration 2066500, lr = 0.01
I0830 19:57:06.890823 916722 solver.cpp:218] Iteration 2067000 (16.8074 iter/s, 29.7489s/500 iters), loss = 0.0580765
I0830 19:57:06.890874 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0580788 (* 1 = 0.0580788 loss)
I0830 19:57:06.890883 916722 sgd_solver.cpp:106] Iteration 2067000, lr = 0.01
I0830 19:57:36.641124 916722 solver.cpp:218] Iteration 2067500 (16.8066 iter/s, 29.7502s/500 iters), loss = 0.133325
I0830 19:57:36.641187 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133328 (* 1 = 0.133328 loss)
I0830 19:57:36.641196 916722 sgd_solver.cpp:106] Iteration 2067500, lr = 0.01
I0830 19:58:06.388715 916722 solver.cpp:218] Iteration 2068000 (16.8081 iter/s, 29.7475s/500 iters), loss = 0.465536
I0830 19:58:06.388768 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.465538 (* 1 = 0.465538 loss)
I0830 19:58:06.388777 916722 sgd_solver.cpp:106] Iteration 2068000, lr = 0.01
I0830 19:58:36.136269 916722 solver.cpp:218] Iteration 2068500 (16.8081 iter/s, 29.7475s/500 iters), loss = 0.0220906
I0830 19:58:36.136328 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.022093 (* 1 = 0.022093 loss)
I0830 19:58:36.136337 916722 sgd_solver.cpp:106] Iteration 2068500, lr = 0.01
I0830 19:59:05.882905 916722 solver.cpp:218] Iteration 2069000 (16.8087 iter/s, 29.7465s/500 iters), loss = 0.167601
I0830 19:59:05.882962 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.167603 (* 1 = 0.167603 loss)
I0830 19:59:05.882972 916722 sgd_solver.cpp:106] Iteration 2069000, lr = 0.01
I0830 19:59:35.626024 916722 solver.cpp:218] Iteration 2069500 (16.8107 iter/s, 29.743s/500 iters), loss = 0.32877
I0830 19:59:35.626083 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.328772 (* 1 = 0.328772 loss)
I0830 19:59:35.626091 916722 sgd_solver.cpp:106] Iteration 2069500, lr = 0.01
I0830 20:00:05.378111 916722 solver.cpp:218] Iteration 2070000 (16.8056 iter/s, 29.752s/500 iters), loss = 0.095316
I0830 20:00:05.378167 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0953183 (* 1 = 0.0953183 loss)
I0830 20:00:05.378177 916722 sgd_solver.cpp:106] Iteration 2070000, lr = 0.01
I0830 20:00:35.128635 916722 solver.cpp:218] Iteration 2070500 (16.8065 iter/s, 29.7504s/500 iters), loss = 0.765657
I0830 20:00:35.128697 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.765659 (* 1 = 0.765659 loss)
I0830 20:00:35.128706 916722 sgd_solver.cpp:106] Iteration 2070500, lr = 0.01
I0830 20:01:04.876250 916722 solver.cpp:218] Iteration 2071000 (16.8081 iter/s, 29.7475s/500 iters), loss = 0.257964
I0830 20:01:04.876299 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.257966 (* 1 = 0.257966 loss)
I0830 20:01:04.876307 916722 sgd_solver.cpp:106] Iteration 2071000, lr = 0.01
I0830 20:01:34.621137 916722 solver.cpp:218] Iteration 2071500 (16.8097 iter/s, 29.7448s/500 iters), loss = 0.0902139
I0830 20:01:34.621196 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0902163 (* 1 = 0.0902163 loss)
I0830 20:01:34.621206 916722 sgd_solver.cpp:106] Iteration 2071500, lr = 0.01
I0830 20:02:04.367987 916722 solver.cpp:218] Iteration 2072000 (16.8086 iter/s, 29.7467s/500 iters), loss = 0.271747
I0830 20:02:04.368041 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.271749 (* 1 = 0.271749 loss)
I0830 20:02:04.368049 916722 sgd_solver.cpp:106] Iteration 2072000, lr = 0.01
I0830 20:02:34.114295 916722 solver.cpp:218] Iteration 2072500 (16.8089 iter/s, 29.7462s/500 iters), loss = 0.155525
I0830 20:02:34.114356 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.155528 (* 1 = 0.155528 loss)
I0830 20:02:34.114363 916722 sgd_solver.cpp:106] Iteration 2072500, lr = 0.01
I0830 20:03:03.855898 916722 solver.cpp:218] Iteration 2073000 (16.8115 iter/s, 29.7415s/500 iters), loss = 0.0525366
I0830 20:03:03.855950 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0525393 (* 1 = 0.0525393 loss)
I0830 20:03:03.855959 916722 sgd_solver.cpp:106] Iteration 2073000, lr = 0.01
I0830 20:03:33.601595 916722 solver.cpp:218] Iteration 2073500 (16.8092 iter/s, 29.7456s/500 iters), loss = 0.0133071
I0830 20:03:33.601668 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0133097 (* 1 = 0.0133097 loss)
I0830 20:03:33.601677 916722 sgd_solver.cpp:106] Iteration 2073500, lr = 0.01
I0830 20:04:03.346572 916722 solver.cpp:218] Iteration 2074000 (16.8096 iter/s, 29.7448s/500 iters), loss = 0.0808661
I0830 20:04:03.346627 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0808688 (* 1 = 0.0808688 loss)
I0830 20:04:03.346637 916722 sgd_solver.cpp:106] Iteration 2074000, lr = 0.01
I0830 20:04:33.094650 916722 solver.cpp:218] Iteration 2074500 (16.8079 iter/s, 29.748s/500 iters), loss = 0.0751174
I0830 20:04:33.094709 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0751202 (* 1 = 0.0751202 loss)
I0830 20:04:33.094718 916722 sgd_solver.cpp:106] Iteration 2074500, lr = 0.01
I0830 20:05:02.845916 916722 solver.cpp:218] Iteration 2075000 (16.8061 iter/s, 29.7512s/500 iters), loss = 0.110445
I0830 20:05:02.845968 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110448 (* 1 = 0.110448 loss)
I0830 20:05:02.845978 916722 sgd_solver.cpp:106] Iteration 2075000, lr = 0.01
I0830 20:05:32.593551 916722 solver.cpp:218] Iteration 2075500 (16.8081 iter/s, 29.7475s/500 iters), loss = 0.114968
I0830 20:05:32.593611 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.114971 (* 1 = 0.114971 loss)
I0830 20:05:32.593619 916722 sgd_solver.cpp:106] Iteration 2075500, lr = 0.01
I0830 20:06:02.340746 916722 solver.cpp:218] Iteration 2076000 (16.8084 iter/s, 29.7471s/500 iters), loss = 0.0570707
I0830 20:06:02.340806 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0570734 (* 1 = 0.0570734 loss)
I0830 20:06:02.340816 916722 sgd_solver.cpp:106] Iteration 2076000, lr = 0.01
I0830 20:06:32.090876 916722 solver.cpp:218] Iteration 2076500 (16.8067 iter/s, 29.75s/500 iters), loss = 0.236829
I0830 20:06:32.090937 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.236832 (* 1 = 0.236832 loss)
I0830 20:06:32.090946 916722 sgd_solver.cpp:106] Iteration 2076500, lr = 0.01
I0830 20:07:01.836107 916722 solver.cpp:218] Iteration 2077000 (16.8095 iter/s, 29.7451s/500 iters), loss = 0.0692879
I0830 20:07:01.836159 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0692907 (* 1 = 0.0692907 loss)
I0830 20:07:01.836169 916722 sgd_solver.cpp:106] Iteration 2077000, lr = 0.01
I0830 20:07:31.576220 916722 solver.cpp:218] Iteration 2077500 (16.8124 iter/s, 29.74s/500 iters), loss = 0.217431
I0830 20:07:31.576282 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.217433 (* 1 = 0.217433 loss)
I0830 20:07:31.576292 916722 sgd_solver.cpp:106] Iteration 2077500, lr = 0.01
I0830 20:08:01.318317 916722 solver.cpp:218] Iteration 2078000 (16.8113 iter/s, 29.742s/500 iters), loss = 0.342624
I0830 20:08:01.318369 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.342627 (* 1 = 0.342627 loss)
I0830 20:08:01.318379 916722 sgd_solver.cpp:106] Iteration 2078000, lr = 0.01
I0830 20:08:31.067778 916722 solver.cpp:218] Iteration 2078500 (16.8071 iter/s, 29.7493s/500 iters), loss = 0.240324
I0830 20:08:31.067835 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.240327 (* 1 = 0.240327 loss)
I0830 20:08:31.067843 916722 sgd_solver.cpp:106] Iteration 2078500, lr = 0.01
I0830 20:09:00.811350 916722 solver.cpp:218] Iteration 2079000 (16.8104 iter/s, 29.7435s/500 iters), loss = 0.311208
I0830 20:09:00.811404 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.311211 (* 1 = 0.311211 loss)
I0830 20:09:00.811414 916722 sgd_solver.cpp:106] Iteration 2079000, lr = 0.01
I0830 20:09:30.558945 916722 solver.cpp:218] Iteration 2079500 (16.8082 iter/s, 29.7475s/500 iters), loss = 0.254864
I0830 20:09:30.559027 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.254866 (* 1 = 0.254866 loss)
I0830 20:09:30.559036 916722 sgd_solver.cpp:106] Iteration 2079500, lr = 0.01
I0830 20:10:00.305732 916722 solver.cpp:218] Iteration 2080000 (16.8086 iter/s, 29.7466s/500 iters), loss = 0.266249
I0830 20:10:00.305788 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.266252 (* 1 = 0.266252 loss)
I0830 20:10:00.305796 916722 sgd_solver.cpp:106] Iteration 2080000, lr = 0.01
I0830 20:10:30.048998 916722 solver.cpp:218] Iteration 2080500 (16.8106 iter/s, 29.7431s/500 iters), loss = 0.329284
I0830 20:10:30.049060 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.329287 (* 1 = 0.329287 loss)
I0830 20:10:30.049068 916722 sgd_solver.cpp:106] Iteration 2080500, lr = 0.01
I0830 20:10:59.793469 916722 solver.cpp:218] Iteration 2081000 (16.8099 iter/s, 29.7443s/500 iters), loss = 0.177039
I0830 20:10:59.793524 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.177041 (* 1 = 0.177041 loss)
I0830 20:10:59.793534 916722 sgd_solver.cpp:106] Iteration 2081000, lr = 0.01
I0830 20:11:29.542954 916722 solver.cpp:218] Iteration 2081500 (16.8071 iter/s, 29.7494s/500 iters), loss = 0.166265
I0830 20:11:29.543015 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.166268 (* 1 = 0.166268 loss)
I0830 20:11:29.543023 916722 sgd_solver.cpp:106] Iteration 2081500, lr = 0.01
I0830 20:11:59.288040 916722 solver.cpp:218] Iteration 2082000 (16.8096 iter/s, 29.745s/500 iters), loss = 0.0257165
I0830 20:11:59.288094 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0257192 (* 1 = 0.0257192 loss)
I0830 20:11:59.288102 916722 sgd_solver.cpp:106] Iteration 2082000, lr = 0.01
I0830 20:12:29.034194 916722 solver.cpp:218] Iteration 2082500 (16.809 iter/s, 29.746s/500 iters), loss = 0.0586799
I0830 20:12:29.034255 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0586826 (* 1 = 0.0586826 loss)
I0830 20:12:29.034265 916722 sgd_solver.cpp:106] Iteration 2082500, lr = 0.01
I0830 20:12:58.785352 916722 solver.cpp:218] Iteration 2083000 (16.8061 iter/s, 29.751s/500 iters), loss = 0.379255
I0830 20:12:58.785406 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.379257 (* 1 = 0.379257 loss)
I0830 20:12:58.785415 916722 sgd_solver.cpp:106] Iteration 2083000, lr = 0.01
I0830 20:13:28.533025 916722 solver.cpp:218] Iteration 2083500 (16.8081 iter/s, 29.7475s/500 iters), loss = 0.235528
I0830 20:13:28.533085 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.23553 (* 1 = 0.23553 loss)
I0830 20:13:28.533094 916722 sgd_solver.cpp:106] Iteration 2083500, lr = 0.01
I0830 20:13:58.276760 916722 solver.cpp:218] Iteration 2084000 (16.8103 iter/s, 29.7436s/500 iters), loss = 0.11558
I0830 20:13:58.276814 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115583 (* 1 = 0.115583 loss)
I0830 20:13:58.276823 916722 sgd_solver.cpp:106] Iteration 2084000, lr = 0.01
I0830 20:14:28.029049 916722 solver.cpp:218] Iteration 2084500 (16.8055 iter/s, 29.7522s/500 iters), loss = 0.0655705
I0830 20:14:28.029112 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0655731 (* 1 = 0.0655731 loss)
I0830 20:14:28.029120 916722 sgd_solver.cpp:106] Iteration 2084500, lr = 0.01
I0830 20:14:57.777451 916722 solver.cpp:218] Iteration 2085000 (16.8077 iter/s, 29.7483s/500 iters), loss = 0.223479
I0830 20:14:57.777508 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.223481 (* 1 = 0.223481 loss)
I0830 20:14:57.777518 916722 sgd_solver.cpp:106] Iteration 2085000, lr = 0.01
I0830 20:15:27.526715 916722 solver.cpp:218] Iteration 2085500 (16.8072 iter/s, 29.7491s/500 iters), loss = 0.131992
I0830 20:15:27.526775 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131995 (* 1 = 0.131995 loss)
I0830 20:15:27.526784 916722 sgd_solver.cpp:106] Iteration 2085500, lr = 0.01
I0830 20:15:57.272200 916722 solver.cpp:218] Iteration 2086000 (16.8093 iter/s, 29.7454s/500 iters), loss = 0.134008
I0830 20:15:57.272264 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13401 (* 1 = 0.13401 loss)
I0830 20:15:57.272275 916722 sgd_solver.cpp:106] Iteration 2086000, lr = 0.01
I0830 20:16:27.016456 916722 solver.cpp:218] Iteration 2086500 (16.81 iter/s, 29.7441s/500 iters), loss = 0.12082
I0830 20:16:27.016527 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.120822 (* 1 = 0.120822 loss)
I0830 20:16:27.016536 916722 sgd_solver.cpp:106] Iteration 2086500, lr = 0.01
I0830 20:16:56.758002 916722 solver.cpp:218] Iteration 2087000 (16.8116 iter/s, 29.7414s/500 iters), loss = 0.0792574
I0830 20:16:56.758054 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.07926 (* 1 = 0.07926 loss)
I0830 20:16:56.758064 916722 sgd_solver.cpp:106] Iteration 2087000, lr = 0.01
I0830 20:17:26.503564 916722 solver.cpp:218] Iteration 2087500 (16.8093 iter/s, 29.7454s/500 iters), loss = 0.236204
I0830 20:17:26.503623 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.236206 (* 1 = 0.236206 loss)
I0830 20:17:26.503633 916722 sgd_solver.cpp:106] Iteration 2087500, lr = 0.01
I0830 20:17:56.253898 916722 solver.cpp:218] Iteration 2088000 (16.8066 iter/s, 29.7502s/500 iters), loss = 0.102925
I0830 20:17:56.253953 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.102928 (* 1 = 0.102928 loss)
I0830 20:17:56.253963 916722 sgd_solver.cpp:106] Iteration 2088000, lr = 0.01
I0830 20:18:26.001428 916722 solver.cpp:218] Iteration 2088500 (16.8082 iter/s, 29.7474s/500 iters), loss = 0.0357243
I0830 20:18:26.001488 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.035727 (* 1 = 0.035727 loss)
I0830 20:18:26.001497 916722 sgd_solver.cpp:106] Iteration 2088500, lr = 0.01
I0830 20:18:55.748764 916722 solver.cpp:218] Iteration 2089000 (16.8083 iter/s, 29.7472s/500 iters), loss = 0.0582743
I0830 20:18:55.748821 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.058277 (* 1 = 0.058277 loss)
I0830 20:18:55.748831 916722 sgd_solver.cpp:106] Iteration 2089000, lr = 0.01
I0830 20:19:25.499264 916722 solver.cpp:218] Iteration 2089500 (16.8065 iter/s, 29.7504s/500 iters), loss = 0.169092
I0830 20:19:25.499326 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.169094 (* 1 = 0.169094 loss)
I0830 20:19:25.499336 916722 sgd_solver.cpp:106] Iteration 2089500, lr = 0.01
I0830 20:19:55.246592 916722 solver.cpp:218] Iteration 2090000 (16.8083 iter/s, 29.7472s/500 iters), loss = 0.0762689
I0830 20:19:55.246642 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0762715 (* 1 = 0.0762715 loss)
I0830 20:19:55.246650 916722 sgd_solver.cpp:106] Iteration 2090000, lr = 0.01
I0830 20:20:24.992182 916722 solver.cpp:218] Iteration 2090500 (16.8093 iter/s, 29.7455s/500 iters), loss = 0.0338392
I0830 20:20:24.992244 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0338418 (* 1 = 0.0338418 loss)
I0830 20:20:24.992254 916722 sgd_solver.cpp:106] Iteration 2090500, lr = 0.01
I0830 20:20:54.744594 916722 solver.cpp:218] Iteration 2091000 (16.8054 iter/s, 29.7523s/500 iters), loss = 0.100202
I0830 20:20:54.744648 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.100205 (* 1 = 0.100205 loss)
I0830 20:20:54.744657 916722 sgd_solver.cpp:106] Iteration 2091000, lr = 0.01
I0830 20:21:24.493276 916722 solver.cpp:218] Iteration 2091500 (16.8075 iter/s, 29.7486s/500 iters), loss = 0.190437
I0830 20:21:24.493336 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.19044 (* 1 = 0.19044 loss)
I0830 20:21:24.493345 916722 sgd_solver.cpp:106] Iteration 2091500, lr = 0.01
I0830 20:21:54.238760 916722 solver.cpp:218] Iteration 2092000 (16.8094 iter/s, 29.7453s/500 iters), loss = 0.248766
I0830 20:21:54.238814 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.248768 (* 1 = 0.248768 loss)
I0830 20:21:54.238823 916722 sgd_solver.cpp:106] Iteration 2092000, lr = 0.01
I0830 20:22:23.989377 916722 solver.cpp:218] Iteration 2092500 (16.8064 iter/s, 29.7505s/500 iters), loss = 0.0313723
I0830 20:22:23.989452 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.031375 (* 1 = 0.031375 loss)
I0830 20:22:23.989461 916722 sgd_solver.cpp:106] Iteration 2092500, lr = 0.01
I0830 20:22:53.735347 916722 solver.cpp:218] Iteration 2093000 (16.8091 iter/s, 29.7458s/500 iters), loss = 0.233368
I0830 20:22:53.735400 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.23337 (* 1 = 0.23337 loss)
I0830 20:22:53.735409 916722 sgd_solver.cpp:106] Iteration 2093000, lr = 0.01
I0830 20:23:23.479308 916722 solver.cpp:218] Iteration 2093500 (16.8102 iter/s, 29.7438s/500 iters), loss = 0.102529
I0830 20:23:23.479372 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.102532 (* 1 = 0.102532 loss)
I0830 20:23:23.479380 916722 sgd_solver.cpp:106] Iteration 2093500, lr = 0.01
I0830 20:23:53.223011 916722 solver.cpp:218] Iteration 2094000 (16.8104 iter/s, 29.7435s/500 iters), loss = 0.0501283
I0830 20:23:53.223065 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0501309 (* 1 = 0.0501309 loss)
I0830 20:23:53.223073 916722 sgd_solver.cpp:106] Iteration 2094000, lr = 0.01
I0830 20:24:22.969724 916722 solver.cpp:218] Iteration 2094500 (16.8087 iter/s, 29.7466s/500 iters), loss = 0.447137
I0830 20:24:22.969784 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.447139 (* 1 = 0.447139 loss)
I0830 20:24:22.969792 916722 sgd_solver.cpp:106] Iteration 2094500, lr = 0.01
I0830 20:24:52.715528 916722 solver.cpp:218] Iteration 2095000 (16.8092 iter/s, 29.7456s/500 iters), loss = 0.0526673
I0830 20:24:52.715581 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0526695 (* 1 = 0.0526695 loss)
I0830 20:24:52.715590 916722 sgd_solver.cpp:106] Iteration 2095000, lr = 0.01
I0830 20:25:22.465328 916722 solver.cpp:218] Iteration 2095500 (16.8069 iter/s, 29.7497s/500 iters), loss = 0.0614862
I0830 20:25:22.465387 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0614885 (* 1 = 0.0614885 loss)
I0830 20:25:22.465396 916722 sgd_solver.cpp:106] Iteration 2095500, lr = 0.01
I0830 20:25:52.210381 916722 solver.cpp:218] Iteration 2096000 (16.8096 iter/s, 29.7449s/500 iters), loss = 0.190562
I0830 20:25:52.210431 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.190565 (* 1 = 0.190565 loss)
I0830 20:25:52.210440 916722 sgd_solver.cpp:106] Iteration 2096000, lr = 0.01
I0830 20:26:21.957705 916722 solver.cpp:218] Iteration 2096500 (16.8083 iter/s, 29.7472s/500 iters), loss = 0.229634
I0830 20:26:21.957767 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.229636 (* 1 = 0.229636 loss)
I0830 20:26:21.957774 916722 sgd_solver.cpp:106] Iteration 2096500, lr = 0.01
I0830 20:26:51.702415 916722 solver.cpp:218] Iteration 2097000 (16.8098 iter/s, 29.7445s/500 iters), loss = 0.0484
I0830 20:26:51.702473 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0484022 (* 1 = 0.0484022 loss)
I0830 20:26:51.702483 916722 sgd_solver.cpp:106] Iteration 2097000, lr = 0.01
I0830 20:27:21.451169 916722 solver.cpp:218] Iteration 2097500 (16.8075 iter/s, 29.7486s/500 iters), loss = 0.386294
I0830 20:27:21.451231 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.386296 (* 1 = 0.386296 loss)
I0830 20:27:21.451238 916722 sgd_solver.cpp:106] Iteration 2097500, lr = 0.01
I0830 20:27:51.197659 916722 solver.cpp:218] Iteration 2098000 (16.8088 iter/s, 29.7463s/500 iters), loss = 0.0253545
I0830 20:27:51.197713 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0253566 (* 1 = 0.0253566 loss)
I0830 20:27:51.197723 916722 sgd_solver.cpp:106] Iteration 2098000, lr = 0.01
I0830 20:28:20.950258 916722 solver.cpp:218] Iteration 2098500 (16.8053 iter/s, 29.7524s/500 iters), loss = 0.0449926
I0830 20:28:20.950320 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0449947 (* 1 = 0.0449947 loss)
I0830 20:28:20.950328 916722 sgd_solver.cpp:106] Iteration 2098500, lr = 0.01
I0830 20:28:50.693696 916722 solver.cpp:218] Iteration 2099000 (16.8105 iter/s, 29.7433s/500 iters), loss = 0.180758
I0830 20:28:50.693750 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.18076 (* 1 = 0.18076 loss)
I0830 20:28:50.693776 916722 sgd_solver.cpp:106] Iteration 2099000, lr = 0.01
I0830 20:29:20.437891 916722 solver.cpp:218] Iteration 2099500 (16.8101 iter/s, 29.744s/500 iters), loss = 0.0981246
I0830 20:29:20.437960 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0981266 (* 1 = 0.0981266 loss)
I0830 20:29:20.437968 916722 sgd_solver.cpp:106] Iteration 2099500, lr = 0.01
I0830 20:29:50.122965 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_2100000.caffemodel
I0830 20:29:50.142202 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_2100000.solverstate
I0830 20:29:50.148314 916722 solver.cpp:330] Iteration 2100000, Testing net (#0)
I0830 20:30:05.526036 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8895
I0830 20:30:05.526086 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.385939 (* 1 = 0.385939 loss)
I0830 20:30:05.584591 916722 solver.cpp:218] Iteration 2100000 (11.0751 iter/s, 45.1465s/500 iters), loss = 0.100604
I0830 20:30:05.584622 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.100606 (* 1 = 0.100606 loss)
I0830 20:30:05.584630 916722 sgd_solver.cpp:106] Iteration 2100000, lr = 0.01
I0830 20:30:35.213341 916722 solver.cpp:218] Iteration 2100500 (16.8756 iter/s, 29.6286s/500 iters), loss = 0.0333961
I0830 20:30:35.213397 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0333981 (* 1 = 0.0333981 loss)
I0830 20:30:35.213407 916722 sgd_solver.cpp:106] Iteration 2100500, lr = 0.01
I0830 20:31:04.895689 916722 solver.cpp:218] Iteration 2101000 (16.8451 iter/s, 29.6822s/500 iters), loss = 0.131149
I0830 20:31:04.895749 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131151 (* 1 = 0.131151 loss)
I0830 20:31:04.895757 916722 sgd_solver.cpp:106] Iteration 2101000, lr = 0.01
I0830 20:31:34.627954 916722 solver.cpp:218] Iteration 2101500 (16.8168 iter/s, 29.7321s/500 iters), loss = 0.139696
I0830 20:31:34.628007 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139698 (* 1 = 0.139698 loss)
I0830 20:31:34.628017 916722 sgd_solver.cpp:106] Iteration 2101500, lr = 0.01
I0830 20:32:04.360263 916722 solver.cpp:218] Iteration 2102000 (16.8168 iter/s, 29.7322s/500 iters), loss = 0.275942
I0830 20:32:04.360319 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.275944 (* 1 = 0.275944 loss)
I0830 20:32:04.360327 916722 sgd_solver.cpp:106] Iteration 2102000, lr = 0.01
I0830 20:32:34.094923 916722 solver.cpp:218] Iteration 2102500 (16.8155 iter/s, 29.7345s/500 iters), loss = 0.133911
I0830 20:32:34.094978 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133913 (* 1 = 0.133913 loss)
I0830 20:32:34.094988 916722 sgd_solver.cpp:106] Iteration 2102500, lr = 0.01
I0830 20:33:03.829124 916722 solver.cpp:218] Iteration 2103000 (16.8157 iter/s, 29.7341s/500 iters), loss = 0.222264
I0830 20:33:03.829185 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.222266 (* 1 = 0.222266 loss)
I0830 20:33:03.829192 916722 sgd_solver.cpp:106] Iteration 2103000, lr = 0.01
I0830 20:33:33.565693 916722 solver.cpp:218] Iteration 2103500 (16.8144 iter/s, 29.7364s/500 iters), loss = 0.0496422
I0830 20:33:33.565747 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0496442 (* 1 = 0.0496442 loss)
I0830 20:33:33.565757 916722 sgd_solver.cpp:106] Iteration 2103500, lr = 0.01
I0830 20:34:03.304668 916722 solver.cpp:218] Iteration 2104000 (16.813 iter/s, 29.7388s/500 iters), loss = 0.312926
I0830 20:34:03.304728 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.312928 (* 1 = 0.312928 loss)
I0830 20:34:03.304738 916722 sgd_solver.cpp:106] Iteration 2104000, lr = 0.01
I0830 20:34:33.043012 916722 solver.cpp:218] Iteration 2104500 (16.8134 iter/s, 29.7382s/500 iters), loss = 0.0437762
I0830 20:34:33.043066 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0437782 (* 1 = 0.0437782 loss)
I0830 20:34:33.043076 916722 sgd_solver.cpp:106] Iteration 2104500, lr = 0.01
I0830 20:35:02.781087 916722 solver.cpp:218] Iteration 2105000 (16.8135 iter/s, 29.7379s/500 iters), loss = 0.24999
I0830 20:35:02.781157 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.249992 (* 1 = 0.249992 loss)
I0830 20:35:02.781165 916722 sgd_solver.cpp:106] Iteration 2105000, lr = 0.01
I0830 20:35:32.526124 916722 solver.cpp:218] Iteration 2105500 (16.8096 iter/s, 29.7449s/500 iters), loss = 0.257788
I0830 20:35:32.526181 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.25779 (* 1 = 0.25779 loss)
I0830 20:35:32.526192 916722 sgd_solver.cpp:106] Iteration 2105500, lr = 0.01
I0830 20:36:02.259130 916722 solver.cpp:218] Iteration 2106000 (16.8164 iter/s, 29.7329s/500 iters), loss = 0.351873
I0830 20:36:02.259193 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.351875 (* 1 = 0.351875 loss)
I0830 20:36:02.259202 916722 sgd_solver.cpp:106] Iteration 2106000, lr = 0.01
I0830 20:36:31.996204 916722 solver.cpp:218] Iteration 2106500 (16.8141 iter/s, 29.7369s/500 iters), loss = 0.055976
I0830 20:36:31.996254 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0559779 (* 1 = 0.0559779 loss)
I0830 20:36:31.996263 916722 sgd_solver.cpp:106] Iteration 2106500, lr = 0.01
I0830 20:37:01.728832 916722 solver.cpp:218] Iteration 2107000 (16.8166 iter/s, 29.7325s/500 iters), loss = 0.0192605
I0830 20:37:01.728889 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0192625 (* 1 = 0.0192625 loss)
I0830 20:37:01.728899 916722 sgd_solver.cpp:106] Iteration 2107000, lr = 0.01
I0830 20:37:31.462359 916722 solver.cpp:218] Iteration 2107500 (16.8161 iter/s, 29.7334s/500 iters), loss = 0.040094
I0830 20:37:31.462412 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0400962 (* 1 = 0.0400962 loss)
I0830 20:37:31.462420 916722 sgd_solver.cpp:106] Iteration 2107500, lr = 0.01
I0830 20:38:01.199057 916722 solver.cpp:218] Iteration 2108000 (16.8143 iter/s, 29.7366s/500 iters), loss = 0.102745
I0830 20:38:01.199115 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.102747 (* 1 = 0.102747 loss)
I0830 20:38:01.199123 916722 sgd_solver.cpp:106] Iteration 2108000, lr = 0.01
I0830 20:38:30.933970 916722 solver.cpp:218] Iteration 2108500 (16.8153 iter/s, 29.7348s/500 iters), loss = 0.11411
I0830 20:38:30.934023 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.114113 (* 1 = 0.114113 loss)
I0830 20:38:30.934032 916722 sgd_solver.cpp:106] Iteration 2108500, lr = 0.01
I0830 20:39:00.666972 916722 solver.cpp:218] Iteration 2109000 (16.8164 iter/s, 29.7329s/500 iters), loss = 0.0488731
I0830 20:39:00.667029 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0488755 (* 1 = 0.0488755 loss)
I0830 20:39:00.667038 916722 sgd_solver.cpp:106] Iteration 2109000, lr = 0.01
I0830 20:39:30.400171 916722 solver.cpp:218] Iteration 2109500 (16.8163 iter/s, 29.7331s/500 iters), loss = 0.0993204
I0830 20:39:30.400228 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0993227 (* 1 = 0.0993227 loss)
I0830 20:39:30.400235 916722 sgd_solver.cpp:106] Iteration 2109500, lr = 0.01
I0830 20:40:00.131990 916722 solver.cpp:218] Iteration 2110000 (16.8171 iter/s, 29.7317s/500 iters), loss = 0.0701333
I0830 20:40:00.132050 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0701358 (* 1 = 0.0701358 loss)
I0830 20:40:00.132058 916722 sgd_solver.cpp:106] Iteration 2110000, lr = 0.01
I0830 20:40:29.865188 916722 solver.cpp:218] Iteration 2110500 (16.8163 iter/s, 29.733s/500 iters), loss = 0.0437306
I0830 20:40:29.865239 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.043733 (* 1 = 0.043733 loss)
I0830 20:40:29.865247 916722 sgd_solver.cpp:106] Iteration 2110500, lr = 0.01
I0830 20:40:59.597887 916722 solver.cpp:218] Iteration 2111000 (16.8166 iter/s, 29.7326s/500 iters), loss = 0.400206
I0830 20:40:59.597944 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.400209 (* 1 = 0.400209 loss)
I0830 20:40:59.597951 916722 sgd_solver.cpp:106] Iteration 2111000, lr = 0.01
I0830 20:41:29.327244 916722 solver.cpp:218] Iteration 2111500 (16.8185 iter/s, 29.7292s/500 iters), loss = 0.131817
I0830 20:41:29.327301 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131819 (* 1 = 0.131819 loss)
I0830 20:41:29.327311 916722 sgd_solver.cpp:106] Iteration 2111500, lr = 0.01
I0830 20:41:59.059461 916722 solver.cpp:218] Iteration 2112000 (16.8169 iter/s, 29.7321s/500 iters), loss = 0.0509573
I0830 20:41:59.059535 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0509597 (* 1 = 0.0509597 loss)
I0830 20:41:59.059542 916722 sgd_solver.cpp:106] Iteration 2112000, lr = 0.01
I0830 20:42:28.789175 916722 solver.cpp:218] Iteration 2112500 (16.8183 iter/s, 29.7296s/500 iters), loss = 0.181905
I0830 20:42:28.789228 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.181908 (* 1 = 0.181908 loss)
I0830 20:42:28.789238 916722 sgd_solver.cpp:106] Iteration 2112500, lr = 0.01
I0830 20:42:58.520848 916722 solver.cpp:218] Iteration 2113000 (16.8172 iter/s, 29.7315s/500 iters), loss = 0.176169
I0830 20:42:58.520907 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.176171 (* 1 = 0.176171 loss)
I0830 20:42:58.520915 916722 sgd_solver.cpp:106] Iteration 2113000, lr = 0.01
I0830 20:43:28.245920 916722 solver.cpp:218] Iteration 2113500 (16.8209 iter/s, 29.7249s/500 iters), loss = 0.0897384
I0830 20:43:28.245975 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0897408 (* 1 = 0.0897408 loss)
I0830 20:43:28.245985 916722 sgd_solver.cpp:106] Iteration 2113500, lr = 0.01
I0830 20:43:57.978637 916722 solver.cpp:218] Iteration 2114000 (16.8166 iter/s, 29.7326s/500 iters), loss = 0.0742663
I0830 20:43:57.978695 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0742686 (* 1 = 0.0742686 loss)
I0830 20:43:57.978703 916722 sgd_solver.cpp:106] Iteration 2114000, lr = 0.01
I0830 20:44:27.713238 916722 solver.cpp:218] Iteration 2114500 (16.8155 iter/s, 29.7345s/500 iters), loss = 0.0726351
I0830 20:44:27.713289 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0726372 (* 1 = 0.0726372 loss)
I0830 20:44:27.713299 916722 sgd_solver.cpp:106] Iteration 2114500, lr = 0.01
I0830 20:44:57.449297 916722 solver.cpp:218] Iteration 2115000 (16.8147 iter/s, 29.7359s/500 iters), loss = 0.0369835
I0830 20:44:57.449353 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0369855 (* 1 = 0.0369855 loss)
I0830 20:44:57.449362 916722 sgd_solver.cpp:106] Iteration 2115000, lr = 0.01
I0830 20:45:27.182390 916722 solver.cpp:218] Iteration 2115500 (16.8164 iter/s, 29.733s/500 iters), loss = 0.102764
I0830 20:45:27.182446 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.102766 (* 1 = 0.102766 loss)
I0830 20:45:27.182456 916722 sgd_solver.cpp:106] Iteration 2115500, lr = 0.01
I0830 20:45:56.911944 916722 solver.cpp:218] Iteration 2116000 (16.8184 iter/s, 29.7294s/500 iters), loss = 0.13322
I0830 20:45:56.912004 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133222 (* 1 = 0.133222 loss)
I0830 20:45:56.912012 916722 sgd_solver.cpp:106] Iteration 2116000, lr = 0.01
I0830 20:46:26.648072 916722 solver.cpp:218] Iteration 2116500 (16.8146 iter/s, 29.736s/500 iters), loss = 0.100889
I0830 20:46:26.648125 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.100891 (* 1 = 0.100891 loss)
I0830 20:46:26.648135 916722 sgd_solver.cpp:106] Iteration 2116500, lr = 0.01
I0830 20:46:56.380722 916722 solver.cpp:218] Iteration 2117000 (16.8166 iter/s, 29.7325s/500 iters), loss = 0.210021
I0830 20:46:56.380793 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.210023 (* 1 = 0.210023 loss)
I0830 20:46:56.380801 916722 sgd_solver.cpp:106] Iteration 2117000, lr = 0.01
I0830 20:47:26.114444 916722 solver.cpp:218] Iteration 2117500 (16.816 iter/s, 29.7336s/500 iters), loss = 0.194784
I0830 20:47:26.114498 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.194786 (* 1 = 0.194786 loss)
I0830 20:47:26.114508 916722 sgd_solver.cpp:106] Iteration 2117500, lr = 0.01
I0830 20:47:55.847733 916722 solver.cpp:218] Iteration 2118000 (16.8162 iter/s, 29.7331s/500 iters), loss = 0.122052
I0830 20:47:55.847806 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.122054 (* 1 = 0.122054 loss)
I0830 20:47:55.847815 916722 sgd_solver.cpp:106] Iteration 2118000, lr = 0.01
I0830 20:48:25.583802 916722 solver.cpp:218] Iteration 2118500 (16.8147 iter/s, 29.7359s/500 iters), loss = 0.154233
I0830 20:48:25.583854 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.154235 (* 1 = 0.154235 loss)
I0830 20:48:25.583864 916722 sgd_solver.cpp:106] Iteration 2118500, lr = 0.01
I0830 20:48:55.316599 916722 solver.cpp:218] Iteration 2119000 (16.8165 iter/s, 29.7327s/500 iters), loss = 0.223683
I0830 20:48:55.316656 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.223685 (* 1 = 0.223685 loss)
I0830 20:48:55.316665 916722 sgd_solver.cpp:106] Iteration 2119000, lr = 0.01
I0830 20:49:25.049489 916722 solver.cpp:218] Iteration 2119500 (16.8165 iter/s, 29.7327s/500 iters), loss = 0.133989
I0830 20:49:25.049538 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133991 (* 1 = 0.133991 loss)
I0830 20:49:25.049548 916722 sgd_solver.cpp:106] Iteration 2119500, lr = 0.01
I0830 20:49:54.782052 916722 solver.cpp:218] Iteration 2120000 (16.8167 iter/s, 29.7324s/500 iters), loss = 0.133645
I0830 20:49:54.782112 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133647 (* 1 = 0.133647 loss)
I0830 20:49:54.782120 916722 sgd_solver.cpp:106] Iteration 2120000, lr = 0.01
I0830 20:50:24.512894 916722 solver.cpp:218] Iteration 2120500 (16.8176 iter/s, 29.7307s/500 iters), loss = 0.121519
I0830 20:50:24.512949 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.121521 (* 1 = 0.121521 loss)
I0830 20:50:24.512959 916722 sgd_solver.cpp:106] Iteration 2120500, lr = 0.01
I0830 20:50:54.246395 916722 solver.cpp:218] Iteration 2121000 (16.8161 iter/s, 29.7334s/500 iters), loss = 0.225308
I0830 20:50:54.246456 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.22531 (* 1 = 0.22531 loss)
I0830 20:50:54.246464 916722 sgd_solver.cpp:106] Iteration 2121000, lr = 0.01
I0830 20:51:23.981520 916722 solver.cpp:218] Iteration 2121500 (16.8152 iter/s, 29.735s/500 iters), loss = 0.0249563
I0830 20:51:23.981575 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0249586 (* 1 = 0.0249586 loss)
I0830 20:51:23.981585 916722 sgd_solver.cpp:106] Iteration 2121500, lr = 0.01
I0830 20:51:53.715900 916722 solver.cpp:218] Iteration 2122000 (16.8156 iter/s, 29.7342s/500 iters), loss = 0.17222
I0830 20:51:53.715963 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.172222 (* 1 = 0.172222 loss)
I0830 20:51:53.715971 916722 sgd_solver.cpp:106] Iteration 2122000, lr = 0.01
I0830 20:52:23.450395 916722 solver.cpp:218] Iteration 2122500 (16.8156 iter/s, 29.7343s/500 iters), loss = 0.0968231
I0830 20:52:23.450450 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0968251 (* 1 = 0.0968251 loss)
I0830 20:52:23.450459 916722 sgd_solver.cpp:106] Iteration 2122500, lr = 0.01
I0830 20:52:53.183380 916722 solver.cpp:218] Iteration 2123000 (16.8164 iter/s, 29.7328s/500 iters), loss = 0.0529441
I0830 20:52:53.183442 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0529463 (* 1 = 0.0529463 loss)
I0830 20:52:53.183450 916722 sgd_solver.cpp:106] Iteration 2123000, lr = 0.01
I0830 20:53:22.914258 916722 solver.cpp:218] Iteration 2123500 (16.8176 iter/s, 29.7307s/500 iters), loss = 0.302079
I0830 20:53:22.914309 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.302081 (* 1 = 0.302081 loss)
I0830 20:53:22.914319 916722 sgd_solver.cpp:106] Iteration 2123500, lr = 0.01
I0830 20:53:52.647472 916722 solver.cpp:218] Iteration 2124000 (16.8163 iter/s, 29.7331s/500 iters), loss = 0.0136593
I0830 20:53:52.647529 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0136617 (* 1 = 0.0136617 loss)
I0830 20:53:52.647538 916722 sgd_solver.cpp:106] Iteration 2124000, lr = 0.01
I0830 20:54:22.378105 916722 solver.cpp:218] Iteration 2124500 (16.8178 iter/s, 29.7305s/500 iters), loss = 0.099089
I0830 20:54:22.378171 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0990915 (* 1 = 0.0990915 loss)
I0830 20:54:22.378180 916722 sgd_solver.cpp:106] Iteration 2124500, lr = 0.01
I0830 20:54:52.109870 916722 solver.cpp:218] Iteration 2125000 (16.8171 iter/s, 29.7316s/500 iters), loss = 0.0998877
I0830 20:54:52.109941 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0998902 (* 1 = 0.0998902 loss)
I0830 20:54:52.109951 916722 sgd_solver.cpp:106] Iteration 2125000, lr = 0.01
I0830 20:55:21.839557 916722 solver.cpp:218] Iteration 2125500 (16.8183 iter/s, 29.7295s/500 iters), loss = 0.123982
I0830 20:55:21.839613 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.123984 (* 1 = 0.123984 loss)
I0830 20:55:21.839622 916722 sgd_solver.cpp:106] Iteration 2125500, lr = 0.01
I0830 20:55:51.572571 916722 solver.cpp:218] Iteration 2126000 (16.8164 iter/s, 29.7329s/500 iters), loss = 0.199594
I0830 20:55:51.572631 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.199597 (* 1 = 0.199597 loss)
I0830 20:55:51.572640 916722 sgd_solver.cpp:106] Iteration 2126000, lr = 0.01
I0830 20:56:21.298480 916722 solver.cpp:218] Iteration 2126500 (16.8204 iter/s, 29.7258s/500 iters), loss = 0.223733
I0830 20:56:21.298532 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.223736 (* 1 = 0.223736 loss)
I0830 20:56:21.298542 916722 sgd_solver.cpp:106] Iteration 2126500, lr = 0.01
I0830 20:56:51.031049 916722 solver.cpp:218] Iteration 2127000 (16.8167 iter/s, 29.7324s/500 iters), loss = 0.140988
I0830 20:56:51.031111 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.140991 (* 1 = 0.140991 loss)
I0830 20:56:51.031119 916722 sgd_solver.cpp:106] Iteration 2127000, lr = 0.01
I0830 20:57:20.759781 916722 solver.cpp:218] Iteration 2127500 (16.8188 iter/s, 29.7286s/500 iters), loss = 0.264714
I0830 20:57:20.759836 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.264717 (* 1 = 0.264717 loss)
I0830 20:57:20.759846 916722 sgd_solver.cpp:106] Iteration 2127500, lr = 0.01
I0830 20:57:50.488515 916722 solver.cpp:218] Iteration 2128000 (16.8189 iter/s, 29.7284s/500 iters), loss = 0.188153
I0830 20:57:50.488570 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.188156 (* 1 = 0.188156 loss)
I0830 20:57:50.488579 916722 sgd_solver.cpp:106] Iteration 2128000, lr = 0.01
I0830 20:58:20.218976 916722 solver.cpp:218] Iteration 2128500 (16.8181 iter/s, 29.7299s/500 iters), loss = 0.360182
I0830 20:58:20.219025 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.360185 (* 1 = 0.360185 loss)
I0830 20:58:20.219035 916722 sgd_solver.cpp:106] Iteration 2128500, lr = 0.01
I0830 20:58:49.950626 916722 solver.cpp:218] Iteration 2129000 (16.8174 iter/s, 29.7312s/500 iters), loss = 0.0380194
I0830 20:58:49.950686 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0380219 (* 1 = 0.0380219 loss)
I0830 20:58:49.950695 916722 sgd_solver.cpp:106] Iteration 2129000, lr = 0.01
I0830 20:59:19.680740 916722 solver.cpp:218] Iteration 2129500 (16.8182 iter/s, 29.7296s/500 iters), loss = 0.117676
I0830 20:59:19.680794 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.117679 (* 1 = 0.117679 loss)
I0830 20:59:19.680804 916722 sgd_solver.cpp:106] Iteration 2129500, lr = 0.01
I0830 20:59:49.411242 916722 solver.cpp:218] Iteration 2130000 (16.818 iter/s, 29.73s/500 iters), loss = 0.0704711
I0830 20:59:49.411303 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0704735 (* 1 = 0.0704735 loss)
I0830 20:59:49.411311 916722 sgd_solver.cpp:106] Iteration 2130000, lr = 0.01
I0830 21:00:19.140281 916722 solver.cpp:218] Iteration 2130500 (16.8188 iter/s, 29.7286s/500 iters), loss = 0.287396
I0830 21:00:19.140333 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.287399 (* 1 = 0.287399 loss)
I0830 21:00:19.140343 916722 sgd_solver.cpp:106] Iteration 2130500, lr = 0.01
I0830 21:00:48.870352 916722 solver.cpp:218] Iteration 2131000 (16.8182 iter/s, 29.7296s/500 iters), loss = 0.117777
I0830 21:00:48.870431 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.11778 (* 1 = 0.11778 loss)
I0830 21:00:48.870440 916722 sgd_solver.cpp:106] Iteration 2131000, lr = 0.01
I0830 21:01:18.599462 916722 solver.cpp:218] Iteration 2131500 (16.8188 iter/s, 29.7287s/500 iters), loss = 0.0866263
I0830 21:01:18.599515 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0866289 (* 1 = 0.0866289 loss)
I0830 21:01:18.599525 916722 sgd_solver.cpp:106] Iteration 2131500, lr = 0.01
I0830 21:01:48.334154 916722 solver.cpp:218] Iteration 2132000 (16.8156 iter/s, 29.7343s/500 iters), loss = 0.0181815
I0830 21:01:48.334213 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.018184 (* 1 = 0.018184 loss)
I0830 21:01:48.334221 916722 sgd_solver.cpp:106] Iteration 2132000, lr = 0.01
I0830 21:02:18.066490 916722 solver.cpp:218] Iteration 2132500 (16.8169 iter/s, 29.7319s/500 iters), loss = 0.327221
I0830 21:02:18.066541 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.327223 (* 1 = 0.327223 loss)
I0830 21:02:18.066551 916722 sgd_solver.cpp:106] Iteration 2132500, lr = 0.01
I0830 21:02:47.797546 916722 solver.cpp:218] Iteration 2133000 (16.8177 iter/s, 29.7307s/500 iters), loss = 0.145917
I0830 21:02:47.797606 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.145919 (* 1 = 0.145919 loss)
I0830 21:02:47.797614 916722 sgd_solver.cpp:106] Iteration 2133000, lr = 0.01
I0830 21:03:17.528249 916722 solver.cpp:218] Iteration 2133500 (16.8179 iter/s, 29.7303s/500 iters), loss = 0.0431453
I0830 21:03:17.528306 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0431475 (* 1 = 0.0431475 loss)
I0830 21:03:17.528314 916722 sgd_solver.cpp:106] Iteration 2133500, lr = 0.01
I0830 21:03:47.262048 916722 solver.cpp:218] Iteration 2134000 (16.8161 iter/s, 29.7334s/500 iters), loss = 0.200919
I0830 21:03:47.262104 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.200921 (* 1 = 0.200921 loss)
I0830 21:03:47.262111 916722 sgd_solver.cpp:106] Iteration 2134000, lr = 0.01
I0830 21:04:16.992483 916722 solver.cpp:218] Iteration 2134500 (16.818 iter/s, 29.7301s/500 iters), loss = 0.137179
I0830 21:04:16.992533 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.137181 (* 1 = 0.137181 loss)
I0830 21:04:16.992542 916722 sgd_solver.cpp:106] Iteration 2134500, lr = 0.01
I0830 21:04:46.731345 916722 solver.cpp:218] Iteration 2135000 (16.8132 iter/s, 29.7385s/500 iters), loss = 0.0195781
I0830 21:04:46.731400 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.01958 (* 1 = 0.01958 loss)
I0830 21:04:46.731408 916722 sgd_solver.cpp:106] Iteration 2135000, lr = 0.01
I0830 21:05:16.461095 916722 solver.cpp:218] Iteration 2135500 (16.8184 iter/s, 29.7294s/500 iters), loss = 0.240786
I0830 21:05:16.461144 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.240788 (* 1 = 0.240788 loss)
I0830 21:05:16.461153 916722 sgd_solver.cpp:106] Iteration 2135500, lr = 0.01
I0830 21:05:46.188849 916722 solver.cpp:218] Iteration 2136000 (16.8195 iter/s, 29.7274s/500 iters), loss = 0.295734
I0830 21:05:46.188905 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.295736 (* 1 = 0.295736 loss)
I0830 21:05:46.188913 916722 sgd_solver.cpp:106] Iteration 2136000, lr = 0.01
I0830 21:06:15.918076 916722 solver.cpp:218] Iteration 2136500 (16.8187 iter/s, 29.7289s/500 iters), loss = 0.124889
I0830 21:06:15.918125 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.124891 (* 1 = 0.124891 loss)
I0830 21:06:15.918133 916722 sgd_solver.cpp:106] Iteration 2136500, lr = 0.01
I0830 21:06:45.646724 916722 solver.cpp:218] Iteration 2137000 (16.819 iter/s, 29.7283s/500 iters), loss = 0.0524488
I0830 21:06:45.646780 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0524508 (* 1 = 0.0524508 loss)
I0830 21:06:45.646788 916722 sgd_solver.cpp:106] Iteration 2137000, lr = 0.01
I0830 21:07:15.375229 916722 solver.cpp:218] Iteration 2137500 (16.8191 iter/s, 29.7282s/500 iters), loss = 0.395599
I0830 21:07:15.375278 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.395601 (* 1 = 0.395601 loss)
I0830 21:07:15.375298 916722 sgd_solver.cpp:106] Iteration 2137500, lr = 0.01
I0830 21:07:45.108781 916722 solver.cpp:218] Iteration 2138000 (16.8162 iter/s, 29.7332s/500 iters), loss = 0.151965
I0830 21:07:45.108846 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.151967 (* 1 = 0.151967 loss)
I0830 21:07:45.108855 916722 sgd_solver.cpp:106] Iteration 2138000, lr = 0.01
I0830 21:08:14.837970 916722 solver.cpp:218] Iteration 2138500 (16.8187 iter/s, 29.7289s/500 iters), loss = 0.0442311
I0830 21:08:14.838016 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0442332 (* 1 = 0.0442332 loss)
I0830 21:08:14.838025 916722 sgd_solver.cpp:106] Iteration 2138500, lr = 0.01
I0830 21:08:44.571429 916722 solver.cpp:218] Iteration 2139000 (16.8162 iter/s, 29.7332s/500 iters), loss = 0.239985
I0830 21:08:44.571480 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.239987 (* 1 = 0.239987 loss)
I0830 21:08:44.571489 916722 sgd_solver.cpp:106] Iteration 2139000, lr = 0.01
I0830 21:09:14.300024 916722 solver.cpp:218] Iteration 2139500 (16.819 iter/s, 29.7283s/500 iters), loss = 0.0864371
I0830 21:09:14.300071 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0864392 (* 1 = 0.0864392 loss)
I0830 21:09:14.300079 916722 sgd_solver.cpp:106] Iteration 2139500, lr = 0.01
I0830 21:09:44.032169 916722 solver.cpp:218] Iteration 2140000 (16.817 iter/s, 29.7319s/500 iters), loss = 0.101919
I0830 21:09:44.032224 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101921 (* 1 = 0.101921 loss)
I0830 21:09:44.032233 916722 sgd_solver.cpp:106] Iteration 2140000, lr = 0.01
I0830 21:10:13.762907 916722 solver.cpp:218] Iteration 2140500 (16.8178 iter/s, 29.7304s/500 iters), loss = 0.410077
I0830 21:10:13.762955 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.410079 (* 1 = 0.410079 loss)
I0830 21:10:13.762964 916722 sgd_solver.cpp:106] Iteration 2140500, lr = 0.01
I0830 21:10:43.493240 916722 solver.cpp:218] Iteration 2141000 (16.818 iter/s, 29.7301s/500 iters), loss = 0.0959267
I0830 21:10:43.493299 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0959284 (* 1 = 0.0959284 loss)
I0830 21:10:43.493306 916722 sgd_solver.cpp:106] Iteration 2141000, lr = 0.01
I0830 21:11:13.226785 916722 solver.cpp:218] Iteration 2141500 (16.8162 iter/s, 29.7333s/500 iters), loss = 0.0896613
I0830 21:11:13.226833 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.089663 (* 1 = 0.089663 loss)
I0830 21:11:13.226841 916722 sgd_solver.cpp:106] Iteration 2141500, lr = 0.01
I0830 21:11:42.989001 916722 solver.cpp:218] Iteration 2142000 (16.8 iter/s, 29.762s/500 iters), loss = 0.0490154
I0830 21:11:42.989058 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.049017 (* 1 = 0.049017 loss)
I0830 21:11:42.989068 916722 sgd_solver.cpp:106] Iteration 2142000, lr = 0.01
I0830 21:12:12.751895 916722 solver.cpp:218] Iteration 2142500 (16.7996 iter/s, 29.7626s/500 iters), loss = 0.211553
I0830 21:12:12.751945 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.211554 (* 1 = 0.211554 loss)
I0830 21:12:12.751953 916722 sgd_solver.cpp:106] Iteration 2142500, lr = 0.01
I0830 21:12:42.497164 916722 solver.cpp:218] Iteration 2143000 (16.8095 iter/s, 29.745s/500 iters), loss = 0.137887
I0830 21:12:42.497220 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.137889 (* 1 = 0.137889 loss)
I0830 21:12:42.497228 916722 sgd_solver.cpp:106] Iteration 2143000, lr = 0.01
I0830 21:13:12.254119 916722 solver.cpp:218] Iteration 2143500 (16.8029 iter/s, 29.7567s/500 iters), loss = 0.276531
I0830 21:13:12.254168 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.276532 (* 1 = 0.276532 loss)
I0830 21:13:12.254179 916722 sgd_solver.cpp:106] Iteration 2143500, lr = 0.01
I0830 21:13:42.013228 916722 solver.cpp:218] Iteration 2144000 (16.8017 iter/s, 29.7589s/500 iters), loss = 0.0773763
I0830 21:13:42.013293 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0773775 (* 1 = 0.0773775 loss)
I0830 21:13:42.013306 916722 sgd_solver.cpp:106] Iteration 2144000, lr = 0.01
I0830 21:14:11.774572 916722 solver.cpp:218] Iteration 2144500 (16.8005 iter/s, 29.7611s/500 iters), loss = 0.211476
I0830 21:14:11.774621 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.211477 (* 1 = 0.211477 loss)
I0830 21:14:11.774629 916722 sgd_solver.cpp:106] Iteration 2144500, lr = 0.01
I0830 21:14:41.531044 916722 solver.cpp:218] Iteration 2145000 (16.8032 iter/s, 29.7562s/500 iters), loss = 0.0599838
I0830 21:14:41.531100 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0599851 (* 1 = 0.0599851 loss)
I0830 21:14:41.531107 916722 sgd_solver.cpp:106] Iteration 2145000, lr = 0.01
I0830 21:15:11.288498 916722 solver.cpp:218] Iteration 2145500 (16.8027 iter/s, 29.7572s/500 iters), loss = 0.118165
I0830 21:15:11.288547 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.118167 (* 1 = 0.118167 loss)
I0830 21:15:11.288558 916722 sgd_solver.cpp:106] Iteration 2145500, lr = 0.01
I0830 21:15:41.046389 916722 solver.cpp:218] Iteration 2146000 (16.8024 iter/s, 29.7576s/500 iters), loss = 0.0249154
I0830 21:15:41.046443 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0249165 (* 1 = 0.0249165 loss)
I0830 21:15:41.046451 916722 sgd_solver.cpp:106] Iteration 2146000, lr = 0.01
I0830 21:16:10.802769 916722 solver.cpp:218] Iteration 2146500 (16.8033 iter/s, 29.7561s/500 iters), loss = 0.424874
I0830 21:16:10.802817 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.424875 (* 1 = 0.424875 loss)
I0830 21:16:10.802827 916722 sgd_solver.cpp:106] Iteration 2146500, lr = 0.01
I0830 21:16:40.563194 916722 solver.cpp:218] Iteration 2147000 (16.801 iter/s, 29.7602s/500 iters), loss = 0.371846
I0830 21:16:40.563247 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.371848 (* 1 = 0.371848 loss)
I0830 21:16:40.563256 916722 sgd_solver.cpp:106] Iteration 2147000, lr = 0.01
I0830 21:17:10.315925 916722 solver.cpp:218] Iteration 2147500 (16.8053 iter/s, 29.7525s/500 iters), loss = 0.30748
I0830 21:17:10.315973 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.307481 (* 1 = 0.307481 loss)
I0830 21:17:10.315982 916722 sgd_solver.cpp:106] Iteration 2147500, lr = 0.01
I0830 21:17:40.078729 916722 solver.cpp:218] Iteration 2148000 (16.7996 iter/s, 29.7626s/500 iters), loss = 0.117427
I0830 21:17:40.078784 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.117428 (* 1 = 0.117428 loss)
I0830 21:17:40.078792 916722 sgd_solver.cpp:106] Iteration 2148000, lr = 0.01
I0830 21:18:09.835386 916722 solver.cpp:218] Iteration 2148500 (16.8031 iter/s, 29.7564s/500 iters), loss = 0.218523
I0830 21:18:09.835434 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.218524 (* 1 = 0.218524 loss)
I0830 21:18:09.835444 916722 sgd_solver.cpp:106] Iteration 2148500, lr = 0.01
I0830 21:18:39.604295 916722 solver.cpp:218] Iteration 2149000 (16.7962 iter/s, 29.7687s/500 iters), loss = 0.0957341
I0830 21:18:39.604355 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0957354 (* 1 = 0.0957354 loss)
I0830 21:18:39.604363 916722 sgd_solver.cpp:106] Iteration 2149000, lr = 0.01
I0830 21:19:09.359258 916722 solver.cpp:218] Iteration 2149500 (16.8041 iter/s, 29.7547s/500 iters), loss = 0.14739
I0830 21:19:09.359310 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.147391 (* 1 = 0.147391 loss)
I0830 21:19:09.359318 916722 sgd_solver.cpp:106] Iteration 2149500, lr = 0.01
I0830 21:19:39.058933 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_2150000.caffemodel
I0830 21:19:39.078532 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_2150000.solverstate
I0830 21:19:39.084820 916722 solver.cpp:330] Iteration 2150000, Testing net (#0)
I0830 21:19:54.588361 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8915
I0830 21:19:54.588399 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.365177 (* 1 = 0.365177 loss)
I0830 21:19:54.646908 916722 solver.cpp:218] Iteration 2150000 (11.0406 iter/s, 45.2873s/500 iters), loss = 0.106975
I0830 21:19:54.646934 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.106976 (* 1 = 0.106976 loss)
I0830 21:19:54.646942 916722 sgd_solver.cpp:106] Iteration 2150000, lr = 0.01
I0830 21:20:24.293422 916722 solver.cpp:218] Iteration 2150500 (16.8655 iter/s, 29.6463s/500 iters), loss = 0.175937
I0830 21:20:24.293495 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.175939 (* 1 = 0.175939 loss)
I0830 21:20:24.293509 916722 sgd_solver.cpp:106] Iteration 2150500, lr = 0.01
I0830 21:20:53.952955 916722 solver.cpp:218] Iteration 2151000 (16.8581 iter/s, 29.6593s/500 iters), loss = 0.13716
I0830 21:20:53.953006 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.137161 (* 1 = 0.137161 loss)
I0830 21:20:53.953016 916722 sgd_solver.cpp:106] Iteration 2151000, lr = 0.01
I0830 21:21:23.705657 916722 solver.cpp:218] Iteration 2151500 (16.8053 iter/s, 29.7525s/500 iters), loss = 0.323125
I0830 21:21:23.705718 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.323126 (* 1 = 0.323126 loss)
I0830 21:21:23.705725 916722 sgd_solver.cpp:106] Iteration 2151500, lr = 0.01
I0830 21:21:53.469301 916722 solver.cpp:218] Iteration 2152000 (16.7992 iter/s, 29.7634s/500 iters), loss = 0.0388118
I0830 21:21:53.469355 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0388129 (* 1 = 0.0388129 loss)
I0830 21:21:53.469364 916722 sgd_solver.cpp:106] Iteration 2152000, lr = 0.01
I0830 21:22:23.232539 916722 solver.cpp:218] Iteration 2152500 (16.7994 iter/s, 29.763s/500 iters), loss = 0.376052
I0830 21:22:23.232602 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.376054 (* 1 = 0.376054 loss)
I0830 21:22:23.232611 916722 sgd_solver.cpp:106] Iteration 2152500, lr = 0.01
I0830 21:22:52.995056 916722 solver.cpp:218] Iteration 2153000 (16.7998 iter/s, 29.7623s/500 iters), loss = 0.1298
I0830 21:22:52.995110 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.129801 (* 1 = 0.129801 loss)
I0830 21:22:52.995118 916722 sgd_solver.cpp:106] Iteration 2153000, lr = 0.01
I0830 21:23:22.762499 916722 solver.cpp:218] Iteration 2153500 (16.797 iter/s, 29.7672s/500 iters), loss = 0.0897845
I0830 21:23:22.762559 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0897855 (* 1 = 0.0897855 loss)
I0830 21:23:22.762568 916722 sgd_solver.cpp:106] Iteration 2153500, lr = 0.01
I0830 21:23:52.524906 916722 solver.cpp:218] Iteration 2154000 (16.7998 iter/s, 29.7622s/500 iters), loss = 0.0333642
I0830 21:23:52.524960 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0333653 (* 1 = 0.0333653 loss)
I0830 21:23:52.524968 916722 sgd_solver.cpp:106] Iteration 2154000, lr = 0.01
I0830 21:24:22.292774 916722 solver.cpp:218] Iteration 2154500 (16.7968 iter/s, 29.7677s/500 iters), loss = 0.614763
I0830 21:24:22.292834 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.614764 (* 1 = 0.614764 loss)
I0830 21:24:22.292841 916722 sgd_solver.cpp:106] Iteration 2154500, lr = 0.01
I0830 21:24:52.056828 916722 solver.cpp:218] Iteration 2155000 (16.7989 iter/s, 29.7638s/500 iters), loss = 0.113976
I0830 21:24:52.056882 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.113977 (* 1 = 0.113977 loss)
I0830 21:24:52.056891 916722 sgd_solver.cpp:106] Iteration 2155000, lr = 0.01
I0830 21:25:21.821689 916722 solver.cpp:218] Iteration 2155500 (16.7985 iter/s, 29.7646s/500 iters), loss = 0.0518131
I0830 21:25:21.821751 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0518144 (* 1 = 0.0518144 loss)
I0830 21:25:21.821759 916722 sgd_solver.cpp:106] Iteration 2155500, lr = 0.01
I0830 21:25:51.584863 916722 solver.cpp:218] Iteration 2156000 (16.7994 iter/s, 29.7629s/500 iters), loss = 0.121021
I0830 21:25:51.584918 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.121023 (* 1 = 0.121023 loss)
I0830 21:25:51.584928 916722 sgd_solver.cpp:106] Iteration 2156000, lr = 0.01
I0830 21:26:21.351130 916722 solver.cpp:218] Iteration 2156500 (16.7977 iter/s, 29.7661s/500 iters), loss = 0.0583766
I0830 21:26:21.351205 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0583781 (* 1 = 0.0583781 loss)
I0830 21:26:21.351213 916722 sgd_solver.cpp:106] Iteration 2156500, lr = 0.01
I0830 21:26:51.115094 916722 solver.cpp:218] Iteration 2157000 (16.799 iter/s, 29.7637s/500 iters), loss = 0.0930364
I0830 21:26:51.115151 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0930377 (* 1 = 0.0930377 loss)
I0830 21:26:51.115161 916722 sgd_solver.cpp:106] Iteration 2157000, lr = 0.01
I0830 21:27:20.881165 916722 solver.cpp:218] Iteration 2157500 (16.7978 iter/s, 29.7658s/500 iters), loss = 0.0795587
I0830 21:27:20.881227 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0795602 (* 1 = 0.0795602 loss)
I0830 21:27:20.881235 916722 sgd_solver.cpp:106] Iteration 2157500, lr = 0.01
I0830 21:27:50.640763 916722 solver.cpp:218] Iteration 2158000 (16.8014 iter/s, 29.7594s/500 iters), loss = 0.260355
I0830 21:27:50.640816 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.260356 (* 1 = 0.260356 loss)
I0830 21:27:50.640826 916722 sgd_solver.cpp:106] Iteration 2158000, lr = 0.01
I0830 21:28:20.405480 916722 solver.cpp:218] Iteration 2158500 (16.7985 iter/s, 29.7645s/500 iters), loss = 0.314257
I0830 21:28:20.405539 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.314258 (* 1 = 0.314258 loss)
I0830 21:28:20.405546 916722 sgd_solver.cpp:106] Iteration 2158500, lr = 0.01
I0830 21:28:50.175441 916722 solver.cpp:218] Iteration 2159000 (16.7956 iter/s, 29.7697s/500 iters), loss = 0.0496193
I0830 21:28:50.175494 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0496208 (* 1 = 0.0496208 loss)
I0830 21:28:50.175504 916722 sgd_solver.cpp:106] Iteration 2159000, lr = 0.01
I0830 21:29:19.942332 916722 solver.cpp:218] Iteration 2159500 (16.7973 iter/s, 29.7667s/500 iters), loss = 0.186314
I0830 21:29:19.942392 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.186315 (* 1 = 0.186315 loss)
I0830 21:29:19.942401 916722 sgd_solver.cpp:106] Iteration 2159500, lr = 0.01
I0830 21:29:49.708209 916722 solver.cpp:218] Iteration 2160000 (16.7979 iter/s, 29.7657s/500 iters), loss = 0.0654905
I0830 21:29:49.708262 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0654919 (* 1 = 0.0654919 loss)
I0830 21:29:49.708272 916722 sgd_solver.cpp:106] Iteration 2160000, lr = 0.01
I0830 21:30:19.473680 916722 solver.cpp:218] Iteration 2160500 (16.7981 iter/s, 29.7653s/500 iters), loss = 0.116976
I0830 21:30:19.473740 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.116978 (* 1 = 0.116978 loss)
I0830 21:30:19.473748 916722 sgd_solver.cpp:106] Iteration 2160500, lr = 0.01
I0830 21:30:49.237501 916722 solver.cpp:218] Iteration 2161000 (16.799 iter/s, 29.7636s/500 iters), loss = 0.148774
I0830 21:30:49.237555 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.148775 (* 1 = 0.148775 loss)
I0830 21:30:49.237566 916722 sgd_solver.cpp:106] Iteration 2161000, lr = 0.01
I0830 21:31:19.000326 916722 solver.cpp:218] Iteration 2161500 (16.7996 iter/s, 29.7626s/500 iters), loss = 0.0533744
I0830 21:31:19.000391 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.053376 (* 1 = 0.053376 loss)
I0830 21:31:19.000399 916722 sgd_solver.cpp:106] Iteration 2161500, lr = 0.01
I0830 21:31:48.764688 916722 solver.cpp:218] Iteration 2162000 (16.7986 iter/s, 29.7643s/500 iters), loss = 0.21339
I0830 21:31:48.764740 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.213391 (* 1 = 0.213391 loss)
I0830 21:31:48.764750 916722 sgd_solver.cpp:106] Iteration 2162000, lr = 0.01
I0830 21:32:18.529811 916722 solver.cpp:218] Iteration 2162500 (16.7978 iter/s, 29.7658s/500 iters), loss = 0.0389584
I0830 21:32:18.529872 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0389601 (* 1 = 0.0389601 loss)
I0830 21:32:18.529881 916722 sgd_solver.cpp:106] Iteration 2162500, lr = 0.01
I0830 21:32:48.292605 916722 solver.cpp:218] Iteration 2163000 (16.7992 iter/s, 29.7634s/500 iters), loss = 0.0543649
I0830 21:32:48.292671 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0543666 (* 1 = 0.0543666 loss)
I0830 21:32:48.292680 916722 sgd_solver.cpp:106] Iteration 2163000, lr = 0.01
I0830 21:33:18.053884 916722 solver.cpp:218] Iteration 2163500 (16.8 iter/s, 29.7619s/500 iters), loss = 0.242458
I0830 21:33:18.053953 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.24246 (* 1 = 0.24246 loss)
I0830 21:33:18.053961 916722 sgd_solver.cpp:106] Iteration 2163500, lr = 0.01
I0830 21:33:47.820788 916722 solver.cpp:218] Iteration 2164000 (16.7969 iter/s, 29.7674s/500 iters), loss = 0.067779
I0830 21:33:47.820840 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0677809 (* 1 = 0.0677809 loss)
I0830 21:33:47.820849 916722 sgd_solver.cpp:106] Iteration 2164000, lr = 0.01
I0830 21:34:17.590474 916722 solver.cpp:218] Iteration 2164500 (16.7953 iter/s, 29.7702s/500 iters), loss = 0.0908547
I0830 21:34:17.590535 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0908566 (* 1 = 0.0908566 loss)
I0830 21:34:17.590543 916722 sgd_solver.cpp:106] Iteration 2164500, lr = 0.01
I0830 21:34:47.354859 916722 solver.cpp:218] Iteration 2165000 (16.7983 iter/s, 29.7648s/500 iters), loss = 0.194472
I0830 21:34:47.354913 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.194474 (* 1 = 0.194474 loss)
I0830 21:34:47.354923 916722 sgd_solver.cpp:106] Iteration 2165000, lr = 0.01
I0830 21:35:17.124007 916722 solver.cpp:218] Iteration 2165500 (16.7957 iter/s, 29.7696s/500 iters), loss = 0.139623
I0830 21:35:17.124068 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139625 (* 1 = 0.139625 loss)
I0830 21:35:17.124078 916722 sgd_solver.cpp:106] Iteration 2165500, lr = 0.01
I0830 21:35:46.896534 916722 solver.cpp:218] Iteration 2166000 (16.7938 iter/s, 29.7729s/500 iters), loss = 0.117818
I0830 21:35:46.896587 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.11782 (* 1 = 0.11782 loss)
I0830 21:35:46.896596 916722 sgd_solver.cpp:106] Iteration 2166000, lr = 0.01
I0830 21:36:16.661159 916722 solver.cpp:218] Iteration 2166500 (16.7982 iter/s, 29.765s/500 iters), loss = 0.166546
I0830 21:36:16.661218 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.166548 (* 1 = 0.166548 loss)
I0830 21:36:16.661227 916722 sgd_solver.cpp:106] Iteration 2166500, lr = 0.01
I0830 21:36:46.427565 916722 solver.cpp:218] Iteration 2167000 (16.7973 iter/s, 29.7668s/500 iters), loss = 0.184463
I0830 21:36:46.427618 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.184464 (* 1 = 0.184464 loss)
I0830 21:36:46.427626 916722 sgd_solver.cpp:106] Iteration 2167000, lr = 0.01
I0830 21:37:16.193496 916722 solver.cpp:218] Iteration 2167500 (16.7975 iter/s, 29.7663s/500 iters), loss = 0.222448
I0830 21:37:16.193558 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.222449 (* 1 = 0.222449 loss)
I0830 21:37:16.193567 916722 sgd_solver.cpp:106] Iteration 2167500, lr = 0.01
I0830 21:37:45.961704 916722 solver.cpp:218] Iteration 2168000 (16.7963 iter/s, 29.7685s/500 iters), loss = 0.173189
I0830 21:37:45.961756 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.17319 (* 1 = 0.17319 loss)
I0830 21:37:45.961764 916722 sgd_solver.cpp:106] Iteration 2168000, lr = 0.01
I0830 21:38:15.729307 916722 solver.cpp:218] Iteration 2168500 (16.7966 iter/s, 29.7679s/500 iters), loss = 0.108322
I0830 21:38:15.729369 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.108324 (* 1 = 0.108324 loss)
I0830 21:38:15.729377 916722 sgd_solver.cpp:106] Iteration 2168500, lr = 0.01
I0830 21:38:45.496124 916722 solver.cpp:218] Iteration 2169000 (16.7971 iter/s, 29.7671s/500 iters), loss = 0.234441
I0830 21:38:45.496178 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.234443 (* 1 = 0.234443 loss)
I0830 21:38:45.496186 916722 sgd_solver.cpp:106] Iteration 2169000, lr = 0.01
I0830 21:39:15.263861 916722 solver.cpp:218] Iteration 2169500 (16.7966 iter/s, 29.768s/500 iters), loss = 0.206209
I0830 21:39:15.263933 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.20621 (* 1 = 0.20621 loss)
I0830 21:39:15.263947 916722 sgd_solver.cpp:106] Iteration 2169500, lr = 0.01
I0830 21:39:45.029292 916722 solver.cpp:218] Iteration 2170000 (16.7979 iter/s, 29.7656s/500 iters), loss = 0.103984
I0830 21:39:45.029347 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.103986 (* 1 = 0.103986 loss)
I0830 21:39:45.029356 916722 sgd_solver.cpp:106] Iteration 2170000, lr = 0.01
I0830 21:40:14.794742 916722 solver.cpp:218] Iteration 2170500 (16.7979 iter/s, 29.7657s/500 iters), loss = 0.0887262
I0830 21:40:14.794803 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.088728 (* 1 = 0.088728 loss)
I0830 21:40:14.794811 916722 sgd_solver.cpp:106] Iteration 2170500, lr = 0.01
I0830 21:40:44.557761 916722 solver.cpp:218] Iteration 2171000 (16.7993 iter/s, 29.7632s/500 iters), loss = 0.0465288
I0830 21:40:44.557817 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0465306 (* 1 = 0.0465306 loss)
I0830 21:40:44.557826 916722 sgd_solver.cpp:106] Iteration 2171000, lr = 0.01
I0830 21:41:14.323019 916722 solver.cpp:218] Iteration 2171500 (16.798 iter/s, 29.7654s/500 iters), loss = 0.29144
I0830 21:41:14.323079 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.291442 (* 1 = 0.291442 loss)
I0830 21:41:14.323087 916722 sgd_solver.cpp:106] Iteration 2171500, lr = 0.01
I0830 21:41:44.089983 916722 solver.cpp:218] Iteration 2172000 (16.7971 iter/s, 29.7671s/500 iters), loss = 0.105462
I0830 21:41:44.090037 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105464 (* 1 = 0.105464 loss)
I0830 21:41:44.090047 916722 sgd_solver.cpp:106] Iteration 2172000, lr = 0.01
I0830 21:42:13.856395 916722 solver.cpp:218] Iteration 2172500 (16.7974 iter/s, 29.7665s/500 iters), loss = 0.0346778
I0830 21:42:13.856468 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0346797 (* 1 = 0.0346797 loss)
I0830 21:42:13.856478 916722 sgd_solver.cpp:106] Iteration 2172500, lr = 0.01
I0830 21:42:43.626938 916722 solver.cpp:218] Iteration 2173000 (16.7951 iter/s, 29.7707s/500 iters), loss = 0.0852471
I0830 21:42:43.626992 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0852492 (* 1 = 0.0852492 loss)
I0830 21:42:43.627002 916722 sgd_solver.cpp:106] Iteration 2173000, lr = 0.01
I0830 21:43:13.390792 916722 solver.cpp:218] Iteration 2173500 (16.7988 iter/s, 29.764s/500 iters), loss = 0.244729
I0830 21:43:13.390853 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.244731 (* 1 = 0.244731 loss)
I0830 21:43:13.390862 916722 sgd_solver.cpp:106] Iteration 2173500, lr = 0.01
I0830 21:43:43.163383 916722 solver.cpp:218] Iteration 2174000 (16.7939 iter/s, 29.7727s/500 iters), loss = 0.0261789
I0830 21:43:43.163439 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0261809 (* 1 = 0.0261809 loss)
I0830 21:43:43.163447 916722 sgd_solver.cpp:106] Iteration 2174000, lr = 0.01
I0830 21:44:12.933430 916722 solver.cpp:218] Iteration 2174500 (16.7954 iter/s, 29.7701s/500 iters), loss = 0.161394
I0830 21:44:12.933490 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.161396 (* 1 = 0.161396 loss)
I0830 21:44:12.933498 916722 sgd_solver.cpp:106] Iteration 2174500, lr = 0.01
I0830 21:44:42.696887 916722 solver.cpp:218] Iteration 2175000 (16.7991 iter/s, 29.7635s/500 iters), loss = 0.0641461
I0830 21:44:42.696941 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0641481 (* 1 = 0.0641481 loss)
I0830 21:44:42.696951 916722 sgd_solver.cpp:106] Iteration 2175000, lr = 0.01
I0830 21:45:12.465469 916722 solver.cpp:218] Iteration 2175500 (16.7962 iter/s, 29.7686s/500 iters), loss = 0.454526
I0830 21:45:12.465529 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.454528 (* 1 = 0.454528 loss)
I0830 21:45:12.465538 916722 sgd_solver.cpp:106] Iteration 2175500, lr = 0.01
I0830 21:45:42.221349 916722 solver.cpp:218] Iteration 2176000 (16.8034 iter/s, 29.7559s/500 iters), loss = 0.0771215
I0830 21:45:42.221406 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0771234 (* 1 = 0.0771234 loss)
I0830 21:45:42.221429 916722 sgd_solver.cpp:106] Iteration 2176000, lr = 0.01
I0830 21:46:11.961604 916722 solver.cpp:218] Iteration 2176500 (16.8122 iter/s, 29.7403s/500 iters), loss = 0.0688967
I0830 21:46:11.961670 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0688985 (* 1 = 0.0688985 loss)
I0830 21:46:11.961679 916722 sgd_solver.cpp:106] Iteration 2176500, lr = 0.01
I0830 21:46:41.698020 916722 solver.cpp:218] Iteration 2177000 (16.8144 iter/s, 29.7364s/500 iters), loss = 0.230872
I0830 21:46:41.698069 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.230874 (* 1 = 0.230874 loss)
I0830 21:46:41.698079 916722 sgd_solver.cpp:106] Iteration 2177000, lr = 0.01
I0830 21:47:11.439373 916722 solver.cpp:218] Iteration 2177500 (16.8116 iter/s, 29.7414s/500 iters), loss = 0.214152
I0830 21:47:11.439437 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.214154 (* 1 = 0.214154 loss)
I0830 21:47:11.439445 916722 sgd_solver.cpp:106] Iteration 2177500, lr = 0.01
I0830 21:47:41.183908 916722 solver.cpp:218] Iteration 2178000 (16.8098 iter/s, 29.7445s/500 iters), loss = 0.0480436
I0830 21:47:41.183961 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0480455 (* 1 = 0.0480455 loss)
I0830 21:47:41.183970 916722 sgd_solver.cpp:106] Iteration 2178000, lr = 0.01
I0830 21:48:10.927748 916722 solver.cpp:218] Iteration 2178500 (16.8102 iter/s, 29.7439s/500 iters), loss = 0.122973
I0830 21:48:10.927809 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.122975 (* 1 = 0.122975 loss)
I0830 21:48:10.927816 916722 sgd_solver.cpp:106] Iteration 2178500, lr = 0.01
I0830 21:48:40.670406 916722 solver.cpp:218] Iteration 2179000 (16.8109 iter/s, 29.7427s/500 iters), loss = 0.11278
I0830 21:48:40.670461 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112782 (* 1 = 0.112782 loss)
I0830 21:48:40.670470 916722 sgd_solver.cpp:106] Iteration 2179000, lr = 0.01
I0830 21:49:10.410495 916722 solver.cpp:218] Iteration 2179500 (16.8123 iter/s, 29.7401s/500 iters), loss = 0.0905908
I0830 21:49:10.410557 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0905925 (* 1 = 0.0905925 loss)
I0830 21:49:10.410564 916722 sgd_solver.cpp:106] Iteration 2179500, lr = 0.01
I0830 21:49:40.159832 916722 solver.cpp:218] Iteration 2180000 (16.8071 iter/s, 29.7493s/500 iters), loss = 0.0526315
I0830 21:49:40.159886 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0526332 (* 1 = 0.0526332 loss)
I0830 21:49:40.159894 916722 sgd_solver.cpp:106] Iteration 2180000, lr = 0.01
I0830 21:50:09.905645 916722 solver.cpp:218] Iteration 2180500 (16.8091 iter/s, 29.7458s/500 iters), loss = 0.220526
I0830 21:50:09.905704 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.220528 (* 1 = 0.220528 loss)
I0830 21:50:09.905712 916722 sgd_solver.cpp:106] Iteration 2180500, lr = 0.01
I0830 21:50:39.654847 916722 solver.cpp:218] Iteration 2181000 (16.8072 iter/s, 29.7492s/500 iters), loss = 0.00961484
I0830 21:50:39.654898 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0096164 (* 1 = 0.0096164 loss)
I0830 21:50:39.654907 916722 sgd_solver.cpp:106] Iteration 2181000, lr = 0.01
I0830 21:51:09.398003 916722 solver.cpp:218] Iteration 2181500 (16.8106 iter/s, 29.7431s/500 iters), loss = 0.139123
I0830 21:51:09.398063 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139124 (* 1 = 0.139124 loss)
I0830 21:51:09.398072 916722 sgd_solver.cpp:106] Iteration 2181500, lr = 0.01
I0830 21:51:39.137914 916722 solver.cpp:218] Iteration 2182000 (16.8124 iter/s, 29.7399s/500 iters), loss = 0.182336
I0830 21:51:39.137969 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.182337 (* 1 = 0.182337 loss)
I0830 21:51:39.137980 916722 sgd_solver.cpp:106] Iteration 2182000, lr = 0.01
I0830 21:52:08.883530 916722 solver.cpp:218] Iteration 2182500 (16.8092 iter/s, 29.7456s/500 iters), loss = 0.112447
I0830 21:52:08.883601 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112448 (* 1 = 0.112448 loss)
I0830 21:52:08.883615 916722 sgd_solver.cpp:106] Iteration 2182500, lr = 0.01
I0830 21:52:38.626894 916722 solver.cpp:218] Iteration 2183000 (16.8105 iter/s, 29.7433s/500 iters), loss = 0.317076
I0830 21:52:38.626948 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.317078 (* 1 = 0.317078 loss)
I0830 21:52:38.626958 916722 sgd_solver.cpp:106] Iteration 2183000, lr = 0.01
I0830 21:53:08.377660 916722 solver.cpp:218] Iteration 2183500 (16.8063 iter/s, 29.7507s/500 iters), loss = 0.230826
I0830 21:53:08.377718 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.230828 (* 1 = 0.230828 loss)
I0830 21:53:08.377727 916722 sgd_solver.cpp:106] Iteration 2183500, lr = 0.01
I0830 21:53:38.124531 916722 solver.cpp:218] Iteration 2184000 (16.8085 iter/s, 29.7468s/500 iters), loss = 0.033245
I0830 21:53:38.124584 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0332468 (* 1 = 0.0332468 loss)
I0830 21:53:38.124595 916722 sgd_solver.cpp:106] Iteration 2184000, lr = 0.01
I0830 21:54:07.870540 916722 solver.cpp:218] Iteration 2184500 (16.809 iter/s, 29.746s/500 iters), loss = 0.026608
I0830 21:54:07.870599 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0266098 (* 1 = 0.0266098 loss)
I0830 21:54:07.870607 916722 sgd_solver.cpp:106] Iteration 2184500, lr = 0.01
I0830 21:54:37.616010 916722 solver.cpp:218] Iteration 2185000 (16.8093 iter/s, 29.7454s/500 iters), loss = 0.210544
I0830 21:54:37.616063 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.210545 (* 1 = 0.210545 loss)
I0830 21:54:37.616075 916722 sgd_solver.cpp:106] Iteration 2185000, lr = 0.01
I0830 21:55:07.359618 916722 solver.cpp:218] Iteration 2185500 (16.8104 iter/s, 29.7436s/500 iters), loss = 0.260028
I0830 21:55:07.359676 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.26003 (* 1 = 0.26003 loss)
I0830 21:55:07.359685 916722 sgd_solver.cpp:106] Iteration 2185500, lr = 0.01
I0830 21:55:37.106905 916722 solver.cpp:218] Iteration 2186000 (16.8083 iter/s, 29.7472s/500 iters), loss = 0.243421
I0830 21:55:37.106958 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.243423 (* 1 = 0.243423 loss)
I0830 21:55:37.106969 916722 sgd_solver.cpp:106] Iteration 2186000, lr = 0.01
I0830 21:56:06.854760 916722 solver.cpp:218] Iteration 2186500 (16.808 iter/s, 29.7478s/500 iters), loss = 0.0377416
I0830 21:56:06.854822 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0377432 (* 1 = 0.0377432 loss)
I0830 21:56:06.854831 916722 sgd_solver.cpp:106] Iteration 2186500, lr = 0.01
I0830 21:56:36.601390 916722 solver.cpp:218] Iteration 2187000 (16.8087 iter/s, 29.7466s/500 iters), loss = 0.0650898
I0830 21:56:36.601444 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0650913 (* 1 = 0.0650913 loss)
I0830 21:56:36.601452 916722 sgd_solver.cpp:106] Iteration 2187000, lr = 0.01
I0830 21:57:06.352177 916722 solver.cpp:218] Iteration 2187500 (16.8063 iter/s, 29.7507s/500 iters), loss = 0.148049
I0830 21:57:06.352239 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.148051 (* 1 = 0.148051 loss)
I0830 21:57:06.352247 916722 sgd_solver.cpp:106] Iteration 2187500, lr = 0.01
I0830 21:57:36.100230 916722 solver.cpp:218] Iteration 2188000 (16.8079 iter/s, 29.748s/500 iters), loss = 0.195302
I0830 21:57:36.100281 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.195303 (* 1 = 0.195303 loss)
I0830 21:57:36.100291 916722 sgd_solver.cpp:106] Iteration 2188000, lr = 0.01
I0830 21:58:05.844718 916722 solver.cpp:218] Iteration 2188500 (16.8099 iter/s, 29.7444s/500 iters), loss = 0.258662
I0830 21:58:05.844789 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.258663 (* 1 = 0.258663 loss)
I0830 21:58:05.844799 916722 sgd_solver.cpp:106] Iteration 2188500, lr = 0.01
I0830 21:58:35.592618 916722 solver.cpp:218] Iteration 2189000 (16.808 iter/s, 29.7478s/500 iters), loss = 0.134682
I0830 21:58:35.592677 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.134684 (* 1 = 0.134684 loss)
I0830 21:58:35.592687 916722 sgd_solver.cpp:106] Iteration 2189000, lr = 0.01
I0830 21:59:05.337888 916722 solver.cpp:218] Iteration 2189500 (16.8094 iter/s, 29.7452s/500 iters), loss = 0.210257
I0830 21:59:05.337960 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.210259 (* 1 = 0.210259 loss)
I0830 21:59:05.337970 916722 sgd_solver.cpp:106] Iteration 2189500, lr = 0.01
I0830 21:59:35.075089 916722 solver.cpp:218] Iteration 2190000 (16.814 iter/s, 29.7371s/500 iters), loss = 0.177402
I0830 21:59:35.075139 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.177403 (* 1 = 0.177403 loss)
I0830 21:59:35.075148 916722 sgd_solver.cpp:106] Iteration 2190000, lr = 0.01
I0830 22:00:04.811827 916722 solver.cpp:218] Iteration 2190500 (16.8143 iter/s, 29.7367s/500 iters), loss = 0.0406831
I0830 22:00:04.811887 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0406844 (* 1 = 0.0406844 loss)
I0830 22:00:04.811895 916722 sgd_solver.cpp:106] Iteration 2190500, lr = 0.01
I0830 22:00:34.556769 916722 solver.cpp:218] Iteration 2191000 (16.8096 iter/s, 29.7449s/500 iters), loss = 0.0347787
I0830 22:00:34.556823 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0347801 (* 1 = 0.0347801 loss)
I0830 22:00:34.556831 916722 sgd_solver.cpp:106] Iteration 2191000, lr = 0.01
I0830 22:01:04.301462 916722 solver.cpp:218] Iteration 2191500 (16.8098 iter/s, 29.7446s/500 iters), loss = 0.243463
I0830 22:01:04.301522 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.243465 (* 1 = 0.243465 loss)
I0830 22:01:04.301530 916722 sgd_solver.cpp:106] Iteration 2191500, lr = 0.01
I0830 22:01:34.041110 916722 solver.cpp:218] Iteration 2192000 (16.8126 iter/s, 29.7396s/500 iters), loss = 0.111301
I0830 22:01:34.041162 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111302 (* 1 = 0.111302 loss)
I0830 22:01:34.041172 916722 sgd_solver.cpp:106] Iteration 2192000, lr = 0.01
I0830 22:02:03.782155 916722 solver.cpp:218] Iteration 2192500 (16.8118 iter/s, 29.741s/500 iters), loss = 0.117056
I0830 22:02:03.782214 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.117058 (* 1 = 0.117058 loss)
I0830 22:02:03.782222 916722 sgd_solver.cpp:106] Iteration 2192500, lr = 0.01
I0830 22:02:33.519315 916722 solver.cpp:218] Iteration 2193000 (16.814 iter/s, 29.7371s/500 iters), loss = 0.0841874
I0830 22:02:33.519371 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0841887 (* 1 = 0.0841887 loss)
I0830 22:02:33.519381 916722 sgd_solver.cpp:106] Iteration 2193000, lr = 0.01
I0830 22:03:03.262696 916722 solver.cpp:218] Iteration 2193500 (16.8105 iter/s, 29.7433s/500 iters), loss = 0.162853
I0830 22:03:03.262754 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.162855 (* 1 = 0.162855 loss)
I0830 22:03:03.262763 916722 sgd_solver.cpp:106] Iteration 2193500, lr = 0.01
I0830 22:03:32.997350 916722 solver.cpp:218] Iteration 2194000 (16.8154 iter/s, 29.7346s/500 iters), loss = 0.226448
I0830 22:03:32.997406 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.226449 (* 1 = 0.226449 loss)
I0830 22:03:32.997416 916722 sgd_solver.cpp:106] Iteration 2194000, lr = 0.01
I0830 22:04:02.738725 916722 solver.cpp:218] Iteration 2194500 (16.8117 iter/s, 29.7413s/500 iters), loss = 0.0308912
I0830 22:04:02.738790 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0308926 (* 1 = 0.0308926 loss)
I0830 22:04:02.738797 916722 sgd_solver.cpp:106] Iteration 2194500, lr = 0.01
I0830 22:04:32.477351 916722 solver.cpp:218] Iteration 2195000 (16.8132 iter/s, 29.7385s/500 iters), loss = 0.114163
I0830 22:04:32.477407 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.114164 (* 1 = 0.114164 loss)
I0830 22:04:32.477417 916722 sgd_solver.cpp:106] Iteration 2195000, lr = 0.01
I0830 22:05:02.218480 916722 solver.cpp:218] Iteration 2195500 (16.8118 iter/s, 29.741s/500 iters), loss = 0.141725
I0830 22:05:02.218537 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.141726 (* 1 = 0.141726 loss)
I0830 22:05:02.218545 916722 sgd_solver.cpp:106] Iteration 2195500, lr = 0.01
I0830 22:05:31.957888 916722 solver.cpp:218] Iteration 2196000 (16.8128 iter/s, 29.7393s/500 iters), loss = 0.0662664
I0830 22:05:31.957942 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0662676 (* 1 = 0.0662676 loss)
I0830 22:05:31.957952 916722 sgd_solver.cpp:106] Iteration 2196000, lr = 0.01
I0830 22:06:01.697335 916722 solver.cpp:218] Iteration 2196500 (16.8128 iter/s, 29.7392s/500 iters), loss = 0.211288
I0830 22:06:01.697403 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.21129 (* 1 = 0.21129 loss)
I0830 22:06:01.697418 916722 sgd_solver.cpp:106] Iteration 2196500, lr = 0.01
I0830 22:06:31.440197 916722 solver.cpp:218] Iteration 2197000 (16.8111 iter/s, 29.7423s/500 iters), loss = 0.0849665
I0830 22:06:31.440248 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0849677 (* 1 = 0.0849677 loss)
I0830 22:06:31.440258 916722 sgd_solver.cpp:106] Iteration 2197000, lr = 0.01
I0830 22:07:01.179150 916722 solver.cpp:218] Iteration 2197500 (16.8133 iter/s, 29.7384s/500 iters), loss = 0.110905
I0830 22:07:01.179210 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110906 (* 1 = 0.110906 loss)
I0830 22:07:01.179219 916722 sgd_solver.cpp:106] Iteration 2197500, lr = 0.01
I0830 22:07:30.915781 916722 solver.cpp:218] Iteration 2198000 (16.8146 iter/s, 29.7361s/500 iters), loss = 0.166496
I0830 22:07:30.915838 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.166497 (* 1 = 0.166497 loss)
I0830 22:07:30.915848 916722 sgd_solver.cpp:106] Iteration 2198000, lr = 0.01
I0830 22:08:00.653916 916722 solver.cpp:218] Iteration 2198500 (16.8137 iter/s, 29.7377s/500 iters), loss = 0.140298
I0830 22:08:00.653975 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.140299 (* 1 = 0.140299 loss)
I0830 22:08:00.653982 916722 sgd_solver.cpp:106] Iteration 2198500, lr = 0.01
I0830 22:08:30.397011 916722 solver.cpp:218] Iteration 2199000 (16.8109 iter/s, 29.7426s/500 iters), loss = 0.0916758
I0830 22:08:30.397068 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.091677 (* 1 = 0.091677 loss)
I0830 22:08:30.397078 916722 sgd_solver.cpp:106] Iteration 2199000, lr = 0.01
I0830 22:09:00.139963 916722 solver.cpp:218] Iteration 2199500 (16.811 iter/s, 29.7425s/500 iters), loss = 0.225821
I0830 22:09:00.140027 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.225823 (* 1 = 0.225823 loss)
I0830 22:09:00.140035 916722 sgd_solver.cpp:106] Iteration 2199500, lr = 0.01
I0830 22:09:29.822731 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_2200000.caffemodel
I0830 22:09:29.842279 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_2200000.solverstate
I0830 22:09:29.848582 916722 solver.cpp:330] Iteration 2200000, Testing net (#0)
I0830 22:09:45.291119 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8878
I0830 22:09:45.291174 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.379085 (* 1 = 0.379085 loss)
I0830 22:09:45.349865 916722 solver.cpp:218] Iteration 2200000 (11.0597 iter/s, 45.2093s/500 iters), loss = 0.048141
I0830 22:09:45.349895 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0481423 (* 1 = 0.0481423 loss)
I0830 22:09:45.349903 916722 sgd_solver.cpp:106] Iteration 2200000, lr = 0.01
I0830 22:10:14.977164 916722 solver.cpp:218] Iteration 2200500 (16.8766 iter/s, 29.6269s/500 iters), loss = 0.183828
I0830 22:10:14.977217 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.18383 (* 1 = 0.18383 loss)
I0830 22:10:14.977226 916722 sgd_solver.cpp:106] Iteration 2200500, lr = 0.01
I0830 22:10:44.615897 916722 solver.cpp:218] Iteration 2201000 (16.87 iter/s, 29.6383s/500 iters), loss = 0.340554
I0830 22:10:44.615962 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.340556 (* 1 = 0.340556 loss)
I0830 22:10:44.615970 916722 sgd_solver.cpp:106] Iteration 2201000, lr = 0.01
I0830 22:11:14.320171 916722 solver.cpp:218] Iteration 2201500 (16.8328 iter/s, 29.7039s/500 iters), loss = 0.15979
I0830 22:11:14.320236 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159792 (* 1 = 0.159792 loss)
I0830 22:11:14.320245 916722 sgd_solver.cpp:106] Iteration 2201500, lr = 0.01
I0830 22:11:44.050523 916722 solver.cpp:218] Iteration 2202000 (16.818 iter/s, 29.73s/500 iters), loss = 0.0437681
I0830 22:11:44.050595 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0437695 (* 1 = 0.0437695 loss)
I0830 22:11:44.050603 916722 sgd_solver.cpp:106] Iteration 2202000, lr = 0.01
I0830 22:12:13.771752 916722 solver.cpp:218] Iteration 2202500 (16.8232 iter/s, 29.7209s/500 iters), loss = 0.0798602
I0830 22:12:13.771806 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0798616 (* 1 = 0.0798616 loss)
I0830 22:12:13.771816 916722 sgd_solver.cpp:106] Iteration 2202500, lr = 0.01
I0830 22:12:43.493396 916722 solver.cpp:218] Iteration 2203000 (16.8229 iter/s, 29.7213s/500 iters), loss = 0.265409
I0830 22:12:43.493453 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.265411 (* 1 = 0.265411 loss)
I0830 22:12:43.493461 916722 sgd_solver.cpp:106] Iteration 2203000, lr = 0.01
I0830 22:13:13.214958 916722 solver.cpp:218] Iteration 2203500 (16.823 iter/s, 29.7212s/500 iters), loss = 0.155004
I0830 22:13:13.215013 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.155006 (* 1 = 0.155006 loss)
I0830 22:13:13.215020 916722 sgd_solver.cpp:106] Iteration 2203500, lr = 0.01
I0830 22:13:42.939199 916722 solver.cpp:218] Iteration 2204000 (16.8215 iter/s, 29.7239s/500 iters), loss = 0.141017
I0830 22:13:42.939261 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.141019 (* 1 = 0.141019 loss)
I0830 22:13:42.939270 916722 sgd_solver.cpp:106] Iteration 2204000, lr = 0.01
I0830 22:14:12.663002 916722 solver.cpp:218] Iteration 2204500 (16.8217 iter/s, 29.7235s/500 iters), loss = 0.210342
I0830 22:14:12.663054 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.210343 (* 1 = 0.210343 loss)
I0830 22:14:12.663064 916722 sgd_solver.cpp:106] Iteration 2204500, lr = 0.01
I0830 22:14:42.390450 916722 solver.cpp:218] Iteration 2205000 (16.8196 iter/s, 29.7272s/500 iters), loss = 0.101657
I0830 22:14:42.390511 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101658 (* 1 = 0.101658 loss)
I0830 22:14:42.390520 916722 sgd_solver.cpp:106] Iteration 2205000, lr = 0.01
I0830 22:15:12.115264 916722 solver.cpp:218] Iteration 2205500 (16.8211 iter/s, 29.7245s/500 iters), loss = 0.0748187
I0830 22:15:12.115319 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0748201 (* 1 = 0.0748201 loss)
I0830 22:15:12.115329 916722 sgd_solver.cpp:106] Iteration 2205500, lr = 0.01
I0830 22:15:41.837636 916722 solver.cpp:218] Iteration 2206000 (16.8225 iter/s, 29.7221s/500 iters), loss = 0.14744
I0830 22:15:41.837697 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.147441 (* 1 = 0.147441 loss)
I0830 22:15:41.837705 916722 sgd_solver.cpp:106] Iteration 2206000, lr = 0.01
I0830 22:16:11.562994 916722 solver.cpp:218] Iteration 2206500 (16.8208 iter/s, 29.7251s/500 iters), loss = 0.190649
I0830 22:16:11.563050 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.19065 (* 1 = 0.19065 loss)
I0830 22:16:11.563060 916722 sgd_solver.cpp:106] Iteration 2206500, lr = 0.01
I0830 22:16:41.289520 916722 solver.cpp:218] Iteration 2207000 (16.8201 iter/s, 29.7263s/500 iters), loss = 0.104409
I0830 22:16:41.289577 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104411 (* 1 = 0.104411 loss)
I0830 22:16:41.289587 916722 sgd_solver.cpp:106] Iteration 2207000, lr = 0.01
I0830 22:17:11.015815 916722 solver.cpp:218] Iteration 2207500 (16.8203 iter/s, 29.726s/500 iters), loss = 0.0806224
I0830 22:17:11.015866 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0806237 (* 1 = 0.0806237 loss)
I0830 22:17:11.015875 916722 sgd_solver.cpp:106] Iteration 2207500, lr = 0.01
I0830 22:17:40.739292 916722 solver.cpp:218] Iteration 2208000 (16.8219 iter/s, 29.7232s/500 iters), loss = 0.303357
I0830 22:17:40.739363 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.303359 (* 1 = 0.303359 loss)
I0830 22:17:40.739377 916722 sgd_solver.cpp:106] Iteration 2208000, lr = 0.01
I0830 22:18:10.464151 916722 solver.cpp:218] Iteration 2208500 (16.8211 iter/s, 29.7246s/500 iters), loss = 0.150978
I0830 22:18:10.464205 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.15098 (* 1 = 0.15098 loss)
I0830 22:18:10.464215 916722 sgd_solver.cpp:106] Iteration 2208500, lr = 0.01
I0830 22:18:40.191541 916722 solver.cpp:218] Iteration 2209000 (16.8196 iter/s, 29.7271s/500 iters), loss = 0.0345768
I0830 22:18:40.191601 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0345783 (* 1 = 0.0345783 loss)
I0830 22:18:40.191609 916722 sgd_solver.cpp:106] Iteration 2209000, lr = 0.01
I0830 22:19:09.912039 916722 solver.cpp:218] Iteration 2209500 (16.8235 iter/s, 29.7203s/500 iters), loss = 0.403517
I0830 22:19:09.912091 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.403519 (* 1 = 0.403519 loss)
I0830 22:19:09.912101 916722 sgd_solver.cpp:106] Iteration 2209500, lr = 0.01
I0830 22:19:39.634853 916722 solver.cpp:218] Iteration 2210000 (16.8222 iter/s, 29.7226s/500 iters), loss = 0.146112
I0830 22:19:39.634913 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.146113 (* 1 = 0.146113 loss)
I0830 22:19:39.634922 916722 sgd_solver.cpp:106] Iteration 2210000, lr = 0.01
I0830 22:20:09.360311 916722 solver.cpp:218] Iteration 2210500 (16.8207 iter/s, 29.7252s/500 iters), loss = 0.264961
I0830 22:20:09.360363 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.264962 (* 1 = 0.264962 loss)
I0830 22:20:09.360373 916722 sgd_solver.cpp:106] Iteration 2210500, lr = 0.01
I0830 22:20:39.079504 916722 solver.cpp:218] Iteration 2211000 (16.8243 iter/s, 29.719s/500 iters), loss = 0.0962148
I0830 22:20:39.079563 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0962164 (* 1 = 0.0962164 loss)
I0830 22:20:39.079572 916722 sgd_solver.cpp:106] Iteration 2211000, lr = 0.01
I0830 22:21:08.803958 916722 solver.cpp:218] Iteration 2211500 (16.8213 iter/s, 29.7242s/500 iters), loss = 0.225385
I0830 22:21:08.804009 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.225387 (* 1 = 0.225387 loss)
I0830 22:21:08.804019 916722 sgd_solver.cpp:106] Iteration 2211500, lr = 0.01
I0830 22:21:38.524482 916722 solver.cpp:218] Iteration 2212000 (16.8235 iter/s, 29.7203s/500 iters), loss = 0.0706785
I0830 22:21:38.524544 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0706801 (* 1 = 0.0706801 loss)
I0830 22:21:38.524554 916722 sgd_solver.cpp:106] Iteration 2212000, lr = 0.01
I0830 22:22:08.248008 916722 solver.cpp:218] Iteration 2212500 (16.8218 iter/s, 29.7233s/500 iters), loss = 0.519347
I0830 22:22:08.248061 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.519349 (* 1 = 0.519349 loss)
I0830 22:22:08.248070 916722 sgd_solver.cpp:106] Iteration 2212500, lr = 0.01
I0830 22:22:37.968132 916722 solver.cpp:218] Iteration 2213000 (16.8237 iter/s, 29.7199s/500 iters), loss = 0.112076
I0830 22:22:37.968190 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112078 (* 1 = 0.112078 loss)
I0830 22:22:37.968199 916722 sgd_solver.cpp:106] Iteration 2213000, lr = 0.01
I0830 22:23:07.689673 916722 solver.cpp:218] Iteration 2213500 (16.823 iter/s, 29.7213s/500 iters), loss = 0.117116
I0830 22:23:07.689738 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.117118 (* 1 = 0.117118 loss)
I0830 22:23:07.689749 916722 sgd_solver.cpp:106] Iteration 2213500, lr = 0.01
I0830 22:23:37.412127 916722 solver.cpp:218] Iteration 2214000 (16.8224 iter/s, 29.7222s/500 iters), loss = 0.0172991
I0830 22:23:37.412179 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0173008 (* 1 = 0.0173008 loss)
I0830 22:23:37.412187 916722 sgd_solver.cpp:106] Iteration 2214000, lr = 0.01
I0830 22:24:07.138113 916722 solver.cpp:218] Iteration 2214500 (16.8204 iter/s, 29.7258s/500 iters), loss = 0.0425233
I0830 22:24:07.138166 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.042525 (* 1 = 0.042525 loss)
I0830 22:24:07.138188 916722 sgd_solver.cpp:106] Iteration 2214500, lr = 0.01
I0830 22:24:36.860056 916722 solver.cpp:218] Iteration 2215000 (16.8227 iter/s, 29.7217s/500 iters), loss = 0.0617979
I0830 22:24:36.860126 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0617996 (* 1 = 0.0617996 loss)
I0830 22:24:36.860146 916722 sgd_solver.cpp:106] Iteration 2215000, lr = 0.01
I0830 22:25:06.582307 916722 solver.cpp:218] Iteration 2215500 (16.8225 iter/s, 29.722s/500 iters), loss = 0.312947
I0830 22:25:06.582361 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.312948 (* 1 = 0.312948 loss)
I0830 22:25:06.582371 916722 sgd_solver.cpp:106] Iteration 2215500, lr = 0.01
I0830 22:25:36.307535 916722 solver.cpp:218] Iteration 2216000 (16.8208 iter/s, 29.725s/500 iters), loss = 0.401466
I0830 22:25:36.307592 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.401468 (* 1 = 0.401468 loss)
I0830 22:25:36.307600 916722 sgd_solver.cpp:106] Iteration 2216000, lr = 0.01
I0830 22:26:06.025120 916722 solver.cpp:218] Iteration 2216500 (16.8252 iter/s, 29.7174s/500 iters), loss = 0.057319
I0830 22:26:06.025167 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0573206 (* 1 = 0.0573206 loss)
I0830 22:26:06.025177 916722 sgd_solver.cpp:106] Iteration 2216500, lr = 0.01
I0830 22:26:35.744578 916722 solver.cpp:218] Iteration 2217000 (16.8241 iter/s, 29.7193s/500 iters), loss = 0.089011
I0830 22:26:35.744642 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0890125 (* 1 = 0.0890125 loss)
I0830 22:26:35.744650 916722 sgd_solver.cpp:106] Iteration 2217000, lr = 0.01
I0830 22:27:05.467276 916722 solver.cpp:218] Iteration 2217500 (16.8223 iter/s, 29.7225s/500 iters), loss = 0.153357
I0830 22:27:05.467332 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.153358 (* 1 = 0.153358 loss)
I0830 22:27:05.467342 916722 sgd_solver.cpp:106] Iteration 2217500, lr = 0.01
I0830 22:27:35.188661 916722 solver.cpp:218] Iteration 2218000 (16.823 iter/s, 29.7212s/500 iters), loss = 0.188558
I0830 22:27:35.188725 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.188559 (* 1 = 0.188559 loss)
I0830 22:27:35.188735 916722 sgd_solver.cpp:106] Iteration 2218000, lr = 0.01
I0830 22:28:04.911363 916722 solver.cpp:218] Iteration 2218500 (16.8223 iter/s, 29.7225s/500 iters), loss = 0.55556
I0830 22:28:04.911414 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.555561 (* 1 = 0.555561 loss)
I0830 22:28:04.911422 916722 sgd_solver.cpp:106] Iteration 2218500, lr = 0.01
I0830 22:28:34.637202 916722 solver.cpp:218] Iteration 2219000 (16.8205 iter/s, 29.7257s/500 iters), loss = 0.114853
I0830 22:28:34.637259 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.114855 (* 1 = 0.114855 loss)
I0830 22:28:34.637267 916722 sgd_solver.cpp:106] Iteration 2219000, lr = 0.01
I0830 22:29:04.358655 916722 solver.cpp:218] Iteration 2219500 (16.823 iter/s, 29.7213s/500 iters), loss = 0.0534907
I0830 22:29:04.358705 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0534925 (* 1 = 0.0534925 loss)
I0830 22:29:04.358713 916722 sgd_solver.cpp:106] Iteration 2219500, lr = 0.01
I0830 22:29:34.081722 916722 solver.cpp:218] Iteration 2220000 (16.8221 iter/s, 29.7229s/500 iters), loss = 0.0954504
I0830 22:29:34.081784 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0954524 (* 1 = 0.0954524 loss)
I0830 22:29:34.081792 916722 sgd_solver.cpp:106] Iteration 2220000, lr = 0.01
I0830 22:30:03.802559 916722 solver.cpp:218] Iteration 2220500 (16.8233 iter/s, 29.7206s/500 iters), loss = 0.272642
I0830 22:30:03.802609 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.272644 (* 1 = 0.272644 loss)
I0830 22:30:03.802618 916722 sgd_solver.cpp:106] Iteration 2220500, lr = 0.01
I0830 22:30:33.527277 916722 solver.cpp:218] Iteration 2221000 (16.8211 iter/s, 29.7245s/500 iters), loss = 0.0808156
I0830 22:30:33.527348 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0808176 (* 1 = 0.0808176 loss)
I0830 22:30:33.527356 916722 sgd_solver.cpp:106] Iteration 2221000, lr = 0.01
I0830 22:31:03.251789 916722 solver.cpp:218] Iteration 2221500 (16.8212 iter/s, 29.7243s/500 iters), loss = 0.342585
I0830 22:31:03.251842 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.342587 (* 1 = 0.342587 loss)
I0830 22:31:03.251850 916722 sgd_solver.cpp:106] Iteration 2221500, lr = 0.01
I0830 22:31:32.972887 916722 solver.cpp:218] Iteration 2222000 (16.8232 iter/s, 29.7209s/500 iters), loss = 0.0963993
I0830 22:31:32.972947 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0964013 (* 1 = 0.0964013 loss)
I0830 22:31:32.972956 916722 sgd_solver.cpp:106] Iteration 2222000, lr = 0.01
I0830 22:32:02.697860 916722 solver.cpp:218] Iteration 2222500 (16.821 iter/s, 29.7248s/500 iters), loss = 0.133455
I0830 22:32:02.697911 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133457 (* 1 = 0.133457 loss)
I0830 22:32:02.697919 916722 sgd_solver.cpp:106] Iteration 2222500, lr = 0.01
I0830 22:32:32.419651 916722 solver.cpp:218] Iteration 2223000 (16.8228 iter/s, 29.7216s/500 iters), loss = 0.155183
I0830 22:32:32.419710 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.155184 (* 1 = 0.155184 loss)
I0830 22:32:32.419719 916722 sgd_solver.cpp:106] Iteration 2223000, lr = 0.01
I0830 22:33:02.141710 916722 solver.cpp:218] Iteration 2223500 (16.8226 iter/s, 29.7219s/500 iters), loss = 0.502899
I0830 22:33:02.141763 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.5029 (* 1 = 0.5029 loss)
I0830 22:33:02.141773 916722 sgd_solver.cpp:106] Iteration 2223500, lr = 0.01
I0830 22:33:31.875401 916722 solver.cpp:218] Iteration 2224000 (16.816 iter/s, 29.7335s/500 iters), loss = 0.0545164
I0830 22:33:31.875464 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0545182 (* 1 = 0.0545182 loss)
I0830 22:33:31.875473 916722 sgd_solver.cpp:106] Iteration 2224000, lr = 0.01
I0830 22:34:01.597375 916722 solver.cpp:218] Iteration 2224500 (16.8227 iter/s, 29.7218s/500 iters), loss = 0.244133
I0830 22:34:01.597427 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.244135 (* 1 = 0.244135 loss)
I0830 22:34:01.597438 916722 sgd_solver.cpp:106] Iteration 2224500, lr = 0.01
I0830 22:34:31.319900 916722 solver.cpp:218] Iteration 2225000 (16.8224 iter/s, 29.7224s/500 iters), loss = 0.0798435
I0830 22:34:31.319955 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0798454 (* 1 = 0.0798454 loss)
I0830 22:34:31.319964 916722 sgd_solver.cpp:106] Iteration 2225000, lr = 0.01
I0830 22:35:01.042543 916722 solver.cpp:218] Iteration 2225500 (16.8223 iter/s, 29.7225s/500 iters), loss = 0.0907921
I0830 22:35:01.042595 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0907939 (* 1 = 0.0907939 loss)
I0830 22:35:01.042605 916722 sgd_solver.cpp:106] Iteration 2225500, lr = 0.01
I0830 22:35:30.763389 916722 solver.cpp:218] Iteration 2226000 (16.8233 iter/s, 29.7207s/500 iters), loss = 0.105979
I0830 22:35:30.763450 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105981 (* 1 = 0.105981 loss)
I0830 22:35:30.763459 916722 sgd_solver.cpp:106] Iteration 2226000, lr = 0.01
I0830 22:36:00.486728 916722 solver.cpp:218] Iteration 2226500 (16.8219 iter/s, 29.7232s/500 iters), loss = 0.15881
I0830 22:36:00.486778 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.158811 (* 1 = 0.158811 loss)
I0830 22:36:00.486789 916722 sgd_solver.cpp:106] Iteration 2226500, lr = 0.01
I0830 22:36:30.209834 916722 solver.cpp:218] Iteration 2227000 (16.822 iter/s, 29.7229s/500 iters), loss = 0.108712
I0830 22:36:30.209895 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.108714 (* 1 = 0.108714 loss)
I0830 22:36:30.209904 916722 sgd_solver.cpp:106] Iteration 2227000, lr = 0.01
I0830 22:36:59.932858 916722 solver.cpp:218] Iteration 2227500 (16.8221 iter/s, 29.7229s/500 iters), loss = 0.0903798
I0830 22:36:59.932914 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0903818 (* 1 = 0.0903818 loss)
I0830 22:36:59.932924 916722 sgd_solver.cpp:106] Iteration 2227500, lr = 0.01
I0830 22:37:29.655366 916722 solver.cpp:218] Iteration 2228000 (16.8224 iter/s, 29.7223s/500 iters), loss = 0.391875
I0830 22:37:29.655437 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.391877 (* 1 = 0.391877 loss)
I0830 22:37:29.655445 916722 sgd_solver.cpp:106] Iteration 2228000, lr = 0.01
I0830 22:37:59.376765 916722 solver.cpp:218] Iteration 2228500 (16.823 iter/s, 29.7212s/500 iters), loss = 0.0744687
I0830 22:37:59.376818 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0744708 (* 1 = 0.0744708 loss)
I0830 22:37:59.376833 916722 sgd_solver.cpp:106] Iteration 2228500, lr = 0.01
I0830 22:38:29.100674 916722 solver.cpp:218] Iteration 2229000 (16.8216 iter/s, 29.7237s/500 iters), loss = 0.150321
I0830 22:38:29.100736 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.150323 (* 1 = 0.150323 loss)
I0830 22:38:29.100754 916722 sgd_solver.cpp:106] Iteration 2229000, lr = 0.01
I0830 22:38:58.822567 916722 solver.cpp:218] Iteration 2229500 (16.8227 iter/s, 29.7217s/500 iters), loss = 0.0915935
I0830 22:38:58.822618 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0915954 (* 1 = 0.0915954 loss)
I0830 22:38:58.822628 916722 sgd_solver.cpp:106] Iteration 2229500, lr = 0.01
I0830 22:39:28.543612 916722 solver.cpp:218] Iteration 2230000 (16.8232 iter/s, 29.7209s/500 iters), loss = 0.143865
I0830 22:39:28.543673 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.143867 (* 1 = 0.143867 loss)
I0830 22:39:28.543682 916722 sgd_solver.cpp:106] Iteration 2230000, lr = 0.01
I0830 22:39:58.263003 916722 solver.cpp:218] Iteration 2230500 (16.8241 iter/s, 29.7192s/500 iters), loss = 0.162373
I0830 22:39:58.263056 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.162375 (* 1 = 0.162375 loss)
I0830 22:39:58.263065 916722 sgd_solver.cpp:106] Iteration 2230500, lr = 0.01
I0830 22:40:27.984812 916722 solver.cpp:218] Iteration 2231000 (16.8228 iter/s, 29.7216s/500 iters), loss = 0.17159
I0830 22:40:27.984874 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.171592 (* 1 = 0.171592 loss)
I0830 22:40:27.984881 916722 sgd_solver.cpp:106] Iteration 2231000, lr = 0.01
I0830 22:40:57.708153 916722 solver.cpp:218] Iteration 2231500 (16.8221 iter/s, 29.7228s/500 iters), loss = 0.0467125
I0830 22:40:57.708206 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0467144 (* 1 = 0.0467144 loss)
I0830 22:40:57.708215 916722 sgd_solver.cpp:106] Iteration 2231500, lr = 0.01
I0830 22:41:27.434145 916722 solver.cpp:218] Iteration 2232000 (16.8206 iter/s, 29.7254s/500 iters), loss = 0.167808
I0830 22:41:27.434204 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.16781 (* 1 = 0.16781 loss)
I0830 22:41:27.434213 916722 sgd_solver.cpp:106] Iteration 2232000, lr = 0.01
I0830 22:41:57.157446 916722 solver.cpp:218] Iteration 2232500 (16.8221 iter/s, 29.7228s/500 iters), loss = 0.266856
I0830 22:41:57.157500 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.266858 (* 1 = 0.266858 loss)
I0830 22:41:57.157508 916722 sgd_solver.cpp:106] Iteration 2232500, lr = 0.01
I0830 22:42:26.883220 916722 solver.cpp:218] Iteration 2233000 (16.8207 iter/s, 29.7253s/500 iters), loss = 0.062334
I0830 22:42:26.883280 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0623358 (* 1 = 0.0623358 loss)
I0830 22:42:26.883289 916722 sgd_solver.cpp:106] Iteration 2233000, lr = 0.01
I0830 22:42:56.609158 916722 solver.cpp:218] Iteration 2233500 (16.8206 iter/s, 29.7254s/500 iters), loss = 0.183314
I0830 22:42:56.609208 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.183316 (* 1 = 0.183316 loss)
I0830 22:42:56.609217 916722 sgd_solver.cpp:106] Iteration 2233500, lr = 0.01
I0830 22:43:26.334089 916722 solver.cpp:218] Iteration 2234000 (16.8212 iter/s, 29.7245s/500 iters), loss = 0.229286
I0830 22:43:26.334148 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.229287 (* 1 = 0.229287 loss)
I0830 22:43:26.334157 916722 sgd_solver.cpp:106] Iteration 2234000, lr = 0.01
I0830 22:43:56.054677 916722 solver.cpp:218] Iteration 2234500 (16.8236 iter/s, 29.7201s/500 iters), loss = 0.0901587
I0830 22:43:56.054745 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0901605 (* 1 = 0.0901605 loss)
I0830 22:43:56.054756 916722 sgd_solver.cpp:106] Iteration 2234500, lr = 0.01
I0830 22:44:25.780879 916722 solver.cpp:218] Iteration 2235000 (16.8204 iter/s, 29.7257s/500 iters), loss = 0.338374
I0830 22:44:25.780947 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.338376 (* 1 = 0.338376 loss)
I0830 22:44:25.780956 916722 sgd_solver.cpp:106] Iteration 2235000, lr = 0.01
I0830 22:44:55.506131 916722 solver.cpp:218] Iteration 2235500 (16.821 iter/s, 29.7248s/500 iters), loss = 0.126846
I0830 22:44:55.506184 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.126848 (* 1 = 0.126848 loss)
I0830 22:44:55.506194 916722 sgd_solver.cpp:106] Iteration 2235500, lr = 0.01
I0830 22:45:25.230886 916722 solver.cpp:218] Iteration 2236000 (16.8212 iter/s, 29.7243s/500 iters), loss = 0.174175
I0830 22:45:25.230950 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.174177 (* 1 = 0.174177 loss)
I0830 22:45:25.230962 916722 sgd_solver.cpp:106] Iteration 2236000, lr = 0.01
I0830 22:45:54.957559 916722 solver.cpp:218] Iteration 2236500 (16.8202 iter/s, 29.7263s/500 iters), loss = 0.108204
I0830 22:45:54.957605 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.108205 (* 1 = 0.108205 loss)
I0830 22:45:54.957613 916722 sgd_solver.cpp:106] Iteration 2236500, lr = 0.01
I0830 22:46:24.683848 916722 solver.cpp:218] Iteration 2237000 (16.8204 iter/s, 29.7259s/500 iters), loss = 0.167598
I0830 22:46:24.683907 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.167599 (* 1 = 0.167599 loss)
I0830 22:46:24.683915 916722 sgd_solver.cpp:106] Iteration 2237000, lr = 0.01
I0830 22:46:54.407699 916722 solver.cpp:218] Iteration 2237500 (16.8217 iter/s, 29.7234s/500 iters), loss = 0.110775
I0830 22:46:54.407752 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110777 (* 1 = 0.110777 loss)
I0830 22:46:54.407761 916722 sgd_solver.cpp:106] Iteration 2237500, lr = 0.01
I0830 22:47:24.135522 916722 solver.cpp:218] Iteration 2238000 (16.8195 iter/s, 29.7274s/500 iters), loss = 0.0467448
I0830 22:47:24.135579 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0467467 (* 1 = 0.0467467 loss)
I0830 22:47:24.135588 916722 sgd_solver.cpp:106] Iteration 2238000, lr = 0.01
I0830 22:47:53.855885 916722 solver.cpp:218] Iteration 2238500 (16.8237 iter/s, 29.72s/500 iters), loss = 0.289324
I0830 22:47:53.855937 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.289326 (* 1 = 0.289326 loss)
I0830 22:47:53.855944 916722 sgd_solver.cpp:106] Iteration 2238500, lr = 0.01
I0830 22:48:23.581482 916722 solver.cpp:218] Iteration 2239000 (16.8207 iter/s, 29.7252s/500 iters), loss = 0.245763
I0830 22:48:23.581542 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.245765 (* 1 = 0.245765 loss)
I0830 22:48:23.581552 916722 sgd_solver.cpp:106] Iteration 2239000, lr = 0.01
I0830 22:48:53.305985 916722 solver.cpp:218] Iteration 2239500 (16.8213 iter/s, 29.7241s/500 iters), loss = 0.141879
I0830 22:48:53.306042 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.141881 (* 1 = 0.141881 loss)
I0830 22:48:53.306052 916722 sgd_solver.cpp:106] Iteration 2239500, lr = 0.01
I0830 22:49:23.029260 916722 solver.cpp:218] Iteration 2240000 (16.822 iter/s, 29.7229s/500 iters), loss = 0.107764
I0830 22:49:23.029316 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.107766 (* 1 = 0.107766 loss)
I0830 22:49:23.029325 916722 sgd_solver.cpp:106] Iteration 2240000, lr = 0.01
I0830 22:49:52.755487 916722 solver.cpp:218] Iteration 2240500 (16.8204 iter/s, 29.7259s/500 iters), loss = 0.108134
I0830 22:49:52.755542 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.108136 (* 1 = 0.108136 loss)
I0830 22:49:52.755553 916722 sgd_solver.cpp:106] Iteration 2240500, lr = 0.01
I0830 22:50:22.476610 916722 solver.cpp:218] Iteration 2241000 (16.8232 iter/s, 29.7208s/500 iters), loss = 0.153187
I0830 22:50:22.476684 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.153188 (* 1 = 0.153188 loss)
I0830 22:50:22.476694 916722 sgd_solver.cpp:106] Iteration 2241000, lr = 0.01
I0830 22:50:52.197814 916722 solver.cpp:218] Iteration 2241500 (16.8232 iter/s, 29.7209s/500 iters), loss = 0.103409
I0830 22:50:52.197870 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.10341 (* 1 = 0.10341 loss)
I0830 22:50:52.197880 916722 sgd_solver.cpp:106] Iteration 2241500, lr = 0.01
I0830 22:51:21.922924 916722 solver.cpp:218] Iteration 2242000 (16.821 iter/s, 29.7248s/500 iters), loss = 0.218235
I0830 22:51:21.922982 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.218236 (* 1 = 0.218236 loss)
I0830 22:51:21.922991 916722 sgd_solver.cpp:106] Iteration 2242000, lr = 0.01
I0830 22:51:51.643163 916722 solver.cpp:218] Iteration 2242500 (16.8237 iter/s, 29.7199s/500 iters), loss = 0.221751
I0830 22:51:51.643213 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.221753 (* 1 = 0.221753 loss)
I0830 22:51:51.643224 916722 sgd_solver.cpp:106] Iteration 2242500, lr = 0.01
I0830 22:52:21.364940 916722 solver.cpp:218] Iteration 2243000 (16.8229 iter/s, 29.7215s/500 iters), loss = 0.398612
I0830 22:52:21.365001 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.398614 (* 1 = 0.398614 loss)
I0830 22:52:21.365010 916722 sgd_solver.cpp:106] Iteration 2243000, lr = 0.01
I0830 22:52:51.086128 916722 solver.cpp:218] Iteration 2243500 (16.8232 iter/s, 29.7209s/500 iters), loss = 0.154448
I0830 22:52:51.086181 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.154449 (* 1 = 0.154449 loss)
I0830 22:52:51.086192 916722 sgd_solver.cpp:106] Iteration 2243500, lr = 0.01
I0830 22:53:20.809135 916722 solver.cpp:218] Iteration 2244000 (16.8222 iter/s, 29.7227s/500 iters), loss = 0.0474106
I0830 22:53:20.809196 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0474121 (* 1 = 0.0474121 loss)
I0830 22:53:20.809204 916722 sgd_solver.cpp:106] Iteration 2244000, lr = 0.01
I0830 22:53:50.534919 916722 solver.cpp:218] Iteration 2244500 (16.8206 iter/s, 29.7255s/500 iters), loss = 0.0464894
I0830 22:53:50.534973 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.046491 (* 1 = 0.046491 loss)
I0830 22:53:50.534983 916722 sgd_solver.cpp:106] Iteration 2244500, lr = 0.01
I0830 22:54:20.257815 916722 solver.cpp:218] Iteration 2245000 (16.8222 iter/s, 29.7226s/500 iters), loss = 0.216423
I0830 22:54:20.257879 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.216425 (* 1 = 0.216425 loss)
I0830 22:54:20.257889 916722 sgd_solver.cpp:106] Iteration 2245000, lr = 0.01
I0830 22:54:49.980844 916722 solver.cpp:218] Iteration 2245500 (16.8221 iter/s, 29.7227s/500 iters), loss = 0.248218
I0830 22:54:49.980895 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.248219 (* 1 = 0.248219 loss)
I0830 22:54:49.980906 916722 sgd_solver.cpp:106] Iteration 2245500, lr = 0.01
I0830 22:55:19.704825 916722 solver.cpp:218] Iteration 2246000 (16.8216 iter/s, 29.7237s/500 iters), loss = 0.26692
I0830 22:55:19.704890 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.266922 (* 1 = 0.266922 loss)
I0830 22:55:19.704898 916722 sgd_solver.cpp:106] Iteration 2246000, lr = 0.01
I0830 22:55:49.429010 916722 solver.cpp:218] Iteration 2246500 (16.8215 iter/s, 29.7239s/500 iters), loss = 0.0933597
I0830 22:55:49.429061 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0933613 (* 1 = 0.0933613 loss)
I0830 22:55:49.429070 916722 sgd_solver.cpp:106] Iteration 2246500, lr = 0.01
I0830 22:56:19.155189 916722 solver.cpp:218] Iteration 2247000 (16.8203 iter/s, 29.7259s/500 iters), loss = 0.0294697
I0830 22:56:19.155243 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0294712 (* 1 = 0.0294712 loss)
I0830 22:56:19.155251 916722 sgd_solver.cpp:106] Iteration 2247000, lr = 0.01
I0830 22:56:48.878248 916722 solver.cpp:218] Iteration 2247500 (16.8221 iter/s, 29.7228s/500 iters), loss = 0.0966165
I0830 22:56:48.878314 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0966182 (* 1 = 0.0966182 loss)
I0830 22:56:48.878324 916722 sgd_solver.cpp:106] Iteration 2247500, lr = 0.01
I0830 22:57:18.607497 916722 solver.cpp:218] Iteration 2248000 (16.8186 iter/s, 29.729s/500 iters), loss = 0.0708061
I0830 22:57:18.607569 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.070808 (* 1 = 0.070808 loss)
I0830 22:57:18.607578 916722 sgd_solver.cpp:106] Iteration 2248000, lr = 0.01
I0830 22:57:48.330312 916722 solver.cpp:218] Iteration 2248500 (16.8223 iter/s, 29.7225s/500 iters), loss = 0.0874147
I0830 22:57:48.330366 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0874164 (* 1 = 0.0874164 loss)
I0830 22:57:48.330375 916722 sgd_solver.cpp:106] Iteration 2248500, lr = 0.01
I0830 22:58:18.058676 916722 solver.cpp:218] Iteration 2249000 (16.8191 iter/s, 29.7281s/500 iters), loss = 0.153854
I0830 22:58:18.058735 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.153856 (* 1 = 0.153856 loss)
I0830 22:58:18.058743 916722 sgd_solver.cpp:106] Iteration 2249000, lr = 0.01
I0830 22:58:47.783912 916722 solver.cpp:218] Iteration 2249500 (16.8209 iter/s, 29.725s/500 iters), loss = 0.226361
I0830 22:58:47.783967 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.226363 (* 1 = 0.226363 loss)
I0830 22:58:47.783975 916722 sgd_solver.cpp:106] Iteration 2249500, lr = 0.01
I0830 22:59:17.448751 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_2250000.caffemodel
I0830 22:59:17.468217 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_2250000.solverstate
I0830 22:59:17.474359 916722 solver.cpp:330] Iteration 2250000, Testing net (#0)
I0830 22:59:32.865875 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8796
I0830 22:59:32.865921 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.415291 (* 1 = 0.415291 loss)
I0830 22:59:32.924628 916722 solver.cpp:218] Iteration 2250000 (11.0766 iter/s, 45.1403s/500 iters), loss = 0.259389
I0830 22:59:32.924659 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.259391 (* 1 = 0.259391 loss)
I0830 22:59:32.924667 916722 sgd_solver.cpp:106] Iteration 2250000, lr = 0.01
I0830 23:00:02.542982 916722 solver.cpp:218] Iteration 2250500 (16.8816 iter/s, 29.6181s/500 iters), loss = 0.401996
I0830 23:00:02.543042 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.401998 (* 1 = 0.401998 loss)
I0830 23:00:02.543051 916722 sgd_solver.cpp:106] Iteration 2250500, lr = 0.01
I0830 23:00:32.188690 916722 solver.cpp:218] Iteration 2251000 (16.866 iter/s, 29.6454s/500 iters), loss = 0.137751
I0830 23:00:32.188755 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.137753 (* 1 = 0.137753 loss)
I0830 23:00:32.188766 916722 sgd_solver.cpp:106] Iteration 2251000, lr = 0.01
I0830 23:01:01.913403 916722 solver.cpp:218] Iteration 2251500 (16.8212 iter/s, 29.7244s/500 iters), loss = 0.0795523
I0830 23:01:01.913460 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0795541 (* 1 = 0.0795541 loss)
I0830 23:01:01.913468 916722 sgd_solver.cpp:106] Iteration 2251500, lr = 0.01
I0830 23:01:31.638142 916722 solver.cpp:218] Iteration 2252000 (16.8212 iter/s, 29.7245s/500 iters), loss = 0.28246
I0830 23:01:31.638196 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.282462 (* 1 = 0.282462 loss)
I0830 23:01:31.638207 916722 sgd_solver.cpp:106] Iteration 2252000, lr = 0.01
I0830 23:02:01.364091 916722 solver.cpp:218] Iteration 2252500 (16.8205 iter/s, 29.7257s/500 iters), loss = 0.0810715
I0830 23:02:01.364148 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0810732 (* 1 = 0.0810732 loss)
I0830 23:02:01.364156 916722 sgd_solver.cpp:106] Iteration 2252500, lr = 0.01
I0830 23:02:31.084754 916722 solver.cpp:218] Iteration 2253000 (16.8235 iter/s, 29.7204s/500 iters), loss = 0.267221
I0830 23:02:31.084808 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.267223 (* 1 = 0.267223 loss)
I0830 23:02:31.084830 916722 sgd_solver.cpp:106] Iteration 2253000, lr = 0.01
I0830 23:03:00.807898 916722 solver.cpp:218] Iteration 2253500 (16.8221 iter/s, 29.7229s/500 iters), loss = 0.276489
I0830 23:03:00.807965 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.276491 (* 1 = 0.276491 loss)
I0830 23:03:00.807973 916722 sgd_solver.cpp:106] Iteration 2253500, lr = 0.01
I0830 23:03:30.532851 916722 solver.cpp:218] Iteration 2254000 (16.821 iter/s, 29.7247s/500 iters), loss = 0.0752888
I0830 23:03:30.532907 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0752903 (* 1 = 0.0752903 loss)
I0830 23:03:30.532917 916722 sgd_solver.cpp:106] Iteration 2254000, lr = 0.01
I0830 23:04:00.255311 916722 solver.cpp:218] Iteration 2254500 (16.8224 iter/s, 29.7222s/500 iters), loss = 0.0894513
I0830 23:04:00.255369 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.089453 (* 1 = 0.089453 loss)
I0830 23:04:00.255378 916722 sgd_solver.cpp:106] Iteration 2254500, lr = 0.01
I0830 23:04:29.979357 916722 solver.cpp:218] Iteration 2255000 (16.8215 iter/s, 29.7238s/500 iters), loss = 0.259584
I0830 23:04:29.979409 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.259586 (* 1 = 0.259586 loss)
I0830 23:04:29.979419 916722 sgd_solver.cpp:106] Iteration 2255000, lr = 0.01
I0830 23:04:59.705850 916722 solver.cpp:218] Iteration 2255500 (16.8202 iter/s, 29.7262s/500 iters), loss = 0.147017
I0830 23:04:59.705909 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.147019 (* 1 = 0.147019 loss)
I0830 23:04:59.705919 916722 sgd_solver.cpp:106] Iteration 2255500, lr = 0.01
I0830 23:05:29.425781 916722 solver.cpp:218] Iteration 2256000 (16.8239 iter/s, 29.7197s/500 iters), loss = 0.0636875
I0830 23:05:29.425833 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0636892 (* 1 = 0.0636892 loss)
I0830 23:05:29.425843 916722 sgd_solver.cpp:106] Iteration 2256000, lr = 0.01
I0830 23:05:59.147081 916722 solver.cpp:218] Iteration 2256500 (16.8231 iter/s, 29.7211s/500 iters), loss = 0.104071
I0830 23:05:59.147145 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104073 (* 1 = 0.104073 loss)
I0830 23:05:59.147153 916722 sgd_solver.cpp:106] Iteration 2256500, lr = 0.01
I0830 23:06:28.869102 916722 solver.cpp:218] Iteration 2257000 (16.8227 iter/s, 29.7218s/500 iters), loss = 0.0752715
I0830 23:06:28.869153 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0752732 (* 1 = 0.0752732 loss)
I0830 23:06:28.869163 916722 sgd_solver.cpp:106] Iteration 2257000, lr = 0.01
I0830 23:06:58.595360 916722 solver.cpp:218] Iteration 2257500 (16.8203 iter/s, 29.726s/500 iters), loss = 0.0384968
I0830 23:06:58.595420 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0384984 (* 1 = 0.0384984 loss)
I0830 23:06:58.595429 916722 sgd_solver.cpp:106] Iteration 2257500, lr = 0.01
I0830 23:07:28.320756 916722 solver.cpp:218] Iteration 2258000 (16.8208 iter/s, 29.7251s/500 iters), loss = 0.282064
I0830 23:07:28.320808 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.282066 (* 1 = 0.282066 loss)
I0830 23:07:28.320817 916722 sgd_solver.cpp:106] Iteration 2258000, lr = 0.01
I0830 23:07:58.043524 916722 solver.cpp:218] Iteration 2258500 (16.8223 iter/s, 29.7225s/500 iters), loss = 0.118386
I0830 23:07:58.043578 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.118388 (* 1 = 0.118388 loss)
I0830 23:07:58.043586 916722 sgd_solver.cpp:106] Iteration 2258500, lr = 0.01
I0830 23:08:27.765668 916722 solver.cpp:218] Iteration 2259000 (16.8226 iter/s, 29.7219s/500 iters), loss = 0.302277
I0830 23:08:27.765720 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.302279 (* 1 = 0.302279 loss)
I0830 23:08:27.765730 916722 sgd_solver.cpp:106] Iteration 2259000, lr = 0.01
I0830 23:08:57.485127 916722 solver.cpp:218] Iteration 2259500 (16.8241 iter/s, 29.7192s/500 iters), loss = 0.105654
I0830 23:08:57.485198 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105656 (* 1 = 0.105656 loss)
I0830 23:08:57.485211 916722 sgd_solver.cpp:106] Iteration 2259500, lr = 0.01
I0830 23:09:27.207530 916722 solver.cpp:218] Iteration 2260000 (16.8225 iter/s, 29.7222s/500 iters), loss = 0.0846933
I0830 23:09:27.207582 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0846954 (* 1 = 0.0846954 loss)
I0830 23:09:27.207592 916722 sgd_solver.cpp:106] Iteration 2260000, lr = 0.01
I0830 23:09:56.929756 916722 solver.cpp:218] Iteration 2260500 (16.8226 iter/s, 29.722s/500 iters), loss = 0.0458131
I0830 23:09:56.929819 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0458153 (* 1 = 0.0458153 loss)
I0830 23:09:56.929827 916722 sgd_solver.cpp:106] Iteration 2260500, lr = 0.01
I0830 23:10:26.653657 916722 solver.cpp:218] Iteration 2261000 (16.8216 iter/s, 29.7237s/500 iters), loss = 0.0137495
I0830 23:10:26.653710 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0137516 (* 1 = 0.0137516 loss)
I0830 23:10:26.653719 916722 sgd_solver.cpp:106] Iteration 2261000, lr = 0.01
I0830 23:10:56.376873 916722 solver.cpp:218] Iteration 2261500 (16.822 iter/s, 29.723s/500 iters), loss = 0.123189
I0830 23:10:56.376936 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.123191 (* 1 = 0.123191 loss)
I0830 23:10:56.376945 916722 sgd_solver.cpp:106] Iteration 2261500, lr = 0.01
I0830 23:11:26.107205 916722 solver.cpp:218] Iteration 2262000 (16.818 iter/s, 29.7301s/500 iters), loss = 0.101156
I0830 23:11:26.107252 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101158 (* 1 = 0.101158 loss)
I0830 23:11:26.107261 916722 sgd_solver.cpp:106] Iteration 2262000, lr = 0.01
I0830 23:11:55.854059 916722 solver.cpp:218] Iteration 2262500 (16.8086 iter/s, 29.7466s/500 iters), loss = 0.116238
I0830 23:11:55.854120 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.116241 (* 1 = 0.116241 loss)
I0830 23:11:55.854128 916722 sgd_solver.cpp:106] Iteration 2262500, lr = 0.01
I0830 23:12:25.585896 916722 solver.cpp:218] Iteration 2263000 (16.8171 iter/s, 29.7316s/500 iters), loss = 0.455407
I0830 23:12:25.585942 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.455409 (* 1 = 0.455409 loss)
I0830 23:12:25.585952 916722 sgd_solver.cpp:106] Iteration 2263000, lr = 0.01
I0830 23:12:55.327342 916722 solver.cpp:218] Iteration 2263500 (16.8117 iter/s, 29.7412s/500 iters), loss = 0.148105
I0830 23:12:55.327399 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.148107 (* 1 = 0.148107 loss)
I0830 23:12:55.327407 916722 sgd_solver.cpp:106] Iteration 2263500, lr = 0.01
I0830 23:13:25.064749 916722 solver.cpp:218] Iteration 2264000 (16.814 iter/s, 29.7372s/500 iters), loss = 0.249913
I0830 23:13:25.064796 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.249915 (* 1 = 0.249915 loss)
I0830 23:13:25.064806 916722 sgd_solver.cpp:106] Iteration 2264000, lr = 0.01
I0830 23:13:54.805343 916722 solver.cpp:218] Iteration 2264500 (16.8122 iter/s, 29.7404s/500 iters), loss = 0.164489
I0830 23:13:54.805395 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.164491 (* 1 = 0.164491 loss)
I0830 23:13:54.805403 916722 sgd_solver.cpp:106] Iteration 2264500, lr = 0.01
I0830 23:14:24.536152 916722 solver.cpp:218] Iteration 2265000 (16.8177 iter/s, 29.7306s/500 iters), loss = 0.16805
I0830 23:14:24.536204 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.168052 (* 1 = 0.168052 loss)
I0830 23:14:24.536213 916722 sgd_solver.cpp:106] Iteration 2265000, lr = 0.01
I0830 23:14:54.268028 916722 solver.cpp:218] Iteration 2265500 (16.817 iter/s, 29.7318s/500 iters), loss = 0.270356
I0830 23:14:54.268090 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.270358 (* 1 = 0.270358 loss)
I0830 23:14:54.268100 916722 sgd_solver.cpp:106] Iteration 2265500, lr = 0.01
I0830 23:15:23.983289 916722 solver.cpp:218] Iteration 2266000 (16.8264 iter/s, 29.7152s/500 iters), loss = 0.12862
I0830 23:15:23.983350 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128622 (* 1 = 0.128622 loss)
I0830 23:15:23.983361 916722 sgd_solver.cpp:106] Iteration 2266000, lr = 0.01
I0830 23:15:53.688094 916722 solver.cpp:218] Iteration 2266500 (16.8323 iter/s, 29.7048s/500 iters), loss = 0.0236375
I0830 23:15:53.688169 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0236395 (* 1 = 0.0236395 loss)
I0830 23:15:53.688177 916722 sgd_solver.cpp:106] Iteration 2266500, lr = 0.01
I0830 23:16:23.388612 916722 solver.cpp:218] Iteration 2267000 (16.8348 iter/s, 29.7005s/500 iters), loss = 0.130625
I0830 23:16:23.388666 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130627 (* 1 = 0.130627 loss)
I0830 23:16:23.388677 916722 sgd_solver.cpp:106] Iteration 2267000, lr = 0.01
I0830 23:16:53.092218 916722 solver.cpp:218] Iteration 2267500 (16.833 iter/s, 29.7035s/500 iters), loss = 0.228676
I0830 23:16:53.092276 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.228678 (* 1 = 0.228678 loss)
I0830 23:16:53.092285 916722 sgd_solver.cpp:106] Iteration 2267500, lr = 0.01
I0830 23:17:22.793792 916722 solver.cpp:218] Iteration 2268000 (16.8342 iter/s, 29.7015s/500 iters), loss = 0.067925
I0830 23:17:22.793843 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0679269 (* 1 = 0.0679269 loss)
I0830 23:17:22.793853 916722 sgd_solver.cpp:106] Iteration 2268000, lr = 0.01
I0830 23:17:52.493508 916722 solver.cpp:218] Iteration 2268500 (16.8352 iter/s, 29.6996s/500 iters), loss = 0.0604311
I0830 23:17:52.493564 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0604331 (* 1 = 0.0604331 loss)
I0830 23:17:52.493573 916722 sgd_solver.cpp:106] Iteration 2268500, lr = 0.01
I0830 23:18:22.193022 916722 solver.cpp:218] Iteration 2269000 (16.8353 iter/s, 29.6994s/500 iters), loss = 0.096523
I0830 23:18:22.193075 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0965251 (* 1 = 0.0965251 loss)
I0830 23:18:22.193085 916722 sgd_solver.cpp:106] Iteration 2269000, lr = 0.01
I0830 23:18:51.893587 916722 solver.cpp:218] Iteration 2269500 (16.8347 iter/s, 29.7005s/500 iters), loss = 0.21614
I0830 23:18:51.893649 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.216142 (* 1 = 0.216142 loss)
I0830 23:18:51.893657 916722 sgd_solver.cpp:106] Iteration 2269500, lr = 0.01
I0830 23:19:21.597044 916722 solver.cpp:218] Iteration 2270000 (16.8331 iter/s, 29.7034s/500 iters), loss = 0.117552
I0830 23:19:21.597098 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.117554 (* 1 = 0.117554 loss)
I0830 23:19:21.597108 916722 sgd_solver.cpp:106] Iteration 2270000, lr = 0.01
I0830 23:19:51.298447 916722 solver.cpp:218] Iteration 2270500 (16.8343 iter/s, 29.7013s/500 iters), loss = 0.0958007
I0830 23:19:51.298511 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0958028 (* 1 = 0.0958028 loss)
I0830 23:19:51.298519 916722 sgd_solver.cpp:106] Iteration 2270500, lr = 0.01
I0830 23:20:20.997615 916722 solver.cpp:218] Iteration 2271000 (16.8356 iter/s, 29.6991s/500 iters), loss = 0.0876815
I0830 23:20:20.997668 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0876838 (* 1 = 0.0876838 loss)
I0830 23:20:20.997675 916722 sgd_solver.cpp:106] Iteration 2271000, lr = 0.01
I0830 23:20:50.698640 916722 solver.cpp:218] Iteration 2271500 (16.8345 iter/s, 29.7009s/500 iters), loss = 0.176027
I0830 23:20:50.698699 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.176029 (* 1 = 0.176029 loss)
I0830 23:20:50.698709 916722 sgd_solver.cpp:106] Iteration 2271500, lr = 0.01
I0830 23:21:20.401059 916722 solver.cpp:218] Iteration 2272000 (16.8337 iter/s, 29.7023s/500 iters), loss = 0.144123
I0830 23:21:20.401109 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.144125 (* 1 = 0.144125 loss)
I0830 23:21:20.401118 916722 sgd_solver.cpp:106] Iteration 2272000, lr = 0.01
I0830 23:21:50.112563 916722 solver.cpp:218] Iteration 2272500 (16.8286 iter/s, 29.7114s/500 iters), loss = 0.201313
I0830 23:21:50.112622 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.201315 (* 1 = 0.201315 loss)
I0830 23:21:50.112630 916722 sgd_solver.cpp:106] Iteration 2272500, lr = 0.01
I0830 23:22:19.825194 916722 solver.cpp:218] Iteration 2273000 (16.8279 iter/s, 29.7125s/500 iters), loss = 0.038233
I0830 23:22:19.825256 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0382351 (* 1 = 0.0382351 loss)
I0830 23:22:19.825265 916722 sgd_solver.cpp:106] Iteration 2273000, lr = 0.01
I0830 23:22:49.534792 916722 solver.cpp:218] Iteration 2273500 (16.8297 iter/s, 29.7095s/500 iters), loss = 0.319536
I0830 23:22:49.534864 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.319538 (* 1 = 0.319538 loss)
I0830 23:22:49.534873 916722 sgd_solver.cpp:106] Iteration 2273500, lr = 0.01
I0830 23:23:19.248996 916722 solver.cpp:218] Iteration 2274000 (16.8271 iter/s, 29.7141s/500 iters), loss = 0.315722
I0830 23:23:19.249050 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.315723 (* 1 = 0.315723 loss)
I0830 23:23:19.249059 916722 sgd_solver.cpp:106] Iteration 2274000, lr = 0.01
I0830 23:23:48.965896 916722 solver.cpp:218] Iteration 2274500 (16.8255 iter/s, 29.7168s/500 iters), loss = 0.0979686
I0830 23:23:48.965955 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0979704 (* 1 = 0.0979704 loss)
I0830 23:23:48.965963 916722 sgd_solver.cpp:106] Iteration 2274500, lr = 0.01
I0830 23:24:18.679984 916722 solver.cpp:218] Iteration 2275000 (16.8271 iter/s, 29.7139s/500 iters), loss = 0.0267249
I0830 23:24:18.680038 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0267268 (* 1 = 0.0267268 loss)
I0830 23:24:18.680047 916722 sgd_solver.cpp:106] Iteration 2275000, lr = 0.01
I0830 23:24:48.395517 916722 solver.cpp:218] Iteration 2275500 (16.8263 iter/s, 29.7154s/500 iters), loss = 0.156666
I0830 23:24:48.395576 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.156668 (* 1 = 0.156668 loss)
I0830 23:24:48.395584 916722 sgd_solver.cpp:106] Iteration 2275500, lr = 0.01
I0830 23:25:18.109905 916722 solver.cpp:218] Iteration 2276000 (16.827 iter/s, 29.7142s/500 iters), loss = 0.187666
I0830 23:25:18.109959 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.187668 (* 1 = 0.187668 loss)
I0830 23:25:18.109970 916722 sgd_solver.cpp:106] Iteration 2276000, lr = 0.01
I0830 23:25:47.823247 916722 solver.cpp:218] Iteration 2276500 (16.8275 iter/s, 29.7132s/500 iters), loss = 0.0433501
I0830 23:25:47.823303 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.043352 (* 1 = 0.043352 loss)
I0830 23:25:47.823312 916722 sgd_solver.cpp:106] Iteration 2276500, lr = 0.01
I0830 23:26:17.534173 916722 solver.cpp:218] Iteration 2277000 (16.8289 iter/s, 29.7108s/500 iters), loss = 0.341823
I0830 23:26:17.534224 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.341825 (* 1 = 0.341825 loss)
I0830 23:26:17.534235 916722 sgd_solver.cpp:106] Iteration 2277000, lr = 0.01
I0830 23:26:47.240212 916722 solver.cpp:218] Iteration 2277500 (16.8317 iter/s, 29.7059s/500 iters), loss = 0.0942203
I0830 23:26:47.240272 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0942222 (* 1 = 0.0942222 loss)
I0830 23:26:47.240279 916722 sgd_solver.cpp:106] Iteration 2277500, lr = 0.01
I0830 23:27:16.952280 916722 solver.cpp:218] Iteration 2278000 (16.8283 iter/s, 29.7119s/500 iters), loss = 0.144914
I0830 23:27:16.952332 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.144916 (* 1 = 0.144916 loss)
I0830 23:27:16.952342 916722 sgd_solver.cpp:106] Iteration 2278000, lr = 0.01
I0830 23:27:46.661779 916722 solver.cpp:218] Iteration 2278500 (16.8297 iter/s, 29.7093s/500 iters), loss = 0.0725351
I0830 23:27:46.661839 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.072537 (* 1 = 0.072537 loss)
I0830 23:27:46.661846 916722 sgd_solver.cpp:106] Iteration 2278500, lr = 0.01
I0830 23:28:16.375255 916722 solver.cpp:218] Iteration 2279000 (16.8275 iter/s, 29.7133s/500 iters), loss = 0.0521162
I0830 23:28:16.375310 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0521181 (* 1 = 0.0521181 loss)
I0830 23:28:16.375320 916722 sgd_solver.cpp:106] Iteration 2279000, lr = 0.01
I0830 23:28:46.087146 916722 solver.cpp:218] Iteration 2279500 (16.8284 iter/s, 29.7117s/500 iters), loss = 0.106946
I0830 23:28:46.087220 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.106948 (* 1 = 0.106948 loss)
I0830 23:28:46.087229 916722 sgd_solver.cpp:106] Iteration 2279500, lr = 0.01
I0830 23:29:15.795588 916722 solver.cpp:218] Iteration 2280000 (16.8303 iter/s, 29.7083s/500 iters), loss = 0.32346
I0830 23:29:15.795642 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.323462 (* 1 = 0.323462 loss)
I0830 23:29:15.795651 916722 sgd_solver.cpp:106] Iteration 2280000, lr = 0.01
I0830 23:29:45.506976 916722 solver.cpp:218] Iteration 2280500 (16.8287 iter/s, 29.7112s/500 iters), loss = 0.0972579
I0830 23:29:45.507033 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0972598 (* 1 = 0.0972598 loss)
I0830 23:29:45.507042 916722 sgd_solver.cpp:106] Iteration 2280500, lr = 0.01
I0830 23:30:15.221801 916722 solver.cpp:218] Iteration 2281000 (16.8267 iter/s, 29.7147s/500 iters), loss = 0.134257
I0830 23:30:15.221851 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.134259 (* 1 = 0.134259 loss)
I0830 23:30:15.221861 916722 sgd_solver.cpp:106] Iteration 2281000, lr = 0.01
I0830 23:30:44.937058 916722 solver.cpp:218] Iteration 2281500 (16.8265 iter/s, 29.7151s/500 iters), loss = 0.0703621
I0830 23:30:44.937115 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0703639 (* 1 = 0.0703639 loss)
I0830 23:30:44.937124 916722 sgd_solver.cpp:106] Iteration 2281500, lr = 0.01
I0830 23:31:14.649622 916722 solver.cpp:218] Iteration 2282000 (16.828 iter/s, 29.7124s/500 iters), loss = 0.299943
I0830 23:31:14.649672 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.299945 (* 1 = 0.299945 loss)
I0830 23:31:14.649682 916722 sgd_solver.cpp:106] Iteration 2282000, lr = 0.01
I0830 23:31:44.360517 916722 solver.cpp:218] Iteration 2282500 (16.8289 iter/s, 29.7107s/500 iters), loss = 0.128799
I0830 23:31:44.360581 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128801 (* 1 = 0.128801 loss)
I0830 23:31:44.360589 916722 sgd_solver.cpp:106] Iteration 2282500, lr = 0.01
I0830 23:32:14.072885 916722 solver.cpp:218] Iteration 2283000 (16.8281 iter/s, 29.7122s/500 iters), loss = 0.199901
I0830 23:32:14.072934 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.199903 (* 1 = 0.199903 loss)
I0830 23:32:14.072943 916722 sgd_solver.cpp:106] Iteration 2283000, lr = 0.01
I0830 23:32:43.793614 916722 solver.cpp:218] Iteration 2283500 (16.8234 iter/s, 29.7205s/500 iters), loss = 0.0518961
I0830 23:32:43.793678 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0518979 (* 1 = 0.0518979 loss)
I0830 23:32:43.793686 916722 sgd_solver.cpp:106] Iteration 2283500, lr = 0.01
I0830 23:33:13.502965 916722 solver.cpp:218] Iteration 2284000 (16.8298 iter/s, 29.7092s/500 iters), loss = 0.0472587
I0830 23:33:13.503021 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0472606 (* 1 = 0.0472606 loss)
I0830 23:33:13.503031 916722 sgd_solver.cpp:106] Iteration 2284000, lr = 0.01
I0830 23:33:43.208364 916722 solver.cpp:218] Iteration 2284500 (16.8321 iter/s, 29.7052s/500 iters), loss = 0.214505
I0830 23:33:43.208428 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.214507 (* 1 = 0.214507 loss)
I0830 23:33:43.208437 916722 sgd_solver.cpp:106] Iteration 2284500, lr = 0.01
I0830 23:34:12.917659 916722 solver.cpp:218] Iteration 2285000 (16.8299 iter/s, 29.7091s/500 iters), loss = 0.052506
I0830 23:34:12.917713 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0525079 (* 1 = 0.0525079 loss)
I0830 23:34:12.917723 916722 sgd_solver.cpp:106] Iteration 2285000, lr = 0.01
I0830 23:34:42.625816 916722 solver.cpp:218] Iteration 2285500 (16.8305 iter/s, 29.708s/500 iters), loss = 0.057334
I0830 23:34:42.625874 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0573358 (* 1 = 0.0573358 loss)
I0830 23:34:42.625883 916722 sgd_solver.cpp:106] Iteration 2285500, lr = 0.01
I0830 23:35:12.334062 916722 solver.cpp:218] Iteration 2286000 (16.8305 iter/s, 29.7081s/500 iters), loss = 0.0806948
I0830 23:35:12.334125 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0806967 (* 1 = 0.0806967 loss)
I0830 23:35:12.334136 916722 sgd_solver.cpp:106] Iteration 2286000, lr = 0.01
I0830 23:35:42.040453 916722 solver.cpp:218] Iteration 2286500 (16.8315 iter/s, 29.7062s/500 iters), loss = 0.104179
I0830 23:35:42.040524 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104181 (* 1 = 0.104181 loss)
I0830 23:35:42.040532 916722 sgd_solver.cpp:106] Iteration 2286500, lr = 0.01
I0830 23:36:11.749222 916722 solver.cpp:218] Iteration 2287000 (16.8302 iter/s, 29.7086s/500 iters), loss = 0.298296
I0830 23:36:11.749275 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.298298 (* 1 = 0.298298 loss)
I0830 23:36:11.749285 916722 sgd_solver.cpp:106] Iteration 2287000, lr = 0.01
I0830 23:36:41.460944 916722 solver.cpp:218] Iteration 2287500 (16.8285 iter/s, 29.7115s/500 iters), loss = 0.296684
I0830 23:36:41.461007 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.296686 (* 1 = 0.296686 loss)
I0830 23:36:41.461015 916722 sgd_solver.cpp:106] Iteration 2287500, lr = 0.01
I0830 23:37:11.166172 916722 solver.cpp:218] Iteration 2288000 (16.8322 iter/s, 29.705s/500 iters), loss = 0.0785691
I0830 23:37:11.166225 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0785711 (* 1 = 0.0785711 loss)
I0830 23:37:11.166234 916722 sgd_solver.cpp:106] Iteration 2288000, lr = 0.01
I0830 23:37:40.873153 916722 solver.cpp:218] Iteration 2288500 (16.8312 iter/s, 29.7068s/500 iters), loss = 0.0186874
I0830 23:37:40.873215 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0186895 (* 1 = 0.0186895 loss)
I0830 23:37:40.873224 916722 sgd_solver.cpp:106] Iteration 2288500, lr = 0.01
I0830 23:38:10.579154 916722 solver.cpp:218] Iteration 2289000 (16.8317 iter/s, 29.7058s/500 iters), loss = 0.424297
I0830 23:38:10.579205 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.424299 (* 1 = 0.424299 loss)
I0830 23:38:10.579214 916722 sgd_solver.cpp:106] Iteration 2289000, lr = 0.01
I0830 23:38:40.285090 916722 solver.cpp:218] Iteration 2289500 (16.8318 iter/s, 29.7057s/500 iters), loss = 0.0676737
I0830 23:38:40.285148 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0676759 (* 1 = 0.0676759 loss)
I0830 23:38:40.285156 916722 sgd_solver.cpp:106] Iteration 2289500, lr = 0.01
I0830 23:39:09.990279 916722 solver.cpp:218] Iteration 2290000 (16.8322 iter/s, 29.705s/500 iters), loss = 0.0863788
I0830 23:39:09.990330 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0863809 (* 1 = 0.0863809 loss)
I0830 23:39:09.990339 916722 sgd_solver.cpp:106] Iteration 2290000, lr = 0.01
I0830 23:39:39.698506 916722 solver.cpp:218] Iteration 2290500 (16.8305 iter/s, 29.708s/500 iters), loss = 0.11823
I0830 23:39:39.698565 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.118232 (* 1 = 0.118232 loss)
I0830 23:39:39.698572 916722 sgd_solver.cpp:106] Iteration 2290500, lr = 0.01
I0830 23:40:09.407308 916722 solver.cpp:218] Iteration 2291000 (16.8301 iter/s, 29.7086s/500 iters), loss = 0.0675016
I0830 23:40:09.407361 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0675041 (* 1 = 0.0675041 loss)
I0830 23:40:09.407369 916722 sgd_solver.cpp:106] Iteration 2291000, lr = 0.01
I0830 23:40:39.116977 916722 solver.cpp:218] Iteration 2291500 (16.8296 iter/s, 29.7095s/500 iters), loss = 0.0908089
I0830 23:40:39.117038 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0908114 (* 1 = 0.0908114 loss)
I0830 23:40:39.117046 916722 sgd_solver.cpp:106] Iteration 2291500, lr = 0.01
I0830 23:41:08.827500 916722 solver.cpp:218] Iteration 2292000 (16.8292 iter/s, 29.7103s/500 iters), loss = 0.225616
I0830 23:41:08.827551 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.225619 (* 1 = 0.225619 loss)
I0830 23:41:08.827560 916722 sgd_solver.cpp:106] Iteration 2292000, lr = 0.01
I0830 23:41:38.534866 916722 solver.cpp:218] Iteration 2292500 (16.8309 iter/s, 29.7072s/500 iters), loss = 0.0829379
I0830 23:41:38.534941 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0829404 (* 1 = 0.0829404 loss)
I0830 23:41:38.534955 916722 sgd_solver.cpp:106] Iteration 2292500, lr = 0.01
I0830 23:42:08.242734 916722 solver.cpp:218] Iteration 2293000 (16.8307 iter/s, 29.7076s/500 iters), loss = 0.106501
I0830 23:42:08.242789 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.106503 (* 1 = 0.106503 loss)
I0830 23:42:08.242799 916722 sgd_solver.cpp:106] Iteration 2293000, lr = 0.01
I0830 23:42:37.950987 916722 solver.cpp:218] Iteration 2293500 (16.8305 iter/s, 29.7081s/500 iters), loss = 0.0461906
I0830 23:42:37.951046 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0461931 (* 1 = 0.0461931 loss)
I0830 23:42:37.951054 916722 sgd_solver.cpp:106] Iteration 2293500, lr = 0.01
I0830 23:43:07.657860 916722 solver.cpp:218] Iteration 2294000 (16.8312 iter/s, 29.7067s/500 iters), loss = 0.178632
I0830 23:43:07.657912 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.178634 (* 1 = 0.178634 loss)
I0830 23:43:07.657922 916722 sgd_solver.cpp:106] Iteration 2294000, lr = 0.01
I0830 23:43:37.367547 916722 solver.cpp:218] Iteration 2294500 (16.8296 iter/s, 29.7095s/500 iters), loss = 0.07375
I0830 23:43:37.367612 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0737525 (* 1 = 0.0737525 loss)
I0830 23:43:37.367621 916722 sgd_solver.cpp:106] Iteration 2294500, lr = 0.01
I0830 23:44:07.073937 916722 solver.cpp:218] Iteration 2295000 (16.8315 iter/s, 29.7062s/500 iters), loss = 0.288703
I0830 23:44:07.073987 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.288706 (* 1 = 0.288706 loss)
I0830 23:44:07.073997 916722 sgd_solver.cpp:106] Iteration 2295000, lr = 0.01
I0830 23:44:36.781002 916722 solver.cpp:218] Iteration 2295500 (16.8311 iter/s, 29.7069s/500 iters), loss = 0.227869
I0830 23:44:36.781059 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.227871 (* 1 = 0.227871 loss)
I0830 23:44:36.781069 916722 sgd_solver.cpp:106] Iteration 2295500, lr = 0.01
I0830 23:45:06.489539 916722 solver.cpp:218] Iteration 2296000 (16.8303 iter/s, 29.7083s/500 iters), loss = 0.0642557
I0830 23:45:06.489590 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0642581 (* 1 = 0.0642581 loss)
I0830 23:45:06.489600 916722 sgd_solver.cpp:106] Iteration 2296000, lr = 0.01
I0830 23:45:36.201368 916722 solver.cpp:218] Iteration 2296500 (16.8284 iter/s, 29.7116s/500 iters), loss = 0.131568
I0830 23:45:36.201426 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13157 (* 1 = 0.13157 loss)
I0830 23:45:36.201433 916722 sgd_solver.cpp:106] Iteration 2296500, lr = 0.01
I0830 23:46:05.909909 916722 solver.cpp:218] Iteration 2297000 (16.8303 iter/s, 29.7083s/500 iters), loss = 0.182254
I0830 23:46:05.909960 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.182256 (* 1 = 0.182256 loss)
I0830 23:46:05.909970 916722 sgd_solver.cpp:106] Iteration 2297000, lr = 0.01
I0830 23:46:35.608124 916722 solver.cpp:218] Iteration 2297500 (16.8361 iter/s, 29.698s/500 iters), loss = 0.0220419
I0830 23:46:35.608181 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0220443 (* 1 = 0.0220443 loss)
I0830 23:46:35.608189 916722 sgd_solver.cpp:106] Iteration 2297500, lr = 0.01
I0830 23:47:05.308508 916722 solver.cpp:218] Iteration 2298000 (16.8349 iter/s, 29.7002s/500 iters), loss = 0.039012
I0830 23:47:05.308560 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0390142 (* 1 = 0.0390142 loss)
I0830 23:47:05.308571 916722 sgd_solver.cpp:106] Iteration 2298000, lr = 0.01
I0830 23:47:35.002655 916722 solver.cpp:218] Iteration 2298500 (16.8384 iter/s, 29.6939s/500 iters), loss = 0.226546
I0830 23:47:35.002717 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.226549 (* 1 = 0.226549 loss)
I0830 23:47:35.002725 916722 sgd_solver.cpp:106] Iteration 2298500, lr = 0.01
I0830 23:48:04.698086 916722 solver.cpp:218] Iteration 2299000 (16.8377 iter/s, 29.6952s/500 iters), loss = 0.100381
I0830 23:48:04.698130 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.100383 (* 1 = 0.100383 loss)
I0830 23:48:04.698150 916722 sgd_solver.cpp:106] Iteration 2299000, lr = 0.01
I0830 23:48:34.393920 916722 solver.cpp:218] Iteration 2299500 (16.8375 iter/s, 29.6956s/500 iters), loss = 0.0322612
I0830 23:48:34.393983 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0322637 (* 1 = 0.0322637 loss)
I0830 23:48:34.393991 916722 sgd_solver.cpp:106] Iteration 2299500, lr = 0.01
I0830 23:49:04.033577 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_2300000.caffemodel
I0830 23:49:04.053040 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_2300000.solverstate
I0830 23:49:04.059208 916722 solver.cpp:330] Iteration 2300000, Testing net (#0)
I0830 23:49:19.356529 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8941
I0830 23:49:19.356590 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.346028 (* 1 = 0.346028 loss)
I0830 23:49:19.415160 916722 solver.cpp:218] Iteration 2300000 (11.1058 iter/s, 45.0215s/500 iters), loss = 0.127455
I0830 23:49:19.415189 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.127458 (* 1 = 0.127458 loss)
I0830 23:49:19.415196 916722 sgd_solver.cpp:106] Iteration 2300000, lr = 0.01
I0830 23:49:49.003665 916722 solver.cpp:218] Iteration 2300500 (16.8983 iter/s, 29.5888s/500 iters), loss = 0.17622
I0830 23:49:49.003715 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.176222 (* 1 = 0.176222 loss)
I0830 23:49:49.003723 916722 sgd_solver.cpp:106] Iteration 2300500, lr = 0.01
I0830 23:50:18.648885 916722 solver.cpp:218] Iteration 2301000 (16.866 iter/s, 29.6455s/500 iters), loss = 0.0226449
I0830 23:50:18.648942 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.022647 (* 1 = 0.022647 loss)
I0830 23:50:18.648950 916722 sgd_solver.cpp:106] Iteration 2301000, lr = 0.01
I0830 23:50:48.340871 916722 solver.cpp:218] Iteration 2301500 (16.8394 iter/s, 29.6922s/500 iters), loss = 0.261643
I0830 23:50:48.340924 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.261645 (* 1 = 0.261645 loss)
I0830 23:50:48.340934 916722 sgd_solver.cpp:106] Iteration 2301500, lr = 0.01
I0830 23:51:18.037855 916722 solver.cpp:218] Iteration 2302000 (16.8366 iter/s, 29.6972s/500 iters), loss = 0.192233
I0830 23:51:18.037914 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.192236 (* 1 = 0.192236 loss)
I0830 23:51:18.037921 916722 sgd_solver.cpp:106] Iteration 2302000, lr = 0.01
I0830 23:51:47.729231 916722 solver.cpp:218] Iteration 2302500 (16.8398 iter/s, 29.6916s/500 iters), loss = 0.254733
I0830 23:51:47.729285 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.254735 (* 1 = 0.254735 loss)
I0830 23:51:47.729295 916722 sgd_solver.cpp:106] Iteration 2302500, lr = 0.01
I0830 23:52:17.420759 916722 solver.cpp:218] Iteration 2303000 (16.8397 iter/s, 29.6917s/500 iters), loss = 0.104033
I0830 23:52:17.420819 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104035 (* 1 = 0.104035 loss)
I0830 23:52:17.420826 916722 sgd_solver.cpp:106] Iteration 2303000, lr = 0.01
I0830 23:52:47.115394 916722 solver.cpp:218] Iteration 2303500 (16.838 iter/s, 29.6948s/500 iters), loss = 0.024766
I0830 23:52:47.115449 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0247681 (* 1 = 0.0247681 loss)
I0830 23:52:47.115459 916722 sgd_solver.cpp:106] Iteration 2303500, lr = 0.01
I0830 23:53:16.812846 916722 solver.cpp:218] Iteration 2304000 (16.8364 iter/s, 29.6976s/500 iters), loss = 0.162771
I0830 23:53:16.812908 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.162773 (* 1 = 0.162773 loss)
I0830 23:53:16.812917 916722 sgd_solver.cpp:106] Iteration 2304000, lr = 0.01
I0830 23:53:46.504984 916722 solver.cpp:218] Iteration 2304500 (16.8394 iter/s, 29.6923s/500 iters), loss = 0.0234427
I0830 23:53:46.505033 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0234448 (* 1 = 0.0234448 loss)
I0830 23:53:46.505041 916722 sgd_solver.cpp:106] Iteration 2304500, lr = 0.01
I0830 23:54:16.196113 916722 solver.cpp:218] Iteration 2305000 (16.84 iter/s, 29.6913s/500 iters), loss = 0.289441
I0830 23:54:16.196183 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.289443 (* 1 = 0.289443 loss)
I0830 23:54:16.196192 916722 sgd_solver.cpp:106] Iteration 2305000, lr = 0.01
I0830 23:54:45.896522 916722 solver.cpp:218] Iteration 2305500 (16.8347 iter/s, 29.7005s/500 iters), loss = 0.639597
I0830 23:54:45.896574 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.6396 (* 1 = 0.6396 loss)
I0830 23:54:45.896584 916722 sgd_solver.cpp:106] Iteration 2305500, lr = 0.01
I0830 23:55:15.593659 916722 solver.cpp:218] Iteration 2306000 (16.8366 iter/s, 29.6972s/500 iters), loss = 0.100673
I0830 23:55:15.593719 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.100675 (* 1 = 0.100675 loss)
I0830 23:55:15.593726 916722 sgd_solver.cpp:106] Iteration 2306000, lr = 0.01
I0830 23:55:45.291246 916722 solver.cpp:218] Iteration 2306500 (16.8363 iter/s, 29.6977s/500 iters), loss = 0.180012
I0830 23:55:45.291301 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.180014 (* 1 = 0.180014 loss)
I0830 23:55:45.291311 916722 sgd_solver.cpp:106] Iteration 2306500, lr = 0.01
I0830 23:56:14.988088 916722 solver.cpp:218] Iteration 2307000 (16.8368 iter/s, 29.6969s/500 iters), loss = 0.0417216
I0830 23:56:14.988152 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0417242 (* 1 = 0.0417242 loss)
I0830 23:56:14.988159 916722 sgd_solver.cpp:106] Iteration 2307000, lr = 0.01
I0830 23:56:44.684214 916722 solver.cpp:218] Iteration 2307500 (16.8372 iter/s, 29.6962s/500 iters), loss = 0.186893
I0830 23:56:44.684265 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.186896 (* 1 = 0.186896 loss)
I0830 23:56:44.684274 916722 sgd_solver.cpp:106] Iteration 2307500, lr = 0.01
I0830 23:57:14.383345 916722 solver.cpp:218] Iteration 2308000 (16.8355 iter/s, 29.6992s/500 iters), loss = 0.210884
I0830 23:57:14.383401 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.210887 (* 1 = 0.210887 loss)
I0830 23:57:14.383409 916722 sgd_solver.cpp:106] Iteration 2308000, lr = 0.01
I0830 23:57:44.086609 916722 solver.cpp:218] Iteration 2308500 (16.8331 iter/s, 29.7033s/500 iters), loss = 0.204249
I0830 23:57:44.086663 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.204251 (* 1 = 0.204251 loss)
I0830 23:57:44.086671 916722 sgd_solver.cpp:106] Iteration 2308500, lr = 0.01
I0830 23:58:13.793422 916722 solver.cpp:218] Iteration 2309000 (16.8311 iter/s, 29.7068s/500 iters), loss = 0.212226
I0830 23:58:13.793483 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.212229 (* 1 = 0.212229 loss)
I0830 23:58:13.793490 916722 sgd_solver.cpp:106] Iteration 2309000, lr = 0.01
I0830 23:58:43.499001 916722 solver.cpp:218] Iteration 2309500 (16.8319 iter/s, 29.7056s/500 iters), loss = 0.0379891
I0830 23:58:43.499055 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0379918 (* 1 = 0.0379918 loss)
I0830 23:58:43.499063 916722 sgd_solver.cpp:106] Iteration 2309500, lr = 0.01
I0830 23:59:13.207393 916722 solver.cpp:218] Iteration 2310000 (16.8303 iter/s, 29.7084s/500 iters), loss = 0.106871
I0830 23:59:13.207453 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.106874 (* 1 = 0.106874 loss)
I0830 23:59:13.207461 916722 sgd_solver.cpp:106] Iteration 2310000, lr = 0.01
I0830 23:59:42.910980 916722 solver.cpp:218] Iteration 2310500 (16.833 iter/s, 29.7036s/500 iters), loss = 0.156219
I0830 23:59:42.911032 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.156222 (* 1 = 0.156222 loss)
I0830 23:59:42.911041 916722 sgd_solver.cpp:106] Iteration 2310500, lr = 0.01
I0831 00:00:12.605944 916722 solver.cpp:218] Iteration 2311000 (16.8379 iter/s, 29.695s/500 iters), loss = 0.184471
I0831 00:00:12.606002 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.184474 (* 1 = 0.184474 loss)
I0831 00:00:12.606010 916722 sgd_solver.cpp:106] Iteration 2311000, lr = 0.01
I0831 00:00:42.304132 916722 solver.cpp:218] Iteration 2311500 (16.8361 iter/s, 29.6982s/500 iters), loss = 0.162352
I0831 00:00:42.304194 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.162355 (* 1 = 0.162355 loss)
I0831 00:00:42.304203 916722 sgd_solver.cpp:106] Iteration 2311500, lr = 0.01
I0831 00:01:12.001411 916722 solver.cpp:218] Iteration 2312000 (16.8366 iter/s, 29.6973s/500 iters), loss = 0.0842226
I0831 00:01:12.001479 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0842253 (* 1 = 0.0842253 loss)
I0831 00:01:12.001487 916722 sgd_solver.cpp:106] Iteration 2312000, lr = 0.01
I0831 00:01:41.692591 916722 solver.cpp:218] Iteration 2312500 (16.84 iter/s, 29.6911s/500 iters), loss = 0.0174855
I0831 00:01:41.692646 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0174883 (* 1 = 0.0174883 loss)
I0831 00:01:41.692656 916722 sgd_solver.cpp:106] Iteration 2312500, lr = 0.01
I0831 00:02:11.387555 916722 solver.cpp:218] Iteration 2313000 (16.8379 iter/s, 29.6949s/500 iters), loss = 0.0381708
I0831 00:02:11.387612 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0381736 (* 1 = 0.0381736 loss)
I0831 00:02:11.387620 916722 sgd_solver.cpp:106] Iteration 2313000, lr = 0.01
I0831 00:02:41.081817 916722 solver.cpp:218] Iteration 2313500 (16.8383 iter/s, 29.6942s/500 iters), loss = 0.118121
I0831 00:02:41.081871 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.118123 (* 1 = 0.118123 loss)
I0831 00:02:41.081880 916722 sgd_solver.cpp:106] Iteration 2313500, lr = 0.01
I0831 00:03:10.776772 916722 solver.cpp:218] Iteration 2314000 (16.8379 iter/s, 29.6949s/500 iters), loss = 0.0341292
I0831 00:03:10.776830 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.034132 (* 1 = 0.034132 loss)
I0831 00:03:10.776839 916722 sgd_solver.cpp:106] Iteration 2314000, lr = 0.01
I0831 00:03:40.473495 916722 solver.cpp:218] Iteration 2314500 (16.8369 iter/s, 29.6967s/500 iters), loss = 0.1714
I0831 00:03:40.473546 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.171403 (* 1 = 0.171403 loss)
I0831 00:03:40.473556 916722 sgd_solver.cpp:106] Iteration 2314500, lr = 0.01
I0831 00:04:10.170516 916722 solver.cpp:218] Iteration 2315000 (16.8367 iter/s, 29.697s/500 iters), loss = 0.0869399
I0831 00:04:10.170575 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0869429 (* 1 = 0.0869429 loss)
I0831 00:04:10.170584 916722 sgd_solver.cpp:106] Iteration 2315000, lr = 0.01
I0831 00:04:39.865561 916722 solver.cpp:218] Iteration 2315500 (16.8379 iter/s, 29.695s/500 iters), loss = 0.0921378
I0831 00:04:39.865613 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0921407 (* 1 = 0.0921407 loss)
I0831 00:04:39.865623 916722 sgd_solver.cpp:106] Iteration 2315500, lr = 0.01
I0831 00:05:09.565517 916722 solver.cpp:218] Iteration 2316000 (16.8351 iter/s, 29.6999s/500 iters), loss = 0.169204
I0831 00:05:09.565575 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.169207 (* 1 = 0.169207 loss)
I0831 00:05:09.565583 916722 sgd_solver.cpp:106] Iteration 2316000, lr = 0.01
I0831 00:05:39.259757 916722 solver.cpp:218] Iteration 2316500 (16.8383 iter/s, 29.6942s/500 iters), loss = 0.204113
I0831 00:05:39.259807 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.204116 (* 1 = 0.204116 loss)
I0831 00:05:39.259817 916722 sgd_solver.cpp:106] Iteration 2316500, lr = 0.01
I0831 00:06:08.953923 916722 solver.cpp:218] Iteration 2317000 (16.8384 iter/s, 29.6941s/500 iters), loss = 0.301715
I0831 00:06:08.953985 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.301718 (* 1 = 0.301718 loss)
I0831 00:06:08.953994 916722 sgd_solver.cpp:106] Iteration 2317000, lr = 0.01
I0831 00:06:38.644001 916722 solver.cpp:218] Iteration 2317500 (16.8407 iter/s, 29.69s/500 iters), loss = 0.146347
I0831 00:06:38.644055 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.14635 (* 1 = 0.14635 loss)
I0831 00:06:38.644064 916722 sgd_solver.cpp:106] Iteration 2317500, lr = 0.01
I0831 00:07:08.334690 916722 solver.cpp:218] Iteration 2318000 (16.8403 iter/s, 29.6906s/500 iters), loss = 0.24054
I0831 00:07:08.334764 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.240543 (* 1 = 0.240543 loss)
I0831 00:07:08.334774 916722 sgd_solver.cpp:106] Iteration 2318000, lr = 0.01
I0831 00:07:38.030217 916722 solver.cpp:218] Iteration 2318500 (16.8376 iter/s, 29.6954s/500 iters), loss = 0.18422
I0831 00:07:38.030268 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.184223 (* 1 = 0.184223 loss)
I0831 00:07:38.030277 916722 sgd_solver.cpp:106] Iteration 2318500, lr = 0.01
I0831 00:08:07.727253 916722 solver.cpp:218] Iteration 2319000 (16.8367 iter/s, 29.697s/500 iters), loss = 0.0943728
I0831 00:08:07.727311 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0943759 (* 1 = 0.0943759 loss)
I0831 00:08:07.727320 916722 sgd_solver.cpp:106] Iteration 2319000, lr = 0.01
I0831 00:08:37.424598 916722 solver.cpp:218] Iteration 2319500 (16.8366 iter/s, 29.6972s/500 iters), loss = 0.112691
I0831 00:08:37.424652 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112694 (* 1 = 0.112694 loss)
I0831 00:08:37.424661 916722 sgd_solver.cpp:106] Iteration 2319500, lr = 0.01
I0831 00:09:07.119371 916722 solver.cpp:218] Iteration 2320000 (16.838 iter/s, 29.6947s/500 iters), loss = 0.148778
I0831 00:09:07.119429 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.148781 (* 1 = 0.148781 loss)
I0831 00:09:07.119438 916722 sgd_solver.cpp:106] Iteration 2320000, lr = 0.01
I0831 00:09:36.814308 916722 solver.cpp:218] Iteration 2320500 (16.8379 iter/s, 29.6948s/500 iters), loss = 0.125329
I0831 00:09:36.814361 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.125332 (* 1 = 0.125332 loss)
I0831 00:09:36.814370 916722 sgd_solver.cpp:106] Iteration 2320500, lr = 0.01
I0831 00:10:06.509145 916722 solver.cpp:218] Iteration 2321000 (16.838 iter/s, 29.6947s/500 iters), loss = 0.0731744
I0831 00:10:06.509205 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0731776 (* 1 = 0.0731776 loss)
I0831 00:10:06.509213 916722 sgd_solver.cpp:106] Iteration 2321000, lr = 0.01
I0831 00:10:36.202802 916722 solver.cpp:218] Iteration 2321500 (16.8387 iter/s, 29.6935s/500 iters), loss = 0.183761
I0831 00:10:36.202854 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.183764 (* 1 = 0.183764 loss)
I0831 00:10:36.202863 916722 sgd_solver.cpp:106] Iteration 2321500, lr = 0.01
I0831 00:11:05.895190 916722 solver.cpp:218] Iteration 2322000 (16.8394 iter/s, 29.6923s/500 iters), loss = 0.110044
I0831 00:11:05.895251 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110047 (* 1 = 0.110047 loss)
I0831 00:11:05.895258 916722 sgd_solver.cpp:106] Iteration 2322000, lr = 0.01
I0831 00:11:35.588658 916722 solver.cpp:218] Iteration 2322500 (16.8388 iter/s, 29.6934s/500 iters), loss = 0.152923
I0831 00:11:35.588711 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152926 (* 1 = 0.152926 loss)
I0831 00:11:35.588718 916722 sgd_solver.cpp:106] Iteration 2322500, lr = 0.01
I0831 00:12:05.280973 916722 solver.cpp:218] Iteration 2323000 (16.8394 iter/s, 29.6922s/500 iters), loss = 0.190759
I0831 00:12:05.281031 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.190763 (* 1 = 0.190763 loss)
I0831 00:12:05.281039 916722 sgd_solver.cpp:106] Iteration 2323000, lr = 0.01
I0831 00:12:34.973168 916722 solver.cpp:218] Iteration 2323500 (16.8395 iter/s, 29.6921s/500 iters), loss = 0.22664
I0831 00:12:34.973220 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.226643 (* 1 = 0.226643 loss)
I0831 00:12:34.973228 916722 sgd_solver.cpp:106] Iteration 2323500, lr = 0.01
I0831 00:13:04.674365 916722 solver.cpp:218] Iteration 2324000 (16.8344 iter/s, 29.7011s/500 iters), loss = 0.0800536
I0831 00:13:04.674422 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0800566 (* 1 = 0.0800566 loss)
I0831 00:13:04.674429 916722 sgd_solver.cpp:106] Iteration 2324000, lr = 0.01
I0831 00:13:34.367259 916722 solver.cpp:218] Iteration 2324500 (16.8391 iter/s, 29.6928s/500 iters), loss = 0.0695358
I0831 00:13:34.367309 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0695388 (* 1 = 0.0695388 loss)
I0831 00:13:34.367329 916722 sgd_solver.cpp:106] Iteration 2324500, lr = 0.01
I0831 00:14:04.065630 916722 solver.cpp:218] Iteration 2325000 (16.836 iter/s, 29.6983s/500 iters), loss = 0.0661133
I0831 00:14:04.065706 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0661162 (* 1 = 0.0661162 loss)
I0831 00:14:04.065713 916722 sgd_solver.cpp:106] Iteration 2325000, lr = 0.01
I0831 00:14:33.761252 916722 solver.cpp:218] Iteration 2325500 (16.8376 iter/s, 29.6955s/500 iters), loss = 0.403884
I0831 00:14:33.761307 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.403887 (* 1 = 0.403887 loss)
I0831 00:14:33.761317 916722 sgd_solver.cpp:106] Iteration 2325500, lr = 0.01
I0831 00:15:03.454082 916722 solver.cpp:218] Iteration 2326000 (16.8391 iter/s, 29.6927s/500 iters), loss = 0.304542
I0831 00:15:03.454135 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.304545 (* 1 = 0.304545 loss)
I0831 00:15:03.454144 916722 sgd_solver.cpp:106] Iteration 2326000, lr = 0.01
I0831 00:15:33.151832 916722 solver.cpp:218] Iteration 2326500 (16.8364 iter/s, 29.6976s/500 iters), loss = 0.149132
I0831 00:15:33.151888 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.149135 (* 1 = 0.149135 loss)
I0831 00:15:33.151898 916722 sgd_solver.cpp:106] Iteration 2326500, lr = 0.01
I0831 00:16:02.848691 916722 solver.cpp:218] Iteration 2327000 (16.8369 iter/s, 29.6967s/500 iters), loss = 0.100495
I0831 00:16:02.848759 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.100498 (* 1 = 0.100498 loss)
I0831 00:16:02.848767 916722 sgd_solver.cpp:106] Iteration 2327000, lr = 0.01
I0831 00:16:32.544864 916722 solver.cpp:218] Iteration 2327500 (16.8373 iter/s, 29.696s/500 iters), loss = 0.135806
I0831 00:16:32.544915 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.135809 (* 1 = 0.135809 loss)
I0831 00:16:32.544925 916722 sgd_solver.cpp:106] Iteration 2327500, lr = 0.01
I0831 00:17:02.241240 916722 solver.cpp:218] Iteration 2328000 (16.8371 iter/s, 29.6963s/500 iters), loss = 0.107922
I0831 00:17:02.241297 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.107925 (* 1 = 0.107925 loss)
I0831 00:17:02.241304 916722 sgd_solver.cpp:106] Iteration 2328000, lr = 0.01
I0831 00:17:31.938566 916722 solver.cpp:218] Iteration 2328500 (16.8366 iter/s, 29.6972s/500 iters), loss = 0.167162
I0831 00:17:31.938619 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.167165 (* 1 = 0.167165 loss)
I0831 00:17:31.938629 916722 sgd_solver.cpp:106] Iteration 2328500, lr = 0.01
I0831 00:18:01.635519 916722 solver.cpp:218] Iteration 2329000 (16.8368 iter/s, 29.6968s/500 iters), loss = 0.0793783
I0831 00:18:01.635574 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0793811 (* 1 = 0.0793811 loss)
I0831 00:18:01.635583 916722 sgd_solver.cpp:106] Iteration 2329000, lr = 0.01
I0831 00:18:31.331229 916722 solver.cpp:218] Iteration 2329500 (16.8375 iter/s, 29.6956s/500 iters), loss = 0.184923
I0831 00:18:31.331280 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.184926 (* 1 = 0.184926 loss)
I0831 00:18:31.331291 916722 sgd_solver.cpp:106] Iteration 2329500, lr = 0.01
I0831 00:19:01.024116 916722 solver.cpp:218] Iteration 2330000 (16.8391 iter/s, 29.6928s/500 iters), loss = 0.0523689
I0831 00:19:01.024171 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0523717 (* 1 = 0.0523717 loss)
I0831 00:19:01.024179 916722 sgd_solver.cpp:106] Iteration 2330000, lr = 0.01
I0831 00:19:30.719705 916722 solver.cpp:218] Iteration 2330500 (16.8376 iter/s, 29.6955s/500 iters), loss = 0.133603
I0831 00:19:30.719758 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133605 (* 1 = 0.133605 loss)
I0831 00:19:30.719767 916722 sgd_solver.cpp:106] Iteration 2330500, lr = 0.01
I0831 00:20:00.414052 916722 solver.cpp:218] Iteration 2331000 (16.8383 iter/s, 29.6942s/500 iters), loss = 0.374325
I0831 00:20:00.414121 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.374327 (* 1 = 0.374327 loss)
I0831 00:20:00.414146 916722 sgd_solver.cpp:106] Iteration 2331000, lr = 0.01
I0831 00:20:30.109431 916722 solver.cpp:218] Iteration 2331500 (16.8377 iter/s, 29.6952s/500 iters), loss = 0.0670257
I0831 00:20:30.109483 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0670284 (* 1 = 0.0670284 loss)
I0831 00:20:30.109491 916722 sgd_solver.cpp:106] Iteration 2331500, lr = 0.01
I0831 00:20:59.801995 916722 solver.cpp:218] Iteration 2332000 (16.8393 iter/s, 29.6924s/500 iters), loss = 0.0698562
I0831 00:20:59.802054 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.069859 (* 1 = 0.069859 loss)
I0831 00:20:59.802062 916722 sgd_solver.cpp:106] Iteration 2332000, lr = 0.01
I0831 00:21:29.497211 916722 solver.cpp:218] Iteration 2332500 (16.8378 iter/s, 29.6951s/500 iters), loss = 0.330998
I0831 00:21:29.497265 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.331001 (* 1 = 0.331001 loss)
I0831 00:21:29.497274 916722 sgd_solver.cpp:106] Iteration 2332500, lr = 0.01
I0831 00:21:59.189258 916722 solver.cpp:218] Iteration 2333000 (16.8396 iter/s, 29.6919s/500 iters), loss = 0.0265977
I0831 00:21:59.189319 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0266004 (* 1 = 0.0266004 loss)
I0831 00:21:59.189328 916722 sgd_solver.cpp:106] Iteration 2333000, lr = 0.01
I0831 00:22:28.883858 916722 solver.cpp:218] Iteration 2333500 (16.8382 iter/s, 29.6945s/500 iters), loss = 0.170485
I0831 00:22:28.883911 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.170488 (* 1 = 0.170488 loss)
I0831 00:22:28.883920 916722 sgd_solver.cpp:106] Iteration 2333500, lr = 0.01
I0831 00:22:58.578866 916722 solver.cpp:218] Iteration 2334000 (16.8379 iter/s, 29.6949s/500 iters), loss = 0.454515
I0831 00:22:58.578922 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.454518 (* 1 = 0.454518 loss)
I0831 00:22:58.578931 916722 sgd_solver.cpp:106] Iteration 2334000, lr = 0.01
I0831 00:23:28.271142 916722 solver.cpp:218] Iteration 2334500 (16.8393 iter/s, 29.6925s/500 iters), loss = 0.0303009
I0831 00:23:28.271195 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0303038 (* 1 = 0.0303038 loss)
I0831 00:23:28.271204 916722 sgd_solver.cpp:106] Iteration 2334500, lr = 0.01
I0831 00:23:57.971966 916722 solver.cpp:218] Iteration 2335000 (16.8344 iter/s, 29.701s/500 iters), loss = 0.0406227
I0831 00:23:57.972026 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0406256 (* 1 = 0.0406256 loss)
I0831 00:23:57.972034 916722 sgd_solver.cpp:106] Iteration 2335000, lr = 0.01
I0831 00:24:27.667807 916722 solver.cpp:218] Iteration 2335500 (16.8373 iter/s, 29.696s/500 iters), loss = 0.0521953
I0831 00:24:27.667862 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0521982 (* 1 = 0.0521982 loss)
I0831 00:24:27.667872 916722 sgd_solver.cpp:106] Iteration 2335500, lr = 0.01
I0831 00:24:57.363621 916722 solver.cpp:218] Iteration 2336000 (16.8373 iter/s, 29.696s/500 iters), loss = 0.160971
I0831 00:24:57.363679 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.160974 (* 1 = 0.160974 loss)
I0831 00:24:57.363687 916722 sgd_solver.cpp:106] Iteration 2336000, lr = 0.01
I0831 00:25:27.057312 916722 solver.cpp:218] Iteration 2336500 (16.8385 iter/s, 29.6938s/500 iters), loss = 0.149685
I0831 00:25:27.057364 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.149688 (* 1 = 0.149688 loss)
I0831 00:25:27.057374 916722 sgd_solver.cpp:106] Iteration 2336500, lr = 0.01
I0831 00:25:56.750259 916722 solver.cpp:218] Iteration 2337000 (16.8389 iter/s, 29.6931s/500 iters), loss = 0.094978
I0831 00:25:56.750319 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.094981 (* 1 = 0.094981 loss)
I0831 00:25:56.750326 916722 sgd_solver.cpp:106] Iteration 2337000, lr = 0.01
I0831 00:26:26.442747 916722 solver.cpp:218] Iteration 2337500 (16.8392 iter/s, 29.6926s/500 iters), loss = 0.225605
I0831 00:26:26.442803 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.225608 (* 1 = 0.225608 loss)
I0831 00:26:26.442826 916722 sgd_solver.cpp:106] Iteration 2337500, lr = 0.01
I0831 00:26:56.138293 916722 solver.cpp:218] Iteration 2338000 (16.8375 iter/s, 29.6957s/500 iters), loss = 0.131984
I0831 00:26:56.138362 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131987 (* 1 = 0.131987 loss)
I0831 00:26:56.138371 916722 sgd_solver.cpp:106] Iteration 2338000, lr = 0.01
I0831 00:27:25.831362 916722 solver.cpp:218] Iteration 2338500 (16.8389 iter/s, 29.6932s/500 iters), loss = 0.222506
I0831 00:27:25.831410 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.222509 (* 1 = 0.222509 loss)
I0831 00:27:25.831420 916722 sgd_solver.cpp:106] Iteration 2338500, lr = 0.01
I0831 00:27:55.525969 916722 solver.cpp:218] Iteration 2339000 (16.838 iter/s, 29.6947s/500 iters), loss = 0.28564
I0831 00:27:55.526027 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.285643 (* 1 = 0.285643 loss)
I0831 00:27:55.526036 916722 sgd_solver.cpp:106] Iteration 2339000, lr = 0.01
I0831 00:28:25.222340 916722 solver.cpp:218] Iteration 2339500 (16.837 iter/s, 29.6964s/500 iters), loss = 0.0974953
I0831 00:28:25.222393 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0974984 (* 1 = 0.0974984 loss)
I0831 00:28:25.222404 916722 sgd_solver.cpp:106] Iteration 2339500, lr = 0.01
I0831 00:28:54.915144 916722 solver.cpp:218] Iteration 2340000 (16.8391 iter/s, 29.6929s/500 iters), loss = 0.115719
I0831 00:28:54.915203 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115722 (* 1 = 0.115722 loss)
I0831 00:28:54.915211 916722 sgd_solver.cpp:106] Iteration 2340000, lr = 0.01
I0831 00:29:24.607523 916722 solver.cpp:218] Iteration 2340500 (16.8393 iter/s, 29.6924s/500 iters), loss = 0.263793
I0831 00:29:24.607576 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.263796 (* 1 = 0.263796 loss)
I0831 00:29:24.607587 916722 sgd_solver.cpp:106] Iteration 2340500, lr = 0.01
I0831 00:29:54.301239 916722 solver.cpp:218] Iteration 2341000 (16.8386 iter/s, 29.6938s/500 iters), loss = 0.198217
I0831 00:29:54.301298 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.19822 (* 1 = 0.19822 loss)
I0831 00:29:54.301306 916722 sgd_solver.cpp:106] Iteration 2341000, lr = 0.01
I0831 00:30:23.993558 916722 solver.cpp:218] Iteration 2341500 (16.8393 iter/s, 29.6924s/500 iters), loss = 0.0254926
I0831 00:30:23.993613 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0254957 (* 1 = 0.0254957 loss)
I0831 00:30:23.993623 916722 sgd_solver.cpp:106] Iteration 2341500, lr = 0.01
I0831 00:30:53.683620 916722 solver.cpp:218] Iteration 2342000 (16.8406 iter/s, 29.6901s/500 iters), loss = 0.0966397
I0831 00:30:53.683678 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0966429 (* 1 = 0.0966429 loss)
I0831 00:30:53.683687 916722 sgd_solver.cpp:106] Iteration 2342000, lr = 0.01
I0831 00:31:23.379236 916722 solver.cpp:218] Iteration 2342500 (16.8375 iter/s, 29.6956s/500 iters), loss = 0.0854961
I0831 00:31:23.379289 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0854993 (* 1 = 0.0854993 loss)
I0831 00:31:23.379299 916722 sgd_solver.cpp:106] Iteration 2342500, lr = 0.01
I0831 00:31:53.070948 916722 solver.cpp:218] Iteration 2343000 (16.8397 iter/s, 29.6917s/500 iters), loss = 0.0586659
I0831 00:31:53.071002 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.058669 (* 1 = 0.058669 loss)
I0831 00:31:53.071010 916722 sgd_solver.cpp:106] Iteration 2343000, lr = 0.01
I0831 00:32:22.766903 916722 solver.cpp:218] Iteration 2343500 (16.8373 iter/s, 29.696s/500 iters), loss = 0.270312
I0831 00:32:22.766954 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.270315 (* 1 = 0.270315 loss)
I0831 00:32:22.766964 916722 sgd_solver.cpp:106] Iteration 2343500, lr = 0.01
I0831 00:32:52.461046 916722 solver.cpp:218] Iteration 2344000 (16.8383 iter/s, 29.6941s/500 iters), loss = 0.0480644
I0831 00:32:52.461105 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0480674 (* 1 = 0.0480674 loss)
I0831 00:32:52.461113 916722 sgd_solver.cpp:106] Iteration 2344000, lr = 0.01
I0831 00:33:22.156076 916722 solver.cpp:218] Iteration 2344500 (16.8378 iter/s, 29.695s/500 iters), loss = 0.121431
I0831 00:33:22.156129 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.121434 (* 1 = 0.121434 loss)
I0831 00:33:22.156141 916722 sgd_solver.cpp:106] Iteration 2344500, lr = 0.01
I0831 00:33:51.849968 916722 solver.cpp:218] Iteration 2345000 (16.8385 iter/s, 29.6939s/500 iters), loss = 0.728231
I0831 00:33:51.850039 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.728234 (* 1 = 0.728234 loss)
I0831 00:33:51.850047 916722 sgd_solver.cpp:106] Iteration 2345000, lr = 0.01
I0831 00:34:21.545298 916722 solver.cpp:218] Iteration 2345500 (16.8377 iter/s, 29.6953s/500 iters), loss = 0.0458362
I0831 00:34:21.545351 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.045839 (* 1 = 0.045839 loss)
I0831 00:34:21.545361 916722 sgd_solver.cpp:106] Iteration 2345500, lr = 0.01
I0831 00:34:51.238647 916722 solver.cpp:218] Iteration 2346000 (16.8388 iter/s, 29.6933s/500 iters), loss = 0.155198
I0831 00:34:51.238708 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.155202 (* 1 = 0.155202 loss)
I0831 00:34:51.238716 916722 sgd_solver.cpp:106] Iteration 2346000, lr = 0.01
I0831 00:35:20.934904 916722 solver.cpp:218] Iteration 2346500 (16.8372 iter/s, 29.6962s/500 iters), loss = 0.0761229
I0831 00:35:20.934955 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0761261 (* 1 = 0.0761261 loss)
I0831 00:35:20.934964 916722 sgd_solver.cpp:106] Iteration 2346500, lr = 0.01
I0831 00:35:50.624846 916722 solver.cpp:218] Iteration 2347000 (16.8407 iter/s, 29.6899s/500 iters), loss = 0.038527
I0831 00:35:50.624904 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0385303 (* 1 = 0.0385303 loss)
I0831 00:35:50.624912 916722 sgd_solver.cpp:106] Iteration 2347000, lr = 0.01
I0831 00:36:20.317669 916722 solver.cpp:218] Iteration 2347500 (16.8391 iter/s, 29.6928s/500 iters), loss = 0.144592
I0831 00:36:20.317719 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.144595 (* 1 = 0.144595 loss)
I0831 00:36:20.317728 916722 sgd_solver.cpp:106] Iteration 2347500, lr = 0.01
I0831 00:36:50.012231 916722 solver.cpp:218] Iteration 2348000 (16.8381 iter/s, 29.6945s/500 iters), loss = 0.080702
I0831 00:36:50.012291 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0807053 (* 1 = 0.0807053 loss)
I0831 00:36:50.012300 916722 sgd_solver.cpp:106] Iteration 2348000, lr = 0.01
I0831 00:37:19.706604 916722 solver.cpp:218] Iteration 2348500 (16.8382 iter/s, 29.6943s/500 iters), loss = 0.320165
I0831 00:37:19.706657 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.320168 (* 1 = 0.320168 loss)
I0831 00:37:19.706665 916722 sgd_solver.cpp:106] Iteration 2348500, lr = 0.01
I0831 00:37:49.402825 916722 solver.cpp:218] Iteration 2349000 (16.8372 iter/s, 29.6962s/500 iters), loss = 0.108844
I0831 00:37:49.402884 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.108847 (* 1 = 0.108847 loss)
I0831 00:37:49.402894 916722 sgd_solver.cpp:106] Iteration 2349000, lr = 0.01
I0831 00:38:19.094374 916722 solver.cpp:218] Iteration 2349500 (16.8398 iter/s, 29.6915s/500 iters), loss = 0.130767
I0831 00:38:19.094427 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13077 (* 1 = 0.13077 loss)
I0831 00:38:19.094436 916722 sgd_solver.cpp:106] Iteration 2349500, lr = 0.01
I0831 00:38:48.727357 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_2350000.caffemodel
I0831 00:38:48.746469 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_2350000.solverstate
I0831 00:38:48.752663 916722 solver.cpp:330] Iteration 2350000, Testing net (#0)
I0831 00:39:04.072664 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8985
I0831 00:39:04.072705 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.343756 (* 1 = 0.343756 loss)
I0831 00:39:04.131237 916722 solver.cpp:218] Iteration 2350000 (11.102 iter/s, 45.0368s/500 iters), loss = 0.0947285
I0831 00:39:04.131275 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0947317 (* 1 = 0.0947317 loss)
I0831 00:39:04.131284 916722 sgd_solver.cpp:106] Iteration 2350000, lr = 0.01
I0831 00:39:33.719234 916722 solver.cpp:218] Iteration 2350500 (16.8988 iter/s, 29.5879s/500 iters), loss = 0.404157
I0831 00:39:33.719307 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.404161 (* 1 = 0.404161 loss)
I0831 00:39:33.719316 916722 sgd_solver.cpp:106] Iteration 2350500, lr = 0.01
I0831 00:40:03.371937 916722 solver.cpp:218] Iteration 2351000 (16.8619 iter/s, 29.6526s/500 iters), loss = 0.106357
I0831 00:40:03.371986 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.10636 (* 1 = 0.10636 loss)
I0831 00:40:03.371994 916722 sgd_solver.cpp:106] Iteration 2351000, lr = 0.01
I0831 00:40:33.063400 916722 solver.cpp:218] Iteration 2351500 (16.8399 iter/s, 29.6914s/500 iters), loss = 0.222645
I0831 00:40:33.063460 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.222649 (* 1 = 0.222649 loss)
I0831 00:40:33.063468 916722 sgd_solver.cpp:106] Iteration 2351500, lr = 0.01
I0831 00:41:02.750156 916722 solver.cpp:218] Iteration 2352000 (16.8426 iter/s, 29.6867s/500 iters), loss = 0.144276
I0831 00:41:02.750207 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.14428 (* 1 = 0.14428 loss)
I0831 00:41:02.750216 916722 sgd_solver.cpp:106] Iteration 2352000, lr = 0.01
I0831 00:41:32.438277 916722 solver.cpp:218] Iteration 2352500 (16.8418 iter/s, 29.6881s/500 iters), loss = 0.464849
I0831 00:41:32.438335 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.464853 (* 1 = 0.464853 loss)
I0831 00:41:32.438344 916722 sgd_solver.cpp:106] Iteration 2352500, lr = 0.01
I0831 00:42:02.126722 916722 solver.cpp:218] Iteration 2353000 (16.8416 iter/s, 29.6884s/500 iters), loss = 0.185691
I0831 00:42:02.126772 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.185695 (* 1 = 0.185695 loss)
I0831 00:42:02.126780 916722 sgd_solver.cpp:106] Iteration 2353000, lr = 0.01
I0831 00:42:31.817494 916722 solver.cpp:218] Iteration 2353500 (16.8403 iter/s, 29.6907s/500 iters), loss = 0.0630801
I0831 00:42:31.817550 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0630838 (* 1 = 0.0630838 loss)
I0831 00:42:31.817559 916722 sgd_solver.cpp:106] Iteration 2353500, lr = 0.01
I0831 00:43:01.506299 916722 solver.cpp:218] Iteration 2354000 (16.8414 iter/s, 29.6887s/500 iters), loss = 0.145551
I0831 00:43:01.506347 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.145554 (* 1 = 0.145554 loss)
I0831 00:43:01.506356 916722 sgd_solver.cpp:106] Iteration 2354000, lr = 0.01
I0831 00:43:31.199314 916722 solver.cpp:218] Iteration 2354500 (16.839 iter/s, 29.693s/500 iters), loss = 0.250098
I0831 00:43:31.199373 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.250102 (* 1 = 0.250102 loss)
I0831 00:43:31.199381 916722 sgd_solver.cpp:106] Iteration 2354500, lr = 0.01
I0831 00:44:00.890264 916722 solver.cpp:218] Iteration 2355000 (16.8402 iter/s, 29.6909s/500 iters), loss = 0.141217
I0831 00:44:00.890313 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.141221 (* 1 = 0.141221 loss)
I0831 00:44:00.890321 916722 sgd_solver.cpp:106] Iteration 2355000, lr = 0.01
I0831 00:44:30.579952 916722 solver.cpp:218] Iteration 2355500 (16.8409 iter/s, 29.6896s/500 iters), loss = 0.0176327
I0831 00:44:30.580011 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0176362 (* 1 = 0.0176362 loss)
I0831 00:44:30.580019 916722 sgd_solver.cpp:106] Iteration 2355500, lr = 0.01
I0831 00:45:00.270788 916722 solver.cpp:218] Iteration 2356000 (16.8403 iter/s, 29.6908s/500 iters), loss = 0.0874119
I0831 00:45:00.270843 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0874153 (* 1 = 0.0874153 loss)
I0831 00:45:00.270853 916722 sgd_solver.cpp:106] Iteration 2356000, lr = 0.01
I0831 00:45:29.961534 916722 solver.cpp:218] Iteration 2356500 (16.8403 iter/s, 29.6907s/500 iters), loss = 0.0993153
I0831 00:45:29.961606 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0993188 (* 1 = 0.0993188 loss)
I0831 00:45:29.961614 916722 sgd_solver.cpp:106] Iteration 2356500, lr = 0.01
I0831 00:45:59.650975 916722 solver.cpp:218] Iteration 2357000 (16.8411 iter/s, 29.6893s/500 iters), loss = 0.0160791
I0831 00:45:59.651028 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0160826 (* 1 = 0.0160826 loss)
I0831 00:45:59.651038 916722 sgd_solver.cpp:106] Iteration 2357000, lr = 0.01
I0831 00:46:29.343885 916722 solver.cpp:218] Iteration 2357500 (16.8391 iter/s, 29.6928s/500 iters), loss = 0.0959321
I0831 00:46:29.343945 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0959353 (* 1 = 0.0959353 loss)
I0831 00:46:29.343955 916722 sgd_solver.cpp:106] Iteration 2357500, lr = 0.01
I0831 00:46:59.035145 916722 solver.cpp:218] Iteration 2358000 (16.84 iter/s, 29.6912s/500 iters), loss = 0.0909532
I0831 00:46:59.035197 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0909564 (* 1 = 0.0909564 loss)
I0831 00:46:59.035207 916722 sgd_solver.cpp:106] Iteration 2358000, lr = 0.01
I0831 00:47:28.725036 916722 solver.cpp:218] Iteration 2358500 (16.8408 iter/s, 29.6898s/500 iters), loss = 0.0488984
I0831 00:47:28.725095 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0489017 (* 1 = 0.0489017 loss)
I0831 00:47:28.725103 916722 sgd_solver.cpp:106] Iteration 2358500, lr = 0.01
I0831 00:47:58.415001 916722 solver.cpp:218] Iteration 2359000 (16.8408 iter/s, 29.6899s/500 iters), loss = 0.0687402
I0831 00:47:58.415055 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0687435 (* 1 = 0.0687435 loss)
I0831 00:47:58.415064 916722 sgd_solver.cpp:106] Iteration 2359000, lr = 0.01
I0831 00:48:28.104874 916722 solver.cpp:218] Iteration 2359500 (16.8408 iter/s, 29.6898s/500 iters), loss = 0.308227
I0831 00:48:28.104933 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.30823 (* 1 = 0.30823 loss)
I0831 00:48:28.104941 916722 sgd_solver.cpp:106] Iteration 2359500, lr = 0.01
I0831 00:48:57.795107 916722 solver.cpp:218] Iteration 2360000 (16.8406 iter/s, 29.6901s/500 iters), loss = 0.0321232
I0831 00:48:57.795161 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0321263 (* 1 = 0.0321263 loss)
I0831 00:48:57.795171 916722 sgd_solver.cpp:106] Iteration 2360000, lr = 0.01
I0831 00:49:27.490640 916722 solver.cpp:218] Iteration 2360500 (16.8376 iter/s, 29.6954s/500 iters), loss = 0.389512
I0831 00:49:27.490700 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.389515 (* 1 = 0.389515 loss)
I0831 00:49:27.490707 916722 sgd_solver.cpp:106] Iteration 2360500, lr = 0.01
I0831 00:49:57.178766 916722 solver.cpp:218] Iteration 2361000 (16.8418 iter/s, 29.688s/500 iters), loss = 0.217363
I0831 00:49:57.178820 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.217366 (* 1 = 0.217366 loss)
I0831 00:49:57.178828 916722 sgd_solver.cpp:106] Iteration 2361000, lr = 0.01
I0831 00:50:26.866691 916722 solver.cpp:218] Iteration 2361500 (16.8419 iter/s, 29.6878s/500 iters), loss = 0.274766
I0831 00:50:26.866751 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.274769 (* 1 = 0.274769 loss)
I0831 00:50:26.866760 916722 sgd_solver.cpp:106] Iteration 2361500, lr = 0.01
I0831 00:50:56.556994 916722 solver.cpp:218] Iteration 2362000 (16.8406 iter/s, 29.6902s/500 iters), loss = 0.135388
I0831 00:50:56.557047 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.135392 (* 1 = 0.135392 loss)
I0831 00:50:56.557056 916722 sgd_solver.cpp:106] Iteration 2362000, lr = 0.01
I0831 00:51:26.249934 916722 solver.cpp:218] Iteration 2362500 (16.8391 iter/s, 29.6928s/500 iters), loss = 0.0533814
I0831 00:51:26.249994 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0533845 (* 1 = 0.0533845 loss)
I0831 00:51:26.250002 916722 sgd_solver.cpp:106] Iteration 2362500, lr = 0.01
I0831 00:51:55.937640 916722 solver.cpp:218] Iteration 2363000 (16.842 iter/s, 29.6876s/500 iters), loss = 0.0946206
I0831 00:51:55.937690 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0946238 (* 1 = 0.0946238 loss)
I0831 00:51:55.937711 916722 sgd_solver.cpp:106] Iteration 2363000, lr = 0.01
I0831 00:52:25.627498 916722 solver.cpp:218] Iteration 2363500 (16.8408 iter/s, 29.6898s/500 iters), loss = 0.135984
I0831 00:52:25.627573 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.135987 (* 1 = 0.135987 loss)
I0831 00:52:25.627583 916722 sgd_solver.cpp:106] Iteration 2363500, lr = 0.01
I0831 00:52:55.315395 916722 solver.cpp:218] Iteration 2364000 (16.8419 iter/s, 29.6878s/500 iters), loss = 0.252031
I0831 00:52:55.315447 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.252034 (* 1 = 0.252034 loss)
I0831 00:52:55.315457 916722 sgd_solver.cpp:106] Iteration 2364000, lr = 0.01
I0831 00:53:25.010186 916722 solver.cpp:218] Iteration 2364500 (16.838 iter/s, 29.6947s/500 iters), loss = 0.0241972
I0831 00:53:25.010243 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0242005 (* 1 = 0.0242005 loss)
I0831 00:53:25.010251 916722 sgd_solver.cpp:106] Iteration 2364500, lr = 0.01
I0831 00:53:54.703505 916722 solver.cpp:218] Iteration 2365000 (16.8389 iter/s, 29.6932s/500 iters), loss = 0.0729748
I0831 00:53:54.703559 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0729781 (* 1 = 0.0729781 loss)
I0831 00:53:54.703569 916722 sgd_solver.cpp:106] Iteration 2365000, lr = 0.01
I0831 00:54:24.395648 916722 solver.cpp:218] Iteration 2365500 (16.8395 iter/s, 29.692s/500 iters), loss = 0.0511976
I0831 00:54:24.395711 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0512009 (* 1 = 0.0512009 loss)
I0831 00:54:24.395720 916722 sgd_solver.cpp:106] Iteration 2365500, lr = 0.01
I0831 00:54:54.086426 916722 solver.cpp:218] Iteration 2366000 (16.8403 iter/s, 29.6907s/500 iters), loss = 0.330132
I0831 00:54:54.086479 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.330135 (* 1 = 0.330135 loss)
I0831 00:54:54.086488 916722 sgd_solver.cpp:106] Iteration 2366000, lr = 0.01
I0831 00:55:23.777995 916722 solver.cpp:218] Iteration 2366500 (16.8399 iter/s, 29.6915s/500 iters), loss = 0.576665
I0831 00:55:23.778056 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.576668 (* 1 = 0.576668 loss)
I0831 00:55:23.778064 916722 sgd_solver.cpp:106] Iteration 2366500, lr = 0.01
I0831 00:55:53.469812 916722 solver.cpp:218] Iteration 2367000 (16.8397 iter/s, 29.6917s/500 iters), loss = 0.0935866
I0831 00:55:53.469866 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0935898 (* 1 = 0.0935898 loss)
I0831 00:55:53.469874 916722 sgd_solver.cpp:106] Iteration 2367000, lr = 0.01
I0831 00:56:23.158988 916722 solver.cpp:218] Iteration 2367500 (16.8412 iter/s, 29.6891s/500 iters), loss = 0.150114
I0831 00:56:23.159047 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.150118 (* 1 = 0.150118 loss)
I0831 00:56:23.159056 916722 sgd_solver.cpp:106] Iteration 2367500, lr = 0.01
I0831 00:56:52.852759 916722 solver.cpp:218] Iteration 2368000 (16.8386 iter/s, 29.6937s/500 iters), loss = 0.176786
I0831 00:56:52.852811 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.176789 (* 1 = 0.176789 loss)
I0831 00:56:52.852820 916722 sgd_solver.cpp:106] Iteration 2368000, lr = 0.01
I0831 00:57:22.541776 916722 solver.cpp:218] Iteration 2368500 (16.8417 iter/s, 29.6883s/500 iters), loss = 0.13311
I0831 00:57:22.541833 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133113 (* 1 = 0.133113 loss)
I0831 00:57:22.541841 916722 sgd_solver.cpp:106] Iteration 2368500, lr = 0.01
I0831 00:57:52.237598 916722 solver.cpp:218] Iteration 2369000 (16.838 iter/s, 29.6947s/500 iters), loss = 0.0645118
I0831 00:57:52.237648 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0645151 (* 1 = 0.0645151 loss)
I0831 00:57:52.237658 916722 sgd_solver.cpp:106] Iteration 2369000, lr = 0.01
I0831 00:58:21.927521 916722 solver.cpp:218] Iteration 2369500 (16.8413 iter/s, 29.6888s/500 iters), loss = 0.214407
I0831 00:58:21.927592 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.21441 (* 1 = 0.21441 loss)
I0831 00:58:21.927605 916722 sgd_solver.cpp:106] Iteration 2369500, lr = 0.01
I0831 00:58:51.620388 916722 solver.cpp:218] Iteration 2370000 (16.8397 iter/s, 29.6918s/500 iters), loss = 0.321103
I0831 00:58:51.620457 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.321106 (* 1 = 0.321106 loss)
I0831 00:58:51.620467 916722 sgd_solver.cpp:106] Iteration 2370000, lr = 0.01
I0831 00:59:21.311353 916722 solver.cpp:218] Iteration 2370500 (16.8407 iter/s, 29.69s/500 iters), loss = 0.162625
I0831 00:59:21.311412 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.162629 (* 1 = 0.162629 loss)
I0831 00:59:21.311420 916722 sgd_solver.cpp:106] Iteration 2370500, lr = 0.01
I0831 00:59:51.002867 916722 solver.cpp:218] Iteration 2371000 (16.8404 iter/s, 29.6905s/500 iters), loss = 0.0854115
I0831 00:59:51.002919 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.085415 (* 1 = 0.085415 loss)
I0831 00:59:51.002928 916722 sgd_solver.cpp:106] Iteration 2371000, lr = 0.01
I0831 01:00:20.697006 916722 solver.cpp:218] Iteration 2371500 (16.8389 iter/s, 29.6932s/500 iters), loss = 0.346023
I0831 01:00:20.697067 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.346026 (* 1 = 0.346026 loss)
I0831 01:00:20.697074 916722 sgd_solver.cpp:106] Iteration 2371500, lr = 0.01
I0831 01:00:50.388072 916722 solver.cpp:218] Iteration 2372000 (16.8406 iter/s, 29.6902s/500 iters), loss = 0.112685
I0831 01:00:50.388126 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112689 (* 1 = 0.112689 loss)
I0831 01:00:50.388135 916722 sgd_solver.cpp:106] Iteration 2372000, lr = 0.01
I0831 01:01:20.080639 916722 solver.cpp:218] Iteration 2372500 (16.8397 iter/s, 29.6917s/500 iters), loss = 0.0512788
I0831 01:01:20.080696 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0512822 (* 1 = 0.0512822 loss)
I0831 01:01:20.080704 916722 sgd_solver.cpp:106] Iteration 2372500, lr = 0.01
I0831 01:01:49.770763 916722 solver.cpp:218] Iteration 2373000 (16.8411 iter/s, 29.6893s/500 iters), loss = 0.0851581
I0831 01:01:49.770815 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0851614 (* 1 = 0.0851614 loss)
I0831 01:01:49.770824 916722 sgd_solver.cpp:106] Iteration 2373000, lr = 0.01
I0831 01:02:19.462257 916722 solver.cpp:218] Iteration 2373500 (16.8403 iter/s, 29.6907s/500 iters), loss = 0.0192152
I0831 01:02:19.462316 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0192186 (* 1 = 0.0192186 loss)
I0831 01:02:19.462323 916722 sgd_solver.cpp:106] Iteration 2373500, lr = 0.01
I0831 01:02:49.152040 916722 solver.cpp:218] Iteration 2374000 (16.8412 iter/s, 29.689s/500 iters), loss = 0.198593
I0831 01:02:49.152094 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.198596 (* 1 = 0.198596 loss)
I0831 01:02:49.152102 916722 sgd_solver.cpp:106] Iteration 2374000, lr = 0.01
I0831 01:03:18.845665 916722 solver.cpp:218] Iteration 2374500 (16.839 iter/s, 29.6929s/500 iters), loss = 0.109306
I0831 01:03:18.845726 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109309 (* 1 = 0.109309 loss)
I0831 01:03:18.845736 916722 sgd_solver.cpp:106] Iteration 2374500, lr = 0.01
I0831 01:03:48.537741 916722 solver.cpp:218] Iteration 2375000 (16.8399 iter/s, 29.6914s/500 iters), loss = 0.144993
I0831 01:03:48.537793 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.144997 (* 1 = 0.144997 loss)
I0831 01:03:48.537802 916722 sgd_solver.cpp:106] Iteration 2375000, lr = 0.01
I0831 01:04:18.229094 916722 solver.cpp:218] Iteration 2375500 (16.8403 iter/s, 29.6907s/500 iters), loss = 0.0171117
I0831 01:04:18.229156 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0171157 (* 1 = 0.0171157 loss)
I0831 01:04:18.229164 916722 sgd_solver.cpp:106] Iteration 2375500, lr = 0.01
I0831 01:04:47.919201 916722 solver.cpp:218] Iteration 2376000 (16.841 iter/s, 29.6894s/500 iters), loss = 0.152988
I0831 01:04:47.919257 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152992 (* 1 = 0.152992 loss)
I0831 01:04:47.919279 916722 sgd_solver.cpp:106] Iteration 2376000, lr = 0.01
I0831 01:05:17.610806 916722 solver.cpp:218] Iteration 2376500 (16.8401 iter/s, 29.691s/500 iters), loss = 0.167303
I0831 01:05:17.610874 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.167307 (* 1 = 0.167307 loss)
I0831 01:05:17.610883 916722 sgd_solver.cpp:106] Iteration 2376500, lr = 0.01
I0831 01:05:47.304231 916722 solver.cpp:218] Iteration 2377000 (16.8391 iter/s, 29.6928s/500 iters), loss = 0.144485
I0831 01:05:47.304286 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.144489 (* 1 = 0.144489 loss)
I0831 01:05:47.304296 916722 sgd_solver.cpp:106] Iteration 2377000, lr = 0.01
I0831 01:06:16.993113 916722 solver.cpp:218] Iteration 2377500 (16.8417 iter/s, 29.6883s/500 iters), loss = 0.0669785
I0831 01:06:16.993171 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0669827 (* 1 = 0.0669827 loss)
I0831 01:06:16.993180 916722 sgd_solver.cpp:106] Iteration 2377500, lr = 0.01
I0831 01:06:46.685237 916722 solver.cpp:218] Iteration 2378000 (16.8398 iter/s, 29.6915s/500 iters), loss = 0.109283
I0831 01:06:46.685286 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109288 (* 1 = 0.109288 loss)
I0831 01:06:46.685295 916722 sgd_solver.cpp:106] Iteration 2378000, lr = 0.01
I0831 01:07:16.375476 916722 solver.cpp:218] Iteration 2378500 (16.8409 iter/s, 29.6897s/500 iters), loss = 0.11759
I0831 01:07:16.375535 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.117595 (* 1 = 0.117595 loss)
I0831 01:07:16.375542 916722 sgd_solver.cpp:106] Iteration 2378500, lr = 0.01
I0831 01:07:46.068790 916722 solver.cpp:218] Iteration 2379000 (16.8391 iter/s, 29.6928s/500 iters), loss = 0.180007
I0831 01:07:46.068842 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.180012 (* 1 = 0.180012 loss)
I0831 01:07:46.068852 916722 sgd_solver.cpp:106] Iteration 2379000, lr = 0.01
I0831 01:08:15.760488 916722 solver.cpp:218] Iteration 2379500 (16.84 iter/s, 29.6912s/500 iters), loss = 0.050263
I0831 01:08:15.760546 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0502673 (* 1 = 0.0502673 loss)
I0831 01:08:15.760555 916722 sgd_solver.cpp:106] Iteration 2379500, lr = 0.01
I0831 01:08:45.451867 916722 solver.cpp:218] Iteration 2380000 (16.8402 iter/s, 29.6909s/500 iters), loss = 0.119096
I0831 01:08:45.451920 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.1191 (* 1 = 0.1191 loss)
I0831 01:08:45.451930 916722 sgd_solver.cpp:106] Iteration 2380000, lr = 0.01
I0831 01:09:15.145552 916722 solver.cpp:218] Iteration 2380500 (16.8389 iter/s, 29.6932s/500 iters), loss = 0.0722605
I0831 01:09:15.145614 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0722644 (* 1 = 0.0722644 loss)
I0831 01:09:15.145622 916722 sgd_solver.cpp:106] Iteration 2380500, lr = 0.01
I0831 01:09:44.836675 916722 solver.cpp:218] Iteration 2381000 (16.8403 iter/s, 29.6906s/500 iters), loss = 0.128932
I0831 01:09:44.836727 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128936 (* 1 = 0.128936 loss)
I0831 01:09:44.836736 916722 sgd_solver.cpp:106] Iteration 2381000, lr = 0.01
I0831 01:10:14.528475 916722 solver.cpp:218] Iteration 2381500 (16.8399 iter/s, 29.6913s/500 iters), loss = 0.11857
I0831 01:10:14.528535 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.118574 (* 1 = 0.118574 loss)
I0831 01:10:14.528544 916722 sgd_solver.cpp:106] Iteration 2381500, lr = 0.01
I0831 01:10:44.218698 916722 solver.cpp:218] Iteration 2382000 (16.8408 iter/s, 29.6897s/500 iters), loss = 0.0796307
I0831 01:10:44.218750 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0796344 (* 1 = 0.0796344 loss)
I0831 01:10:44.218758 916722 sgd_solver.cpp:106] Iteration 2382000, lr = 0.01
I0831 01:11:13.911434 916722 solver.cpp:218] Iteration 2382500 (16.8394 iter/s, 29.6923s/500 iters), loss = 0.0518823
I0831 01:11:13.911495 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0518859 (* 1 = 0.0518859 loss)
I0831 01:11:13.911504 916722 sgd_solver.cpp:106] Iteration 2382500, lr = 0.01
I0831 01:11:43.602303 916722 solver.cpp:218] Iteration 2383000 (16.8405 iter/s, 29.6904s/500 iters), loss = 0.22394
I0831 01:11:43.602356 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.223943 (* 1 = 0.223943 loss)
I0831 01:11:43.602365 916722 sgd_solver.cpp:106] Iteration 2383000, lr = 0.01
I0831 01:12:13.294224 916722 solver.cpp:218] Iteration 2383500 (16.8398 iter/s, 29.6915s/500 iters), loss = 0.0320912
I0831 01:12:13.294294 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0320947 (* 1 = 0.0320947 loss)
I0831 01:12:13.294303 916722 sgd_solver.cpp:106] Iteration 2383500, lr = 0.01
I0831 01:12:42.985468 916722 solver.cpp:218] Iteration 2384000 (16.8402 iter/s, 29.6908s/500 iters), loss = 0.248483
I0831 01:12:42.985522 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.248487 (* 1 = 0.248487 loss)
I0831 01:12:42.985530 916722 sgd_solver.cpp:106] Iteration 2384000, lr = 0.01
I0831 01:13:12.675959 916722 solver.cpp:218] Iteration 2384500 (16.8406 iter/s, 29.6901s/500 iters), loss = 0.178647
I0831 01:13:12.676018 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.178651 (* 1 = 0.178651 loss)
I0831 01:13:12.676028 916722 sgd_solver.cpp:106] Iteration 2384500, lr = 0.01
I0831 01:13:42.364630 916722 solver.cpp:218] Iteration 2385000 (16.8417 iter/s, 29.6882s/500 iters), loss = 0.118096
I0831 01:13:42.364683 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.1181 (* 1 = 0.1181 loss)
I0831 01:13:42.364692 916722 sgd_solver.cpp:106] Iteration 2385000, lr = 0.01
I0831 01:14:12.055686 916722 solver.cpp:218] Iteration 2385500 (16.8403 iter/s, 29.6907s/500 iters), loss = 0.10088
I0831 01:14:12.055747 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.100883 (* 1 = 0.100883 loss)
I0831 01:14:12.055760 916722 sgd_solver.cpp:106] Iteration 2385500, lr = 0.01
I0831 01:14:41.748719 916722 solver.cpp:218] Iteration 2386000 (16.8392 iter/s, 29.6926s/500 iters), loss = 0.124354
I0831 01:14:41.748780 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.124357 (* 1 = 0.124357 loss)
I0831 01:14:41.748790 916722 sgd_solver.cpp:106] Iteration 2386000, lr = 0.01
I0831 01:15:11.439873 916722 solver.cpp:218] Iteration 2386500 (16.8403 iter/s, 29.6908s/500 iters), loss = 0.732771
I0831 01:15:11.439929 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.732774 (* 1 = 0.732774 loss)
I0831 01:15:11.439937 916722 sgd_solver.cpp:106] Iteration 2386500, lr = 0.01
I0831 01:15:41.127745 916722 solver.cpp:218] Iteration 2387000 (16.8421 iter/s, 29.6875s/500 iters), loss = 0.01961
I0831 01:15:41.127801 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0196135 (* 1 = 0.0196135 loss)
I0831 01:15:41.127811 916722 sgd_solver.cpp:106] Iteration 2387000, lr = 0.01
I0831 01:16:10.817418 916722 solver.cpp:218] Iteration 2387500 (16.8411 iter/s, 29.6893s/500 iters), loss = 0.258804
I0831 01:16:10.817476 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.258807 (* 1 = 0.258807 loss)
I0831 01:16:10.817483 916722 sgd_solver.cpp:106] Iteration 2387500, lr = 0.01
I0831 01:16:40.508036 916722 solver.cpp:218] Iteration 2388000 (16.8405 iter/s, 29.6902s/500 iters), loss = 0.0435006
I0831 01:16:40.508090 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0435041 (* 1 = 0.0435041 loss)
I0831 01:16:40.508100 916722 sgd_solver.cpp:106] Iteration 2388000, lr = 0.01
I0831 01:17:10.201337 916722 solver.cpp:218] Iteration 2388500 (16.839 iter/s, 29.6929s/500 iters), loss = 0.159833
I0831 01:17:10.201395 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159837 (* 1 = 0.159837 loss)
I0831 01:17:10.201404 916722 sgd_solver.cpp:106] Iteration 2388500, lr = 0.01
I0831 01:17:39.890918 916722 solver.cpp:218] Iteration 2389000 (16.8411 iter/s, 29.6892s/500 iters), loss = 0.126321
I0831 01:17:39.890971 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.126324 (* 1 = 0.126324 loss)
I0831 01:17:39.890982 916722 sgd_solver.cpp:106] Iteration 2389000, lr = 0.01
I0831 01:18:09.581900 916722 solver.cpp:218] Iteration 2389500 (16.8403 iter/s, 29.6906s/500 iters), loss = 0.150083
I0831 01:18:09.581974 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.150087 (* 1 = 0.150087 loss)
I0831 01:18:09.581982 916722 sgd_solver.cpp:106] Iteration 2389500, lr = 0.01
I0831 01:18:39.272363 916722 solver.cpp:218] Iteration 2390000 (16.8406 iter/s, 29.6901s/500 iters), loss = 0.0445456
I0831 01:18:39.272416 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0445491 (* 1 = 0.0445491 loss)
I0831 01:18:39.272431 916722 sgd_solver.cpp:106] Iteration 2390000, lr = 0.01
I0831 01:19:08.961125 916722 solver.cpp:218] Iteration 2390500 (16.8416 iter/s, 29.6884s/500 iters), loss = 0.159808
I0831 01:19:08.961181 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159812 (* 1 = 0.159812 loss)
I0831 01:19:08.961189 916722 sgd_solver.cpp:106] Iteration 2390500, lr = 0.01
I0831 01:19:38.657384 916722 solver.cpp:218] Iteration 2391000 (16.8373 iter/s, 29.6959s/500 iters), loss = 0.109722
I0831 01:19:38.657438 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109726 (* 1 = 0.109726 loss)
I0831 01:19:38.657447 916722 sgd_solver.cpp:106] Iteration 2391000, lr = 0.01
I0831 01:20:08.354873 916722 solver.cpp:218] Iteration 2391500 (16.8366 iter/s, 29.6971s/500 iters), loss = 0.0842444
I0831 01:20:08.354933 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0842481 (* 1 = 0.0842481 loss)
I0831 01:20:08.354941 916722 sgd_solver.cpp:106] Iteration 2391500, lr = 0.01
I0831 01:20:38.057251 916722 solver.cpp:218] Iteration 2392000 (16.8339 iter/s, 29.702s/500 iters), loss = 0.0225925
I0831 01:20:38.057307 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0225962 (* 1 = 0.0225962 loss)
I0831 01:20:38.057317 916722 sgd_solver.cpp:106] Iteration 2392000, lr = 0.01
I0831 01:21:07.761711 916722 solver.cpp:218] Iteration 2392500 (16.8327 iter/s, 29.7041s/500 iters), loss = 0.0549719
I0831 01:21:07.761772 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0549757 (* 1 = 0.0549757 loss)
I0831 01:21:07.761781 916722 sgd_solver.cpp:106] Iteration 2392500, lr = 0.01
I0831 01:21:37.478333 916722 solver.cpp:218] Iteration 2393000 (16.8258 iter/s, 29.7163s/500 iters), loss = 0.0710298
I0831 01:21:37.478390 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0710337 (* 1 = 0.0710337 loss)
I0831 01:21:37.478399 916722 sgd_solver.cpp:106] Iteration 2393000, lr = 0.01
I0831 01:22:07.182031 916722 solver.cpp:218] Iteration 2393500 (16.8331 iter/s, 29.7034s/500 iters), loss = 0.218987
I0831 01:22:07.182090 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.218991 (* 1 = 0.218991 loss)
I0831 01:22:07.182099 916722 sgd_solver.cpp:106] Iteration 2393500, lr = 0.01
I0831 01:22:36.885159 916722 solver.cpp:218] Iteration 2394000 (16.8334 iter/s, 29.7028s/500 iters), loss = 0.0280341
I0831 01:22:36.885210 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0280381 (* 1 = 0.0280381 loss)
I0831 01:22:36.885219 916722 sgd_solver.cpp:106] Iteration 2394000, lr = 0.01
I0831 01:23:06.581425 916722 solver.cpp:218] Iteration 2394500 (16.8373 iter/s, 29.6959s/500 iters), loss = 0.124018
I0831 01:23:06.581485 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.124022 (* 1 = 0.124022 loss)
I0831 01:23:06.581493 916722 sgd_solver.cpp:106] Iteration 2394500, lr = 0.01
I0831 01:23:36.281067 916722 solver.cpp:218] Iteration 2395000 (16.8354 iter/s, 29.6993s/500 iters), loss = 0.0813137
I0831 01:23:36.281119 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0813177 (* 1 = 0.0813177 loss)
I0831 01:23:36.281127 916722 sgd_solver.cpp:106] Iteration 2395000, lr = 0.01
I0831 01:24:05.982172 916722 solver.cpp:218] Iteration 2395500 (16.8346 iter/s, 29.7008s/500 iters), loss = 0.141717
I0831 01:24:05.982232 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.141721 (* 1 = 0.141721 loss)
I0831 01:24:05.982240 916722 sgd_solver.cpp:106] Iteration 2395500, lr = 0.01
I0831 01:24:35.683017 916722 solver.cpp:218] Iteration 2396000 (16.8347 iter/s, 29.7005s/500 iters), loss = 0.11716
I0831 01:24:35.683080 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.117164 (* 1 = 0.117164 loss)
I0831 01:24:35.683089 916722 sgd_solver.cpp:106] Iteration 2396000, lr = 0.01
I0831 01:25:05.378592 916722 solver.cpp:218] Iteration 2396500 (16.8377 iter/s, 29.6953s/500 iters), loss = 0.108925
I0831 01:25:05.378661 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.108929 (* 1 = 0.108929 loss)
I0831 01:25:05.378685 916722 sgd_solver.cpp:106] Iteration 2396500, lr = 0.01
I0831 01:25:35.072749 916722 solver.cpp:218] Iteration 2397000 (16.8385 iter/s, 29.6938s/500 iters), loss = 0.162452
I0831 01:25:35.072803 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.162455 (* 1 = 0.162455 loss)
I0831 01:25:35.072813 916722 sgd_solver.cpp:106] Iteration 2397000, lr = 0.01
I0831 01:26:04.775527 916722 solver.cpp:218] Iteration 2397500 (16.8336 iter/s, 29.7025s/500 iters), loss = 0.109588
I0831 01:26:04.775586 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109592 (* 1 = 0.109592 loss)
I0831 01:26:04.775594 916722 sgd_solver.cpp:106] Iteration 2397500, lr = 0.01
I0831 01:26:34.477224 916722 solver.cpp:218] Iteration 2398000 (16.8342 iter/s, 29.7014s/500 iters), loss = 0.142878
I0831 01:26:34.477277 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.142882 (* 1 = 0.142882 loss)
I0831 01:26:34.477288 916722 sgd_solver.cpp:106] Iteration 2398000, lr = 0.01
I0831 01:27:04.177770 916722 solver.cpp:218] Iteration 2398500 (16.8349 iter/s, 29.7002s/500 iters), loss = 0.112518
I0831 01:27:04.177827 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112522 (* 1 = 0.112522 loss)
I0831 01:27:04.177835 916722 sgd_solver.cpp:106] Iteration 2398500, lr = 0.01
I0831 01:27:33.876765 916722 solver.cpp:218] Iteration 2399000 (16.8358 iter/s, 29.6987s/500 iters), loss = 0.447018
I0831 01:27:33.876817 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.447022 (* 1 = 0.447022 loss)
I0831 01:27:33.876827 916722 sgd_solver.cpp:106] Iteration 2399000, lr = 0.01
I0831 01:28:03.573443 916722 solver.cpp:218] Iteration 2399500 (16.8371 iter/s, 29.6964s/500 iters), loss = 0.108915
I0831 01:28:03.573498 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.108919 (* 1 = 0.108919 loss)
I0831 01:28:03.573506 916722 sgd_solver.cpp:106] Iteration 2399500, lr = 0.01
I0831 01:28:33.219508 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_2400000.caffemodel
I0831 01:28:33.238541 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_2400000.solverstate
I0831 01:28:33.244663 916722 solver.cpp:330] Iteration 2400000, Testing net (#0)
I0831 01:28:48.583276 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8796
I0831 01:28:48.583325 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.401504 (* 1 = 0.401504 loss)
I0831 01:28:48.641734 916722 solver.cpp:218] Iteration 2400000 (11.0944 iter/s, 45.0679s/500 iters), loss = 0.0959316
I0831 01:28:48.641759 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0959358 (* 1 = 0.0959358 loss)
I0831 01:28:48.641768 916722 sgd_solver.cpp:106] Iteration 2400000, lr = 0.01
I0831 01:29:18.241045 916722 solver.cpp:218] Iteration 2400500 (16.8925 iter/s, 29.599s/500 iters), loss = 0.0829755
I0831 01:29:18.241101 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0829797 (* 1 = 0.0829797 loss)
I0831 01:29:18.241109 916722 sgd_solver.cpp:106] Iteration 2400500, lr = 0.01
I0831 01:29:47.854642 916722 solver.cpp:218] Iteration 2401000 (16.8843 iter/s, 29.6133s/500 iters), loss = 0.0514483
I0831 01:29:47.854699 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0514522 (* 1 = 0.0514522 loss)
I0831 01:29:47.854707 916722 sgd_solver.cpp:106] Iteration 2401000, lr = 0.01
I0831 01:30:17.543095 916722 solver.cpp:218] Iteration 2401500 (16.8417 iter/s, 29.6881s/500 iters), loss = 0.152933
I0831 01:30:17.543144 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152938 (* 1 = 0.152938 loss)
I0831 01:30:17.543164 916722 sgd_solver.cpp:106] Iteration 2401500, lr = 0.01
I0831 01:30:47.229682 916722 solver.cpp:218] Iteration 2402000 (16.8428 iter/s, 29.6863s/500 iters), loss = 0.0365497
I0831 01:30:47.229753 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0365538 (* 1 = 0.0365538 loss)
I0831 01:30:47.229761 916722 sgd_solver.cpp:106] Iteration 2402000, lr = 0.01
I0831 01:31:16.917491 916722 solver.cpp:218] Iteration 2402500 (16.842 iter/s, 29.6876s/500 iters), loss = 0.220909
I0831 01:31:16.917543 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.220913 (* 1 = 0.220913 loss)
I0831 01:31:16.917553 916722 sgd_solver.cpp:106] Iteration 2402500, lr = 0.01
I0831 01:31:46.605316 916722 solver.cpp:218] Iteration 2403000 (16.8416 iter/s, 29.6883s/500 iters), loss = 0.320833
I0831 01:31:46.605376 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.320837 (* 1 = 0.320837 loss)
I0831 01:31:46.605383 916722 sgd_solver.cpp:106] Iteration 2403000, lr = 0.01
I0831 01:32:16.290925 916722 solver.cpp:218] Iteration 2403500 (16.8429 iter/s, 29.6861s/500 iters), loss = 0.142306
I0831 01:32:16.290977 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.14231 (* 1 = 0.14231 loss)
I0831 01:32:16.290987 916722 sgd_solver.cpp:106] Iteration 2403500, lr = 0.01
I0831 01:32:45.980206 916722 solver.cpp:218] Iteration 2404000 (16.8408 iter/s, 29.6897s/500 iters), loss = 0.0160532
I0831 01:32:45.980265 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0160573 (* 1 = 0.0160573 loss)
I0831 01:32:45.980274 916722 sgd_solver.cpp:106] Iteration 2404000, lr = 0.01
I0831 01:33:15.680336 916722 solver.cpp:218] Iteration 2404500 (16.8347 iter/s, 29.7005s/500 iters), loss = 0.0194296
I0831 01:33:15.680393 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0194338 (* 1 = 0.0194338 loss)
I0831 01:33:15.680404 916722 sgd_solver.cpp:106] Iteration 2404500, lr = 0.01
I0831 01:33:45.410192 916722 solver.cpp:218] Iteration 2405000 (16.8179 iter/s, 29.7302s/500 iters), loss = 0.158627
I0831 01:33:45.410252 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.158632 (* 1 = 0.158632 loss)
I0831 01:33:45.410261 916722 sgd_solver.cpp:106] Iteration 2405000, lr = 0.01
I0831 01:34:15.142377 916722 solver.cpp:218] Iteration 2405500 (16.8166 iter/s, 29.7325s/500 iters), loss = 0.230039
I0831 01:34:15.142434 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.230043 (* 1 = 0.230043 loss)
I0831 01:34:15.142446 916722 sgd_solver.cpp:106] Iteration 2405500, lr = 0.01
I0831 01:34:44.868958 916722 solver.cpp:218] Iteration 2406000 (16.8198 iter/s, 29.7269s/500 iters), loss = 0.0909424
I0831 01:34:44.869025 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0909468 (* 1 = 0.0909468 loss)
I0831 01:34:44.869033 916722 sgd_solver.cpp:106] Iteration 2406000, lr = 0.01
I0831 01:35:14.596004 916722 solver.cpp:218] Iteration 2406500 (16.8195 iter/s, 29.7273s/500 iters), loss = 0.298928
I0831 01:35:14.596060 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.298932 (* 1 = 0.298932 loss)
I0831 01:35:14.596068 916722 sgd_solver.cpp:106] Iteration 2406500, lr = 0.01
I0831 01:35:44.317370 916722 solver.cpp:218] Iteration 2407000 (16.8228 iter/s, 29.7216s/500 iters), loss = 0.181649
I0831 01:35:44.317432 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.181653 (* 1 = 0.181653 loss)
I0831 01:35:44.317440 916722 sgd_solver.cpp:106] Iteration 2407000, lr = 0.01
I0831 01:36:14.041532 916722 solver.cpp:218] Iteration 2407500 (16.8212 iter/s, 29.7244s/500 iters), loss = 0.105596
I0831 01:36:14.041586 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.1056 (* 1 = 0.1056 loss)
I0831 01:36:14.041595 916722 sgd_solver.cpp:106] Iteration 2407500, lr = 0.01
I0831 01:36:43.767729 916722 solver.cpp:218] Iteration 2408000 (16.8201 iter/s, 29.7264s/500 iters), loss = 0.190967
I0831 01:36:43.767803 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.190972 (* 1 = 0.190972 loss)
I0831 01:36:43.767817 916722 sgd_solver.cpp:106] Iteration 2408000, lr = 0.01
I0831 01:37:13.493294 916722 solver.cpp:218] Iteration 2408500 (16.8204 iter/s, 29.7257s/500 iters), loss = 0.0741183
I0831 01:37:13.493348 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0741227 (* 1 = 0.0741227 loss)
I0831 01:37:13.493357 916722 sgd_solver.cpp:106] Iteration 2408500, lr = 0.01
I0831 01:37:43.219974 916722 solver.cpp:218] Iteration 2409000 (16.8198 iter/s, 29.7269s/500 iters), loss = 0.203144
I0831 01:37:43.220036 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.203148 (* 1 = 0.203148 loss)
I0831 01:37:43.220044 916722 sgd_solver.cpp:106] Iteration 2409000, lr = 0.01
I0831 01:38:12.938043 916722 solver.cpp:218] Iteration 2409500 (16.8247 iter/s, 29.7182s/500 iters), loss = 0.116779
I0831 01:38:12.938097 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.116784 (* 1 = 0.116784 loss)
I0831 01:38:12.938107 916722 sgd_solver.cpp:106] Iteration 2409500, lr = 0.01
I0831 01:38:42.657694 916722 solver.cpp:218] Iteration 2410000 (16.8238 iter/s, 29.7198s/500 iters), loss = 0.0639146
I0831 01:38:42.657753 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0639193 (* 1 = 0.0639193 loss)
I0831 01:38:42.657763 916722 sgd_solver.cpp:106] Iteration 2410000, lr = 0.01
I0831 01:39:12.373289 916722 solver.cpp:218] Iteration 2410500 (16.8261 iter/s, 29.7157s/500 iters), loss = 0.016306
I0831 01:39:12.373345 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0163108 (* 1 = 0.0163108 loss)
I0831 01:39:12.373353 916722 sgd_solver.cpp:106] Iteration 2410500, lr = 0.01
I0831 01:39:42.092850 916722 solver.cpp:218] Iteration 2411000 (16.8239 iter/s, 29.7197s/500 iters), loss = 0.195508
I0831 01:39:42.092911 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.195513 (* 1 = 0.195513 loss)
I0831 01:39:42.092919 916722 sgd_solver.cpp:106] Iteration 2411000, lr = 0.01
I0831 01:40:11.811241 916722 solver.cpp:218] Iteration 2411500 (16.8246 iter/s, 29.7185s/500 iters), loss = 0.167152
I0831 01:40:11.811295 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.167157 (* 1 = 0.167157 loss)
I0831 01:40:11.811304 916722 sgd_solver.cpp:106] Iteration 2411500, lr = 0.01
I0831 01:40:41.530012 916722 solver.cpp:218] Iteration 2412000 (16.8243 iter/s, 29.7188s/500 iters), loss = 0.216339
I0831 01:40:41.530076 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.216344 (* 1 = 0.216344 loss)
I0831 01:40:41.530084 916722 sgd_solver.cpp:106] Iteration 2412000, lr = 0.01
I0831 01:41:11.248802 916722 solver.cpp:218] Iteration 2412500 (16.8244 iter/s, 29.7188s/500 iters), loss = 0.159053
I0831 01:41:11.248858 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159058 (* 1 = 0.159058 loss)
I0831 01:41:11.248869 916722 sgd_solver.cpp:106] Iteration 2412500, lr = 0.01
I0831 01:41:40.982933 916722 solver.cpp:218] Iteration 2413000 (16.8157 iter/s, 29.7342s/500 iters), loss = 0.0547724
I0831 01:41:40.982997 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0547773 (* 1 = 0.0547773 loss)
I0831 01:41:40.983006 916722 sgd_solver.cpp:106] Iteration 2413000, lr = 0.01
I0831 01:42:10.714067 916722 solver.cpp:218] Iteration 2413500 (16.8174 iter/s, 29.7312s/500 iters), loss = 0.15146
I0831 01:42:10.714128 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.151464 (* 1 = 0.151464 loss)
I0831 01:42:10.714138 916722 sgd_solver.cpp:106] Iteration 2413500, lr = 0.01
I0831 01:42:40.444767 916722 solver.cpp:218] Iteration 2414000 (16.8176 iter/s, 29.7307s/500 iters), loss = 0.0675254
I0831 01:42:40.444824 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0675301 (* 1 = 0.0675301 loss)
I0831 01:42:40.444833 916722 sgd_solver.cpp:106] Iteration 2414000, lr = 0.01
I0831 01:43:10.175871 916722 solver.cpp:218] Iteration 2414500 (16.8174 iter/s, 29.7311s/500 iters), loss = 0.0514037
I0831 01:43:10.175921 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0514085 (* 1 = 0.0514085 loss)
I0831 01:43:10.175945 916722 sgd_solver.cpp:106] Iteration 2414500, lr = 0.01
I0831 01:43:39.907507 916722 solver.cpp:218] Iteration 2415000 (16.8171 iter/s, 29.7316s/500 iters), loss = 0.0771553
I0831 01:43:39.907578 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0771602 (* 1 = 0.0771602 loss)
I0831 01:43:39.907588 916722 sgd_solver.cpp:106] Iteration 2415000, lr = 0.01
I0831 01:44:09.639153 916722 solver.cpp:218] Iteration 2415500 (16.8171 iter/s, 29.7316s/500 iters), loss = 0.156065
I0831 01:44:09.639206 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.15607 (* 1 = 0.15607 loss)
I0831 01:44:09.639216 916722 sgd_solver.cpp:106] Iteration 2415500, lr = 0.01
I0831 01:44:39.372416 916722 solver.cpp:218] Iteration 2416000 (16.8162 iter/s, 29.7332s/500 iters), loss = 0.0156745
I0831 01:44:39.372486 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0156792 (* 1 = 0.0156792 loss)
I0831 01:44:39.372495 916722 sgd_solver.cpp:106] Iteration 2416000, lr = 0.01
I0831 01:45:09.104717 916722 solver.cpp:218] Iteration 2416500 (16.8168 iter/s, 29.7323s/500 iters), loss = 0.0679558
I0831 01:45:09.104782 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0679606 (* 1 = 0.0679606 loss)
I0831 01:45:09.104792 916722 sgd_solver.cpp:106] Iteration 2416500, lr = 0.01
I0831 01:45:38.840458 916722 solver.cpp:218] Iteration 2417000 (16.8148 iter/s, 29.7357s/500 iters), loss = 0.147405
I0831 01:45:38.840523 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.14741 (* 1 = 0.14741 loss)
I0831 01:45:38.840530 916722 sgd_solver.cpp:106] Iteration 2417000, lr = 0.01
I0831 01:46:08.574319 916722 solver.cpp:218] Iteration 2417500 (16.8159 iter/s, 29.7338s/500 iters), loss = 0.127165
I0831 01:46:08.574370 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.12717 (* 1 = 0.12717 loss)
I0831 01:46:08.574380 916722 sgd_solver.cpp:106] Iteration 2417500, lr = 0.01
I0831 01:46:38.302803 916722 solver.cpp:218] Iteration 2418000 (16.8189 iter/s, 29.7284s/500 iters), loss = 0.101019
I0831 01:46:38.302866 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101023 (* 1 = 0.101023 loss)
I0831 01:46:38.302875 916722 sgd_solver.cpp:106] Iteration 2418000, lr = 0.01
I0831 01:47:08.034888 916722 solver.cpp:218] Iteration 2418500 (16.8169 iter/s, 29.732s/500 iters), loss = 0.114451
I0831 01:47:08.034940 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.114456 (* 1 = 0.114456 loss)
I0831 01:47:08.034948 916722 sgd_solver.cpp:106] Iteration 2418500, lr = 0.01
I0831 01:47:37.763849 916722 solver.cpp:218] Iteration 2419000 (16.8187 iter/s, 29.7289s/500 iters), loss = 0.0639046
I0831 01:47:37.763908 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0639094 (* 1 = 0.0639094 loss)
I0831 01:47:37.763917 916722 sgd_solver.cpp:106] Iteration 2419000, lr = 0.01
I0831 01:48:07.496511 916722 solver.cpp:218] Iteration 2419500 (16.8166 iter/s, 29.7326s/500 iters), loss = 0.0995765
I0831 01:48:07.496565 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0995813 (* 1 = 0.0995813 loss)
I0831 01:48:07.496574 916722 sgd_solver.cpp:106] Iteration 2419500, lr = 0.01
I0831 01:48:37.227416 916722 solver.cpp:218] Iteration 2420000 (16.8176 iter/s, 29.7308s/500 iters), loss = 0.15447
I0831 01:48:37.227474 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.154475 (* 1 = 0.154475 loss)
I0831 01:48:37.227483 916722 sgd_solver.cpp:106] Iteration 2420000, lr = 0.01
I0831 01:49:06.958912 916722 solver.cpp:218] Iteration 2420500 (16.8172 iter/s, 29.7314s/500 iters), loss = 0.150075
I0831 01:49:06.958964 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.15008 (* 1 = 0.15008 loss)
I0831 01:49:06.958973 916722 sgd_solver.cpp:106] Iteration 2420500, lr = 0.01
I0831 01:49:36.694552 916722 solver.cpp:218] Iteration 2421000 (16.8149 iter/s, 29.7355s/500 iters), loss = 0.168735
I0831 01:49:36.694610 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.16874 (* 1 = 0.16874 loss)
I0831 01:49:36.694618 916722 sgd_solver.cpp:106] Iteration 2421000, lr = 0.01
I0831 01:50:06.429179 916722 solver.cpp:218] Iteration 2421500 (16.8155 iter/s, 29.7345s/500 iters), loss = 0.200334
I0831 01:50:06.429234 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.20034 (* 1 = 0.20034 loss)
I0831 01:50:06.429242 916722 sgd_solver.cpp:106] Iteration 2421500, lr = 0.01
I0831 01:50:36.164952 916722 solver.cpp:218] Iteration 2422000 (16.8148 iter/s, 29.7357s/500 iters), loss = 0.0967675
I0831 01:50:36.165024 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0967727 (* 1 = 0.0967727 loss)
I0831 01:50:36.165032 916722 sgd_solver.cpp:106] Iteration 2422000, lr = 0.01
I0831 01:51:05.901880 916722 solver.cpp:218] Iteration 2422500 (16.8142 iter/s, 29.7368s/500 iters), loss = 0.193982
I0831 01:51:05.901932 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.193988 (* 1 = 0.193988 loss)
I0831 01:51:05.901940 916722 sgd_solver.cpp:106] Iteration 2422500, lr = 0.01
I0831 01:51:35.638962 916722 solver.cpp:218] Iteration 2423000 (16.8141 iter/s, 29.737s/500 iters), loss = 0.291149
I0831 01:51:35.639021 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.291154 (* 1 = 0.291154 loss)
I0831 01:51:35.639029 916722 sgd_solver.cpp:106] Iteration 2423000, lr = 0.01
I0831 01:52:05.377092 916722 solver.cpp:218] Iteration 2423500 (16.8135 iter/s, 29.738s/500 iters), loss = 0.0905819
I0831 01:52:05.377146 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0905871 (* 1 = 0.0905871 loss)
I0831 01:52:05.377156 916722 sgd_solver.cpp:106] Iteration 2423500, lr = 0.01
I0831 01:52:35.106501 916722 solver.cpp:218] Iteration 2424000 (16.8184 iter/s, 29.7293s/500 iters), loss = 0.0580065
I0831 01:52:35.106561 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0580117 (* 1 = 0.0580117 loss)
I0831 01:52:35.106570 916722 sgd_solver.cpp:106] Iteration 2424000, lr = 0.01
I0831 01:53:04.845968 916722 solver.cpp:218] Iteration 2424500 (16.8127 iter/s, 29.7393s/500 iters), loss = 0.215537
I0831 01:53:04.846022 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.215542 (* 1 = 0.215542 loss)
I0831 01:53:04.846033 916722 sgd_solver.cpp:106] Iteration 2424500, lr = 0.01
I0831 01:53:34.581903 916722 solver.cpp:218] Iteration 2425000 (16.8147 iter/s, 29.7358s/500 iters), loss = 0.185336
I0831 01:53:34.581961 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.185341 (* 1 = 0.185341 loss)
I0831 01:53:34.581970 916722 sgd_solver.cpp:106] Iteration 2425000, lr = 0.01
I0831 01:54:04.313416 916722 solver.cpp:218] Iteration 2425500 (16.8172 iter/s, 29.7314s/500 iters), loss = 0.107319
I0831 01:54:04.313467 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.107324 (* 1 = 0.107324 loss)
I0831 01:54:04.313477 916722 sgd_solver.cpp:106] Iteration 2425500, lr = 0.01
I0831 01:54:34.047716 916722 solver.cpp:218] Iteration 2426000 (16.8157 iter/s, 29.7342s/500 iters), loss = 0.1253
I0831 01:54:34.047775 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.125305 (* 1 = 0.125305 loss)
I0831 01:54:34.047783 916722 sgd_solver.cpp:106] Iteration 2426000, lr = 0.01
I0831 01:55:03.779840 916722 solver.cpp:218] Iteration 2426500 (16.8169 iter/s, 29.732s/500 iters), loss = 0.302141
I0831 01:55:03.779893 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.302146 (* 1 = 0.302146 loss)
I0831 01:55:03.779903 916722 sgd_solver.cpp:106] Iteration 2426500, lr = 0.01
I0831 01:55:33.513942 916722 solver.cpp:218] Iteration 2427000 (16.8158 iter/s, 29.734s/500 iters), loss = 0.277241
I0831 01:55:33.513996 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.277246 (* 1 = 0.277246 loss)
I0831 01:55:33.514005 916722 sgd_solver.cpp:106] Iteration 2427000, lr = 0.01
I0831 01:56:03.248824 916722 solver.cpp:218] Iteration 2427500 (16.8153 iter/s, 29.7347s/500 iters), loss = 0.0603825
I0831 01:56:03.248878 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0603874 (* 1 = 0.0603874 loss)
I0831 01:56:03.248886 916722 sgd_solver.cpp:106] Iteration 2427500, lr = 0.01
I0831 01:56:32.982681 916722 solver.cpp:218] Iteration 2428000 (16.8159 iter/s, 29.7337s/500 iters), loss = 0.284214
I0831 01:56:32.982754 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.284219 (* 1 = 0.284219 loss)
I0831 01:56:32.982762 916722 sgd_solver.cpp:106] Iteration 2428000, lr = 0.01
I0831 01:57:02.720681 916722 solver.cpp:218] Iteration 2428500 (16.8136 iter/s, 29.7378s/500 iters), loss = 0.101878
I0831 01:57:02.720734 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101883 (* 1 = 0.101883 loss)
I0831 01:57:02.720742 916722 sgd_solver.cpp:106] Iteration 2428500, lr = 0.01
I0831 01:57:32.462013 916722 solver.cpp:218] Iteration 2429000 (16.8117 iter/s, 29.7412s/500 iters), loss = 0.156646
I0831 01:57:32.462075 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.156651 (* 1 = 0.156651 loss)
I0831 01:57:32.462083 916722 sgd_solver.cpp:106] Iteration 2429000, lr = 0.01
I0831 01:58:02.196336 916722 solver.cpp:218] Iteration 2429500 (16.8157 iter/s, 29.7342s/500 iters), loss = 0.11233
I0831 01:58:02.196393 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112335 (* 1 = 0.112335 loss)
I0831 01:58:02.196403 916722 sgd_solver.cpp:106] Iteration 2429500, lr = 0.01
I0831 01:58:31.929811 916722 solver.cpp:218] Iteration 2430000 (16.8162 iter/s, 29.7333s/500 iters), loss = 0.0546087
I0831 01:58:31.929867 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0546137 (* 1 = 0.0546137 loss)
I0831 01:58:31.929875 916722 sgd_solver.cpp:106] Iteration 2430000, lr = 0.01
I0831 01:59:01.667521 916722 solver.cpp:218] Iteration 2430500 (16.8138 iter/s, 29.7376s/500 iters), loss = 0.0352411
I0831 01:59:01.667574 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0352463 (* 1 = 0.0352463 loss)
I0831 01:59:01.667584 916722 sgd_solver.cpp:106] Iteration 2430500, lr = 0.01
I0831 01:59:31.407037 916722 solver.cpp:218] Iteration 2431000 (16.8127 iter/s, 29.7394s/500 iters), loss = 0.0482669
I0831 01:59:31.407095 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0482722 (* 1 = 0.0482722 loss)
I0831 01:59:31.407104 916722 sgd_solver.cpp:106] Iteration 2431000, lr = 0.01
I0831 02:00:01.142261 916722 solver.cpp:218] Iteration 2431500 (16.8152 iter/s, 29.7351s/500 iters), loss = 0.0610732
I0831 02:00:01.142311 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0610787 (* 1 = 0.0610787 loss)
I0831 02:00:01.142321 916722 sgd_solver.cpp:106] Iteration 2431500, lr = 0.01
I0831 02:00:30.880093 916722 solver.cpp:218] Iteration 2432000 (16.8137 iter/s, 29.7377s/500 iters), loss = 0.137313
I0831 02:00:30.880153 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.137318 (* 1 = 0.137318 loss)
I0831 02:00:30.880162 916722 sgd_solver.cpp:106] Iteration 2432000, lr = 0.01
I0831 02:01:00.613981 916722 solver.cpp:218] Iteration 2432500 (16.8159 iter/s, 29.7337s/500 iters), loss = 0.099648
I0831 02:01:00.614032 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0996534 (* 1 = 0.0996534 loss)
I0831 02:01:00.614043 916722 sgd_solver.cpp:106] Iteration 2432500, lr = 0.01
I0831 02:01:30.344192 916722 solver.cpp:218] Iteration 2433000 (16.818 iter/s, 29.73s/500 iters), loss = 0.0140014
I0831 02:01:30.344252 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0140067 (* 1 = 0.0140067 loss)
I0831 02:01:30.344261 916722 sgd_solver.cpp:106] Iteration 2433000, lr = 0.01
I0831 02:02:00.077562 916722 solver.cpp:218] Iteration 2433500 (16.8162 iter/s, 29.7332s/500 iters), loss = 0.176634
I0831 02:02:00.077616 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.176639 (* 1 = 0.176639 loss)
I0831 02:02:00.077626 916722 sgd_solver.cpp:106] Iteration 2433500, lr = 0.01
I0831 02:02:29.810719 916722 solver.cpp:218] Iteration 2434000 (16.8163 iter/s, 29.733s/500 iters), loss = 0.19171
I0831 02:02:29.810782 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.191716 (* 1 = 0.191716 loss)
I0831 02:02:29.810791 916722 sgd_solver.cpp:106] Iteration 2434000, lr = 0.01
I0831 02:02:59.542809 916722 solver.cpp:218] Iteration 2434500 (16.8169 iter/s, 29.7319s/500 iters), loss = 0.286165
I0831 02:02:59.542870 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.286171 (* 1 = 0.286171 loss)
I0831 02:02:59.542878 916722 sgd_solver.cpp:106] Iteration 2434500, lr = 0.01
I0831 02:03:29.280130 916722 solver.cpp:218] Iteration 2435000 (16.814 iter/s, 29.7372s/500 iters), loss = 0.140396
I0831 02:03:29.280211 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.140401 (* 1 = 0.140401 loss)
I0831 02:03:29.280220 916722 sgd_solver.cpp:106] Iteration 2435000, lr = 0.01
I0831 02:03:59.017464 916722 solver.cpp:218] Iteration 2435500 (16.814 iter/s, 29.7371s/500 iters), loss = 0.0632028
I0831 02:03:59.017519 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.063208 (* 1 = 0.063208 loss)
I0831 02:03:59.017529 916722 sgd_solver.cpp:106] Iteration 2435500, lr = 0.01
I0831 02:04:28.753363 916722 solver.cpp:218] Iteration 2436000 (16.8148 iter/s, 29.7357s/500 iters), loss = 0.0738494
I0831 02:04:28.753425 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0738544 (* 1 = 0.0738544 loss)
I0831 02:04:28.753433 916722 sgd_solver.cpp:106] Iteration 2436000, lr = 0.01
I0831 02:04:58.487433 916722 solver.cpp:218] Iteration 2436500 (16.8158 iter/s, 29.7339s/500 iters), loss = 0.135299
I0831 02:04:58.487488 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.135304 (* 1 = 0.135304 loss)
I0831 02:04:58.487496 916722 sgd_solver.cpp:106] Iteration 2436500, lr = 0.01
I0831 02:05:28.223587 916722 solver.cpp:218] Iteration 2437000 (16.8146 iter/s, 29.736s/500 iters), loss = 0.0128176
I0831 02:05:28.223647 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0128228 (* 1 = 0.0128228 loss)
I0831 02:05:28.223656 916722 sgd_solver.cpp:106] Iteration 2437000, lr = 0.01
I0831 02:05:57.958920 916722 solver.cpp:218] Iteration 2437500 (16.815 iter/s, 29.7354s/500 iters), loss = 0.129674
I0831 02:05:57.958976 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.129679 (* 1 = 0.129679 loss)
I0831 02:05:57.958984 916722 sgd_solver.cpp:106] Iteration 2437500, lr = 0.01
I0831 02:06:27.697991 916722 solver.cpp:218] Iteration 2438000 (16.8129 iter/s, 29.7391s/500 iters), loss = 0.0461158
I0831 02:06:27.698052 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0461208 (* 1 = 0.0461208 loss)
I0831 02:06:27.698061 916722 sgd_solver.cpp:106] Iteration 2438000, lr = 0.01
I0831 02:06:57.432063 916722 solver.cpp:218] Iteration 2438500 (16.8157 iter/s, 29.7341s/500 iters), loss = 0.0751709
I0831 02:06:57.432117 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0751759 (* 1 = 0.0751759 loss)
I0831 02:06:57.432126 916722 sgd_solver.cpp:106] Iteration 2438500, lr = 0.01
I0831 02:07:27.163954 916722 solver.cpp:218] Iteration 2439000 (16.8169 iter/s, 29.7319s/500 iters), loss = 0.514463
I0831 02:07:27.164016 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.514468 (* 1 = 0.514468 loss)
I0831 02:07:27.164024 916722 sgd_solver.cpp:106] Iteration 2439000, lr = 0.01
I0831 02:07:56.895608 916722 solver.cpp:218] Iteration 2439500 (16.8171 iter/s, 29.7317s/500 iters), loss = 0.0490863
I0831 02:07:56.895664 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0490914 (* 1 = 0.0490914 loss)
I0831 02:07:56.895675 916722 sgd_solver.cpp:106] Iteration 2439500, lr = 0.01
I0831 02:08:26.634833 916722 solver.cpp:218] Iteration 2440000 (16.8128 iter/s, 29.7392s/500 iters), loss = 0.162152
I0831 02:08:26.634892 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.162157 (* 1 = 0.162157 loss)
I0831 02:08:26.634900 916722 sgd_solver.cpp:106] Iteration 2440000, lr = 0.01
I0831 02:08:56.372715 916722 solver.cpp:218] Iteration 2440500 (16.8136 iter/s, 29.7379s/500 iters), loss = 0.180591
I0831 02:08:56.372787 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.180596 (* 1 = 0.180596 loss)
I0831 02:08:56.372797 916722 sgd_solver.cpp:106] Iteration 2440500, lr = 0.01
I0831 02:09:26.109112 916722 solver.cpp:218] Iteration 2441000 (16.8144 iter/s, 29.7364s/500 iters), loss = 0.193054
I0831 02:09:26.109186 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.193059 (* 1 = 0.193059 loss)
I0831 02:09:26.109195 916722 sgd_solver.cpp:106] Iteration 2441000, lr = 0.01
I0831 02:09:55.846647 916722 solver.cpp:218] Iteration 2441500 (16.8138 iter/s, 29.7375s/500 iters), loss = 0.14563
I0831 02:09:55.846699 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.145635 (* 1 = 0.145635 loss)
I0831 02:09:55.846709 916722 sgd_solver.cpp:106] Iteration 2441500, lr = 0.01
I0831 02:10:25.585408 916722 solver.cpp:218] Iteration 2442000 (16.8131 iter/s, 29.7387s/500 iters), loss = 0.186486
I0831 02:10:25.585467 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.186491 (* 1 = 0.186491 loss)
I0831 02:10:25.585475 916722 sgd_solver.cpp:106] Iteration 2442000, lr = 0.01
I0831 02:10:55.316777 916722 solver.cpp:218] Iteration 2442500 (16.8173 iter/s, 29.7313s/500 iters), loss = 0.260747
I0831 02:10:55.316833 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.260752 (* 1 = 0.260752 loss)
I0831 02:10:55.316843 916722 sgd_solver.cpp:106] Iteration 2442500, lr = 0.01
I0831 02:11:25.049129 916722 solver.cpp:218] Iteration 2443000 (16.8167 iter/s, 29.7323s/500 iters), loss = 0.159953
I0831 02:11:25.049187 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159958 (* 1 = 0.159958 loss)
I0831 02:11:25.049196 916722 sgd_solver.cpp:106] Iteration 2443000, lr = 0.01
I0831 02:11:54.782444 916722 solver.cpp:218] Iteration 2443500 (16.8162 iter/s, 29.7333s/500 iters), loss = 0.121008
I0831 02:11:54.782493 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.121013 (* 1 = 0.121013 loss)
I0831 02:11:54.782503 916722 sgd_solver.cpp:106] Iteration 2443500, lr = 0.01
I0831 02:12:24.513901 916722 solver.cpp:218] Iteration 2444000 (16.8172 iter/s, 29.7314s/500 iters), loss = 0.1031
I0831 02:12:24.513960 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.103105 (* 1 = 0.103105 loss)
I0831 02:12:24.513968 916722 sgd_solver.cpp:106] Iteration 2444000, lr = 0.01
I0831 02:12:54.251070 916722 solver.cpp:218] Iteration 2444500 (16.814 iter/s, 29.7371s/500 iters), loss = 0.390527
I0831 02:12:54.251122 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.390532 (* 1 = 0.390532 loss)
I0831 02:12:54.251132 916722 sgd_solver.cpp:106] Iteration 2444500, lr = 0.01
I0831 02:13:23.982378 916722 solver.cpp:218] Iteration 2445000 (16.8173 iter/s, 29.7312s/500 iters), loss = 0.123856
I0831 02:13:23.982441 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.123861 (* 1 = 0.123861 loss)
I0831 02:13:23.982450 916722 sgd_solver.cpp:106] Iteration 2445000, lr = 0.01
I0831 02:13:53.712844 916722 solver.cpp:218] Iteration 2445500 (16.8178 iter/s, 29.7304s/500 iters), loss = 0.06425
I0831 02:13:53.712898 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0642546 (* 1 = 0.0642546 loss)
I0831 02:13:53.712908 916722 sgd_solver.cpp:106] Iteration 2445500, lr = 0.01
I0831 02:14:23.443995 916722 solver.cpp:218] Iteration 2446000 (16.8174 iter/s, 29.7311s/500 iters), loss = 0.0374467
I0831 02:14:23.444054 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0374512 (* 1 = 0.0374512 loss)
I0831 02:14:23.444063 916722 sgd_solver.cpp:106] Iteration 2446000, lr = 0.01
I0831 02:14:53.178515 916722 solver.cpp:218] Iteration 2446500 (16.8155 iter/s, 29.7344s/500 iters), loss = 0.337203
I0831 02:14:53.178568 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.337208 (* 1 = 0.337208 loss)
I0831 02:14:53.178577 916722 sgd_solver.cpp:106] Iteration 2446500, lr = 0.01
I0831 02:15:22.911187 916722 solver.cpp:218] Iteration 2447000 (16.8166 iter/s, 29.7326s/500 iters), loss = 0.0819182
I0831 02:15:22.911247 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0819226 (* 1 = 0.0819226 loss)
I0831 02:15:22.911255 916722 sgd_solver.cpp:106] Iteration 2447000, lr = 0.01
I0831 02:15:52.644182 916722 solver.cpp:218] Iteration 2447500 (16.8164 iter/s, 29.7329s/500 iters), loss = 0.121531
I0831 02:15:52.644233 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.121536 (* 1 = 0.121536 loss)
I0831 02:15:52.644254 916722 sgd_solver.cpp:106] Iteration 2447500, lr = 0.01
I0831 02:16:22.374701 916722 solver.cpp:218] Iteration 2448000 (16.8178 iter/s, 29.7304s/500 iters), loss = 0.00901556
I0831 02:16:22.374769 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.00901989 (* 1 = 0.00901989 loss)
I0831 02:16:22.374778 916722 sgd_solver.cpp:106] Iteration 2448000, lr = 0.01
I0831 02:16:52.104858 916722 solver.cpp:218] Iteration 2448500 (16.818 iter/s, 29.73s/500 iters), loss = 0.192281
I0831 02:16:52.104912 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.192285 (* 1 = 0.192285 loss)
I0831 02:16:52.104921 916722 sgd_solver.cpp:106] Iteration 2448500, lr = 0.01
I0831 02:17:21.838241 916722 solver.cpp:218] Iteration 2449000 (16.8162 iter/s, 29.7333s/500 iters), loss = 0.22815
I0831 02:17:21.838304 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.228155 (* 1 = 0.228155 loss)
I0831 02:17:21.838312 916722 sgd_solver.cpp:106] Iteration 2449000, lr = 0.01
I0831 02:17:51.558907 916722 solver.cpp:218] Iteration 2449500 (16.8234 iter/s, 29.7206s/500 iters), loss = 0.115551
I0831 02:17:51.558964 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115555 (* 1 = 0.115555 loss)
I0831 02:17:51.558974 916722 sgd_solver.cpp:106] Iteration 2449500, lr = 0.01
I0831 02:18:21.210008 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_2450000.caffemodel
I0831 02:18:21.229387 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_2450000.solverstate
I0831 02:18:21.235651 916722 solver.cpp:330] Iteration 2450000, Testing net (#0)
I0831 02:18:36.584288 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8934
I0831 02:18:36.584331 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.367066 (* 1 = 0.367066 loss)
I0831 02:18:36.642993 916722 solver.cpp:218] Iteration 2450000 (11.0904 iter/s, 45.084s/500 iters), loss = 0.170847
I0831 02:18:36.643020 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.170851 (* 1 = 0.170851 loss)
I0831 02:18:36.643028 916722 sgd_solver.cpp:106] Iteration 2450000, lr = 0.01
I0831 02:19:06.248334 916722 solver.cpp:218] Iteration 2450500 (16.8889 iter/s, 29.6052s/500 iters), loss = 0.0214687
I0831 02:19:06.248396 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.021473 (* 1 = 0.021473 loss)
I0831 02:19:06.248404 916722 sgd_solver.cpp:106] Iteration 2450500, lr = 0.01
I0831 02:19:35.910970 916722 solver.cpp:218] Iteration 2451000 (16.8563 iter/s, 29.6625s/500 iters), loss = 0.205407
I0831 02:19:35.911023 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.205411 (* 1 = 0.205411 loss)
I0831 02:19:35.911033 916722 sgd_solver.cpp:106] Iteration 2451000, lr = 0.01
I0831 02:20:05.622684 916722 solver.cpp:218] Iteration 2451500 (16.8285 iter/s, 29.7116s/500 iters), loss = 0.126359
I0831 02:20:05.622745 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.126363 (* 1 = 0.126363 loss)
I0831 02:20:05.622754 916722 sgd_solver.cpp:106] Iteration 2451500, lr = 0.01
I0831 02:20:35.334722 916722 solver.cpp:218] Iteration 2452000 (16.8283 iter/s, 29.7119s/500 iters), loss = 0.160738
I0831 02:20:35.334774 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.160743 (* 1 = 0.160743 loss)
I0831 02:20:35.334784 916722 sgd_solver.cpp:106] Iteration 2452000, lr = 0.01
I0831 02:21:05.043650 916722 solver.cpp:218] Iteration 2452500 (16.83 iter/s, 29.7088s/500 iters), loss = 0.346399
I0831 02:21:05.043709 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.346404 (* 1 = 0.346404 loss)
I0831 02:21:05.043717 916722 sgd_solver.cpp:106] Iteration 2452500, lr = 0.01
I0831 02:21:34.755537 916722 solver.cpp:218] Iteration 2453000 (16.8284 iter/s, 29.7118s/500 iters), loss = 0.167438
I0831 02:21:34.755589 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.167443 (* 1 = 0.167443 loss)
I0831 02:21:34.755599 916722 sgd_solver.cpp:106] Iteration 2453000, lr = 0.01
I0831 02:22:04.467310 916722 solver.cpp:218] Iteration 2453500 (16.8284 iter/s, 29.7116s/500 iters), loss = 0.0734266
I0831 02:22:04.467382 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0734308 (* 1 = 0.0734308 loss)
I0831 02:22:04.467391 916722 sgd_solver.cpp:106] Iteration 2453500, lr = 0.01
I0831 02:22:34.178884 916722 solver.cpp:218] Iteration 2454000 (16.8285 iter/s, 29.7114s/500 iters), loss = 0.17025
I0831 02:22:34.178936 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.170254 (* 1 = 0.170254 loss)
I0831 02:22:34.178946 916722 sgd_solver.cpp:106] Iteration 2454000, lr = 0.01
I0831 02:23:03.890347 916722 solver.cpp:218] Iteration 2454500 (16.8286 iter/s, 29.7113s/500 iters), loss = 0.0746337
I0831 02:23:03.890403 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.074638 (* 1 = 0.074638 loss)
I0831 02:23:03.890411 916722 sgd_solver.cpp:106] Iteration 2454500, lr = 0.01
I0831 02:23:33.603323 916722 solver.cpp:218] Iteration 2455000 (16.8277 iter/s, 29.7129s/500 iters), loss = 0.103369
I0831 02:23:33.603379 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.103374 (* 1 = 0.103374 loss)
I0831 02:23:33.603389 916722 sgd_solver.cpp:106] Iteration 2455000, lr = 0.01
I0831 02:24:03.316273 916722 solver.cpp:218] Iteration 2455500 (16.8278 iter/s, 29.7128s/500 iters), loss = 0.0903642
I0831 02:24:03.316334 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0903686 (* 1 = 0.0903686 loss)
I0831 02:24:03.316342 916722 sgd_solver.cpp:106] Iteration 2455500, lr = 0.01
I0831 02:24:33.028908 916722 solver.cpp:218] Iteration 2456000 (16.8279 iter/s, 29.7125s/500 iters), loss = 0.135686
I0831 02:24:33.028961 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13569 (* 1 = 0.13569 loss)
I0831 02:24:33.028970 916722 sgd_solver.cpp:106] Iteration 2456000, lr = 0.01
I0831 02:25:02.741155 916722 solver.cpp:218] Iteration 2456500 (16.8281 iter/s, 29.7121s/500 iters), loss = 0.0691134
I0831 02:25:02.741214 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0691179 (* 1 = 0.0691179 loss)
I0831 02:25:02.741221 916722 sgd_solver.cpp:106] Iteration 2456500, lr = 0.01
I0831 02:25:32.457476 916722 solver.cpp:218] Iteration 2457000 (16.8258 iter/s, 29.7162s/500 iters), loss = 0.13445
I0831 02:25:32.457531 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.134455 (* 1 = 0.134455 loss)
I0831 02:25:32.457541 916722 sgd_solver.cpp:106] Iteration 2457000, lr = 0.01
I0831 02:26:02.171768 916722 solver.cpp:218] Iteration 2457500 (16.827 iter/s, 29.7142s/500 iters), loss = 0.104404
I0831 02:26:02.171828 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104409 (* 1 = 0.104409 loss)
I0831 02:26:02.171836 916722 sgd_solver.cpp:106] Iteration 2457500, lr = 0.01
I0831 02:26:31.886561 916722 solver.cpp:218] Iteration 2458000 (16.8267 iter/s, 29.7146s/500 iters), loss = 0.177021
I0831 02:26:31.886615 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.177025 (* 1 = 0.177025 loss)
I0831 02:26:31.886624 916722 sgd_solver.cpp:106] Iteration 2458000, lr = 0.01
I0831 02:27:01.602535 916722 solver.cpp:218] Iteration 2458500 (16.826 iter/s, 29.7158s/500 iters), loss = 0.095748
I0831 02:27:01.602594 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0957525 (* 1 = 0.0957525 loss)
I0831 02:27:01.602602 916722 sgd_solver.cpp:106] Iteration 2458500, lr = 0.01
I0831 02:27:31.320519 916722 solver.cpp:218] Iteration 2459000 (16.8249 iter/s, 29.7178s/500 iters), loss = 0.146325
I0831 02:27:31.320569 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.14633 (* 1 = 0.14633 loss)
I0831 02:27:31.320578 916722 sgd_solver.cpp:106] Iteration 2459000, lr = 0.01
I0831 02:28:01.033843 916722 solver.cpp:218] Iteration 2459500 (16.8275 iter/s, 29.7132s/500 iters), loss = 0.412356
I0831 02:28:01.033901 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.412361 (* 1 = 0.412361 loss)
I0831 02:28:01.033910 916722 sgd_solver.cpp:106] Iteration 2459500, lr = 0.01
I0831 02:28:30.747614 916722 solver.cpp:218] Iteration 2460000 (16.8273 iter/s, 29.7136s/500 iters), loss = 0.31881
I0831 02:28:30.747669 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.318815 (* 1 = 0.318815 loss)
I0831 02:28:30.747678 916722 sgd_solver.cpp:106] Iteration 2460000, lr = 0.01
I0831 02:29:00.461796 916722 solver.cpp:218] Iteration 2460500 (16.8271 iter/s, 29.714s/500 iters), loss = 0.171433
I0831 02:29:00.461863 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.171438 (* 1 = 0.171438 loss)
I0831 02:29:00.461872 916722 sgd_solver.cpp:106] Iteration 2460500, lr = 0.01
I0831 02:29:30.181406 916722 solver.cpp:218] Iteration 2461000 (16.824 iter/s, 29.7194s/500 iters), loss = 0.374111
I0831 02:29:30.181461 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.374116 (* 1 = 0.374116 loss)
I0831 02:29:30.181471 916722 sgd_solver.cpp:106] Iteration 2461000, lr = 0.01
I0831 02:29:59.902812 916722 solver.cpp:218] Iteration 2461500 (16.823 iter/s, 29.7213s/500 iters), loss = 0.263467
I0831 02:29:59.902873 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.263472 (* 1 = 0.263472 loss)
I0831 02:29:59.902881 916722 sgd_solver.cpp:106] Iteration 2461500, lr = 0.01
I0831 02:30:29.622771 916722 solver.cpp:218] Iteration 2462000 (16.8238 iter/s, 29.7198s/500 iters), loss = 0.236353
I0831 02:30:29.622825 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.236358 (* 1 = 0.236358 loss)
I0831 02:30:29.622835 916722 sgd_solver.cpp:106] Iteration 2462000, lr = 0.01
I0831 02:30:59.341521 916722 solver.cpp:218] Iteration 2462500 (16.8245 iter/s, 29.7186s/500 iters), loss = 0.353632
I0831 02:30:59.341579 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.353637 (* 1 = 0.353637 loss)
I0831 02:30:59.341588 916722 sgd_solver.cpp:106] Iteration 2462500, lr = 0.01
I0831 02:31:29.056597 916722 solver.cpp:218] Iteration 2463000 (16.8266 iter/s, 29.7149s/500 iters), loss = 0.166925
I0831 02:31:29.056648 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.16693 (* 1 = 0.16693 loss)
I0831 02:31:29.056658 916722 sgd_solver.cpp:106] Iteration 2463000, lr = 0.01
I0831 02:31:58.770005 916722 solver.cpp:218] Iteration 2463500 (16.8275 iter/s, 29.7133s/500 iters), loss = 0.272825
I0831 02:31:58.770058 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.27283 (* 1 = 0.27283 loss)
I0831 02:31:58.770067 916722 sgd_solver.cpp:106] Iteration 2463500, lr = 0.01
I0831 02:32:28.486469 916722 solver.cpp:218] Iteration 2464000 (16.8258 iter/s, 29.7163s/500 iters), loss = 0.168192
I0831 02:32:28.486524 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.168197 (* 1 = 0.168197 loss)
I0831 02:32:28.486534 916722 sgd_solver.cpp:106] Iteration 2464000, lr = 0.01
I0831 02:32:58.203438 916722 solver.cpp:218] Iteration 2464500 (16.8255 iter/s, 29.7168s/500 iters), loss = 0.165712
I0831 02:32:58.203497 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.165717 (* 1 = 0.165717 loss)
I0831 02:32:58.203505 916722 sgd_solver.cpp:106] Iteration 2464500, lr = 0.01
I0831 02:33:27.921041 916722 solver.cpp:218] Iteration 2465000 (16.8251 iter/s, 29.7175s/500 iters), loss = 0.15335
I0831 02:33:27.921094 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.153355 (* 1 = 0.153355 loss)
I0831 02:33:27.921104 916722 sgd_solver.cpp:106] Iteration 2465000, lr = 0.01
I0831 02:33:57.637378 916722 solver.cpp:218] Iteration 2465500 (16.8258 iter/s, 29.7162s/500 iters), loss = 0.289957
I0831 02:33:57.637436 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.289962 (* 1 = 0.289962 loss)
I0831 02:33:57.637445 916722 sgd_solver.cpp:106] Iteration 2465500, lr = 0.01
I0831 02:34:27.357579 916722 solver.cpp:218] Iteration 2466000 (16.8237 iter/s, 29.7201s/500 iters), loss = 0.0650191
I0831 02:34:27.357633 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0650239 (* 1 = 0.0650239 loss)
I0831 02:34:27.357645 916722 sgd_solver.cpp:106] Iteration 2466000, lr = 0.01
I0831 02:34:57.072031 916722 solver.cpp:218] Iteration 2466500 (16.8269 iter/s, 29.7143s/500 iters), loss = 0.0633983
I0831 02:34:57.072113 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0634031 (* 1 = 0.0634031 loss)
I0831 02:34:57.072120 916722 sgd_solver.cpp:106] Iteration 2466500, lr = 0.01
I0831 02:35:26.786000 916722 solver.cpp:218] Iteration 2467000 (16.8272 iter/s, 29.7138s/500 iters), loss = 0.18665
I0831 02:35:26.786053 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.186655 (* 1 = 0.186655 loss)
I0831 02:35:26.786062 916722 sgd_solver.cpp:106] Iteration 2467000, lr = 0.01
I0831 02:35:56.501837 916722 solver.cpp:218] Iteration 2467500 (16.8261 iter/s, 29.7157s/500 iters), loss = 0.138825
I0831 02:35:56.501894 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.138829 (* 1 = 0.138829 loss)
I0831 02:35:56.501904 916722 sgd_solver.cpp:106] Iteration 2467500, lr = 0.01
I0831 02:36:26.220494 916722 solver.cpp:218] Iteration 2468000 (16.8245 iter/s, 29.7185s/500 iters), loss = 0.0384171
I0831 02:36:26.220542 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.038422 (* 1 = 0.038422 loss)
I0831 02:36:26.220551 916722 sgd_solver.cpp:106] Iteration 2468000, lr = 0.01
I0831 02:36:55.936136 916722 solver.cpp:218] Iteration 2468500 (16.8262 iter/s, 29.7155s/500 iters), loss = 0.536809
I0831 02:36:55.936197 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.536814 (* 1 = 0.536814 loss)
I0831 02:36:55.936204 916722 sgd_solver.cpp:106] Iteration 2468500, lr = 0.01
I0831 02:37:25.652020 916722 solver.cpp:218] Iteration 2469000 (16.8261 iter/s, 29.7157s/500 iters), loss = 0.228655
I0831 02:37:25.652073 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.22866 (* 1 = 0.22866 loss)
I0831 02:37:25.652081 916722 sgd_solver.cpp:106] Iteration 2469000, lr = 0.01
I0831 02:37:55.369372 916722 solver.cpp:218] Iteration 2469500 (16.8253 iter/s, 29.7172s/500 iters), loss = 0.0736349
I0831 02:37:55.369433 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0736398 (* 1 = 0.0736398 loss)
I0831 02:37:55.369442 916722 sgd_solver.cpp:106] Iteration 2469500, lr = 0.01
I0831 02:38:25.087069 916722 solver.cpp:218] Iteration 2470000 (16.8251 iter/s, 29.7175s/500 iters), loss = 0.106396
I0831 02:38:25.087126 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.106401 (* 1 = 0.106401 loss)
I0831 02:38:25.087134 916722 sgd_solver.cpp:106] Iteration 2470000, lr = 0.01
I0831 02:38:54.801151 916722 solver.cpp:218] Iteration 2470500 (16.8271 iter/s, 29.7139s/500 iters), loss = 0.0489388
I0831 02:38:54.801210 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0489436 (* 1 = 0.0489436 loss)
I0831 02:38:54.801219 916722 sgd_solver.cpp:106] Iteration 2470500, lr = 0.01
I0831 02:39:24.516492 916722 solver.cpp:218] Iteration 2471000 (16.8264 iter/s, 29.7152s/500 iters), loss = 0.12629
I0831 02:39:24.516547 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.126294 (* 1 = 0.126294 loss)
I0831 02:39:24.516558 916722 sgd_solver.cpp:106] Iteration 2471000, lr = 0.01
I0831 02:39:54.229986 916722 solver.cpp:218] Iteration 2471500 (16.8275 iter/s, 29.7133s/500 iters), loss = 0.256748
I0831 02:39:54.230041 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.256752 (* 1 = 0.256752 loss)
I0831 02:39:54.230051 916722 sgd_solver.cpp:106] Iteration 2471500, lr = 0.01
I0831 02:40:23.942981 916722 solver.cpp:218] Iteration 2472000 (16.8278 iter/s, 29.7128s/500 iters), loss = 0.0154298
I0831 02:40:23.943033 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0154347 (* 1 = 0.0154347 loss)
I0831 02:40:23.943042 916722 sgd_solver.cpp:106] Iteration 2472000, lr = 0.01
I0831 02:40:53.660697 916722 solver.cpp:218] Iteration 2472500 (16.8251 iter/s, 29.7175s/500 iters), loss = 0.191037
I0831 02:40:53.660759 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.191041 (* 1 = 0.191041 loss)
I0831 02:40:53.660768 916722 sgd_solver.cpp:106] Iteration 2472500, lr = 0.01
I0831 02:41:23.377722 916722 solver.cpp:218] Iteration 2473000 (16.8255 iter/s, 29.7168s/500 iters), loss = 0.0764314
I0831 02:41:23.377791 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0764361 (* 1 = 0.0764361 loss)
I0831 02:41:23.377800 916722 sgd_solver.cpp:106] Iteration 2473000, lr = 0.01
I0831 02:41:53.097366 916722 solver.cpp:218] Iteration 2473500 (16.824 iter/s, 29.7194s/500 iters), loss = 0.0281602
I0831 02:41:53.097440 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0281648 (* 1 = 0.0281648 loss)
I0831 02:41:53.097447 916722 sgd_solver.cpp:106] Iteration 2473500, lr = 0.01
I0831 02:42:22.811980 916722 solver.cpp:218] Iteration 2474000 (16.8269 iter/s, 29.7144s/500 iters), loss = 0.228641
I0831 02:42:22.812034 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.228645 (* 1 = 0.228645 loss)
I0831 02:42:22.812043 916722 sgd_solver.cpp:106] Iteration 2474000, lr = 0.01
I0831 02:42:52.530107 916722 solver.cpp:218] Iteration 2474500 (16.8249 iter/s, 29.7179s/500 iters), loss = 0.21446
I0831 02:42:52.530166 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.214464 (* 1 = 0.214464 loss)
I0831 02:42:52.530175 916722 sgd_solver.cpp:106] Iteration 2474500, lr = 0.01
I0831 02:43:22.242287 916722 solver.cpp:218] Iteration 2475000 (16.8282 iter/s, 29.712s/500 iters), loss = 0.22106
I0831 02:43:22.242342 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.221064 (* 1 = 0.221064 loss)
I0831 02:43:22.242352 916722 sgd_solver.cpp:106] Iteration 2475000, lr = 0.01
I0831 02:43:51.955237 916722 solver.cpp:218] Iteration 2475500 (16.8278 iter/s, 29.7127s/500 iters), loss = 0.181071
I0831 02:43:51.955299 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.181075 (* 1 = 0.181075 loss)
I0831 02:43:51.955308 916722 sgd_solver.cpp:106] Iteration 2475500, lr = 0.01
I0831 02:44:21.668901 916722 solver.cpp:218] Iteration 2476000 (16.8274 iter/s, 29.7134s/500 iters), loss = 0.187088
I0831 02:44:21.668958 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.187092 (* 1 = 0.187092 loss)
I0831 02:44:21.668968 916722 sgd_solver.cpp:106] Iteration 2476000, lr = 0.01
I0831 02:44:51.386232 916722 solver.cpp:218] Iteration 2476500 (16.8253 iter/s, 29.7171s/500 iters), loss = 0.412747
I0831 02:44:51.386294 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.412752 (* 1 = 0.412752 loss)
I0831 02:44:51.386302 916722 sgd_solver.cpp:106] Iteration 2476500, lr = 0.01
I0831 02:45:21.099864 916722 solver.cpp:218] Iteration 2477000 (16.8274 iter/s, 29.7134s/500 iters), loss = 0.44281
I0831 02:45:21.099920 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.442815 (* 1 = 0.442815 loss)
I0831 02:45:21.099929 916722 sgd_solver.cpp:106] Iteration 2477000, lr = 0.01
I0831 02:45:50.813751 916722 solver.cpp:218] Iteration 2477500 (16.8273 iter/s, 29.7137s/500 iters), loss = 0.238433
I0831 02:45:50.813812 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.238438 (* 1 = 0.238438 loss)
I0831 02:45:50.813822 916722 sgd_solver.cpp:106] Iteration 2477500, lr = 0.01
I0831 02:46:20.529680 916722 solver.cpp:218] Iteration 2478000 (16.8261 iter/s, 29.7157s/500 iters), loss = 0.133007
I0831 02:46:20.529733 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133011 (* 1 = 0.133011 loss)
I0831 02:46:20.529743 916722 sgd_solver.cpp:106] Iteration 2478000, lr = 0.01
I0831 02:46:50.244168 916722 solver.cpp:218] Iteration 2478500 (16.8269 iter/s, 29.7143s/500 iters), loss = 0.111949
I0831 02:46:50.244227 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111954 (* 1 = 0.111954 loss)
I0831 02:46:50.244236 916722 sgd_solver.cpp:106] Iteration 2478500, lr = 0.01
I0831 02:47:19.957777 916722 solver.cpp:218] Iteration 2479000 (16.8274 iter/s, 29.7134s/500 iters), loss = 0.139946
I0831 02:47:19.957830 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139951 (* 1 = 0.139951 loss)
I0831 02:47:19.957840 916722 sgd_solver.cpp:106] Iteration 2479000, lr = 0.01
I0831 02:47:49.672835 916722 solver.cpp:218] Iteration 2479500 (16.8266 iter/s, 29.7149s/500 iters), loss = 0.159722
I0831 02:47:49.672909 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159726 (* 1 = 0.159726 loss)
I0831 02:47:49.672922 916722 sgd_solver.cpp:106] Iteration 2479500, lr = 0.01
I0831 02:48:19.383338 916722 solver.cpp:218] Iteration 2480000 (16.8292 iter/s, 29.7103s/500 iters), loss = 0.126209
I0831 02:48:19.383392 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.126214 (* 1 = 0.126214 loss)
I0831 02:48:19.383404 916722 sgd_solver.cpp:106] Iteration 2480000, lr = 0.01
I0831 02:48:49.098040 916722 solver.cpp:218] Iteration 2480500 (16.8268 iter/s, 29.7145s/500 iters), loss = 0.14007
I0831 02:48:49.098101 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.140074 (* 1 = 0.140074 loss)
I0831 02:48:49.098109 916722 sgd_solver.cpp:106] Iteration 2480500, lr = 0.01
I0831 02:49:18.812638 916722 solver.cpp:218] Iteration 2481000 (16.8269 iter/s, 29.7144s/500 iters), loss = 0.148278
I0831 02:49:18.812690 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.148282 (* 1 = 0.148282 loss)
I0831 02:49:18.812700 916722 sgd_solver.cpp:106] Iteration 2481000, lr = 0.01
I0831 02:49:48.522876 916722 solver.cpp:218] Iteration 2481500 (16.8293 iter/s, 29.7101s/500 iters), loss = 0.0565774
I0831 02:49:48.522938 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0565814 (* 1 = 0.0565814 loss)
I0831 02:49:48.522946 916722 sgd_solver.cpp:106] Iteration 2481500, lr = 0.01
I0831 02:50:18.234783 916722 solver.cpp:218] Iteration 2482000 (16.8284 iter/s, 29.7117s/500 iters), loss = 0.042543
I0831 02:50:18.234838 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.042547 (* 1 = 0.042547 loss)
I0831 02:50:18.234846 916722 sgd_solver.cpp:106] Iteration 2482000, lr = 0.01
I0831 02:50:47.944752 916722 solver.cpp:218] Iteration 2482500 (16.8295 iter/s, 29.7098s/500 iters), loss = 0.0128838
I0831 02:50:47.944813 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0128878 (* 1 = 0.0128878 loss)
I0831 02:50:47.944823 916722 sgd_solver.cpp:106] Iteration 2482500, lr = 0.01
I0831 02:51:17.658005 916722 solver.cpp:218] Iteration 2483000 (16.8276 iter/s, 29.7131s/500 iters), loss = 0.0482424
I0831 02:51:17.658057 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0482464 (* 1 = 0.0482464 loss)
I0831 02:51:17.658066 916722 sgd_solver.cpp:106] Iteration 2483000, lr = 0.01
I0831 02:51:47.372745 916722 solver.cpp:218] Iteration 2483500 (16.8268 iter/s, 29.7146s/500 iters), loss = 0.0638736
I0831 02:51:47.372803 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0638777 (* 1 = 0.0638777 loss)
I0831 02:51:47.372812 916722 sgd_solver.cpp:106] Iteration 2483500, lr = 0.01
I0831 02:52:17.087013 916722 solver.cpp:218] Iteration 2484000 (16.827 iter/s, 29.7141s/500 iters), loss = 0.0126792
I0831 02:52:17.087069 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0126834 (* 1 = 0.0126834 loss)
I0831 02:52:17.087077 916722 sgd_solver.cpp:106] Iteration 2484000, lr = 0.01
I0831 02:52:46.798808 916722 solver.cpp:218] Iteration 2484500 (16.8284 iter/s, 29.7116s/500 iters), loss = 0.230039
I0831 02:52:46.798871 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.230043 (* 1 = 0.230043 loss)
I0831 02:52:46.798879 916722 sgd_solver.cpp:106] Iteration 2484500, lr = 0.01
I0831 02:53:16.511373 916722 solver.cpp:218] Iteration 2485000 (16.828 iter/s, 29.7124s/500 iters), loss = 0.0679656
I0831 02:53:16.511428 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0679696 (* 1 = 0.0679696 loss)
I0831 02:53:16.511437 916722 sgd_solver.cpp:106] Iteration 2485000, lr = 0.01
I0831 02:53:46.223402 916722 solver.cpp:218] Iteration 2485500 (16.8283 iter/s, 29.7119s/500 iters), loss = 0.267606
I0831 02:53:46.223464 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.26761 (* 1 = 0.26761 loss)
I0831 02:53:46.223472 916722 sgd_solver.cpp:106] Iteration 2485500, lr = 0.01
I0831 02:54:15.933285 916722 solver.cpp:218] Iteration 2486000 (16.8295 iter/s, 29.7097s/500 iters), loss = 0.0837525
I0831 02:54:15.933339 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0837567 (* 1 = 0.0837567 loss)
I0831 02:54:15.933359 916722 sgd_solver.cpp:106] Iteration 2486000, lr = 0.01
I0831 02:54:45.643975 916722 solver.cpp:218] Iteration 2486500 (16.8291 iter/s, 29.7105s/500 iters), loss = 0.052415
I0831 02:54:45.644047 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0524191 (* 1 = 0.0524191 loss)
I0831 02:54:45.644055 916722 sgd_solver.cpp:106] Iteration 2486500, lr = 0.01
I0831 02:55:15.353260 916722 solver.cpp:218] Iteration 2487000 (16.8299 iter/s, 29.7091s/500 iters), loss = 0.0860956
I0831 02:55:15.353317 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0860995 (* 1 = 0.0860995 loss)
I0831 02:55:15.353327 916722 sgd_solver.cpp:106] Iteration 2487000, lr = 0.01
I0831 02:55:45.067296 916722 solver.cpp:218] Iteration 2487500 (16.8272 iter/s, 29.7139s/500 iters), loss = 0.14094
I0831 02:55:45.067353 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.140944 (* 1 = 0.140944 loss)
I0831 02:55:45.067361 916722 sgd_solver.cpp:106] Iteration 2487500, lr = 0.01
I0831 02:56:14.777802 916722 solver.cpp:218] Iteration 2488000 (16.8292 iter/s, 29.7103s/500 iters), loss = 0.444589
I0831 02:56:14.777851 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.444593 (* 1 = 0.444593 loss)
I0831 02:56:14.777861 916722 sgd_solver.cpp:106] Iteration 2488000, lr = 0.01
I0831 02:56:44.490262 916722 solver.cpp:218] Iteration 2488500 (16.8281 iter/s, 29.7123s/500 iters), loss = 0.1417
I0831 02:56:44.490321 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.141705 (* 1 = 0.141705 loss)
I0831 02:56:44.490329 916722 sgd_solver.cpp:106] Iteration 2488500, lr = 0.01
I0831 02:57:14.204093 916722 solver.cpp:218] Iteration 2489000 (16.8273 iter/s, 29.7137s/500 iters), loss = 0.264698
I0831 02:57:14.204149 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.264702 (* 1 = 0.264702 loss)
I0831 02:57:14.204159 916722 sgd_solver.cpp:106] Iteration 2489000, lr = 0.01
I0831 02:57:43.916646 916722 solver.cpp:218] Iteration 2489500 (16.828 iter/s, 29.7124s/500 iters), loss = 0.160056
I0831 02:57:43.916705 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.16006 (* 1 = 0.16006 loss)
I0831 02:57:43.916713 916722 sgd_solver.cpp:106] Iteration 2489500, lr = 0.01
I0831 02:58:13.632242 916722 solver.cpp:218] Iteration 2490000 (16.8263 iter/s, 29.7154s/500 iters), loss = 0.0977291
I0831 02:58:13.632297 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0977331 (* 1 = 0.0977331 loss)
I0831 02:58:13.632308 916722 sgd_solver.cpp:106] Iteration 2490000, lr = 0.01
I0831 02:58:43.351431 916722 solver.cpp:218] Iteration 2490500 (16.8242 iter/s, 29.719s/500 iters), loss = 0.212183
I0831 02:58:43.351492 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.212187 (* 1 = 0.212187 loss)
I0831 02:58:43.351501 916722 sgd_solver.cpp:106] Iteration 2490500, lr = 0.01
I0831 02:59:13.065582 916722 solver.cpp:218] Iteration 2491000 (16.8271 iter/s, 29.714s/500 iters), loss = 0.212467
I0831 02:59:13.065634 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.212472 (* 1 = 0.212472 loss)
I0831 02:59:13.065644 916722 sgd_solver.cpp:106] Iteration 2491000, lr = 0.01
I0831 02:59:42.779085 916722 solver.cpp:218] Iteration 2491500 (16.8275 iter/s, 29.7133s/500 iters), loss = 0.0667319
I0831 02:59:42.779145 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0667362 (* 1 = 0.0667362 loss)
I0831 02:59:42.779153 916722 sgd_solver.cpp:106] Iteration 2491500, lr = 0.01
I0831 03:00:12.493778 916722 solver.cpp:218] Iteration 2492000 (16.8268 iter/s, 29.7145s/500 iters), loss = 0.134745
I0831 03:00:12.493830 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13475 (* 1 = 0.13475 loss)
I0831 03:00:12.493840 916722 sgd_solver.cpp:106] Iteration 2492000, lr = 0.01
I0831 03:00:42.221700 916722 solver.cpp:218] Iteration 2492500 (16.8193 iter/s, 29.7277s/500 iters), loss = 0.184269
I0831 03:00:42.221771 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.184273 (* 1 = 0.184273 loss)
I0831 03:00:42.221786 916722 sgd_solver.cpp:106] Iteration 2492500, lr = 0.01
I0831 03:01:11.946442 916722 solver.cpp:218] Iteration 2493000 (16.8211 iter/s, 29.7246s/500 iters), loss = 0.265188
I0831 03:01:11.946496 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.265192 (* 1 = 0.265192 loss)
I0831 03:01:11.946506 916722 sgd_solver.cpp:106] Iteration 2493000, lr = 0.01
I0831 03:01:41.669092 916722 solver.cpp:218] Iteration 2493500 (16.8223 iter/s, 29.7225s/500 iters), loss = 0.058292
I0831 03:01:41.669150 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0582961 (* 1 = 0.0582961 loss)
I0831 03:01:41.669159 916722 sgd_solver.cpp:106] Iteration 2493500, lr = 0.01
I0831 03:02:11.395579 916722 solver.cpp:218] Iteration 2494000 (16.8201 iter/s, 29.7263s/500 iters), loss = 0.175628
I0831 03:02:11.395634 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.175632 (* 1 = 0.175632 loss)
I0831 03:02:11.395644 916722 sgd_solver.cpp:106] Iteration 2494000, lr = 0.01
I0831 03:02:41.119652 916722 solver.cpp:218] Iteration 2494500 (16.8215 iter/s, 29.7239s/500 iters), loss = 0.0962292
I0831 03:02:41.119712 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0962334 (* 1 = 0.0962334 loss)
I0831 03:02:41.119721 916722 sgd_solver.cpp:106] Iteration 2494500, lr = 0.01
I0831 03:03:10.844799 916722 solver.cpp:218] Iteration 2495000 (16.8209 iter/s, 29.725s/500 iters), loss = 0.0360887
I0831 03:03:10.844854 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0360929 (* 1 = 0.0360929 loss)
I0831 03:03:10.844864 916722 sgd_solver.cpp:106] Iteration 2495000, lr = 0.01
I0831 03:03:40.572175 916722 solver.cpp:218] Iteration 2495500 (16.8196 iter/s, 29.7272s/500 iters), loss = 0.407411
I0831 03:03:40.572233 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.407415 (* 1 = 0.407415 loss)
I0831 03:03:40.572242 916722 sgd_solver.cpp:106] Iteration 2495500, lr = 0.01
I0831 03:04:10.297727 916722 solver.cpp:218] Iteration 2496000 (16.8206 iter/s, 29.7254s/500 iters), loss = 0.0825455
I0831 03:04:10.297781 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0825497 (* 1 = 0.0825497 loss)
I0831 03:04:10.297792 916722 sgd_solver.cpp:106] Iteration 2496000, lr = 0.01
I0831 03:04:40.026736 916722 solver.cpp:218] Iteration 2496500 (16.8187 iter/s, 29.7288s/500 iters), loss = 0.118828
I0831 03:04:40.026795 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.118832 (* 1 = 0.118832 loss)
I0831 03:04:40.026804 916722 sgd_solver.cpp:106] Iteration 2496500, lr = 0.01
I0831 03:05:09.752210 916722 solver.cpp:218] Iteration 2497000 (16.8207 iter/s, 29.7253s/500 iters), loss = 0.226314
I0831 03:05:09.752261 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.226318 (* 1 = 0.226318 loss)
I0831 03:05:09.752271 916722 sgd_solver.cpp:106] Iteration 2497000, lr = 0.01
I0831 03:05:39.481350 916722 solver.cpp:218] Iteration 2497500 (16.8186 iter/s, 29.729s/500 iters), loss = 0.0594229
I0831 03:05:39.481415 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0594269 (* 1 = 0.0594269 loss)
I0831 03:05:39.481424 916722 sgd_solver.cpp:106] Iteration 2497500, lr = 0.01
I0831 03:06:09.203601 916722 solver.cpp:218] Iteration 2498000 (16.8225 iter/s, 29.7221s/500 iters), loss = 0.0373528
I0831 03:06:09.203655 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0373569 (* 1 = 0.0373569 loss)
I0831 03:06:09.203665 916722 sgd_solver.cpp:106] Iteration 2498000, lr = 0.01
I0831 03:06:38.926398 916722 solver.cpp:218] Iteration 2498500 (16.8222 iter/s, 29.7226s/500 iters), loss = 0.133818
I0831 03:06:38.926458 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133822 (* 1 = 0.133822 loss)
I0831 03:06:38.926467 916722 sgd_solver.cpp:106] Iteration 2498500, lr = 0.01
I0831 03:07:08.654042 916722 solver.cpp:218] Iteration 2499000 (16.8195 iter/s, 29.7275s/500 iters), loss = 0.118873
I0831 03:07:08.654096 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.118877 (* 1 = 0.118877 loss)
I0831 03:07:08.654105 916722 sgd_solver.cpp:106] Iteration 2499000, lr = 0.01
I0831 03:07:38.377107 916722 solver.cpp:218] Iteration 2499500 (16.822 iter/s, 29.7229s/500 iters), loss = 0.141408
I0831 03:07:38.377179 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.141412 (* 1 = 0.141412 loss)
I0831 03:07:38.377187 916722 sgd_solver.cpp:106] Iteration 2499500, lr = 0.01
I0831 03:08:08.045892 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_2500000.caffemodel
I0831 03:08:08.065302 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_2500000.solverstate
I0831 03:08:08.071410 916722 solver.cpp:330] Iteration 2500000, Testing net (#0)
I0831 03:08:23.508656 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8998
I0831 03:08:23.508714 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.353276 (* 1 = 0.353276 loss)
I0831 03:08:23.567317 916722 solver.cpp:218] Iteration 2500000 (11.0644 iter/s, 45.19s/500 iters), loss = 0.110063
I0831 03:08:23.567344 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110067 (* 1 = 0.110067 loss)
I0831 03:08:23.567353 916722 sgd_solver.cpp:106] Iteration 2500000, lr = 0.01
I0831 03:08:53.191152 916722 solver.cpp:218] Iteration 2500500 (16.8784 iter/s, 29.6236s/500 iters), loss = 0.141091
I0831 03:08:53.191206 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.141095 (* 1 = 0.141095 loss)
I0831 03:08:53.191215 916722 sgd_solver.cpp:106] Iteration 2500500, lr = 0.01
I0831 03:09:22.897478 916722 solver.cpp:218] Iteration 2501000 (16.8315 iter/s, 29.7061s/500 iters), loss = 0.186651
I0831 03:09:22.897540 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.186655 (* 1 = 0.186655 loss)
I0831 03:09:22.897549 916722 sgd_solver.cpp:106] Iteration 2501000, lr = 0.01
I0831 03:09:52.643296 916722 solver.cpp:218] Iteration 2501500 (16.8092 iter/s, 29.7456s/500 iters), loss = 0.258692
I0831 03:09:52.643354 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.258696 (* 1 = 0.258696 loss)
I0831 03:09:52.643364 916722 sgd_solver.cpp:106] Iteration 2501500, lr = 0.01
I0831 03:10:22.397789 916722 solver.cpp:218] Iteration 2502000 (16.8043 iter/s, 29.7543s/500 iters), loss = 0.0511708
I0831 03:10:22.397850 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.051175 (* 1 = 0.051175 loss)
I0831 03:10:22.397857 916722 sgd_solver.cpp:106] Iteration 2502000, lr = 0.01
I0831 03:10:52.143649 916722 solver.cpp:218] Iteration 2502500 (16.8092 iter/s, 29.7457s/500 iters), loss = 0.0426544
I0831 03:10:52.143709 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0426586 (* 1 = 0.0426586 loss)
I0831 03:10:52.143719 916722 sgd_solver.cpp:106] Iteration 2502500, lr = 0.01
I0831 03:11:21.898717 916722 solver.cpp:218] Iteration 2503000 (16.804 iter/s, 29.7549s/500 iters), loss = 0.360008
I0831 03:11:21.898775 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.360012 (* 1 = 0.360012 loss)
I0831 03:11:21.898784 916722 sgd_solver.cpp:106] Iteration 2503000, lr = 0.01
I0831 03:11:51.652632 916722 solver.cpp:218] Iteration 2503500 (16.8046 iter/s, 29.7537s/500 iters), loss = 0.0627013
I0831 03:11:51.652684 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0627056 (* 1 = 0.0627056 loss)
I0831 03:11:51.652695 916722 sgd_solver.cpp:106] Iteration 2503500, lr = 0.01
I0831 03:12:21.407805 916722 solver.cpp:218] Iteration 2504000 (16.8039 iter/s, 29.755s/500 iters), loss = 0.136081
I0831 03:12:21.407861 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.136085 (* 1 = 0.136085 loss)
I0831 03:12:21.407871 916722 sgd_solver.cpp:106] Iteration 2504000, lr = 0.01
I0831 03:12:51.160351 916722 solver.cpp:218] Iteration 2504500 (16.8054 iter/s, 29.7524s/500 iters), loss = 0.130626
I0831 03:12:51.160405 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13063 (* 1 = 0.13063 loss)
I0831 03:12:51.160416 916722 sgd_solver.cpp:106] Iteration 2504500, lr = 0.01
I0831 03:13:20.915597 916722 solver.cpp:218] Iteration 2505000 (16.8039 iter/s, 29.7551s/500 iters), loss = 0.462025
I0831 03:13:20.915673 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.46203 (* 1 = 0.46203 loss)
I0831 03:13:20.915681 916722 sgd_solver.cpp:106] Iteration 2505000, lr = 0.01
I0831 03:13:50.672338 916722 solver.cpp:218] Iteration 2505500 (16.8031 iter/s, 29.7565s/500 iters), loss = 0.0329063
I0831 03:13:50.672392 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0329104 (* 1 = 0.0329104 loss)
I0831 03:13:50.672402 916722 sgd_solver.cpp:106] Iteration 2505500, lr = 0.01
I0831 03:14:20.427913 916722 solver.cpp:218] Iteration 2506000 (16.8038 iter/s, 29.7552s/500 iters), loss = 0.218679
I0831 03:14:20.427973 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.218683 (* 1 = 0.218683 loss)
I0831 03:14:20.427981 916722 sgd_solver.cpp:106] Iteration 2506000, lr = 0.01
I0831 03:14:50.181875 916722 solver.cpp:218] Iteration 2506500 (16.8047 iter/s, 29.7536s/500 iters), loss = 0.219827
I0831 03:14:50.181929 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.219831 (* 1 = 0.219831 loss)
I0831 03:14:50.181939 916722 sgd_solver.cpp:106] Iteration 2506500, lr = 0.01
I0831 03:15:19.937007 916722 solver.cpp:218] Iteration 2507000 (16.804 iter/s, 29.7548s/500 iters), loss = 0.118076
I0831 03:15:19.937067 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.118081 (* 1 = 0.118081 loss)
I0831 03:15:19.937075 916722 sgd_solver.cpp:106] Iteration 2507000, lr = 0.01
I0831 03:15:49.694772 916722 solver.cpp:218] Iteration 2507500 (16.8025 iter/s, 29.7574s/500 iters), loss = 0.357853
I0831 03:15:49.694823 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.357857 (* 1 = 0.357857 loss)
I0831 03:15:49.694833 916722 sgd_solver.cpp:106] Iteration 2507500, lr = 0.01
I0831 03:16:19.445574 916722 solver.cpp:218] Iteration 2508000 (16.8065 iter/s, 29.7505s/500 iters), loss = 0.406276
I0831 03:16:19.445629 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.40628 (* 1 = 0.40628 loss)
I0831 03:16:19.445637 916722 sgd_solver.cpp:106] Iteration 2508000, lr = 0.01
I0831 03:16:49.205909 916722 solver.cpp:218] Iteration 2508500 (16.8011 iter/s, 29.76s/500 iters), loss = 0.0522367
I0831 03:16:49.205960 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0522408 (* 1 = 0.0522408 loss)
I0831 03:16:49.205969 916722 sgd_solver.cpp:106] Iteration 2508500, lr = 0.01
I0831 03:17:18.963608 916722 solver.cpp:218] Iteration 2509000 (16.8025 iter/s, 29.7574s/500 iters), loss = 0.165692
I0831 03:17:18.963670 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.165696 (* 1 = 0.165696 loss)
I0831 03:17:18.963678 916722 sgd_solver.cpp:106] Iteration 2509000, lr = 0.01
I0831 03:17:48.728588 916722 solver.cpp:218] Iteration 2509500 (16.7984 iter/s, 29.7647s/500 iters), loss = 0.318731
I0831 03:17:48.728646 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.318736 (* 1 = 0.318736 loss)
I0831 03:17:48.728655 916722 sgd_solver.cpp:106] Iteration 2509500, lr = 0.01
I0831 03:18:18.475678 916722 solver.cpp:218] Iteration 2510000 (16.8085 iter/s, 29.7468s/500 iters), loss = 0.292529
I0831 03:18:18.475740 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.292533 (* 1 = 0.292533 loss)
I0831 03:18:18.475749 916722 sgd_solver.cpp:106] Iteration 2510000, lr = 0.01
I0831 03:18:48.226773 916722 solver.cpp:218] Iteration 2510500 (16.8063 iter/s, 29.7508s/500 iters), loss = 0.335249
I0831 03:18:48.226827 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.335253 (* 1 = 0.335253 loss)
I0831 03:18:48.226837 916722 sgd_solver.cpp:106] Iteration 2510500, lr = 0.01
I0831 03:19:17.981765 916722 solver.cpp:218] Iteration 2511000 (16.8041 iter/s, 29.7547s/500 iters), loss = 0.0466135
I0831 03:19:17.981827 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0466178 (* 1 = 0.0466178 loss)
I0831 03:19:17.981837 916722 sgd_solver.cpp:106] Iteration 2511000, lr = 0.01
I0831 03:19:47.730262 916722 solver.cpp:218] Iteration 2511500 (16.8077 iter/s, 29.7482s/500 iters), loss = 0.109504
I0831 03:19:47.730329 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109508 (* 1 = 0.109508 loss)
I0831 03:19:47.730350 916722 sgd_solver.cpp:106] Iteration 2511500, lr = 0.01
I0831 03:20:17.484943 916722 solver.cpp:218] Iteration 2512000 (16.8042 iter/s, 29.7544s/500 iters), loss = 0.204476
I0831 03:20:17.485014 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.20448 (* 1 = 0.20448 loss)
I0831 03:20:17.485023 916722 sgd_solver.cpp:106] Iteration 2512000, lr = 0.01
I0831 03:20:47.236274 916722 solver.cpp:218] Iteration 2512500 (16.8061 iter/s, 29.751s/500 iters), loss = 0.088615
I0831 03:20:47.236325 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0886195 (* 1 = 0.0886195 loss)
I0831 03:20:47.236335 916722 sgd_solver.cpp:106] Iteration 2512500, lr = 0.01
I0831 03:21:17.002626 916722 solver.cpp:218] Iteration 2513000 (16.7976 iter/s, 29.7661s/500 iters), loss = 0.165908
I0831 03:21:17.002688 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.165913 (* 1 = 0.165913 loss)
I0831 03:21:17.002697 916722 sgd_solver.cpp:106] Iteration 2513000, lr = 0.01
I0831 03:21:46.754081 916722 solver.cpp:218] Iteration 2513500 (16.8061 iter/s, 29.7512s/500 iters), loss = 0.229112
I0831 03:21:46.754135 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.229117 (* 1 = 0.229117 loss)
I0831 03:21:46.754144 916722 sgd_solver.cpp:106] Iteration 2513500, lr = 0.01
I0831 03:22:16.510637 916722 solver.cpp:218] Iteration 2514000 (16.8032 iter/s, 29.7563s/500 iters), loss = 0.197699
I0831 03:22:16.510699 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.197703 (* 1 = 0.197703 loss)
I0831 03:22:16.510708 916722 sgd_solver.cpp:106] Iteration 2514000, lr = 0.01
I0831 03:22:46.262209 916722 solver.cpp:218] Iteration 2514500 (16.806 iter/s, 29.7513s/500 iters), loss = 0.15096
I0831 03:22:46.262264 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.150965 (* 1 = 0.150965 loss)
I0831 03:22:46.262272 916722 sgd_solver.cpp:106] Iteration 2514500, lr = 0.01
I0831 03:23:16.005945 916722 solver.cpp:218] Iteration 2515000 (16.8104 iter/s, 29.7435s/500 iters), loss = 0.155601
I0831 03:23:16.006006 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.155606 (* 1 = 0.155606 loss)
I0831 03:23:16.006013 916722 sgd_solver.cpp:106] Iteration 2515000, lr = 0.01
I0831 03:23:45.746837 916722 solver.cpp:218] Iteration 2515500 (16.812 iter/s, 29.7406s/500 iters), loss = 0.0934876
I0831 03:23:45.746891 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0934922 (* 1 = 0.0934922 loss)
I0831 03:23:45.746901 916722 sgd_solver.cpp:106] Iteration 2515500, lr = 0.01
I0831 03:24:15.488793 916722 solver.cpp:218] Iteration 2516000 (16.8114 iter/s, 29.7417s/500 iters), loss = 0.116326
I0831 03:24:15.488855 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.116331 (* 1 = 0.116331 loss)
I0831 03:24:15.488863 916722 sgd_solver.cpp:106] Iteration 2516000, lr = 0.01
I0831 03:24:45.242888 916722 solver.cpp:218] Iteration 2516500 (16.8046 iter/s, 29.7538s/500 iters), loss = 0.126795
I0831 03:24:45.242945 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.1268 (* 1 = 0.1268 loss)
I0831 03:24:45.242956 916722 sgd_solver.cpp:106] Iteration 2516500, lr = 0.01
I0831 03:25:14.997802 916722 solver.cpp:218] Iteration 2517000 (16.8041 iter/s, 29.7547s/500 iters), loss = 0.256782
I0831 03:25:14.997861 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.256787 (* 1 = 0.256787 loss)
I0831 03:25:14.997870 916722 sgd_solver.cpp:106] Iteration 2517000, lr = 0.01
I0831 03:25:44.744410 916722 solver.cpp:218] Iteration 2517500 (16.8088 iter/s, 29.7464s/500 iters), loss = 0.125342
I0831 03:25:44.744489 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.125347 (* 1 = 0.125347 loss)
I0831 03:25:44.744501 916722 sgd_solver.cpp:106] Iteration 2517500, lr = 0.01
I0831 03:26:14.492084 916722 solver.cpp:218] Iteration 2518000 (16.8082 iter/s, 29.7474s/500 iters), loss = 0.049981
I0831 03:26:14.492157 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0499858 (* 1 = 0.0499858 loss)
I0831 03:26:14.492170 916722 sgd_solver.cpp:106] Iteration 2518000, lr = 0.01
I0831 03:26:44.235998 916722 solver.cpp:218] Iteration 2518500 (16.8103 iter/s, 29.7437s/500 iters), loss = 0.120011
I0831 03:26:44.236054 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.120016 (* 1 = 0.120016 loss)
I0831 03:26:44.236064 916722 sgd_solver.cpp:106] Iteration 2518500, lr = 0.01
I0831 03:27:13.978526 916722 solver.cpp:218] Iteration 2519000 (16.8111 iter/s, 29.7423s/500 iters), loss = 0.383143
I0831 03:27:13.978587 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.383148 (* 1 = 0.383148 loss)
I0831 03:27:13.978595 916722 sgd_solver.cpp:106] Iteration 2519000, lr = 0.01
I0831 03:27:43.726263 916722 solver.cpp:218] Iteration 2519500 (16.8081 iter/s, 29.7475s/500 iters), loss = 0.0893138
I0831 03:27:43.726318 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0893188 (* 1 = 0.0893188 loss)
I0831 03:27:43.726328 916722 sgd_solver.cpp:106] Iteration 2519500, lr = 0.01
I0831 03:28:13.475080 916722 solver.cpp:218] Iteration 2520000 (16.8075 iter/s, 29.7486s/500 iters), loss = 0.0958907
I0831 03:28:13.475140 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0958958 (* 1 = 0.0958958 loss)
I0831 03:28:13.475149 916722 sgd_solver.cpp:106] Iteration 2520000, lr = 0.01
I0831 03:28:43.224171 916722 solver.cpp:218] Iteration 2520500 (16.8074 iter/s, 29.7489s/500 iters), loss = 0.135956
I0831 03:28:43.224225 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.135962 (* 1 = 0.135962 loss)
I0831 03:28:43.224234 916722 sgd_solver.cpp:106] Iteration 2520500, lr = 0.01
I0831 03:29:12.971803 916722 solver.cpp:218] Iteration 2521000 (16.8082 iter/s, 29.7474s/500 iters), loss = 0.0875171
I0831 03:29:12.971863 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0875223 (* 1 = 0.0875223 loss)
I0831 03:29:12.971871 916722 sgd_solver.cpp:106] Iteration 2521000, lr = 0.01
I0831 03:29:42.722959 916722 solver.cpp:218] Iteration 2521500 (16.8062 iter/s, 29.7509s/500 iters), loss = 0.133909
I0831 03:29:42.723008 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133914 (* 1 = 0.133914 loss)
I0831 03:29:42.723018 916722 sgd_solver.cpp:106] Iteration 2521500, lr = 0.01
I0831 03:30:12.474602 916722 solver.cpp:218] Iteration 2522000 (16.8059 iter/s, 29.7514s/500 iters), loss = 0.0664453
I0831 03:30:12.474661 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0664503 (* 1 = 0.0664503 loss)
I0831 03:30:12.474669 916722 sgd_solver.cpp:106] Iteration 2522000, lr = 0.01
I0831 03:30:42.231432 916722 solver.cpp:218] Iteration 2522500 (16.803 iter/s, 29.7566s/500 iters), loss = 0.160822
I0831 03:30:42.231484 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.160827 (* 1 = 0.160827 loss)
I0831 03:30:42.231493 916722 sgd_solver.cpp:106] Iteration 2522500, lr = 0.01
I0831 03:31:11.983583 916722 solver.cpp:218] Iteration 2523000 (16.8056 iter/s, 29.7519s/500 iters), loss = 0.355529
I0831 03:31:11.983644 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.355534 (* 1 = 0.355534 loss)
I0831 03:31:11.983651 916722 sgd_solver.cpp:106] Iteration 2523000, lr = 0.01
I0831 03:31:41.731925 916722 solver.cpp:218] Iteration 2523500 (16.8078 iter/s, 29.7481s/500 iters), loss = 0.0600774
I0831 03:31:41.731979 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0600822 (* 1 = 0.0600822 loss)
I0831 03:31:41.731988 916722 sgd_solver.cpp:106] Iteration 2523500, lr = 0.01
I0831 03:32:11.480799 916722 solver.cpp:218] Iteration 2524000 (16.8075 iter/s, 29.7487s/500 iters), loss = 0.0421853
I0831 03:32:11.480859 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.04219 (* 1 = 0.04219 loss)
I0831 03:32:11.480868 916722 sgd_solver.cpp:106] Iteration 2524000, lr = 0.01
I0831 03:32:41.235312 916722 solver.cpp:218] Iteration 2524500 (16.8043 iter/s, 29.7543s/500 iters), loss = 0.0798565
I0831 03:32:41.235365 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0798611 (* 1 = 0.0798611 loss)
I0831 03:32:41.235388 916722 sgd_solver.cpp:106] Iteration 2524500, lr = 0.01
I0831 03:33:10.986158 916722 solver.cpp:218] Iteration 2525000 (16.8064 iter/s, 29.7506s/500 iters), loss = 0.0380099
I0831 03:33:10.986228 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0380145 (* 1 = 0.0380145 loss)
I0831 03:33:10.986238 916722 sgd_solver.cpp:106] Iteration 2525000, lr = 0.01
I0831 03:33:40.732388 916722 solver.cpp:218] Iteration 2525500 (16.809 iter/s, 29.746s/500 iters), loss = 0.216587
I0831 03:33:40.732446 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.216591 (* 1 = 0.216591 loss)
I0831 03:33:40.732456 916722 sgd_solver.cpp:106] Iteration 2525500, lr = 0.01
I0831 03:34:10.481122 916722 solver.cpp:218] Iteration 2526000 (16.8076 iter/s, 29.7485s/500 iters), loss = 0.389877
I0831 03:34:10.481182 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.389881 (* 1 = 0.389881 loss)
I0831 03:34:10.481191 916722 sgd_solver.cpp:106] Iteration 2526000, lr = 0.01
I0831 03:34:40.230465 916722 solver.cpp:218] Iteration 2526500 (16.8072 iter/s, 29.7491s/500 iters), loss = 0.0711686
I0831 03:34:40.230517 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0711731 (* 1 = 0.0711731 loss)
I0831 03:34:40.230526 916722 sgd_solver.cpp:106] Iteration 2526500, lr = 0.01
I0831 03:35:09.982327 916722 solver.cpp:218] Iteration 2527000 (16.8058 iter/s, 29.7517s/500 iters), loss = 0.044098
I0831 03:35:09.982389 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0441025 (* 1 = 0.0441025 loss)
I0831 03:35:09.982398 916722 sgd_solver.cpp:106] Iteration 2527000, lr = 0.01
I0831 03:35:39.732710 916722 solver.cpp:218] Iteration 2527500 (16.8066 iter/s, 29.7502s/500 iters), loss = 0.105307
I0831 03:35:39.732777 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105311 (* 1 = 0.105311 loss)
I0831 03:35:39.732789 916722 sgd_solver.cpp:106] Iteration 2527500, lr = 0.01
I0831 03:36:09.482599 916722 solver.cpp:218] Iteration 2528000 (16.8069 iter/s, 29.7497s/500 iters), loss = 0.34656
I0831 03:36:09.482657 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.346565 (* 1 = 0.346565 loss)
I0831 03:36:09.482666 916722 sgd_solver.cpp:106] Iteration 2528000, lr = 0.01
I0831 03:36:39.233034 916722 solver.cpp:218] Iteration 2528500 (16.8066 iter/s, 29.7502s/500 iters), loss = 0.316986
I0831 03:36:39.233089 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.31699 (* 1 = 0.31699 loss)
I0831 03:36:39.233099 916722 sgd_solver.cpp:106] Iteration 2528500, lr = 0.01
I0831 03:37:08.986193 916722 solver.cpp:218] Iteration 2529000 (16.8051 iter/s, 29.7529s/500 iters), loss = 0.131836
I0831 03:37:08.986253 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13184 (* 1 = 0.13184 loss)
I0831 03:37:08.986261 916722 sgd_solver.cpp:106] Iteration 2529000, lr = 0.01
I0831 03:37:38.737488 916722 solver.cpp:218] Iteration 2529500 (16.8061 iter/s, 29.7511s/500 iters), loss = 0.0505237
I0831 03:37:38.737542 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0505281 (* 1 = 0.0505281 loss)
I0831 03:37:38.737552 916722 sgd_solver.cpp:106] Iteration 2529500, lr = 0.01
I0831 03:38:08.484795 916722 solver.cpp:218] Iteration 2530000 (16.8084 iter/s, 29.7471s/500 iters), loss = 0.133149
I0831 03:38:08.484853 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133153 (* 1 = 0.133153 loss)
I0831 03:38:08.484861 916722 sgd_solver.cpp:106] Iteration 2530000, lr = 0.01
I0831 03:38:38.231091 916722 solver.cpp:218] Iteration 2530500 (16.8089 iter/s, 29.7461s/500 iters), loss = 0.0578587
I0831 03:38:38.231146 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0578631 (* 1 = 0.0578631 loss)
I0831 03:38:38.231156 916722 sgd_solver.cpp:106] Iteration 2530500, lr = 0.01
I0831 03:39:07.978863 916722 solver.cpp:218] Iteration 2531000 (16.8081 iter/s, 29.7476s/500 iters), loss = 0.140046
I0831 03:39:07.978932 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.14005 (* 1 = 0.14005 loss)
I0831 03:39:07.978941 916722 sgd_solver.cpp:106] Iteration 2531000, lr = 0.01
I0831 03:39:37.727850 916722 solver.cpp:218] Iteration 2531500 (16.8074 iter/s, 29.7488s/500 iters), loss = 0.0580004
I0831 03:39:37.727906 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0580049 (* 1 = 0.0580049 loss)
I0831 03:39:37.727916 916722 sgd_solver.cpp:106] Iteration 2531500, lr = 0.01
I0831 03:40:07.478507 916722 solver.cpp:218] Iteration 2532000 (16.8065 iter/s, 29.7504s/500 iters), loss = 0.151659
I0831 03:40:07.478565 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.151663 (* 1 = 0.151663 loss)
I0831 03:40:07.478574 916722 sgd_solver.cpp:106] Iteration 2532000, lr = 0.01
I0831 03:40:37.229187 916722 solver.cpp:218] Iteration 2532500 (16.8065 iter/s, 29.7505s/500 iters), loss = 0.0355358
I0831 03:40:37.229239 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0355403 (* 1 = 0.0355403 loss)
I0831 03:40:37.229250 916722 sgd_solver.cpp:106] Iteration 2532500, lr = 0.01
I0831 03:41:06.983243 916722 solver.cpp:218] Iteration 2533000 (16.8046 iter/s, 29.7538s/500 iters), loss = 0.0534448
I0831 03:41:06.983302 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0534494 (* 1 = 0.0534494 loss)
I0831 03:41:06.983311 916722 sgd_solver.cpp:106] Iteration 2533000, lr = 0.01
I0831 03:41:36.734829 916722 solver.cpp:218] Iteration 2533500 (16.8059 iter/s, 29.7514s/500 iters), loss = 0.0766216
I0831 03:41:36.734880 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0766261 (* 1 = 0.0766261 loss)
I0831 03:41:36.734889 916722 sgd_solver.cpp:106] Iteration 2533500, lr = 0.01
I0831 03:42:06.483613 916722 solver.cpp:218] Iteration 2534000 (16.8075 iter/s, 29.7486s/500 iters), loss = 0.317901
I0831 03:42:06.483671 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.317906 (* 1 = 0.317906 loss)
I0831 03:42:06.483680 916722 sgd_solver.cpp:106] Iteration 2534000, lr = 0.01
I0831 03:42:36.235705 916722 solver.cpp:218] Iteration 2534500 (16.8057 iter/s, 29.7519s/500 iters), loss = 0.370101
I0831 03:42:36.235760 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.370105 (* 1 = 0.370105 loss)
I0831 03:42:36.235769 916722 sgd_solver.cpp:106] Iteration 2534500, lr = 0.01
I0831 03:43:05.982970 916722 solver.cpp:218] Iteration 2535000 (16.8084 iter/s, 29.7471s/500 iters), loss = 0.109968
I0831 03:43:05.983031 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109973 (* 1 = 0.109973 loss)
I0831 03:43:05.983038 916722 sgd_solver.cpp:106] Iteration 2535000, lr = 0.01
I0831 03:43:35.731287 916722 solver.cpp:218] Iteration 2535500 (16.8078 iter/s, 29.7481s/500 iters), loss = 0.0689312
I0831 03:43:35.731338 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0689356 (* 1 = 0.0689356 loss)
I0831 03:43:35.731348 916722 sgd_solver.cpp:106] Iteration 2535500, lr = 0.01
I0831 03:44:05.481041 916722 solver.cpp:218] Iteration 2536000 (16.807 iter/s, 29.7496s/500 iters), loss = 0.386595
I0831 03:44:05.481101 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.386599 (* 1 = 0.386599 loss)
I0831 03:44:05.481109 916722 sgd_solver.cpp:106] Iteration 2536000, lr = 0.01
I0831 03:44:35.229410 916722 solver.cpp:218] Iteration 2536500 (16.8078 iter/s, 29.7482s/500 iters), loss = 0.236521
I0831 03:44:35.229462 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.236526 (* 1 = 0.236526 loss)
I0831 03:44:35.229471 916722 sgd_solver.cpp:106] Iteration 2536500, lr = 0.01
I0831 03:45:04.979957 916722 solver.cpp:218] Iteration 2537000 (16.8065 iter/s, 29.7504s/500 iters), loss = 0.147377
I0831 03:45:04.980016 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.147382 (* 1 = 0.147382 loss)
I0831 03:45:04.980024 916722 sgd_solver.cpp:106] Iteration 2537000, lr = 0.01
I0831 03:45:34.704121 916722 solver.cpp:218] Iteration 2537500 (16.8214 iter/s, 29.724s/500 iters), loss = 0.396735
I0831 03:45:34.704171 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.396739 (* 1 = 0.396739 loss)
I0831 03:45:34.704180 916722 sgd_solver.cpp:106] Iteration 2537500, lr = 0.01
I0831 03:46:04.427068 916722 solver.cpp:218] Iteration 2538000 (16.8221 iter/s, 29.7228s/500 iters), loss = 0.168058
I0831 03:46:04.427136 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.168063 (* 1 = 0.168063 loss)
I0831 03:46:04.427145 916722 sgd_solver.cpp:106] Iteration 2538000, lr = 0.01
I0831 03:46:34.145367 916722 solver.cpp:218] Iteration 2538500 (16.8248 iter/s, 29.7181s/500 iters), loss = 0.192336
I0831 03:46:34.145419 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.19234 (* 1 = 0.19234 loss)
I0831 03:46:34.145428 916722 sgd_solver.cpp:106] Iteration 2538500, lr = 0.01
I0831 03:47:03.867033 916722 solver.cpp:218] Iteration 2539000 (16.8229 iter/s, 29.7215s/500 iters), loss = 0.291641
I0831 03:47:03.867089 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.291646 (* 1 = 0.291646 loss)
I0831 03:47:03.867098 916722 sgd_solver.cpp:106] Iteration 2539000, lr = 0.01
I0831 03:47:33.584723 916722 solver.cpp:218] Iteration 2539500 (16.8251 iter/s, 29.7175s/500 iters), loss = 0.032483
I0831 03:47:33.584785 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0324879 (* 1 = 0.0324879 loss)
I0831 03:47:33.584794 916722 sgd_solver.cpp:106] Iteration 2539500, lr = 0.01
I0831 03:48:03.302198 916722 solver.cpp:218] Iteration 2540000 (16.8252 iter/s, 29.7173s/500 iters), loss = 0.0176903
I0831 03:48:03.302255 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0176952 (* 1 = 0.0176952 loss)
I0831 03:48:03.302264 916722 sgd_solver.cpp:106] Iteration 2540000, lr = 0.01
I0831 03:48:33.022392 916722 solver.cpp:218] Iteration 2540500 (16.8237 iter/s, 29.72s/500 iters), loss = 0.293107
I0831 03:48:33.022445 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.293111 (* 1 = 0.293111 loss)
I0831 03:48:33.022454 916722 sgd_solver.cpp:106] Iteration 2540500, lr = 0.01
I0831 03:49:02.739382 916722 solver.cpp:218] Iteration 2541000 (16.8255 iter/s, 29.7168s/500 iters), loss = 0.181543
I0831 03:49:02.739437 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.181547 (* 1 = 0.181547 loss)
I0831 03:49:02.739445 916722 sgd_solver.cpp:106] Iteration 2541000, lr = 0.01
I0831 03:49:32.456290 916722 solver.cpp:218] Iteration 2541500 (16.8255 iter/s, 29.7167s/500 iters), loss = 0.103372
I0831 03:49:32.456341 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.103376 (* 1 = 0.103376 loss)
I0831 03:49:32.456349 916722 sgd_solver.cpp:106] Iteration 2541500, lr = 0.01
I0831 03:50:02.174472 916722 solver.cpp:218] Iteration 2542000 (16.8248 iter/s, 29.718s/500 iters), loss = 0.146873
I0831 03:50:02.174530 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.146877 (* 1 = 0.146877 loss)
I0831 03:50:02.174537 916722 sgd_solver.cpp:106] Iteration 2542000, lr = 0.01
I0831 03:50:31.897058 916722 solver.cpp:218] Iteration 2542500 (16.8223 iter/s, 29.7224s/500 iters), loss = 0.0991068
I0831 03:50:31.897109 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0991115 (* 1 = 0.0991115 loss)
I0831 03:50:31.897116 916722 sgd_solver.cpp:106] Iteration 2542500, lr = 0.01
I0831 03:51:01.616026 916722 solver.cpp:218] Iteration 2543000 (16.8244 iter/s, 29.7188s/500 iters), loss = 0.239808
I0831 03:51:01.616086 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.239813 (* 1 = 0.239813 loss)
I0831 03:51:01.616094 916722 sgd_solver.cpp:106] Iteration 2543000, lr = 0.01
I0831 03:51:31.333185 916722 solver.cpp:218] Iteration 2543500 (16.8254 iter/s, 29.717s/500 iters), loss = 0.227019
I0831 03:51:31.333242 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.227024 (* 1 = 0.227024 loss)
I0831 03:51:31.333252 916722 sgd_solver.cpp:106] Iteration 2543500, lr = 0.01
I0831 03:52:01.054601 916722 solver.cpp:218] Iteration 2544000 (16.823 iter/s, 29.7212s/500 iters), loss = 0.187714
I0831 03:52:01.054656 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.187719 (* 1 = 0.187719 loss)
I0831 03:52:01.054664 916722 sgd_solver.cpp:106] Iteration 2544000, lr = 0.01
I0831 03:52:30.774478 916722 solver.cpp:218] Iteration 2544500 (16.8239 iter/s, 29.7197s/500 iters), loss = 0.267825
I0831 03:52:30.774544 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.267829 (* 1 = 0.267829 loss)
I0831 03:52:30.774554 916722 sgd_solver.cpp:106] Iteration 2544500, lr = 0.01
I0831 03:53:00.492210 916722 solver.cpp:218] Iteration 2545000 (16.8251 iter/s, 29.7175s/500 iters), loss = 0.250698
I0831 03:53:00.492277 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.250702 (* 1 = 0.250702 loss)
I0831 03:53:00.492285 916722 sgd_solver.cpp:106] Iteration 2545000, lr = 0.01
I0831 03:53:30.209944 916722 solver.cpp:218] Iteration 2545500 (16.8251 iter/s, 29.7175s/500 iters), loss = 0.158845
I0831 03:53:30.209997 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.158849 (* 1 = 0.158849 loss)
I0831 03:53:30.210008 916722 sgd_solver.cpp:106] Iteration 2545500, lr = 0.01
I0831 03:53:59.929401 916722 solver.cpp:218] Iteration 2546000 (16.8241 iter/s, 29.7193s/500 iters), loss = 0.101138
I0831 03:53:59.929458 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101142 (* 1 = 0.101142 loss)
I0831 03:53:59.929467 916722 sgd_solver.cpp:106] Iteration 2546000, lr = 0.01
I0831 03:54:29.648439 916722 solver.cpp:218] Iteration 2546500 (16.8243 iter/s, 29.7188s/500 iters), loss = 0.0883449
I0831 03:54:29.648491 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0883494 (* 1 = 0.0883494 loss)
I0831 03:54:29.648501 916722 sgd_solver.cpp:106] Iteration 2546500, lr = 0.01
I0831 03:54:59.368948 916722 solver.cpp:218] Iteration 2547000 (16.8235 iter/s, 29.7203s/500 iters), loss = 0.0199539
I0831 03:54:59.369007 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0199583 (* 1 = 0.0199583 loss)
I0831 03:54:59.369015 916722 sgd_solver.cpp:106] Iteration 2547000, lr = 0.01
I0831 03:55:29.087134 916722 solver.cpp:218] Iteration 2547500 (16.8248 iter/s, 29.718s/500 iters), loss = 0.078813
I0831 03:55:29.087188 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0788175 (* 1 = 0.0788175 loss)
I0831 03:55:29.087198 916722 sgd_solver.cpp:106] Iteration 2547500, lr = 0.01
I0831 03:55:58.803423 916722 solver.cpp:218] Iteration 2548000 (16.8259 iter/s, 29.7161s/500 iters), loss = 0.136403
I0831 03:55:58.803483 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.136408 (* 1 = 0.136408 loss)
I0831 03:55:58.803491 916722 sgd_solver.cpp:106] Iteration 2548000, lr = 0.01
I0831 03:56:28.523676 916722 solver.cpp:218] Iteration 2548500 (16.8237 iter/s, 29.7201s/500 iters), loss = 0.086575
I0831 03:56:28.523730 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0865796 (* 1 = 0.0865796 loss)
I0831 03:56:28.523741 916722 sgd_solver.cpp:106] Iteration 2548500, lr = 0.01
I0831 03:56:58.244051 916722 solver.cpp:218] Iteration 2549000 (16.8236 iter/s, 29.7202s/500 iters), loss = 0.246587
I0831 03:56:58.244113 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.246592 (* 1 = 0.246592 loss)
I0831 03:56:58.244122 916722 sgd_solver.cpp:106] Iteration 2549000, lr = 0.01
I0831 03:57:27.966221 916722 solver.cpp:218] Iteration 2549500 (16.8226 iter/s, 29.722s/500 iters), loss = 0.187774
I0831 03:57:27.966274 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.187778 (* 1 = 0.187778 loss)
I0831 03:57:27.966284 916722 sgd_solver.cpp:106] Iteration 2549500, lr = 0.01
I0831 03:57:57.631829 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_2550000.caffemodel
I0831 03:57:57.651114 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_2550000.solverstate
I0831 03:57:57.657281 916722 solver.cpp:330] Iteration 2550000, Testing net (#0)
I0831 03:58:12.977838 916722 solver.cpp:397]     Test net output #0: accuracy = 0.81
I0831 03:58:12.977880 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.68369 (* 1 = 0.68369 loss)
I0831 03:58:13.036365 916722 solver.cpp:218] Iteration 2550000 (11.0939 iter/s, 45.0699s/500 iters), loss = 0.0568172
I0831 03:58:13.036392 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.056822 (* 1 = 0.056822 loss)
I0831 03:58:13.036412 916722 sgd_solver.cpp:106] Iteration 2550000, lr = 0.01
I0831 03:58:42.622848 916722 solver.cpp:218] Iteration 2550500 (16.8997 iter/s, 29.5863s/500 iters), loss = 0.139791
I0831 03:58:42.622922 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139796 (* 1 = 0.139796 loss)
I0831 03:58:42.622931 916722 sgd_solver.cpp:106] Iteration 2550500, lr = 0.01
I0831 03:59:12.300967 916722 solver.cpp:218] Iteration 2551000 (16.8476 iter/s, 29.6779s/500 iters), loss = 0.0399525
I0831 03:59:12.301016 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0399576 (* 1 = 0.0399576 loss)
I0831 03:59:12.301025 916722 sgd_solver.cpp:106] Iteration 2551000, lr = 0.01
I0831 03:59:41.994287 916722 solver.cpp:218] Iteration 2551500 (16.8389 iter/s, 29.6931s/500 iters), loss = 0.330239
I0831 03:59:41.994347 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.330244 (* 1 = 0.330244 loss)
I0831 03:59:41.994355 916722 sgd_solver.cpp:106] Iteration 2551500, lr = 0.01
I0831 04:00:11.692472 916722 solver.cpp:218] Iteration 2552000 (16.8362 iter/s, 29.698s/500 iters), loss = 0.107238
I0831 04:00:11.692526 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.107243 (* 1 = 0.107243 loss)
I0831 04:00:11.692538 916722 sgd_solver.cpp:106] Iteration 2552000, lr = 0.01
I0831 04:00:41.389061 916722 solver.cpp:218] Iteration 2552500 (16.8371 iter/s, 29.6964s/500 iters), loss = 0.0667748
I0831 04:00:41.389123 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0667797 (* 1 = 0.0667797 loss)
I0831 04:00:41.389132 916722 sgd_solver.cpp:106] Iteration 2552500, lr = 0.01
I0831 04:01:11.081579 916722 solver.cpp:218] Iteration 2553000 (16.8394 iter/s, 29.6923s/500 iters), loss = 0.115255
I0831 04:01:11.081627 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.11526 (* 1 = 0.11526 loss)
I0831 04:01:11.081636 916722 sgd_solver.cpp:106] Iteration 2553000, lr = 0.01
I0831 04:01:40.779489 916722 solver.cpp:218] Iteration 2553500 (16.8363 iter/s, 29.6977s/500 iters), loss = 0.132403
I0831 04:01:40.779546 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.132408 (* 1 = 0.132408 loss)
I0831 04:01:40.779556 916722 sgd_solver.cpp:106] Iteration 2553500, lr = 0.01
I0831 04:02:10.472407 916722 solver.cpp:218] Iteration 2554000 (16.8391 iter/s, 29.6927s/500 iters), loss = 0.0912556
I0831 04:02:10.472477 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0912606 (* 1 = 0.0912606 loss)
I0831 04:02:10.472487 916722 sgd_solver.cpp:106] Iteration 2554000, lr = 0.01
I0831 04:02:40.167546 916722 solver.cpp:218] Iteration 2554500 (16.8379 iter/s, 29.6949s/500 iters), loss = 0.254541
I0831 04:02:40.167604 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.254546 (* 1 = 0.254546 loss)
I0831 04:02:40.167613 916722 sgd_solver.cpp:106] Iteration 2554500, lr = 0.01
I0831 04:03:09.861677 916722 solver.cpp:218] Iteration 2555000 (16.8385 iter/s, 29.6939s/500 iters), loss = 0.225199
I0831 04:03:09.861729 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.225204 (* 1 = 0.225204 loss)
I0831 04:03:09.861738 916722 sgd_solver.cpp:106] Iteration 2555000, lr = 0.01
I0831 04:03:39.554759 916722 solver.cpp:218] Iteration 2555500 (16.839 iter/s, 29.6929s/500 iters), loss = 0.125544
I0831 04:03:39.554821 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.125549 (* 1 = 0.125549 loss)
I0831 04:03:39.554829 916722 sgd_solver.cpp:106] Iteration 2555500, lr = 0.01
I0831 04:04:09.246498 916722 solver.cpp:218] Iteration 2556000 (16.8398 iter/s, 29.6915s/500 iters), loss = 0.104846
I0831 04:04:09.246551 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104851 (* 1 = 0.104851 loss)
I0831 04:04:09.246559 916722 sgd_solver.cpp:106] Iteration 2556000, lr = 0.01
I0831 04:04:38.941325 916722 solver.cpp:218] Iteration 2556500 (16.8381 iter/s, 29.6946s/500 iters), loss = 0.116192
I0831 04:04:38.941396 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.116197 (* 1 = 0.116197 loss)
I0831 04:04:38.941409 916722 sgd_solver.cpp:106] Iteration 2556500, lr = 0.01
I0831 04:05:08.635689 916722 solver.cpp:218] Iteration 2557000 (16.8383 iter/s, 29.6942s/500 iters), loss = 0.100502
I0831 04:05:08.635742 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.100506 (* 1 = 0.100506 loss)
I0831 04:05:08.635751 916722 sgd_solver.cpp:106] Iteration 2557000, lr = 0.01
I0831 04:05:38.334360 916722 solver.cpp:218] Iteration 2557500 (16.8359 iter/s, 29.6985s/500 iters), loss = 0.217777
I0831 04:05:38.334417 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.217782 (* 1 = 0.217782 loss)
I0831 04:05:38.334425 916722 sgd_solver.cpp:106] Iteration 2557500, lr = 0.01
I0831 04:06:08.028887 916722 solver.cpp:218] Iteration 2558000 (16.8382 iter/s, 29.6943s/500 iters), loss = 0.133195
I0831 04:06:08.028939 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.1332 (* 1 = 0.1332 loss)
I0831 04:06:08.028949 916722 sgd_solver.cpp:106] Iteration 2558000, lr = 0.01
I0831 04:06:37.723798 916722 solver.cpp:218] Iteration 2558500 (16.838 iter/s, 29.6947s/500 iters), loss = 0.145083
I0831 04:06:37.723855 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.145087 (* 1 = 0.145087 loss)
I0831 04:06:37.723863 916722 sgd_solver.cpp:106] Iteration 2558500, lr = 0.01
I0831 04:07:07.416208 916722 solver.cpp:218] Iteration 2559000 (16.8394 iter/s, 29.6922s/500 iters), loss = 0.478056
I0831 04:07:07.416260 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.478061 (* 1 = 0.478061 loss)
I0831 04:07:07.416270 916722 sgd_solver.cpp:106] Iteration 2559000, lr = 0.01
I0831 04:07:37.109822 916722 solver.cpp:218] Iteration 2559500 (16.8387 iter/s, 29.6934s/500 iters), loss = 0.185344
I0831 04:07:37.109879 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.185348 (* 1 = 0.185348 loss)
I0831 04:07:37.109889 916722 sgd_solver.cpp:106] Iteration 2559500, lr = 0.01
I0831 04:08:06.802201 916722 solver.cpp:218] Iteration 2560000 (16.8394 iter/s, 29.6922s/500 iters), loss = 0.112511
I0831 04:08:06.802253 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112515 (* 1 = 0.112515 loss)
I0831 04:08:06.802263 916722 sgd_solver.cpp:106] Iteration 2560000, lr = 0.01
I0831 04:08:36.501435 916722 solver.cpp:218] Iteration 2560500 (16.8356 iter/s, 29.699s/500 iters), loss = 0.115903
I0831 04:08:36.501492 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115908 (* 1 = 0.115908 loss)
I0831 04:08:36.501500 916722 sgd_solver.cpp:106] Iteration 2560500, lr = 0.01
I0831 04:09:06.198310 916722 solver.cpp:218] Iteration 2561000 (16.8369 iter/s, 29.6967s/500 iters), loss = 0.0476721
I0831 04:09:06.198361 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0476768 (* 1 = 0.0476768 loss)
I0831 04:09:06.198372 916722 sgd_solver.cpp:106] Iteration 2561000, lr = 0.01
I0831 04:09:35.897011 916722 solver.cpp:218] Iteration 2561500 (16.8359 iter/s, 29.6985s/500 iters), loss = 0.133209
I0831 04:09:35.897069 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133213 (* 1 = 0.133213 loss)
I0831 04:09:35.897078 916722 sgd_solver.cpp:106] Iteration 2561500, lr = 0.01
I0831 04:10:05.601248 916722 solver.cpp:218] Iteration 2562000 (16.8327 iter/s, 29.704s/500 iters), loss = 0.182081
I0831 04:10:05.601301 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.182086 (* 1 = 0.182086 loss)
I0831 04:10:05.601312 916722 sgd_solver.cpp:106] Iteration 2562000, lr = 0.01
I0831 04:10:35.295161 916722 solver.cpp:218] Iteration 2562500 (16.8386 iter/s, 29.6937s/500 iters), loss = 0.0945482
I0831 04:10:35.295215 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0945529 (* 1 = 0.0945529 loss)
I0831 04:10:35.295223 916722 sgd_solver.cpp:106] Iteration 2562500, lr = 0.01
I0831 04:11:04.988827 916722 solver.cpp:218] Iteration 2563000 (16.8387 iter/s, 29.6935s/500 iters), loss = 0.0401306
I0831 04:11:04.988883 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0401353 (* 1 = 0.0401353 loss)
I0831 04:11:04.988891 916722 sgd_solver.cpp:106] Iteration 2563000, lr = 0.01
I0831 04:11:34.679371 916722 solver.cpp:218] Iteration 2563500 (16.8405 iter/s, 29.6903s/500 iters), loss = 0.270135
I0831 04:11:34.679440 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.27014 (* 1 = 0.27014 loss)
I0831 04:11:34.679450 916722 sgd_solver.cpp:106] Iteration 2563500, lr = 0.01
I0831 04:12:04.368196 916722 solver.cpp:218] Iteration 2564000 (16.8415 iter/s, 29.6886s/500 iters), loss = 0.056888
I0831 04:12:04.368247 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0568928 (* 1 = 0.0568928 loss)
I0831 04:12:04.368257 916722 sgd_solver.cpp:106] Iteration 2564000, lr = 0.01
I0831 04:12:34.057621 916722 solver.cpp:218] Iteration 2564500 (16.8411 iter/s, 29.6892s/500 iters), loss = 0.0357072
I0831 04:12:34.057678 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.035712 (* 1 = 0.035712 loss)
I0831 04:12:34.057687 916722 sgd_solver.cpp:106] Iteration 2564500, lr = 0.01
I0831 04:13:03.750483 916722 solver.cpp:218] Iteration 2565000 (16.8392 iter/s, 29.6927s/500 iters), loss = 0.0435141
I0831 04:13:03.750533 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.043519 (* 1 = 0.043519 loss)
I0831 04:13:03.750543 916722 sgd_solver.cpp:106] Iteration 2565000, lr = 0.01
I0831 04:13:33.448365 916722 solver.cpp:218] Iteration 2565500 (16.8363 iter/s, 29.6977s/500 iters), loss = 0.128849
I0831 04:13:33.448431 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128853 (* 1 = 0.128853 loss)
I0831 04:13:33.448441 916722 sgd_solver.cpp:106] Iteration 2565500, lr = 0.01
I0831 04:14:03.142233 916722 solver.cpp:218] Iteration 2566000 (16.8386 iter/s, 29.6937s/500 iters), loss = 0.176347
I0831 04:14:03.142283 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.176351 (* 1 = 0.176351 loss)
I0831 04:14:03.142293 916722 sgd_solver.cpp:106] Iteration 2566000, lr = 0.01
I0831 04:14:32.833675 916722 solver.cpp:218] Iteration 2566500 (16.84 iter/s, 29.6912s/500 iters), loss = 0.0472035
I0831 04:14:32.833730 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0472081 (* 1 = 0.0472081 loss)
I0831 04:14:32.833739 916722 sgd_solver.cpp:106] Iteration 2566500, lr = 0.01
I0831 04:15:02.523099 916722 solver.cpp:218] Iteration 2567000 (16.8411 iter/s, 29.6892s/500 iters), loss = 0.467074
I0831 04:15:02.523149 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.467078 (* 1 = 0.467078 loss)
I0831 04:15:02.523159 916722 sgd_solver.cpp:106] Iteration 2567000, lr = 0.01
I0831 04:15:32.212870 916722 solver.cpp:218] Iteration 2567500 (16.8409 iter/s, 29.6896s/500 iters), loss = 0.360685
I0831 04:15:32.212930 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.360689 (* 1 = 0.360689 loss)
I0831 04:15:32.212939 916722 sgd_solver.cpp:106] Iteration 2567500, lr = 0.01
I0831 04:16:01.904242 916722 solver.cpp:218] Iteration 2568000 (16.84 iter/s, 29.6912s/500 iters), loss = 0.205906
I0831 04:16:01.904291 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.205911 (* 1 = 0.205911 loss)
I0831 04:16:01.904301 916722 sgd_solver.cpp:106] Iteration 2568000, lr = 0.01
I0831 04:16:31.593466 916722 solver.cpp:218] Iteration 2568500 (16.8412 iter/s, 29.689s/500 iters), loss = 0.223155
I0831 04:16:31.593525 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.223159 (* 1 = 0.223159 loss)
I0831 04:16:31.593534 916722 sgd_solver.cpp:106] Iteration 2568500, lr = 0.01
I0831 04:17:01.285152 916722 solver.cpp:218] Iteration 2569000 (16.8398 iter/s, 29.6915s/500 iters), loss = 0.105493
I0831 04:17:01.285203 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105497 (* 1 = 0.105497 loss)
I0831 04:17:01.285213 916722 sgd_solver.cpp:106] Iteration 2569000, lr = 0.01
I0831 04:17:30.978195 916722 solver.cpp:218] Iteration 2569500 (16.8391 iter/s, 29.6929s/500 iters), loss = 0.194658
I0831 04:17:30.978257 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.194661 (* 1 = 0.194661 loss)
I0831 04:17:30.978266 916722 sgd_solver.cpp:106] Iteration 2569500, lr = 0.01
I0831 04:18:00.671959 916722 solver.cpp:218] Iteration 2570000 (16.8387 iter/s, 29.6936s/500 iters), loss = 0.136653
I0831 04:18:00.672008 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.136657 (* 1 = 0.136657 loss)
I0831 04:18:00.672016 916722 sgd_solver.cpp:106] Iteration 2570000, lr = 0.01
I0831 04:18:30.359056 916722 solver.cpp:218] Iteration 2570500 (16.8424 iter/s, 29.6869s/500 iters), loss = 0.328558
I0831 04:18:30.359134 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.328562 (* 1 = 0.328562 loss)
I0831 04:18:30.359143 916722 sgd_solver.cpp:106] Iteration 2570500, lr = 0.01
I0831 04:19:00.050573 916722 solver.cpp:218] Iteration 2571000 (16.8399 iter/s, 29.6913s/500 iters), loss = 0.47478
I0831 04:19:00.050622 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.474784 (* 1 = 0.474784 loss)
I0831 04:19:00.050630 916722 sgd_solver.cpp:106] Iteration 2571000, lr = 0.01
I0831 04:19:29.740948 916722 solver.cpp:218] Iteration 2571500 (16.8406 iter/s, 29.6902s/500 iters), loss = 0.30292
I0831 04:19:29.741009 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.302924 (* 1 = 0.302924 loss)
I0831 04:19:29.741017 916722 sgd_solver.cpp:106] Iteration 2571500, lr = 0.01
I0831 04:19:59.431452 916722 solver.cpp:218] Iteration 2572000 (16.8405 iter/s, 29.6903s/500 iters), loss = 0.20501
I0831 04:19:59.431505 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.205014 (* 1 = 0.205014 loss)
I0831 04:19:59.431514 916722 sgd_solver.cpp:106] Iteration 2572000, lr = 0.01
I0831 04:20:29.122124 916722 solver.cpp:218] Iteration 2572500 (16.8404 iter/s, 29.6905s/500 iters), loss = 0.091742
I0831 04:20:29.122184 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0917463 (* 1 = 0.0917463 loss)
I0831 04:20:29.122192 916722 sgd_solver.cpp:106] Iteration 2572500, lr = 0.01
I0831 04:20:58.813400 916722 solver.cpp:218] Iteration 2573000 (16.8401 iter/s, 29.6911s/500 iters), loss = 0.172978
I0831 04:20:58.813452 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.172982 (* 1 = 0.172982 loss)
I0831 04:20:58.813462 916722 sgd_solver.cpp:106] Iteration 2573000, lr = 0.01
I0831 04:21:28.500582 916722 solver.cpp:218] Iteration 2573500 (16.8424 iter/s, 29.687s/500 iters), loss = 0.0530417
I0831 04:21:28.500644 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0530457 (* 1 = 0.0530457 loss)
I0831 04:21:28.500653 916722 sgd_solver.cpp:106] Iteration 2573500, lr = 0.01
I0831 04:21:58.190557 916722 solver.cpp:218] Iteration 2574000 (16.8408 iter/s, 29.6898s/500 iters), loss = 0.0411613
I0831 04:21:58.190608 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0411654 (* 1 = 0.0411654 loss)
I0831 04:21:58.190616 916722 sgd_solver.cpp:106] Iteration 2574000, lr = 0.01
I0831 04:22:27.880832 916722 solver.cpp:218] Iteration 2574500 (16.8405 iter/s, 29.6903s/500 iters), loss = 0.00822726
I0831 04:22:27.880892 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.00823124 (* 1 = 0.00823124 loss)
I0831 04:22:27.880901 916722 sgd_solver.cpp:106] Iteration 2574500, lr = 0.01
I0831 04:22:57.570431 916722 solver.cpp:218] Iteration 2575000 (16.8409 iter/s, 29.6896s/500 iters), loss = 0.0973652
I0831 04:22:57.570484 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0973691 (* 1 = 0.0973691 loss)
I0831 04:22:57.570494 916722 sgd_solver.cpp:106] Iteration 2575000, lr = 0.01
I0831 04:23:27.258916 916722 solver.cpp:218] Iteration 2575500 (16.8415 iter/s, 29.6885s/500 iters), loss = 0.271206
I0831 04:23:27.258976 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.27121 (* 1 = 0.27121 loss)
I0831 04:23:27.258985 916722 sgd_solver.cpp:106] Iteration 2575500, lr = 0.01
I0831 04:23:56.951355 916722 solver.cpp:218] Iteration 2576000 (16.8393 iter/s, 29.6924s/500 iters), loss = 0.198269
I0831 04:23:56.951409 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.198273 (* 1 = 0.198273 loss)
I0831 04:23:56.951419 916722 sgd_solver.cpp:106] Iteration 2576000, lr = 0.01
I0831 04:24:26.644279 916722 solver.cpp:218] Iteration 2576500 (16.839 iter/s, 29.6929s/500 iters), loss = 0.233329
I0831 04:24:26.644353 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.233333 (* 1 = 0.233333 loss)
I0831 04:24:26.644362 916722 sgd_solver.cpp:106] Iteration 2576500, lr = 0.01
I0831 04:24:56.333175 916722 solver.cpp:218] Iteration 2577000 (16.8413 iter/s, 29.6889s/500 iters), loss = 0.294832
I0831 04:24:56.333228 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.294836 (* 1 = 0.294836 loss)
I0831 04:24:56.333240 916722 sgd_solver.cpp:106] Iteration 2577000, lr = 0.01
I0831 04:25:26.026815 916722 solver.cpp:218] Iteration 2577500 (16.8386 iter/s, 29.6936s/500 iters), loss = 0.153383
I0831 04:25:26.026873 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.153387 (* 1 = 0.153387 loss)
I0831 04:25:26.026881 916722 sgd_solver.cpp:106] Iteration 2577500, lr = 0.01
I0831 04:25:55.717103 916722 solver.cpp:218] Iteration 2578000 (16.8405 iter/s, 29.6903s/500 iters), loss = 0.115229
I0831 04:25:55.717159 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115233 (* 1 = 0.115233 loss)
I0831 04:25:55.717168 916722 sgd_solver.cpp:106] Iteration 2578000, lr = 0.01
I0831 04:26:25.405553 916722 solver.cpp:218] Iteration 2578500 (16.8416 iter/s, 29.6884s/500 iters), loss = 0.0759983
I0831 04:26:25.405611 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0760021 (* 1 = 0.0760021 loss)
I0831 04:26:25.405619 916722 sgd_solver.cpp:106] Iteration 2578500, lr = 0.01
I0831 04:26:55.094453 916722 solver.cpp:218] Iteration 2579000 (16.8413 iter/s, 29.6889s/500 iters), loss = 0.126726
I0831 04:26:55.094504 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.126729 (* 1 = 0.126729 loss)
I0831 04:26:55.094514 916722 sgd_solver.cpp:106] Iteration 2579000, lr = 0.01
I0831 04:27:24.781921 916722 solver.cpp:218] Iteration 2579500 (16.8422 iter/s, 29.6874s/500 iters), loss = 0.186547
I0831 04:27:24.781975 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.186551 (* 1 = 0.186551 loss)
I0831 04:27:24.781983 916722 sgd_solver.cpp:106] Iteration 2579500, lr = 0.01
I0831 04:27:54.473712 916722 solver.cpp:218] Iteration 2580000 (16.8397 iter/s, 29.6917s/500 iters), loss = 0.0988705
I0831 04:27:54.473765 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0988744 (* 1 = 0.0988744 loss)
I0831 04:27:54.473775 916722 sgd_solver.cpp:106] Iteration 2580000, lr = 0.01
I0831 04:28:24.163604 916722 solver.cpp:218] Iteration 2580500 (16.8408 iter/s, 29.6898s/500 iters), loss = 0.461994
I0831 04:28:24.163661 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.461998 (* 1 = 0.461998 loss)
I0831 04:28:24.163669 916722 sgd_solver.cpp:106] Iteration 2580500, lr = 0.01
I0831 04:28:53.858541 916722 solver.cpp:218] Iteration 2581000 (16.8379 iter/s, 29.6949s/500 iters), loss = 0.419557
I0831 04:28:53.858593 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.419561 (* 1 = 0.419561 loss)
I0831 04:28:53.858603 916722 sgd_solver.cpp:106] Iteration 2581000, lr = 0.01
I0831 04:29:23.547152 916722 solver.cpp:218] Iteration 2581500 (16.8415 iter/s, 29.6885s/500 iters), loss = 0.0702793
I0831 04:29:23.547210 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0702833 (* 1 = 0.0702833 loss)
I0831 04:29:23.547219 916722 sgd_solver.cpp:106] Iteration 2581500, lr = 0.01
I0831 04:29:53.237715 916722 solver.cpp:218] Iteration 2582000 (16.8404 iter/s, 29.6905s/500 iters), loss = 0.214249
I0831 04:29:53.237767 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.214254 (* 1 = 0.214254 loss)
I0831 04:29:53.237777 916722 sgd_solver.cpp:106] Iteration 2582000, lr = 0.01
I0831 04:30:22.927305 916722 solver.cpp:218] Iteration 2582500 (16.841 iter/s, 29.6895s/500 iters), loss = 0.113312
I0831 04:30:22.927364 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.113316 (* 1 = 0.113316 loss)
I0831 04:30:22.927372 916722 sgd_solver.cpp:106] Iteration 2582500, lr = 0.01
I0831 04:30:52.618243 916722 solver.cpp:218] Iteration 2583000 (16.8402 iter/s, 29.6908s/500 iters), loss = 0.0469388
I0831 04:30:52.618307 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0469431 (* 1 = 0.0469431 loss)
I0831 04:30:52.618317 916722 sgd_solver.cpp:106] Iteration 2583000, lr = 0.01
I0831 04:31:22.309514 916722 solver.cpp:218] Iteration 2583500 (16.84 iter/s, 29.6912s/500 iters), loss = 0.109995
I0831 04:31:22.309583 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109999 (* 1 = 0.109999 loss)
I0831 04:31:22.309592 916722 sgd_solver.cpp:106] Iteration 2583500, lr = 0.01
I0831 04:31:52.002823 916722 solver.cpp:218] Iteration 2584000 (16.8389 iter/s, 29.6932s/500 iters), loss = 0.145095
I0831 04:31:52.002873 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.145099 (* 1 = 0.145099 loss)
I0831 04:31:52.002883 916722 sgd_solver.cpp:106] Iteration 2584000, lr = 0.01
I0831 04:32:21.695955 916722 solver.cpp:218] Iteration 2584500 (16.839 iter/s, 29.693s/500 iters), loss = 0.242179
I0831 04:32:21.696013 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.242183 (* 1 = 0.242183 loss)
I0831 04:32:21.696022 916722 sgd_solver.cpp:106] Iteration 2584500, lr = 0.01
I0831 04:32:51.385545 916722 solver.cpp:218] Iteration 2585000 (16.841 iter/s, 29.6895s/500 iters), loss = 0.238221
I0831 04:32:51.385597 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.238225 (* 1 = 0.238225 loss)
I0831 04:32:51.385607 916722 sgd_solver.cpp:106] Iteration 2585000, lr = 0.01
I0831 04:33:21.074381 916722 solver.cpp:218] Iteration 2585500 (16.8414 iter/s, 29.6887s/500 iters), loss = 0.102343
I0831 04:33:21.074442 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.102347 (* 1 = 0.102347 loss)
I0831 04:33:21.074451 916722 sgd_solver.cpp:106] Iteration 2585500, lr = 0.01
I0831 04:33:50.767197 916722 solver.cpp:218] Iteration 2586000 (16.8392 iter/s, 29.6927s/500 iters), loss = 0.111921
I0831 04:33:50.767253 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111925 (* 1 = 0.111925 loss)
I0831 04:33:50.767263 916722 sgd_solver.cpp:106] Iteration 2586000, lr = 0.01
I0831 04:34:20.455865 916722 solver.cpp:218] Iteration 2586500 (16.8415 iter/s, 29.6885s/500 iters), loss = 0.1467
I0831 04:34:20.455922 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.146705 (* 1 = 0.146705 loss)
I0831 04:34:20.455930 916722 sgd_solver.cpp:106] Iteration 2586500, lr = 0.01
I0831 04:34:50.147543 916722 solver.cpp:218] Iteration 2587000 (16.8398 iter/s, 29.6916s/500 iters), loss = 0.05013
I0831 04:34:50.147599 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0501344 (* 1 = 0.0501344 loss)
I0831 04:34:50.147609 916722 sgd_solver.cpp:106] Iteration 2587000, lr = 0.01
I0831 04:35:19.836246 916722 solver.cpp:218] Iteration 2587500 (16.8415 iter/s, 29.6886s/500 iters), loss = 0.115469
I0831 04:35:19.836308 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115473 (* 1 = 0.115473 loss)
I0831 04:35:19.836315 916722 sgd_solver.cpp:106] Iteration 2587500, lr = 0.01
I0831 04:35:49.523607 916722 solver.cpp:218] Iteration 2588000 (16.8423 iter/s, 29.6872s/500 iters), loss = 0.257584
I0831 04:35:49.523659 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.257589 (* 1 = 0.257589 loss)
I0831 04:35:49.523669 916722 sgd_solver.cpp:106] Iteration 2588000, lr = 0.01
I0831 04:36:19.210197 916722 solver.cpp:218] Iteration 2588500 (16.8427 iter/s, 29.6865s/500 iters), loss = 0.0811471
I0831 04:36:19.210258 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0811515 (* 1 = 0.0811515 loss)
I0831 04:36:19.210266 916722 sgd_solver.cpp:106] Iteration 2588500, lr = 0.01
I0831 04:36:48.896802 916722 solver.cpp:218] Iteration 2589000 (16.8427 iter/s, 29.6865s/500 iters), loss = 0.129016
I0831 04:36:48.896857 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.12902 (* 1 = 0.12902 loss)
I0831 04:36:48.896867 916722 sgd_solver.cpp:106] Iteration 2589000, lr = 0.01
I0831 04:37:18.584547 916722 solver.cpp:218] Iteration 2589500 (16.842 iter/s, 29.6876s/500 iters), loss = 0.137606
I0831 04:37:18.584619 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.137611 (* 1 = 0.137611 loss)
I0831 04:37:18.584631 916722 sgd_solver.cpp:106] Iteration 2589500, lr = 0.01
I0831 04:37:48.275079 916722 solver.cpp:218] Iteration 2590000 (16.8405 iter/s, 29.6904s/500 iters), loss = 0.0319011
I0831 04:37:48.275132 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0319056 (* 1 = 0.0319056 loss)
I0831 04:37:48.275142 916722 sgd_solver.cpp:106] Iteration 2590000, lr = 0.01
I0831 04:38:17.964541 916722 solver.cpp:218] Iteration 2590500 (16.8411 iter/s, 29.6893s/500 iters), loss = 0.093444
I0831 04:38:17.964604 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0934485 (* 1 = 0.0934485 loss)
I0831 04:38:17.964613 916722 sgd_solver.cpp:106] Iteration 2590500, lr = 0.01
I0831 04:38:47.655416 916722 solver.cpp:218] Iteration 2591000 (16.8403 iter/s, 29.6907s/500 iters), loss = 0.371161
I0831 04:38:47.655465 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.371166 (* 1 = 0.371166 loss)
I0831 04:38:47.655473 916722 sgd_solver.cpp:106] Iteration 2591000, lr = 0.01
I0831 04:39:17.348083 916722 solver.cpp:218] Iteration 2591500 (16.8393 iter/s, 29.6925s/500 iters), loss = 0.246672
I0831 04:39:17.348145 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.246677 (* 1 = 0.246677 loss)
I0831 04:39:17.348152 916722 sgd_solver.cpp:106] Iteration 2591500, lr = 0.01
I0831 04:39:47.035919 916722 solver.cpp:218] Iteration 2592000 (16.842 iter/s, 29.6877s/500 iters), loss = 0.0295012
I0831 04:39:47.035974 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0295057 (* 1 = 0.0295057 loss)
I0831 04:39:47.035982 916722 sgd_solver.cpp:106] Iteration 2592000, lr = 0.01
I0831 04:40:16.728209 916722 solver.cpp:218] Iteration 2592500 (16.8395 iter/s, 29.6921s/500 iters), loss = 0.197472
I0831 04:40:16.728268 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.197477 (* 1 = 0.197477 loss)
I0831 04:40:16.728276 916722 sgd_solver.cpp:106] Iteration 2592500, lr = 0.01
I0831 04:40:46.415835 916722 solver.cpp:218] Iteration 2593000 (16.8421 iter/s, 29.6875s/500 iters), loss = 0.197807
I0831 04:40:46.415889 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.197812 (* 1 = 0.197812 loss)
I0831 04:40:46.415897 916722 sgd_solver.cpp:106] Iteration 2593000, lr = 0.01
I0831 04:41:16.103147 916722 solver.cpp:218] Iteration 2593500 (16.8423 iter/s, 29.6872s/500 iters), loss = 0.134298
I0831 04:41:16.103209 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.134303 (* 1 = 0.134303 loss)
I0831 04:41:16.103217 916722 sgd_solver.cpp:106] Iteration 2593500, lr = 0.01
I0831 04:41:45.790875 916722 solver.cpp:218] Iteration 2594000 (16.8421 iter/s, 29.6876s/500 iters), loss = 0.178832
I0831 04:41:45.790927 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.178837 (* 1 = 0.178837 loss)
I0831 04:41:45.790936 916722 sgd_solver.cpp:106] Iteration 2594000, lr = 0.01
I0831 04:42:15.480684 916722 solver.cpp:218] Iteration 2594500 (16.8409 iter/s, 29.6897s/500 iters), loss = 0.0474306
I0831 04:42:15.480756 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0474353 (* 1 = 0.0474353 loss)
I0831 04:42:15.480763 916722 sgd_solver.cpp:106] Iteration 2594500, lr = 0.01
I0831 04:42:45.166832 916722 solver.cpp:218] Iteration 2595000 (16.843 iter/s, 29.686s/500 iters), loss = 0.0367087
I0831 04:42:45.166883 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0367134 (* 1 = 0.0367134 loss)
I0831 04:42:45.166893 916722 sgd_solver.cpp:106] Iteration 2595000, lr = 0.01
I0831 04:43:14.856196 916722 solver.cpp:218] Iteration 2595500 (16.8411 iter/s, 29.6892s/500 iters), loss = 0.117866
I0831 04:43:14.856257 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.117871 (* 1 = 0.117871 loss)
I0831 04:43:14.856266 916722 sgd_solver.cpp:106] Iteration 2595500, lr = 0.01
I0831 04:43:44.543057 916722 solver.cpp:218] Iteration 2596000 (16.8426 iter/s, 29.6867s/500 iters), loss = 0.213615
I0831 04:43:44.543113 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.213619 (* 1 = 0.213619 loss)
I0831 04:43:44.543135 916722 sgd_solver.cpp:106] Iteration 2596000, lr = 0.01
I0831 04:44:14.232471 916722 solver.cpp:218] Iteration 2596500 (16.8411 iter/s, 29.6893s/500 iters), loss = 0.307443
I0831 04:44:14.232542 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.307448 (* 1 = 0.307448 loss)
I0831 04:44:14.232551 916722 sgd_solver.cpp:106] Iteration 2596500, lr = 0.01
I0831 04:44:43.920559 916722 solver.cpp:218] Iteration 2597000 (16.8419 iter/s, 29.6879s/500 iters), loss = 0.0780593
I0831 04:44:43.920614 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0780639 (* 1 = 0.0780639 loss)
I0831 04:44:43.920625 916722 sgd_solver.cpp:106] Iteration 2597000, lr = 0.01
I0831 04:45:13.608688 916722 solver.cpp:218] Iteration 2597500 (16.8418 iter/s, 29.688s/500 iters), loss = 0.230276
I0831 04:45:13.608760 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.230281 (* 1 = 0.230281 loss)
I0831 04:45:13.608769 916722 sgd_solver.cpp:106] Iteration 2597500, lr = 0.01
I0831 04:45:43.296188 916722 solver.cpp:218] Iteration 2598000 (16.8422 iter/s, 29.6873s/500 iters), loss = 0.0612462
I0831 04:45:43.296241 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0612508 (* 1 = 0.0612508 loss)
I0831 04:45:43.296252 916722 sgd_solver.cpp:106] Iteration 2598000, lr = 0.01
I0831 04:46:12.985040 916722 solver.cpp:218] Iteration 2598500 (16.8414 iter/s, 29.6887s/500 iters), loss = 0.326357
I0831 04:46:12.985096 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.326361 (* 1 = 0.326361 loss)
I0831 04:46:12.985105 916722 sgd_solver.cpp:106] Iteration 2598500, lr = 0.01
I0831 04:46:42.672302 916722 solver.cpp:218] Iteration 2599000 (16.8423 iter/s, 29.6871s/500 iters), loss = 0.0803369
I0831 04:46:42.672354 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0803414 (* 1 = 0.0803414 loss)
I0831 04:46:42.672364 916722 sgd_solver.cpp:106] Iteration 2599000, lr = 0.01
I0831 04:47:12.363806 916722 solver.cpp:218] Iteration 2599500 (16.8399 iter/s, 29.6913s/500 iters), loss = 0.212591
I0831 04:47:12.363863 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.212595 (* 1 = 0.212595 loss)
I0831 04:47:12.363873 916722 sgd_solver.cpp:106] Iteration 2599500, lr = 0.01
I0831 04:47:41.994685 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_2600000.caffemodel
I0831 04:47:42.013880 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_2600000.solverstate
I0831 04:47:42.019942 916722 solver.cpp:330] Iteration 2600000, Testing net (#0)
I0831 04:47:57.329984 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8877
I0831 04:47:57.330034 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.37507 (* 1 = 0.37507 loss)
I0831 04:47:57.388486 916722 solver.cpp:218] Iteration 2600000 (11.1051 iter/s, 45.0245s/500 iters), loss = 0.212816
I0831 04:47:57.388514 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.212821 (* 1 = 0.212821 loss)
I0831 04:47:57.388522 916722 sgd_solver.cpp:106] Iteration 2600000, lr = 0.01
I0831 04:48:26.970955 916722 solver.cpp:218] Iteration 2600500 (16.902 iter/s, 29.5823s/500 iters), loss = 0.16372
I0831 04:48:26.971010 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.163724 (* 1 = 0.163724 loss)
I0831 04:48:26.971019 916722 sgd_solver.cpp:106] Iteration 2600500, lr = 0.01
I0831 04:48:56.679083 916722 solver.cpp:218] Iteration 2601000 (16.8305 iter/s, 29.7079s/500 iters), loss = 0.106958
I0831 04:48:56.679142 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.106963 (* 1 = 0.106963 loss)
I0831 04:48:56.679150 916722 sgd_solver.cpp:106] Iteration 2601000, lr = 0.01
I0831 04:49:26.387589 916722 solver.cpp:218] Iteration 2601500 (16.8303 iter/s, 29.7083s/500 iters), loss = 0.379378
I0831 04:49:26.387638 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.379382 (* 1 = 0.379382 loss)
I0831 04:49:26.387648 916722 sgd_solver.cpp:106] Iteration 2601500, lr = 0.01
I0831 04:49:56.098912 916722 solver.cpp:218] Iteration 2602000 (16.8287 iter/s, 29.7112s/500 iters), loss = 0.352169
I0831 04:49:56.098981 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.352173 (* 1 = 0.352173 loss)
I0831 04:49:56.098990 916722 sgd_solver.cpp:106] Iteration 2602000, lr = 0.01
I0831 04:50:25.813727 916722 solver.cpp:218] Iteration 2602500 (16.8267 iter/s, 29.7146s/500 iters), loss = 0.167377
I0831 04:50:25.813779 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.167382 (* 1 = 0.167382 loss)
I0831 04:50:25.813789 916722 sgd_solver.cpp:106] Iteration 2602500, lr = 0.01
I0831 04:50:55.525012 916722 solver.cpp:218] Iteration 2603000 (16.8287 iter/s, 29.7111s/500 iters), loss = 0.221517
I0831 04:50:55.525075 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.221522 (* 1 = 0.221522 loss)
I0831 04:50:55.525086 916722 sgd_solver.cpp:106] Iteration 2603000, lr = 0.01
I0831 04:51:25.237965 916722 solver.cpp:218] Iteration 2603500 (16.8278 iter/s, 29.7128s/500 iters), loss = 0.115852
I0831 04:51:25.238013 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115857 (* 1 = 0.115857 loss)
I0831 04:51:25.238021 916722 sgd_solver.cpp:106] Iteration 2603500, lr = 0.01
I0831 04:51:54.954491 916722 solver.cpp:218] Iteration 2604000 (16.8257 iter/s, 29.7164s/500 iters), loss = 0.0859014
I0831 04:51:54.954551 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0859061 (* 1 = 0.0859061 loss)
I0831 04:51:54.954560 916722 sgd_solver.cpp:106] Iteration 2604000, lr = 0.01
I0831 04:52:24.674762 916722 solver.cpp:218] Iteration 2604500 (16.8236 iter/s, 29.7201s/500 iters), loss = 0.0740996
I0831 04:52:24.674814 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0741042 (* 1 = 0.0741042 loss)
I0831 04:52:24.674823 916722 sgd_solver.cpp:106] Iteration 2604500, lr = 0.01
I0831 04:52:54.394060 916722 solver.cpp:218] Iteration 2605000 (16.8242 iter/s, 29.7191s/500 iters), loss = 0.0528426
I0831 04:52:54.394120 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0528472 (* 1 = 0.0528472 loss)
I0831 04:52:54.394129 916722 sgd_solver.cpp:106] Iteration 2605000, lr = 0.01
I0831 04:53:24.115612 916722 solver.cpp:218] Iteration 2605500 (16.8229 iter/s, 29.7214s/500 iters), loss = 0.328926
I0831 04:53:24.115669 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.328931 (* 1 = 0.328931 loss)
I0831 04:53:24.115679 916722 sgd_solver.cpp:106] Iteration 2605500, lr = 0.01
I0831 04:53:53.840188 916722 solver.cpp:218] Iteration 2606000 (16.8212 iter/s, 29.7244s/500 iters), loss = 0.232097
I0831 04:53:53.840245 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.232102 (* 1 = 0.232102 loss)
I0831 04:53:53.840253 916722 sgd_solver.cpp:106] Iteration 2606000, lr = 0.01
I0831 04:54:23.563585 916722 solver.cpp:218] Iteration 2606500 (16.8219 iter/s, 29.7232s/500 iters), loss = 0.110335
I0831 04:54:23.563638 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110339 (* 1 = 0.110339 loss)
I0831 04:54:23.563648 916722 sgd_solver.cpp:106] Iteration 2606500, lr = 0.01
I0831 04:54:53.286401 916722 solver.cpp:218] Iteration 2607000 (16.8222 iter/s, 29.7226s/500 iters), loss = 0.349409
I0831 04:54:53.286460 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.349414 (* 1 = 0.349414 loss)
I0831 04:54:53.286468 916722 sgd_solver.cpp:106] Iteration 2607000, lr = 0.01
I0831 04:55:23.007418 916722 solver.cpp:218] Iteration 2607500 (16.8232 iter/s, 29.7208s/500 iters), loss = 0.0501918
I0831 04:55:23.007472 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0501965 (* 1 = 0.0501965 loss)
I0831 04:55:23.007483 916722 sgd_solver.cpp:106] Iteration 2607500, lr = 0.01
I0831 04:55:52.729185 916722 solver.cpp:218] Iteration 2608000 (16.8228 iter/s, 29.7216s/500 iters), loss = 0.348208
I0831 04:55:52.729244 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.348212 (* 1 = 0.348212 loss)
I0831 04:55:52.729252 916722 sgd_solver.cpp:106] Iteration 2608000, lr = 0.01
I0831 04:56:22.448959 916722 solver.cpp:218] Iteration 2608500 (16.8238 iter/s, 29.7198s/500 iters), loss = 0.25708
I0831 04:56:22.449012 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.257085 (* 1 = 0.257085 loss)
I0831 04:56:22.449023 916722 sgd_solver.cpp:106] Iteration 2608500, lr = 0.01
I0831 04:56:52.174235 916722 solver.cpp:218] Iteration 2609000 (16.8206 iter/s, 29.7254s/500 iters), loss = 0.0588634
I0831 04:56:52.174305 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.058868 (* 1 = 0.058868 loss)
I0831 04:56:52.174314 916722 sgd_solver.cpp:106] Iteration 2609000, lr = 0.01
I0831 04:57:21.893770 916722 solver.cpp:218] Iteration 2609500 (16.8239 iter/s, 29.7197s/500 iters), loss = 0.35739
I0831 04:57:21.893823 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.357394 (* 1 = 0.357394 loss)
I0831 04:57:21.893833 916722 sgd_solver.cpp:106] Iteration 2609500, lr = 0.01
I0831 04:57:51.616878 916722 solver.cpp:218] Iteration 2610000 (16.8219 iter/s, 29.7232s/500 iters), loss = 0.24962
I0831 04:57:51.616933 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.249625 (* 1 = 0.249625 loss)
I0831 04:57:51.616941 916722 sgd_solver.cpp:106] Iteration 2610000, lr = 0.01
I0831 04:58:21.334515 916722 solver.cpp:218] Iteration 2610500 (16.825 iter/s, 29.7178s/500 iters), loss = 0.0931056
I0831 04:58:21.334563 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0931102 (* 1 = 0.0931102 loss)
I0831 04:58:21.334573 916722 sgd_solver.cpp:106] Iteration 2610500, lr = 0.01
I0831 04:58:51.056732 916722 solver.cpp:218] Iteration 2611000 (16.8224 iter/s, 29.7223s/500 iters), loss = 0.294238
I0831 04:58:51.056805 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.294243 (* 1 = 0.294243 loss)
I0831 04:58:51.056813 916722 sgd_solver.cpp:106] Iteration 2611000, lr = 0.01
I0831 04:59:20.781095 916722 solver.cpp:218] Iteration 2611500 (16.8212 iter/s, 29.7244s/500 iters), loss = 0.105968
I0831 04:59:20.781148 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105973 (* 1 = 0.105973 loss)
I0831 04:59:20.781157 916722 sgd_solver.cpp:106] Iteration 2611500, lr = 0.01
I0831 04:59:50.508627 916722 solver.cpp:218] Iteration 2612000 (16.8194 iter/s, 29.7276s/500 iters), loss = 0.0361026
I0831 04:59:50.508690 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0361074 (* 1 = 0.0361074 loss)
I0831 04:59:50.508700 916722 sgd_solver.cpp:106] Iteration 2612000, lr = 0.01
I0831 05:00:20.224872 916722 solver.cpp:218] Iteration 2612500 (16.8258 iter/s, 29.7163s/500 iters), loss = 0.528986
I0831 05:00:20.224925 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.528991 (* 1 = 0.528991 loss)
I0831 05:00:20.224933 916722 sgd_solver.cpp:106] Iteration 2612500, lr = 0.01
I0831 05:00:49.948457 916722 solver.cpp:218] Iteration 2613000 (16.8216 iter/s, 29.7236s/500 iters), loss = 0.0611666
I0831 05:00:49.948518 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0611714 (* 1 = 0.0611714 loss)
I0831 05:00:49.948526 916722 sgd_solver.cpp:106] Iteration 2613000, lr = 0.01
I0831 05:01:19.673993 916722 solver.cpp:218] Iteration 2613500 (16.8205 iter/s, 29.7256s/500 iters), loss = 0.138855
I0831 05:01:19.674046 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13886 (* 1 = 0.13886 loss)
I0831 05:01:19.674055 916722 sgd_solver.cpp:106] Iteration 2613500, lr = 0.01
I0831 05:01:49.393975 916722 solver.cpp:218] Iteration 2614000 (16.8237 iter/s, 29.72s/500 iters), loss = 0.13151
I0831 05:01:49.394033 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131515 (* 1 = 0.131515 loss)
I0831 05:01:49.394042 916722 sgd_solver.cpp:106] Iteration 2614000, lr = 0.01
I0831 05:02:19.115541 916722 solver.cpp:218] Iteration 2614500 (16.8228 iter/s, 29.7216s/500 iters), loss = 0.074552
I0831 05:02:19.115593 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0745569 (* 1 = 0.0745569 loss)
I0831 05:02:19.115602 916722 sgd_solver.cpp:106] Iteration 2614500, lr = 0.01
I0831 05:02:48.833025 916722 solver.cpp:218] Iteration 2615000 (16.8251 iter/s, 29.7175s/500 iters), loss = 0.0651009
I0831 05:02:48.833101 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0651059 (* 1 = 0.0651059 loss)
I0831 05:02:48.833108 916722 sgd_solver.cpp:106] Iteration 2615000, lr = 0.01
I0831 05:03:18.554944 916722 solver.cpp:218] Iteration 2615500 (16.8226 iter/s, 29.7219s/500 iters), loss = 0.181307
I0831 05:03:18.554998 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.181312 (* 1 = 0.181312 loss)
I0831 05:03:18.555009 916722 sgd_solver.cpp:106] Iteration 2615500, lr = 0.01
I0831 05:03:48.275146 916722 solver.cpp:218] Iteration 2616000 (16.8236 iter/s, 29.7202s/500 iters), loss = 0.110863
I0831 05:03:48.275204 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110868 (* 1 = 0.110868 loss)
I0831 05:03:48.275213 916722 sgd_solver.cpp:106] Iteration 2616000, lr = 0.01
I0831 05:04:17.996920 916722 solver.cpp:218] Iteration 2616500 (16.8227 iter/s, 29.7218s/500 iters), loss = 0.114608
I0831 05:04:17.996973 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.114613 (* 1 = 0.114613 loss)
I0831 05:04:17.996984 916722 sgd_solver.cpp:106] Iteration 2616500, lr = 0.01
I0831 05:04:47.718757 916722 solver.cpp:218] Iteration 2617000 (16.8227 iter/s, 29.7218s/500 iters), loss = 0.238394
I0831 05:04:47.718816 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.238399 (* 1 = 0.238399 loss)
I0831 05:04:47.718825 916722 sgd_solver.cpp:106] Iteration 2617000, lr = 0.01
I0831 05:05:17.440344 916722 solver.cpp:218] Iteration 2617500 (16.8228 iter/s, 29.7216s/500 iters), loss = 0.0404591
I0831 05:05:17.440397 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0404638 (* 1 = 0.0404638 loss)
I0831 05:05:17.440407 916722 sgd_solver.cpp:106] Iteration 2617500, lr = 0.01
I0831 05:05:47.162601 916722 solver.cpp:218] Iteration 2618000 (16.8224 iter/s, 29.7222s/500 iters), loss = 0.0954867
I0831 05:05:47.162659 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0954915 (* 1 = 0.0954915 loss)
I0831 05:05:47.162668 916722 sgd_solver.cpp:106] Iteration 2618000, lr = 0.01
I0831 05:06:16.885334 916722 solver.cpp:218] Iteration 2618500 (16.8222 iter/s, 29.7227s/500 iters), loss = 0.186833
I0831 05:06:16.885385 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.186837 (* 1 = 0.186837 loss)
I0831 05:06:16.885394 916722 sgd_solver.cpp:106] Iteration 2618500, lr = 0.01
I0831 05:06:46.601135 916722 solver.cpp:218] Iteration 2619000 (16.8261 iter/s, 29.7158s/500 iters), loss = 0.205506
I0831 05:06:46.601191 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.20551 (* 1 = 0.20551 loss)
I0831 05:06:46.601199 916722 sgd_solver.cpp:106] Iteration 2619000, lr = 0.01
I0831 05:07:16.325026 916722 solver.cpp:218] Iteration 2619500 (16.8215 iter/s, 29.7239s/500 iters), loss = 0.204069
I0831 05:07:16.325079 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.204073 (* 1 = 0.204073 loss)
I0831 05:07:16.325089 916722 sgd_solver.cpp:106] Iteration 2619500, lr = 0.01
I0831 05:07:46.048209 916722 solver.cpp:218] Iteration 2620000 (16.8219 iter/s, 29.7231s/500 iters), loss = 0.209267
I0831 05:07:46.048271 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.209271 (* 1 = 0.209271 loss)
I0831 05:07:46.048280 916722 sgd_solver.cpp:106] Iteration 2620000, lr = 0.01
I0831 05:08:15.782099 916722 solver.cpp:218] Iteration 2620500 (16.8159 iter/s, 29.7338s/500 iters), loss = 0.23157
I0831 05:08:15.782153 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.231575 (* 1 = 0.231575 loss)
I0831 05:08:15.782162 916722 sgd_solver.cpp:106] Iteration 2620500, lr = 0.01
I0831 05:08:45.506074 916722 solver.cpp:218] Iteration 2621000 (16.8215 iter/s, 29.7239s/500 iters), loss = 0.163935
I0831 05:08:45.506134 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.16394 (* 1 = 0.16394 loss)
I0831 05:08:45.506142 916722 sgd_solver.cpp:106] Iteration 2621000, lr = 0.01
I0831 05:09:15.226596 916722 solver.cpp:218] Iteration 2621500 (16.8234 iter/s, 29.7205s/500 iters), loss = 0.0810921
I0831 05:09:15.226663 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0810968 (* 1 = 0.0810968 loss)
I0831 05:09:15.226672 916722 sgd_solver.cpp:106] Iteration 2621500, lr = 0.01
I0831 05:09:44.946789 916722 solver.cpp:218] Iteration 2622000 (16.8236 iter/s, 29.7201s/500 iters), loss = 0.133718
I0831 05:09:44.946859 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133722 (* 1 = 0.133722 loss)
I0831 05:09:44.946868 916722 sgd_solver.cpp:106] Iteration 2622000, lr = 0.01
I0831 05:10:14.665993 916722 solver.cpp:218] Iteration 2622500 (16.8242 iter/s, 29.7191s/500 iters), loss = 0.143302
I0831 05:10:14.666045 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.143307 (* 1 = 0.143307 loss)
I0831 05:10:14.666054 916722 sgd_solver.cpp:106] Iteration 2622500, lr = 0.01
I0831 05:10:44.387030 916722 solver.cpp:218] Iteration 2623000 (16.8231 iter/s, 29.721s/500 iters), loss = 0.0766149
I0831 05:10:44.387087 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0766197 (* 1 = 0.0766197 loss)
I0831 05:10:44.387095 916722 sgd_solver.cpp:106] Iteration 2623000, lr = 0.01
I0831 05:11:14.107656 916722 solver.cpp:218] Iteration 2623500 (16.8234 iter/s, 29.7205s/500 iters), loss = 0.0852701
I0831 05:11:14.107705 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0852751 (* 1 = 0.0852751 loss)
I0831 05:11:14.107714 916722 sgd_solver.cpp:106] Iteration 2623500, lr = 0.01
I0831 05:11:43.823725 916722 solver.cpp:218] Iteration 2624000 (16.826 iter/s, 29.716s/500 iters), loss = 0.0567545
I0831 05:11:43.823783 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0567595 (* 1 = 0.0567595 loss)
I0831 05:11:43.823791 916722 sgd_solver.cpp:106] Iteration 2624000, lr = 0.01
I0831 05:12:13.544719 916722 solver.cpp:218] Iteration 2624500 (16.8232 iter/s, 29.7209s/500 iters), loss = 0.16796
I0831 05:12:13.544793 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.167965 (* 1 = 0.167965 loss)
I0831 05:12:13.544802 916722 sgd_solver.cpp:106] Iteration 2624500, lr = 0.01
I0831 05:12:43.268091 916722 solver.cpp:218] Iteration 2625000 (16.8218 iter/s, 29.7233s/500 iters), loss = 0.133763
I0831 05:12:43.268151 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133768 (* 1 = 0.133768 loss)
I0831 05:12:43.268159 916722 sgd_solver.cpp:106] Iteration 2625000, lr = 0.01
I0831 05:13:12.986050 916722 solver.cpp:218] Iteration 2625500 (16.8249 iter/s, 29.7179s/500 iters), loss = 0.0388997
I0831 05:13:12.986102 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0389045 (* 1 = 0.0389045 loss)
I0831 05:13:12.986111 916722 sgd_solver.cpp:106] Iteration 2625500, lr = 0.01
I0831 05:13:42.702067 916722 solver.cpp:218] Iteration 2626000 (16.826 iter/s, 29.7159s/500 iters), loss = 0.416939
I0831 05:13:42.702127 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.416944 (* 1 = 0.416944 loss)
I0831 05:13:42.702136 916722 sgd_solver.cpp:106] Iteration 2626000, lr = 0.01
I0831 05:14:12.420151 916722 solver.cpp:218] Iteration 2626500 (16.8248 iter/s, 29.718s/500 iters), loss = 0.0774132
I0831 05:14:12.420204 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0774181 (* 1 = 0.0774181 loss)
I0831 05:14:12.420213 916722 sgd_solver.cpp:106] Iteration 2626500, lr = 0.01
I0831 05:14:42.140878 916722 solver.cpp:218] Iteration 2627000 (16.8233 iter/s, 29.7206s/500 iters), loss = 0.0340122
I0831 05:14:42.140938 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0340171 (* 1 = 0.0340171 loss)
I0831 05:14:42.140946 916722 sgd_solver.cpp:106] Iteration 2627000, lr = 0.01
I0831 05:15:11.858044 916722 solver.cpp:218] Iteration 2627500 (16.8254 iter/s, 29.7171s/500 iters), loss = 0.357234
I0831 05:15:11.858094 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.357239 (* 1 = 0.357239 loss)
I0831 05:15:11.858103 916722 sgd_solver.cpp:106] Iteration 2627500, lr = 0.01
I0831 05:15:41.572836 916722 solver.cpp:218] Iteration 2628000 (16.8267 iter/s, 29.7147s/500 iters), loss = 0.287425
I0831 05:15:41.572902 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.28743 (* 1 = 0.28743 loss)
I0831 05:15:41.572916 916722 sgd_solver.cpp:106] Iteration 2628000, lr = 0.01
I0831 05:16:11.293414 916722 solver.cpp:218] Iteration 2628500 (16.8234 iter/s, 29.7205s/500 iters), loss = 0.432292
I0831 05:16:11.293467 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.432297 (* 1 = 0.432297 loss)
I0831 05:16:11.293475 916722 sgd_solver.cpp:106] Iteration 2628500, lr = 0.01
I0831 05:16:41.011505 916722 solver.cpp:218] Iteration 2629000 (16.8248 iter/s, 29.718s/500 iters), loss = 0.291031
I0831 05:16:41.011569 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.291036 (* 1 = 0.291036 loss)
I0831 05:16:41.011579 916722 sgd_solver.cpp:106] Iteration 2629000, lr = 0.01
I0831 05:17:10.729360 916722 solver.cpp:218] Iteration 2629500 (16.825 iter/s, 29.7177s/500 iters), loss = 0.0631182
I0831 05:17:10.729418 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0631233 (* 1 = 0.0631233 loss)
I0831 05:17:10.729426 916722 sgd_solver.cpp:106] Iteration 2629500, lr = 0.01
I0831 05:17:40.448777 916722 solver.cpp:218] Iteration 2630000 (16.8241 iter/s, 29.7193s/500 iters), loss = 0.147637
I0831 05:17:40.448837 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.147642 (* 1 = 0.147642 loss)
I0831 05:17:40.448844 916722 sgd_solver.cpp:106] Iteration 2630000, lr = 0.01
I0831 05:18:10.169227 916722 solver.cpp:218] Iteration 2630500 (16.8235 iter/s, 29.7203s/500 iters), loss = 0.143195
I0831 05:18:10.169281 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.1432 (* 1 = 0.1432 loss)
I0831 05:18:10.169291 916722 sgd_solver.cpp:106] Iteration 2630500, lr = 0.01
I0831 05:18:39.889143 916722 solver.cpp:218] Iteration 2631000 (16.8238 iter/s, 29.7198s/500 iters), loss = 0.216115
I0831 05:18:39.889204 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.21612 (* 1 = 0.21612 loss)
I0831 05:18:39.889212 916722 sgd_solver.cpp:106] Iteration 2631000, lr = 0.01
I0831 05:19:09.605329 916722 solver.cpp:218] Iteration 2631500 (16.8259 iter/s, 29.7161s/500 iters), loss = 0.260789
I0831 05:19:09.605376 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.260794 (* 1 = 0.260794 loss)
I0831 05:19:09.605384 916722 sgd_solver.cpp:106] Iteration 2631500, lr = 0.01
I0831 05:19:39.329383 916722 solver.cpp:218] Iteration 2632000 (16.8215 iter/s, 29.7239s/500 iters), loss = 0.194229
I0831 05:19:39.329439 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.194233 (* 1 = 0.194233 loss)
I0831 05:19:39.329447 916722 sgd_solver.cpp:106] Iteration 2632000, lr = 0.01
I0831 05:20:09.050720 916722 solver.cpp:218] Iteration 2632500 (16.823 iter/s, 29.7212s/500 iters), loss = 0.187047
I0831 05:20:09.050771 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.187052 (* 1 = 0.187052 loss)
I0831 05:20:09.050782 916722 sgd_solver.cpp:106] Iteration 2632500, lr = 0.01
I0831 05:20:38.773905 916722 solver.cpp:218] Iteration 2633000 (16.8219 iter/s, 29.7231s/500 iters), loss = 0.104857
I0831 05:20:38.773964 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104861 (* 1 = 0.104861 loss)
I0831 05:20:38.773972 916722 sgd_solver.cpp:106] Iteration 2633000, lr = 0.01
I0831 05:21:08.488183 916722 solver.cpp:218] Iteration 2633500 (16.827 iter/s, 29.7142s/500 iters), loss = 0.117122
I0831 05:21:08.488235 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.117126 (* 1 = 0.117126 loss)
I0831 05:21:08.488245 916722 sgd_solver.cpp:106] Iteration 2633500, lr = 0.01
I0831 05:21:38.207037 916722 solver.cpp:218] Iteration 2634000 (16.8244 iter/s, 29.7187s/500 iters), loss = 0.0770527
I0831 05:21:38.207095 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0770576 (* 1 = 0.0770576 loss)
I0831 05:21:38.207104 916722 sgd_solver.cpp:106] Iteration 2634000, lr = 0.01
I0831 05:22:07.930981 916722 solver.cpp:218] Iteration 2634500 (16.8215 iter/s, 29.7238s/500 iters), loss = 0.201433
I0831 05:22:07.931035 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.201438 (* 1 = 0.201438 loss)
I0831 05:22:07.931056 916722 sgd_solver.cpp:106] Iteration 2634500, lr = 0.01
I0831 05:22:37.652755 916722 solver.cpp:218] Iteration 2635000 (16.8228 iter/s, 29.7217s/500 iters), loss = 0.0568325
I0831 05:22:37.652827 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0568373 (* 1 = 0.0568373 loss)
I0831 05:22:37.652837 916722 sgd_solver.cpp:106] Iteration 2635000, lr = 0.01
I0831 05:23:07.373208 916722 solver.cpp:218] Iteration 2635500 (16.8235 iter/s, 29.7203s/500 iters), loss = 0.0713598
I0831 05:23:07.373260 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0713646 (* 1 = 0.0713646 loss)
I0831 05:23:07.373270 916722 sgd_solver.cpp:106] Iteration 2635500, lr = 0.01
I0831 05:23:37.091555 916722 solver.cpp:218] Iteration 2636000 (16.8247 iter/s, 29.7182s/500 iters), loss = 0.168878
I0831 05:23:37.091614 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.168882 (* 1 = 0.168882 loss)
I0831 05:23:37.091622 916722 sgd_solver.cpp:106] Iteration 2636000, lr = 0.01
I0831 05:24:06.814069 916722 solver.cpp:218] Iteration 2636500 (16.8223 iter/s, 29.7224s/500 iters), loss = 0.24185
I0831 05:24:06.814119 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.241854 (* 1 = 0.241854 loss)
I0831 05:24:06.814127 916722 sgd_solver.cpp:106] Iteration 2636500, lr = 0.01
I0831 05:24:36.534854 916722 solver.cpp:218] Iteration 2637000 (16.8233 iter/s, 29.7207s/500 iters), loss = 0.350891
I0831 05:24:36.534914 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.350896 (* 1 = 0.350896 loss)
I0831 05:24:36.534921 916722 sgd_solver.cpp:106] Iteration 2637000, lr = 0.01
I0831 05:25:06.256899 916722 solver.cpp:218] Iteration 2637500 (16.8226 iter/s, 29.7219s/500 iters), loss = 0.245706
I0831 05:25:06.256953 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.245711 (* 1 = 0.245711 loss)
I0831 05:25:06.256961 916722 sgd_solver.cpp:106] Iteration 2637500, lr = 0.01
I0831 05:25:35.974229 916722 solver.cpp:218] Iteration 2638000 (16.8253 iter/s, 29.7172s/500 iters), loss = 0.170134
I0831 05:25:35.974288 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.170139 (* 1 = 0.170139 loss)
I0831 05:25:35.974296 916722 sgd_solver.cpp:106] Iteration 2638000, lr = 0.01
I0831 05:26:05.692782 916722 solver.cpp:218] Iteration 2638500 (16.8246 iter/s, 29.7184s/500 iters), loss = 0.0529143
I0831 05:26:05.692835 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0529192 (* 1 = 0.0529192 loss)
I0831 05:26:05.692843 916722 sgd_solver.cpp:106] Iteration 2638500, lr = 0.01
I0831 05:26:35.414628 916722 solver.cpp:218] Iteration 2639000 (16.8227 iter/s, 29.7217s/500 iters), loss = 0.286913
I0831 05:26:35.414685 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.286918 (* 1 = 0.286918 loss)
I0831 05:26:35.414693 916722 sgd_solver.cpp:106] Iteration 2639000, lr = 0.01
I0831 05:27:05.138670 916722 solver.cpp:218] Iteration 2639500 (16.8215 iter/s, 29.7239s/500 iters), loss = 0.313309
I0831 05:27:05.138722 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.313314 (* 1 = 0.313314 loss)
I0831 05:27:05.138731 916722 sgd_solver.cpp:106] Iteration 2639500, lr = 0.01
I0831 05:27:34.860337 916722 solver.cpp:218] Iteration 2640000 (16.8228 iter/s, 29.7215s/500 iters), loss = 0.225954
I0831 05:27:34.860395 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.225959 (* 1 = 0.225959 loss)
I0831 05:27:34.860404 916722 sgd_solver.cpp:106] Iteration 2640000, lr = 0.01
I0831 05:28:04.586851 916722 solver.cpp:218] Iteration 2640500 (16.8201 iter/s, 29.7264s/500 iters), loss = 0.163629
I0831 05:28:04.586905 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.163634 (* 1 = 0.163634 loss)
I0831 05:28:04.586915 916722 sgd_solver.cpp:106] Iteration 2640500, lr = 0.01
I0831 05:28:34.304785 916722 solver.cpp:218] Iteration 2641000 (16.8249 iter/s, 29.7178s/500 iters), loss = 0.0265929
I0831 05:28:34.304850 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0265979 (* 1 = 0.0265979 loss)
I0831 05:28:34.304859 916722 sgd_solver.cpp:106] Iteration 2641000, lr = 0.01
I0831 05:29:04.029422 916722 solver.cpp:218] Iteration 2641500 (16.8211 iter/s, 29.7245s/500 iters), loss = 0.279949
I0831 05:29:04.029474 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.279954 (* 1 = 0.279954 loss)
I0831 05:29:04.029484 916722 sgd_solver.cpp:106] Iteration 2641500, lr = 0.01
I0831 05:29:33.751016 916722 solver.cpp:218] Iteration 2642000 (16.8229 iter/s, 29.7215s/500 iters), loss = 0.185745
I0831 05:29:33.751075 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.18575 (* 1 = 0.18575 loss)
I0831 05:29:33.751083 916722 sgd_solver.cpp:106] Iteration 2642000, lr = 0.01
I0831 05:30:03.471737 916722 solver.cpp:218] Iteration 2642500 (16.8234 iter/s, 29.7206s/500 iters), loss = 0.213548
I0831 05:30:03.471788 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.213553 (* 1 = 0.213553 loss)
I0831 05:30:03.471798 916722 sgd_solver.cpp:106] Iteration 2642500, lr = 0.01
I0831 05:30:33.187346 916722 solver.cpp:218] Iteration 2643000 (16.8263 iter/s, 29.7153s/500 iters), loss = 0.346199
I0831 05:30:33.187404 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.346204 (* 1 = 0.346204 loss)
I0831 05:30:33.187412 916722 sgd_solver.cpp:106] Iteration 2643000, lr = 0.01
I0831 05:31:02.908087 916722 solver.cpp:218] Iteration 2643500 (16.8234 iter/s, 29.7204s/500 iters), loss = 0.106109
I0831 05:31:02.908140 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.106114 (* 1 = 0.106114 loss)
I0831 05:31:02.908149 916722 sgd_solver.cpp:106] Iteration 2643500, lr = 0.01
I0831 05:31:32.628355 916722 solver.cpp:218] Iteration 2644000 (16.8237 iter/s, 29.72s/500 iters), loss = 0.0434708
I0831 05:31:32.628417 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0434757 (* 1 = 0.0434757 loss)
I0831 05:31:32.628430 916722 sgd_solver.cpp:106] Iteration 2644000, lr = 0.01
I0831 05:32:02.351536 916722 solver.cpp:218] Iteration 2644500 (16.8221 iter/s, 29.7229s/500 iters), loss = 0.406649
I0831 05:32:02.351586 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.406654 (* 1 = 0.406654 loss)
I0831 05:32:02.351596 916722 sgd_solver.cpp:106] Iteration 2644500, lr = 0.01
I0831 05:32:32.072939 916722 solver.cpp:218] Iteration 2645000 (16.8231 iter/s, 29.7211s/500 iters), loss = 0.0555764
I0831 05:32:32.073001 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0555811 (* 1 = 0.0555811 loss)
I0831 05:32:32.073009 916722 sgd_solver.cpp:106] Iteration 2645000, lr = 0.01
I0831 05:33:01.793081 916722 solver.cpp:218] Iteration 2645500 (16.8238 iter/s, 29.7199s/500 iters), loss = 0.279519
I0831 05:33:01.793133 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.279524 (* 1 = 0.279524 loss)
I0831 05:33:01.793141 916722 sgd_solver.cpp:106] Iteration 2645500, lr = 0.01
I0831 05:33:31.516898 916722 solver.cpp:218] Iteration 2646000 (16.8217 iter/s, 29.7236s/500 iters), loss = 0.083912
I0831 05:33:31.516961 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0839168 (* 1 = 0.0839168 loss)
I0831 05:33:31.516969 916722 sgd_solver.cpp:106] Iteration 2646000, lr = 0.01
I0831 05:34:01.238054 916722 solver.cpp:218] Iteration 2646500 (16.8232 iter/s, 29.7209s/500 iters), loss = 0.0612669
I0831 05:34:01.238106 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0612717 (* 1 = 0.0612717 loss)
I0831 05:34:01.238114 916722 sgd_solver.cpp:106] Iteration 2646500, lr = 0.01
I0831 05:34:30.959277 916722 solver.cpp:218] Iteration 2647000 (16.8231 iter/s, 29.721s/500 iters), loss = 0.264083
I0831 05:34:30.959336 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.264087 (* 1 = 0.264087 loss)
I0831 05:34:30.959344 916722 sgd_solver.cpp:106] Iteration 2647000, lr = 0.01
I0831 05:35:00.677644 916722 solver.cpp:218] Iteration 2647500 (16.8248 iter/s, 29.7181s/500 iters), loss = 0.297392
I0831 05:35:00.677695 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.297397 (* 1 = 0.297397 loss)
I0831 05:35:00.677702 916722 sgd_solver.cpp:106] Iteration 2647500, lr = 0.01
I0831 05:35:30.403465 916722 solver.cpp:218] Iteration 2648000 (16.8205 iter/s, 29.7256s/500 iters), loss = 0.0171935
I0831 05:35:30.403537 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.017198 (* 1 = 0.017198 loss)
I0831 05:35:30.403546 916722 sgd_solver.cpp:106] Iteration 2648000, lr = 0.01
I0831 05:36:00.126463 916722 solver.cpp:218] Iteration 2648500 (16.8221 iter/s, 29.7227s/500 iters), loss = 0.0256164
I0831 05:36:00.126516 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0256209 (* 1 = 0.0256209 loss)
I0831 05:36:00.126525 916722 sgd_solver.cpp:106] Iteration 2648500, lr = 0.01
I0831 05:36:29.856518 916722 solver.cpp:218] Iteration 2649000 (16.8181 iter/s, 29.7298s/500 iters), loss = 0.0223883
I0831 05:36:29.856575 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0223928 (* 1 = 0.0223928 loss)
I0831 05:36:29.856583 916722 sgd_solver.cpp:106] Iteration 2649000, lr = 0.01
I0831 05:36:59.595049 916722 solver.cpp:218] Iteration 2649500 (16.8133 iter/s, 29.7383s/500 iters), loss = 0.039681
I0831 05:36:59.595098 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0396855 (* 1 = 0.0396855 loss)
I0831 05:36:59.595106 916722 sgd_solver.cpp:106] Iteration 2649500, lr = 0.01
I0831 05:37:29.264274 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_2650000.caffemodel
I0831 05:37:29.283288 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_2650000.solverstate
I0831 05:37:29.289351 916722 solver.cpp:330] Iteration 2650000, Testing net (#0)
I0831 05:37:44.658603 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8965
I0831 05:37:44.658641 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.360708 (* 1 = 0.360708 loss)
I0831 05:37:44.717010 916722 solver.cpp:218] Iteration 2650000 (11.0812 iter/s, 45.1217s/500 iters), loss = 0.0721601
I0831 05:37:44.717036 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0721645 (* 1 = 0.0721645 loss)
I0831 05:37:44.717044 916722 sgd_solver.cpp:106] Iteration 2650000, lr = 0.01
I0831 05:38:14.318578 916722 solver.cpp:218] Iteration 2650500 (16.8911 iter/s, 29.6013s/500 iters), loss = 0.0566506
I0831 05:38:14.318634 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0566551 (* 1 = 0.0566551 loss)
I0831 05:38:14.318643 916722 sgd_solver.cpp:106] Iteration 2650500, lr = 0.01
I0831 05:38:44.012737 916722 solver.cpp:218] Iteration 2651000 (16.8385 iter/s, 29.6939s/500 iters), loss = 0.0630658
I0831 05:38:44.012794 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0630704 (* 1 = 0.0630704 loss)
I0831 05:38:44.012802 916722 sgd_solver.cpp:106] Iteration 2651000, lr = 0.01
I0831 05:39:13.733254 916722 solver.cpp:218] Iteration 2651500 (16.8235 iter/s, 29.7203s/500 iters), loss = 0.283266
I0831 05:39:13.733317 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.283271 (* 1 = 0.283271 loss)
I0831 05:39:13.733326 916722 sgd_solver.cpp:106] Iteration 2651500, lr = 0.01
I0831 05:39:43.463922 916722 solver.cpp:218] Iteration 2652000 (16.8178 iter/s, 29.7304s/500 iters), loss = 0.0743975
I0831 05:39:43.463977 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.074402 (* 1 = 0.074402 loss)
I0831 05:39:43.463986 916722 sgd_solver.cpp:106] Iteration 2652000, lr = 0.01
I0831 05:40:13.195436 916722 solver.cpp:218] Iteration 2652500 (16.8173 iter/s, 29.7313s/500 iters), loss = 0.258599
I0831 05:40:13.195502 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.258603 (* 1 = 0.258603 loss)
I0831 05:40:13.195511 916722 sgd_solver.cpp:106] Iteration 2652500, lr = 0.01
I0831 05:40:42.927889 916722 solver.cpp:218] Iteration 2653000 (16.8168 iter/s, 29.7322s/500 iters), loss = 0.0939551
I0831 05:40:42.927943 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0939595 (* 1 = 0.0939595 loss)
I0831 05:40:42.927953 916722 sgd_solver.cpp:106] Iteration 2653000, lr = 0.01
I0831 05:41:12.657932 916722 solver.cpp:218] Iteration 2653500 (16.8181 iter/s, 29.7298s/500 iters), loss = 0.148468
I0831 05:41:12.658008 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.148473 (* 1 = 0.148473 loss)
I0831 05:41:12.658017 916722 sgd_solver.cpp:106] Iteration 2653500, lr = 0.01
I0831 05:41:42.391109 916722 solver.cpp:218] Iteration 2654000 (16.8164 iter/s, 29.733s/500 iters), loss = 0.0696293
I0831 05:41:42.391160 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0696338 (* 1 = 0.0696338 loss)
I0831 05:41:42.391170 916722 sgd_solver.cpp:106] Iteration 2654000, lr = 0.01
I0831 05:42:12.123327 916722 solver.cpp:218] Iteration 2654500 (16.8169 iter/s, 29.732s/500 iters), loss = 0.113841
I0831 05:42:12.123389 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.113846 (* 1 = 0.113846 loss)
I0831 05:42:12.123397 916722 sgd_solver.cpp:106] Iteration 2654500, lr = 0.01
I0831 05:42:41.856772 916722 solver.cpp:218] Iteration 2655000 (16.8162 iter/s, 29.7332s/500 iters), loss = 0.161883
I0831 05:42:41.856828 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.161888 (* 1 = 0.161888 loss)
I0831 05:42:41.856837 916722 sgd_solver.cpp:106] Iteration 2655000, lr = 0.01
I0831 05:43:11.590651 916722 solver.cpp:218] Iteration 2655500 (16.8159 iter/s, 29.7337s/500 iters), loss = 0.187488
I0831 05:43:11.590714 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.187492 (* 1 = 0.187492 loss)
I0831 05:43:11.590723 916722 sgd_solver.cpp:106] Iteration 2655500, lr = 0.01
I0831 05:43:41.321430 916722 solver.cpp:218] Iteration 2656000 (16.8177 iter/s, 29.7306s/500 iters), loss = 0.0813188
I0831 05:43:41.321489 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0813233 (* 1 = 0.0813233 loss)
I0831 05:43:41.321501 916722 sgd_solver.cpp:106] Iteration 2656000, lr = 0.01
I0831 05:44:11.052160 916722 solver.cpp:218] Iteration 2656500 (16.8177 iter/s, 29.7305s/500 iters), loss = 0.0348554
I0831 05:44:11.052219 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0348599 (* 1 = 0.0348599 loss)
I0831 05:44:11.052228 916722 sgd_solver.cpp:106] Iteration 2656500, lr = 0.01
I0831 05:44:40.783903 916722 solver.cpp:218] Iteration 2657000 (16.8171 iter/s, 29.7316s/500 iters), loss = 0.0482143
I0831 05:44:40.783958 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0482187 (* 1 = 0.0482187 loss)
I0831 05:44:40.783968 916722 sgd_solver.cpp:106] Iteration 2657000, lr = 0.01
I0831 05:45:10.520849 916722 solver.cpp:218] Iteration 2657500 (16.8142 iter/s, 29.7368s/500 iters), loss = 0.213173
I0831 05:45:10.520910 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.213177 (* 1 = 0.213177 loss)
I0831 05:45:10.520918 916722 sgd_solver.cpp:106] Iteration 2657500, lr = 0.01
I0831 05:45:40.252498 916722 solver.cpp:218] Iteration 2658000 (16.8172 iter/s, 29.7315s/500 iters), loss = 0.0215456
I0831 05:45:40.252552 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.02155 (* 1 = 0.02155 loss)
I0831 05:45:40.252561 916722 sgd_solver.cpp:106] Iteration 2658000, lr = 0.01
I0831 05:46:09.988243 916722 solver.cpp:218] Iteration 2658500 (16.8149 iter/s, 29.7356s/500 iters), loss = 0.247675
I0831 05:46:09.988304 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.247679 (* 1 = 0.247679 loss)
I0831 05:46:09.988313 916722 sgd_solver.cpp:106] Iteration 2658500, lr = 0.01
I0831 05:46:39.723320 916722 solver.cpp:218] Iteration 2659000 (16.8153 iter/s, 29.7349s/500 iters), loss = 0.11847
I0831 05:46:39.723376 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.118474 (* 1 = 0.118474 loss)
I0831 05:46:39.723385 916722 sgd_solver.cpp:106] Iteration 2659000, lr = 0.01
I0831 05:47:09.457422 916722 solver.cpp:218] Iteration 2659500 (16.8158 iter/s, 29.7339s/500 iters), loss = 0.0533169
I0831 05:47:09.457481 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.053321 (* 1 = 0.053321 loss)
I0831 05:47:09.457490 916722 sgd_solver.cpp:106] Iteration 2659500, lr = 0.01
I0831 05:47:39.197027 916722 solver.cpp:218] Iteration 2660000 (16.8127 iter/s, 29.7394s/500 iters), loss = 0.234613
I0831 05:47:39.197094 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.234617 (* 1 = 0.234617 loss)
I0831 05:47:39.197104 916722 sgd_solver.cpp:106] Iteration 2660000, lr = 0.01
I0831 05:48:08.934993 916722 solver.cpp:218] Iteration 2660500 (16.8136 iter/s, 29.7378s/500 iters), loss = 0.160948
I0831 05:48:08.935063 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.160952 (* 1 = 0.160952 loss)
I0831 05:48:08.935072 916722 sgd_solver.cpp:106] Iteration 2660500, lr = 0.01
I0831 05:48:38.671430 916722 solver.cpp:218] Iteration 2661000 (16.8145 iter/s, 29.7362s/500 iters), loss = 0.0344936
I0831 05:48:38.671486 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0344975 (* 1 = 0.0344975 loss)
I0831 05:48:38.671496 916722 sgd_solver.cpp:106] Iteration 2661000, lr = 0.01
I0831 05:49:08.406766 916722 solver.cpp:218] Iteration 2661500 (16.8151 iter/s, 29.7352s/500 iters), loss = 0.146458
I0831 05:49:08.406832 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.146462 (* 1 = 0.146462 loss)
I0831 05:49:08.406841 916722 sgd_solver.cpp:106] Iteration 2661500, lr = 0.01
I0831 05:49:38.138195 916722 solver.cpp:218] Iteration 2662000 (16.8173 iter/s, 29.7312s/500 iters), loss = 0.129309
I0831 05:49:38.138247 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.129312 (* 1 = 0.129312 loss)
I0831 05:49:38.138255 916722 sgd_solver.cpp:106] Iteration 2662000, lr = 0.01
I0831 05:50:07.862185 916722 solver.cpp:218] Iteration 2662500 (16.8215 iter/s, 29.7238s/500 iters), loss = 0.198588
I0831 05:50:07.862244 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.198592 (* 1 = 0.198592 loss)
I0831 05:50:07.862252 916722 sgd_solver.cpp:106] Iteration 2662500, lr = 0.01
I0831 05:50:37.588014 916722 solver.cpp:218] Iteration 2663000 (16.8205 iter/s, 29.7257s/500 iters), loss = 0.111058
I0831 05:50:37.588069 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111062 (* 1 = 0.111062 loss)
I0831 05:50:37.588078 916722 sgd_solver.cpp:106] Iteration 2663000, lr = 0.01
I0831 05:51:07.309235 916722 solver.cpp:218] Iteration 2663500 (16.8231 iter/s, 29.7211s/500 iters), loss = 0.1928
I0831 05:51:07.309294 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.192804 (* 1 = 0.192804 loss)
I0831 05:51:07.309303 916722 sgd_solver.cpp:106] Iteration 2663500, lr = 0.01
I0831 05:51:37.032095 916722 solver.cpp:218] Iteration 2664000 (16.8222 iter/s, 29.7227s/500 iters), loss = 0.0985443
I0831 05:51:37.032150 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.098548 (* 1 = 0.098548 loss)
I0831 05:51:37.032157 916722 sgd_solver.cpp:106] Iteration 2664000, lr = 0.01
I0831 05:52:06.753682 916722 solver.cpp:218] Iteration 2664500 (16.8229 iter/s, 29.7214s/500 iters), loss = 0.0534017
I0831 05:52:06.753743 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0534054 (* 1 = 0.0534054 loss)
I0831 05:52:06.753751 916722 sgd_solver.cpp:106] Iteration 2664500, lr = 0.01
I0831 05:52:36.478407 916722 solver.cpp:218] Iteration 2665000 (16.8211 iter/s, 29.7245s/500 iters), loss = 0.0702343
I0831 05:52:36.478462 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0702378 (* 1 = 0.0702378 loss)
I0831 05:52:36.478471 916722 sgd_solver.cpp:106] Iteration 2665000, lr = 0.01
I0831 05:53:06.201050 916722 solver.cpp:218] Iteration 2665500 (16.8223 iter/s, 29.7225s/500 iters), loss = 0.0685598
I0831 05:53:06.201113 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0685635 (* 1 = 0.0685635 loss)
I0831 05:53:06.201122 916722 sgd_solver.cpp:106] Iteration 2665500, lr = 0.01
I0831 05:53:35.921073 916722 solver.cpp:218] Iteration 2666000 (16.8238 iter/s, 29.7198s/500 iters), loss = 0.0453542
I0831 05:53:35.921124 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0453578 (* 1 = 0.0453578 loss)
I0831 05:53:35.921133 916722 sgd_solver.cpp:106] Iteration 2666000, lr = 0.01
I0831 05:54:05.647608 916722 solver.cpp:218] Iteration 2666500 (16.8201 iter/s, 29.7264s/500 iters), loss = 0.157584
I0831 05:54:05.647677 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.157588 (* 1 = 0.157588 loss)
I0831 05:54:05.647691 916722 sgd_solver.cpp:106] Iteration 2666500, lr = 0.01
I0831 05:54:35.370527 916722 solver.cpp:218] Iteration 2667000 (16.8221 iter/s, 29.7227s/500 iters), loss = 0.240522
I0831 05:54:35.370579 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.240525 (* 1 = 0.240525 loss)
I0831 05:54:35.370589 916722 sgd_solver.cpp:106] Iteration 2667000, lr = 0.01
I0831 05:55:05.093852 916722 solver.cpp:218] Iteration 2667500 (16.8219 iter/s, 29.7232s/500 iters), loss = 0.0410589
I0831 05:55:05.093910 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0410622 (* 1 = 0.0410622 loss)
I0831 05:55:05.093919 916722 sgd_solver.cpp:106] Iteration 2667500, lr = 0.01
I0831 05:55:34.823467 916722 solver.cpp:218] Iteration 2668000 (16.8183 iter/s, 29.7294s/500 iters), loss = 0.303927
I0831 05:55:34.823523 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.30393 (* 1 = 0.30393 loss)
I0831 05:55:34.823534 916722 sgd_solver.cpp:106] Iteration 2668000, lr = 0.01
I0831 05:56:04.549304 916722 solver.cpp:218] Iteration 2668500 (16.8205 iter/s, 29.7257s/500 iters), loss = 0.349887
I0831 05:56:04.549362 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.34989 (* 1 = 0.34989 loss)
I0831 05:56:04.549371 916722 sgd_solver.cpp:106] Iteration 2668500, lr = 0.01
I0831 05:56:34.274400 916722 solver.cpp:218] Iteration 2669000 (16.8209 iter/s, 29.7249s/500 iters), loss = 0.142808
I0831 05:56:34.274456 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.142812 (* 1 = 0.142812 loss)
I0831 05:56:34.274466 916722 sgd_solver.cpp:106] Iteration 2669000, lr = 0.01
I0831 05:57:03.998286 916722 solver.cpp:218] Iteration 2669500 (16.8216 iter/s, 29.7237s/500 iters), loss = 0.080628
I0831 05:57:03.998344 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0806311 (* 1 = 0.0806311 loss)
I0831 05:57:03.998353 916722 sgd_solver.cpp:106] Iteration 2669500, lr = 0.01
I0831 05:57:33.723949 916722 solver.cpp:218] Iteration 2670000 (16.8206 iter/s, 29.7255s/500 iters), loss = 0.204845
I0831 05:57:33.724004 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.204848 (* 1 = 0.204848 loss)
I0831 05:57:33.724014 916722 sgd_solver.cpp:106] Iteration 2670000, lr = 0.01
I0831 05:58:03.446318 916722 solver.cpp:218] Iteration 2670500 (16.8224 iter/s, 29.7222s/500 iters), loss = 0.0594797
I0831 05:58:03.446372 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.059483 (* 1 = 0.059483 loss)
I0831 05:58:03.446381 916722 sgd_solver.cpp:106] Iteration 2670500, lr = 0.01
I0831 05:58:33.171038 916722 solver.cpp:218] Iteration 2671000 (16.8211 iter/s, 29.7246s/500 iters), loss = 0.152388
I0831 05:58:33.171090 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152392 (* 1 = 0.152392 loss)
I0831 05:58:33.171099 916722 sgd_solver.cpp:106] Iteration 2671000, lr = 0.01
I0831 05:59:02.893934 916722 solver.cpp:218] Iteration 2671500 (16.8221 iter/s, 29.7227s/500 iters), loss = 0.231955
I0831 05:59:02.893988 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.231958 (* 1 = 0.231958 loss)
I0831 05:59:02.893997 916722 sgd_solver.cpp:106] Iteration 2671500, lr = 0.01
I0831 05:59:32.620204 916722 solver.cpp:218] Iteration 2672000 (16.8202 iter/s, 29.7261s/500 iters), loss = 0.141693
I0831 05:59:32.620261 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.141696 (* 1 = 0.141696 loss)
I0831 05:59:32.620271 916722 sgd_solver.cpp:106] Iteration 2672000, lr = 0.01
I0831 06:00:02.340798 916722 solver.cpp:218] Iteration 2672500 (16.8234 iter/s, 29.7204s/500 iters), loss = 0.130875
I0831 06:00:02.340857 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130878 (* 1 = 0.130878 loss)
I0831 06:00:02.340867 916722 sgd_solver.cpp:106] Iteration 2672500, lr = 0.01
I0831 06:00:32.063225 916722 solver.cpp:218] Iteration 2673000 (16.8224 iter/s, 29.7223s/500 iters), loss = 0.36748
I0831 06:00:32.063280 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.367483 (* 1 = 0.367483 loss)
I0831 06:00:32.063302 916722 sgd_solver.cpp:106] Iteration 2673000, lr = 0.01
I0831 06:01:01.785252 916722 solver.cpp:218] Iteration 2673500 (16.8226 iter/s, 29.7219s/500 iters), loss = 0.268928
I0831 06:01:01.785320 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.268932 (* 1 = 0.268932 loss)
I0831 06:01:01.785329 916722 sgd_solver.cpp:106] Iteration 2673500, lr = 0.01
I0831 06:01:31.507865 916722 solver.cpp:218] Iteration 2674000 (16.8223 iter/s, 29.7224s/500 iters), loss = 0.139263
I0831 06:01:31.507920 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139267 (* 1 = 0.139267 loss)
I0831 06:01:31.507930 916722 sgd_solver.cpp:106] Iteration 2674000, lr = 0.01
I0831 06:02:01.232879 916722 solver.cpp:218] Iteration 2674500 (16.8209 iter/s, 29.7248s/500 iters), loss = 0.274222
I0831 06:02:01.232937 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.274225 (* 1 = 0.274225 loss)
I0831 06:02:01.232946 916722 sgd_solver.cpp:106] Iteration 2674500, lr = 0.01
I0831 06:02:30.958092 916722 solver.cpp:218] Iteration 2675000 (16.8208 iter/s, 29.7251s/500 iters), loss = 0.0884131
I0831 06:02:30.958145 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0884165 (* 1 = 0.0884165 loss)
I0831 06:02:30.958155 916722 sgd_solver.cpp:106] Iteration 2675000, lr = 0.01
I0831 06:03:00.682056 916722 solver.cpp:218] Iteration 2675500 (16.8215 iter/s, 29.7238s/500 iters), loss = 0.166432
I0831 06:03:00.682114 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.166435 (* 1 = 0.166435 loss)
I0831 06:03:00.682122 916722 sgd_solver.cpp:106] Iteration 2675500, lr = 0.01
I0831 06:03:30.404937 916722 solver.cpp:218] Iteration 2676000 (16.8221 iter/s, 29.7227s/500 iters), loss = 0.0299505
I0831 06:03:30.404994 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.029954 (* 1 = 0.029954 loss)
I0831 06:03:30.405004 916722 sgd_solver.cpp:106] Iteration 2676000, lr = 0.01
I0831 06:04:00.127254 916722 solver.cpp:218] Iteration 2676500 (16.8225 iter/s, 29.7222s/500 iters), loss = 0.104906
I0831 06:04:00.127315 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.10491 (* 1 = 0.10491 loss)
I0831 06:04:00.127324 916722 sgd_solver.cpp:106] Iteration 2676500, lr = 0.01
I0831 06:04:29.852367 916722 solver.cpp:218] Iteration 2677000 (16.821 iter/s, 29.7248s/500 iters), loss = 0.119211
I0831 06:04:29.852422 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.119214 (* 1 = 0.119214 loss)
I0831 06:04:29.852439 916722 sgd_solver.cpp:106] Iteration 2677000, lr = 0.01
I0831 06:04:59.572589 916722 solver.cpp:218] Iteration 2677500 (16.8239 iter/s, 29.7197s/500 iters), loss = 0.0382496
I0831 06:04:59.572660 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.038253 (* 1 = 0.038253 loss)
I0831 06:04:59.572669 916722 sgd_solver.cpp:106] Iteration 2677500, lr = 0.01
I0831 06:05:29.293658 916722 solver.cpp:218] Iteration 2678000 (16.8234 iter/s, 29.7205s/500 iters), loss = 0.10928
I0831 06:05:29.293712 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109284 (* 1 = 0.109284 loss)
I0831 06:05:29.293721 916722 sgd_solver.cpp:106] Iteration 2678000, lr = 0.01
I0831 06:05:59.018060 916722 solver.cpp:218] Iteration 2678500 (16.8215 iter/s, 29.7239s/500 iters), loss = 0.074341
I0831 06:05:59.018123 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0743445 (* 1 = 0.0743445 loss)
I0831 06:05:59.018132 916722 sgd_solver.cpp:106] Iteration 2678500, lr = 0.01
I0831 06:06:28.738497 916722 solver.cpp:218] Iteration 2679000 (16.8237 iter/s, 29.7199s/500 iters), loss = 0.231104
I0831 06:06:28.738548 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.231107 (* 1 = 0.231107 loss)
I0831 06:06:28.738556 916722 sgd_solver.cpp:106] Iteration 2679000, lr = 0.01
I0831 06:06:58.471082 916722 solver.cpp:218] Iteration 2679500 (16.8168 iter/s, 29.7321s/500 iters), loss = 0.159941
I0831 06:06:58.471151 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159945 (* 1 = 0.159945 loss)
I0831 06:06:58.471160 916722 sgd_solver.cpp:106] Iteration 2679500, lr = 0.01
I0831 06:07:28.193856 916722 solver.cpp:218] Iteration 2680000 (16.8224 iter/s, 29.7223s/500 iters), loss = 0.0459705
I0831 06:07:28.193905 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.045974 (* 1 = 0.045974 loss)
I0831 06:07:28.193913 916722 sgd_solver.cpp:106] Iteration 2680000, lr = 0.01
I0831 06:07:57.914692 916722 solver.cpp:218] Iteration 2680500 (16.8235 iter/s, 29.7204s/500 iters), loss = 0.547699
I0831 06:07:57.914753 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.547703 (* 1 = 0.547703 loss)
I0831 06:07:57.914762 916722 sgd_solver.cpp:106] Iteration 2680500, lr = 0.01
I0831 06:08:27.637789 916722 solver.cpp:218] Iteration 2681000 (16.8222 iter/s, 29.7227s/500 iters), loss = 0.0195952
I0831 06:08:27.637845 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0195987 (* 1 = 0.0195987 loss)
I0831 06:08:27.637854 916722 sgd_solver.cpp:106] Iteration 2681000, lr = 0.01
I0831 06:08:57.360901 916722 solver.cpp:218] Iteration 2681500 (16.8222 iter/s, 29.7227s/500 iters), loss = 0.0574326
I0831 06:08:57.360963 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.057436 (* 1 = 0.057436 loss)
I0831 06:08:57.360971 916722 sgd_solver.cpp:106] Iteration 2681500, lr = 0.01
I0831 06:09:27.082438 916722 solver.cpp:218] Iteration 2682000 (16.823 iter/s, 29.7211s/500 iters), loss = 0.209602
I0831 06:09:27.082492 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.209605 (* 1 = 0.209605 loss)
I0831 06:09:27.082501 916722 sgd_solver.cpp:106] Iteration 2682000, lr = 0.01
I0831 06:09:56.806067 916722 solver.cpp:218] Iteration 2682500 (16.8218 iter/s, 29.7232s/500 iters), loss = 0.189848
I0831 06:09:56.806129 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.189852 (* 1 = 0.189852 loss)
I0831 06:09:56.806138 916722 sgd_solver.cpp:106] Iteration 2682500, lr = 0.01
I0831 06:10:26.530323 916722 solver.cpp:218] Iteration 2683000 (16.8215 iter/s, 29.7239s/500 iters), loss = 0.170186
I0831 06:10:26.530378 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.170189 (* 1 = 0.170189 loss)
I0831 06:10:26.530388 916722 sgd_solver.cpp:106] Iteration 2683000, lr = 0.01
I0831 06:10:56.256729 916722 solver.cpp:218] Iteration 2683500 (16.8203 iter/s, 29.726s/500 iters), loss = 0.203499
I0831 06:10:56.256798 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.203503 (* 1 = 0.203503 loss)
I0831 06:10:56.256808 916722 sgd_solver.cpp:106] Iteration 2683500, lr = 0.01
I0831 06:11:25.981770 916722 solver.cpp:218] Iteration 2684000 (16.821 iter/s, 29.7247s/500 iters), loss = 0.0240225
I0831 06:11:25.981822 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0240256 (* 1 = 0.0240256 loss)
I0831 06:11:25.981832 916722 sgd_solver.cpp:106] Iteration 2684000, lr = 0.01
I0831 06:11:55.705891 916722 solver.cpp:218] Iteration 2684500 (16.8216 iter/s, 29.7238s/500 iters), loss = 0.259034
I0831 06:11:55.705946 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.259037 (* 1 = 0.259037 loss)
I0831 06:11:55.705955 916722 sgd_solver.cpp:106] Iteration 2684500, lr = 0.01
I0831 06:12:25.429653 916722 solver.cpp:218] Iteration 2685000 (16.8217 iter/s, 29.7234s/500 iters), loss = 0.120327
I0831 06:12:25.429709 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.12033 (* 1 = 0.12033 loss)
I0831 06:12:25.429719 916722 sgd_solver.cpp:106] Iteration 2685000, lr = 0.01
I0831 06:12:55.153355 916722 solver.cpp:218] Iteration 2685500 (16.8218 iter/s, 29.7234s/500 iters), loss = 0.0827159
I0831 06:12:55.153419 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.082719 (* 1 = 0.082719 loss)
I0831 06:12:55.153427 916722 sgd_solver.cpp:106] Iteration 2685500, lr = 0.01
I0831 06:13:24.881141 916722 solver.cpp:218] Iteration 2686000 (16.8195 iter/s, 29.7275s/500 iters), loss = 0.395791
I0831 06:13:24.881196 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.395795 (* 1 = 0.395795 loss)
I0831 06:13:24.881206 916722 sgd_solver.cpp:106] Iteration 2686000, lr = 0.01
I0831 06:13:54.602741 916722 solver.cpp:218] Iteration 2686500 (16.823 iter/s, 29.7213s/500 iters), loss = 0.0663413
I0831 06:13:54.602813 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0663445 (* 1 = 0.0663445 loss)
I0831 06:13:54.602821 916722 sgd_solver.cpp:106] Iteration 2686500, lr = 0.01
I0831 06:14:24.330631 916722 solver.cpp:218] Iteration 2687000 (16.8194 iter/s, 29.7276s/500 iters), loss = 0.217329
I0831 06:14:24.330683 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.217333 (* 1 = 0.217333 loss)
I0831 06:14:24.330694 916722 sgd_solver.cpp:106] Iteration 2687000, lr = 0.01
I0831 06:14:54.055941 916722 solver.cpp:218] Iteration 2687500 (16.8209 iter/s, 29.725s/500 iters), loss = 0.337651
I0831 06:14:54.056002 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.337655 (* 1 = 0.337655 loss)
I0831 06:14:54.056011 916722 sgd_solver.cpp:106] Iteration 2687500, lr = 0.01
I0831 06:15:23.781288 916722 solver.cpp:218] Iteration 2688000 (16.8208 iter/s, 29.725s/500 iters), loss = 0.192758
I0831 06:15:23.781339 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.192761 (* 1 = 0.192761 loss)
I0831 06:15:23.781349 916722 sgd_solver.cpp:106] Iteration 2688000, lr = 0.01
I0831 06:15:53.507015 916722 solver.cpp:218] Iteration 2688500 (16.8206 iter/s, 29.7254s/500 iters), loss = 0.375942
I0831 06:15:53.507071 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.375945 (* 1 = 0.375945 loss)
I0831 06:15:53.507079 916722 sgd_solver.cpp:106] Iteration 2688500, lr = 0.01
I0831 06:16:23.233306 916722 solver.cpp:218] Iteration 2689000 (16.8203 iter/s, 29.726s/500 iters), loss = 0.044055
I0831 06:16:23.233361 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0440582 (* 1 = 0.0440582 loss)
I0831 06:16:23.233372 916722 sgd_solver.cpp:106] Iteration 2689000, lr = 0.01
I0831 06:16:52.962720 916722 solver.cpp:218] Iteration 2689500 (16.8185 iter/s, 29.7291s/500 iters), loss = 0.31509
I0831 06:16:52.962782 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.315093 (* 1 = 0.315093 loss)
I0831 06:16:52.962791 916722 sgd_solver.cpp:106] Iteration 2689500, lr = 0.01
I0831 06:17:22.687150 916722 solver.cpp:218] Iteration 2690000 (16.8213 iter/s, 29.7241s/500 iters), loss = 0.125167
I0831 06:17:22.687202 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.125169 (* 1 = 0.125169 loss)
I0831 06:17:22.687211 916722 sgd_solver.cpp:106] Iteration 2690000, lr = 0.01
I0831 06:17:52.419263 916722 solver.cpp:218] Iteration 2690500 (16.817 iter/s, 29.7318s/500 iters), loss = 0.0448716
I0831 06:17:52.419324 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0448746 (* 1 = 0.0448746 loss)
I0831 06:17:52.419333 916722 sgd_solver.cpp:106] Iteration 2690500, lr = 0.01
I0831 06:18:22.144227 916722 solver.cpp:218] Iteration 2691000 (16.821 iter/s, 29.7247s/500 iters), loss = 0.109115
I0831 06:18:22.144280 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109118 (* 1 = 0.109118 loss)
I0831 06:18:22.144289 916722 sgd_solver.cpp:106] Iteration 2691000, lr = 0.01
I0831 06:18:51.871098 916722 solver.cpp:218] Iteration 2691500 (16.8199 iter/s, 29.7266s/500 iters), loss = 0.0431275
I0831 06:18:51.871160 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0431307 (* 1 = 0.0431307 loss)
I0831 06:18:51.871167 916722 sgd_solver.cpp:106] Iteration 2691500, lr = 0.01
I0831 06:19:21.595490 916722 solver.cpp:218] Iteration 2692000 (16.8214 iter/s, 29.7241s/500 iters), loss = 0.0240077
I0831 06:19:21.595541 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.024011 (* 1 = 0.024011 loss)
I0831 06:19:21.595551 916722 sgd_solver.cpp:106] Iteration 2692000, lr = 0.01
I0831 06:19:51.326215 916722 solver.cpp:218] Iteration 2692500 (16.8178 iter/s, 29.7305s/500 iters), loss = 0.0484435
I0831 06:19:51.326272 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0484468 (* 1 = 0.0484468 loss)
I0831 06:19:51.326280 916722 sgd_solver.cpp:106] Iteration 2692500, lr = 0.01
I0831 06:20:21.051527 916722 solver.cpp:218] Iteration 2693000 (16.8208 iter/s, 29.7251s/500 iters), loss = 0.174491
I0831 06:20:21.051584 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.174494 (* 1 = 0.174494 loss)
I0831 06:20:21.051592 916722 sgd_solver.cpp:106] Iteration 2693000, lr = 0.01
I0831 06:20:50.774720 916722 solver.cpp:218] Iteration 2693500 (16.822 iter/s, 29.7229s/500 iters), loss = 0.0999154
I0831 06:20:50.774793 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0999186 (* 1 = 0.0999186 loss)
I0831 06:20:50.774803 916722 sgd_solver.cpp:106] Iteration 2693500, lr = 0.01
I0831 06:21:20.500119 916722 solver.cpp:218] Iteration 2694000 (16.8208 iter/s, 29.7251s/500 iters), loss = 0.145928
I0831 06:21:20.500173 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.145931 (* 1 = 0.145931 loss)
I0831 06:21:20.500185 916722 sgd_solver.cpp:106] Iteration 2694000, lr = 0.01
I0831 06:21:50.223747 916722 solver.cpp:218] Iteration 2694500 (16.8218 iter/s, 29.7234s/500 iters), loss = 0.126306
I0831 06:21:50.223806 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.126309 (* 1 = 0.126309 loss)
I0831 06:21:50.223815 916722 sgd_solver.cpp:106] Iteration 2694500, lr = 0.01
I0831 06:22:19.944654 916722 solver.cpp:218] Iteration 2695000 (16.8233 iter/s, 29.7207s/500 iters), loss = 0.165672
I0831 06:22:19.944710 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.165675 (* 1 = 0.165675 loss)
I0831 06:22:19.944720 916722 sgd_solver.cpp:106] Iteration 2695000, lr = 0.01
I0831 06:22:49.676468 916722 solver.cpp:218] Iteration 2695500 (16.8171 iter/s, 29.7316s/500 iters), loss = 0.243055
I0831 06:22:49.676532 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.243059 (* 1 = 0.243059 loss)
I0831 06:22:49.676540 916722 sgd_solver.cpp:106] Iteration 2695500, lr = 0.01
I0831 06:23:19.399076 916722 solver.cpp:218] Iteration 2696000 (16.8224 iter/s, 29.7224s/500 iters), loss = 0.0770341
I0831 06:23:19.399129 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0770376 (* 1 = 0.0770376 loss)
I0831 06:23:19.399138 916722 sgd_solver.cpp:106] Iteration 2696000, lr = 0.01
I0831 06:23:49.125954 916722 solver.cpp:218] Iteration 2696500 (16.8199 iter/s, 29.7266s/500 iters), loss = 0.113116
I0831 06:23:49.126013 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.11312 (* 1 = 0.11312 loss)
I0831 06:23:49.126022 916722 sgd_solver.cpp:106] Iteration 2696500, lr = 0.01
I0831 06:24:18.851222 916722 solver.cpp:218] Iteration 2697000 (16.8208 iter/s, 29.725s/500 iters), loss = 0.0630575
I0831 06:24:18.851274 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0630608 (* 1 = 0.0630608 loss)
I0831 06:24:18.851281 916722 sgd_solver.cpp:106] Iteration 2697000, lr = 0.01
I0831 06:24:48.576978 916722 solver.cpp:218] Iteration 2697500 (16.8206 iter/s, 29.7255s/500 iters), loss = 0.0145928
I0831 06:24:48.577033 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0145962 (* 1 = 0.0145962 loss)
I0831 06:24:48.577042 916722 sgd_solver.cpp:106] Iteration 2697500, lr = 0.01
I0831 06:25:18.304183 916722 solver.cpp:218] Iteration 2698000 (16.8197 iter/s, 29.727s/500 iters), loss = 0.0598564
I0831 06:25:18.304237 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0598599 (* 1 = 0.0598599 loss)
I0831 06:25:18.304246 916722 sgd_solver.cpp:106] Iteration 2698000, lr = 0.01
I0831 06:25:48.030972 916722 solver.cpp:218] Iteration 2698500 (16.82 iter/s, 29.7266s/500 iters), loss = 0.13225
I0831 06:25:48.031030 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.132254 (* 1 = 0.132254 loss)
I0831 06:25:48.031038 916722 sgd_solver.cpp:106] Iteration 2698500, lr = 0.01
I0831 06:26:17.764560 916722 solver.cpp:218] Iteration 2699000 (16.8161 iter/s, 29.7334s/500 iters), loss = 0.101982
I0831 06:26:17.764613 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101986 (* 1 = 0.101986 loss)
I0831 06:26:17.764622 916722 sgd_solver.cpp:106] Iteration 2699000, lr = 0.01
I0831 06:26:47.491557 916722 solver.cpp:218] Iteration 2699500 (16.8199 iter/s, 29.7268s/500 iters), loss = 0.244614
I0831 06:26:47.491632 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.244618 (* 1 = 0.244618 loss)
I0831 06:26:47.491641 916722 sgd_solver.cpp:106] Iteration 2699500, lr = 0.01
I0831 06:27:17.160109 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_2700000.caffemodel
I0831 06:27:17.179513 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_2700000.solverstate
I0831 06:27:17.185557 916722 solver.cpp:330] Iteration 2700000, Testing net (#0)
I0831 06:27:32.556392 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8797
I0831 06:27:32.556473 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.438731 (* 1 = 0.438731 loss)
I0831 06:27:32.615082 916722 solver.cpp:218] Iteration 2700000 (11.0808 iter/s, 45.1232s/500 iters), loss = 0.202478
I0831 06:27:32.615110 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.202482 (* 1 = 0.202482 loss)
I0831 06:27:32.615118 916722 sgd_solver.cpp:106] Iteration 2700000, lr = 0.01
I0831 06:28:02.240628 916722 solver.cpp:218] Iteration 2700500 (16.8775 iter/s, 29.6253s/500 iters), loss = 0.23921
I0831 06:28:02.240679 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.239214 (* 1 = 0.239214 loss)
I0831 06:28:02.240689 916722 sgd_solver.cpp:106] Iteration 2700500, lr = 0.01
I0831 06:28:31.951417 916722 solver.cpp:218] Iteration 2701000 (16.829 iter/s, 29.7106s/500 iters), loss = 0.278739
I0831 06:28:31.951475 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.278743 (* 1 = 0.278743 loss)
I0831 06:28:31.951484 916722 sgd_solver.cpp:106] Iteration 2701000, lr = 0.01
I0831 06:29:01.666571 916722 solver.cpp:218] Iteration 2701500 (16.8266 iter/s, 29.7149s/500 iters), loss = 0.0332974
I0831 06:29:01.666622 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0333011 (* 1 = 0.0333011 loss)
I0831 06:29:01.666630 916722 sgd_solver.cpp:106] Iteration 2701500, lr = 0.01
I0831 06:29:31.389884 916722 solver.cpp:218] Iteration 2702000 (16.8219 iter/s, 29.7231s/500 iters), loss = 0.252582
I0831 06:29:31.389945 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.252586 (* 1 = 0.252586 loss)
I0831 06:29:31.389953 916722 sgd_solver.cpp:106] Iteration 2702000, lr = 0.01
I0831 06:30:01.108238 916722 solver.cpp:218] Iteration 2702500 (16.8247 iter/s, 29.7181s/500 iters), loss = 0.215623
I0831 06:30:01.108289 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.215627 (* 1 = 0.215627 loss)
I0831 06:30:01.108297 916722 sgd_solver.cpp:106] Iteration 2702500, lr = 0.01
I0831 06:30:30.829195 916722 solver.cpp:218] Iteration 2703000 (16.8233 iter/s, 29.7208s/500 iters), loss = 0.212081
I0831 06:30:30.829252 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.212085 (* 1 = 0.212085 loss)
I0831 06:30:30.829259 916722 sgd_solver.cpp:106] Iteration 2703000, lr = 0.01
I0831 06:31:00.554940 916722 solver.cpp:218] Iteration 2703500 (16.8206 iter/s, 29.7255s/500 iters), loss = 0.0646884
I0831 06:31:00.554991 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.064692 (* 1 = 0.064692 loss)
I0831 06:31:00.554999 916722 sgd_solver.cpp:106] Iteration 2703500, lr = 0.01
I0831 06:31:30.274910 916722 solver.cpp:218] Iteration 2704000 (16.8238 iter/s, 29.7198s/500 iters), loss = 0.112582
I0831 06:31:30.274971 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112586 (* 1 = 0.112586 loss)
I0831 06:31:30.274978 916722 sgd_solver.cpp:106] Iteration 2704000, lr = 0.01
I0831 06:31:59.993969 916722 solver.cpp:218] Iteration 2704500 (16.8243 iter/s, 29.7188s/500 iters), loss = 0.265493
I0831 06:31:59.994021 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.265496 (* 1 = 0.265496 loss)
I0831 06:31:59.994030 916722 sgd_solver.cpp:106] Iteration 2704500, lr = 0.01
I0831 06:32:29.717195 916722 solver.cpp:218] Iteration 2705000 (16.822 iter/s, 29.723s/500 iters), loss = 0.0406183
I0831 06:32:29.717270 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0406217 (* 1 = 0.0406217 loss)
I0831 06:32:29.717283 916722 sgd_solver.cpp:106] Iteration 2705000, lr = 0.01
I0831 06:32:59.438422 916722 solver.cpp:218] Iteration 2705500 (16.8231 iter/s, 29.721s/500 iters), loss = 0.254285
I0831 06:32:59.438474 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.254288 (* 1 = 0.254288 loss)
I0831 06:32:59.438484 916722 sgd_solver.cpp:106] Iteration 2705500, lr = 0.01
I0831 06:33:29.160830 916722 solver.cpp:218] Iteration 2706000 (16.8224 iter/s, 29.7222s/500 iters), loss = 0.211641
I0831 06:33:29.160887 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.211644 (* 1 = 0.211644 loss)
I0831 06:33:29.160895 916722 sgd_solver.cpp:106] Iteration 2706000, lr = 0.01
I0831 06:33:58.881409 916722 solver.cpp:218] Iteration 2706500 (16.8235 iter/s, 29.7204s/500 iters), loss = 0.0156942
I0831 06:33:58.881462 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0156974 (* 1 = 0.0156974 loss)
I0831 06:33:58.881474 916722 sgd_solver.cpp:106] Iteration 2706500, lr = 0.01
I0831 06:34:28.601980 916722 solver.cpp:218] Iteration 2707000 (16.8235 iter/s, 29.7204s/500 iters), loss = 0.154589
I0831 06:34:28.602041 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.154592 (* 1 = 0.154592 loss)
I0831 06:34:28.602048 916722 sgd_solver.cpp:106] Iteration 2707000, lr = 0.01
I0831 06:34:58.331765 916722 solver.cpp:218] Iteration 2707500 (16.8183 iter/s, 29.7296s/500 iters), loss = 0.146971
I0831 06:34:58.331817 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.146975 (* 1 = 0.146975 loss)
I0831 06:34:58.331827 916722 sgd_solver.cpp:106] Iteration 2707500, lr = 0.01
I0831 06:35:28.063558 916722 solver.cpp:218] Iteration 2708000 (16.8171 iter/s, 29.7316s/500 iters), loss = 0.186621
I0831 06:35:28.063618 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.186625 (* 1 = 0.186625 loss)
I0831 06:35:28.063628 916722 sgd_solver.cpp:106] Iteration 2708000, lr = 0.01
I0831 06:35:57.786967 916722 solver.cpp:218] Iteration 2708500 (16.8219 iter/s, 29.7232s/500 iters), loss = 0.194894
I0831 06:35:57.787019 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.194897 (* 1 = 0.194897 loss)
I0831 06:35:57.787030 916722 sgd_solver.cpp:106] Iteration 2708500, lr = 0.01
I0831 06:36:27.511335 916722 solver.cpp:218] Iteration 2709000 (16.8213 iter/s, 29.7242s/500 iters), loss = 0.190098
I0831 06:36:27.511391 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.190101 (* 1 = 0.190101 loss)
I0831 06:36:27.511399 916722 sgd_solver.cpp:106] Iteration 2709000, lr = 0.01
I0831 06:36:57.228754 916722 solver.cpp:218] Iteration 2709500 (16.8253 iter/s, 29.7172s/500 iters), loss = 0.437917
I0831 06:36:57.228804 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.437921 (* 1 = 0.437921 loss)
I0831 06:36:57.228813 916722 sgd_solver.cpp:106] Iteration 2709500, lr = 0.01
I0831 06:37:26.946521 916722 solver.cpp:218] Iteration 2710000 (16.8251 iter/s, 29.7176s/500 iters), loss = 0.106569
I0831 06:37:26.946580 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.106573 (* 1 = 0.106573 loss)
I0831 06:37:26.946589 916722 sgd_solver.cpp:106] Iteration 2710000, lr = 0.01
I0831 06:37:56.669595 916722 solver.cpp:218] Iteration 2710500 (16.8221 iter/s, 29.7229s/500 iters), loss = 0.100563
I0831 06:37:56.669651 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.100566 (* 1 = 0.100566 loss)
I0831 06:37:56.669661 916722 sgd_solver.cpp:106] Iteration 2710500, lr = 0.01
I0831 06:38:26.390605 916722 solver.cpp:218] Iteration 2711000 (16.8232 iter/s, 29.7208s/500 iters), loss = 0.0288975
I0831 06:38:26.390666 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0289008 (* 1 = 0.0289008 loss)
I0831 06:38:26.390673 916722 sgd_solver.cpp:106] Iteration 2711000, lr = 0.01
I0831 06:38:56.109908 916722 solver.cpp:218] Iteration 2711500 (16.8243 iter/s, 29.7189s/500 iters), loss = 0.154399
I0831 06:38:56.109961 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.154402 (* 1 = 0.154402 loss)
I0831 06:38:56.109983 916722 sgd_solver.cpp:106] Iteration 2711500, lr = 0.01
I0831 06:39:25.831279 916722 solver.cpp:218] Iteration 2712000 (16.8232 iter/s, 29.7209s/500 iters), loss = 0.137074
I0831 06:39:25.831349 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.137077 (* 1 = 0.137077 loss)
I0831 06:39:25.831358 916722 sgd_solver.cpp:106] Iteration 2712000, lr = 0.01
I0831 06:39:55.552778 916722 solver.cpp:218] Iteration 2712500 (16.8231 iter/s, 29.7211s/500 iters), loss = 0.250843
I0831 06:39:55.552829 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.250846 (* 1 = 0.250846 loss)
I0831 06:39:55.552839 916722 sgd_solver.cpp:106] Iteration 2712500, lr = 0.01
I0831 06:40:25.276185 916722 solver.cpp:218] Iteration 2713000 (16.822 iter/s, 29.723s/500 iters), loss = 0.164791
I0831 06:40:25.276239 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.164794 (* 1 = 0.164794 loss)
I0831 06:40:25.276247 916722 sgd_solver.cpp:106] Iteration 2713000, lr = 0.01
I0831 06:40:54.996768 916722 solver.cpp:218] Iteration 2713500 (16.8236 iter/s, 29.7202s/500 iters), loss = 0.0536274
I0831 06:40:54.996819 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0536304 (* 1 = 0.0536304 loss)
I0831 06:40:54.996829 916722 sgd_solver.cpp:106] Iteration 2713500, lr = 0.01
I0831 06:41:24.714496 916722 solver.cpp:218] Iteration 2714000 (16.8252 iter/s, 29.7173s/500 iters), loss = 0.104696
I0831 06:41:24.714555 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104699 (* 1 = 0.104699 loss)
I0831 06:41:24.714565 916722 sgd_solver.cpp:106] Iteration 2714000, lr = 0.01
I0831 06:41:54.437644 916722 solver.cpp:218] Iteration 2714500 (16.8221 iter/s, 29.7228s/500 iters), loss = 0.0166458
I0831 06:41:54.437696 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0166487 (* 1 = 0.0166487 loss)
I0831 06:41:54.437706 916722 sgd_solver.cpp:106] Iteration 2714500, lr = 0.01
I0831 06:42:24.157999 916722 solver.cpp:218] Iteration 2715000 (16.8237 iter/s, 29.72s/500 iters), loss = 0.244931
I0831 06:42:24.158061 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.244934 (* 1 = 0.244934 loss)
I0831 06:42:24.158069 916722 sgd_solver.cpp:106] Iteration 2715000, lr = 0.01
I0831 06:42:53.876957 916722 solver.cpp:218] Iteration 2715500 (16.8245 iter/s, 29.7186s/500 iters), loss = 0.431897
I0831 06:42:53.877004 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.431899 (* 1 = 0.431899 loss)
I0831 06:42:53.877013 916722 sgd_solver.cpp:106] Iteration 2715500, lr = 0.01
I0831 06:43:23.596709 916722 solver.cpp:218] Iteration 2716000 (16.824 iter/s, 29.7194s/500 iters), loss = 0.16054
I0831 06:43:23.596779 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.160543 (* 1 = 0.160543 loss)
I0831 06:43:23.596788 916722 sgd_solver.cpp:106] Iteration 2716000, lr = 0.01
I0831 06:43:53.319408 916722 solver.cpp:218] Iteration 2716500 (16.8224 iter/s, 29.7223s/500 iters), loss = 0.0636087
I0831 06:43:53.319460 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0636116 (* 1 = 0.0636116 loss)
I0831 06:43:53.319471 916722 sgd_solver.cpp:106] Iteration 2716500, lr = 0.01
I0831 06:44:23.040275 916722 solver.cpp:218] Iteration 2717000 (16.8234 iter/s, 29.7205s/500 iters), loss = 0.342332
I0831 06:44:23.040333 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.342335 (* 1 = 0.342335 loss)
I0831 06:44:23.040342 916722 sgd_solver.cpp:106] Iteration 2717000, lr = 0.01
I0831 06:44:52.759658 916722 solver.cpp:218] Iteration 2717500 (16.8242 iter/s, 29.7191s/500 iters), loss = 0.155447
I0831 06:44:52.759711 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.15545 (* 1 = 0.15545 loss)
I0831 06:44:52.759719 916722 sgd_solver.cpp:106] Iteration 2717500, lr = 0.01
I0831 06:45:22.478062 916722 solver.cpp:218] Iteration 2718000 (16.8248 iter/s, 29.7181s/500 iters), loss = 0.168713
I0831 06:45:22.478122 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.168716 (* 1 = 0.168716 loss)
I0831 06:45:22.478130 916722 sgd_solver.cpp:106] Iteration 2718000, lr = 0.01
I0831 06:45:52.195288 916722 solver.cpp:218] Iteration 2718500 (16.8254 iter/s, 29.7169s/500 iters), loss = 0.1767
I0831 06:45:52.195343 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.176703 (* 1 = 0.176703 loss)
I0831 06:45:52.195353 916722 sgd_solver.cpp:106] Iteration 2718500, lr = 0.01
I0831 06:46:21.913841 916722 solver.cpp:218] Iteration 2719000 (16.8247 iter/s, 29.7182s/500 iters), loss = 0.18413
I0831 06:46:21.913909 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.184133 (* 1 = 0.184133 loss)
I0831 06:46:21.913918 916722 sgd_solver.cpp:106] Iteration 2719000, lr = 0.01
I0831 06:46:51.637501 916722 solver.cpp:218] Iteration 2719500 (16.8218 iter/s, 29.7233s/500 iters), loss = 0.0380334
I0831 06:46:51.637553 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0380365 (* 1 = 0.0380365 loss)
I0831 06:46:51.637564 916722 sgd_solver.cpp:106] Iteration 2719500, lr = 0.01
I0831 06:47:21.358072 916722 solver.cpp:218] Iteration 2720000 (16.8235 iter/s, 29.7203s/500 iters), loss = 0.0332783
I0831 06:47:21.358134 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0332814 (* 1 = 0.0332814 loss)
I0831 06:47:21.358142 916722 sgd_solver.cpp:106] Iteration 2720000, lr = 0.01
I0831 06:47:51.075914 916722 solver.cpp:218] Iteration 2720500 (16.8251 iter/s, 29.7175s/500 iters), loss = 0.168664
I0831 06:47:51.075963 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.168667 (* 1 = 0.168667 loss)
I0831 06:47:51.075973 916722 sgd_solver.cpp:106] Iteration 2720500, lr = 0.01
I0831 06:48:20.800325 916722 solver.cpp:218] Iteration 2721000 (16.8214 iter/s, 29.7241s/500 iters), loss = 0.123046
I0831 06:48:20.800384 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.12305 (* 1 = 0.12305 loss)
I0831 06:48:20.800392 916722 sgd_solver.cpp:106] Iteration 2721000, lr = 0.01
I0831 06:48:50.520704 916722 solver.cpp:218] Iteration 2721500 (16.8236 iter/s, 29.7201s/500 iters), loss = 0.0854142
I0831 06:48:50.520769 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0854175 (* 1 = 0.0854175 loss)
I0831 06:48:50.520778 916722 sgd_solver.cpp:106] Iteration 2721500, lr = 0.01
I0831 06:49:20.243578 916722 solver.cpp:218] Iteration 2722000 (16.8222 iter/s, 29.7226s/500 iters), loss = 0.367598
I0831 06:49:20.243638 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.367601 (* 1 = 0.367601 loss)
I0831 06:49:20.243647 916722 sgd_solver.cpp:106] Iteration 2722000, lr = 0.01
I0831 06:49:49.965667 916722 solver.cpp:218] Iteration 2722500 (16.8227 iter/s, 29.7218s/500 iters), loss = 0.108884
I0831 06:49:49.965719 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.108887 (* 1 = 0.108887 loss)
I0831 06:49:49.965728 916722 sgd_solver.cpp:106] Iteration 2722500, lr = 0.01
I0831 06:50:19.689836 916722 solver.cpp:218] Iteration 2723000 (16.8215 iter/s, 29.7239s/500 iters), loss = 0.183341
I0831 06:50:19.689894 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.183345 (* 1 = 0.183345 loss)
I0831 06:50:19.689903 916722 sgd_solver.cpp:106] Iteration 2723000, lr = 0.01
I0831 06:50:49.412091 916722 solver.cpp:218] Iteration 2723500 (16.8226 iter/s, 29.722s/500 iters), loss = 0.272056
I0831 06:50:49.412145 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.27206 (* 1 = 0.27206 loss)
I0831 06:50:49.412153 916722 sgd_solver.cpp:106] Iteration 2723500, lr = 0.01
I0831 06:51:19.138152 916722 solver.cpp:218] Iteration 2724000 (16.8204 iter/s, 29.7258s/500 iters), loss = 0.399346
I0831 06:51:19.138209 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.39935 (* 1 = 0.39935 loss)
I0831 06:51:19.138218 916722 sgd_solver.cpp:106] Iteration 2724000, lr = 0.01
I0831 06:51:48.858700 916722 solver.cpp:218] Iteration 2724500 (16.8235 iter/s, 29.7203s/500 iters), loss = 0.155063
I0831 06:51:48.858747 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.155067 (* 1 = 0.155067 loss)
I0831 06:51:48.858757 916722 sgd_solver.cpp:106] Iteration 2724500, lr = 0.01
I0831 06:52:18.581566 916722 solver.cpp:218] Iteration 2725000 (16.8222 iter/s, 29.7226s/500 iters), loss = 0.165517
I0831 06:52:18.581645 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.16552 (* 1 = 0.16552 loss)
I0831 06:52:18.581655 916722 sgd_solver.cpp:106] Iteration 2725000, lr = 0.01
I0831 06:52:48.301045 916722 solver.cpp:218] Iteration 2725500 (16.8241 iter/s, 29.7192s/500 iters), loss = 0.203003
I0831 06:52:48.301101 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.203006 (* 1 = 0.203006 loss)
I0831 06:52:48.301111 916722 sgd_solver.cpp:106] Iteration 2725500, lr = 0.01
I0831 06:53:18.022960 916722 solver.cpp:218] Iteration 2726000 (16.8228 iter/s, 29.7217s/500 iters), loss = 0.236106
I0831 06:53:18.023020 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.236109 (* 1 = 0.236109 loss)
I0831 06:53:18.023028 916722 sgd_solver.cpp:106] Iteration 2726000, lr = 0.01
I0831 06:53:47.744139 916722 solver.cpp:218] Iteration 2726500 (16.8232 iter/s, 29.7209s/500 iters), loss = 0.305273
I0831 06:53:47.744192 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.305276 (* 1 = 0.305276 loss)
I0831 06:53:47.744202 916722 sgd_solver.cpp:106] Iteration 2726500, lr = 0.01
I0831 06:54:17.467568 916722 solver.cpp:218] Iteration 2727000 (16.8219 iter/s, 29.7232s/500 iters), loss = 0.0359721
I0831 06:54:17.467626 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0359754 (* 1 = 0.0359754 loss)
I0831 06:54:17.467634 916722 sgd_solver.cpp:106] Iteration 2727000, lr = 0.01
I0831 06:54:47.190490 916722 solver.cpp:218] Iteration 2727500 (16.8222 iter/s, 29.7227s/500 iters), loss = 0.0856029
I0831 06:54:47.190541 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0856063 (* 1 = 0.0856063 loss)
I0831 06:54:47.190552 916722 sgd_solver.cpp:106] Iteration 2727500, lr = 0.01
I0831 06:55:16.914549 916722 solver.cpp:218] Iteration 2728000 (16.8215 iter/s, 29.7238s/500 iters), loss = 0.129001
I0831 06:55:16.914605 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.129004 (* 1 = 0.129004 loss)
I0831 06:55:16.914613 916722 sgd_solver.cpp:106] Iteration 2728000, lr = 0.01
I0831 06:55:46.636787 916722 solver.cpp:218] Iteration 2728500 (16.8226 iter/s, 29.722s/500 iters), loss = 0.0430888
I0831 06:55:46.636840 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0430921 (* 1 = 0.0430921 loss)
I0831 06:55:46.636850 916722 sgd_solver.cpp:106] Iteration 2728500, lr = 0.01
I0831 06:56:16.359601 916722 solver.cpp:218] Iteration 2729000 (16.8222 iter/s, 29.7226s/500 iters), loss = 0.169208
I0831 06:56:16.359658 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.169211 (* 1 = 0.169211 loss)
I0831 06:56:16.359666 916722 sgd_solver.cpp:106] Iteration 2729000, lr = 0.01
I0831 06:56:46.080188 916722 solver.cpp:218] Iteration 2729500 (16.8235 iter/s, 29.7203s/500 iters), loss = 0.193706
I0831 06:56:46.080243 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.193709 (* 1 = 0.193709 loss)
I0831 06:56:46.080253 916722 sgd_solver.cpp:106] Iteration 2729500, lr = 0.01
I0831 06:57:15.799336 916722 solver.cpp:218] Iteration 2730000 (16.8243 iter/s, 29.7189s/500 iters), loss = 0.129899
I0831 06:57:15.799396 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.129903 (* 1 = 0.129903 loss)
I0831 06:57:15.799403 916722 sgd_solver.cpp:106] Iteration 2730000, lr = 0.01
I0831 06:57:45.522387 916722 solver.cpp:218] Iteration 2730500 (16.8221 iter/s, 29.7228s/500 iters), loss = 0.130545
I0831 06:57:45.522441 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130548 (* 1 = 0.130548 loss)
I0831 06:57:45.522451 916722 sgd_solver.cpp:106] Iteration 2730500, lr = 0.01
I0831 06:58:15.245024 916722 solver.cpp:218] Iteration 2731000 (16.8223 iter/s, 29.7224s/500 iters), loss = 0.0695819
I0831 06:58:15.245087 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0695853 (* 1 = 0.0695853 loss)
I0831 06:58:15.245095 916722 sgd_solver.cpp:106] Iteration 2731000, lr = 0.01
I0831 06:58:44.967375 916722 solver.cpp:218] Iteration 2731500 (16.8225 iter/s, 29.7221s/500 iters), loss = 0.0131862
I0831 06:58:44.967438 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0131896 (* 1 = 0.0131896 loss)
I0831 06:58:44.967447 916722 sgd_solver.cpp:106] Iteration 2731500, lr = 0.01
I0831 06:59:14.692755 916722 solver.cpp:218] Iteration 2732000 (16.8208 iter/s, 29.7251s/500 iters), loss = 0.109021
I0831 06:59:14.692822 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109024 (* 1 = 0.109024 loss)
I0831 06:59:14.692831 916722 sgd_solver.cpp:106] Iteration 2732000, lr = 0.01
I0831 06:59:44.415329 916722 solver.cpp:218] Iteration 2732500 (16.8224 iter/s, 29.7223s/500 iters), loss = 0.0168929
I0831 06:59:44.415383 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0168965 (* 1 = 0.0168965 loss)
I0831 06:59:44.415392 916722 sgd_solver.cpp:106] Iteration 2732500, lr = 0.01
I0831 07:00:14.140251 916722 solver.cpp:218] Iteration 2733000 (16.821 iter/s, 29.7247s/500 iters), loss = 0.115969
I0831 07:00:14.140311 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115973 (* 1 = 0.115973 loss)
I0831 07:00:14.140319 916722 sgd_solver.cpp:106] Iteration 2733000, lr = 0.01
I0831 07:00:43.861294 916722 solver.cpp:218] Iteration 2733500 (16.8232 iter/s, 29.7208s/500 iters), loss = 0.168142
I0831 07:00:43.861346 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.168146 (* 1 = 0.168146 loss)
I0831 07:00:43.861356 916722 sgd_solver.cpp:106] Iteration 2733500, lr = 0.01
I0831 07:01:13.581984 916722 solver.cpp:218] Iteration 2734000 (16.8234 iter/s, 29.7205s/500 iters), loss = 0.0839387
I0831 07:01:13.582044 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0839423 (* 1 = 0.0839423 loss)
I0831 07:01:13.582052 916722 sgd_solver.cpp:106] Iteration 2734000, lr = 0.01
I0831 07:01:43.301344 916722 solver.cpp:218] Iteration 2734500 (16.8242 iter/s, 29.7191s/500 iters), loss = 0.155046
I0831 07:01:43.301396 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.15505 (* 1 = 0.15505 loss)
I0831 07:01:43.301405 916722 sgd_solver.cpp:106] Iteration 2734500, lr = 0.01
I0831 07:02:13.026110 916722 solver.cpp:218] Iteration 2735000 (16.8211 iter/s, 29.7245s/500 iters), loss = 0.218781
I0831 07:02:13.026167 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.218785 (* 1 = 0.218785 loss)
I0831 07:02:13.026175 916722 sgd_solver.cpp:106] Iteration 2735000, lr = 0.01
I0831 07:02:42.748059 916722 solver.cpp:218] Iteration 2735500 (16.8227 iter/s, 29.7217s/500 iters), loss = 0.028608
I0831 07:02:42.748113 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0286117 (* 1 = 0.0286117 loss)
I0831 07:02:42.748123 916722 sgd_solver.cpp:106] Iteration 2735500, lr = 0.01
I0831 07:03:12.471473 916722 solver.cpp:218] Iteration 2736000 (16.8219 iter/s, 29.7232s/500 iters), loss = 0.0344441
I0831 07:03:12.471527 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0344475 (* 1 = 0.0344475 loss)
I0831 07:03:12.471535 916722 sgd_solver.cpp:106] Iteration 2736000, lr = 0.01
I0831 07:03:42.192602 916722 solver.cpp:218] Iteration 2736500 (16.8232 iter/s, 29.7209s/500 iters), loss = 0.173692
I0831 07:03:42.192657 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.173695 (* 1 = 0.173695 loss)
I0831 07:03:42.192668 916722 sgd_solver.cpp:106] Iteration 2736500, lr = 0.01
I0831 07:04:11.916302 916722 solver.cpp:218] Iteration 2737000 (16.8217 iter/s, 29.7235s/500 iters), loss = 0.130266
I0831 07:04:11.916360 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130269 (* 1 = 0.130269 loss)
I0831 07:04:11.916368 916722 sgd_solver.cpp:106] Iteration 2737000, lr = 0.01
I0831 07:04:41.636021 916722 solver.cpp:218] Iteration 2737500 (16.824 iter/s, 29.7195s/500 iters), loss = 0.102565
I0831 07:04:41.636071 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.102569 (* 1 = 0.102569 loss)
I0831 07:04:41.636080 916722 sgd_solver.cpp:106] Iteration 2737500, lr = 0.01
I0831 07:05:11.356231 916722 solver.cpp:218] Iteration 2738000 (16.8237 iter/s, 29.72s/500 iters), loss = 0.132331
I0831 07:05:11.356307 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.132334 (* 1 = 0.132334 loss)
I0831 07:05:11.356315 916722 sgd_solver.cpp:106] Iteration 2738000, lr = 0.01
I0831 07:05:41.076642 916722 solver.cpp:218] Iteration 2738500 (16.8236 iter/s, 29.7202s/500 iters), loss = 0.232243
I0831 07:05:41.076697 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.232247 (* 1 = 0.232247 loss)
I0831 07:05:41.076707 916722 sgd_solver.cpp:106] Iteration 2738500, lr = 0.01
I0831 07:06:10.798619 916722 solver.cpp:218] Iteration 2739000 (16.8227 iter/s, 29.7218s/500 iters), loss = 0.0883801
I0831 07:06:10.798677 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0883832 (* 1 = 0.0883832 loss)
I0831 07:06:10.798686 916722 sgd_solver.cpp:106] Iteration 2739000, lr = 0.01
I0831 07:06:40.518900 916722 solver.cpp:218] Iteration 2739500 (16.8237 iter/s, 29.72s/500 iters), loss = 0.100893
I0831 07:06:40.518954 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.100896 (* 1 = 0.100896 loss)
I0831 07:06:40.518962 916722 sgd_solver.cpp:106] Iteration 2739500, lr = 0.01
I0831 07:07:10.237583 916722 solver.cpp:218] Iteration 2740000 (16.8246 iter/s, 29.7185s/500 iters), loss = 0.146375
I0831 07:07:10.237643 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.146378 (* 1 = 0.146378 loss)
I0831 07:07:10.237650 916722 sgd_solver.cpp:106] Iteration 2740000, lr = 0.01
I0831 07:07:39.959996 916722 solver.cpp:218] Iteration 2740500 (16.8225 iter/s, 29.7222s/500 iters), loss = 0.102637
I0831 07:07:39.960052 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.102641 (* 1 = 0.102641 loss)
I0831 07:07:39.960062 916722 sgd_solver.cpp:106] Iteration 2740500, lr = 0.01
I0831 07:08:09.682245 916722 solver.cpp:218] Iteration 2741000 (16.8225 iter/s, 29.722s/500 iters), loss = 0.0913286
I0831 07:08:09.682303 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0913319 (* 1 = 0.0913319 loss)
I0831 07:08:09.682312 916722 sgd_solver.cpp:106] Iteration 2741000, lr = 0.01
I0831 07:08:39.401086 916722 solver.cpp:218] Iteration 2741500 (16.8245 iter/s, 29.7186s/500 iters), loss = 0.125335
I0831 07:08:39.401141 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.125338 (* 1 = 0.125338 loss)
I0831 07:08:39.401151 916722 sgd_solver.cpp:106] Iteration 2741500, lr = 0.01
I0831 07:09:09.120841 916722 solver.cpp:218] Iteration 2742000 (16.824 iter/s, 29.7195s/500 iters), loss = 0.19107
I0831 07:09:09.120899 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.191073 (* 1 = 0.191073 loss)
I0831 07:09:09.120908 916722 sgd_solver.cpp:106] Iteration 2742000, lr = 0.01
I0831 07:09:38.844724 916722 solver.cpp:218] Iteration 2742500 (16.8216 iter/s, 29.7237s/500 iters), loss = 0.192658
I0831 07:09:38.844787 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.192661 (* 1 = 0.192661 loss)
I0831 07:09:38.844797 916722 sgd_solver.cpp:106] Iteration 2742500, lr = 0.01
I0831 07:10:08.566522 916722 solver.cpp:218] Iteration 2743000 (16.8228 iter/s, 29.7216s/500 iters), loss = 0.236008
I0831 07:10:08.566581 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.236012 (* 1 = 0.236012 loss)
I0831 07:10:08.566591 916722 sgd_solver.cpp:106] Iteration 2743000, lr = 0.01
I0831 07:10:38.290159 916722 solver.cpp:218] Iteration 2743500 (16.8218 iter/s, 29.7234s/500 iters), loss = 0.220852
I0831 07:10:38.290210 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.220856 (* 1 = 0.220856 loss)
I0831 07:10:38.290220 916722 sgd_solver.cpp:106] Iteration 2743500, lr = 0.01
I0831 07:11:08.016788 916722 solver.cpp:218] Iteration 2744000 (16.8201 iter/s, 29.7264s/500 iters), loss = 0.344731
I0831 07:11:08.016847 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.344735 (* 1 = 0.344735 loss)
I0831 07:11:08.016856 916722 sgd_solver.cpp:106] Iteration 2744000, lr = 0.01
I0831 07:11:37.736811 916722 solver.cpp:218] Iteration 2744500 (16.8238 iter/s, 29.7198s/500 iters), loss = 0.175407
I0831 07:11:37.736865 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.17541 (* 1 = 0.17541 loss)
I0831 07:11:37.736887 916722 sgd_solver.cpp:106] Iteration 2744500, lr = 0.01
I0831 07:12:07.459208 916722 solver.cpp:218] Iteration 2745000 (16.8225 iter/s, 29.7222s/500 iters), loss = 0.051159
I0831 07:12:07.459278 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0511624 (* 1 = 0.0511624 loss)
I0831 07:12:07.459286 916722 sgd_solver.cpp:106] Iteration 2745000, lr = 0.01
I0831 07:12:37.182001 916722 solver.cpp:218] Iteration 2745500 (16.8222 iter/s, 29.7226s/500 iters), loss = 0.197115
I0831 07:12:37.182056 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.197119 (* 1 = 0.197119 loss)
I0831 07:12:37.182066 916722 sgd_solver.cpp:106] Iteration 2745500, lr = 0.01
I0831 07:13:06.901870 916722 solver.cpp:218] Iteration 2746000 (16.8235 iter/s, 29.7204s/500 iters), loss = 0.476591
I0831 07:13:06.901932 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.476595 (* 1 = 0.476595 loss)
I0831 07:13:06.901940 916722 sgd_solver.cpp:106] Iteration 2746000, lr = 0.01
I0831 07:13:36.625032 916722 solver.cpp:218] Iteration 2746500 (16.8216 iter/s, 29.7236s/500 iters), loss = 0.194372
I0831 07:13:36.625082 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.194375 (* 1 = 0.194375 loss)
I0831 07:13:36.625092 916722 sgd_solver.cpp:106] Iteration 2746500, lr = 0.01
I0831 07:14:06.353981 916722 solver.cpp:218] Iteration 2747000 (16.8184 iter/s, 29.7294s/500 iters), loss = 0.0254024
I0831 07:14:06.354038 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0254057 (* 1 = 0.0254057 loss)
I0831 07:14:06.354046 916722 sgd_solver.cpp:106] Iteration 2747000, lr = 0.01
I0831 07:14:36.088949 916722 solver.cpp:218] Iteration 2747500 (16.815 iter/s, 29.7354s/500 iters), loss = 0.371233
I0831 07:14:36.089000 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.371236 (* 1 = 0.371236 loss)
I0831 07:14:36.089008 916722 sgd_solver.cpp:106] Iteration 2747500, lr = 0.01
I0831 07:15:05.819530 916722 solver.cpp:218] Iteration 2748000 (16.8175 iter/s, 29.731s/500 iters), loss = 0.0690815
I0831 07:15:05.819591 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0690851 (* 1 = 0.0690851 loss)
I0831 07:15:05.819598 916722 sgd_solver.cpp:106] Iteration 2748000, lr = 0.01
I0831 07:15:35.550024 916722 solver.cpp:218] Iteration 2748500 (16.8176 iter/s, 29.7308s/500 iters), loss = 0.0368071
I0831 07:15:35.550076 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0368107 (* 1 = 0.0368107 loss)
I0831 07:15:35.550086 916722 sgd_solver.cpp:106] Iteration 2748500, lr = 0.01
I0831 07:16:05.282071 916722 solver.cpp:218] Iteration 2749000 (16.8167 iter/s, 29.7324s/500 iters), loss = 0.073841
I0831 07:16:05.282130 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0738447 (* 1 = 0.0738447 loss)
I0831 07:16:05.282137 916722 sgd_solver.cpp:106] Iteration 2749000, lr = 0.01
I0831 07:16:35.014410 916722 solver.cpp:218] Iteration 2749500 (16.8165 iter/s, 29.7326s/500 iters), loss = 0.0926252
I0831 07:16:35.014462 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.092629 (* 1 = 0.092629 loss)
I0831 07:16:35.014472 916722 sgd_solver.cpp:106] Iteration 2749500, lr = 0.01
I0831 07:17:04.681191 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_2750000.caffemodel
I0831 07:17:04.700611 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_2750000.solverstate
I0831 07:17:04.706658 916722 solver.cpp:330] Iteration 2750000, Testing net (#0)
I0831 07:17:20.103448 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8883
I0831 07:17:20.103492 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.398055 (* 1 = 0.398055 loss)
I0831 07:17:20.162052 916722 solver.cpp:218] Iteration 2750000 (11.0747 iter/s, 45.1481s/500 iters), loss = 0.0381941
I0831 07:17:20.162081 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0381978 (* 1 = 0.0381978 loss)
I0831 07:17:20.162089 916722 sgd_solver.cpp:106] Iteration 2750000, lr = 0.01
I0831 07:17:49.842590 916722 solver.cpp:218] Iteration 2750500 (16.8459 iter/s, 29.6808s/500 iters), loss = 0.0959262
I0831 07:17:49.842659 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0959298 (* 1 = 0.0959298 loss)
I0831 07:17:49.842669 916722 sgd_solver.cpp:106] Iteration 2750500, lr = 0.01
I0831 07:18:19.571820 916722 solver.cpp:218] Iteration 2751000 (16.8184 iter/s, 29.7294s/500 iters), loss = 0.0189518
I0831 07:18:19.571874 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0189552 (* 1 = 0.0189552 loss)
I0831 07:18:19.571884 916722 sgd_solver.cpp:106] Iteration 2751000, lr = 0.01
I0831 07:18:49.300771 916722 solver.cpp:218] Iteration 2751500 (16.8185 iter/s, 29.7291s/500 iters), loss = 0.105926
I0831 07:18:49.300830 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.10593 (* 1 = 0.10593 loss)
I0831 07:18:49.300839 916722 sgd_solver.cpp:106] Iteration 2751500, lr = 0.01
I0831 07:19:19.026540 916722 solver.cpp:218] Iteration 2752000 (16.8203 iter/s, 29.7259s/500 iters), loss = 0.145402
I0831 07:19:19.026592 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.145405 (* 1 = 0.145405 loss)
I0831 07:19:19.026602 916722 sgd_solver.cpp:106] Iteration 2752000, lr = 0.01
I0831 07:19:48.752562 916722 solver.cpp:218] Iteration 2752500 (16.8202 iter/s, 29.7262s/500 iters), loss = 0.126874
I0831 07:19:48.752621 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.126877 (* 1 = 0.126877 loss)
I0831 07:19:48.752631 916722 sgd_solver.cpp:106] Iteration 2752500, lr = 0.01
I0831 07:20:18.483644 916722 solver.cpp:218] Iteration 2753000 (16.8173 iter/s, 29.7312s/500 iters), loss = 0.060937
I0831 07:20:18.483696 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0609403 (* 1 = 0.0609403 loss)
I0831 07:20:18.483706 916722 sgd_solver.cpp:106] Iteration 2753000, lr = 0.01
I0831 07:20:48.213388 916722 solver.cpp:218] Iteration 2753500 (16.8181 iter/s, 29.7299s/500 iters), loss = 0.00679711
I0831 07:20:48.213449 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0068005 (* 1 = 0.0068005 loss)
I0831 07:20:48.213456 916722 sgd_solver.cpp:106] Iteration 2753500, lr = 0.01
I0831 07:21:17.945310 916722 solver.cpp:218] Iteration 2754000 (16.8169 iter/s, 29.732s/500 iters), loss = 0.0968068
I0831 07:21:17.945363 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0968103 (* 1 = 0.0968103 loss)
I0831 07:21:17.945374 916722 sgd_solver.cpp:106] Iteration 2754000, lr = 0.01
I0831 07:21:47.675978 916722 solver.cpp:218] Iteration 2754500 (16.8176 iter/s, 29.7308s/500 iters), loss = 0.227434
I0831 07:21:47.676039 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.227438 (* 1 = 0.227438 loss)
I0831 07:21:47.676048 916722 sgd_solver.cpp:106] Iteration 2754500, lr = 0.01
I0831 07:22:17.403121 916722 solver.cpp:218] Iteration 2755000 (16.8196 iter/s, 29.7272s/500 iters), loss = 0.145887
I0831 07:22:17.403172 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.14589 (* 1 = 0.14589 loss)
I0831 07:22:17.403182 916722 sgd_solver.cpp:106] Iteration 2755000, lr = 0.01
I0831 07:22:47.125419 916722 solver.cpp:218] Iteration 2755500 (16.8223 iter/s, 29.7224s/500 iters), loss = 0.0492773
I0831 07:22:47.125489 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0492809 (* 1 = 0.0492809 loss)
I0831 07:22:47.125499 916722 sgd_solver.cpp:106] Iteration 2755500, lr = 0.01
I0831 07:23:16.847170 916722 solver.cpp:218] Iteration 2756000 (16.8227 iter/s, 29.7218s/500 iters), loss = 0.129483
I0831 07:23:16.847223 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.129487 (* 1 = 0.129487 loss)
I0831 07:23:16.847231 916722 sgd_solver.cpp:106] Iteration 2756000, lr = 0.01
I0831 07:23:46.572065 916722 solver.cpp:218] Iteration 2756500 (16.8209 iter/s, 29.725s/500 iters), loss = 0.0660208
I0831 07:23:46.572126 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0660243 (* 1 = 0.0660243 loss)
I0831 07:23:46.572134 916722 sgd_solver.cpp:106] Iteration 2756500, lr = 0.01
I0831 07:24:16.287268 916722 solver.cpp:218] Iteration 2757000 (16.8264 iter/s, 29.7152s/500 iters), loss = 0.0678394
I0831 07:24:16.287324 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0678429 (* 1 = 0.0678429 loss)
I0831 07:24:16.287333 916722 sgd_solver.cpp:106] Iteration 2757000, lr = 0.01
I0831 07:24:46.005841 916722 solver.cpp:218] Iteration 2757500 (16.8245 iter/s, 29.7186s/500 iters), loss = 0.10516
I0831 07:24:46.005916 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105163 (* 1 = 0.105163 loss)
I0831 07:24:46.005925 916722 sgd_solver.cpp:106] Iteration 2757500, lr = 0.01
I0831 07:25:15.721165 916722 solver.cpp:218] Iteration 2758000 (16.8263 iter/s, 29.7153s/500 iters), loss = 0.0595696
I0831 07:25:15.721220 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.059573 (* 1 = 0.059573 loss)
I0831 07:25:15.721227 916722 sgd_solver.cpp:106] Iteration 2758000, lr = 0.01
I0831 07:25:45.442615 916722 solver.cpp:218] Iteration 2758500 (16.8229 iter/s, 29.7215s/500 iters), loss = 0.0398648
I0831 07:25:45.442677 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0398684 (* 1 = 0.0398684 loss)
I0831 07:25:45.442684 916722 sgd_solver.cpp:106] Iteration 2758500, lr = 0.01
I0831 07:26:15.161355 916722 solver.cpp:218] Iteration 2759000 (16.8244 iter/s, 29.7187s/500 iters), loss = 0.263565
I0831 07:26:15.161408 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.263569 (* 1 = 0.263569 loss)
I0831 07:26:15.161417 916722 sgd_solver.cpp:106] Iteration 2759000, lr = 0.01
I0831 07:26:44.886502 916722 solver.cpp:218] Iteration 2759500 (16.8208 iter/s, 29.7251s/500 iters), loss = 0.186212
I0831 07:26:44.886564 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.186216 (* 1 = 0.186216 loss)
I0831 07:26:44.886571 916722 sgd_solver.cpp:106] Iteration 2759500, lr = 0.01
I0831 07:27:14.608175 916722 solver.cpp:218] Iteration 2760000 (16.8228 iter/s, 29.7217s/500 iters), loss = 0.106327
I0831 07:27:14.608229 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.106331 (* 1 = 0.106331 loss)
I0831 07:27:14.608237 916722 sgd_solver.cpp:106] Iteration 2760000, lr = 0.01
I0831 07:27:44.329587 916722 solver.cpp:218] Iteration 2760500 (16.8229 iter/s, 29.7214s/500 iters), loss = 0.0361751
I0831 07:27:44.329649 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0361787 (* 1 = 0.0361787 loss)
I0831 07:27:44.329658 916722 sgd_solver.cpp:106] Iteration 2760500, lr = 0.01
I0831 07:28:14.046962 916722 solver.cpp:218] Iteration 2761000 (16.8252 iter/s, 29.7173s/500 iters), loss = 0.170619
I0831 07:28:14.047017 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.170623 (* 1 = 0.170623 loss)
I0831 07:28:14.047027 916722 sgd_solver.cpp:106] Iteration 2761000, lr = 0.01
I0831 07:28:43.767318 916722 solver.cpp:218] Iteration 2761500 (16.8235 iter/s, 29.7203s/500 iters), loss = 0.0513673
I0831 07:28:43.767377 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.051371 (* 1 = 0.051371 loss)
I0831 07:28:43.767385 916722 sgd_solver.cpp:106] Iteration 2761500, lr = 0.01
I0831 07:29:13.481104 916722 solver.cpp:218] Iteration 2762000 (16.8272 iter/s, 29.7137s/500 iters), loss = 0.0403011
I0831 07:29:13.481153 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0403048 (* 1 = 0.0403048 loss)
I0831 07:29:13.481163 916722 sgd_solver.cpp:106] Iteration 2762000, lr = 0.01
I0831 07:29:43.195976 916722 solver.cpp:218] Iteration 2762500 (16.8266 iter/s, 29.7148s/500 iters), loss = 0.0580824
I0831 07:29:43.196036 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0580862 (* 1 = 0.0580862 loss)
I0831 07:29:43.196045 916722 sgd_solver.cpp:106] Iteration 2762500, lr = 0.01
I0831 07:30:12.913580 916722 solver.cpp:218] Iteration 2763000 (16.8251 iter/s, 29.7176s/500 iters), loss = 0.218009
I0831 07:30:12.913633 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.218013 (* 1 = 0.218013 loss)
I0831 07:30:12.913643 916722 sgd_solver.cpp:106] Iteration 2763000, lr = 0.01
I0831 07:30:42.632078 916722 solver.cpp:218] Iteration 2763500 (16.8246 iter/s, 29.7184s/500 iters), loss = 0.182457
I0831 07:30:42.632153 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.182461 (* 1 = 0.182461 loss)
I0831 07:30:42.632160 916722 sgd_solver.cpp:106] Iteration 2763500, lr = 0.01
I0831 07:31:12.345710 916722 solver.cpp:218] Iteration 2764000 (16.8273 iter/s, 29.7136s/500 iters), loss = 0.134449
I0831 07:31:12.345763 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.134453 (* 1 = 0.134453 loss)
I0831 07:31:12.345773 916722 sgd_solver.cpp:106] Iteration 2764000, lr = 0.01
I0831 07:31:42.062644 916722 solver.cpp:218] Iteration 2764500 (16.8255 iter/s, 29.7169s/500 iters), loss = 0.14428
I0831 07:31:42.062703 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.144283 (* 1 = 0.144283 loss)
I0831 07:31:42.062711 916722 sgd_solver.cpp:106] Iteration 2764500, lr = 0.01
I0831 07:32:11.755113 916722 solver.cpp:218] Iteration 2765000 (16.8393 iter/s, 29.6924s/500 iters), loss = 0.0827238
I0831 07:32:11.755165 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0827276 (* 1 = 0.0827276 loss)
I0831 07:32:11.755175 916722 sgd_solver.cpp:106] Iteration 2765000, lr = 0.01
I0831 07:32:41.449172 916722 solver.cpp:218] Iteration 2765500 (16.8384 iter/s, 29.694s/500 iters), loss = 0.135536
I0831 07:32:41.449230 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13554 (* 1 = 0.13554 loss)
I0831 07:32:41.449239 916722 sgd_solver.cpp:106] Iteration 2765500, lr = 0.01
I0831 07:33:11.148108 916722 solver.cpp:218] Iteration 2766000 (16.8357 iter/s, 29.6989s/500 iters), loss = 0.0259557
I0831 07:33:11.148161 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0259595 (* 1 = 0.0259595 loss)
I0831 07:33:11.148171 916722 sgd_solver.cpp:106] Iteration 2766000, lr = 0.01
I0831 07:33:40.845075 916722 solver.cpp:218] Iteration 2766500 (16.8368 iter/s, 29.6969s/500 iters), loss = 0.163294
I0831 07:33:40.845134 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.163297 (* 1 = 0.163297 loss)
I0831 07:33:40.845144 916722 sgd_solver.cpp:106] Iteration 2766500, lr = 0.01
I0831 07:34:10.538379 916722 solver.cpp:218] Iteration 2767000 (16.8389 iter/s, 29.6932s/500 iters), loss = 0.193034
I0831 07:34:10.538432 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.193037 (* 1 = 0.193037 loss)
I0831 07:34:10.538442 916722 sgd_solver.cpp:106] Iteration 2767000, lr = 0.01
I0831 07:34:40.230645 916722 solver.cpp:218] Iteration 2767500 (16.8395 iter/s, 29.6922s/500 iters), loss = 0.0810974
I0831 07:34:40.230705 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0811011 (* 1 = 0.0811011 loss)
I0831 07:34:40.230715 916722 sgd_solver.cpp:106] Iteration 2767500, lr = 0.01
I0831 07:35:09.921006 916722 solver.cpp:218] Iteration 2768000 (16.8405 iter/s, 29.6903s/500 iters), loss = 0.179518
I0831 07:35:09.921058 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.179522 (* 1 = 0.179522 loss)
I0831 07:35:09.921069 916722 sgd_solver.cpp:106] Iteration 2768000, lr = 0.01
I0831 07:35:39.616032 916722 solver.cpp:218] Iteration 2768500 (16.8379 iter/s, 29.6949s/500 iters), loss = 0.138711
I0831 07:35:39.616091 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.138714 (* 1 = 0.138714 loss)
I0831 07:35:39.616101 916722 sgd_solver.cpp:106] Iteration 2768500, lr = 0.01
I0831 07:36:09.323406 916722 solver.cpp:218] Iteration 2769000 (16.8309 iter/s, 29.7073s/500 iters), loss = 0.313281
I0831 07:36:09.323457 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.313285 (* 1 = 0.313285 loss)
I0831 07:36:09.323467 916722 sgd_solver.cpp:106] Iteration 2769000, lr = 0.01
I0831 07:36:39.030401 916722 solver.cpp:218] Iteration 2769500 (16.8311 iter/s, 29.7069s/500 iters), loss = 0.0836408
I0831 07:36:39.030462 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0836448 (* 1 = 0.0836448 loss)
I0831 07:36:39.030470 916722 sgd_solver.cpp:106] Iteration 2769500, lr = 0.01
I0831 07:37:08.736160 916722 solver.cpp:218] Iteration 2770000 (16.8318 iter/s, 29.7057s/500 iters), loss = 0.251134
I0831 07:37:08.736223 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.251138 (* 1 = 0.251138 loss)
I0831 07:37:08.736233 916722 sgd_solver.cpp:106] Iteration 2770000, lr = 0.01
I0831 07:37:38.449782 916722 solver.cpp:218] Iteration 2770500 (16.8274 iter/s, 29.7135s/500 iters), loss = 0.0216926
I0831 07:37:38.449856 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0216968 (* 1 = 0.0216968 loss)
I0831 07:37:38.449864 916722 sgd_solver.cpp:106] Iteration 2770500, lr = 0.01
I0831 07:38:08.156708 916722 solver.cpp:218] Iteration 2771000 (16.8312 iter/s, 29.7068s/500 iters), loss = 0.112409
I0831 07:38:08.156760 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112413 (* 1 = 0.112413 loss)
I0831 07:38:08.156769 916722 sgd_solver.cpp:106] Iteration 2771000, lr = 0.01
I0831 07:38:37.864789 916722 solver.cpp:218] Iteration 2771500 (16.8305 iter/s, 29.708s/500 iters), loss = 0.170454
I0831 07:38:37.864847 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.170458 (* 1 = 0.170458 loss)
I0831 07:38:37.864856 916722 sgd_solver.cpp:106] Iteration 2771500, lr = 0.01
I0831 07:39:07.569741 916722 solver.cpp:218] Iteration 2772000 (16.8323 iter/s, 29.7048s/500 iters), loss = 0.119639
I0831 07:39:07.569793 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.119644 (* 1 = 0.119644 loss)
I0831 07:39:07.569802 916722 sgd_solver.cpp:106] Iteration 2772000, lr = 0.01
I0831 07:39:37.277882 916722 solver.cpp:218] Iteration 2772500 (16.8305 iter/s, 29.708s/500 iters), loss = 0.027794
I0831 07:39:37.277941 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0277985 (* 1 = 0.0277985 loss)
I0831 07:39:37.277951 916722 sgd_solver.cpp:106] Iteration 2772500, lr = 0.01
I0831 07:40:06.984871 916722 solver.cpp:218] Iteration 2773000 (16.8311 iter/s, 29.7069s/500 iters), loss = 0.0794851
I0831 07:40:06.984925 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0794895 (* 1 = 0.0794895 loss)
I0831 07:40:06.984933 916722 sgd_solver.cpp:106] Iteration 2773000, lr = 0.01
I0831 07:40:36.695758 916722 solver.cpp:218] Iteration 2773500 (16.8289 iter/s, 29.7108s/500 iters), loss = 0.135744
I0831 07:40:36.695819 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.135748 (* 1 = 0.135748 loss)
I0831 07:40:36.695828 916722 sgd_solver.cpp:106] Iteration 2773500, lr = 0.01
I0831 07:41:06.403858 916722 solver.cpp:218] Iteration 2774000 (16.8305 iter/s, 29.708s/500 iters), loss = 0.241503
I0831 07:41:06.403910 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.241508 (* 1 = 0.241508 loss)
I0831 07:41:06.403919 916722 sgd_solver.cpp:106] Iteration 2774000, lr = 0.01
I0831 07:41:36.138021 916722 solver.cpp:218] Iteration 2774500 (16.8157 iter/s, 29.7341s/500 iters), loss = 0.15448
I0831 07:41:36.138079 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.154485 (* 1 = 0.154485 loss)
I0831 07:41:36.138087 916722 sgd_solver.cpp:106] Iteration 2774500, lr = 0.01
I0831 07:42:05.864898 916722 solver.cpp:218] Iteration 2775000 (16.8199 iter/s, 29.7268s/500 iters), loss = 0.142288
I0831 07:42:05.864950 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.142292 (* 1 = 0.142292 loss)
I0831 07:42:05.864959 916722 sgd_solver.cpp:106] Iteration 2775000, lr = 0.01
I0831 07:42:35.592156 916722 solver.cpp:218] Iteration 2775500 (16.8196 iter/s, 29.7271s/500 iters), loss = 0.0944919
I0831 07:42:35.592216 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0944963 (* 1 = 0.0944963 loss)
I0831 07:42:35.592223 916722 sgd_solver.cpp:106] Iteration 2775500, lr = 0.01
I0831 07:43:05.317579 916722 solver.cpp:218] Iteration 2776000 (16.8207 iter/s, 29.7253s/500 iters), loss = 0.27444
I0831 07:43:05.317632 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.274444 (* 1 = 0.274444 loss)
I0831 07:43:05.317642 916722 sgd_solver.cpp:106] Iteration 2776000, lr = 0.01
I0831 07:43:35.048835 916722 solver.cpp:218] Iteration 2776500 (16.8174 iter/s, 29.7311s/500 iters), loss = 0.101431
I0831 07:43:35.048909 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101436 (* 1 = 0.101436 loss)
I0831 07:43:35.048918 916722 sgd_solver.cpp:106] Iteration 2776500, lr = 0.01
I0831 07:44:04.777966 916722 solver.cpp:218] Iteration 2777000 (16.8186 iter/s, 29.729s/500 iters), loss = 0.0444766
I0831 07:44:04.778019 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0444812 (* 1 = 0.0444812 loss)
I0831 07:44:04.778029 916722 sgd_solver.cpp:106] Iteration 2777000, lr = 0.01
I0831 07:44:34.506171 916722 solver.cpp:218] Iteration 2777500 (16.8191 iter/s, 29.7281s/500 iters), loss = 0.0581842
I0831 07:44:34.506230 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0581887 (* 1 = 0.0581887 loss)
I0831 07:44:34.506239 916722 sgd_solver.cpp:106] Iteration 2777500, lr = 0.01
I0831 07:45:04.230008 916722 solver.cpp:218] Iteration 2778000 (16.8216 iter/s, 29.7237s/500 iters), loss = 0.062434
I0831 07:45:04.230059 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0624384 (* 1 = 0.0624384 loss)
I0831 07:45:04.230068 916722 sgd_solver.cpp:106] Iteration 2778000, lr = 0.01
I0831 07:45:33.959369 916722 solver.cpp:218] Iteration 2778500 (16.8185 iter/s, 29.7292s/500 iters), loss = 0.082969
I0831 07:45:33.959425 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0829733 (* 1 = 0.0829733 loss)
I0831 07:45:33.959434 916722 sgd_solver.cpp:106] Iteration 2778500, lr = 0.01
I0831 07:46:03.690297 916722 solver.cpp:218] Iteration 2779000 (16.8176 iter/s, 29.7308s/500 iters), loss = 0.116982
I0831 07:46:03.690346 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.116987 (* 1 = 0.116987 loss)
I0831 07:46:03.690356 916722 sgd_solver.cpp:106] Iteration 2779000, lr = 0.01
I0831 07:46:33.420121 916722 solver.cpp:218] Iteration 2779500 (16.8182 iter/s, 29.7297s/500 iters), loss = 0.111743
I0831 07:46:33.420179 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111747 (* 1 = 0.111747 loss)
I0831 07:46:33.420187 916722 sgd_solver.cpp:106] Iteration 2779500, lr = 0.01
I0831 07:47:03.150897 916722 solver.cpp:218] Iteration 2780000 (16.8177 iter/s, 29.7306s/500 iters), loss = 0.147732
I0831 07:47:03.150945 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.147737 (* 1 = 0.147737 loss)
I0831 07:47:03.150955 916722 sgd_solver.cpp:106] Iteration 2780000, lr = 0.01
I0831 07:47:32.881762 916722 solver.cpp:218] Iteration 2780500 (16.8176 iter/s, 29.7307s/500 iters), loss = 0.0153851
I0831 07:47:32.881816 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0153895 (* 1 = 0.0153895 loss)
I0831 07:47:32.881824 916722 sgd_solver.cpp:106] Iteration 2780500, lr = 0.01
I0831 07:48:02.613890 916722 solver.cpp:218] Iteration 2781000 (16.8169 iter/s, 29.732s/500 iters), loss = 0.411475
I0831 07:48:02.613940 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.411479 (* 1 = 0.411479 loss)
I0831 07:48:02.613950 916722 sgd_solver.cpp:106] Iteration 2781000, lr = 0.01
I0831 07:48:32.342236 916722 solver.cpp:218] Iteration 2781500 (16.819 iter/s, 29.7282s/500 iters), loss = 0.171404
I0831 07:48:32.342299 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.171409 (* 1 = 0.171409 loss)
I0831 07:48:32.342308 916722 sgd_solver.cpp:106] Iteration 2781500, lr = 0.01
I0831 07:49:02.073994 916722 solver.cpp:218] Iteration 2782000 (16.8171 iter/s, 29.7316s/500 iters), loss = 0.074882
I0831 07:49:02.074041 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0748866 (* 1 = 0.0748866 loss)
I0831 07:49:02.074049 916722 sgd_solver.cpp:106] Iteration 2782000, lr = 0.01
I0831 07:49:31.803504 916722 solver.cpp:218] Iteration 2782500 (16.8184 iter/s, 29.7294s/500 iters), loss = 0.145088
I0831 07:49:31.803565 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.145093 (* 1 = 0.145093 loss)
I0831 07:49:31.803573 916722 sgd_solver.cpp:106] Iteration 2782500, lr = 0.01
I0831 07:50:01.527875 916722 solver.cpp:218] Iteration 2783000 (16.8213 iter/s, 29.7242s/500 iters), loss = 0.261167
I0831 07:50:01.527925 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.261171 (* 1 = 0.261171 loss)
I0831 07:50:01.527945 916722 sgd_solver.cpp:106] Iteration 2783000, lr = 0.01
I0831 07:50:31.257899 916722 solver.cpp:218] Iteration 2783500 (16.8181 iter/s, 29.7299s/500 iters), loss = 0.0861591
I0831 07:50:31.257968 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0861638 (* 1 = 0.0861638 loss)
I0831 07:50:31.257977 916722 sgd_solver.cpp:106] Iteration 2783500, lr = 0.01
I0831 07:51:00.987540 916722 solver.cpp:218] Iteration 2784000 (16.8183 iter/s, 29.7295s/500 iters), loss = 0.0522925
I0831 07:51:00.987591 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0522973 (* 1 = 0.0522973 loss)
I0831 07:51:00.987599 916722 sgd_solver.cpp:106] Iteration 2784000, lr = 0.01
I0831 07:51:30.714414 916722 solver.cpp:218] Iteration 2784500 (16.8199 iter/s, 29.7267s/500 iters), loss = 0.104143
I0831 07:51:30.714476 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104148 (* 1 = 0.104148 loss)
I0831 07:51:30.714485 916722 sgd_solver.cpp:106] Iteration 2784500, lr = 0.01
I0831 07:52:00.442917 916722 solver.cpp:218] Iteration 2785000 (16.819 iter/s, 29.7283s/500 iters), loss = 0.0785082
I0831 07:52:00.442968 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0785131 (* 1 = 0.0785131 loss)
I0831 07:52:00.442976 916722 sgd_solver.cpp:106] Iteration 2785000, lr = 0.01
I0831 07:52:30.175150 916722 solver.cpp:218] Iteration 2785500 (16.8168 iter/s, 29.7321s/500 iters), loss = 0.128652
I0831 07:52:30.175211 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128657 (* 1 = 0.128657 loss)
I0831 07:52:30.175220 916722 sgd_solver.cpp:106] Iteration 2785500, lr = 0.01
I0831 07:52:59.905988 916722 solver.cpp:218] Iteration 2786000 (16.8176 iter/s, 29.7307s/500 iters), loss = 0.0348711
I0831 07:52:59.906042 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.034876 (* 1 = 0.034876 loss)
I0831 07:52:59.906051 916722 sgd_solver.cpp:106] Iteration 2786000, lr = 0.01
I0831 07:53:29.636019 916722 solver.cpp:218] Iteration 2786500 (16.8181 iter/s, 29.7299s/500 iters), loss = 0.205728
I0831 07:53:29.636080 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.205732 (* 1 = 0.205732 loss)
I0831 07:53:29.636088 916722 sgd_solver.cpp:106] Iteration 2786500, lr = 0.01
I0831 07:53:59.364749 916722 solver.cpp:218] Iteration 2787000 (16.8188 iter/s, 29.7286s/500 iters), loss = 0.127382
I0831 07:53:59.364802 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.127387 (* 1 = 0.127387 loss)
I0831 07:53:59.364810 916722 sgd_solver.cpp:106] Iteration 2787000, lr = 0.01
I0831 07:54:29.095541 916722 solver.cpp:218] Iteration 2787500 (16.8177 iter/s, 29.7307s/500 iters), loss = 0.133404
I0831 07:54:29.095600 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133409 (* 1 = 0.133409 loss)
I0831 07:54:29.095608 916722 sgd_solver.cpp:106] Iteration 2787500, lr = 0.01
I0831 07:54:58.825332 916722 solver.cpp:218] Iteration 2788000 (16.8182 iter/s, 29.7296s/500 iters), loss = 0.155613
I0831 07:54:58.825384 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.155618 (* 1 = 0.155618 loss)
I0831 07:54:58.825394 916722 sgd_solver.cpp:106] Iteration 2788000, lr = 0.01
I0831 07:55:28.556447 916722 solver.cpp:218] Iteration 2788500 (16.8175 iter/s, 29.731s/500 iters), loss = 0.090689
I0831 07:55:28.556505 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0906939 (* 1 = 0.0906939 loss)
I0831 07:55:28.556514 916722 sgd_solver.cpp:106] Iteration 2788500, lr = 0.01
I0831 07:55:58.288091 916722 solver.cpp:218] Iteration 2789000 (16.8172 iter/s, 29.7315s/500 iters), loss = 0.0984447
I0831 07:55:58.288143 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0984496 (* 1 = 0.0984496 loss)
I0831 07:55:58.288153 916722 sgd_solver.cpp:106] Iteration 2789000, lr = 0.01
I0831 07:56:28.017798 916722 solver.cpp:218] Iteration 2789500 (16.8183 iter/s, 29.7296s/500 iters), loss = 0.0258583
I0831 07:56:28.017870 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.025863 (* 1 = 0.025863 loss)
I0831 07:56:28.017884 916722 sgd_solver.cpp:106] Iteration 2789500, lr = 0.01
I0831 07:56:57.746556 916722 solver.cpp:218] Iteration 2790000 (16.8188 iter/s, 29.7286s/500 iters), loss = 0.238885
I0831 07:56:57.746608 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.23889 (* 1 = 0.23889 loss)
I0831 07:56:57.746618 916722 sgd_solver.cpp:106] Iteration 2790000, lr = 0.01
I0831 07:57:27.478945 916722 solver.cpp:218] Iteration 2790500 (16.8168 iter/s, 29.7323s/500 iters), loss = 0.0846271
I0831 07:57:27.479004 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0846318 (* 1 = 0.0846318 loss)
I0831 07:57:27.479012 916722 sgd_solver.cpp:106] Iteration 2790500, lr = 0.01
I0831 07:57:57.210878 916722 solver.cpp:218] Iteration 2791000 (16.817 iter/s, 29.7318s/500 iters), loss = 0.0736467
I0831 07:57:57.210932 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0736515 (* 1 = 0.0736515 loss)
I0831 07:57:57.210942 916722 sgd_solver.cpp:106] Iteration 2791000, lr = 0.01
I0831 07:58:26.941552 916722 solver.cpp:218] Iteration 2791500 (16.8177 iter/s, 29.7305s/500 iters), loss = 0.081255
I0831 07:58:26.941612 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0812598 (* 1 = 0.0812598 loss)
I0831 07:58:26.941622 916722 sgd_solver.cpp:106] Iteration 2791500, lr = 0.01
I0831 07:58:56.665252 916722 solver.cpp:218] Iteration 2792000 (16.8217 iter/s, 29.7236s/500 iters), loss = 0.0820872
I0831 07:58:56.665305 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0820919 (* 1 = 0.0820919 loss)
I0831 07:58:56.665315 916722 sgd_solver.cpp:106] Iteration 2792000, lr = 0.01
I0831 07:59:26.394727 916722 solver.cpp:218] Iteration 2792500 (16.8184 iter/s, 29.7293s/500 iters), loss = 0.190834
I0831 07:59:26.394788 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.190839 (* 1 = 0.190839 loss)
I0831 07:59:26.394796 916722 sgd_solver.cpp:106] Iteration 2792500, lr = 0.01
I0831 07:59:56.120039 916722 solver.cpp:218] Iteration 2793000 (16.8208 iter/s, 29.7252s/500 iters), loss = 0.0638314
I0831 07:59:56.120092 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0638362 (* 1 = 0.0638362 loss)
I0831 07:59:56.120103 916722 sgd_solver.cpp:106] Iteration 2793000, lr = 0.01
I0831 08:00:25.848042 916722 solver.cpp:218] Iteration 2793500 (16.8192 iter/s, 29.7279s/500 iters), loss = 0.0178246
I0831 08:00:25.848104 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0178295 (* 1 = 0.0178295 loss)
I0831 08:00:25.848112 916722 sgd_solver.cpp:106] Iteration 2793500, lr = 0.01
I0831 08:00:55.578347 916722 solver.cpp:218] Iteration 2794000 (16.8179 iter/s, 29.7302s/500 iters), loss = 0.0688316
I0831 08:00:55.578400 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0688363 (* 1 = 0.0688363 loss)
I0831 08:00:55.578409 916722 sgd_solver.cpp:106] Iteration 2794000, lr = 0.01
I0831 08:01:25.308373 916722 solver.cpp:218] Iteration 2794500 (16.8181 iter/s, 29.7299s/500 iters), loss = 0.25746
I0831 08:01:25.308437 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.257464 (* 1 = 0.257464 loss)
I0831 08:01:25.308459 916722 sgd_solver.cpp:106] Iteration 2794500, lr = 0.01
I0831 08:01:55.039587 916722 solver.cpp:218] Iteration 2795000 (16.8174 iter/s, 29.7311s/500 iters), loss = 0.055083
I0831 08:01:55.039639 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0550878 (* 1 = 0.0550878 loss)
I0831 08:01:55.039649 916722 sgd_solver.cpp:106] Iteration 2795000, lr = 0.01
I0831 08:02:24.770933 916722 solver.cpp:218] Iteration 2795500 (16.8173 iter/s, 29.7312s/500 iters), loss = 0.102756
I0831 08:02:24.770992 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.102761 (* 1 = 0.102761 loss)
I0831 08:02:24.770999 916722 sgd_solver.cpp:106] Iteration 2795500, lr = 0.01
I0831 08:02:54.498359 916722 solver.cpp:218] Iteration 2796000 (16.8196 iter/s, 29.7273s/500 iters), loss = 0.0627536
I0831 08:02:54.498412 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0627582 (* 1 = 0.0627582 loss)
I0831 08:02:54.498432 916722 sgd_solver.cpp:106] Iteration 2796000, lr = 0.01
I0831 08:03:24.230103 916722 solver.cpp:218] Iteration 2796500 (16.8171 iter/s, 29.7316s/500 iters), loss = 0.0729293
I0831 08:03:24.230175 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0729339 (* 1 = 0.0729339 loss)
I0831 08:03:24.230183 916722 sgd_solver.cpp:106] Iteration 2796500, lr = 0.01
I0831 08:03:53.959679 916722 solver.cpp:218] Iteration 2797000 (16.8184 iter/s, 29.7294s/500 iters), loss = 0.125821
I0831 08:03:53.959730 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.125826 (* 1 = 0.125826 loss)
I0831 08:03:53.959738 916722 sgd_solver.cpp:106] Iteration 2797000, lr = 0.01
I0831 08:04:23.690552 916722 solver.cpp:218] Iteration 2797500 (16.8176 iter/s, 29.7307s/500 iters), loss = 0.219293
I0831 08:04:23.690614 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.219298 (* 1 = 0.219298 loss)
I0831 08:04:23.690623 916722 sgd_solver.cpp:106] Iteration 2797500, lr = 0.01
I0831 08:04:53.421907 916722 solver.cpp:218] Iteration 2798000 (16.8173 iter/s, 29.7312s/500 iters), loss = 0.223551
I0831 08:04:53.421959 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.223556 (* 1 = 0.223556 loss)
I0831 08:04:53.421968 916722 sgd_solver.cpp:106] Iteration 2798000, lr = 0.01
I0831 08:05:23.156211 916722 solver.cpp:218] Iteration 2798500 (16.8157 iter/s, 29.7342s/500 iters), loss = 0.163912
I0831 08:05:23.156270 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.163916 (* 1 = 0.163916 loss)
I0831 08:05:23.156280 916722 sgd_solver.cpp:106] Iteration 2798500, lr = 0.01
I0831 08:05:52.891248 916722 solver.cpp:218] Iteration 2799000 (16.8153 iter/s, 29.7349s/500 iters), loss = 0.112307
I0831 08:05:52.891300 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112312 (* 1 = 0.112312 loss)
I0831 08:05:52.891310 916722 sgd_solver.cpp:106] Iteration 2799000, lr = 0.01
I0831 08:06:22.624222 916722 solver.cpp:218] Iteration 2799500 (16.8164 iter/s, 29.7328s/500 iters), loss = 0.118326
I0831 08:06:22.624281 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.118331 (* 1 = 0.118331 loss)
I0831 08:06:22.624289 916722 sgd_solver.cpp:106] Iteration 2799500, lr = 0.01
I0831 08:06:52.296408 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_2800000.caffemodel
I0831 08:06:52.315742 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_2800000.solverstate
I0831 08:06:52.321826 916722 solver.cpp:330] Iteration 2800000, Testing net (#0)
I0831 08:07:07.723001 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8799
I0831 08:07:07.723052 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.406673 (* 1 = 0.406673 loss)
I0831 08:07:07.781575 916722 solver.cpp:218] Iteration 2800000 (11.0724 iter/s, 45.1572s/500 iters), loss = 0.317373
I0831 08:07:07.781602 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.317378 (* 1 = 0.317378 loss)
I0831 08:07:07.781610 916722 sgd_solver.cpp:106] Iteration 2800000, lr = 0.01
I0831 08:07:37.505306 916722 solver.cpp:218] Iteration 2800500 (16.8217 iter/s, 29.7236s/500 iters), loss = 0.0374554
I0831 08:07:37.505357 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0374599 (* 1 = 0.0374599 loss)
I0831 08:07:37.505367 916722 sgd_solver.cpp:106] Iteration 2800500, lr = 0.01
I0831 08:08:07.266185 916722 solver.cpp:218] Iteration 2801000 (16.8007 iter/s, 29.7607s/500 iters), loss = 0.019112
I0831 08:08:07.266247 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0191166 (* 1 = 0.0191166 loss)
I0831 08:08:07.266256 916722 sgd_solver.cpp:106] Iteration 2801000, lr = 0.01
I0831 08:08:37.032141 916722 solver.cpp:218] Iteration 2801500 (16.7978 iter/s, 29.7658s/500 iters), loss = 0.384176
I0831 08:08:37.032198 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.384181 (* 1 = 0.384181 loss)
I0831 08:08:37.032208 916722 sgd_solver.cpp:106] Iteration 2801500, lr = 0.01
I0831 08:09:06.802428 916722 solver.cpp:218] Iteration 2802000 (16.7954 iter/s, 29.7701s/500 iters), loss = 0.276381
I0831 08:09:06.802503 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.276386 (* 1 = 0.276386 loss)
I0831 08:09:06.802512 916722 sgd_solver.cpp:106] Iteration 2802000, lr = 0.01
I0831 08:09:36.569756 916722 solver.cpp:218] Iteration 2802500 (16.797 iter/s, 29.7672s/500 iters), loss = 0.0710795
I0831 08:09:36.569808 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0710844 (* 1 = 0.0710844 loss)
I0831 08:09:36.569818 916722 sgd_solver.cpp:106] Iteration 2802500, lr = 0.01
I0831 08:10:06.331885 916722 solver.cpp:218] Iteration 2803000 (16.8 iter/s, 29.762s/500 iters), loss = 0.052947
I0831 08:10:06.331945 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.052952 (* 1 = 0.052952 loss)
I0831 08:10:06.331954 916722 sgd_solver.cpp:106] Iteration 2803000, lr = 0.01
I0831 08:10:36.106077 916722 solver.cpp:218] Iteration 2803500 (16.7931 iter/s, 29.7741s/500 iters), loss = 0.224203
I0831 08:10:36.106129 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.224208 (* 1 = 0.224208 loss)
I0831 08:10:36.106139 916722 sgd_solver.cpp:106] Iteration 2803500, lr = 0.01
I0831 08:11:05.874735 916722 solver.cpp:218] Iteration 2804000 (16.7963 iter/s, 29.7685s/500 iters), loss = 0.227914
I0831 08:11:05.874795 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.227919 (* 1 = 0.227919 loss)
I0831 08:11:05.874804 916722 sgd_solver.cpp:106] Iteration 2804000, lr = 0.01
I0831 08:11:35.641109 916722 solver.cpp:218] Iteration 2804500 (16.7976 iter/s, 29.7662s/500 iters), loss = 0.409773
I0831 08:11:35.641158 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.409779 (* 1 = 0.409779 loss)
I0831 08:11:35.641168 916722 sgd_solver.cpp:106] Iteration 2804500, lr = 0.01
I0831 08:12:05.408099 916722 solver.cpp:218] Iteration 2805000 (16.7972 iter/s, 29.7669s/500 iters), loss = 0.0926117
I0831 08:12:05.408159 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0926167 (* 1 = 0.0926167 loss)
I0831 08:12:05.408167 916722 sgd_solver.cpp:106] Iteration 2805000, lr = 0.01
I0831 08:12:35.173285 916722 solver.cpp:218] Iteration 2805500 (16.7982 iter/s, 29.7651s/500 iters), loss = 0.0452719
I0831 08:12:35.173339 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0452768 (* 1 = 0.0452768 loss)
I0831 08:12:35.173349 916722 sgd_solver.cpp:106] Iteration 2805500, lr = 0.01
I0831 08:13:04.934746 916722 solver.cpp:218] Iteration 2806000 (16.8003 iter/s, 29.7613s/500 iters), loss = 0.139947
I0831 08:13:04.934803 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139952 (* 1 = 0.139952 loss)
I0831 08:13:04.934811 916722 sgd_solver.cpp:106] Iteration 2806000, lr = 0.01
I0831 08:13:34.702920 916722 solver.cpp:218] Iteration 2806500 (16.7965 iter/s, 29.768s/500 iters), loss = 0.0416234
I0831 08:13:34.702973 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0416284 (* 1 = 0.0416284 loss)
I0831 08:13:34.702983 916722 sgd_solver.cpp:106] Iteration 2806500, lr = 0.01
I0831 08:14:04.470839 916722 solver.cpp:218] Iteration 2807000 (16.7967 iter/s, 29.7678s/500 iters), loss = 0.0428613
I0831 08:14:04.470898 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0428665 (* 1 = 0.0428665 loss)
I0831 08:14:04.470906 916722 sgd_solver.cpp:106] Iteration 2807000, lr = 0.01
I0831 08:14:34.236877 916722 solver.cpp:218] Iteration 2807500 (16.7977 iter/s, 29.7659s/500 iters), loss = 0.0733424
I0831 08:14:34.236932 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0733476 (* 1 = 0.0733476 loss)
I0831 08:14:34.236941 916722 sgd_solver.cpp:106] Iteration 2807500, lr = 0.01
I0831 08:15:04.006093 916722 solver.cpp:218] Iteration 2808000 (16.796 iter/s, 29.7691s/500 iters), loss = 0.0849644
I0831 08:15:04.006151 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0849696 (* 1 = 0.0849696 loss)
I0831 08:15:04.006160 916722 sgd_solver.cpp:106] Iteration 2808000, lr = 0.01
I0831 08:15:33.777509 916722 solver.cpp:218] Iteration 2808500 (16.7947 iter/s, 29.7713s/500 iters), loss = 0.0426819
I0831 08:15:33.777568 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0426874 (* 1 = 0.0426874 loss)
I0831 08:15:33.777576 916722 sgd_solver.cpp:106] Iteration 2808500, lr = 0.01
I0831 08:16:03.553745 916722 solver.cpp:218] Iteration 2809000 (16.792 iter/s, 29.7761s/500 iters), loss = 0.0645654
I0831 08:16:03.553814 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0645709 (* 1 = 0.0645709 loss)
I0831 08:16:03.553822 916722 sgd_solver.cpp:106] Iteration 2809000, lr = 0.01
I0831 08:16:33.342759 916722 solver.cpp:218] Iteration 2809500 (16.7848 iter/s, 29.7889s/500 iters), loss = 0.0282128
I0831 08:16:33.342808 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0282183 (* 1 = 0.0282183 loss)
I0831 08:16:33.342816 916722 sgd_solver.cpp:106] Iteration 2809500, lr = 0.01
I0831 08:17:03.135131 916722 solver.cpp:218] Iteration 2810000 (16.7829 iter/s, 29.7923s/500 iters), loss = 0.218205
I0831 08:17:03.135186 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.21821 (* 1 = 0.21821 loss)
I0831 08:17:03.135195 916722 sgd_solver.cpp:106] Iteration 2810000, lr = 0.01
I0831 08:17:32.921814 916722 solver.cpp:218] Iteration 2810500 (16.7861 iter/s, 29.7866s/500 iters), loss = 0.125587
I0831 08:17:32.921861 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.125593 (* 1 = 0.125593 loss)
I0831 08:17:32.921871 916722 sgd_solver.cpp:106] Iteration 2810500, lr = 0.01
I0831 08:18:02.710136 916722 solver.cpp:218] Iteration 2811000 (16.7852 iter/s, 29.7882s/500 iters), loss = 0.0549374
I0831 08:18:02.710191 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0549428 (* 1 = 0.0549428 loss)
I0831 08:18:02.710199 916722 sgd_solver.cpp:106] Iteration 2811000, lr = 0.01
I0831 08:18:32.504915 916722 solver.cpp:218] Iteration 2811500 (16.7815 iter/s, 29.7947s/500 iters), loss = 0.295723
I0831 08:18:32.504962 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.295729 (* 1 = 0.295729 loss)
I0831 08:18:32.504971 916722 sgd_solver.cpp:106] Iteration 2811500, lr = 0.01
I0831 08:19:02.282316 916722 solver.cpp:218] Iteration 2812000 (16.7913 iter/s, 29.7773s/500 iters), loss = 0.244752
I0831 08:19:02.282373 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.244757 (* 1 = 0.244757 loss)
I0831 08:19:02.282382 916722 sgd_solver.cpp:106] Iteration 2812000, lr = 0.01
I0831 08:19:32.054663 916722 solver.cpp:218] Iteration 2812500 (16.7942 iter/s, 29.7722s/500 iters), loss = 0.1827
I0831 08:19:32.054716 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.182706 (* 1 = 0.182706 loss)
I0831 08:19:32.054725 916722 sgd_solver.cpp:106] Iteration 2812500, lr = 0.01
I0831 08:20:01.837672 916722 solver.cpp:218] Iteration 2813000 (16.7882 iter/s, 29.7829s/500 iters), loss = 0.287722
I0831 08:20:01.837731 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.287728 (* 1 = 0.287728 loss)
I0831 08:20:01.837739 916722 sgd_solver.cpp:106] Iteration 2813000, lr = 0.01
I0831 08:20:31.618623 916722 solver.cpp:218] Iteration 2813500 (16.7893 iter/s, 29.7808s/500 iters), loss = 0.0999815
I0831 08:20:31.618680 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.099987 (* 1 = 0.099987 loss)
I0831 08:20:31.618690 916722 sgd_solver.cpp:106] Iteration 2813500, lr = 0.01
I0831 08:21:01.401981 916722 solver.cpp:218] Iteration 2814000 (16.788 iter/s, 29.7832s/500 iters), loss = 0.303067
I0831 08:21:01.402037 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.303072 (* 1 = 0.303072 loss)
I0831 08:21:01.402046 916722 sgd_solver.cpp:106] Iteration 2814000, lr = 0.01
I0831 08:21:31.178738 916722 solver.cpp:218] Iteration 2814500 (16.7917 iter/s, 29.7765s/500 iters), loss = 0.121676
I0831 08:21:31.178793 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.121682 (* 1 = 0.121682 loss)
I0831 08:21:31.178803 916722 sgd_solver.cpp:106] Iteration 2814500, lr = 0.01
I0831 08:22:00.951375 916722 solver.cpp:218] Iteration 2815000 (16.7941 iter/s, 29.7724s/500 iters), loss = 0.0557617
I0831 08:22:00.951447 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0557669 (* 1 = 0.0557669 loss)
I0831 08:22:00.951455 916722 sgd_solver.cpp:106] Iteration 2815000, lr = 0.01
I0831 08:22:30.727309 916722 solver.cpp:218] Iteration 2815500 (16.7922 iter/s, 29.7757s/500 iters), loss = 0.354481
I0831 08:22:30.727365 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.354486 (* 1 = 0.354486 loss)
I0831 08:22:30.727375 916722 sgd_solver.cpp:106] Iteration 2815500, lr = 0.01
I0831 08:23:00.499745 916722 solver.cpp:218] Iteration 2816000 (16.7942 iter/s, 29.7722s/500 iters), loss = 0.107154
I0831 08:23:00.499801 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.107159 (* 1 = 0.107159 loss)
I0831 08:23:00.499810 916722 sgd_solver.cpp:106] Iteration 2816000, lr = 0.01
I0831 08:23:30.274313 916722 solver.cpp:218] Iteration 2816500 (16.793 iter/s, 29.7744s/500 iters), loss = 0.206108
I0831 08:23:30.274367 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.206113 (* 1 = 0.206113 loss)
I0831 08:23:30.274377 916722 sgd_solver.cpp:106] Iteration 2816500, lr = 0.01
I0831 08:24:00.052791 916722 solver.cpp:218] Iteration 2817000 (16.7908 iter/s, 29.7783s/500 iters), loss = 0.296853
I0831 08:24:00.052850 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.296858 (* 1 = 0.296858 loss)
I0831 08:24:00.052857 916722 sgd_solver.cpp:106] Iteration 2817000, lr = 0.01
I0831 08:24:29.829792 916722 solver.cpp:218] Iteration 2817500 (16.7916 iter/s, 29.7768s/500 iters), loss = 0.121293
I0831 08:24:29.829846 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.121298 (* 1 = 0.121298 loss)
I0831 08:24:29.829856 916722 sgd_solver.cpp:106] Iteration 2817500, lr = 0.01
I0831 08:24:59.606464 916722 solver.cpp:218] Iteration 2818000 (16.7918 iter/s, 29.7765s/500 iters), loss = 0.0407049
I0831 08:24:59.606521 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0407101 (* 1 = 0.0407101 loss)
I0831 08:24:59.606530 916722 sgd_solver.cpp:106] Iteration 2818000, lr = 0.01
I0831 08:25:29.387792 916722 solver.cpp:218] Iteration 2818500 (16.7891 iter/s, 29.7811s/500 iters), loss = 0.177532
I0831 08:25:29.387845 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.177537 (* 1 = 0.177537 loss)
I0831 08:25:29.387854 916722 sgd_solver.cpp:106] Iteration 2818500, lr = 0.01
I0831 08:25:59.165077 916722 solver.cpp:218] Iteration 2819000 (16.7914 iter/s, 29.7771s/500 iters), loss = 0.0425493
I0831 08:25:59.165143 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0425544 (* 1 = 0.0425544 loss)
I0831 08:25:59.165151 916722 sgd_solver.cpp:106] Iteration 2819000, lr = 0.01
I0831 08:26:28.948664 916722 solver.cpp:218] Iteration 2819500 (16.7879 iter/s, 29.7834s/500 iters), loss = 0.18436
I0831 08:26:28.948719 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.184366 (* 1 = 0.184366 loss)
I0831 08:26:28.948729 916722 sgd_solver.cpp:106] Iteration 2819500, lr = 0.01
I0831 08:26:58.734259 916722 solver.cpp:218] Iteration 2820000 (16.7867 iter/s, 29.7854s/500 iters), loss = 0.30655
I0831 08:26:58.734320 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.306555 (* 1 = 0.306555 loss)
I0831 08:26:58.734328 916722 sgd_solver.cpp:106] Iteration 2820000, lr = 0.01
I0831 08:27:28.513231 916722 solver.cpp:218] Iteration 2820500 (16.7905 iter/s, 29.7788s/500 iters), loss = 0.0651957
I0831 08:27:28.513284 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.065201 (* 1 = 0.065201 loss)
I0831 08:27:28.513293 916722 sgd_solver.cpp:106] Iteration 2820500, lr = 0.01
I0831 08:27:58.305685 916722 solver.cpp:218] Iteration 2821000 (16.7829 iter/s, 29.7923s/500 iters), loss = 0.391958
I0831 08:27:58.305747 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.391963 (* 1 = 0.391963 loss)
I0831 08:27:58.305756 916722 sgd_solver.cpp:106] Iteration 2821000, lr = 0.01
I0831 08:28:28.090948 916722 solver.cpp:218] Iteration 2821500 (16.7869 iter/s, 29.7851s/500 iters), loss = 0.179092
I0831 08:28:28.091002 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.179097 (* 1 = 0.179097 loss)
I0831 08:28:28.091023 916722 sgd_solver.cpp:106] Iteration 2821500, lr = 0.01
I0831 08:28:57.874163 916722 solver.cpp:218] Iteration 2822000 (16.7881 iter/s, 29.7831s/500 iters), loss = 0.393021
I0831 08:28:57.874233 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.393026 (* 1 = 0.393026 loss)
I0831 08:28:57.874243 916722 sgd_solver.cpp:106] Iteration 2822000, lr = 0.01
I0831 08:29:27.662719 916722 solver.cpp:218] Iteration 2822500 (16.7851 iter/s, 29.7884s/500 iters), loss = 0.0706352
I0831 08:29:27.662770 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0706405 (* 1 = 0.0706405 loss)
I0831 08:29:27.662779 916722 sgd_solver.cpp:106] Iteration 2822500, lr = 0.01
I0831 08:29:57.451851 916722 solver.cpp:218] Iteration 2823000 (16.7847 iter/s, 29.789s/500 iters), loss = 0.286659
I0831 08:29:57.451908 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.286664 (* 1 = 0.286664 loss)
I0831 08:29:57.451916 916722 sgd_solver.cpp:106] Iteration 2823000, lr = 0.01
I0831 08:30:27.240712 916722 solver.cpp:218] Iteration 2823500 (16.7849 iter/s, 29.7887s/500 iters), loss = 0.148823
I0831 08:30:27.240780 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.148828 (* 1 = 0.148828 loss)
I0831 08:30:27.240790 916722 sgd_solver.cpp:106] Iteration 2823500, lr = 0.01
I0831 08:30:57.031133 916722 solver.cpp:218] Iteration 2824000 (16.784 iter/s, 29.7903s/500 iters), loss = 0.126473
I0831 08:30:57.031193 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.126478 (* 1 = 0.126478 loss)
I0831 08:30:57.031203 916722 sgd_solver.cpp:106] Iteration 2824000, lr = 0.01
I0831 08:31:26.830513 916722 solver.cpp:218] Iteration 2824500 (16.7789 iter/s, 29.7992s/500 iters), loss = 0.256226
I0831 08:31:26.830566 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.256231 (* 1 = 0.256231 loss)
I0831 08:31:26.830576 916722 sgd_solver.cpp:106] Iteration 2824500, lr = 0.01
I0831 08:31:56.625918 916722 solver.cpp:218] Iteration 2825000 (16.7812 iter/s, 29.7953s/500 iters), loss = 0.018169
I0831 08:31:56.625982 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0181745 (* 1 = 0.0181745 loss)
I0831 08:31:56.625991 916722 sgd_solver.cpp:106] Iteration 2825000, lr = 0.01
I0831 08:32:26.427577 916722 solver.cpp:218] Iteration 2825500 (16.7777 iter/s, 29.8015s/500 iters), loss = 0.122716
I0831 08:32:26.427631 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.122721 (* 1 = 0.122721 loss)
I0831 08:32:26.427641 916722 sgd_solver.cpp:106] Iteration 2825500, lr = 0.01
I0831 08:32:56.227356 916722 solver.cpp:218] Iteration 2826000 (16.7787 iter/s, 29.7997s/500 iters), loss = 0.0766337
I0831 08:32:56.227416 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0766393 (* 1 = 0.0766393 loss)
I0831 08:32:56.227425 916722 sgd_solver.cpp:106] Iteration 2826000, lr = 0.01
I0831 08:33:26.030817 916722 solver.cpp:218] Iteration 2826500 (16.7766 iter/s, 29.8033s/500 iters), loss = 0.305939
I0831 08:33:26.030869 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.305945 (* 1 = 0.305945 loss)
I0831 08:33:26.030879 916722 sgd_solver.cpp:106] Iteration 2826500, lr = 0.01
I0831 08:33:55.836311 916722 solver.cpp:218] Iteration 2827000 (16.7755 iter/s, 29.8054s/500 iters), loss = 0.15213
I0831 08:33:55.836365 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152135 (* 1 = 0.152135 loss)
I0831 08:33:55.836374 916722 sgd_solver.cpp:106] Iteration 2827000, lr = 0.01
I0831 08:34:25.635154 916722 solver.cpp:218] Iteration 2827500 (16.7792 iter/s, 29.7987s/500 iters), loss = 0.0934898
I0831 08:34:25.635205 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0934954 (* 1 = 0.0934954 loss)
I0831 08:34:25.635215 916722 sgd_solver.cpp:106] Iteration 2827500, lr = 0.01
I0831 08:34:55.436695 916722 solver.cpp:218] Iteration 2828000 (16.7777 iter/s, 29.8014s/500 iters), loss = 0.15999
I0831 08:34:55.436765 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159996 (* 1 = 0.159996 loss)
I0831 08:34:55.436779 916722 sgd_solver.cpp:106] Iteration 2828000, lr = 0.01
I0831 08:35:25.230551 916722 solver.cpp:218] Iteration 2828500 (16.7821 iter/s, 29.7937s/500 iters), loss = 0.32711
I0831 08:35:25.230604 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.327115 (* 1 = 0.327115 loss)
I0831 08:35:25.230614 916722 sgd_solver.cpp:106] Iteration 2828500, lr = 0.01
I0831 08:35:55.032898 916722 solver.cpp:218] Iteration 2829000 (16.7773 iter/s, 29.8022s/500 iters), loss = 0.0539124
I0831 08:35:55.032964 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0539179 (* 1 = 0.0539179 loss)
I0831 08:35:55.032974 916722 sgd_solver.cpp:106] Iteration 2829000, lr = 0.01
I0831 08:36:24.816493 916722 solver.cpp:218] Iteration 2829500 (16.7878 iter/s, 29.7835s/500 iters), loss = 0.0447455
I0831 08:36:24.816548 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.044751 (* 1 = 0.044751 loss)
I0831 08:36:24.816557 916722 sgd_solver.cpp:106] Iteration 2829500, lr = 0.01
I0831 08:36:54.598312 916722 solver.cpp:218] Iteration 2830000 (16.7888 iter/s, 29.7817s/500 iters), loss = 0.175849
I0831 08:36:54.598373 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.175855 (* 1 = 0.175855 loss)
I0831 08:36:54.598382 916722 sgd_solver.cpp:106] Iteration 2830000, lr = 0.01
I0831 08:37:24.372294 916722 solver.cpp:218] Iteration 2830500 (16.7932 iter/s, 29.7739s/500 iters), loss = 0.409819
I0831 08:37:24.372349 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.409825 (* 1 = 0.409825 loss)
I0831 08:37:24.372357 916722 sgd_solver.cpp:106] Iteration 2830500, lr = 0.01
I0831 08:37:54.147158 916722 solver.cpp:218] Iteration 2831000 (16.7927 iter/s, 29.7748s/500 iters), loss = 0.0931511
I0831 08:37:54.147218 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0931568 (* 1 = 0.0931568 loss)
I0831 08:37:54.147228 916722 sgd_solver.cpp:106] Iteration 2831000, lr = 0.01
I0831 08:38:23.918726 916722 solver.cpp:218] Iteration 2831500 (16.7946 iter/s, 29.7715s/500 iters), loss = 0.112722
I0831 08:38:23.918777 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112728 (* 1 = 0.112728 loss)
I0831 08:38:23.918787 916722 sgd_solver.cpp:106] Iteration 2831500, lr = 0.01
I0831 08:38:53.690124 916722 solver.cpp:218] Iteration 2832000 (16.7947 iter/s, 29.7713s/500 iters), loss = 0.148831
I0831 08:38:53.690181 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.148836 (* 1 = 0.148836 loss)
I0831 08:38:53.690189 916722 sgd_solver.cpp:106] Iteration 2832000, lr = 0.01
I0831 08:39:23.458371 916722 solver.cpp:218] Iteration 2832500 (16.7965 iter/s, 29.7681s/500 iters), loss = 0.150885
I0831 08:39:23.458425 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.150891 (* 1 = 0.150891 loss)
I0831 08:39:23.458436 916722 sgd_solver.cpp:106] Iteration 2832500, lr = 0.01
I0831 08:39:53.221913 916722 solver.cpp:218] Iteration 2833000 (16.7991 iter/s, 29.7634s/500 iters), loss = 0.043297
I0831 08:39:53.221976 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0433024 (* 1 = 0.0433024 loss)
I0831 08:39:53.221984 916722 sgd_solver.cpp:106] Iteration 2833000, lr = 0.01
I0831 08:40:22.990430 916722 solver.cpp:218] Iteration 2833500 (16.7963 iter/s, 29.7684s/500 iters), loss = 0.127779
I0831 08:40:22.990482 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.127785 (* 1 = 0.127785 loss)
I0831 08:40:22.990492 916722 sgd_solver.cpp:106] Iteration 2833500, lr = 0.01
I0831 08:40:52.763512 916722 solver.cpp:218] Iteration 2834000 (16.7937 iter/s, 29.773s/500 iters), loss = 0.160655
I0831 08:40:52.763574 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.160661 (* 1 = 0.160661 loss)
I0831 08:40:52.763583 916722 sgd_solver.cpp:106] Iteration 2834000, lr = 0.01
I0831 08:41:22.533324 916722 solver.cpp:218] Iteration 2834500 (16.7956 iter/s, 29.7697s/500 iters), loss = 0.186243
I0831 08:41:22.533378 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.186248 (* 1 = 0.186248 loss)
I0831 08:41:22.533401 916722 sgd_solver.cpp:106] Iteration 2834500, lr = 0.01
I0831 08:41:52.305987 916722 solver.cpp:218] Iteration 2835000 (16.794 iter/s, 29.7726s/500 iters), loss = 0.105325
I0831 08:41:52.306061 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.10533 (* 1 = 0.10533 loss)
I0831 08:41:52.306069 916722 sgd_solver.cpp:106] Iteration 2835000, lr = 0.01
I0831 08:42:22.084563 916722 solver.cpp:218] Iteration 2835500 (16.7907 iter/s, 29.7785s/500 iters), loss = 0.0752703
I0831 08:42:22.084614 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0752758 (* 1 = 0.0752758 loss)
I0831 08:42:22.084622 916722 sgd_solver.cpp:106] Iteration 2835500, lr = 0.01
I0831 08:42:51.863662 916722 solver.cpp:218] Iteration 2836000 (16.7903 iter/s, 29.779s/500 iters), loss = 0.301129
I0831 08:42:51.863719 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.301134 (* 1 = 0.301134 loss)
I0831 08:42:51.863729 916722 sgd_solver.cpp:106] Iteration 2836000, lr = 0.01
I0831 08:43:21.636881 916722 solver.cpp:218] Iteration 2836500 (16.7937 iter/s, 29.7731s/500 iters), loss = 0.0721638
I0831 08:43:21.636931 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0721693 (* 1 = 0.0721693 loss)
I0831 08:43:21.636940 916722 sgd_solver.cpp:106] Iteration 2836500, lr = 0.01
I0831 08:43:51.417315 916722 solver.cpp:218] Iteration 2837000 (16.7896 iter/s, 29.7803s/500 iters), loss = 0.14849
I0831 08:43:51.417377 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.148495 (* 1 = 0.148495 loss)
I0831 08:43:51.417387 916722 sgd_solver.cpp:106] Iteration 2837000, lr = 0.01
I0831 08:44:21.201928 916722 solver.cpp:218] Iteration 2837500 (16.7872 iter/s, 29.7845s/500 iters), loss = 0.0985491
I0831 08:44:21.201983 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0985546 (* 1 = 0.0985546 loss)
I0831 08:44:21.201992 916722 sgd_solver.cpp:106] Iteration 2837500, lr = 0.01
I0831 08:44:50.984977 916722 solver.cpp:218] Iteration 2838000 (16.7881 iter/s, 29.783s/500 iters), loss = 0.103727
I0831 08:44:50.985040 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.103732 (* 1 = 0.103732 loss)
I0831 08:44:50.985049 916722 sgd_solver.cpp:106] Iteration 2838000, lr = 0.01
I0831 08:45:20.769109 916722 solver.cpp:218] Iteration 2838500 (16.7875 iter/s, 29.784s/500 iters), loss = 0.221838
I0831 08:45:20.769165 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.221844 (* 1 = 0.221844 loss)
I0831 08:45:20.769176 916722 sgd_solver.cpp:106] Iteration 2838500, lr = 0.01
I0831 08:45:50.550659 916722 solver.cpp:218] Iteration 2839000 (16.789 iter/s, 29.7815s/500 iters), loss = 0.104961
I0831 08:45:50.550720 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104967 (* 1 = 0.104967 loss)
I0831 08:45:50.550729 916722 sgd_solver.cpp:106] Iteration 2839000, lr = 0.01
I0831 08:46:20.337234 916722 solver.cpp:218] Iteration 2839500 (16.7861 iter/s, 29.7865s/500 iters), loss = 0.0754724
I0831 08:46:20.337288 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.075478 (* 1 = 0.075478 loss)
I0831 08:46:20.337298 916722 sgd_solver.cpp:106] Iteration 2839500, lr = 0.01
I0831 08:46:50.126912 916722 solver.cpp:218] Iteration 2840000 (16.7844 iter/s, 29.7896s/500 iters), loss = 0.326046
I0831 08:46:50.126971 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.326052 (* 1 = 0.326052 loss)
I0831 08:46:50.126979 916722 sgd_solver.cpp:106] Iteration 2840000, lr = 0.01
I0831 08:47:19.911772 916722 solver.cpp:218] Iteration 2840500 (16.7871 iter/s, 29.7848s/500 iters), loss = 0.27248
I0831 08:47:19.911823 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.272486 (* 1 = 0.272486 loss)
I0831 08:47:19.911834 916722 sgd_solver.cpp:106] Iteration 2840500, lr = 0.01
I0831 08:47:49.701056 916722 solver.cpp:218] Iteration 2841000 (16.7846 iter/s, 29.7892s/500 iters), loss = 0.257044
I0831 08:47:49.701109 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.257049 (* 1 = 0.257049 loss)
I0831 08:47:49.701118 916722 sgd_solver.cpp:106] Iteration 2841000, lr = 0.01
I0831 08:48:19.497225 916722 solver.cpp:218] Iteration 2841500 (16.7807 iter/s, 29.7961s/500 iters), loss = 0.107987
I0831 08:48:19.497279 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.107993 (* 1 = 0.107993 loss)
I0831 08:48:19.497290 916722 sgd_solver.cpp:106] Iteration 2841500, lr = 0.01
I0831 08:48:49.287521 916722 solver.cpp:218] Iteration 2842000 (16.784 iter/s, 29.7902s/500 iters), loss = 0.129142
I0831 08:48:49.287590 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.129147 (* 1 = 0.129147 loss)
I0831 08:48:49.287600 916722 sgd_solver.cpp:106] Iteration 2842000, lr = 0.01
I0831 08:49:19.083093 916722 solver.cpp:218] Iteration 2842500 (16.7811 iter/s, 29.7955s/500 iters), loss = 0.0535378
I0831 08:49:19.083146 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0535436 (* 1 = 0.0535436 loss)
I0831 08:49:19.083156 916722 sgd_solver.cpp:106] Iteration 2842500, lr = 0.01
I0831 08:49:48.874003 916722 solver.cpp:218] Iteration 2843000 (16.7837 iter/s, 29.7908s/500 iters), loss = 0.0748116
I0831 08:49:48.874064 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0748175 (* 1 = 0.0748175 loss)
I0831 08:49:48.874073 916722 sgd_solver.cpp:106] Iteration 2843000, lr = 0.01
I0831 08:50:18.665014 916722 solver.cpp:218] Iteration 2843500 (16.7836 iter/s, 29.7909s/500 iters), loss = 0.0821964
I0831 08:50:18.665071 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0822022 (* 1 = 0.0822022 loss)
I0831 08:50:18.665081 916722 sgd_solver.cpp:106] Iteration 2843500, lr = 0.01
I0831 08:50:48.449936 916722 solver.cpp:218] Iteration 2844000 (16.7871 iter/s, 29.7848s/500 iters), loss = 0.039939
I0831 08:50:48.450001 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0399448 (* 1 = 0.0399448 loss)
I0831 08:50:48.450011 916722 sgd_solver.cpp:106] Iteration 2844000, lr = 0.01
I0831 08:51:18.248935 916722 solver.cpp:218] Iteration 2844500 (16.7791 iter/s, 29.7989s/500 iters), loss = 0.118973
I0831 08:51:18.248989 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.118979 (* 1 = 0.118979 loss)
I0831 08:51:18.248998 916722 sgd_solver.cpp:106] Iteration 2844500, lr = 0.01
I0831 08:51:48.044723 916722 solver.cpp:218] Iteration 2845000 (16.7809 iter/s, 29.7957s/500 iters), loss = 0.0937408
I0831 08:51:48.044782 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0937466 (* 1 = 0.0937466 loss)
I0831 08:51:48.044791 916722 sgd_solver.cpp:106] Iteration 2845000, lr = 0.01
I0831 08:52:17.845856 916722 solver.cpp:218] Iteration 2845500 (16.7779 iter/s, 29.8011s/500 iters), loss = 0.134891
I0831 08:52:17.845914 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.134897 (* 1 = 0.134897 loss)
I0831 08:52:17.845923 916722 sgd_solver.cpp:106] Iteration 2845500, lr = 0.01
I0831 08:52:47.639977 916722 solver.cpp:218] Iteration 2846000 (16.7819 iter/s, 29.794s/500 iters), loss = 0.0958273
I0831 08:52:47.640041 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0958331 (* 1 = 0.0958331 loss)
I0831 08:52:47.640050 916722 sgd_solver.cpp:106] Iteration 2846000, lr = 0.01
I0831 08:53:17.436471 916722 solver.cpp:218] Iteration 2846500 (16.7805 iter/s, 29.7964s/500 iters), loss = 0.347439
I0831 08:53:17.436527 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.347445 (* 1 = 0.347445 loss)
I0831 08:53:17.436535 916722 sgd_solver.cpp:106] Iteration 2846500, lr = 0.01
I0831 08:53:47.237349 916722 solver.cpp:218] Iteration 2847000 (16.7781 iter/s, 29.8008s/500 iters), loss = 0.243265
I0831 08:53:47.237411 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.243271 (* 1 = 0.243271 loss)
I0831 08:53:47.237421 916722 sgd_solver.cpp:106] Iteration 2847000, lr = 0.01
I0831 08:54:17.046977 916722 solver.cpp:218] Iteration 2847500 (16.7731 iter/s, 29.8095s/500 iters), loss = 0.29792
I0831 08:54:17.047032 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.297925 (* 1 = 0.297925 loss)
I0831 08:54:17.047041 916722 sgd_solver.cpp:106] Iteration 2847500, lr = 0.01
I0831 08:54:46.856844 916722 solver.cpp:218] Iteration 2848000 (16.773 iter/s, 29.8098s/500 iters), loss = 0.0765986
I0831 08:54:46.856922 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0766043 (* 1 = 0.0766043 loss)
I0831 08:54:46.856931 916722 sgd_solver.cpp:106] Iteration 2848000, lr = 0.01
I0831 08:55:16.673926 916722 solver.cpp:218] Iteration 2848500 (16.7689 iter/s, 29.8171s/500 iters), loss = 0.208589
I0831 08:55:16.673980 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.208594 (* 1 = 0.208594 loss)
I0831 08:55:16.673990 916722 sgd_solver.cpp:106] Iteration 2848500, lr = 0.01
I0831 08:55:46.478175 916722 solver.cpp:218] Iteration 2849000 (16.7761 iter/s, 29.8043s/500 iters), loss = 0.0627542
I0831 08:55:46.478235 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.06276 (* 1 = 0.06276 loss)
I0831 08:55:46.478245 916722 sgd_solver.cpp:106] Iteration 2849000, lr = 0.01
I0831 08:56:16.288385 916722 solver.cpp:218] Iteration 2849500 (16.7727 iter/s, 29.8103s/500 iters), loss = 0.172073
I0831 08:56:16.288452 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.172078 (* 1 = 0.172078 loss)
I0831 08:56:16.288465 916722 sgd_solver.cpp:106] Iteration 2849500, lr = 0.01
I0831 08:56:46.041800 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_2850000.caffemodel
I0831 08:56:46.061003 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_2850000.solverstate
I0831 08:56:46.067095 916722 solver.cpp:330] Iteration 2850000, Testing net (#0)
I0831 08:57:01.514930 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8818
I0831 08:57:01.514976 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.403041 (* 1 = 0.403041 loss)
I0831 08:57:01.573652 916722 solver.cpp:218] Iteration 2850000 (11.0411 iter/s, 45.2854s/500 iters), loss = 0.0592939
I0831 08:57:01.573680 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0592995 (* 1 = 0.0592995 loss)
I0831 08:57:01.573688 916722 sgd_solver.cpp:106] Iteration 2850000, lr = 0.01
I0831 08:57:31.344236 916722 solver.cpp:218] Iteration 2850500 (16.7951 iter/s, 29.7706s/500 iters), loss = 0.109594
I0831 08:57:31.344297 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.1096 (* 1 = 0.1096 loss)
I0831 08:57:31.344305 916722 sgd_solver.cpp:106] Iteration 2850500, lr = 0.01
I0831 08:58:01.112032 916722 solver.cpp:218] Iteration 2851000 (16.7966 iter/s, 29.7678s/500 iters), loss = 0.214688
I0831 08:58:01.112082 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.214694 (* 1 = 0.214694 loss)
I0831 08:58:01.112092 916722 sgd_solver.cpp:106] Iteration 2851000, lr = 0.01
I0831 08:58:30.927219 916722 solver.cpp:218] Iteration 2851500 (16.7699 iter/s, 29.8152s/500 iters), loss = 0.189214
I0831 08:58:30.927276 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.18922 (* 1 = 0.18922 loss)
I0831 08:58:30.927284 916722 sgd_solver.cpp:106] Iteration 2851500, lr = 0.01
I0831 08:59:00.834252 916722 solver.cpp:218] Iteration 2852000 (16.7184 iter/s, 29.9071s/500 iters), loss = 0.24646
I0831 08:59:00.834301 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.246465 (* 1 = 0.246465 loss)
I0831 08:59:00.834311 916722 sgd_solver.cpp:106] Iteration 2852000, lr = 0.01
I0831 08:59:30.746611 916722 solver.cpp:218] Iteration 2852500 (16.7155 iter/s, 29.9124s/500 iters), loss = 0.129611
I0831 08:59:30.746670 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.129616 (* 1 = 0.129616 loss)
I0831 08:59:30.746680 916722 sgd_solver.cpp:106] Iteration 2852500, lr = 0.01
I0831 09:00:00.629317 916722 solver.cpp:218] Iteration 2853000 (16.7321 iter/s, 29.8827s/500 iters), loss = 0.332356
I0831 09:00:00.629366 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.332361 (* 1 = 0.332361 loss)
I0831 09:00:00.629376 916722 sgd_solver.cpp:106] Iteration 2853000, lr = 0.01
I0831 09:00:30.512818 916722 solver.cpp:218] Iteration 2853500 (16.7316 iter/s, 29.8835s/500 iters), loss = 0.166572
I0831 09:00:30.512895 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.166577 (* 1 = 0.166577 loss)
I0831 09:00:30.512904 916722 sgd_solver.cpp:106] Iteration 2853500, lr = 0.01
I0831 09:01:00.393168 916722 solver.cpp:218] Iteration 2854000 (16.7334 iter/s, 29.8804s/500 iters), loss = 0.0278225
I0831 09:01:00.393224 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0278283 (* 1 = 0.0278283 loss)
I0831 09:01:00.393234 916722 sgd_solver.cpp:106] Iteration 2854000, lr = 0.01
I0831 09:01:30.273509 916722 solver.cpp:218] Iteration 2854500 (16.7334 iter/s, 29.8804s/500 iters), loss = 0.0544484
I0831 09:01:30.273571 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0544541 (* 1 = 0.0544541 loss)
I0831 09:01:30.273578 916722 sgd_solver.cpp:106] Iteration 2854500, lr = 0.01
I0831 09:02:00.151784 916722 solver.cpp:218] Iteration 2855000 (16.7346 iter/s, 29.8783s/500 iters), loss = 0.141526
I0831 09:02:00.151839 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.141532 (* 1 = 0.141532 loss)
I0831 09:02:00.151850 916722 sgd_solver.cpp:106] Iteration 2855000, lr = 0.01
I0831 09:02:30.028990 916722 solver.cpp:218] Iteration 2855500 (16.7352 iter/s, 29.8772s/500 iters), loss = 0.217784
I0831 09:02:30.029048 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.217789 (* 1 = 0.217789 loss)
I0831 09:02:30.029057 916722 sgd_solver.cpp:106] Iteration 2855500, lr = 0.01
I0831 09:02:59.909258 916722 solver.cpp:218] Iteration 2856000 (16.7334 iter/s, 29.8803s/500 iters), loss = 0.207341
I0831 09:02:59.909308 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.207346 (* 1 = 0.207346 loss)
I0831 09:02:59.909318 916722 sgd_solver.cpp:106] Iteration 2856000, lr = 0.01
I0831 09:03:29.788105 916722 solver.cpp:218] Iteration 2856500 (16.7342 iter/s, 29.8789s/500 iters), loss = 0.257345
I0831 09:03:29.788166 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.257351 (* 1 = 0.257351 loss)
I0831 09:03:29.788175 916722 sgd_solver.cpp:106] Iteration 2856500, lr = 0.01
I0831 09:03:59.666319 916722 solver.cpp:218] Iteration 2857000 (16.7346 iter/s, 29.8782s/500 iters), loss = 0.0722638
I0831 09:03:59.666376 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0722691 (* 1 = 0.0722691 loss)
I0831 09:03:59.666386 916722 sgd_solver.cpp:106] Iteration 2857000, lr = 0.01
I0831 09:04:29.550938 916722 solver.cpp:218] Iteration 2857500 (16.731 iter/s, 29.8846s/500 iters), loss = 0.412823
I0831 09:04:29.551002 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.412828 (* 1 = 0.412828 loss)
I0831 09:04:29.551012 916722 sgd_solver.cpp:106] Iteration 2857500, lr = 0.01
I0831 09:04:59.426649 916722 solver.cpp:218] Iteration 2858000 (16.736 iter/s, 29.8757s/500 iters), loss = 0.225026
I0831 09:04:59.426702 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.225031 (* 1 = 0.225031 loss)
I0831 09:04:59.426712 916722 sgd_solver.cpp:106] Iteration 2858000, lr = 0.01
I0831 09:05:29.306599 916722 solver.cpp:218] Iteration 2858500 (16.7336 iter/s, 29.88s/500 iters), loss = 0.0740895
I0831 09:05:29.306660 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0740947 (* 1 = 0.0740947 loss)
I0831 09:05:29.306669 916722 sgd_solver.cpp:106] Iteration 2858500, lr = 0.01
I0831 09:05:59.178149 916722 solver.cpp:218] Iteration 2859000 (16.7383 iter/s, 29.8715s/500 iters), loss = 0.259649
I0831 09:05:59.178205 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.259654 (* 1 = 0.259654 loss)
I0831 09:05:59.178215 916722 sgd_solver.cpp:106] Iteration 2859000, lr = 0.01
I0831 09:06:29.047463 916722 solver.cpp:218] Iteration 2859500 (16.7396 iter/s, 29.8693s/500 iters), loss = 0.0815433
I0831 09:06:29.047523 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0815485 (* 1 = 0.0815485 loss)
I0831 09:06:29.047531 916722 sgd_solver.cpp:106] Iteration 2859500, lr = 0.01
I0831 09:06:58.913924 916722 solver.cpp:218] Iteration 2860000 (16.7412 iter/s, 29.8664s/500 iters), loss = 0.0584433
I0831 09:06:58.913975 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0584485 (* 1 = 0.0584485 loss)
I0831 09:06:58.913995 916722 sgd_solver.cpp:106] Iteration 2860000, lr = 0.01
I0831 09:07:28.783805 916722 solver.cpp:218] Iteration 2860500 (16.7393 iter/s, 29.8699s/500 iters), loss = 0.0545723
I0831 09:07:28.783875 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0545775 (* 1 = 0.0545775 loss)
I0831 09:07:28.783895 916722 sgd_solver.cpp:106] Iteration 2860500, lr = 0.01
I0831 09:07:58.652002 916722 solver.cpp:218] Iteration 2861000 (16.7402 iter/s, 29.8682s/500 iters), loss = 0.130918
I0831 09:07:58.652056 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130923 (* 1 = 0.130923 loss)
I0831 09:07:58.652065 916722 sgd_solver.cpp:106] Iteration 2861000, lr = 0.01
I0831 09:08:28.520288 916722 solver.cpp:218] Iteration 2861500 (16.7402 iter/s, 29.8683s/500 iters), loss = 0.110169
I0831 09:08:28.520354 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110174 (* 1 = 0.110174 loss)
I0831 09:08:28.520362 916722 sgd_solver.cpp:106] Iteration 2861500, lr = 0.01
I0831 09:08:58.368367 916722 solver.cpp:218] Iteration 2862000 (16.7515 iter/s, 29.8481s/500 iters), loss = 0.111227
I0831 09:08:58.368428 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111232 (* 1 = 0.111232 loss)
I0831 09:08:58.368438 916722 sgd_solver.cpp:106] Iteration 2862000, lr = 0.01
I0831 09:09:28.246141 916722 solver.cpp:218] Iteration 2862500 (16.7349 iter/s, 29.8778s/500 iters), loss = 0.0832339
I0831 09:09:28.246199 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0832392 (* 1 = 0.0832392 loss)
I0831 09:09:28.246208 916722 sgd_solver.cpp:106] Iteration 2862500, lr = 0.01
I0831 09:09:58.126670 916722 solver.cpp:218] Iteration 2863000 (16.7333 iter/s, 29.8805s/500 iters), loss = 0.0757284
I0831 09:09:58.126726 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0757336 (* 1 = 0.0757336 loss)
I0831 09:09:58.126736 916722 sgd_solver.cpp:106] Iteration 2863000, lr = 0.01
I0831 09:10:27.998975 916722 solver.cpp:218] Iteration 2863500 (16.7379 iter/s, 29.8723s/500 iters), loss = 0.0368545
I0831 09:10:27.999037 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0368596 (* 1 = 0.0368596 loss)
I0831 09:10:27.999045 916722 sgd_solver.cpp:106] Iteration 2863500, lr = 0.01
I0831 09:10:57.873992 916722 solver.cpp:218] Iteration 2864000 (16.7364 iter/s, 29.875s/500 iters), loss = 0.188632
I0831 09:10:57.874043 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.188637 (* 1 = 0.188637 loss)
I0831 09:10:57.874053 916722 sgd_solver.cpp:106] Iteration 2864000, lr = 0.01
I0831 09:11:27.747763 916722 solver.cpp:218] Iteration 2864500 (16.7371 iter/s, 29.8738s/500 iters), loss = 0.154852
I0831 09:11:27.747820 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.154858 (* 1 = 0.154858 loss)
I0831 09:11:27.747829 916722 sgd_solver.cpp:106] Iteration 2864500, lr = 0.01
I0831 09:11:57.616921 916722 solver.cpp:218] Iteration 2865000 (16.7397 iter/s, 29.8691s/500 iters), loss = 0.0835995
I0831 09:11:57.616969 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0836047 (* 1 = 0.0836047 loss)
I0831 09:11:57.616979 916722 sgd_solver.cpp:106] Iteration 2865000, lr = 0.01
I0831 09:12:27.480677 916722 solver.cpp:218] Iteration 2865500 (16.7427 iter/s, 29.8637s/500 iters), loss = 0.122911
I0831 09:12:27.480736 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.122916 (* 1 = 0.122916 loss)
I0831 09:12:27.480744 916722 sgd_solver.cpp:106] Iteration 2865500, lr = 0.01
I0831 09:12:57.358129 916722 solver.cpp:218] Iteration 2866000 (16.735 iter/s, 29.8774s/500 iters), loss = 0.178747
I0831 09:12:57.358181 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.178752 (* 1 = 0.178752 loss)
I0831 09:12:57.358191 916722 sgd_solver.cpp:106] Iteration 2866000, lr = 0.01
I0831 09:13:27.235801 916722 solver.cpp:218] Iteration 2866500 (16.7349 iter/s, 29.8777s/500 iters), loss = 0.160408
I0831 09:13:27.235873 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.160413 (* 1 = 0.160413 loss)
I0831 09:13:27.235886 916722 sgd_solver.cpp:106] Iteration 2866500, lr = 0.01
I0831 09:13:57.111244 916722 solver.cpp:218] Iteration 2867000 (16.7362 iter/s, 29.8754s/500 iters), loss = 0.199673
I0831 09:13:57.111294 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.199678 (* 1 = 0.199678 loss)
I0831 09:13:57.111304 916722 sgd_solver.cpp:106] Iteration 2867000, lr = 0.01
I0831 09:14:26.996662 916722 solver.cpp:218] Iteration 2867500 (16.7306 iter/s, 29.8854s/500 iters), loss = 0.141079
I0831 09:14:26.996721 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.141084 (* 1 = 0.141084 loss)
I0831 09:14:26.996729 916722 sgd_solver.cpp:106] Iteration 2867500, lr = 0.01
I0831 09:14:56.876803 916722 solver.cpp:218] Iteration 2868000 (16.7335 iter/s, 29.8801s/500 iters), loss = 0.175938
I0831 09:14:56.876855 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.175943 (* 1 = 0.175943 loss)
I0831 09:14:56.876864 916722 sgd_solver.cpp:106] Iteration 2868000, lr = 0.01
I0831 09:15:26.761932 916722 solver.cpp:218] Iteration 2868500 (16.7307 iter/s, 29.8851s/500 iters), loss = 0.104458
I0831 09:15:26.761996 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104463 (* 1 = 0.104463 loss)
I0831 09:15:26.762003 916722 sgd_solver.cpp:106] Iteration 2868500, lr = 0.01
I0831 09:15:56.652701 916722 solver.cpp:218] Iteration 2869000 (16.7276 iter/s, 29.8907s/500 iters), loss = 0.0617727
I0831 09:15:56.652755 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.061778 (* 1 = 0.061778 loss)
I0831 09:15:56.652765 916722 sgd_solver.cpp:106] Iteration 2869000, lr = 0.01
I0831 09:16:26.525619 916722 solver.cpp:218] Iteration 2869500 (16.7376 iter/s, 29.8729s/500 iters), loss = 0.10247
I0831 09:16:26.525682 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.102475 (* 1 = 0.102475 loss)
I0831 09:16:26.525691 916722 sgd_solver.cpp:106] Iteration 2869500, lr = 0.01
I0831 09:16:56.414480 916722 solver.cpp:218] Iteration 2870000 (16.7287 iter/s, 29.8888s/500 iters), loss = 0.121388
I0831 09:16:56.414531 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.121393 (* 1 = 0.121393 loss)
I0831 09:16:56.414541 916722 sgd_solver.cpp:106] Iteration 2870000, lr = 0.01
I0831 09:17:26.320643 916722 solver.cpp:218] Iteration 2870500 (16.719 iter/s, 29.9061s/500 iters), loss = 0.037014
I0831 09:17:26.320704 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0370192 (* 1 = 0.0370192 loss)
I0831 09:17:26.320713 916722 sgd_solver.cpp:106] Iteration 2870500, lr = 0.01
I0831 09:17:56.192500 916722 solver.cpp:218] Iteration 2871000 (16.7382 iter/s, 29.8718s/500 iters), loss = 0.0913452
I0831 09:17:56.192553 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0913505 (* 1 = 0.0913505 loss)
I0831 09:17:56.192561 916722 sgd_solver.cpp:106] Iteration 2871000, lr = 0.01
I0831 09:18:26.078547 916722 solver.cpp:218] Iteration 2871500 (16.7302 iter/s, 29.886s/500 iters), loss = 0.203515
I0831 09:18:26.078603 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.20352 (* 1 = 0.20352 loss)
I0831 09:18:26.078613 916722 sgd_solver.cpp:106] Iteration 2871500, lr = 0.01
I0831 09:18:55.965656 916722 solver.cpp:218] Iteration 2872000 (16.7296 iter/s, 29.8871s/500 iters), loss = 0.0978051
I0831 09:18:55.965709 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0978105 (* 1 = 0.0978105 loss)
I0831 09:18:55.965718 916722 sgd_solver.cpp:106] Iteration 2872000, lr = 0.01
I0831 09:19:25.861114 916722 solver.cpp:218] Iteration 2872500 (16.725 iter/s, 29.8954s/500 iters), loss = 0.114116
I0831 09:19:25.861177 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.114121 (* 1 = 0.114121 loss)
I0831 09:19:25.861186 916722 sgd_solver.cpp:106] Iteration 2872500, lr = 0.01
I0831 09:19:55.770354 916722 solver.cpp:218] Iteration 2873000 (16.7173 iter/s, 29.9092s/500 iters), loss = 0.170715
I0831 09:19:55.770406 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.17072 (* 1 = 0.17072 loss)
I0831 09:19:55.770416 916722 sgd_solver.cpp:106] Iteration 2873000, lr = 0.01
I0831 09:20:25.687445 916722 solver.cpp:218] Iteration 2873500 (16.7129 iter/s, 29.9171s/500 iters), loss = 0.0791712
I0831 09:20:25.687520 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0791765 (* 1 = 0.0791765 loss)
I0831 09:20:25.687530 916722 sgd_solver.cpp:106] Iteration 2873500, lr = 0.01
I0831 09:20:55.615351 916722 solver.cpp:218] Iteration 2874000 (16.7068 iter/s, 29.9279s/500 iters), loss = 0.0457375
I0831 09:20:55.615406 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0457429 (* 1 = 0.0457429 loss)
I0831 09:20:55.615417 916722 sgd_solver.cpp:106] Iteration 2874000, lr = 0.01
I0831 09:21:25.537784 916722 solver.cpp:218] Iteration 2874500 (16.7099 iter/s, 29.9224s/500 iters), loss = 0.100506
I0831 09:21:25.537844 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.100511 (* 1 = 0.100511 loss)
I0831 09:21:25.537853 916722 sgd_solver.cpp:106] Iteration 2874500, lr = 0.01
I0831 09:21:55.490873 916722 solver.cpp:218] Iteration 2875000 (16.6928 iter/s, 29.9531s/500 iters), loss = 0.248668
I0831 09:21:55.490924 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.248673 (* 1 = 0.248673 loss)
I0831 09:21:55.490934 916722 sgd_solver.cpp:106] Iteration 2875000, lr = 0.01
I0831 09:22:25.425312 916722 solver.cpp:218] Iteration 2875500 (16.7032 iter/s, 29.9344s/500 iters), loss = 0.115424
I0831 09:22:25.425371 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115429 (* 1 = 0.115429 loss)
I0831 09:22:25.425379 916722 sgd_solver.cpp:106] Iteration 2875500, lr = 0.01
I0831 09:22:55.366917 916722 solver.cpp:218] Iteration 2876000 (16.6992 iter/s, 29.9416s/500 iters), loss = 0.499743
I0831 09:22:55.366968 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.499748 (* 1 = 0.499748 loss)
I0831 09:22:55.366978 916722 sgd_solver.cpp:106] Iteration 2876000, lr = 0.01
I0831 09:23:25.318717 916722 solver.cpp:218] Iteration 2876500 (16.6935 iter/s, 29.9518s/500 iters), loss = 0.0762629
I0831 09:23:25.318775 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.076268 (* 1 = 0.076268 loss)
I0831 09:23:25.318783 916722 sgd_solver.cpp:106] Iteration 2876500, lr = 0.01
I0831 09:23:55.246975 916722 solver.cpp:218] Iteration 2877000 (16.7066 iter/s, 29.9282s/500 iters), loss = 0.203554
I0831 09:23:55.247028 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.203559 (* 1 = 0.203559 loss)
I0831 09:23:55.247038 916722 sgd_solver.cpp:106] Iteration 2877000, lr = 0.01
I0831 09:24:25.204339 916722 solver.cpp:218] Iteration 2877500 (16.6904 iter/s, 29.9573s/500 iters), loss = 0.127322
I0831 09:24:25.204402 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.127327 (* 1 = 0.127327 loss)
I0831 09:24:25.204411 916722 sgd_solver.cpp:106] Iteration 2877500, lr = 0.01
I0831 09:24:55.154528 916722 solver.cpp:218] Iteration 2878000 (16.6944 iter/s, 29.9502s/500 iters), loss = 0.048808
I0831 09:24:55.154582 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0488131 (* 1 = 0.0488131 loss)
I0831 09:24:55.154592 916722 sgd_solver.cpp:106] Iteration 2878000, lr = 0.01
I0831 09:25:25.097535 916722 solver.cpp:218] Iteration 2878500 (16.6984 iter/s, 29.943s/500 iters), loss = 0.326319
I0831 09:25:25.097599 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.326324 (* 1 = 0.326324 loss)
I0831 09:25:25.097607 916722 sgd_solver.cpp:106] Iteration 2878500, lr = 0.01
I0831 09:25:55.042573 916722 solver.cpp:218] Iteration 2879000 (16.6973 iter/s, 29.945s/500 iters), loss = 0.11511
I0831 09:25:55.042627 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115115 (* 1 = 0.115115 loss)
I0831 09:25:55.042636 916722 sgd_solver.cpp:106] Iteration 2879000, lr = 0.01
I0831 09:26:24.983953 916722 solver.cpp:218] Iteration 2879500 (16.6993 iter/s, 29.9414s/500 iters), loss = 0.177642
I0831 09:26:24.984015 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.177647 (* 1 = 0.177647 loss)
I0831 09:26:24.984025 916722 sgd_solver.cpp:106] Iteration 2879500, lr = 0.01
I0831 09:26:54.927665 916722 solver.cpp:218] Iteration 2880000 (16.698 iter/s, 29.9437s/500 iters), loss = 0.186699
I0831 09:26:54.927716 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.186704 (* 1 = 0.186704 loss)
I0831 09:26:54.927723 916722 sgd_solver.cpp:106] Iteration 2880000, lr = 0.01
I0831 09:27:24.867058 916722 solver.cpp:218] Iteration 2880500 (16.7004 iter/s, 29.9394s/500 iters), loss = 0.115755
I0831 09:27:24.867125 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.11576 (* 1 = 0.11576 loss)
I0831 09:27:24.867133 916722 sgd_solver.cpp:106] Iteration 2880500, lr = 0.01
I0831 09:27:54.828245 916722 solver.cpp:218] Iteration 2881000 (16.6883 iter/s, 29.9612s/500 iters), loss = 0.290365
I0831 09:27:54.828297 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.29037 (* 1 = 0.29037 loss)
I0831 09:27:54.828305 916722 sgd_solver.cpp:106] Iteration 2881000, lr = 0.01
I0831 09:28:24.786504 916722 solver.cpp:218] Iteration 2881500 (16.6899 iter/s, 29.9582s/500 iters), loss = 0.116509
I0831 09:28:24.786572 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.116514 (* 1 = 0.116514 loss)
I0831 09:28:24.786581 916722 sgd_solver.cpp:106] Iteration 2881500, lr = 0.01
I0831 09:28:54.734859 916722 solver.cpp:218] Iteration 2882000 (16.6954 iter/s, 29.9483s/500 iters), loss = 0.0639986
I0831 09:28:54.734911 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0640035 (* 1 = 0.0640035 loss)
I0831 09:28:54.734920 916722 sgd_solver.cpp:106] Iteration 2882000, lr = 0.01
I0831 09:29:24.686640 916722 solver.cpp:218] Iteration 2882500 (16.6937 iter/s, 29.9514s/500 iters), loss = 0.251452
I0831 09:29:24.686702 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.251457 (* 1 = 0.251457 loss)
I0831 09:29:24.686710 916722 sgd_solver.cpp:106] Iteration 2882500, lr = 0.01
I0831 09:29:54.640733 916722 solver.cpp:218] Iteration 2883000 (16.6926 iter/s, 29.9534s/500 iters), loss = 0.405257
I0831 09:29:54.640789 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.405262 (* 1 = 0.405262 loss)
I0831 09:29:54.640798 916722 sgd_solver.cpp:106] Iteration 2883000, lr = 0.01
I0831 09:30:24.617044 916722 solver.cpp:218] Iteration 2883500 (16.6802 iter/s, 29.9757s/500 iters), loss = 0.135939
I0831 09:30:24.617105 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.135944 (* 1 = 0.135944 loss)
I0831 09:30:24.617113 916722 sgd_solver.cpp:106] Iteration 2883500, lr = 0.01
I0831 09:30:54.559898 916722 solver.cpp:218] Iteration 2884000 (16.6988 iter/s, 29.9422s/500 iters), loss = 0.117535
I0831 09:30:54.559949 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.11754 (* 1 = 0.11754 loss)
I0831 09:30:54.559958 916722 sgd_solver.cpp:106] Iteration 2884000, lr = 0.01
I0831 09:31:24.512446 916722 solver.cpp:218] Iteration 2884500 (16.6934 iter/s, 29.952s/500 iters), loss = 0.287332
I0831 09:31:24.512506 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.287337 (* 1 = 0.287337 loss)
I0831 09:31:24.512516 916722 sgd_solver.cpp:106] Iteration 2884500, lr = 0.01
I0831 09:31:54.475955 916722 solver.cpp:218] Iteration 2885000 (16.6873 iter/s, 29.963s/500 iters), loss = 0.170519
I0831 09:31:54.476004 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.170524 (* 1 = 0.170524 loss)
I0831 09:31:54.476013 916722 sgd_solver.cpp:106] Iteration 2885000, lr = 0.01
I0831 09:32:24.435312 916722 solver.cpp:218] Iteration 2885500 (16.6896 iter/s, 29.9588s/500 iters), loss = 0.168666
I0831 09:32:24.435369 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.168672 (* 1 = 0.168672 loss)
I0831 09:32:24.435377 916722 sgd_solver.cpp:106] Iteration 2885500, lr = 0.01
I0831 09:32:54.395452 916722 solver.cpp:218] Iteration 2886000 (16.6891 iter/s, 29.9596s/500 iters), loss = 0.0544318
I0831 09:32:54.395503 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0544373 (* 1 = 0.0544373 loss)
I0831 09:32:54.395511 916722 sgd_solver.cpp:106] Iteration 2886000, lr = 0.01
I0831 09:33:24.358597 916722 solver.cpp:218] Iteration 2886500 (16.6874 iter/s, 29.9627s/500 iters), loss = 0.241671
I0831 09:33:24.358678 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.241677 (* 1 = 0.241677 loss)
I0831 09:33:24.358687 916722 sgd_solver.cpp:106] Iteration 2886500, lr = 0.01
I0831 09:33:54.322492 916722 solver.cpp:218] Iteration 2887000 (16.687 iter/s, 29.9634s/500 iters), loss = 0.0555017
I0831 09:33:54.322543 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0555072 (* 1 = 0.0555072 loss)
I0831 09:33:54.322551 916722 sgd_solver.cpp:106] Iteration 2887000, lr = 0.01
I0831 09:34:24.290503 916722 solver.cpp:218] Iteration 2887500 (16.6847 iter/s, 29.9676s/500 iters), loss = 0.105457
I0831 09:34:24.290565 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105463 (* 1 = 0.105463 loss)
I0831 09:34:24.290572 916722 sgd_solver.cpp:106] Iteration 2887500, lr = 0.01
I0831 09:34:54.257079 916722 solver.cpp:218] Iteration 2888000 (16.6855 iter/s, 29.9662s/500 iters), loss = 0.245261
I0831 09:34:54.257133 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.245266 (* 1 = 0.245266 loss)
I0831 09:34:54.257143 916722 sgd_solver.cpp:106] Iteration 2888000, lr = 0.01
I0831 09:35:24.222259 916722 solver.cpp:218] Iteration 2888500 (16.6863 iter/s, 29.9648s/500 iters), loss = 0.195435
I0831 09:35:24.222317 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.195441 (* 1 = 0.195441 loss)
I0831 09:35:24.222326 916722 sgd_solver.cpp:106] Iteration 2888500, lr = 0.01
I0831 09:35:54.191190 916722 solver.cpp:218] Iteration 2889000 (16.6842 iter/s, 29.9686s/500 iters), loss = 0.10384
I0831 09:35:54.191242 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.103845 (* 1 = 0.103845 loss)
I0831 09:35:54.191252 916722 sgd_solver.cpp:106] Iteration 2889000, lr = 0.01
I0831 09:36:24.161938 916722 solver.cpp:218] Iteration 2889500 (16.6831 iter/s, 29.9704s/500 iters), loss = 0.127249
I0831 09:36:24.161995 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.127255 (* 1 = 0.127255 loss)
I0831 09:36:24.162003 916722 sgd_solver.cpp:106] Iteration 2889500, lr = 0.01
I0831 09:36:54.136795 916722 solver.cpp:218] Iteration 2890000 (16.6808 iter/s, 29.9745s/500 iters), loss = 0.202397
I0831 09:36:54.136843 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.202402 (* 1 = 0.202402 loss)
I0831 09:36:54.136852 916722 sgd_solver.cpp:106] Iteration 2890000, lr = 0.01
I0831 09:37:24.109912 916722 solver.cpp:218] Iteration 2890500 (16.6818 iter/s, 29.9728s/500 iters), loss = 0.226874
I0831 09:37:24.109972 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.22688 (* 1 = 0.22688 loss)
I0831 09:37:24.109982 916722 sgd_solver.cpp:106] Iteration 2890500, lr = 0.01
I0831 09:37:54.070013 916722 solver.cpp:218] Iteration 2891000 (16.689 iter/s, 29.9598s/500 iters), loss = 0.156288
I0831 09:37:54.070065 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.156294 (* 1 = 0.156294 loss)
I0831 09:37:54.070075 916722 sgd_solver.cpp:106] Iteration 2891000, lr = 0.01
I0831 09:38:24.035271 916722 solver.cpp:218] Iteration 2891500 (16.6862 iter/s, 29.965s/500 iters), loss = 0.152653
I0831 09:38:24.035332 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152659 (* 1 = 0.152659 loss)
I0831 09:38:24.035341 916722 sgd_solver.cpp:106] Iteration 2891500, lr = 0.01
I0831 09:38:54.004199 916722 solver.cpp:218] Iteration 2892000 (16.6841 iter/s, 29.9686s/500 iters), loss = 0.193076
I0831 09:38:54.004251 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.193082 (* 1 = 0.193082 loss)
I0831 09:38:54.004261 916722 sgd_solver.cpp:106] Iteration 2892000, lr = 0.01
I0831 09:39:23.968215 916722 solver.cpp:218] Iteration 2892500 (16.6868 iter/s, 29.9637s/500 iters), loss = 0.129592
I0831 09:39:23.968276 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.129598 (* 1 = 0.129598 loss)
I0831 09:39:23.968284 916722 sgd_solver.cpp:106] Iteration 2892500, lr = 0.01
I0831 09:39:53.945197 916722 solver.cpp:218] Iteration 2893000 (16.6796 iter/s, 29.9767s/500 iters), loss = 0.0915011
I0831 09:39:53.945262 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0915071 (* 1 = 0.0915071 loss)
I0831 09:39:53.945272 916722 sgd_solver.cpp:106] Iteration 2893000, lr = 0.01
I0831 09:40:23.924660 916722 solver.cpp:218] Iteration 2893500 (16.6782 iter/s, 29.9792s/500 iters), loss = 0.159713
I0831 09:40:23.924738 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159719 (* 1 = 0.159719 loss)
I0831 09:40:23.924757 916722 sgd_solver.cpp:106] Iteration 2893500, lr = 0.01
I0831 09:40:53.902398 916722 solver.cpp:218] Iteration 2894000 (16.6792 iter/s, 29.9775s/500 iters), loss = 0.012904
I0831 09:40:53.902448 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0129101 (* 1 = 0.0129101 loss)
I0831 09:40:53.902457 916722 sgd_solver.cpp:106] Iteration 2894000, lr = 0.01
I0831 09:41:23.902266 916722 solver.cpp:218] Iteration 2894500 (16.6669 iter/s, 29.9996s/500 iters), loss = 0.04309
I0831 09:41:23.902323 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0430961 (* 1 = 0.0430961 loss)
I0831 09:41:23.902331 916722 sgd_solver.cpp:106] Iteration 2894500, lr = 0.01
I0831 09:41:53.893834 916722 solver.cpp:218] Iteration 2895000 (16.6715 iter/s, 29.9913s/500 iters), loss = 0.267792
I0831 09:41:53.893885 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.267798 (* 1 = 0.267798 loss)
I0831 09:41:53.893893 916722 sgd_solver.cpp:106] Iteration 2895000, lr = 0.01
I0831 09:42:23.871891 916722 solver.cpp:218] Iteration 2895500 (16.679 iter/s, 29.9778s/500 iters), loss = 0.0216306
I0831 09:42:23.871953 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0216369 (* 1 = 0.0216369 loss)
I0831 09:42:23.871963 916722 sgd_solver.cpp:106] Iteration 2895500, lr = 0.01
I0831 09:42:53.863951 916722 solver.cpp:218] Iteration 2896000 (16.6712 iter/s, 29.9918s/500 iters), loss = 0.0221714
I0831 09:42:53.864001 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0221779 (* 1 = 0.0221779 loss)
I0831 09:42:53.864009 916722 sgd_solver.cpp:106] Iteration 2896000, lr = 0.01
I0831 09:43:23.870875 916722 solver.cpp:218] Iteration 2896500 (16.6629 iter/s, 30.0067s/500 iters), loss = 0.105521
I0831 09:43:23.870937 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105528 (* 1 = 0.105528 loss)
I0831 09:43:23.870945 916722 sgd_solver.cpp:106] Iteration 2896500, lr = 0.01
I0831 09:43:53.868441 916722 solver.cpp:218] Iteration 2897000 (16.6681 iter/s, 29.9973s/500 iters), loss = 0.0704923
I0831 09:43:53.868492 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.070499 (* 1 = 0.070499 loss)
I0831 09:43:53.868500 916722 sgd_solver.cpp:106] Iteration 2897000, lr = 0.01
I0831 09:44:23.854805 916722 solver.cpp:218] Iteration 2897500 (16.6744 iter/s, 29.9862s/500 iters), loss = 0.330678
I0831 09:44:23.854864 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.330684 (* 1 = 0.330684 loss)
I0831 09:44:23.854873 916722 sgd_solver.cpp:106] Iteration 2897500, lr = 0.01
I0831 09:44:53.846243 916722 solver.cpp:218] Iteration 2898000 (16.6715 iter/s, 29.9912s/500 iters), loss = 0.32529
I0831 09:44:53.846294 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.325296 (* 1 = 0.325296 loss)
I0831 09:44:53.846303 916722 sgd_solver.cpp:106] Iteration 2898000, lr = 0.01
I0831 09:45:23.839745 916722 solver.cpp:218] Iteration 2898500 (16.6704 iter/s, 29.9933s/500 iters), loss = 0.0121364
I0831 09:45:23.839807 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.012143 (* 1 = 0.012143 loss)
I0831 09:45:23.839814 916722 sgd_solver.cpp:106] Iteration 2898500, lr = 0.01
I0831 09:45:53.840939 916722 solver.cpp:218] Iteration 2899000 (16.6661 iter/s, 30.001s/500 iters), loss = 0.315548
I0831 09:45:53.840997 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.315555 (* 1 = 0.315555 loss)
I0831 09:45:53.841006 916722 sgd_solver.cpp:106] Iteration 2899000, lr = 0.01
I0831 09:46:23.830334 916722 solver.cpp:218] Iteration 2899500 (16.6727 iter/s, 29.9892s/500 iters), loss = 0.0483501
I0831 09:46:23.830389 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0483566 (* 1 = 0.0483566 loss)
I0831 09:46:23.830411 916722 sgd_solver.cpp:106] Iteration 2899500, lr = 0.01
I0831 09:46:53.766736 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_2900000.caffemodel
I0831 09:46:53.785976 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_2900000.solverstate
I0831 09:46:53.792062 916722 solver.cpp:330] Iteration 2900000, Testing net (#0)
I0831 09:47:09.256151 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8956
I0831 09:47:09.256196 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.350133 (* 1 = 0.350133 loss)
I0831 09:47:09.314914 916722 solver.cpp:218] Iteration 2900000 (10.9928 iter/s, 45.4843s/500 iters), loss = 0.047412
I0831 09:47:09.314942 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0474186 (* 1 = 0.0474186 loss)
I0831 09:47:09.314950 916722 sgd_solver.cpp:106] Iteration 2900000, lr = 0.01
I0831 09:47:39.117472 916722 solver.cpp:218] Iteration 2900500 (16.7772 iter/s, 29.8024s/500 iters), loss = 0.0901952
I0831 09:47:39.117539 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0902018 (* 1 = 0.0902018 loss)
I0831 09:47:39.117548 916722 sgd_solver.cpp:106] Iteration 2900500, lr = 0.01
I0831 09:48:09.097429 916722 solver.cpp:218] Iteration 2901000 (16.6779 iter/s, 29.9798s/500 iters), loss = 0.0218409
I0831 09:48:09.097482 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0218476 (* 1 = 0.0218476 loss)
I0831 09:48:09.097492 916722 sgd_solver.cpp:106] Iteration 2901000, lr = 0.01
I0831 09:48:39.108378 916722 solver.cpp:218] Iteration 2901500 (16.6607 iter/s, 30.0108s/500 iters), loss = 0.296516
I0831 09:48:39.108462 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.296522 (* 1 = 0.296522 loss)
I0831 09:48:39.108472 916722 sgd_solver.cpp:106] Iteration 2901500, lr = 0.01
I0831 09:49:09.133031 916722 solver.cpp:218] Iteration 2902000 (16.6531 iter/s, 30.0245s/500 iters), loss = 0.193986
I0831 09:49:09.133091 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.193992 (* 1 = 0.193992 loss)
I0831 09:49:09.133100 916722 sgd_solver.cpp:106] Iteration 2902000, lr = 0.01
I0831 09:49:39.130900 916722 solver.cpp:218] Iteration 2902500 (16.6679 iter/s, 29.9977s/500 iters), loss = 0.112291
I0831 09:49:39.130954 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112297 (* 1 = 0.112297 loss)
I0831 09:49:39.130964 916722 sgd_solver.cpp:106] Iteration 2902500, lr = 0.01
I0831 09:50:09.130976 916722 solver.cpp:218] Iteration 2903000 (16.6667 iter/s, 29.9999s/500 iters), loss = 0.239497
I0831 09:50:09.131036 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.239504 (* 1 = 0.239504 loss)
I0831 09:50:09.131044 916722 sgd_solver.cpp:106] Iteration 2903000, lr = 0.01
I0831 09:50:39.134770 916722 solver.cpp:218] Iteration 2903500 (16.6646 iter/s, 30.0037s/500 iters), loss = 0.11842
I0831 09:50:39.134829 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.118426 (* 1 = 0.118426 loss)
I0831 09:50:39.134837 916722 sgd_solver.cpp:106] Iteration 2903500, lr = 0.01
I0831 09:51:09.137244 916722 solver.cpp:218] Iteration 2904000 (16.6654 iter/s, 30.0023s/500 iters), loss = 0.0621015
I0831 09:51:09.137305 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.062108 (* 1 = 0.062108 loss)
I0831 09:51:09.137315 916722 sgd_solver.cpp:106] Iteration 2904000, lr = 0.01
I0831 09:51:39.138813 916722 solver.cpp:218] Iteration 2904500 (16.6659 iter/s, 30.0014s/500 iters), loss = 0.254503
I0831 09:51:39.138868 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.254509 (* 1 = 0.254509 loss)
I0831 09:51:39.138877 916722 sgd_solver.cpp:106] Iteration 2904500, lr = 0.01
I0831 09:52:09.136031 916722 solver.cpp:218] Iteration 2905000 (16.6683 iter/s, 29.9971s/500 iters), loss = 0.0759319
I0831 09:52:09.136086 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0759384 (* 1 = 0.0759384 loss)
I0831 09:52:09.136109 916722 sgd_solver.cpp:106] Iteration 2905000, lr = 0.01
I0831 09:52:39.137023 916722 solver.cpp:218] Iteration 2905500 (16.6662 iter/s, 30.0009s/500 iters), loss = 0.198499
I0831 09:52:39.137092 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.198505 (* 1 = 0.198505 loss)
I0831 09:52:39.137100 916722 sgd_solver.cpp:106] Iteration 2905500, lr = 0.01
I0831 09:53:09.132663 916722 solver.cpp:218] Iteration 2906000 (16.6692 iter/s, 29.9955s/500 iters), loss = 0.254758
I0831 09:53:09.132717 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.254764 (* 1 = 0.254764 loss)
I0831 09:53:09.132728 916722 sgd_solver.cpp:106] Iteration 2906000, lr = 0.01
I0831 09:53:39.148087 916722 solver.cpp:218] Iteration 2906500 (16.6582 iter/s, 30.0153s/500 iters), loss = 0.331077
I0831 09:53:39.148147 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.331083 (* 1 = 0.331083 loss)
I0831 09:53:39.148156 916722 sgd_solver.cpp:106] Iteration 2906500, lr = 0.01
I0831 09:54:09.162571 916722 solver.cpp:218] Iteration 2907000 (16.6587 iter/s, 30.0144s/500 iters), loss = 0.0996365
I0831 09:54:09.162632 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0996431 (* 1 = 0.0996431 loss)
I0831 09:54:09.162640 916722 sgd_solver.cpp:106] Iteration 2907000, lr = 0.01
I0831 09:54:39.161625 916722 solver.cpp:218] Iteration 2907500 (16.6673 iter/s, 29.9989s/500 iters), loss = 0.0721793
I0831 09:54:39.161676 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.072186 (* 1 = 0.072186 loss)
I0831 09:54:39.161686 916722 sgd_solver.cpp:106] Iteration 2907500, lr = 0.01
I0831 09:55:09.166821 916722 solver.cpp:218] Iteration 2908000 (16.6638 iter/s, 30.0051s/500 iters), loss = 0.721484
I0831 09:55:09.166880 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.721491 (* 1 = 0.721491 loss)
I0831 09:55:09.166889 916722 sgd_solver.cpp:106] Iteration 2908000, lr = 0.01
I0831 09:55:39.180105 916722 solver.cpp:218] Iteration 2908500 (16.6594 iter/s, 30.0132s/500 iters), loss = 0.0848484
I0831 09:55:39.180162 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0848551 (* 1 = 0.0848551 loss)
I0831 09:55:39.180171 916722 sgd_solver.cpp:106] Iteration 2908500, lr = 0.01
I0831 09:56:09.197427 916722 solver.cpp:218] Iteration 2909000 (16.6571 iter/s, 30.0172s/500 iters), loss = 0.0334707
I0831 09:56:09.197486 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0334774 (* 1 = 0.0334774 loss)
I0831 09:56:09.197494 916722 sgd_solver.cpp:106] Iteration 2909000, lr = 0.01
I0831 09:56:39.209936 916722 solver.cpp:218] Iteration 2909500 (16.6598 iter/s, 30.0124s/500 iters), loss = 0.0318988
I0831 09:56:39.209998 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0319058 (* 1 = 0.0319058 loss)
I0831 09:56:39.210007 916722 sgd_solver.cpp:106] Iteration 2909500, lr = 0.01
I0831 09:57:09.225327 916722 solver.cpp:218] Iteration 2910000 (16.6582 iter/s, 30.0153s/500 iters), loss = 0.0866031
I0831 09:57:09.225385 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0866101 (* 1 = 0.0866101 loss)
I0831 09:57:09.225394 916722 sgd_solver.cpp:106] Iteration 2910000, lr = 0.01
I0831 09:57:39.229465 916722 solver.cpp:218] Iteration 2910500 (16.6644 iter/s, 30.004s/500 iters), loss = 0.182526
I0831 09:57:39.229522 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.182533 (* 1 = 0.182533 loss)
I0831 09:57:39.229530 916722 sgd_solver.cpp:106] Iteration 2910500, lr = 0.01
I0831 09:58:09.238816 916722 solver.cpp:218] Iteration 2911000 (16.6615 iter/s, 30.0092s/500 iters), loss = 0.0536662
I0831 09:58:09.238873 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0536733 (* 1 = 0.0536733 loss)
I0831 09:58:09.238883 916722 sgd_solver.cpp:106] Iteration 2911000, lr = 0.01
I0831 09:58:39.254488 916722 solver.cpp:218] Iteration 2911500 (16.658 iter/s, 30.0156s/500 iters), loss = 0.179017
I0831 09:58:39.254552 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.179025 (* 1 = 0.179025 loss)
I0831 09:58:39.254561 916722 sgd_solver.cpp:106] Iteration 2911500, lr = 0.01
I0831 09:59:09.268532 916722 solver.cpp:218] Iteration 2912000 (16.6589 iter/s, 30.0139s/500 iters), loss = 0.0845677
I0831 09:59:09.268602 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0845748 (* 1 = 0.0845748 loss)
I0831 09:59:09.268611 916722 sgd_solver.cpp:106] Iteration 2912000, lr = 0.01
I0831 09:59:39.276510 916722 solver.cpp:218] Iteration 2912500 (16.6623 iter/s, 30.0079s/500 iters), loss = 0.246269
I0831 09:59:39.276572 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.246275 (* 1 = 0.246275 loss)
I0831 09:59:39.276582 916722 sgd_solver.cpp:106] Iteration 2912500, lr = 0.01
I0831 10:00:09.315399 916722 solver.cpp:218] Iteration 2913000 (16.6452 iter/s, 30.0388s/500 iters), loss = 0.0400648
I0831 10:00:09.315459 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0400717 (* 1 = 0.0400717 loss)
I0831 10:00:09.315469 916722 sgd_solver.cpp:106] Iteration 2913000, lr = 0.01
I0831 10:00:39.361146 916722 solver.cpp:218] Iteration 2913500 (16.6413 iter/s, 30.0456s/500 iters), loss = 0.0680705
I0831 10:00:39.361208 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0680775 (* 1 = 0.0680775 loss)
I0831 10:00:39.361217 916722 sgd_solver.cpp:106] Iteration 2913500, lr = 0.01
I0831 10:01:09.381585 916722 solver.cpp:218] Iteration 2914000 (16.6554 iter/s, 30.0203s/500 iters), loss = 0.0804093
I0831 10:01:09.381644 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0804163 (* 1 = 0.0804163 loss)
I0831 10:01:09.381654 916722 sgd_solver.cpp:106] Iteration 2914000, lr = 0.01
I0831 10:01:39.410048 916722 solver.cpp:218] Iteration 2914500 (16.6509 iter/s, 30.0284s/500 iters), loss = 0.0895188
I0831 10:01:39.410105 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0895257 (* 1 = 0.0895257 loss)
I0831 10:01:39.410113 916722 sgd_solver.cpp:106] Iteration 2914500, lr = 0.01
I0831 10:02:09.441504 916722 solver.cpp:218] Iteration 2915000 (16.6493 iter/s, 30.0313s/500 iters), loss = 0.139801
I0831 10:02:09.441561 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139807 (* 1 = 0.139807 loss)
I0831 10:02:09.441570 916722 sgd_solver.cpp:106] Iteration 2915000, lr = 0.01
I0831 10:02:39.457770 916722 solver.cpp:218] Iteration 2915500 (16.6577 iter/s, 30.0162s/500 iters), loss = 0.0768364
I0831 10:02:39.457825 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0768433 (* 1 = 0.0768433 loss)
I0831 10:02:39.457834 916722 sgd_solver.cpp:106] Iteration 2915500, lr = 0.01
I0831 10:03:09.478058 916722 solver.cpp:218] Iteration 2916000 (16.6555 iter/s, 30.0202s/500 iters), loss = 0.215487
I0831 10:03:09.478116 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.215494 (* 1 = 0.215494 loss)
I0831 10:03:09.478124 916722 sgd_solver.cpp:106] Iteration 2916000, lr = 0.01
I0831 10:03:39.505367 916722 solver.cpp:218] Iteration 2916500 (16.6516 iter/s, 30.0272s/500 iters), loss = 0.0806033
I0831 10:03:39.505429 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0806103 (* 1 = 0.0806103 loss)
I0831 10:03:39.505439 916722 sgd_solver.cpp:106] Iteration 2916500, lr = 0.01
I0831 10:04:09.559757 916722 solver.cpp:218] Iteration 2917000 (16.6366 iter/s, 30.0542s/500 iters), loss = 0.224635
I0831 10:04:09.559818 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.224642 (* 1 = 0.224642 loss)
I0831 10:04:09.559828 916722 sgd_solver.cpp:106] Iteration 2917000, lr = 0.01
I0831 10:04:39.596007 916722 solver.cpp:218] Iteration 2917500 (16.6466 iter/s, 30.0361s/500 iters), loss = 0.109076
I0831 10:04:39.596071 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109083 (* 1 = 0.109083 loss)
I0831 10:04:39.596081 916722 sgd_solver.cpp:106] Iteration 2917500, lr = 0.01
I0831 10:05:09.619946 916722 solver.cpp:218] Iteration 2918000 (16.6535 iter/s, 30.0238s/500 iters), loss = 0.235964
I0831 10:05:09.620003 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.235971 (* 1 = 0.235971 loss)
I0831 10:05:09.620012 916722 sgd_solver.cpp:106] Iteration 2918000, lr = 0.01
I0831 10:05:39.656913 916722 solver.cpp:218] Iteration 2918500 (16.6462 iter/s, 30.0368s/500 iters), loss = 0.109986
I0831 10:05:39.656985 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109993 (* 1 = 0.109993 loss)
I0831 10:05:39.656993 916722 sgd_solver.cpp:106] Iteration 2918500, lr = 0.01
I0831 10:06:09.683234 916722 solver.cpp:218] Iteration 2919000 (16.6521 iter/s, 30.0262s/500 iters), loss = 0.128589
I0831 10:06:09.683291 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128596 (* 1 = 0.128596 loss)
I0831 10:06:09.683300 916722 sgd_solver.cpp:106] Iteration 2919000, lr = 0.01
I0831 10:06:39.723953 916722 solver.cpp:218] Iteration 2919500 (16.6442 iter/s, 30.0406s/500 iters), loss = 0.0820807
I0831 10:06:39.724011 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0820876 (* 1 = 0.0820876 loss)
I0831 10:06:39.724020 916722 sgd_solver.cpp:106] Iteration 2919500, lr = 0.01
I0831 10:07:09.782699 916722 solver.cpp:218] Iteration 2920000 (16.6342 iter/s, 30.0586s/500 iters), loss = 0.165357
I0831 10:07:09.782755 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.165364 (* 1 = 0.165364 loss)
I0831 10:07:09.782764 916722 sgd_solver.cpp:106] Iteration 2920000, lr = 0.01
I0831 10:07:39.832088 916722 solver.cpp:218] Iteration 2920500 (16.6394 iter/s, 30.0492s/500 iters), loss = 0.0479567
I0831 10:07:39.832149 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0479637 (* 1 = 0.0479637 loss)
I0831 10:07:39.832157 916722 sgd_solver.cpp:106] Iteration 2920500, lr = 0.01
I0831 10:08:09.870764 916722 solver.cpp:218] Iteration 2921000 (16.6453 iter/s, 30.0385s/500 iters), loss = 0.0275693
I0831 10:08:09.870823 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0275764 (* 1 = 0.0275764 loss)
I0831 10:08:09.870832 916722 sgd_solver.cpp:106] Iteration 2921000, lr = 0.01
I0831 10:08:39.908300 916722 solver.cpp:218] Iteration 2921500 (16.6459 iter/s, 30.0374s/500 iters), loss = 0.16319
I0831 10:08:39.908361 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.163198 (* 1 = 0.163198 loss)
I0831 10:08:39.908370 916722 sgd_solver.cpp:106] Iteration 2921500, lr = 0.01
I0831 10:09:09.963169 916722 solver.cpp:218] Iteration 2922000 (16.6363 iter/s, 30.0547s/500 iters), loss = 0.256294
I0831 10:09:09.963228 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.256301 (* 1 = 0.256301 loss)
I0831 10:09:09.963236 916722 sgd_solver.cpp:106] Iteration 2922000, lr = 0.01
I0831 10:09:40.004539 916722 solver.cpp:218] Iteration 2922500 (16.6438 iter/s, 30.0412s/500 iters), loss = 0.31603
I0831 10:09:40.004601 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.316037 (* 1 = 0.316037 loss)
I0831 10:09:40.004609 916722 sgd_solver.cpp:106] Iteration 2922500, lr = 0.01
I0831 10:10:10.044903 916722 solver.cpp:218] Iteration 2923000 (16.6444 iter/s, 30.0402s/500 iters), loss = 0.111601
I0831 10:10:10.044961 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111608 (* 1 = 0.111608 loss)
I0831 10:10:10.044970 916722 sgd_solver.cpp:106] Iteration 2923000, lr = 0.01
I0831 10:10:40.091287 916722 solver.cpp:218] Iteration 2923500 (16.641 iter/s, 30.0463s/500 iters), loss = 0.135394
I0831 10:10:40.091347 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.135401 (* 1 = 0.135401 loss)
I0831 10:10:40.091356 916722 sgd_solver.cpp:106] Iteration 2923500, lr = 0.01
I0831 10:11:10.135062 916722 solver.cpp:218] Iteration 2924000 (16.6425 iter/s, 30.0436s/500 iters), loss = 0.0436058
I0831 10:11:10.135120 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0436131 (* 1 = 0.0436131 loss)
I0831 10:11:10.135128 916722 sgd_solver.cpp:106] Iteration 2924000, lr = 0.01
I0831 10:11:40.180521 916722 solver.cpp:218] Iteration 2924500 (16.6415 iter/s, 30.0453s/500 iters), loss = 0.0197729
I0831 10:11:40.180583 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0197802 (* 1 = 0.0197802 loss)
I0831 10:11:40.180590 916722 sgd_solver.cpp:106] Iteration 2924500, lr = 0.01
I0831 10:12:10.233880 916722 solver.cpp:218] Iteration 2925000 (16.6372 iter/s, 30.0532s/500 iters), loss = 0.263248
I0831 10:12:10.233958 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.263255 (* 1 = 0.263255 loss)
I0831 10:12:10.233966 916722 sgd_solver.cpp:106] Iteration 2925000, lr = 0.01
I0831 10:12:40.284145 916722 solver.cpp:218] Iteration 2925500 (16.6389 iter/s, 30.0501s/500 iters), loss = 0.0911331
I0831 10:12:40.284209 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0911402 (* 1 = 0.0911402 loss)
I0831 10:12:40.284217 916722 sgd_solver.cpp:106] Iteration 2925500, lr = 0.01
I0831 10:13:10.341987 916722 solver.cpp:218] Iteration 2926000 (16.6347 iter/s, 30.0577s/500 iters), loss = 0.323606
I0831 10:13:10.342046 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.323613 (* 1 = 0.323613 loss)
I0831 10:13:10.342056 916722 sgd_solver.cpp:106] Iteration 2926000, lr = 0.01
I0831 10:13:40.376159 916722 solver.cpp:218] Iteration 2926500 (16.6478 iter/s, 30.034s/500 iters), loss = 0.0336579
I0831 10:13:40.376219 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0336652 (* 1 = 0.0336652 loss)
I0831 10:13:40.376226 916722 sgd_solver.cpp:106] Iteration 2926500, lr = 0.01
I0831 10:14:10.423173 916722 solver.cpp:218] Iteration 2927000 (16.6407 iter/s, 30.0469s/500 iters), loss = 0.0661794
I0831 10:14:10.423231 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0661866 (* 1 = 0.0661866 loss)
I0831 10:14:10.423239 916722 sgd_solver.cpp:106] Iteration 2927000, lr = 0.01
I0831 10:14:40.451236 916722 solver.cpp:218] Iteration 2927500 (16.6512 iter/s, 30.0279s/500 iters), loss = 0.208949
I0831 10:14:40.451289 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.208956 (* 1 = 0.208956 loss)
I0831 10:14:40.451298 916722 sgd_solver.cpp:106] Iteration 2927500, lr = 0.01
I0831 10:15:10.497534 916722 solver.cpp:218] Iteration 2928000 (16.6411 iter/s, 30.0462s/500 iters), loss = 0.394107
I0831 10:15:10.497594 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.394114 (* 1 = 0.394114 loss)
I0831 10:15:10.497602 916722 sgd_solver.cpp:106] Iteration 2928000, lr = 0.01
I0831 10:15:40.543058 916722 solver.cpp:218] Iteration 2928500 (16.6415 iter/s, 30.0454s/500 iters), loss = 0.152363
I0831 10:15:40.543121 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.15237 (* 1 = 0.15237 loss)
I0831 10:15:40.543129 916722 sgd_solver.cpp:106] Iteration 2928500, lr = 0.01
I0831 10:16:10.595381 916722 solver.cpp:218] Iteration 2929000 (16.6377 iter/s, 30.0522s/500 iters), loss = 0.118484
I0831 10:16:10.595438 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.118491 (* 1 = 0.118491 loss)
I0831 10:16:10.595446 916722 sgd_solver.cpp:106] Iteration 2929000, lr = 0.01
I0831 10:16:40.652729 916722 solver.cpp:218] Iteration 2929500 (16.6349 iter/s, 30.0572s/500 iters), loss = 0.0655704
I0831 10:16:40.652793 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0655776 (* 1 = 0.0655776 loss)
I0831 10:16:40.652801 916722 sgd_solver.cpp:106] Iteration 2929500, lr = 0.01
I0831 10:17:10.715070 916722 solver.cpp:218] Iteration 2930000 (16.6322 iter/s, 30.0622s/500 iters), loss = 0.0580901
I0831 10:17:10.715131 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0580973 (* 1 = 0.0580973 loss)
I0831 10:17:10.715138 916722 sgd_solver.cpp:106] Iteration 2930000, lr = 0.01
I0831 10:17:40.764472 916722 solver.cpp:218] Iteration 2930500 (16.6393 iter/s, 30.0493s/500 iters), loss = 0.143303
I0831 10:17:40.764533 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.14331 (* 1 = 0.14331 loss)
I0831 10:17:40.764541 916722 sgd_solver.cpp:106] Iteration 2930500, lr = 0.01
I0831 10:18:10.830451 916722 solver.cpp:218] Iteration 2931000 (16.6302 iter/s, 30.0659s/500 iters), loss = 0.108417
I0831 10:18:10.830514 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.108424 (* 1 = 0.108424 loss)
I0831 10:18:10.830523 916722 sgd_solver.cpp:106] Iteration 2931000, lr = 0.01
I0831 10:18:40.888095 916722 solver.cpp:218] Iteration 2931500 (16.6348 iter/s, 30.0575s/500 iters), loss = 0.193083
I0831 10:18:40.888171 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.19309 (* 1 = 0.19309 loss)
I0831 10:18:40.888185 916722 sgd_solver.cpp:106] Iteration 2931500, lr = 0.01
I0831 10:19:10.945505 916722 solver.cpp:218] Iteration 2932000 (16.6349 iter/s, 30.0573s/500 iters), loss = 0.0675611
I0831 10:19:10.945564 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0675682 (* 1 = 0.0675682 loss)
I0831 10:19:10.945572 916722 sgd_solver.cpp:106] Iteration 2932000, lr = 0.01
I0831 10:19:40.997285 916722 solver.cpp:218] Iteration 2932500 (16.638 iter/s, 30.0517s/500 iters), loss = 0.0899834
I0831 10:19:40.997347 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0899907 (* 1 = 0.0899907 loss)
I0831 10:19:40.997355 916722 sgd_solver.cpp:106] Iteration 2932500, lr = 0.01
I0831 10:20:11.048115 916722 solver.cpp:218] Iteration 2933000 (16.6385 iter/s, 30.0507s/500 iters), loss = 0.0727346
I0831 10:20:11.048175 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0727419 (* 1 = 0.0727419 loss)
I0831 10:20:11.048184 916722 sgd_solver.cpp:106] Iteration 2933000, lr = 0.01
I0831 10:20:41.055653 916722 solver.cpp:218] Iteration 2933500 (16.6625 iter/s, 30.0074s/500 iters), loss = 0.0632395
I0831 10:20:41.055714 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0632468 (* 1 = 0.0632468 loss)
I0831 10:20:41.055723 916722 sgd_solver.cpp:106] Iteration 2933500, lr = 0.01
I0831 10:21:11.055622 916722 solver.cpp:218] Iteration 2934000 (16.6667 iter/s, 29.9999s/500 iters), loss = 0.199048
I0831 10:21:11.055675 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.199055 (* 1 = 0.199055 loss)
I0831 10:21:11.055685 916722 sgd_solver.cpp:106] Iteration 2934000, lr = 0.01
I0831 10:21:41.038666 916722 solver.cpp:218] Iteration 2934500 (16.6762 iter/s, 29.9829s/500 iters), loss = 0.0424905
I0831 10:21:41.038729 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0424979 (* 1 = 0.0424979 loss)
I0831 10:21:41.038738 916722 sgd_solver.cpp:106] Iteration 2934500, lr = 0.01
I0831 10:22:10.999199 916722 solver.cpp:218] Iteration 2935000 (16.6887 iter/s, 29.9604s/500 iters), loss = 0.17852
I0831 10:22:10.999253 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.178528 (* 1 = 0.178528 loss)
I0831 10:22:10.999264 916722 sgd_solver.cpp:106] Iteration 2935000, lr = 0.01
I0831 10:22:40.934232 916722 solver.cpp:218] Iteration 2935500 (16.7029 iter/s, 29.9349s/500 iters), loss = 0.137946
I0831 10:22:40.934293 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.137953 (* 1 = 0.137953 loss)
I0831 10:22:40.934301 916722 sgd_solver.cpp:106] Iteration 2935500, lr = 0.01
I0831 10:23:10.847985 916722 solver.cpp:218] Iteration 2936000 (16.7148 iter/s, 29.9136s/500 iters), loss = 0.219628
I0831 10:23:10.848038 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.219635 (* 1 = 0.219635 loss)
I0831 10:23:10.848047 916722 sgd_solver.cpp:106] Iteration 2936000, lr = 0.01
I0831 10:23:40.751929 916722 solver.cpp:218] Iteration 2936500 (16.7203 iter/s, 29.9038s/500 iters), loss = 0.0982681
I0831 10:23:40.751986 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0982752 (* 1 = 0.0982752 loss)
I0831 10:23:40.751994 916722 sgd_solver.cpp:106] Iteration 2936500, lr = 0.01
I0831 10:24:10.659243 916722 solver.cpp:218] Iteration 2937000 (16.7184 iter/s, 29.9072s/500 iters), loss = 0.102062
I0831 10:24:10.659296 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.102069 (* 1 = 0.102069 loss)
I0831 10:24:10.659305 916722 sgd_solver.cpp:106] Iteration 2937000, lr = 0.01
I0831 10:24:40.526757 916722 solver.cpp:218] Iteration 2937500 (16.7407 iter/s, 29.8674s/500 iters), loss = 0.124686
I0831 10:24:40.526818 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.124693 (* 1 = 0.124693 loss)
I0831 10:24:40.526826 916722 sgd_solver.cpp:106] Iteration 2937500, lr = 0.01
I0831 10:25:10.385074 916722 solver.cpp:218] Iteration 2938000 (16.7458 iter/s, 29.8582s/500 iters), loss = 0.273479
I0831 10:25:10.385138 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.273486 (* 1 = 0.273486 loss)
I0831 10:25:10.385147 916722 sgd_solver.cpp:106] Iteration 2938000, lr = 0.01
I0831 10:25:40.241561 916722 solver.cpp:218] Iteration 2938500 (16.7469 iter/s, 29.8563s/500 iters), loss = 0.344969
I0831 10:25:40.241647 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.344976 (* 1 = 0.344976 loss)
I0831 10:25:40.241657 916722 sgd_solver.cpp:106] Iteration 2938500, lr = 0.01
I0831 10:26:10.102382 916722 solver.cpp:218] Iteration 2939000 (16.7444 iter/s, 29.8606s/500 iters), loss = 0.136362
I0831 10:26:10.102433 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.136369 (* 1 = 0.136369 loss)
I0831 10:26:10.102442 916722 sgd_solver.cpp:106] Iteration 2939000, lr = 0.01
I0831 10:26:39.959285 916722 solver.cpp:218] Iteration 2939500 (16.7466 iter/s, 29.8568s/500 iters), loss = 0.0766443
I0831 10:26:39.959347 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0766513 (* 1 = 0.0766513 loss)
I0831 10:26:39.959355 916722 sgd_solver.cpp:106] Iteration 2939500, lr = 0.01
I0831 10:27:09.814296 916722 solver.cpp:218] Iteration 2940000 (16.7477 iter/s, 29.8549s/500 iters), loss = 0.0973474
I0831 10:27:09.814348 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0973542 (* 1 = 0.0973542 loss)
I0831 10:27:09.814357 916722 sgd_solver.cpp:106] Iteration 2940000, lr = 0.01
I0831 10:27:39.678336 916722 solver.cpp:218] Iteration 2940500 (16.7426 iter/s, 29.8639s/500 iters), loss = 0.264334
I0831 10:27:39.678395 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.264341 (* 1 = 0.264341 loss)
I0831 10:27:39.678404 916722 sgd_solver.cpp:106] Iteration 2940500, lr = 0.01
I0831 10:28:09.542697 916722 solver.cpp:218] Iteration 2941000 (16.7425 iter/s, 29.8642s/500 iters), loss = 0.0672367
I0831 10:28:09.542752 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0672437 (* 1 = 0.0672437 loss)
I0831 10:28:09.542762 916722 sgd_solver.cpp:106] Iteration 2941000, lr = 0.01
I0831 10:28:39.395100 916722 solver.cpp:218] Iteration 2941500 (16.7492 iter/s, 29.8522s/500 iters), loss = 0.237353
I0831 10:28:39.395160 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.237359 (* 1 = 0.237359 loss)
I0831 10:28:39.395169 916722 sgd_solver.cpp:106] Iteration 2941500, lr = 0.01
I0831 10:29:09.250277 916722 solver.cpp:218] Iteration 2942000 (16.7476 iter/s, 29.855s/500 iters), loss = 0.152323
I0831 10:29:09.250331 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.15233 (* 1 = 0.15233 loss)
I0831 10:29:09.250341 916722 sgd_solver.cpp:106] Iteration 2942000, lr = 0.01
I0831 10:29:39.101114 916722 solver.cpp:218] Iteration 2942500 (16.75 iter/s, 29.8507s/500 iters), loss = 0.077954
I0831 10:29:39.101176 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0779607 (* 1 = 0.0779607 loss)
I0831 10:29:39.101184 916722 sgd_solver.cpp:106] Iteration 2942500, lr = 0.01
I0831 10:30:08.953927 916722 solver.cpp:218] Iteration 2943000 (16.7489 iter/s, 29.8527s/500 iters), loss = 0.088619
I0831 10:30:08.953980 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0886258 (* 1 = 0.0886258 loss)
I0831 10:30:08.953990 916722 sgd_solver.cpp:106] Iteration 2943000, lr = 0.01
I0831 10:30:38.798226 916722 solver.cpp:218] Iteration 2943500 (16.7537 iter/s, 29.8441s/500 iters), loss = 0.191795
I0831 10:30:38.798285 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.191802 (* 1 = 0.191802 loss)
I0831 10:30:38.798293 916722 sgd_solver.cpp:106] Iteration 2943500, lr = 0.01
I0831 10:31:08.648178 916722 solver.cpp:218] Iteration 2944000 (16.7505 iter/s, 29.8498s/500 iters), loss = 0.551847
I0831 10:31:08.648231 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.551854 (* 1 = 0.551854 loss)
I0831 10:31:08.648241 916722 sgd_solver.cpp:106] Iteration 2944000, lr = 0.01
I0831 10:31:38.501719 916722 solver.cpp:218] Iteration 2944500 (16.7485 iter/s, 29.8534s/500 iters), loss = 0.094767
I0831 10:31:38.501789 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0947738 (* 1 = 0.0947738 loss)
I0831 10:31:38.501802 916722 sgd_solver.cpp:106] Iteration 2944500, lr = 0.01
I0831 10:32:08.349534 916722 solver.cpp:218] Iteration 2945000 (16.7517 iter/s, 29.8476s/500 iters), loss = 0.204137
I0831 10:32:08.349587 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.204144 (* 1 = 0.204144 loss)
I0831 10:32:08.349597 916722 sgd_solver.cpp:106] Iteration 2945000, lr = 0.01
I0831 10:32:38.201284 916722 solver.cpp:218] Iteration 2945500 (16.7495 iter/s, 29.8516s/500 iters), loss = 0.0432637
I0831 10:32:38.201344 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0432706 (* 1 = 0.0432706 loss)
I0831 10:32:38.201354 916722 sgd_solver.cpp:106] Iteration 2945500, lr = 0.01
I0831 10:33:08.051285 916722 solver.cpp:218] Iteration 2946000 (16.7505 iter/s, 29.8498s/500 iters), loss = 0.402328
I0831 10:33:08.051338 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.402334 (* 1 = 0.402334 loss)
I0831 10:33:08.051347 916722 sgd_solver.cpp:106] Iteration 2946000, lr = 0.01
I0831 10:33:37.903303 916722 solver.cpp:218] Iteration 2946500 (16.7494 iter/s, 29.8519s/500 iters), loss = 0.136845
I0831 10:33:37.903360 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.136852 (* 1 = 0.136852 loss)
I0831 10:33:37.903368 916722 sgd_solver.cpp:106] Iteration 2946500, lr = 0.01
I0831 10:34:07.757040 916722 solver.cpp:218] Iteration 2947000 (16.7484 iter/s, 29.8536s/500 iters), loss = 0.295225
I0831 10:34:07.757094 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.295232 (* 1 = 0.295232 loss)
I0831 10:34:07.757104 916722 sgd_solver.cpp:106] Iteration 2947000, lr = 0.01
I0831 10:34:37.612572 916722 solver.cpp:218] Iteration 2947500 (16.7474 iter/s, 29.8554s/500 iters), loss = 0.115193
I0831 10:34:37.612632 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.1152 (* 1 = 0.1152 loss)
I0831 10:34:37.612641 916722 sgd_solver.cpp:106] Iteration 2947500, lr = 0.01
I0831 10:35:07.462824 916722 solver.cpp:218] Iteration 2948000 (16.7504 iter/s, 29.8501s/500 iters), loss = 0.0932601
I0831 10:35:07.462878 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0932669 (* 1 = 0.0932669 loss)
I0831 10:35:07.462888 916722 sgd_solver.cpp:106] Iteration 2948000, lr = 0.01
I0831 10:35:37.314659 916722 solver.cpp:218] Iteration 2948500 (16.7495 iter/s, 29.8517s/500 iters), loss = 0.0702661
I0831 10:35:37.314719 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0702728 (* 1 = 0.0702728 loss)
I0831 10:35:37.314728 916722 sgd_solver.cpp:106] Iteration 2948500, lr = 0.01
I0831 10:36:07.163318 916722 solver.cpp:218] Iteration 2949000 (16.7513 iter/s, 29.8485s/500 iters), loss = 0.151787
I0831 10:36:07.163369 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.151793 (* 1 = 0.151793 loss)
I0831 10:36:07.163379 916722 sgd_solver.cpp:106] Iteration 2949000, lr = 0.01
I0831 10:36:37.014109 916722 solver.cpp:218] Iteration 2949500 (16.7501 iter/s, 29.8506s/500 iters), loss = 0.0799714
I0831 10:36:37.014170 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0799782 (* 1 = 0.0799782 loss)
I0831 10:36:37.014179 916722 sgd_solver.cpp:106] Iteration 2949500, lr = 0.01
I0831 10:37:06.806748 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_2950000.caffemodel
I0831 10:37:06.826174 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_2950000.solverstate
I0831 10:37:06.832149 916722 solver.cpp:330] Iteration 2950000, Testing net (#0)
I0831 10:37:22.204650 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8973
I0831 10:37:22.204706 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.363964 (* 1 = 0.363964 loss)
I0831 10:37:22.263334 916722 solver.cpp:218] Iteration 2950000 (11.05 iter/s, 45.249s/500 iters), loss = 0.105612
I0831 10:37:22.263360 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105619 (* 1 = 0.105619 loss)
I0831 10:37:22.263368 916722 sgd_solver.cpp:106] Iteration 2950000, lr = 0.01
I0831 10:37:52.013314 916722 solver.cpp:218] Iteration 2950500 (16.8068 iter/s, 29.7499s/500 iters), loss = 0.0624354
I0831 10:37:52.013371 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0624423 (* 1 = 0.0624423 loss)
I0831 10:37:52.013381 916722 sgd_solver.cpp:106] Iteration 2950500, lr = 0.01
I0831 10:38:21.758291 916722 solver.cpp:218] Iteration 2951000 (16.8096 iter/s, 29.7449s/500 iters), loss = 0.0731671
I0831 10:38:21.758363 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0731739 (* 1 = 0.0731739 loss)
I0831 10:38:21.758373 916722 sgd_solver.cpp:106] Iteration 2951000, lr = 0.01
I0831 10:38:51.500483 916722 solver.cpp:218] Iteration 2951500 (16.8112 iter/s, 29.7421s/500 iters), loss = 0.24159
I0831 10:38:51.500538 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.241596 (* 1 = 0.241596 loss)
I0831 10:38:51.500548 916722 sgd_solver.cpp:106] Iteration 2951500, lr = 0.01
I0831 10:39:21.244709 916722 solver.cpp:218] Iteration 2952000 (16.81 iter/s, 29.7441s/500 iters), loss = 0.254513
I0831 10:39:21.244788 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.254519 (* 1 = 0.254519 loss)
I0831 10:39:21.244796 916722 sgd_solver.cpp:106] Iteration 2952000, lr = 0.01
I0831 10:39:50.994282 916722 solver.cpp:218] Iteration 2952500 (16.807 iter/s, 29.7495s/500 iters), loss = 0.321558
I0831 10:39:50.994336 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.321565 (* 1 = 0.321565 loss)
I0831 10:39:50.994346 916722 sgd_solver.cpp:106] Iteration 2952500, lr = 0.01
I0831 10:40:20.737807 916722 solver.cpp:218] Iteration 2953000 (16.8104 iter/s, 29.7434s/500 iters), loss = 0.160284
I0831 10:40:20.737865 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.16029 (* 1 = 0.16029 loss)
I0831 10:40:20.737874 916722 sgd_solver.cpp:106] Iteration 2953000, lr = 0.01
I0831 10:40:50.481822 916722 solver.cpp:218] Iteration 2953500 (16.8102 iter/s, 29.7439s/500 iters), loss = 0.0440625
I0831 10:40:50.481878 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0440693 (* 1 = 0.0440693 loss)
I0831 10:40:50.481887 916722 sgd_solver.cpp:106] Iteration 2953500, lr = 0.01
I0831 10:41:20.233312 916722 solver.cpp:218] Iteration 2954000 (16.8059 iter/s, 29.7514s/500 iters), loss = 0.041878
I0831 10:41:20.233371 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0418848 (* 1 = 0.0418848 loss)
I0831 10:41:20.233379 916722 sgd_solver.cpp:106] Iteration 2954000, lr = 0.01
I0831 10:41:49.973493 916722 solver.cpp:218] Iteration 2954500 (16.8123 iter/s, 29.7401s/500 iters), loss = 0.100905
I0831 10:41:49.973547 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.100912 (* 1 = 0.100912 loss)
I0831 10:41:49.973557 916722 sgd_solver.cpp:106] Iteration 2954500, lr = 0.01
I0831 10:42:19.717993 916722 solver.cpp:218] Iteration 2955000 (16.8099 iter/s, 29.7444s/500 iters), loss = 0.315644
I0831 10:42:19.718056 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.31565 (* 1 = 0.31565 loss)
I0831 10:42:19.718065 916722 sgd_solver.cpp:106] Iteration 2955000, lr = 0.01
I0831 10:42:49.457342 916722 solver.cpp:218] Iteration 2955500 (16.8128 iter/s, 29.7392s/500 iters), loss = 0.240817
I0831 10:42:49.457394 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.240823 (* 1 = 0.240823 loss)
I0831 10:42:49.457403 916722 sgd_solver.cpp:106] Iteration 2955500, lr = 0.01
I0831 10:43:19.197911 916722 solver.cpp:218] Iteration 2956000 (16.8121 iter/s, 29.7405s/500 iters), loss = 0.166341
I0831 10:43:19.197969 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.166348 (* 1 = 0.166348 loss)
I0831 10:43:19.197978 916722 sgd_solver.cpp:106] Iteration 2956000, lr = 0.01
I0831 10:43:48.936012 916722 solver.cpp:218] Iteration 2956500 (16.8135 iter/s, 29.738s/500 iters), loss = 0.156921
I0831 10:43:48.936067 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.156928 (* 1 = 0.156928 loss)
I0831 10:43:48.936076 916722 sgd_solver.cpp:106] Iteration 2956500, lr = 0.01
I0831 10:44:18.674149 916722 solver.cpp:218] Iteration 2957000 (16.8135 iter/s, 29.738s/500 iters), loss = 0.0420106
I0831 10:44:18.674221 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0420169 (* 1 = 0.0420169 loss)
I0831 10:44:18.674229 916722 sgd_solver.cpp:106] Iteration 2957000, lr = 0.01
I0831 10:44:48.414428 916722 solver.cpp:218] Iteration 2957500 (16.8123 iter/s, 29.7401s/500 iters), loss = 0.0671031
I0831 10:44:48.414485 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0671095 (* 1 = 0.0671095 loss)
I0831 10:44:48.414494 916722 sgd_solver.cpp:106] Iteration 2957500, lr = 0.01
I0831 10:45:18.152592 916722 solver.cpp:218] Iteration 2958000 (16.8135 iter/s, 29.738s/500 iters), loss = 0.0900703
I0831 10:45:18.152654 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0900767 (* 1 = 0.0900767 loss)
I0831 10:45:18.152663 916722 sgd_solver.cpp:106] Iteration 2958000, lr = 0.01
I0831 10:45:47.889732 916722 solver.cpp:218] Iteration 2958500 (16.8141 iter/s, 29.737s/500 iters), loss = 0.321398
I0831 10:45:47.889791 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.321405 (* 1 = 0.321405 loss)
I0831 10:45:47.889801 916722 sgd_solver.cpp:106] Iteration 2958500, lr = 0.01
I0831 10:46:17.627840 916722 solver.cpp:218] Iteration 2959000 (16.8135 iter/s, 29.738s/500 iters), loss = 0.179969
I0831 10:46:17.627899 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.179975 (* 1 = 0.179975 loss)
I0831 10:46:17.627908 916722 sgd_solver.cpp:106] Iteration 2959000, lr = 0.01
I0831 10:46:47.364038 916722 solver.cpp:218] Iteration 2959500 (16.8146 iter/s, 29.7361s/500 iters), loss = 0.0581216
I0831 10:46:47.364090 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0581279 (* 1 = 0.0581279 loss)
I0831 10:46:47.364099 916722 sgd_solver.cpp:106] Iteration 2959500, lr = 0.01
I0831 10:47:17.099192 916722 solver.cpp:218] Iteration 2960000 (16.8152 iter/s, 29.735s/500 iters), loss = 0.152511
I0831 10:47:17.099252 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152517 (* 1 = 0.152517 loss)
I0831 10:47:17.099260 916722 sgd_solver.cpp:106] Iteration 2960000, lr = 0.01
I0831 10:47:46.835568 916722 solver.cpp:218] Iteration 2960500 (16.8145 iter/s, 29.7362s/500 iters), loss = 0.125411
I0831 10:47:46.835621 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.125417 (* 1 = 0.125417 loss)
I0831 10:47:46.835631 916722 sgd_solver.cpp:106] Iteration 2960500, lr = 0.01
I0831 10:48:16.569566 916722 solver.cpp:218] Iteration 2961000 (16.8158 iter/s, 29.7339s/500 iters), loss = 0.152983
I0831 10:48:16.569620 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152989 (* 1 = 0.152989 loss)
I0831 10:48:16.569628 916722 sgd_solver.cpp:106] Iteration 2961000, lr = 0.01
I0831 10:48:46.305899 916722 solver.cpp:218] Iteration 2961500 (16.8145 iter/s, 29.7362s/500 iters), loss = 0.114207
I0831 10:48:46.305953 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.114213 (* 1 = 0.114213 loss)
I0831 10:48:46.305963 916722 sgd_solver.cpp:106] Iteration 2961500, lr = 0.01
I0831 10:49:16.042542 916722 solver.cpp:218] Iteration 2962000 (16.8144 iter/s, 29.7365s/500 iters), loss = 0.0781774
I0831 10:49:16.042601 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0781835 (* 1 = 0.0781835 loss)
I0831 10:49:16.042610 916722 sgd_solver.cpp:106] Iteration 2962000, lr = 0.01
I0831 10:49:45.782178 916722 solver.cpp:218] Iteration 2962500 (16.8127 iter/s, 29.7395s/500 iters), loss = 0.166398
I0831 10:49:45.782230 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.166404 (* 1 = 0.166404 loss)
I0831 10:49:45.782240 916722 sgd_solver.cpp:106] Iteration 2962500, lr = 0.01
I0831 10:50:15.517314 916722 solver.cpp:218] Iteration 2963000 (16.8152 iter/s, 29.735s/500 iters), loss = 0.225995
I0831 10:50:15.517374 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.226001 (* 1 = 0.226001 loss)
I0831 10:50:15.517382 916722 sgd_solver.cpp:106] Iteration 2963000, lr = 0.01
I0831 10:50:45.253569 916722 solver.cpp:218] Iteration 2963500 (16.8146 iter/s, 29.7361s/500 iters), loss = 0.0708114
I0831 10:50:45.253635 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0708176 (* 1 = 0.0708176 loss)
I0831 10:50:45.253645 916722 sgd_solver.cpp:106] Iteration 2963500, lr = 0.01
I0831 10:51:14.988019 916722 solver.cpp:218] Iteration 2964000 (16.8156 iter/s, 29.7343s/500 iters), loss = 0.0221874
I0831 10:51:14.988090 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0221935 (* 1 = 0.0221935 loss)
I0831 10:51:14.988097 916722 sgd_solver.cpp:106] Iteration 2964000, lr = 0.01
I0831 10:51:44.720257 916722 solver.cpp:218] Iteration 2964500 (16.8169 iter/s, 29.7321s/500 iters), loss = 0.11108
I0831 10:51:44.720309 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111086 (* 1 = 0.111086 loss)
I0831 10:51:44.720319 916722 sgd_solver.cpp:106] Iteration 2964500, lr = 0.01
I0831 10:52:14.454612 916722 solver.cpp:218] Iteration 2965000 (16.8157 iter/s, 29.7342s/500 iters), loss = 0.166225
I0831 10:52:14.454670 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.166231 (* 1 = 0.166231 loss)
I0831 10:52:14.454679 916722 sgd_solver.cpp:106] Iteration 2965000, lr = 0.01
I0831 10:52:44.189108 916722 solver.cpp:218] Iteration 2965500 (16.8156 iter/s, 29.7343s/500 iters), loss = 0.158335
I0831 10:52:44.189160 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.158341 (* 1 = 0.158341 loss)
I0831 10:52:44.189168 916722 sgd_solver.cpp:106] Iteration 2965500, lr = 0.01
I0831 10:53:13.925941 916722 solver.cpp:218] Iteration 2966000 (16.8142 iter/s, 29.7367s/500 iters), loss = 0.300916
I0831 10:53:13.926002 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.300922 (* 1 = 0.300922 loss)
I0831 10:53:13.926010 916722 sgd_solver.cpp:106] Iteration 2966000, lr = 0.01
I0831 10:53:43.658620 916722 solver.cpp:218] Iteration 2966500 (16.8166 iter/s, 29.7325s/500 iters), loss = 0.101555
I0831 10:53:43.658674 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101561 (* 1 = 0.101561 loss)
I0831 10:53:43.658684 916722 sgd_solver.cpp:106] Iteration 2966500, lr = 0.01
I0831 10:54:13.392791 916722 solver.cpp:218] Iteration 2967000 (16.8158 iter/s, 29.734s/500 iters), loss = 0.0934682
I0831 10:54:13.392851 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0934738 (* 1 = 0.0934738 loss)
I0831 10:54:13.392860 916722 sgd_solver.cpp:106] Iteration 2967000, lr = 0.01
I0831 10:54:43.127768 916722 solver.cpp:218] Iteration 2967500 (16.8153 iter/s, 29.7348s/500 iters), loss = 0.265451
I0831 10:54:43.127821 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.265456 (* 1 = 0.265456 loss)
I0831 10:54:43.127830 916722 sgd_solver.cpp:106] Iteration 2967500, lr = 0.01
I0831 10:55:12.865624 916722 solver.cpp:218] Iteration 2968000 (16.8137 iter/s, 29.7377s/500 iters), loss = 0.0147357
I0831 10:55:12.865685 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0147413 (* 1 = 0.0147413 loss)
I0831 10:55:12.865694 916722 sgd_solver.cpp:106] Iteration 2968000, lr = 0.01
I0831 10:55:42.597358 916722 solver.cpp:218] Iteration 2968500 (16.8171 iter/s, 29.7316s/500 iters), loss = 0.166885
I0831 10:55:42.597412 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.16689 (* 1 = 0.16689 loss)
I0831 10:55:42.597420 916722 sgd_solver.cpp:106] Iteration 2968500, lr = 0.01
I0831 10:56:12.334491 916722 solver.cpp:218] Iteration 2969000 (16.8141 iter/s, 29.737s/500 iters), loss = 0.118427
I0831 10:56:12.334549 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.118433 (* 1 = 0.118433 loss)
I0831 10:56:12.334558 916722 sgd_solver.cpp:106] Iteration 2969000, lr = 0.01
I0831 10:56:42.069730 916722 solver.cpp:218] Iteration 2969500 (16.8152 iter/s, 29.7351s/500 iters), loss = 0.304226
I0831 10:56:42.069790 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.304232 (* 1 = 0.304232 loss)
I0831 10:56:42.069800 916722 sgd_solver.cpp:106] Iteration 2969500, lr = 0.01
I0831 10:57:11.807132 916722 solver.cpp:218] Iteration 2970000 (16.8139 iter/s, 29.7372s/500 iters), loss = 0.0941552
I0831 10:57:11.807207 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.094161 (* 1 = 0.094161 loss)
I0831 10:57:11.807216 916722 sgd_solver.cpp:106] Iteration 2970000, lr = 0.01
I0831 10:57:41.542013 916722 solver.cpp:218] Iteration 2970500 (16.8154 iter/s, 29.7347s/500 iters), loss = 0.157822
I0831 10:57:41.542068 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.157828 (* 1 = 0.157828 loss)
I0831 10:57:41.542078 916722 sgd_solver.cpp:106] Iteration 2970500, lr = 0.01
I0831 10:58:11.279825 916722 solver.cpp:218] Iteration 2971000 (16.8137 iter/s, 29.7377s/500 iters), loss = 0.0850083
I0831 10:58:11.279883 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0850138 (* 1 = 0.0850138 loss)
I0831 10:58:11.279892 916722 sgd_solver.cpp:106] Iteration 2971000, lr = 0.01
I0831 10:58:41.015355 916722 solver.cpp:218] Iteration 2971500 (16.815 iter/s, 29.7354s/500 iters), loss = 0.0782481
I0831 10:58:41.015408 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0782535 (* 1 = 0.0782535 loss)
I0831 10:58:41.015419 916722 sgd_solver.cpp:106] Iteration 2971500, lr = 0.01
I0831 10:59:10.749615 916722 solver.cpp:218] Iteration 2972000 (16.8157 iter/s, 29.7341s/500 iters), loss = 0.148777
I0831 10:59:10.749675 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.148783 (* 1 = 0.148783 loss)
I0831 10:59:10.749684 916722 sgd_solver.cpp:106] Iteration 2972000, lr = 0.01
I0831 10:59:40.485010 916722 solver.cpp:218] Iteration 2972500 (16.8151 iter/s, 29.7352s/500 iters), loss = 0.100919
I0831 10:59:40.485064 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.100924 (* 1 = 0.100924 loss)
I0831 10:59:40.485074 916722 sgd_solver.cpp:106] Iteration 2972500, lr = 0.01
I0831 11:00:10.221081 916722 solver.cpp:218] Iteration 2973000 (16.8147 iter/s, 29.7359s/500 iters), loss = 0.101125
I0831 11:00:10.221140 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.10113 (* 1 = 0.10113 loss)
I0831 11:00:10.221148 916722 sgd_solver.cpp:106] Iteration 2973000, lr = 0.01
I0831 11:00:39.956174 916722 solver.cpp:218] Iteration 2973500 (16.8152 iter/s, 29.7349s/500 iters), loss = 0.245983
I0831 11:00:39.956228 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.245988 (* 1 = 0.245988 loss)
I0831 11:00:39.956238 916722 sgd_solver.cpp:106] Iteration 2973500, lr = 0.01
I0831 11:01:09.693600 916722 solver.cpp:218] Iteration 2974000 (16.8139 iter/s, 29.7373s/500 iters), loss = 0.0100243
I0831 11:01:09.693655 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0100294 (* 1 = 0.0100294 loss)
I0831 11:01:09.693663 916722 sgd_solver.cpp:106] Iteration 2974000, lr = 0.01
I0831 11:01:39.431198 916722 solver.cpp:218] Iteration 2974500 (16.8138 iter/s, 29.7374s/500 iters), loss = 0.14612
I0831 11:01:39.431249 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.146125 (* 1 = 0.146125 loss)
I0831 11:01:39.431259 916722 sgd_solver.cpp:106] Iteration 2974500, lr = 0.01
I0831 11:02:09.167690 916722 solver.cpp:218] Iteration 2975000 (16.8144 iter/s, 29.7363s/500 iters), loss = 0.177625
I0831 11:02:09.167750 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.17763 (* 1 = 0.17763 loss)
I0831 11:02:09.167759 916722 sgd_solver.cpp:106] Iteration 2975000, lr = 0.01
I0831 11:02:38.902535 916722 solver.cpp:218] Iteration 2975500 (16.8154 iter/s, 29.7347s/500 iters), loss = 0.24909
I0831 11:02:38.902590 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.249095 (* 1 = 0.249095 loss)
I0831 11:02:38.902598 916722 sgd_solver.cpp:106] Iteration 2975500, lr = 0.01
I0831 11:03:08.644140 916722 solver.cpp:218] Iteration 2976000 (16.8116 iter/s, 29.7414s/500 iters), loss = 0.0518657
I0831 11:03:08.644198 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0518707 (* 1 = 0.0518707 loss)
I0831 11:03:08.644207 916722 sgd_solver.cpp:106] Iteration 2976000, lr = 0.01
I0831 11:03:38.393127 916722 solver.cpp:218] Iteration 2976500 (16.8074 iter/s, 29.7488s/500 iters), loss = 0.146021
I0831 11:03:38.393180 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.146026 (* 1 = 0.146026 loss)
I0831 11:03:38.393203 916722 sgd_solver.cpp:106] Iteration 2976500, lr = 0.01
I0831 11:04:08.142578 916722 solver.cpp:218] Iteration 2977000 (16.8071 iter/s, 29.7493s/500 iters), loss = 0.0205723
I0831 11:04:08.142648 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0205773 (* 1 = 0.0205773 loss)
I0831 11:04:08.142657 916722 sgd_solver.cpp:106] Iteration 2977000, lr = 0.01
I0831 11:04:37.888707 916722 solver.cpp:218] Iteration 2977500 (16.809 iter/s, 29.746s/500 iters), loss = 0.150605
I0831 11:04:37.888770 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.15061 (* 1 = 0.15061 loss)
I0831 11:04:37.888780 916722 sgd_solver.cpp:106] Iteration 2977500, lr = 0.01
I0831 11:05:07.635419 916722 solver.cpp:218] Iteration 2978000 (16.8087 iter/s, 29.7465s/500 iters), loss = 0.220153
I0831 11:05:07.635476 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.220158 (* 1 = 0.220158 loss)
I0831 11:05:07.635484 916722 sgd_solver.cpp:106] Iteration 2978000, lr = 0.01
I0831 11:05:37.379844 916722 solver.cpp:218] Iteration 2978500 (16.81 iter/s, 29.7443s/500 iters), loss = 0.152386
I0831 11:05:37.379891 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152391 (* 1 = 0.152391 loss)
I0831 11:05:37.379901 916722 sgd_solver.cpp:106] Iteration 2978500, lr = 0.01
I0831 11:06:07.131600 916722 solver.cpp:218] Iteration 2979000 (16.8058 iter/s, 29.7516s/500 iters), loss = 0.198702
I0831 11:06:07.131659 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.198707 (* 1 = 0.198707 loss)
I0831 11:06:07.131666 916722 sgd_solver.cpp:106] Iteration 2979000, lr = 0.01
I0831 11:06:36.877673 916722 solver.cpp:218] Iteration 2979500 (16.809 iter/s, 29.7459s/500 iters), loss = 0.0449218
I0831 11:06:36.877725 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0449265 (* 1 = 0.0449265 loss)
I0831 11:06:36.877735 916722 sgd_solver.cpp:106] Iteration 2979500, lr = 0.01
I0831 11:07:06.619199 916722 solver.cpp:218] Iteration 2980000 (16.8116 iter/s, 29.7414s/500 iters), loss = 0.0711628
I0831 11:07:06.619258 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0711676 (* 1 = 0.0711676 loss)
I0831 11:07:06.619266 916722 sgd_solver.cpp:106] Iteration 2980000, lr = 0.01
I0831 11:07:36.368726 916722 solver.cpp:218] Iteration 2980500 (16.8071 iter/s, 29.7494s/500 iters), loss = 0.276191
I0831 11:07:36.368788 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.276196 (* 1 = 0.276196 loss)
I0831 11:07:36.368798 916722 sgd_solver.cpp:106] Iteration 2980500, lr = 0.01
I0831 11:08:06.104470 916722 solver.cpp:218] Iteration 2981000 (16.8149 iter/s, 29.7356s/500 iters), loss = 0.175441
I0831 11:08:06.104529 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.175445 (* 1 = 0.175445 loss)
I0831 11:08:06.104538 916722 sgd_solver.cpp:106] Iteration 2981000, lr = 0.01
I0831 11:08:35.840677 916722 solver.cpp:218] Iteration 2981500 (16.8146 iter/s, 29.736s/500 iters), loss = 0.212253
I0831 11:08:35.840728 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.212258 (* 1 = 0.212258 loss)
I0831 11:08:35.840737 916722 sgd_solver.cpp:106] Iteration 2981500, lr = 0.01
I0831 11:09:05.575615 916722 solver.cpp:218] Iteration 2982000 (16.8153 iter/s, 29.7348s/500 iters), loss = 0.184732
I0831 11:09:05.575672 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.184737 (* 1 = 0.184737 loss)
I0831 11:09:05.575681 916722 sgd_solver.cpp:106] Iteration 2982000, lr = 0.01
I0831 11:09:35.309172 916722 solver.cpp:218] Iteration 2982500 (16.8161 iter/s, 29.7334s/500 iters), loss = 0.133699
I0831 11:09:35.309222 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133703 (* 1 = 0.133703 loss)
I0831 11:09:35.309231 916722 sgd_solver.cpp:106] Iteration 2982500, lr = 0.01
I0831 11:10:05.046954 916722 solver.cpp:218] Iteration 2983000 (16.8137 iter/s, 29.7376s/500 iters), loss = 0.125709
I0831 11:10:05.047025 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.125713 (* 1 = 0.125713 loss)
I0831 11:10:05.047039 916722 sgd_solver.cpp:106] Iteration 2983000, lr = 0.01
I0831 11:10:34.780580 916722 solver.cpp:218] Iteration 2983500 (16.8161 iter/s, 29.7334s/500 iters), loss = 0.0802625
I0831 11:10:34.780632 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.080267 (* 1 = 0.080267 loss)
I0831 11:10:34.780642 916722 sgd_solver.cpp:106] Iteration 2983500, lr = 0.01
I0831 11:11:04.513932 916722 solver.cpp:218] Iteration 2984000 (16.8162 iter/s, 29.7332s/500 iters), loss = 0.216247
I0831 11:11:04.513991 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.216251 (* 1 = 0.216251 loss)
I0831 11:11:04.513999 916722 sgd_solver.cpp:106] Iteration 2984000, lr = 0.01
I0831 11:11:34.247341 916722 solver.cpp:218] Iteration 2984500 (16.8162 iter/s, 29.7333s/500 iters), loss = 0.111525
I0831 11:11:34.247393 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111529 (* 1 = 0.111529 loss)
I0831 11:11:34.247402 916722 sgd_solver.cpp:106] Iteration 2984500, lr = 0.01
I0831 11:12:03.983127 916722 solver.cpp:218] Iteration 2985000 (16.8145 iter/s, 29.7362s/500 iters), loss = 0.0497134
I0831 11:12:03.983186 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0497178 (* 1 = 0.0497178 loss)
I0831 11:12:03.983194 916722 sgd_solver.cpp:106] Iteration 2985000, lr = 0.01
I0831 11:12:33.718616 916722 solver.cpp:218] Iteration 2985500 (16.8147 iter/s, 29.7358s/500 iters), loss = 0.131698
I0831 11:12:33.718672 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131702 (* 1 = 0.131702 loss)
I0831 11:12:33.718681 916722 sgd_solver.cpp:106] Iteration 2985500, lr = 0.01
I0831 11:13:03.454885 916722 solver.cpp:218] Iteration 2986000 (16.8143 iter/s, 29.7366s/500 iters), loss = 0.119138
I0831 11:13:03.454943 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.119142 (* 1 = 0.119142 loss)
I0831 11:13:03.454952 916722 sgd_solver.cpp:106] Iteration 2986000, lr = 0.01
I0831 11:13:33.188941 916722 solver.cpp:218] Iteration 2986500 (16.8156 iter/s, 29.7344s/500 iters), loss = 0.142171
I0831 11:13:33.188995 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.142175 (* 1 = 0.142175 loss)
I0831 11:13:33.189005 916722 sgd_solver.cpp:106] Iteration 2986500, lr = 0.01
I0831 11:14:02.925010 916722 solver.cpp:218] Iteration 2987000 (16.8144 iter/s, 29.7363s/500 iters), loss = 0.126674
I0831 11:14:02.925067 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.126678 (* 1 = 0.126678 loss)
I0831 11:14:02.925076 916722 sgd_solver.cpp:106] Iteration 2987000, lr = 0.01
I0831 11:14:32.661804 916722 solver.cpp:218] Iteration 2987500 (16.814 iter/s, 29.737s/500 iters), loss = 0.257039
I0831 11:14:32.661855 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.257043 (* 1 = 0.257043 loss)
I0831 11:14:32.661865 916722 sgd_solver.cpp:106] Iteration 2987500, lr = 0.01
I0831 11:15:02.399262 916722 solver.cpp:218] Iteration 2988000 (16.8137 iter/s, 29.7377s/500 iters), loss = 0.128445
I0831 11:15:02.399317 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128449 (* 1 = 0.128449 loss)
I0831 11:15:02.399325 916722 sgd_solver.cpp:106] Iteration 2988000, lr = 0.01
I0831 11:15:32.138824 916722 solver.cpp:218] Iteration 2988500 (16.8125 iter/s, 29.7398s/500 iters), loss = 0.139412
I0831 11:15:32.138883 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139416 (* 1 = 0.139416 loss)
I0831 11:15:32.138898 916722 sgd_solver.cpp:106] Iteration 2988500, lr = 0.01
I0831 11:16:01.877876 916722 solver.cpp:218] Iteration 2989000 (16.8128 iter/s, 29.7392s/500 iters), loss = 0.169825
I0831 11:16:01.877934 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.169829 (* 1 = 0.169829 loss)
I0831 11:16:01.877943 916722 sgd_solver.cpp:106] Iteration 2989000, lr = 0.01
I0831 11:16:31.617609 916722 solver.cpp:218] Iteration 2989500 (16.8124 iter/s, 29.7399s/500 iters), loss = 0.0172275
I0831 11:16:31.617661 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0172317 (* 1 = 0.0172317 loss)
I0831 11:16:31.617686 916722 sgd_solver.cpp:106] Iteration 2989500, lr = 0.01
I0831 11:17:01.354892 916722 solver.cpp:218] Iteration 2990000 (16.8138 iter/s, 29.7374s/500 iters), loss = 0.119197
I0831 11:17:01.354960 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.119201 (* 1 = 0.119201 loss)
I0831 11:17:01.354969 916722 sgd_solver.cpp:106] Iteration 2990000, lr = 0.01
I0831 11:17:31.092327 916722 solver.cpp:218] Iteration 2990500 (16.8137 iter/s, 29.7376s/500 iters), loss = 0.218552
I0831 11:17:31.092379 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.218556 (* 1 = 0.218556 loss)
I0831 11:17:31.092388 916722 sgd_solver.cpp:106] Iteration 2990500, lr = 0.01
I0831 11:18:00.831986 916722 solver.cpp:218] Iteration 2991000 (16.8125 iter/s, 29.7398s/500 iters), loss = 0.235391
I0831 11:18:00.832041 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.235395 (* 1 = 0.235395 loss)
I0831 11:18:00.832049 916722 sgd_solver.cpp:106] Iteration 2991000, lr = 0.01
I0831 11:18:30.565388 916722 solver.cpp:218] Iteration 2991500 (16.816 iter/s, 29.7335s/500 iters), loss = 0.150159
I0831 11:18:30.565443 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.150164 (* 1 = 0.150164 loss)
I0831 11:18:30.565451 916722 sgd_solver.cpp:106] Iteration 2991500, lr = 0.01
I0831 11:19:00.301003 916722 solver.cpp:218] Iteration 2992000 (16.8148 iter/s, 29.7357s/500 iters), loss = 0.165097
I0831 11:19:00.301064 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.165101 (* 1 = 0.165101 loss)
I0831 11:19:00.301071 916722 sgd_solver.cpp:106] Iteration 2992000, lr = 0.01
I0831 11:19:30.037050 916722 solver.cpp:218] Iteration 2992500 (16.8146 iter/s, 29.7361s/500 iters), loss = 0.0316101
I0831 11:19:30.037102 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0316144 (* 1 = 0.0316144 loss)
I0831 11:19:30.037111 916722 sgd_solver.cpp:106] Iteration 2992500, lr = 0.01
I0831 11:19:59.772699 916722 solver.cpp:218] Iteration 2993000 (16.8148 iter/s, 29.7357s/500 iters), loss = 0.108249
I0831 11:19:59.772759 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.108254 (* 1 = 0.108254 loss)
I0831 11:19:59.772768 916722 sgd_solver.cpp:106] Iteration 2993000, lr = 0.01
I0831 11:20:29.507894 916722 solver.cpp:218] Iteration 2993500 (16.8151 iter/s, 29.7353s/500 iters), loss = 0.285212
I0831 11:20:29.507951 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.285216 (* 1 = 0.285216 loss)
I0831 11:20:29.507959 916722 sgd_solver.cpp:106] Iteration 2993500, lr = 0.01
I0831 11:20:59.239491 916722 solver.cpp:218] Iteration 2994000 (16.8171 iter/s, 29.7317s/500 iters), loss = 0.0704067
I0831 11:20:59.239547 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0704112 (* 1 = 0.0704112 loss)
I0831 11:20:59.239557 916722 sgd_solver.cpp:106] Iteration 2994000, lr = 0.01
I0831 11:21:28.974865 916722 solver.cpp:218] Iteration 2994500 (16.815 iter/s, 29.7354s/500 iters), loss = 0.125811
I0831 11:21:28.974918 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.125815 (* 1 = 0.125815 loss)
I0831 11:21:28.974927 916722 sgd_solver.cpp:106] Iteration 2994500, lr = 0.01
I0831 11:21:58.708333 916722 solver.cpp:218] Iteration 2995000 (16.816 iter/s, 29.7335s/500 iters), loss = 0.185018
I0831 11:21:58.708395 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.185022 (* 1 = 0.185022 loss)
I0831 11:21:58.708402 916722 sgd_solver.cpp:106] Iteration 2995000, lr = 0.01
I0831 11:22:28.445523 916722 solver.cpp:218] Iteration 2995500 (16.814 iter/s, 29.7372s/500 iters), loss = 0.0335845
I0831 11:22:28.445596 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.033589 (* 1 = 0.033589 loss)
I0831 11:22:28.445605 916722 sgd_solver.cpp:106] Iteration 2995500, lr = 0.01
I0831 11:22:58.182955 916722 solver.cpp:218] Iteration 2996000 (16.8138 iter/s, 29.7375s/500 iters), loss = 0.159972
I0831 11:22:58.183008 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159977 (* 1 = 0.159977 loss)
I0831 11:22:58.183017 916722 sgd_solver.cpp:106] Iteration 2996000, lr = 0.01
I0831 11:23:27.920936 916722 solver.cpp:218] Iteration 2996500 (16.8135 iter/s, 29.738s/500 iters), loss = 0.151571
I0831 11:23:27.920990 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.151576 (* 1 = 0.151576 loss)
I0831 11:23:27.921000 916722 sgd_solver.cpp:106] Iteration 2996500, lr = 0.01
I0831 11:23:57.659224 916722 solver.cpp:218] Iteration 2997000 (16.8133 iter/s, 29.7383s/500 iters), loss = 0.0493542
I0831 11:23:57.659291 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0493588 (* 1 = 0.0493588 loss)
I0831 11:23:57.659301 916722 sgd_solver.cpp:106] Iteration 2997000, lr = 0.01
I0831 11:24:27.395287 916722 solver.cpp:218] Iteration 2997500 (16.8146 iter/s, 29.7361s/500 iters), loss = 0.0664334
I0831 11:24:27.395339 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0664379 (* 1 = 0.0664379 loss)
I0831 11:24:27.395349 916722 sgd_solver.cpp:106] Iteration 2997500, lr = 0.01
I0831 11:24:57.134083 916722 solver.cpp:218] Iteration 2998000 (16.8131 iter/s, 29.7388s/500 iters), loss = 0.0313373
I0831 11:24:57.134138 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0313418 (* 1 = 0.0313418 loss)
I0831 11:24:57.134146 916722 sgd_solver.cpp:106] Iteration 2998000, lr = 0.01
I0831 11:25:26.869554 916722 solver.cpp:218] Iteration 2998500 (16.8149 iter/s, 29.7355s/500 iters), loss = 0.205247
I0831 11:25:26.869601 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.205251 (* 1 = 0.205251 loss)
I0831 11:25:26.869609 916722 sgd_solver.cpp:106] Iteration 2998500, lr = 0.01
I0831 11:25:56.606675 916722 solver.cpp:218] Iteration 2999000 (16.814 iter/s, 29.7371s/500 iters), loss = 0.0205628
I0831 11:25:56.606734 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0205673 (* 1 = 0.0205673 loss)
I0831 11:25:56.606742 916722 sgd_solver.cpp:106] Iteration 2999000, lr = 0.01
I0831 11:26:26.344086 916722 solver.cpp:218] Iteration 2999500 (16.8138 iter/s, 29.7374s/500 iters), loss = 0.133583
I0831 11:26:26.344139 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133588 (* 1 = 0.133588 loss)
I0831 11:26:26.344149 916722 sgd_solver.cpp:106] Iteration 2999500, lr = 0.01
I0831 11:26:56.019366 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_3000000.caffemodel
I0831 11:26:56.038717 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_3000000.solverstate
I0831 11:26:56.044780 916722 solver.cpp:330] Iteration 3000000, Testing net (#0)
I0831 11:27:11.379137 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8824
I0831 11:27:11.379181 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.390001 (* 1 = 0.390001 loss)
I0831 11:27:11.437880 916722 solver.cpp:218] Iteration 3000000 (11.088 iter/s, 45.0938s/500 iters), loss = 0.20862
I0831 11:27:11.437906 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.208624 (* 1 = 0.208624 loss)
I0831 11:27:11.437914 916722 sgd_solver.cpp:106] Iteration 3000000, lr = 0.01
I0831 11:27:41.160055 916722 solver.cpp:218] Iteration 3000500 (16.8225 iter/s, 29.7221s/500 iters), loss = 0.179752
I0831 11:27:41.160109 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.179756 (* 1 = 0.179756 loss)
I0831 11:27:41.160117 916722 sgd_solver.cpp:106] Iteration 3000500, lr = 0.01
I0831 11:28:10.885943 916722 solver.cpp:218] Iteration 3001000 (16.8204 iter/s, 29.7258s/500 iters), loss = 0.240489
I0831 11:28:10.885996 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.240494 (* 1 = 0.240494 loss)
I0831 11:28:10.886006 916722 sgd_solver.cpp:106] Iteration 3001000, lr = 0.01
I0831 11:28:40.617085 916722 solver.cpp:218] Iteration 3001500 (16.8174 iter/s, 29.7311s/500 iters), loss = 0.095835
I0831 11:28:40.617144 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0958395 (* 1 = 0.0958395 loss)
I0831 11:28:40.617152 916722 sgd_solver.cpp:106] Iteration 3001500, lr = 0.01
I0831 11:29:10.349308 916722 solver.cpp:218] Iteration 3002000 (16.8168 iter/s, 29.7322s/500 iters), loss = 0.0832879
I0831 11:29:10.349371 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0832924 (* 1 = 0.0832924 loss)
I0831 11:29:10.349381 916722 sgd_solver.cpp:106] Iteration 3002000, lr = 0.01
I0831 11:29:40.081313 916722 solver.cpp:218] Iteration 3002500 (16.8169 iter/s, 29.732s/500 iters), loss = 0.0455691
I0831 11:29:40.081384 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0455736 (* 1 = 0.0455736 loss)
I0831 11:29:40.081393 916722 sgd_solver.cpp:106] Iteration 3002500, lr = 0.01
I0831 11:30:09.815557 916722 solver.cpp:218] Iteration 3003000 (16.8157 iter/s, 29.7342s/500 iters), loss = 0.154118
I0831 11:30:09.815610 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.154123 (* 1 = 0.154123 loss)
I0831 11:30:09.815620 916722 sgd_solver.cpp:106] Iteration 3003000, lr = 0.01
I0831 11:30:39.549672 916722 solver.cpp:218] Iteration 3003500 (16.8157 iter/s, 29.7341s/500 iters), loss = 0.0418231
I0831 11:30:39.549731 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0418276 (* 1 = 0.0418276 loss)
I0831 11:30:39.549739 916722 sgd_solver.cpp:106] Iteration 3003500, lr = 0.01
I0831 11:31:09.283473 916722 solver.cpp:218] Iteration 3004000 (16.8159 iter/s, 29.7338s/500 iters), loss = 0.157975
I0831 11:31:09.283524 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.157979 (* 1 = 0.157979 loss)
I0831 11:31:09.283535 916722 sgd_solver.cpp:106] Iteration 3004000, lr = 0.01
I0831 11:31:39.016834 916722 solver.cpp:218] Iteration 3004500 (16.8162 iter/s, 29.7333s/500 iters), loss = 0.0618995
I0831 11:31:39.016891 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.061904 (* 1 = 0.061904 loss)
I0831 11:31:39.016898 916722 sgd_solver.cpp:106] Iteration 3004500, lr = 0.01
I0831 11:32:08.756209 916722 solver.cpp:218] Iteration 3005000 (16.8128 iter/s, 29.7393s/500 iters), loss = 0.0464862
I0831 11:32:08.756263 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0464906 (* 1 = 0.0464906 loss)
I0831 11:32:08.756273 916722 sgd_solver.cpp:106] Iteration 3005000, lr = 0.01
I0831 11:32:38.493603 916722 solver.cpp:218] Iteration 3005500 (16.8139 iter/s, 29.7373s/500 iters), loss = 0.268637
I0831 11:32:38.493665 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.268642 (* 1 = 0.268642 loss)
I0831 11:32:38.493674 916722 sgd_solver.cpp:106] Iteration 3005500, lr = 0.01
I0831 11:33:08.228627 916722 solver.cpp:218] Iteration 3006000 (16.8152 iter/s, 29.735s/500 iters), loss = 0.00320996
I0831 11:33:08.228682 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.00321457 (* 1 = 0.00321457 loss)
I0831 11:33:08.228690 916722 sgd_solver.cpp:106] Iteration 3006000, lr = 0.01
I0831 11:33:37.965601 916722 solver.cpp:218] Iteration 3006500 (16.8141 iter/s, 29.7369s/500 iters), loss = 0.0554116
I0831 11:33:37.965658 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0554162 (* 1 = 0.0554162 loss)
I0831 11:33:37.965667 916722 sgd_solver.cpp:106] Iteration 3006500, lr = 0.01
I0831 11:34:07.699579 916722 solver.cpp:218] Iteration 3007000 (16.8158 iter/s, 29.7339s/500 iters), loss = 0.209289
I0831 11:34:07.699630 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.209294 (* 1 = 0.209294 loss)
I0831 11:34:07.699638 916722 sgd_solver.cpp:106] Iteration 3007000, lr = 0.01
I0831 11:34:37.432782 916722 solver.cpp:218] Iteration 3007500 (16.8162 iter/s, 29.7331s/500 iters), loss = 0.215737
I0831 11:34:37.432839 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.215741 (* 1 = 0.215741 loss)
I0831 11:34:37.432847 916722 sgd_solver.cpp:106] Iteration 3007500, lr = 0.01
I0831 11:35:07.168149 916722 solver.cpp:218] Iteration 3008000 (16.815 iter/s, 29.7353s/500 iters), loss = 0.223935
I0831 11:35:07.168201 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.22394 (* 1 = 0.22394 loss)
I0831 11:35:07.168210 916722 sgd_solver.cpp:106] Iteration 3008000, lr = 0.01
I0831 11:35:36.901499 916722 solver.cpp:218] Iteration 3008500 (16.8162 iter/s, 29.7333s/500 iters), loss = 0.0431026
I0831 11:35:36.901569 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0431074 (* 1 = 0.0431074 loss)
I0831 11:35:36.901577 916722 sgd_solver.cpp:106] Iteration 3008500, lr = 0.01
I0831 11:36:06.634935 916722 solver.cpp:218] Iteration 3009000 (16.8161 iter/s, 29.7333s/500 iters), loss = 0.0548829
I0831 11:36:06.634984 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0548878 (* 1 = 0.0548878 loss)
I0831 11:36:06.634992 916722 sgd_solver.cpp:106] Iteration 3009000, lr = 0.01
I0831 11:36:36.371446 916722 solver.cpp:218] Iteration 3009500 (16.8144 iter/s, 29.7364s/500 iters), loss = 0.075239
I0831 11:36:36.371505 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0752439 (* 1 = 0.0752439 loss)
I0831 11:36:36.371515 916722 sgd_solver.cpp:106] Iteration 3009500, lr = 0.01
I0831 11:37:06.105525 916722 solver.cpp:218] Iteration 3010000 (16.8158 iter/s, 29.734s/500 iters), loss = 0.0455732
I0831 11:37:06.105581 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.045578 (* 1 = 0.045578 loss)
I0831 11:37:06.105590 916722 sgd_solver.cpp:106] Iteration 3010000, lr = 0.01
I0831 11:37:35.839320 916722 solver.cpp:218] Iteration 3010500 (16.8159 iter/s, 29.7337s/500 iters), loss = 0.143068
I0831 11:37:35.839378 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.143073 (* 1 = 0.143073 loss)
I0831 11:37:35.839386 916722 sgd_solver.cpp:106] Iteration 3010500, lr = 0.01
I0831 11:38:05.574404 916722 solver.cpp:218] Iteration 3011000 (16.8152 iter/s, 29.735s/500 iters), loss = 0.0908852
I0831 11:38:05.574460 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0908898 (* 1 = 0.0908898 loss)
I0831 11:38:05.574470 916722 sgd_solver.cpp:106] Iteration 3011000, lr = 0.01
I0831 11:38:35.309973 916722 solver.cpp:218] Iteration 3011500 (16.8149 iter/s, 29.7355s/500 iters), loss = 0.269051
I0831 11:38:35.310029 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.269055 (* 1 = 0.269055 loss)
I0831 11:38:35.310037 916722 sgd_solver.cpp:106] Iteration 3011500, lr = 0.01
I0831 11:39:05.039865 916722 solver.cpp:218] Iteration 3012000 (16.8181 iter/s, 29.7298s/500 iters), loss = 0.06406
I0831 11:39:05.039914 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0640646 (* 1 = 0.0640646 loss)
I0831 11:39:05.039924 916722 sgd_solver.cpp:106] Iteration 3012000, lr = 0.01
I0831 11:39:34.773454 916722 solver.cpp:218] Iteration 3012500 (16.816 iter/s, 29.7335s/500 iters), loss = 0.0382044
I0831 11:39:34.773512 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.038209 (* 1 = 0.038209 loss)
I0831 11:39:34.773520 916722 sgd_solver.cpp:106] Iteration 3012500, lr = 0.01
I0831 11:40:04.506376 916722 solver.cpp:218] Iteration 3013000 (16.8164 iter/s, 29.7328s/500 iters), loss = 0.263381
I0831 11:40:04.506426 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.263386 (* 1 = 0.263386 loss)
I0831 11:40:04.506436 916722 sgd_solver.cpp:106] Iteration 3013000, lr = 0.01
I0831 11:40:34.245934 916722 solver.cpp:218] Iteration 3013500 (16.8127 iter/s, 29.7395s/500 iters), loss = 0.0634896
I0831 11:40:34.245990 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0634946 (* 1 = 0.0634946 loss)
I0831 11:40:34.245998 916722 sgd_solver.cpp:106] Iteration 3013500, lr = 0.01
I0831 11:41:03.978556 916722 solver.cpp:218] Iteration 3014000 (16.8166 iter/s, 29.7325s/500 iters), loss = 0.149869
I0831 11:41:03.978606 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.149874 (* 1 = 0.149874 loss)
I0831 11:41:03.978616 916722 sgd_solver.cpp:106] Iteration 3014000, lr = 0.01
I0831 11:41:33.711014 916722 solver.cpp:218] Iteration 3014500 (16.8167 iter/s, 29.7324s/500 iters), loss = 0.0689811
I0831 11:41:33.711078 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0689861 (* 1 = 0.0689861 loss)
I0831 11:41:33.711087 916722 sgd_solver.cpp:106] Iteration 3014500, lr = 0.01
I0831 11:42:03.446768 916722 solver.cpp:218] Iteration 3015000 (16.8148 iter/s, 29.7357s/500 iters), loss = 0.083429
I0831 11:42:03.446816 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.083434 (* 1 = 0.083434 loss)
I0831 11:42:03.446838 916722 sgd_solver.cpp:106] Iteration 3015000, lr = 0.01
I0831 11:42:33.183008 916722 solver.cpp:218] Iteration 3015500 (16.8145 iter/s, 29.7362s/500 iters), loss = 0.135118
I0831 11:42:33.183076 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.135124 (* 1 = 0.135124 loss)
I0831 11:42:33.183084 916722 sgd_solver.cpp:106] Iteration 3015500, lr = 0.01
I0831 11:43:02.921409 916722 solver.cpp:218] Iteration 3016000 (16.8133 iter/s, 29.7383s/500 iters), loss = 0.0670114
I0831 11:43:02.921459 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0670164 (* 1 = 0.0670164 loss)
I0831 11:43:02.921469 916722 sgd_solver.cpp:106] Iteration 3016000, lr = 0.01
I0831 11:43:32.659860 916722 solver.cpp:218] Iteration 3016500 (16.8133 iter/s, 29.7384s/500 iters), loss = 0.0955137
I0831 11:43:32.659915 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0955188 (* 1 = 0.0955188 loss)
I0831 11:43:32.659924 916722 sgd_solver.cpp:106] Iteration 3016500, lr = 0.01
I0831 11:44:02.398227 916722 solver.cpp:218] Iteration 3017000 (16.8133 iter/s, 29.7383s/500 iters), loss = 0.227275
I0831 11:44:02.398278 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.22728 (* 1 = 0.22728 loss)
I0831 11:44:02.398288 916722 sgd_solver.cpp:106] Iteration 3017000, lr = 0.01
I0831 11:44:32.131517 916722 solver.cpp:218] Iteration 3017500 (16.8162 iter/s, 29.7332s/500 iters), loss = 0.0521127
I0831 11:44:32.131575 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0521178 (* 1 = 0.0521178 loss)
I0831 11:44:32.131583 916722 sgd_solver.cpp:106] Iteration 3017500, lr = 0.01
I0831 11:45:01.866015 916722 solver.cpp:218] Iteration 3018000 (16.8155 iter/s, 29.7344s/500 iters), loss = 0.0796443
I0831 11:45:01.866065 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0796495 (* 1 = 0.0796495 loss)
I0831 11:45:01.866076 916722 sgd_solver.cpp:106] Iteration 3018000, lr = 0.01
I0831 11:45:31.604136 916722 solver.cpp:218] Iteration 3018500 (16.8135 iter/s, 29.738s/500 iters), loss = 0.123814
I0831 11:45:31.604194 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.123819 (* 1 = 0.123819 loss)
I0831 11:45:31.604202 916722 sgd_solver.cpp:106] Iteration 3018500, lr = 0.01
I0831 11:46:01.338106 916722 solver.cpp:218] Iteration 3019000 (16.8161 iter/s, 29.7335s/500 iters), loss = 0.0551309
I0831 11:46:01.338156 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0551361 (* 1 = 0.0551361 loss)
I0831 11:46:01.338167 916722 sgd_solver.cpp:106] Iteration 3019000, lr = 0.01
I0831 11:46:31.072600 916722 solver.cpp:218] Iteration 3019500 (16.8159 iter/s, 29.7338s/500 iters), loss = 0.182843
I0831 11:46:31.072660 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.182848 (* 1 = 0.182848 loss)
I0831 11:46:31.072669 916722 sgd_solver.cpp:106] Iteration 3019500, lr = 0.01
I0831 11:47:00.811610 916722 solver.cpp:218] Iteration 3020000 (16.8133 iter/s, 29.7384s/500 iters), loss = 0.076854
I0831 11:47:00.811661 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0768592 (* 1 = 0.0768592 loss)
I0831 11:47:00.811671 916722 sgd_solver.cpp:106] Iteration 3020000, lr = 0.01
I0831 11:47:30.548120 916722 solver.cpp:218] Iteration 3020500 (16.8147 iter/s, 29.7359s/500 iters), loss = 0.173606
I0831 11:47:30.548182 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.173611 (* 1 = 0.173611 loss)
I0831 11:47:30.548192 916722 sgd_solver.cpp:106] Iteration 3020500, lr = 0.01
I0831 11:48:00.283910 916722 solver.cpp:218] Iteration 3021000 (16.8151 iter/s, 29.7352s/500 iters), loss = 0.0278594
I0831 11:48:00.283963 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0278645 (* 1 = 0.0278645 loss)
I0831 11:48:00.283972 916722 sgd_solver.cpp:106] Iteration 3021000, lr = 0.01
I0831 11:48:30.021675 916722 solver.cpp:218] Iteration 3021500 (16.8139 iter/s, 29.7372s/500 iters), loss = 0.141327
I0831 11:48:30.021749 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.141332 (* 1 = 0.141332 loss)
I0831 11:48:30.021761 916722 sgd_solver.cpp:106] Iteration 3021500, lr = 0.01
I0831 11:48:59.764163 916722 solver.cpp:218] Iteration 3022000 (16.8113 iter/s, 29.7419s/500 iters), loss = 0.394474
I0831 11:48:59.764214 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.394479 (* 1 = 0.394479 loss)
I0831 11:48:59.764223 916722 sgd_solver.cpp:106] Iteration 3022000, lr = 0.01
I0831 11:49:29.497823 916722 solver.cpp:218] Iteration 3022500 (16.8162 iter/s, 29.7332s/500 iters), loss = 0.24256
I0831 11:49:29.497884 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.242565 (* 1 = 0.242565 loss)
I0831 11:49:29.497891 916722 sgd_solver.cpp:106] Iteration 3022500, lr = 0.01
I0831 11:49:59.229257 916722 solver.cpp:218] Iteration 3023000 (16.8175 iter/s, 29.7309s/500 iters), loss = 0.0314778
I0831 11:49:59.229310 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0314832 (* 1 = 0.0314832 loss)
I0831 11:49:59.229319 916722 sgd_solver.cpp:106] Iteration 3023000, lr = 0.01
I0831 11:50:28.961136 916722 solver.cpp:218] Iteration 3023500 (16.8172 iter/s, 29.7314s/500 iters), loss = 0.0940004
I0831 11:50:28.961197 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0940057 (* 1 = 0.0940057 loss)
I0831 11:50:28.961205 916722 sgd_solver.cpp:106] Iteration 3023500, lr = 0.01
I0831 11:50:58.696080 916722 solver.cpp:218] Iteration 3024000 (16.8155 iter/s, 29.7345s/500 iters), loss = 0.156468
I0831 11:50:58.696133 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.156473 (* 1 = 0.156473 loss)
I0831 11:50:58.696142 916722 sgd_solver.cpp:106] Iteration 3024000, lr = 0.01
I0831 11:51:28.427621 916722 solver.cpp:218] Iteration 3024500 (16.8174 iter/s, 29.7311s/500 iters), loss = 0.0307285
I0831 11:51:28.427681 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0307339 (* 1 = 0.0307339 loss)
I0831 11:51:28.427690 916722 sgd_solver.cpp:106] Iteration 3024500, lr = 0.01
I0831 11:51:58.162001 916722 solver.cpp:218] Iteration 3025000 (16.8158 iter/s, 29.7339s/500 iters), loss = 0.189421
I0831 11:51:58.162055 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.189426 (* 1 = 0.189426 loss)
I0831 11:51:58.162063 916722 sgd_solver.cpp:106] Iteration 3025000, lr = 0.01
I0831 11:52:27.891645 916722 solver.cpp:218] Iteration 3025500 (16.8185 iter/s, 29.7292s/500 iters), loss = 0.199986
I0831 11:52:27.891703 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.199991 (* 1 = 0.199991 loss)
I0831 11:52:27.891711 916722 sgd_solver.cpp:106] Iteration 3025500, lr = 0.01
I0831 11:52:57.622656 916722 solver.cpp:218] Iteration 3026000 (16.8177 iter/s, 29.7306s/500 iters), loss = 0.266629
I0831 11:52:57.622710 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.266635 (* 1 = 0.266635 loss)
I0831 11:52:57.622721 916722 sgd_solver.cpp:106] Iteration 3026000, lr = 0.01
I0831 11:53:27.357043 916722 solver.cpp:218] Iteration 3026500 (16.8158 iter/s, 29.734s/500 iters), loss = 0.265007
I0831 11:53:27.357098 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.265012 (* 1 = 0.265012 loss)
I0831 11:53:27.357106 916722 sgd_solver.cpp:106] Iteration 3026500, lr = 0.01
I0831 11:53:57.088001 916722 solver.cpp:218] Iteration 3027000 (16.8177 iter/s, 29.7306s/500 iters), loss = 0.0459376
I0831 11:53:57.088055 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0459428 (* 1 = 0.0459428 loss)
I0831 11:53:57.088065 916722 sgd_solver.cpp:106] Iteration 3027000, lr = 0.01
I0831 11:54:26.818248 916722 solver.cpp:218] Iteration 3027500 (16.8181 iter/s, 29.7299s/500 iters), loss = 0.0239026
I0831 11:54:26.818307 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0239078 (* 1 = 0.0239078 loss)
I0831 11:54:26.818315 916722 sgd_solver.cpp:106] Iteration 3027500, lr = 0.01
I0831 11:54:56.548207 916722 solver.cpp:218] Iteration 3028000 (16.8182 iter/s, 29.7296s/500 iters), loss = 0.0639136
I0831 11:54:56.548259 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0639189 (* 1 = 0.0639189 loss)
I0831 11:54:56.548282 916722 sgd_solver.cpp:106] Iteration 3028000, lr = 0.01
I0831 11:55:26.276674 916722 solver.cpp:218] Iteration 3028500 (16.8191 iter/s, 29.7281s/500 iters), loss = 0.0709478
I0831 11:55:26.276757 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0709533 (* 1 = 0.0709533 loss)
I0831 11:55:26.276765 916722 sgd_solver.cpp:106] Iteration 3028500, lr = 0.01
I0831 11:55:56.003057 916722 solver.cpp:218] Iteration 3029000 (16.8203 iter/s, 29.726s/500 iters), loss = 0.0466552
I0831 11:55:56.003109 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0466607 (* 1 = 0.0466607 loss)
I0831 11:55:56.003119 916722 sgd_solver.cpp:106] Iteration 3029000, lr = 0.01
I0831 11:56:25.733063 916722 solver.cpp:218] Iteration 3029500 (16.8182 iter/s, 29.7297s/500 iters), loss = 0.0435761
I0831 11:56:25.733122 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0435817 (* 1 = 0.0435817 loss)
I0831 11:56:25.733131 916722 sgd_solver.cpp:106] Iteration 3029500, lr = 0.01
I0831 11:56:55.458941 916722 solver.cpp:218] Iteration 3030000 (16.8205 iter/s, 29.7256s/500 iters), loss = 0.152313
I0831 11:56:55.458994 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152318 (* 1 = 0.152318 loss)
I0831 11:56:55.459003 916722 sgd_solver.cpp:106] Iteration 3030000, lr = 0.01
I0831 11:57:25.188045 916722 solver.cpp:218] Iteration 3030500 (16.8187 iter/s, 29.7288s/500 iters), loss = 0.175955
I0831 11:57:25.188107 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.175961 (* 1 = 0.175961 loss)
I0831 11:57:25.188115 916722 sgd_solver.cpp:106] Iteration 3030500, lr = 0.01
I0831 11:57:54.915261 916722 solver.cpp:218] Iteration 3031000 (16.8198 iter/s, 29.7269s/500 iters), loss = 0.0979291
I0831 11:57:54.915310 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0979349 (* 1 = 0.0979349 loss)
I0831 11:57:54.915319 916722 sgd_solver.cpp:106] Iteration 3031000, lr = 0.01
I0831 11:58:24.645325 916722 solver.cpp:218] Iteration 3031500 (16.8181 iter/s, 29.7298s/500 iters), loss = 0.12556
I0831 11:58:24.645383 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.125566 (* 1 = 0.125566 loss)
I0831 11:58:24.645391 916722 sgd_solver.cpp:106] Iteration 3031500, lr = 0.01
I0831 11:58:54.374398 916722 solver.cpp:218] Iteration 3032000 (16.8187 iter/s, 29.7288s/500 iters), loss = 0.0490057
I0831 11:58:54.374452 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0490116 (* 1 = 0.0490116 loss)
I0831 11:58:54.374460 916722 sgd_solver.cpp:106] Iteration 3032000, lr = 0.01
I0831 11:59:24.104648 916722 solver.cpp:218] Iteration 3032500 (16.818 iter/s, 29.73s/500 iters), loss = 0.0940091
I0831 11:59:24.104710 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0940149 (* 1 = 0.0940149 loss)
I0831 11:59:24.104719 916722 sgd_solver.cpp:106] Iteration 3032500, lr = 0.01
I0831 11:59:53.832762 916722 solver.cpp:218] Iteration 3033000 (16.8193 iter/s, 29.7278s/500 iters), loss = 0.222277
I0831 11:59:53.832813 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.222282 (* 1 = 0.222282 loss)
I0831 11:59:53.832823 916722 sgd_solver.cpp:106] Iteration 3033000, lr = 0.01
I0831 12:00:23.562129 916722 solver.cpp:218] Iteration 3033500 (16.8185 iter/s, 29.7291s/500 iters), loss = 0.134773
I0831 12:00:23.562187 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.134779 (* 1 = 0.134779 loss)
I0831 12:00:23.562196 916722 sgd_solver.cpp:106] Iteration 3033500, lr = 0.01
I0831 12:00:53.289634 916722 solver.cpp:218] Iteration 3034000 (16.8196 iter/s, 29.7272s/500 iters), loss = 0.317248
I0831 12:00:53.289686 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.317254 (* 1 = 0.317254 loss)
I0831 12:00:53.289695 916722 sgd_solver.cpp:106] Iteration 3034000, lr = 0.01
I0831 12:01:23.020542 916722 solver.cpp:218] Iteration 3034500 (16.8177 iter/s, 29.7307s/500 iters), loss = 0.217144
I0831 12:01:23.020612 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.21715 (* 1 = 0.21715 loss)
I0831 12:01:23.020620 916722 sgd_solver.cpp:106] Iteration 3034500, lr = 0.01
I0831 12:01:52.752780 916722 solver.cpp:218] Iteration 3035000 (16.8169 iter/s, 29.732s/500 iters), loss = 0.0434908
I0831 12:01:52.752831 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0434968 (* 1 = 0.0434968 loss)
I0831 12:01:52.752840 916722 sgd_solver.cpp:106] Iteration 3035000, lr = 0.01
I0831 12:02:22.486482 916722 solver.cpp:218] Iteration 3035500 (16.8161 iter/s, 29.7335s/500 iters), loss = 0.182165
I0831 12:02:22.486537 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.182171 (* 1 = 0.182171 loss)
I0831 12:02:22.486546 916722 sgd_solver.cpp:106] Iteration 3035500, lr = 0.01
I0831 12:02:52.212579 916722 solver.cpp:218] Iteration 3036000 (16.8204 iter/s, 29.7259s/500 iters), loss = 0.166772
I0831 12:02:52.212633 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.166778 (* 1 = 0.166778 loss)
I0831 12:02:52.212642 916722 sgd_solver.cpp:106] Iteration 3036000, lr = 0.01
I0831 12:03:21.941309 916722 solver.cpp:218] Iteration 3036500 (16.8189 iter/s, 29.7285s/500 iters), loss = 0.226548
I0831 12:03:21.941370 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.226555 (* 1 = 0.226555 loss)
I0831 12:03:21.941378 916722 sgd_solver.cpp:106] Iteration 3036500, lr = 0.01
I0831 12:03:51.669313 916722 solver.cpp:218] Iteration 3037000 (16.8193 iter/s, 29.7278s/500 iters), loss = 0.0661463
I0831 12:03:51.669368 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0661526 (* 1 = 0.0661526 loss)
I0831 12:03:51.669376 916722 sgd_solver.cpp:106] Iteration 3037000, lr = 0.01
I0831 12:04:21.397856 916722 solver.cpp:218] Iteration 3037500 (16.819 iter/s, 29.7283s/500 iters), loss = 0.176684
I0831 12:04:21.397917 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.17669 (* 1 = 0.17669 loss)
I0831 12:04:21.397925 916722 sgd_solver.cpp:106] Iteration 3037500, lr = 0.01
I0831 12:04:51.125291 916722 solver.cpp:218] Iteration 3038000 (16.8196 iter/s, 29.7272s/500 iters), loss = 0.0270697
I0831 12:04:51.125344 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.027076 (* 1 = 0.027076 loss)
I0831 12:04:51.125353 916722 sgd_solver.cpp:106] Iteration 3038000, lr = 0.01
I0831 12:05:20.855916 916722 solver.cpp:218] Iteration 3038500 (16.8178 iter/s, 29.7304s/500 iters), loss = 0.121535
I0831 12:05:20.855975 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.121542 (* 1 = 0.121542 loss)
I0831 12:05:20.855984 916722 sgd_solver.cpp:106] Iteration 3038500, lr = 0.01
I0831 12:05:50.587118 916722 solver.cpp:218] Iteration 3039000 (16.8175 iter/s, 29.731s/500 iters), loss = 0.084646
I0831 12:05:50.587172 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0846523 (* 1 = 0.0846523 loss)
I0831 12:05:50.587182 916722 sgd_solver.cpp:106] Iteration 3039000, lr = 0.01
I0831 12:06:20.317098 916722 solver.cpp:218] Iteration 3039500 (16.8182 iter/s, 29.7298s/500 iters), loss = 0.232876
I0831 12:06:20.317157 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.232882 (* 1 = 0.232882 loss)
I0831 12:06:20.317165 916722 sgd_solver.cpp:106] Iteration 3039500, lr = 0.01
I0831 12:06:50.045751 916722 solver.cpp:218] Iteration 3040000 (16.8189 iter/s, 29.7284s/500 iters), loss = 0.0885108
I0831 12:06:50.045809 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0885171 (* 1 = 0.0885171 loss)
I0831 12:06:50.045819 916722 sgd_solver.cpp:106] Iteration 3040000, lr = 0.01
I0831 12:07:19.778313 916722 solver.cpp:218] Iteration 3040500 (16.8167 iter/s, 29.7323s/500 iters), loss = 0.25215
I0831 12:07:19.778371 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.252156 (* 1 = 0.252156 loss)
I0831 12:07:19.778380 916722 sgd_solver.cpp:106] Iteration 3040500, lr = 0.01
I0831 12:07:49.507488 916722 solver.cpp:218] Iteration 3041000 (16.8186 iter/s, 29.729s/500 iters), loss = 0.030784
I0831 12:07:49.507540 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0307903 (* 1 = 0.0307903 loss)
I0831 12:07:49.507550 916722 sgd_solver.cpp:106] Iteration 3041000, lr = 0.01
I0831 12:08:19.238019 916722 solver.cpp:218] Iteration 3041500 (16.8178 iter/s, 29.7303s/500 iters), loss = 0.0979053
I0831 12:08:19.238095 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0979115 (* 1 = 0.0979115 loss)
I0831 12:08:19.238102 916722 sgd_solver.cpp:106] Iteration 3041500, lr = 0.01
I0831 12:08:48.982897 916722 solver.cpp:218] Iteration 3042000 (16.8097 iter/s, 29.7447s/500 iters), loss = 0.235197
I0831 12:08:48.982959 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.235203 (* 1 = 0.235203 loss)
I0831 12:08:48.982969 916722 sgd_solver.cpp:106] Iteration 3042000, lr = 0.01
I0831 12:09:18.717000 916722 solver.cpp:218] Iteration 3042500 (16.8158 iter/s, 29.7339s/500 iters), loss = 0.11536
I0831 12:09:18.717062 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115367 (* 1 = 0.115367 loss)
I0831 12:09:18.717070 916722 sgd_solver.cpp:106] Iteration 3042500, lr = 0.01
I0831 12:09:48.447355 916722 solver.cpp:218] Iteration 3043000 (16.8179 iter/s, 29.7302s/500 iters), loss = 0.295232
I0831 12:09:48.447407 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.295238 (* 1 = 0.295238 loss)
I0831 12:09:48.447417 916722 sgd_solver.cpp:106] Iteration 3043000, lr = 0.01
I0831 12:10:18.179350 916722 solver.cpp:218] Iteration 3043500 (16.817 iter/s, 29.7318s/500 iters), loss = 0.236001
I0831 12:10:18.179410 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.236008 (* 1 = 0.236008 loss)
I0831 12:10:18.179419 916722 sgd_solver.cpp:106] Iteration 3043500, lr = 0.01
I0831 12:10:47.914541 916722 solver.cpp:218] Iteration 3044000 (16.8152 iter/s, 29.735s/500 iters), loss = 0.199255
I0831 12:10:47.914595 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.199262 (* 1 = 0.199262 loss)
I0831 12:10:47.914605 916722 sgd_solver.cpp:106] Iteration 3044000, lr = 0.01
I0831 12:11:17.645676 916722 solver.cpp:218] Iteration 3044500 (16.8175 iter/s, 29.7309s/500 iters), loss = 0.123542
I0831 12:11:17.645737 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.123548 (* 1 = 0.123548 loss)
I0831 12:11:17.645746 916722 sgd_solver.cpp:106] Iteration 3044500, lr = 0.01
I0831 12:11:47.377269 916722 solver.cpp:218] Iteration 3045000 (16.8172 iter/s, 29.7314s/500 iters), loss = 0.33986
I0831 12:11:47.377324 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.339867 (* 1 = 0.339867 loss)
I0831 12:11:47.377334 916722 sgd_solver.cpp:106] Iteration 3045000, lr = 0.01
I0831 12:12:17.112622 916722 solver.cpp:218] Iteration 3045500 (16.8151 iter/s, 29.7352s/500 iters), loss = 0.200493
I0831 12:12:17.112689 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.2005 (* 1 = 0.2005 loss)
I0831 12:12:17.112697 916722 sgd_solver.cpp:106] Iteration 3045500, lr = 0.01
I0831 12:12:46.845741 916722 solver.cpp:218] Iteration 3046000 (16.8164 iter/s, 29.7329s/500 iters), loss = 0.130502
I0831 12:12:46.845794 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130509 (* 1 = 0.130509 loss)
I0831 12:12:46.845803 916722 sgd_solver.cpp:106] Iteration 3046000, lr = 0.01
I0831 12:13:16.577148 916722 solver.cpp:218] Iteration 3046500 (16.8173 iter/s, 29.7312s/500 iters), loss = 0.248358
I0831 12:13:16.577204 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.248365 (* 1 = 0.248365 loss)
I0831 12:13:16.577214 916722 sgd_solver.cpp:106] Iteration 3046500, lr = 0.01
I0831 12:13:46.312220 916722 solver.cpp:218] Iteration 3047000 (16.8153 iter/s, 29.7349s/500 iters), loss = 0.201159
I0831 12:13:46.312273 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.201166 (* 1 = 0.201166 loss)
I0831 12:13:46.312281 916722 sgd_solver.cpp:106] Iteration 3047000, lr = 0.01
I0831 12:14:16.053241 916722 solver.cpp:218] Iteration 3047500 (16.8119 iter/s, 29.7408s/500 iters), loss = 0.249036
I0831 12:14:16.053300 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.249043 (* 1 = 0.249043 loss)
I0831 12:14:16.053308 916722 sgd_solver.cpp:106] Iteration 3047500, lr = 0.01
I0831 12:14:45.791709 916722 solver.cpp:218] Iteration 3048000 (16.8133 iter/s, 29.7383s/500 iters), loss = 0.15161
I0831 12:14:45.791777 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.151617 (* 1 = 0.151617 loss)
I0831 12:14:45.791786 916722 sgd_solver.cpp:106] Iteration 3048000, lr = 0.01
I0831 12:15:15.528240 916722 solver.cpp:218] Iteration 3048500 (16.8144 iter/s, 29.7363s/500 iters), loss = 0.167833
I0831 12:15:15.528313 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.167839 (* 1 = 0.167839 loss)
I0831 12:15:15.528322 916722 sgd_solver.cpp:106] Iteration 3048500, lr = 0.01
I0831 12:15:45.271227 916722 solver.cpp:218] Iteration 3049000 (16.8108 iter/s, 29.7428s/500 iters), loss = 0.110349
I0831 12:15:45.271281 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110356 (* 1 = 0.110356 loss)
I0831 12:15:45.271291 916722 sgd_solver.cpp:106] Iteration 3049000, lr = 0.01
I0831 12:16:15.017431 916722 solver.cpp:218] Iteration 3049500 (16.809 iter/s, 29.746s/500 iters), loss = 0.133153
I0831 12:16:15.017488 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13316 (* 1 = 0.13316 loss)
I0831 12:16:15.017498 916722 sgd_solver.cpp:106] Iteration 3049500, lr = 0.01
I0831 12:16:44.696286 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_3050000.caffemodel
I0831 12:16:44.715296 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_3050000.solverstate
I0831 12:16:44.721321 916722 solver.cpp:330] Iteration 3050000, Testing net (#0)
I0831 12:17:00.088465 916722 solver.cpp:397]     Test net output #0: accuracy = 0.866
I0831 12:17:00.088523 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.476452 (* 1 = 0.476452 loss)
I0831 12:17:00.146971 916722 solver.cpp:218] Iteration 3050000 (11.0793 iter/s, 45.1293s/500 iters), loss = 0.125957
I0831 12:17:00.146997 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.125964 (* 1 = 0.125964 loss)
I0831 12:17:00.147006 916722 sgd_solver.cpp:106] Iteration 3050000, lr = 0.01
I0831 12:17:29.875581 916722 solver.cpp:218] Iteration 3050500 (16.8189 iter/s, 29.7284s/500 iters), loss = 0.260031
I0831 12:17:29.875633 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.260037 (* 1 = 0.260037 loss)
I0831 12:17:29.875641 916722 sgd_solver.cpp:106] Iteration 3050500, lr = 0.01
I0831 12:17:59.605901 916722 solver.cpp:218] Iteration 3051000 (16.818 iter/s, 29.7301s/500 iters), loss = 0.0357879
I0831 12:17:59.605962 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0357947 (* 1 = 0.0357947 loss)
I0831 12:17:59.605971 916722 sgd_solver.cpp:106] Iteration 3051000, lr = 0.01
I0831 12:18:29.345525 916722 solver.cpp:218] Iteration 3051500 (16.8127 iter/s, 29.7394s/500 iters), loss = 0.121835
I0831 12:18:29.345577 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.121842 (* 1 = 0.121842 loss)
I0831 12:18:29.345585 916722 sgd_solver.cpp:106] Iteration 3051500, lr = 0.01
I0831 12:18:59.082962 916722 solver.cpp:218] Iteration 3052000 (16.8139 iter/s, 29.7373s/500 iters), loss = 0.139477
I0831 12:18:59.083021 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139484 (* 1 = 0.139484 loss)
I0831 12:18:59.083029 916722 sgd_solver.cpp:106] Iteration 3052000, lr = 0.01
I0831 12:19:28.816710 916722 solver.cpp:218] Iteration 3052500 (16.816 iter/s, 29.7336s/500 iters), loss = 0.25283
I0831 12:19:28.816763 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.252837 (* 1 = 0.252837 loss)
I0831 12:19:28.816771 916722 sgd_solver.cpp:106] Iteration 3052500, lr = 0.01
I0831 12:19:58.553582 916722 solver.cpp:218] Iteration 3053000 (16.8142 iter/s, 29.7367s/500 iters), loss = 0.157923
I0831 12:19:58.553638 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.15793 (* 1 = 0.15793 loss)
I0831 12:19:58.553647 916722 sgd_solver.cpp:106] Iteration 3053000, lr = 0.01
I0831 12:20:28.294685 916722 solver.cpp:218] Iteration 3053500 (16.8118 iter/s, 29.7411s/500 iters), loss = 0.2233
I0831 12:20:28.294739 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.223307 (* 1 = 0.223307 loss)
I0831 12:20:28.294759 916722 sgd_solver.cpp:106] Iteration 3053500, lr = 0.01
I0831 12:20:58.040891 916722 solver.cpp:218] Iteration 3054000 (16.8089 iter/s, 29.7462s/500 iters), loss = 0.0424423
I0831 12:20:58.040964 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0424489 (* 1 = 0.0424489 loss)
I0831 12:20:58.040973 916722 sgd_solver.cpp:106] Iteration 3054000, lr = 0.01
I0831 12:21:27.784420 916722 solver.cpp:218] Iteration 3054500 (16.8104 iter/s, 29.7435s/500 iters), loss = 0.168578
I0831 12:21:27.784476 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.168585 (* 1 = 0.168585 loss)
I0831 12:21:27.784484 916722 sgd_solver.cpp:106] Iteration 3054500, lr = 0.01
I0831 12:21:57.522219 916722 solver.cpp:218] Iteration 3055000 (16.8136 iter/s, 29.7378s/500 iters), loss = 0.0927444
I0831 12:21:57.522281 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.092751 (* 1 = 0.092751 loss)
I0831 12:21:57.522289 916722 sgd_solver.cpp:106] Iteration 3055000, lr = 0.01
I0831 12:22:27.266500 916722 solver.cpp:218] Iteration 3055500 (16.81 iter/s, 29.7442s/500 iters), loss = 0.082832
I0831 12:22:27.266556 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0828388 (* 1 = 0.0828388 loss)
I0831 12:22:27.266566 916722 sgd_solver.cpp:106] Iteration 3055500, lr = 0.01
I0831 12:22:57.011262 916722 solver.cpp:218] Iteration 3056000 (16.8097 iter/s, 29.7447s/500 iters), loss = 0.289809
I0831 12:22:57.011320 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.289816 (* 1 = 0.289816 loss)
I0831 12:22:57.011328 916722 sgd_solver.cpp:106] Iteration 3056000, lr = 0.01
I0831 12:23:26.753917 916722 solver.cpp:218] Iteration 3056500 (16.8109 iter/s, 29.7426s/500 iters), loss = 0.108082
I0831 12:23:26.753969 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.108089 (* 1 = 0.108089 loss)
I0831 12:23:26.753979 916722 sgd_solver.cpp:106] Iteration 3056500, lr = 0.01
I0831 12:23:56.495898 916722 solver.cpp:218] Iteration 3057000 (16.8113 iter/s, 29.7419s/500 iters), loss = 0.0718996
I0831 12:23:56.495956 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0719064 (* 1 = 0.0719064 loss)
I0831 12:23:56.495965 916722 sgd_solver.cpp:106] Iteration 3057000, lr = 0.01
I0831 12:24:26.235105 916722 solver.cpp:218] Iteration 3057500 (16.8129 iter/s, 29.7391s/500 iters), loss = 0.156908
I0831 12:24:26.235157 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.156915 (* 1 = 0.156915 loss)
I0831 12:24:26.235167 916722 sgd_solver.cpp:106] Iteration 3057500, lr = 0.01
I0831 12:24:55.984760 916722 solver.cpp:218] Iteration 3058000 (16.807 iter/s, 29.7496s/500 iters), loss = 0.145618
I0831 12:24:55.984819 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.145625 (* 1 = 0.145625 loss)
I0831 12:24:55.984827 916722 sgd_solver.cpp:106] Iteration 3058000, lr = 0.01
I0831 12:25:25.723930 916722 solver.cpp:218] Iteration 3058500 (16.8129 iter/s, 29.7391s/500 iters), loss = 0.0655686
I0831 12:25:25.723985 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0655754 (* 1 = 0.0655754 loss)
I0831 12:25:25.723995 916722 sgd_solver.cpp:106] Iteration 3058500, lr = 0.01
I0831 12:25:55.467803 916722 solver.cpp:218] Iteration 3059000 (16.8102 iter/s, 29.7438s/500 iters), loss = 0.337884
I0831 12:25:55.467864 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.33789 (* 1 = 0.33789 loss)
I0831 12:25:55.467871 916722 sgd_solver.cpp:106] Iteration 3059000, lr = 0.01
I0831 12:26:25.202203 916722 solver.cpp:218] Iteration 3059500 (16.8156 iter/s, 29.7343s/500 iters), loss = 0.351832
I0831 12:26:25.202257 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.351839 (* 1 = 0.351839 loss)
I0831 12:26:25.202267 916722 sgd_solver.cpp:106] Iteration 3059500, lr = 0.01
I0831 12:26:54.931524 916722 solver.cpp:218] Iteration 3060000 (16.8185 iter/s, 29.7292s/500 iters), loss = 0.306565
I0831 12:26:54.931594 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.306572 (* 1 = 0.306572 loss)
I0831 12:26:54.931607 916722 sgd_solver.cpp:106] Iteration 3060000, lr = 0.01
I0831 12:27:24.660084 916722 solver.cpp:218] Iteration 3060500 (16.8189 iter/s, 29.7285s/500 iters), loss = 0.23133
I0831 12:27:24.660136 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.231337 (* 1 = 0.231337 loss)
I0831 12:27:24.660146 916722 sgd_solver.cpp:106] Iteration 3060500, lr = 0.01
I0831 12:27:54.390586 916722 solver.cpp:218] Iteration 3061000 (16.8178 iter/s, 29.7304s/500 iters), loss = 0.0612141
I0831 12:27:54.390643 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.061221 (* 1 = 0.061221 loss)
I0831 12:27:54.390651 916722 sgd_solver.cpp:106] Iteration 3061000, lr = 0.01
I0831 12:28:24.123741 916722 solver.cpp:218] Iteration 3061500 (16.8163 iter/s, 29.7331s/500 iters), loss = 0.0524932
I0831 12:28:24.123795 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0525002 (* 1 = 0.0525002 loss)
I0831 12:28:24.123804 916722 sgd_solver.cpp:106] Iteration 3061500, lr = 0.01
I0831 12:28:53.852622 916722 solver.cpp:218] Iteration 3062000 (16.8187 iter/s, 29.7288s/500 iters), loss = 0.162506
I0831 12:28:53.852686 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.162513 (* 1 = 0.162513 loss)
I0831 12:28:53.852695 916722 sgd_solver.cpp:106] Iteration 3062000, lr = 0.01
I0831 12:29:23.596879 916722 solver.cpp:218] Iteration 3062500 (16.81 iter/s, 29.7441s/500 iters), loss = 0.104241
I0831 12:29:23.596932 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104248 (* 1 = 0.104248 loss)
I0831 12:29:23.596941 916722 sgd_solver.cpp:106] Iteration 3062500, lr = 0.01
I0831 12:29:53.333801 916722 solver.cpp:218] Iteration 3063000 (16.8142 iter/s, 29.7368s/500 iters), loss = 0.0733022
I0831 12:29:53.333863 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0733092 (* 1 = 0.0733092 loss)
I0831 12:29:53.333871 916722 sgd_solver.cpp:106] Iteration 3063000, lr = 0.01
I0831 12:30:23.065317 916722 solver.cpp:218] Iteration 3063500 (16.8172 iter/s, 29.7314s/500 iters), loss = 0.340472
I0831 12:30:23.065371 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.340479 (* 1 = 0.340479 loss)
I0831 12:30:23.065379 916722 sgd_solver.cpp:106] Iteration 3063500, lr = 0.01
I0831 12:30:52.803594 916722 solver.cpp:218] Iteration 3064000 (16.8134 iter/s, 29.7382s/500 iters), loss = 0.0293866
I0831 12:30:52.803656 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0293936 (* 1 = 0.0293936 loss)
I0831 12:30:52.803664 916722 sgd_solver.cpp:106] Iteration 3064000, lr = 0.01
I0831 12:31:22.539444 916722 solver.cpp:218] Iteration 3064500 (16.8148 iter/s, 29.7357s/500 iters), loss = 0.128228
I0831 12:31:22.539495 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128235 (* 1 = 0.128235 loss)
I0831 12:31:22.539503 916722 sgd_solver.cpp:106] Iteration 3064500, lr = 0.01
I0831 12:31:52.270692 916722 solver.cpp:218] Iteration 3065000 (16.8181 iter/s, 29.7298s/500 iters), loss = 0.0846067
I0831 12:31:52.270768 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0846136 (* 1 = 0.0846136 loss)
I0831 12:31:52.270777 916722 sgd_solver.cpp:106] Iteration 3065000, lr = 0.01
I0831 12:32:22.003940 916722 solver.cpp:218] Iteration 3065500 (16.8163 iter/s, 29.7331s/500 iters), loss = 0.187693
I0831 12:32:22.003988 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.1877 (* 1 = 0.1877 loss)
I0831 12:32:22.003996 916722 sgd_solver.cpp:106] Iteration 3065500, lr = 0.01
I0831 12:32:51.745000 916722 solver.cpp:218] Iteration 3066000 (16.8118 iter/s, 29.7409s/500 iters), loss = 0.0576851
I0831 12:32:51.745060 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0576919 (* 1 = 0.0576919 loss)
I0831 12:32:51.745069 916722 sgd_solver.cpp:106] Iteration 3066000, lr = 0.01
I0831 12:33:21.478235 916722 solver.cpp:218] Iteration 3066500 (16.8163 iter/s, 29.7331s/500 iters), loss = 0.124516
I0831 12:33:21.478288 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.124523 (* 1 = 0.124523 loss)
I0831 12:33:21.478296 916722 sgd_solver.cpp:106] Iteration 3066500, lr = 0.01
I0831 12:33:51.214547 916722 solver.cpp:218] Iteration 3067000 (16.8145 iter/s, 29.7362s/500 iters), loss = 0.22468
I0831 12:33:51.214618 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.224687 (* 1 = 0.224687 loss)
I0831 12:33:51.214627 916722 sgd_solver.cpp:106] Iteration 3067000, lr = 0.01
I0831 12:34:20.951630 916722 solver.cpp:218] Iteration 3067500 (16.8141 iter/s, 29.7369s/500 iters), loss = 0.223519
I0831 12:34:20.951683 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.223526 (* 1 = 0.223526 loss)
I0831 12:34:20.951691 916722 sgd_solver.cpp:106] Iteration 3067500, lr = 0.01
I0831 12:34:50.691654 916722 solver.cpp:218] Iteration 3068000 (16.8124 iter/s, 29.7399s/500 iters), loss = 0.263971
I0831 12:34:50.691715 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.263978 (* 1 = 0.263978 loss)
I0831 12:34:50.691723 916722 sgd_solver.cpp:106] Iteration 3068000, lr = 0.01
I0831 12:35:20.423171 916722 solver.cpp:218] Iteration 3068500 (16.8172 iter/s, 29.7314s/500 iters), loss = 0.152962
I0831 12:35:20.423224 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152968 (* 1 = 0.152968 loss)
I0831 12:35:20.423233 916722 sgd_solver.cpp:106] Iteration 3068500, lr = 0.01
I0831 12:35:50.159885 916722 solver.cpp:218] Iteration 3069000 (16.8143 iter/s, 29.7366s/500 iters), loss = 0.140574
I0831 12:35:50.159945 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.140581 (* 1 = 0.140581 loss)
I0831 12:35:50.159953 916722 sgd_solver.cpp:106] Iteration 3069000, lr = 0.01
I0831 12:36:19.897320 916722 solver.cpp:218] Iteration 3069500 (16.8139 iter/s, 29.7373s/500 iters), loss = 0.155824
I0831 12:36:19.897375 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.155831 (* 1 = 0.155831 loss)
I0831 12:36:19.897383 916722 sgd_solver.cpp:106] Iteration 3069500, lr = 0.01
I0831 12:36:49.635200 916722 solver.cpp:218] Iteration 3070000 (16.8136 iter/s, 29.7378s/500 iters), loss = 0.245807
I0831 12:36:49.635260 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.245815 (* 1 = 0.245815 loss)
I0831 12:36:49.635269 916722 sgd_solver.cpp:106] Iteration 3070000, lr = 0.01
I0831 12:37:19.372303 916722 solver.cpp:218] Iteration 3070500 (16.8141 iter/s, 29.737s/500 iters), loss = 0.101183
I0831 12:37:19.372356 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.10119 (* 1 = 0.10119 loss)
I0831 12:37:19.372366 916722 sgd_solver.cpp:106] Iteration 3070500, lr = 0.01
I0831 12:37:49.163760 916722 solver.cpp:218] Iteration 3071000 (16.7834 iter/s, 29.7913s/500 iters), loss = 0.0807915
I0831 12:37:49.163821 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0807986 (* 1 = 0.0807986 loss)
I0831 12:37:49.163830 916722 sgd_solver.cpp:106] Iteration 3071000, lr = 0.01
I0831 12:38:18.937613 916722 solver.cpp:218] Iteration 3071500 (16.7933 iter/s, 29.7737s/500 iters), loss = 0.264898
I0831 12:38:18.937671 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.264905 (* 1 = 0.264905 loss)
I0831 12:38:18.937682 916722 sgd_solver.cpp:106] Iteration 3071500, lr = 0.01
I0831 12:38:48.716024 916722 solver.cpp:218] Iteration 3072000 (16.7908 iter/s, 29.7783s/500 iters), loss = 0.182288
I0831 12:38:48.716084 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.182295 (* 1 = 0.182295 loss)
I0831 12:38:48.716092 916722 sgd_solver.cpp:106] Iteration 3072000, lr = 0.01
I0831 12:39:18.494160 916722 solver.cpp:218] Iteration 3072500 (16.7909 iter/s, 29.778s/500 iters), loss = 0.186169
I0831 12:39:18.494217 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.186176 (* 1 = 0.186176 loss)
I0831 12:39:18.494227 916722 sgd_solver.cpp:106] Iteration 3072500, lr = 0.01
I0831 12:39:48.269517 916722 solver.cpp:218] Iteration 3073000 (16.7925 iter/s, 29.7752s/500 iters), loss = 0.205163
I0831 12:39:48.269578 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.20517 (* 1 = 0.20517 loss)
I0831 12:39:48.269587 916722 sgd_solver.cpp:106] Iteration 3073000, lr = 0.01
I0831 12:40:18.049293 916722 solver.cpp:218] Iteration 3073500 (16.79 iter/s, 29.7796s/500 iters), loss = 0.105451
I0831 12:40:18.049346 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105458 (* 1 = 0.105458 loss)
I0831 12:40:18.049356 916722 sgd_solver.cpp:106] Iteration 3073500, lr = 0.01
I0831 12:40:47.829749 916722 solver.cpp:218] Iteration 3074000 (16.7896 iter/s, 29.7803s/500 iters), loss = 0.0440065
I0831 12:40:47.829821 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0440131 (* 1 = 0.0440131 loss)
I0831 12:40:47.829829 916722 sgd_solver.cpp:106] Iteration 3074000, lr = 0.01
I0831 12:41:17.602129 916722 solver.cpp:218] Iteration 3074500 (16.7942 iter/s, 29.7722s/500 iters), loss = 0.320874
I0831 12:41:17.602180 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.320881 (* 1 = 0.320881 loss)
I0831 12:41:17.602190 916722 sgd_solver.cpp:106] Iteration 3074500, lr = 0.01
I0831 12:41:47.375406 916722 solver.cpp:218] Iteration 3075000 (16.7937 iter/s, 29.7731s/500 iters), loss = 0.0757531
I0831 12:41:47.375461 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0757596 (* 1 = 0.0757596 loss)
I0831 12:41:47.375469 916722 sgd_solver.cpp:106] Iteration 3075000, lr = 0.01
I0831 12:42:17.152290 916722 solver.cpp:218] Iteration 3075500 (16.7916 iter/s, 29.7767s/500 iters), loss = 0.0835875
I0831 12:42:17.152345 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.083594 (* 1 = 0.083594 loss)
I0831 12:42:17.152355 916722 sgd_solver.cpp:106] Iteration 3075500, lr = 0.01
I0831 12:42:46.933291 916722 solver.cpp:218] Iteration 3076000 (16.7893 iter/s, 29.7809s/500 iters), loss = 0.0535445
I0831 12:42:46.933353 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.053551 (* 1 = 0.053551 loss)
I0831 12:42:46.933362 916722 sgd_solver.cpp:106] Iteration 3076000, lr = 0.01
I0831 12:43:16.712617 916722 solver.cpp:218] Iteration 3076500 (16.7903 iter/s, 29.7792s/500 iters), loss = 0.0984071
I0831 12:43:16.712671 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0984136 (* 1 = 0.0984136 loss)
I0831 12:43:16.712680 916722 sgd_solver.cpp:106] Iteration 3076500, lr = 0.01
I0831 12:43:46.491240 916722 solver.cpp:218] Iteration 3077000 (16.7906 iter/s, 29.7785s/500 iters), loss = 0.115598
I0831 12:43:46.491303 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115605 (* 1 = 0.115605 loss)
I0831 12:43:46.491312 916722 sgd_solver.cpp:106] Iteration 3077000, lr = 0.01
I0831 12:44:16.267697 916722 solver.cpp:218] Iteration 3077500 (16.7919 iter/s, 29.7763s/500 iters), loss = 0.216894
I0831 12:44:16.267752 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.216901 (* 1 = 0.216901 loss)
I0831 12:44:16.267761 916722 sgd_solver.cpp:106] Iteration 3077500, lr = 0.01
I0831 12:44:46.044842 916722 solver.cpp:218] Iteration 3078000 (16.7915 iter/s, 29.777s/500 iters), loss = 0.152755
I0831 12:44:46.044901 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152761 (* 1 = 0.152761 loss)
I0831 12:44:46.044909 916722 sgd_solver.cpp:106] Iteration 3078000, lr = 0.01
I0831 12:45:15.823493 916722 solver.cpp:218] Iteration 3078500 (16.7906 iter/s, 29.7785s/500 iters), loss = 0.0528212
I0831 12:45:15.823545 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0528278 (* 1 = 0.0528278 loss)
I0831 12:45:15.823554 916722 sgd_solver.cpp:106] Iteration 3078500, lr = 0.01
I0831 12:45:45.604432 916722 solver.cpp:218] Iteration 3079000 (16.7893 iter/s, 29.7808s/500 iters), loss = 0.155417
I0831 12:45:45.604502 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.155424 (* 1 = 0.155424 loss)
I0831 12:45:45.604511 916722 sgd_solver.cpp:106] Iteration 3079000, lr = 0.01
I0831 12:46:15.378875 916722 solver.cpp:218] Iteration 3079500 (16.793 iter/s, 29.7743s/500 iters), loss = 0.310251
I0831 12:46:15.378927 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.310258 (* 1 = 0.310258 loss)
I0831 12:46:15.378937 916722 sgd_solver.cpp:106] Iteration 3079500, lr = 0.01
I0831 12:46:45.152642 916722 solver.cpp:218] Iteration 3080000 (16.7934 iter/s, 29.7736s/500 iters), loss = 0.398169
I0831 12:46:45.152717 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.398175 (* 1 = 0.398175 loss)
I0831 12:46:45.152726 916722 sgd_solver.cpp:106] Iteration 3080000, lr = 0.01
I0831 12:47:14.932750 916722 solver.cpp:218] Iteration 3080500 (16.7898 iter/s, 29.7799s/500 iters), loss = 0.299234
I0831 12:47:14.932804 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.29924 (* 1 = 0.29924 loss)
I0831 12:47:14.932813 916722 sgd_solver.cpp:106] Iteration 3080500, lr = 0.01
I0831 12:47:44.714145 916722 solver.cpp:218] Iteration 3081000 (16.7891 iter/s, 29.7813s/500 iters), loss = 0.205999
I0831 12:47:44.714206 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.206005 (* 1 = 0.206005 loss)
I0831 12:47:44.714215 916722 sgd_solver.cpp:106] Iteration 3081000, lr = 0.01
I0831 12:48:14.495846 916722 solver.cpp:218] Iteration 3081500 (16.7889 iter/s, 29.7815s/500 iters), loss = 0.172305
I0831 12:48:14.495898 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.172311 (* 1 = 0.172311 loss)
I0831 12:48:14.495906 916722 sgd_solver.cpp:106] Iteration 3081500, lr = 0.01
I0831 12:48:44.282464 916722 solver.cpp:218] Iteration 3082000 (16.7861 iter/s, 29.7865s/500 iters), loss = 0.0433724
I0831 12:48:44.282523 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0433787 (* 1 = 0.0433787 loss)
I0831 12:48:44.282532 916722 sgd_solver.cpp:106] Iteration 3082000, lr = 0.01
I0831 12:49:14.054869 916722 solver.cpp:218] Iteration 3082500 (16.7942 iter/s, 29.7723s/500 iters), loss = 0.0426666
I0831 12:49:14.054924 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0426727 (* 1 = 0.0426727 loss)
I0831 12:49:14.054934 916722 sgd_solver.cpp:106] Iteration 3082500, lr = 0.01
I0831 12:49:43.831437 916722 solver.cpp:218] Iteration 3083000 (16.7918 iter/s, 29.7764s/500 iters), loss = 0.15264
I0831 12:49:43.831496 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152646 (* 1 = 0.152646 loss)
I0831 12:49:43.831503 916722 sgd_solver.cpp:106] Iteration 3083000, lr = 0.01
I0831 12:50:13.611536 916722 solver.cpp:218] Iteration 3083500 (16.7898 iter/s, 29.78s/500 iters), loss = 0.0263279
I0831 12:50:13.611586 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.026334 (* 1 = 0.026334 loss)
I0831 12:50:13.611596 916722 sgd_solver.cpp:106] Iteration 3083500, lr = 0.01
I0831 12:50:43.397718 916722 solver.cpp:218] Iteration 3084000 (16.7864 iter/s, 29.786s/500 iters), loss = 0.218059
I0831 12:50:43.397778 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.218065 (* 1 = 0.218065 loss)
I0831 12:50:43.397786 916722 sgd_solver.cpp:106] Iteration 3084000, lr = 0.01
I0831 12:51:13.182066 916722 solver.cpp:218] Iteration 3084500 (16.7874 iter/s, 29.7842s/500 iters), loss = 0.26001
I0831 12:51:13.182119 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.260016 (* 1 = 0.260016 loss)
I0831 12:51:13.182129 916722 sgd_solver.cpp:106] Iteration 3084500, lr = 0.01
I0831 12:51:42.960587 916722 solver.cpp:218] Iteration 3085000 (16.7907 iter/s, 29.7784s/500 iters), loss = 0.0182055
I0831 12:51:42.960650 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0182118 (* 1 = 0.0182118 loss)
I0831 12:51:42.960659 916722 sgd_solver.cpp:106] Iteration 3085000, lr = 0.01
I0831 12:52:12.739010 916722 solver.cpp:218] Iteration 3085500 (16.7908 iter/s, 29.7783s/500 iters), loss = 0.250152
I0831 12:52:12.739064 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.250159 (* 1 = 0.250159 loss)
I0831 12:52:12.739074 916722 sgd_solver.cpp:106] Iteration 3085500, lr = 0.01
I0831 12:52:42.501263 916722 solver.cpp:218] Iteration 3086000 (16.7999 iter/s, 29.7621s/500 iters), loss = 0.0730724
I0831 12:52:42.501323 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0730787 (* 1 = 0.0730787 loss)
I0831 12:52:42.501332 916722 sgd_solver.cpp:106] Iteration 3086000, lr = 0.01
I0831 12:53:12.261569 916722 solver.cpp:218] Iteration 3086500 (16.801 iter/s, 29.7602s/500 iters), loss = 0.0385317
I0831 12:53:12.261636 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.038538 (* 1 = 0.038538 loss)
I0831 12:53:12.261646 916722 sgd_solver.cpp:106] Iteration 3086500, lr = 0.01
I0831 12:53:42.025840 916722 solver.cpp:218] Iteration 3087000 (16.7988 iter/s, 29.7641s/500 iters), loss = 0.19814
I0831 12:53:42.025910 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.198146 (* 1 = 0.198146 loss)
I0831 12:53:42.025918 916722 sgd_solver.cpp:106] Iteration 3087000, lr = 0.01
I0831 12:54:11.790565 916722 solver.cpp:218] Iteration 3087500 (16.7985 iter/s, 29.7646s/500 iters), loss = 0.119744
I0831 12:54:11.790619 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.119751 (* 1 = 0.119751 loss)
I0831 12:54:11.790629 916722 sgd_solver.cpp:106] Iteration 3087500, lr = 0.01
I0831 12:54:41.553792 916722 solver.cpp:218] Iteration 3088000 (16.7993 iter/s, 29.7631s/500 iters), loss = 0.451738
I0831 12:54:41.553851 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.451745 (* 1 = 0.451745 loss)
I0831 12:54:41.553859 916722 sgd_solver.cpp:106] Iteration 3088000, lr = 0.01
I0831 12:55:11.320749 916722 solver.cpp:218] Iteration 3088500 (16.7972 iter/s, 29.7668s/500 iters), loss = 0.180576
I0831 12:55:11.320802 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.180583 (* 1 = 0.180583 loss)
I0831 12:55:11.320811 916722 sgd_solver.cpp:106] Iteration 3088500, lr = 0.01
I0831 12:55:41.090363 916722 solver.cpp:218] Iteration 3089000 (16.7957 iter/s, 29.7695s/500 iters), loss = 0.0645174
I0831 12:55:41.090425 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0645241 (* 1 = 0.0645241 loss)
I0831 12:55:41.090432 916722 sgd_solver.cpp:106] Iteration 3089000, lr = 0.01
I0831 12:56:10.858266 916722 solver.cpp:218] Iteration 3089500 (16.7967 iter/s, 29.7678s/500 iters), loss = 0.186409
I0831 12:56:10.858320 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.186416 (* 1 = 0.186416 loss)
I0831 12:56:10.858330 916722 sgd_solver.cpp:106] Iteration 3089500, lr = 0.01
I0831 12:56:40.623098 916722 solver.cpp:218] Iteration 3090000 (16.7984 iter/s, 29.7647s/500 iters), loss = 0.163515
I0831 12:56:40.623158 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.163522 (* 1 = 0.163522 loss)
I0831 12:56:40.623167 916722 sgd_solver.cpp:106] Iteration 3090000, lr = 0.01
I0831 12:57:10.386716 916722 solver.cpp:218] Iteration 3090500 (16.7991 iter/s, 29.7635s/500 iters), loss = 0.239464
I0831 12:57:10.386768 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.23947 (* 1 = 0.23947 loss)
I0831 12:57:10.386777 916722 sgd_solver.cpp:106] Iteration 3090500, lr = 0.01
I0831 12:57:40.149888 916722 solver.cpp:218] Iteration 3091000 (16.7994 iter/s, 29.7631s/500 iters), loss = 0.218473
I0831 12:57:40.149948 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.21848 (* 1 = 0.21848 loss)
I0831 12:57:40.149957 916722 sgd_solver.cpp:106] Iteration 3091000, lr = 0.01
I0831 12:58:09.917627 916722 solver.cpp:218] Iteration 3091500 (16.7968 iter/s, 29.7676s/500 iters), loss = 0.162109
I0831 12:58:09.917680 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.162115 (* 1 = 0.162115 loss)
I0831 12:58:09.917690 916722 sgd_solver.cpp:106] Iteration 3091500, lr = 0.01
I0831 12:58:39.683781 916722 solver.cpp:218] Iteration 3092000 (16.7977 iter/s, 29.766s/500 iters), loss = 0.104912
I0831 12:58:39.683841 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104919 (* 1 = 0.104919 loss)
I0831 12:58:39.683849 916722 sgd_solver.cpp:106] Iteration 3092000, lr = 0.01
I0831 12:59:09.447448 916722 solver.cpp:218] Iteration 3092500 (16.7991 iter/s, 29.7635s/500 iters), loss = 0.069446
I0831 12:59:09.447497 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0694528 (* 1 = 0.0694528 loss)
I0831 12:59:09.447505 916722 sgd_solver.cpp:106] Iteration 3092500, lr = 0.01
I0831 12:59:39.210958 916722 solver.cpp:218] Iteration 3093000 (16.7992 iter/s, 29.7634s/500 iters), loss = 0.176101
I0831 12:59:39.211030 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.176108 (* 1 = 0.176108 loss)
I0831 12:59:39.211042 916722 sgd_solver.cpp:106] Iteration 3093000, lr = 0.01
I0831 13:00:08.972908 916722 solver.cpp:218] Iteration 3093500 (16.8001 iter/s, 29.7618s/500 iters), loss = 0.128212
I0831 13:00:08.972965 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128218 (* 1 = 0.128218 loss)
I0831 13:00:08.972975 916722 sgd_solver.cpp:106] Iteration 3093500, lr = 0.01
I0831 13:00:38.736341 916722 solver.cpp:218] Iteration 3094000 (16.7992 iter/s, 29.7633s/500 iters), loss = 0.0633066
I0831 13:00:38.736403 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0633135 (* 1 = 0.0633135 loss)
I0831 13:00:38.736413 916722 sgd_solver.cpp:106] Iteration 3094000, lr = 0.01
I0831 13:01:08.502247 916722 solver.cpp:218] Iteration 3094500 (16.7978 iter/s, 29.7658s/500 iters), loss = 0.0383732
I0831 13:01:08.502302 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0383801 (* 1 = 0.0383801 loss)
I0831 13:01:08.502312 916722 sgd_solver.cpp:106] Iteration 3094500, lr = 0.01
I0831 13:01:38.272356 916722 solver.cpp:218] Iteration 3095000 (16.7954 iter/s, 29.77s/500 iters), loss = 0.242996
I0831 13:01:38.272415 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.243003 (* 1 = 0.243003 loss)
I0831 13:01:38.272429 916722 sgd_solver.cpp:106] Iteration 3095000, lr = 0.01
I0831 13:02:08.037555 916722 solver.cpp:218] Iteration 3095500 (16.7982 iter/s, 29.7651s/500 iters), loss = 0.109985
I0831 13:02:08.037612 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109992 (* 1 = 0.109992 loss)
I0831 13:02:08.037622 916722 sgd_solver.cpp:106] Iteration 3095500, lr = 0.01
I0831 13:02:37.803112 916722 solver.cpp:218] Iteration 3096000 (16.798 iter/s, 29.7654s/500 iters), loss = 0.193622
I0831 13:02:37.803171 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.193628 (* 1 = 0.193628 loss)
I0831 13:02:37.803179 916722 sgd_solver.cpp:106] Iteration 3096000, lr = 0.01
I0831 13:03:07.565155 916722 solver.cpp:218] Iteration 3096500 (16.8 iter/s, 29.7619s/500 iters), loss = 0.0650897
I0831 13:03:07.565209 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0650964 (* 1 = 0.0650964 loss)
I0831 13:03:07.565220 916722 sgd_solver.cpp:106] Iteration 3096500, lr = 0.01
I0831 13:03:37.331802 916722 solver.cpp:218] Iteration 3097000 (16.7974 iter/s, 29.7665s/500 iters), loss = 0.241259
I0831 13:03:37.331861 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.241266 (* 1 = 0.241266 loss)
I0831 13:03:37.331869 916722 sgd_solver.cpp:106] Iteration 3097000, lr = 0.01
I0831 13:04:07.098049 916722 solver.cpp:218] Iteration 3097500 (16.7976 iter/s, 29.7661s/500 iters), loss = 0.175439
I0831 13:04:07.098104 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.175446 (* 1 = 0.175446 loss)
I0831 13:04:07.098114 916722 sgd_solver.cpp:106] Iteration 3097500, lr = 0.01
I0831 13:04:36.861438 916722 solver.cpp:218] Iteration 3098000 (16.7992 iter/s, 29.7633s/500 iters), loss = 0.032174
I0831 13:04:36.861497 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0321805 (* 1 = 0.0321805 loss)
I0831 13:04:36.861505 916722 sgd_solver.cpp:106] Iteration 3098000, lr = 0.01
I0831 13:05:06.626132 916722 solver.cpp:218] Iteration 3098500 (16.7985 iter/s, 29.7646s/500 iters), loss = 0.0783943
I0831 13:05:06.626185 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0784008 (* 1 = 0.0784008 loss)
I0831 13:05:06.626196 916722 sgd_solver.cpp:106] Iteration 3098500, lr = 0.01
I0831 13:05:36.395376 916722 solver.cpp:218] Iteration 3099000 (16.7959 iter/s, 29.7691s/500 iters), loss = 0.173481
I0831 13:05:36.395437 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.173487 (* 1 = 0.173487 loss)
I0831 13:05:36.395444 916722 sgd_solver.cpp:106] Iteration 3099000, lr = 0.01
I0831 13:06:06.156478 916722 solver.cpp:218] Iteration 3099500 (16.8005 iter/s, 29.761s/500 iters), loss = 0.0846995
I0831 13:06:06.156530 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0847059 (* 1 = 0.0847059 loss)
I0831 13:06:06.156550 916722 sgd_solver.cpp:106] Iteration 3099500, lr = 0.01
I0831 13:06:35.867008 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_3100000.caffemodel
I0831 13:06:35.886294 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_3100000.solverstate
I0831 13:06:35.892483 916722 solver.cpp:330] Iteration 3100000, Testing net (#0)
I0831 13:06:51.318904 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8864
I0831 13:06:51.318948 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.391362 (* 1 = 0.391362 loss)
I0831 13:06:51.377386 916722 solver.cpp:218] Iteration 3100000 (11.0569 iter/s, 45.2207s/500 iters), loss = 0.264652
I0831 13:06:51.377414 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.264659 (* 1 = 0.264659 loss)
I0831 13:06:51.377422 916722 sgd_solver.cpp:106] Iteration 3100000, lr = 0.01
I0831 13:07:21.103241 916722 solver.cpp:218] Iteration 3100500 (16.8205 iter/s, 29.7257s/500 iters), loss = 0.0792151
I0831 13:07:21.103302 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0792214 (* 1 = 0.0792214 loss)
I0831 13:07:21.103310 916722 sgd_solver.cpp:106] Iteration 3100500, lr = 0.01
I0831 13:07:50.837683 916722 solver.cpp:218] Iteration 3101000 (16.8156 iter/s, 29.7343s/500 iters), loss = 0.392513
I0831 13:07:50.837738 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.392519 (* 1 = 0.392519 loss)
I0831 13:07:50.837749 916722 sgd_solver.cpp:106] Iteration 3101000, lr = 0.01
I0831 13:08:20.576273 916722 solver.cpp:218] Iteration 3101500 (16.8133 iter/s, 29.7384s/500 iters), loss = 0.130181
I0831 13:08:20.576335 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130188 (* 1 = 0.130188 loss)
I0831 13:08:20.576344 916722 sgd_solver.cpp:106] Iteration 3101500, lr = 0.01
I0831 13:08:50.315559 916722 solver.cpp:218] Iteration 3102000 (16.8129 iter/s, 29.7391s/500 iters), loss = 0.0250909
I0831 13:08:50.315614 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0250973 (* 1 = 0.0250973 loss)
I0831 13:08:50.315623 916722 sgd_solver.cpp:106] Iteration 3102000, lr = 0.01
I0831 13:09:20.060436 916722 solver.cpp:218] Iteration 3102500 (16.8097 iter/s, 29.7447s/500 iters), loss = 0.195587
I0831 13:09:20.060496 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.195593 (* 1 = 0.195593 loss)
I0831 13:09:20.060505 916722 sgd_solver.cpp:106] Iteration 3102500, lr = 0.01
I0831 13:09:49.801566 916722 solver.cpp:218] Iteration 3103000 (16.8118 iter/s, 29.741s/500 iters), loss = 0.0884668
I0831 13:09:49.801622 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0884732 (* 1 = 0.0884732 loss)
I0831 13:09:49.801630 916722 sgd_solver.cpp:106] Iteration 3103000, lr = 0.01
I0831 13:10:19.545373 916722 solver.cpp:218] Iteration 3103500 (16.8103 iter/s, 29.7437s/500 iters), loss = 0.25225
I0831 13:10:19.545433 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.252256 (* 1 = 0.252256 loss)
I0831 13:10:19.545442 916722 sgd_solver.cpp:106] Iteration 3103500, lr = 0.01
I0831 13:10:49.290647 916722 solver.cpp:218] Iteration 3104000 (16.8095 iter/s, 29.7451s/500 iters), loss = 0.0341234
I0831 13:10:49.290702 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0341296 (* 1 = 0.0341296 loss)
I0831 13:10:49.290710 916722 sgd_solver.cpp:106] Iteration 3104000, lr = 0.01
I0831 13:11:19.036465 916722 solver.cpp:218] Iteration 3104500 (16.8092 iter/s, 29.7457s/500 iters), loss = 0.270806
I0831 13:11:19.036527 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.270812 (* 1 = 0.270812 loss)
I0831 13:11:19.036536 916722 sgd_solver.cpp:106] Iteration 3104500, lr = 0.01
I0831 13:11:48.783018 916722 solver.cpp:218] Iteration 3105000 (16.8088 iter/s, 29.7464s/500 iters), loss = 0.181361
I0831 13:11:48.783071 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.181368 (* 1 = 0.181368 loss)
I0831 13:11:48.783079 916722 sgd_solver.cpp:106] Iteration 3105000, lr = 0.01
I0831 13:12:18.528187 916722 solver.cpp:218] Iteration 3105500 (16.8095 iter/s, 29.745s/500 iters), loss = 0.154633
I0831 13:12:18.528259 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.154639 (* 1 = 0.154639 loss)
I0831 13:12:18.528267 916722 sgd_solver.cpp:106] Iteration 3105500, lr = 0.01
I0831 13:12:48.275800 916722 solver.cpp:218] Iteration 3106000 (16.8082 iter/s, 29.7475s/500 iters), loss = 0.0508254
I0831 13:12:48.275851 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0508315 (* 1 = 0.0508315 loss)
I0831 13:12:48.275859 916722 sgd_solver.cpp:106] Iteration 3106000, lr = 0.01
I0831 13:13:18.023075 916722 solver.cpp:218] Iteration 3106500 (16.8083 iter/s, 29.7471s/500 iters), loss = 0.115041
I0831 13:13:18.023137 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115047 (* 1 = 0.115047 loss)
I0831 13:13:18.023146 916722 sgd_solver.cpp:106] Iteration 3106500, lr = 0.01
I0831 13:13:47.767208 916722 solver.cpp:218] Iteration 3107000 (16.8101 iter/s, 29.744s/500 iters), loss = 0.317266
I0831 13:13:47.767264 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.317273 (* 1 = 0.317273 loss)
I0831 13:13:47.767275 916722 sgd_solver.cpp:106] Iteration 3107000, lr = 0.01
I0831 13:14:17.514434 916722 solver.cpp:218] Iteration 3107500 (16.8084 iter/s, 29.7471s/500 iters), loss = 0.0234101
I0831 13:14:17.514494 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0234164 (* 1 = 0.0234164 loss)
I0831 13:14:17.514503 916722 sgd_solver.cpp:106] Iteration 3107500, lr = 0.01
I0831 13:14:47.258606 916722 solver.cpp:218] Iteration 3108000 (16.8101 iter/s, 29.744s/500 iters), loss = 0.0585111
I0831 13:14:47.258661 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0585172 (* 1 = 0.0585172 loss)
I0831 13:14:47.258672 916722 sgd_solver.cpp:106] Iteration 3108000, lr = 0.01
I0831 13:15:16.999612 916722 solver.cpp:218] Iteration 3108500 (16.8119 iter/s, 29.7409s/500 iters), loss = 0.15401
I0831 13:15:16.999672 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.154016 (* 1 = 0.154016 loss)
I0831 13:15:16.999681 916722 sgd_solver.cpp:106] Iteration 3108500, lr = 0.01
I0831 13:15:46.745002 916722 solver.cpp:218] Iteration 3109000 (16.8094 iter/s, 29.7452s/500 iters), loss = 0.133376
I0831 13:15:46.745055 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133383 (* 1 = 0.133383 loss)
I0831 13:15:46.745065 916722 sgd_solver.cpp:106] Iteration 3109000, lr = 0.01
I0831 13:16:16.491746 916722 solver.cpp:218] Iteration 3109500 (16.8086 iter/s, 29.7466s/500 iters), loss = 0.0440778
I0831 13:16:16.491806 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0440839 (* 1 = 0.0440839 loss)
I0831 13:16:16.491816 916722 sgd_solver.cpp:106] Iteration 3109500, lr = 0.01
I0831 13:16:46.235257 916722 solver.cpp:218] Iteration 3110000 (16.8105 iter/s, 29.7434s/500 iters), loss = 0.0885562
I0831 13:16:46.235312 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0885622 (* 1 = 0.0885622 loss)
I0831 13:16:46.235322 916722 sgd_solver.cpp:106] Iteration 3110000, lr = 0.01
I0831 13:17:15.978262 916722 solver.cpp:218] Iteration 3110500 (16.8108 iter/s, 29.7429s/500 iters), loss = 0.130239
I0831 13:17:15.978318 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130245 (* 1 = 0.130245 loss)
I0831 13:17:15.978327 916722 sgd_solver.cpp:106] Iteration 3110500, lr = 0.01
I0831 13:17:45.720772 916722 solver.cpp:218] Iteration 3111000 (16.811 iter/s, 29.7424s/500 iters), loss = 0.0665078
I0831 13:17:45.720826 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0665138 (* 1 = 0.0665138 loss)
I0831 13:17:45.720836 916722 sgd_solver.cpp:106] Iteration 3111000, lr = 0.01
I0831 13:18:15.465227 916722 solver.cpp:218] Iteration 3111500 (16.8099 iter/s, 29.7443s/500 iters), loss = 0.142031
I0831 13:18:15.465287 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.142037 (* 1 = 0.142037 loss)
I0831 13:18:15.465296 916722 sgd_solver.cpp:106] Iteration 3111500, lr = 0.01
I0831 13:18:45.207499 916722 solver.cpp:218] Iteration 3112000 (16.8112 iter/s, 29.7421s/500 iters), loss = 0.269363
I0831 13:18:45.207564 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.269369 (* 1 = 0.269369 loss)
I0831 13:18:45.207576 916722 sgd_solver.cpp:106] Iteration 3112000, lr = 0.01
I0831 13:19:14.954226 916722 solver.cpp:218] Iteration 3112500 (16.8087 iter/s, 29.7466s/500 iters), loss = 0.27706
I0831 13:19:14.954295 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.277067 (* 1 = 0.277067 loss)
I0831 13:19:14.954303 916722 sgd_solver.cpp:106] Iteration 3112500, lr = 0.01
I0831 13:19:44.700688 916722 solver.cpp:218] Iteration 3113000 (16.8088 iter/s, 29.7463s/500 iters), loss = 0.106991
I0831 13:19:44.700754 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.106997 (* 1 = 0.106997 loss)
I0831 13:19:44.700764 916722 sgd_solver.cpp:106] Iteration 3113000, lr = 0.01
I0831 13:20:14.449301 916722 solver.cpp:218] Iteration 3113500 (16.8076 iter/s, 29.7485s/500 iters), loss = 0.167279
I0831 13:20:14.449362 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.167285 (* 1 = 0.167285 loss)
I0831 13:20:14.449370 916722 sgd_solver.cpp:106] Iteration 3113500, lr = 0.01
I0831 13:20:44.196295 916722 solver.cpp:218] Iteration 3114000 (16.8085 iter/s, 29.7468s/500 iters), loss = 0.217377
I0831 13:20:44.196346 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.217383 (* 1 = 0.217383 loss)
I0831 13:20:44.196355 916722 sgd_solver.cpp:106] Iteration 3114000, lr = 0.01
I0831 13:21:13.944716 916722 solver.cpp:218] Iteration 3114500 (16.8077 iter/s, 29.7483s/500 iters), loss = 0.189329
I0831 13:21:13.944787 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.189335 (* 1 = 0.189335 loss)
I0831 13:21:13.944797 916722 sgd_solver.cpp:106] Iteration 3114500, lr = 0.01
I0831 13:21:43.687633 916722 solver.cpp:218] Iteration 3115000 (16.8108 iter/s, 29.7428s/500 iters), loss = 0.118276
I0831 13:21:43.687682 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.118282 (* 1 = 0.118282 loss)
I0831 13:21:43.687691 916722 sgd_solver.cpp:106] Iteration 3115000, lr = 0.01
I0831 13:22:13.430059 916722 solver.cpp:218] Iteration 3115500 (16.8111 iter/s, 29.7423s/500 iters), loss = 0.0473998
I0831 13:22:13.430115 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0474056 (* 1 = 0.0474056 loss)
I0831 13:22:13.430124 916722 sgd_solver.cpp:106] Iteration 3115500, lr = 0.01
I0831 13:22:43.176895 916722 solver.cpp:218] Iteration 3116000 (16.8086 iter/s, 29.7467s/500 iters), loss = 0.333974
I0831 13:22:43.176951 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.333979 (* 1 = 0.333979 loss)
I0831 13:22:43.176961 916722 sgd_solver.cpp:106] Iteration 3116000, lr = 0.01
I0831 13:23:12.921430 916722 solver.cpp:218] Iteration 3116500 (16.8099 iter/s, 29.7444s/500 iters), loss = 0.120406
I0831 13:23:12.921490 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.120412 (* 1 = 0.120412 loss)
I0831 13:23:12.921499 916722 sgd_solver.cpp:106] Iteration 3116500, lr = 0.01
I0831 13:23:42.666021 916722 solver.cpp:218] Iteration 3117000 (16.8099 iter/s, 29.7444s/500 iters), loss = 0.221665
I0831 13:23:42.666075 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.221671 (* 1 = 0.221671 loss)
I0831 13:23:42.666085 916722 sgd_solver.cpp:106] Iteration 3117000, lr = 0.01
I0831 13:24:12.411172 916722 solver.cpp:218] Iteration 3117500 (16.8095 iter/s, 29.745s/500 iters), loss = 0.170054
I0831 13:24:12.411232 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.17006 (* 1 = 0.17006 loss)
I0831 13:24:12.411242 916722 sgd_solver.cpp:106] Iteration 3117500, lr = 0.01
I0831 13:24:42.153581 916722 solver.cpp:218] Iteration 3118000 (16.8111 iter/s, 29.7423s/500 iters), loss = 0.149726
I0831 13:24:42.153636 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.149732 (* 1 = 0.149732 loss)
I0831 13:24:42.153646 916722 sgd_solver.cpp:106] Iteration 3118000, lr = 0.01
I0831 13:25:11.897359 916722 solver.cpp:218] Iteration 3118500 (16.8103 iter/s, 29.7436s/500 iters), loss = 0.0130968
I0831 13:25:11.897439 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0131029 (* 1 = 0.0131029 loss)
I0831 13:25:11.897446 916722 sgd_solver.cpp:106] Iteration 3118500, lr = 0.01
I0831 13:25:41.640841 916722 solver.cpp:218] Iteration 3119000 (16.8105 iter/s, 29.7433s/500 iters), loss = 0.0385124
I0831 13:25:41.640894 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0385185 (* 1 = 0.0385185 loss)
I0831 13:25:41.640903 916722 sgd_solver.cpp:106] Iteration 3119000, lr = 0.01
I0831 13:26:11.386973 916722 solver.cpp:218] Iteration 3119500 (16.809 iter/s, 29.746s/500 iters), loss = 0.195284
I0831 13:26:11.387029 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.19529 (* 1 = 0.19529 loss)
I0831 13:26:11.387038 916722 sgd_solver.cpp:106] Iteration 3119500, lr = 0.01
I0831 13:26:41.128048 916722 solver.cpp:218] Iteration 3120000 (16.8118 iter/s, 29.7409s/500 iters), loss = 0.161524
I0831 13:26:41.128101 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.16153 (* 1 = 0.16153 loss)
I0831 13:26:41.128110 916722 sgd_solver.cpp:106] Iteration 3120000, lr = 0.01
I0831 13:27:10.872586 916722 solver.cpp:218] Iteration 3120500 (16.8099 iter/s, 29.7444s/500 iters), loss = 0.090501
I0831 13:27:10.872649 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.090507 (* 1 = 0.090507 loss)
I0831 13:27:10.872658 916722 sgd_solver.cpp:106] Iteration 3120500, lr = 0.01
I0831 13:27:40.612912 916722 solver.cpp:218] Iteration 3121000 (16.8123 iter/s, 29.7402s/500 iters), loss = 0.0316363
I0831 13:27:40.612965 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0316426 (* 1 = 0.0316426 loss)
I0831 13:27:40.612974 916722 sgd_solver.cpp:106] Iteration 3121000, lr = 0.01
I0831 13:28:10.358104 916722 solver.cpp:218] Iteration 3121500 (16.8095 iter/s, 29.7452s/500 iters), loss = 0.205505
I0831 13:28:10.358165 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.205511 (* 1 = 0.205511 loss)
I0831 13:28:10.358172 916722 sgd_solver.cpp:106] Iteration 3121500, lr = 0.01
I0831 13:28:40.100437 916722 solver.cpp:218] Iteration 3122000 (16.8108 iter/s, 29.7429s/500 iters), loss = 0.063537
I0831 13:28:40.100503 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0635435 (* 1 = 0.0635435 loss)
I0831 13:28:40.100512 916722 sgd_solver.cpp:106] Iteration 3122000, lr = 0.01
I0831 13:29:09.844691 916722 solver.cpp:218] Iteration 3122500 (16.8097 iter/s, 29.7448s/500 iters), loss = 0.0744859
I0831 13:29:09.844764 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0744923 (* 1 = 0.0744923 loss)
I0831 13:29:09.844772 916722 sgd_solver.cpp:106] Iteration 3122500, lr = 0.01
I0831 13:29:39.589728 916722 solver.cpp:218] Iteration 3123000 (16.8093 iter/s, 29.7455s/500 iters), loss = 0.47227
I0831 13:29:39.589781 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.472276 (* 1 = 0.472276 loss)
I0831 13:29:39.589790 916722 sgd_solver.cpp:106] Iteration 3123000, lr = 0.01
I0831 13:30:09.332792 916722 solver.cpp:218] Iteration 3123500 (16.8104 iter/s, 29.7435s/500 iters), loss = 0.0905163
I0831 13:30:09.332851 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0905225 (* 1 = 0.0905225 loss)
I0831 13:30:09.332860 916722 sgd_solver.cpp:106] Iteration 3123500, lr = 0.01
I0831 13:30:39.076705 916722 solver.cpp:218] Iteration 3124000 (16.8099 iter/s, 29.7443s/500 iters), loss = 0.323653
I0831 13:30:39.076771 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.323659 (* 1 = 0.323659 loss)
I0831 13:30:39.076781 916722 sgd_solver.cpp:106] Iteration 3124000, lr = 0.01
I0831 13:31:08.818267 916722 solver.cpp:218] Iteration 3124500 (16.8113 iter/s, 29.7419s/500 iters), loss = 0.0469152
I0831 13:31:08.818327 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0469213 (* 1 = 0.0469213 loss)
I0831 13:31:08.818336 916722 sgd_solver.cpp:106] Iteration 3124500, lr = 0.01
I0831 13:31:38.562980 916722 solver.cpp:218] Iteration 3125000 (16.8095 iter/s, 29.7451s/500 iters), loss = 0.0965931
I0831 13:31:38.563045 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0965992 (* 1 = 0.0965992 loss)
I0831 13:31:38.563055 916722 sgd_solver.cpp:106] Iteration 3125000, lr = 0.01
I0831 13:32:08.308159 916722 solver.cpp:218] Iteration 3125500 (16.8093 iter/s, 29.7455s/500 iters), loss = 0.273122
I0831 13:32:08.308233 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.273128 (* 1 = 0.273128 loss)
I0831 13:32:08.308240 916722 sgd_solver.cpp:106] Iteration 3125500, lr = 0.01
I0831 13:32:38.057098 916722 solver.cpp:218] Iteration 3126000 (16.8071 iter/s, 29.7492s/500 iters), loss = 0.128893
I0831 13:32:38.057152 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128899 (* 1 = 0.128899 loss)
I0831 13:32:38.057163 916722 sgd_solver.cpp:106] Iteration 3126000, lr = 0.01
I0831 13:33:07.805043 916722 solver.cpp:218] Iteration 3126500 (16.8077 iter/s, 29.7482s/500 iters), loss = 0.0782265
I0831 13:33:07.805104 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0782324 (* 1 = 0.0782324 loss)
I0831 13:33:07.805112 916722 sgd_solver.cpp:106] Iteration 3126500, lr = 0.01
I0831 13:33:37.549891 916722 solver.cpp:218] Iteration 3127000 (16.8095 iter/s, 29.7451s/500 iters), loss = 0.0575465
I0831 13:33:37.549943 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0575523 (* 1 = 0.0575523 loss)
I0831 13:33:37.549953 916722 sgd_solver.cpp:106] Iteration 3127000, lr = 0.01
I0831 13:34:07.296896 916722 solver.cpp:218] Iteration 3127500 (16.8083 iter/s, 29.7473s/500 iters), loss = 0.0337344
I0831 13:34:07.296955 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0337402 (* 1 = 0.0337402 loss)
I0831 13:34:07.296964 916722 sgd_solver.cpp:106] Iteration 3127500, lr = 0.01
I0831 13:34:37.042865 916722 solver.cpp:218] Iteration 3128000 (16.8089 iter/s, 29.7462s/500 iters), loss = 0.150798
I0831 13:34:37.042917 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.150803 (* 1 = 0.150803 loss)
I0831 13:34:37.042927 916722 sgd_solver.cpp:106] Iteration 3128000, lr = 0.01
I0831 13:35:06.787428 916722 solver.cpp:218] Iteration 3128500 (16.8097 iter/s, 29.7448s/500 iters), loss = 0.0545564
I0831 13:35:06.787485 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.054562 (* 1 = 0.054562 loss)
I0831 13:35:06.787493 916722 sgd_solver.cpp:106] Iteration 3128500, lr = 0.01
I0831 13:35:36.533903 916722 solver.cpp:218] Iteration 3129000 (16.8086 iter/s, 29.7467s/500 iters), loss = 0.129512
I0831 13:35:36.533957 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.129518 (* 1 = 0.129518 loss)
I0831 13:35:36.533967 916722 sgd_solver.cpp:106] Iteration 3129000, lr = 0.01
I0831 13:36:06.280457 916722 solver.cpp:218] Iteration 3129500 (16.8086 iter/s, 29.7467s/500 iters), loss = 0.400948
I0831 13:36:06.280517 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.400954 (* 1 = 0.400954 loss)
I0831 13:36:06.280526 916722 sgd_solver.cpp:106] Iteration 3129500, lr = 0.01
I0831 13:36:36.029551 916722 solver.cpp:218] Iteration 3130000 (16.8071 iter/s, 29.7493s/500 iters), loss = 0.0644515
I0831 13:36:36.029603 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0644572 (* 1 = 0.0644572 loss)
I0831 13:36:36.029613 916722 sgd_solver.cpp:106] Iteration 3130000, lr = 0.01
I0831 13:37:05.776592 916722 solver.cpp:218] Iteration 3130500 (16.8083 iter/s, 29.7472s/500 iters), loss = 0.179453
I0831 13:37:05.776677 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.179459 (* 1 = 0.179459 loss)
I0831 13:37:05.776688 916722 sgd_solver.cpp:106] Iteration 3130500, lr = 0.01
I0831 13:37:35.525291 916722 solver.cpp:218] Iteration 3131000 (16.8074 iter/s, 29.7488s/500 iters), loss = 0.0377491
I0831 13:37:35.525344 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0377548 (* 1 = 0.0377548 loss)
I0831 13:37:35.525353 916722 sgd_solver.cpp:106] Iteration 3131000, lr = 0.01
I0831 13:38:05.277384 916722 solver.cpp:218] Iteration 3131500 (16.8055 iter/s, 29.7522s/500 iters), loss = 0.240202
I0831 13:38:05.277451 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.240207 (* 1 = 0.240207 loss)
I0831 13:38:05.277464 916722 sgd_solver.cpp:106] Iteration 3131500, lr = 0.01
I0831 13:38:35.020135 916722 solver.cpp:218] Iteration 3132000 (16.8108 iter/s, 29.7429s/500 iters), loss = 0.0828379
I0831 13:38:35.020187 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0828435 (* 1 = 0.0828435 loss)
I0831 13:38:35.020196 916722 sgd_solver.cpp:106] Iteration 3132000, lr = 0.01
I0831 13:39:04.768013 916722 solver.cpp:218] Iteration 3132500 (16.8079 iter/s, 29.748s/500 iters), loss = 0.310248
I0831 13:39:04.768074 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.310253 (* 1 = 0.310253 loss)
I0831 13:39:04.768081 916722 sgd_solver.cpp:106] Iteration 3132500, lr = 0.01
I0831 13:39:34.515318 916722 solver.cpp:218] Iteration 3133000 (16.8082 iter/s, 29.7474s/500 iters), loss = 0.0635633
I0831 13:39:34.515369 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0635688 (* 1 = 0.0635688 loss)
I0831 13:39:34.515378 916722 sgd_solver.cpp:106] Iteration 3133000, lr = 0.01
I0831 13:40:04.264459 916722 solver.cpp:218] Iteration 3133500 (16.8071 iter/s, 29.7492s/500 iters), loss = 0.181872
I0831 13:40:04.264518 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.181877 (* 1 = 0.181877 loss)
I0831 13:40:04.264528 916722 sgd_solver.cpp:106] Iteration 3133500, lr = 0.01
I0831 13:40:34.013468 916722 solver.cpp:218] Iteration 3134000 (16.8072 iter/s, 29.7491s/500 iters), loss = 0.0598387
I0831 13:40:34.013520 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0598443 (* 1 = 0.0598443 loss)
I0831 13:40:34.013528 916722 sgd_solver.cpp:106] Iteration 3134000, lr = 0.01
I0831 13:41:03.762533 916722 solver.cpp:218] Iteration 3134500 (16.8072 iter/s, 29.7492s/500 iters), loss = 0.091694
I0831 13:41:03.762591 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0916997 (* 1 = 0.0916997 loss)
I0831 13:41:03.762600 916722 sgd_solver.cpp:106] Iteration 3134500, lr = 0.01
I0831 13:41:33.510042 916722 solver.cpp:218] Iteration 3135000 (16.8081 iter/s, 29.7476s/500 iters), loss = 0.15798
I0831 13:41:33.510097 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.157985 (* 1 = 0.157985 loss)
I0831 13:41:33.510107 916722 sgd_solver.cpp:106] Iteration 3135000, lr = 0.01
I0831 13:42:03.253944 916722 solver.cpp:218] Iteration 3135500 (16.8101 iter/s, 29.744s/500 iters), loss = 0.126916
I0831 13:42:03.254004 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.126921 (* 1 = 0.126921 loss)
I0831 13:42:03.254011 916722 sgd_solver.cpp:106] Iteration 3135500, lr = 0.01
I0831 13:42:33.001984 916722 solver.cpp:218] Iteration 3136000 (16.8078 iter/s, 29.7481s/500 iters), loss = 0.197176
I0831 13:42:33.002040 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.197182 (* 1 = 0.197182 loss)
I0831 13:42:33.002051 916722 sgd_solver.cpp:106] Iteration 3136000, lr = 0.01
I0831 13:43:02.749598 916722 solver.cpp:218] Iteration 3136500 (16.808 iter/s, 29.7477s/500 iters), loss = 0.350729
I0831 13:43:02.749655 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.350734 (* 1 = 0.350734 loss)
I0831 13:43:02.749662 916722 sgd_solver.cpp:106] Iteration 3136500, lr = 0.01
I0831 13:43:32.496950 916722 solver.cpp:218] Iteration 3137000 (16.8082 iter/s, 29.7474s/500 iters), loss = 0.386189
I0831 13:43:32.497000 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.386195 (* 1 = 0.386195 loss)
I0831 13:43:32.497010 916722 sgd_solver.cpp:106] Iteration 3137000, lr = 0.01
I0831 13:44:02.240860 916722 solver.cpp:218] Iteration 3137500 (16.8101 iter/s, 29.7439s/500 iters), loss = 0.10354
I0831 13:44:02.240916 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.103545 (* 1 = 0.103545 loss)
I0831 13:44:02.240923 916722 sgd_solver.cpp:106] Iteration 3137500, lr = 0.01
I0831 13:44:31.989010 916722 solver.cpp:218] Iteration 3138000 (16.8077 iter/s, 29.7482s/500 iters), loss = 0.0337909
I0831 13:44:31.989064 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0337966 (* 1 = 0.0337966 loss)
I0831 13:44:31.989086 916722 sgd_solver.cpp:106] Iteration 3138000, lr = 0.01
I0831 13:45:01.733435 916722 solver.cpp:218] Iteration 3138500 (16.8099 iter/s, 29.7444s/500 iters), loss = 0.154969
I0831 13:45:01.733507 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.154975 (* 1 = 0.154975 loss)
I0831 13:45:01.733516 916722 sgd_solver.cpp:106] Iteration 3138500, lr = 0.01
I0831 13:45:31.478477 916722 solver.cpp:218] Iteration 3139000 (16.8095 iter/s, 29.7451s/500 iters), loss = 0.132876
I0831 13:45:31.478531 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.132882 (* 1 = 0.132882 loss)
I0831 13:45:31.478543 916722 sgd_solver.cpp:106] Iteration 3139000, lr = 0.01
I0831 13:46:01.222981 916722 solver.cpp:218] Iteration 3139500 (16.8098 iter/s, 29.7445s/500 iters), loss = 0.308664
I0831 13:46:01.223038 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.30867 (* 1 = 0.30867 loss)
I0831 13:46:01.223047 916722 sgd_solver.cpp:106] Iteration 3139500, lr = 0.01
I0831 13:46:30.971429 916722 solver.cpp:218] Iteration 3140000 (16.8076 iter/s, 29.7485s/500 iters), loss = 0.151918
I0831 13:46:30.971482 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.151923 (* 1 = 0.151923 loss)
I0831 13:46:30.971491 916722 sgd_solver.cpp:106] Iteration 3140000, lr = 0.01
I0831 13:47:00.714426 916722 solver.cpp:218] Iteration 3140500 (16.8107 iter/s, 29.743s/500 iters), loss = 0.150263
I0831 13:47:00.714483 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.150269 (* 1 = 0.150269 loss)
I0831 13:47:00.714491 916722 sgd_solver.cpp:106] Iteration 3140500, lr = 0.01
I0831 13:47:30.458606 916722 solver.cpp:218] Iteration 3141000 (16.81 iter/s, 29.7442s/500 iters), loss = 0.197561
I0831 13:47:30.458659 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.197567 (* 1 = 0.197567 loss)
I0831 13:47:30.458669 916722 sgd_solver.cpp:106] Iteration 3141000, lr = 0.01
I0831 13:48:00.207851 916722 solver.cpp:218] Iteration 3141500 (16.8071 iter/s, 29.7492s/500 iters), loss = 0.0911486
I0831 13:48:00.207909 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0911544 (* 1 = 0.0911544 loss)
I0831 13:48:00.207918 916722 sgd_solver.cpp:106] Iteration 3141500, lr = 0.01
I0831 13:48:29.950953 916722 solver.cpp:218] Iteration 3142000 (16.8106 iter/s, 29.7431s/500 iters), loss = 0.122746
I0831 13:48:29.951007 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.122751 (* 1 = 0.122751 loss)
I0831 13:48:29.951017 916722 sgd_solver.cpp:106] Iteration 3142000, lr = 0.01
I0831 13:48:59.697929 916722 solver.cpp:218] Iteration 3142500 (16.8084 iter/s, 29.747s/500 iters), loss = 0.100914
I0831 13:48:59.697993 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.100919 (* 1 = 0.100919 loss)
I0831 13:48:59.698001 916722 sgd_solver.cpp:106] Iteration 3142500, lr = 0.01
I0831 13:49:29.444027 916722 solver.cpp:218] Iteration 3143000 (16.8089 iter/s, 29.7461s/500 iters), loss = 0.0644789
I0831 13:49:29.444082 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0644844 (* 1 = 0.0644844 loss)
I0831 13:49:29.444090 916722 sgd_solver.cpp:106] Iteration 3143000, lr = 0.01
I0831 13:49:59.187561 916722 solver.cpp:218] Iteration 3143500 (16.8104 iter/s, 29.7435s/500 iters), loss = 0.0668312
I0831 13:49:59.187623 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0668367 (* 1 = 0.0668367 loss)
I0831 13:49:59.187631 916722 sgd_solver.cpp:106] Iteration 3143500, lr = 0.01
I0831 13:50:28.931782 916722 solver.cpp:218] Iteration 3144000 (16.81 iter/s, 29.7442s/500 iters), loss = 0.124887
I0831 13:50:28.931835 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.124892 (* 1 = 0.124892 loss)
I0831 13:50:28.931844 916722 sgd_solver.cpp:106] Iteration 3144000, lr = 0.01
I0831 13:50:58.676721 916722 solver.cpp:218] Iteration 3144500 (16.8096 iter/s, 29.7449s/500 iters), loss = 0.13093
I0831 13:50:58.676811 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130936 (* 1 = 0.130936 loss)
I0831 13:50:58.676820 916722 sgd_solver.cpp:106] Iteration 3144500, lr = 0.01
I0831 13:51:28.420601 916722 solver.cpp:218] Iteration 3145000 (16.8102 iter/s, 29.7438s/500 iters), loss = 0.0643559
I0831 13:51:28.420656 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0643615 (* 1 = 0.0643615 loss)
I0831 13:51:28.420666 916722 sgd_solver.cpp:106] Iteration 3145000, lr = 0.01
I0831 13:51:58.167060 916722 solver.cpp:218] Iteration 3145500 (16.8087 iter/s, 29.7464s/500 iters), loss = 0.186964
I0831 13:51:58.167119 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.186969 (* 1 = 0.186969 loss)
I0831 13:51:58.167126 916722 sgd_solver.cpp:106] Iteration 3145500, lr = 0.01
I0831 13:52:27.917645 916722 solver.cpp:218] Iteration 3146000 (16.8064 iter/s, 29.7506s/500 iters), loss = 0.232716
I0831 13:52:27.917694 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.232722 (* 1 = 0.232722 loss)
I0831 13:52:27.917703 916722 sgd_solver.cpp:106] Iteration 3146000, lr = 0.01
I0831 13:52:57.667484 916722 solver.cpp:218] Iteration 3146500 (16.8068 iter/s, 29.7498s/500 iters), loss = 0.052618
I0831 13:52:57.667544 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0526238 (* 1 = 0.0526238 loss)
I0831 13:52:57.667553 916722 sgd_solver.cpp:106] Iteration 3146500, lr = 0.01
I0831 13:53:27.412142 916722 solver.cpp:218] Iteration 3147000 (16.8098 iter/s, 29.7446s/500 iters), loss = 0.14661
I0831 13:53:27.412199 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.146616 (* 1 = 0.146616 loss)
I0831 13:53:27.412209 916722 sgd_solver.cpp:106] Iteration 3147000, lr = 0.01
I0831 13:53:57.161098 916722 solver.cpp:218] Iteration 3147500 (16.8073 iter/s, 29.7489s/500 iters), loss = 0.0261617
I0831 13:53:57.161159 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0261675 (* 1 = 0.0261675 loss)
I0831 13:53:57.161167 916722 sgd_solver.cpp:106] Iteration 3147500, lr = 0.01
I0831 13:54:26.905840 916722 solver.cpp:218] Iteration 3148000 (16.8097 iter/s, 29.7447s/500 iters), loss = 0.128393
I0831 13:54:26.905894 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128399 (* 1 = 0.128399 loss)
I0831 13:54:26.905905 916722 sgd_solver.cpp:106] Iteration 3148000, lr = 0.01
I0831 13:54:56.653468 916722 solver.cpp:218] Iteration 3148500 (16.8081 iter/s, 29.7476s/500 iters), loss = 0.0632961
I0831 13:54:56.653528 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0633021 (* 1 = 0.0633021 loss)
I0831 13:54:56.653537 916722 sgd_solver.cpp:106] Iteration 3148500, lr = 0.01
I0831 13:55:26.398964 916722 solver.cpp:218] Iteration 3149000 (16.8093 iter/s, 29.7455s/500 iters), loss = 0.337317
I0831 13:55:26.399016 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.337323 (* 1 = 0.337323 loss)
I0831 13:55:26.399027 916722 sgd_solver.cpp:106] Iteration 3149000, lr = 0.01
I0831 13:55:56.142159 916722 solver.cpp:218] Iteration 3149500 (16.8106 iter/s, 29.7432s/500 iters), loss = 0.274459
I0831 13:55:56.142220 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.274465 (* 1 = 0.274465 loss)
I0831 13:55:56.142227 916722 sgd_solver.cpp:106] Iteration 3149500, lr = 0.01
I0831 13:56:25.827033 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_3150000.caffemodel
I0831 13:56:25.846244 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_3150000.solverstate
I0831 13:56:25.852324 916722 solver.cpp:330] Iteration 3150000, Testing net (#0)
I0831 13:56:41.264356 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8928
I0831 13:56:41.264411 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.361539 (* 1 = 0.361539 loss)
I0831 13:56:41.322976 916722 solver.cpp:218] Iteration 3150000 (11.0667 iter/s, 45.1808s/500 iters), loss = 0.163704
I0831 13:56:41.323004 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.16371 (* 1 = 0.16371 loss)
I0831 13:56:41.323012 916722 sgd_solver.cpp:106] Iteration 3150000, lr = 0.01
I0831 13:57:11.082736 916722 solver.cpp:218] Iteration 3150500 (16.8012 iter/s, 29.7597s/500 iters), loss = 0.0999296
I0831 13:57:11.082808 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0999356 (* 1 = 0.0999356 loss)
I0831 13:57:11.082818 916722 sgd_solver.cpp:106] Iteration 3150500, lr = 0.01
I0831 13:57:40.841526 916722 solver.cpp:218] Iteration 3151000 (16.8018 iter/s, 29.7587s/500 iters), loss = 0.290239
I0831 13:57:40.841600 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.290245 (* 1 = 0.290245 loss)
I0831 13:57:40.841609 916722 sgd_solver.cpp:106] Iteration 3151000, lr = 0.01
I0831 13:58:10.599058 916722 solver.cpp:218] Iteration 3151500 (16.8025 iter/s, 29.7575s/500 iters), loss = 0.0663742
I0831 13:58:10.599112 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0663803 (* 1 = 0.0663803 loss)
I0831 13:58:10.599123 916722 sgd_solver.cpp:106] Iteration 3151500, lr = 0.01
I0831 13:58:40.356500 916722 solver.cpp:218] Iteration 3152000 (16.8025 iter/s, 29.7574s/500 iters), loss = 0.204641
I0831 13:58:40.356560 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.204647 (* 1 = 0.204647 loss)
I0831 13:58:40.356570 916722 sgd_solver.cpp:106] Iteration 3152000, lr = 0.01
I0831 13:59:10.115952 916722 solver.cpp:218] Iteration 3152500 (16.8014 iter/s, 29.7594s/500 iters), loss = 0.22297
I0831 13:59:10.116006 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.222976 (* 1 = 0.222976 loss)
I0831 13:59:10.116016 916722 sgd_solver.cpp:106] Iteration 3152500, lr = 0.01
I0831 13:59:39.876029 916722 solver.cpp:218] Iteration 3153000 (16.8011 iter/s, 29.76s/500 iters), loss = 0.0897847
I0831 13:59:39.876106 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0897909 (* 1 = 0.0897909 loss)
I0831 13:59:39.876114 916722 sgd_solver.cpp:106] Iteration 3153000, lr = 0.01
I0831 14:00:09.636807 916722 solver.cpp:218] Iteration 3153500 (16.8007 iter/s, 29.7607s/500 iters), loss = 0.0942708
I0831 14:00:09.636862 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0942767 (* 1 = 0.0942767 loss)
I0831 14:00:09.636873 916722 sgd_solver.cpp:106] Iteration 3153500, lr = 0.01
I0831 14:00:39.394928 916722 solver.cpp:218] Iteration 3154000 (16.8022 iter/s, 29.7581s/500 iters), loss = 0.107293
I0831 14:00:39.394987 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.107299 (* 1 = 0.107299 loss)
I0831 14:00:39.394996 916722 sgd_solver.cpp:106] Iteration 3154000, lr = 0.01
I0831 14:01:09.158730 916722 solver.cpp:218] Iteration 3154500 (16.799 iter/s, 29.7638s/500 iters), loss = 0.18099
I0831 14:01:09.158782 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.180996 (* 1 = 0.180996 loss)
I0831 14:01:09.158792 916722 sgd_solver.cpp:106] Iteration 3154500, lr = 0.01
I0831 14:01:38.927089 916722 solver.cpp:218] Iteration 3155000 (16.7964 iter/s, 29.7683s/500 iters), loss = 0.110468
I0831 14:01:38.927145 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110474 (* 1 = 0.110474 loss)
I0831 14:01:38.927152 916722 sgd_solver.cpp:106] Iteration 3155000, lr = 0.01
I0831 14:02:08.689473 916722 solver.cpp:218] Iteration 3155500 (16.7998 iter/s, 29.7623s/500 iters), loss = 0.0506965
I0831 14:02:08.689527 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0507024 (* 1 = 0.0507024 loss)
I0831 14:02:08.689538 916722 sgd_solver.cpp:106] Iteration 3155500, lr = 0.01
I0831 14:02:38.456132 916722 solver.cpp:218] Iteration 3156000 (16.798 iter/s, 29.7655s/500 iters), loss = 0.449742
I0831 14:02:38.456194 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.449748 (* 1 = 0.449748 loss)
I0831 14:02:38.456203 916722 sgd_solver.cpp:106] Iteration 3156000, lr = 0.01
I0831 14:03:08.221971 916722 solver.cpp:218] Iteration 3156500 (16.7985 iter/s, 29.7645s/500 iters), loss = 0.183478
I0831 14:03:08.222023 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.183484 (* 1 = 0.183484 loss)
I0831 14:03:08.222033 916722 sgd_solver.cpp:106] Iteration 3156500, lr = 0.01
I0831 14:03:37.990010 916722 solver.cpp:218] Iteration 3157000 (16.7973 iter/s, 29.7668s/500 iters), loss = 0.137925
I0831 14:03:37.990083 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.137931 (* 1 = 0.137931 loss)
I0831 14:03:37.990092 916722 sgd_solver.cpp:106] Iteration 3157000, lr = 0.01
I0831 14:04:07.758889 916722 solver.cpp:218] Iteration 3157500 (16.7968 iter/s, 29.7676s/500 iters), loss = 0.0453677
I0831 14:04:07.758944 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0453738 (* 1 = 0.0453738 loss)
I0831 14:04:07.758953 916722 sgd_solver.cpp:106] Iteration 3157500, lr = 0.01
I0831 14:04:37.524186 916722 solver.cpp:218] Iteration 3158000 (16.7987 iter/s, 29.7641s/500 iters), loss = 0.203132
I0831 14:04:37.524245 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.203138 (* 1 = 0.203138 loss)
I0831 14:04:37.524253 916722 sgd_solver.cpp:106] Iteration 3158000, lr = 0.01
I0831 14:05:07.292618 916722 solver.cpp:218] Iteration 3158500 (16.7969 iter/s, 29.7673s/500 iters), loss = 0.0593309
I0831 14:05:07.292671 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.059337 (* 1 = 0.059337 loss)
I0831 14:05:07.292681 916722 sgd_solver.cpp:106] Iteration 3158500, lr = 0.01
I0831 14:05:37.055589 916722 solver.cpp:218] Iteration 3159000 (16.8 iter/s, 29.7619s/500 iters), loss = 0.210121
I0831 14:05:37.055646 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.210127 (* 1 = 0.210127 loss)
I0831 14:05:37.055655 916722 sgd_solver.cpp:106] Iteration 3159000, lr = 0.01
I0831 14:06:06.832463 916722 solver.cpp:218] Iteration 3159500 (16.7921 iter/s, 29.7759s/500 iters), loss = 0.125922
I0831 14:06:06.832511 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.125928 (* 1 = 0.125928 loss)
I0831 14:06:06.832520 916722 sgd_solver.cpp:106] Iteration 3159500, lr = 0.01
I0831 14:06:36.609617 916722 solver.cpp:218] Iteration 3160000 (16.7919 iter/s, 29.7762s/500 iters), loss = 0.0314976
I0831 14:06:36.609678 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0315035 (* 1 = 0.0315035 loss)
I0831 14:06:36.609686 916722 sgd_solver.cpp:106] Iteration 3160000, lr = 0.01
I0831 14:07:06.386587 916722 solver.cpp:218] Iteration 3160500 (16.792 iter/s, 29.776s/500 iters), loss = 0.193613
I0831 14:07:06.386643 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.193619 (* 1 = 0.193619 loss)
I0831 14:07:06.386653 916722 sgd_solver.cpp:106] Iteration 3160500, lr = 0.01
I0831 14:07:36.169486 916722 solver.cpp:218] Iteration 3161000 (16.7887 iter/s, 29.782s/500 iters), loss = 0.034553
I0831 14:07:36.169565 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0345588 (* 1 = 0.0345588 loss)
I0831 14:07:36.169574 916722 sgd_solver.cpp:106] Iteration 3161000, lr = 0.01
I0831 14:08:05.947708 916722 solver.cpp:218] Iteration 3161500 (16.7913 iter/s, 29.7774s/500 iters), loss = 0.0795058
I0831 14:08:05.947765 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0795116 (* 1 = 0.0795116 loss)
I0831 14:08:05.951581 916722 sgd_solver.cpp:106] Iteration 3161500, lr = 0.01
I0831 14:08:35.736714 916722 solver.cpp:218] Iteration 3162000 (16.7852 iter/s, 29.7882s/500 iters), loss = 0.105164
I0831 14:08:35.736784 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.10517 (* 1 = 0.10517 loss)
I0831 14:08:35.736793 916722 sgd_solver.cpp:106] Iteration 3162000, lr = 0.01
I0831 14:09:05.511061 916722 solver.cpp:218] Iteration 3162500 (16.7934 iter/s, 29.7736s/500 iters), loss = 0.0372848
I0831 14:09:05.511116 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0372905 (* 1 = 0.0372905 loss)
I0831 14:09:05.514832 916722 sgd_solver.cpp:106] Iteration 3162500, lr = 0.01
I0831 14:09:35.286108 916722 solver.cpp:218] Iteration 3163000 (16.793 iter/s, 29.7743s/500 iters), loss = 0.291664
I0831 14:09:35.286164 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.29167 (* 1 = 0.29167 loss)
I0831 14:09:35.286172 916722 sgd_solver.cpp:106] Iteration 3163000, lr = 0.01
I0831 14:10:05.053074 916722 solver.cpp:218] Iteration 3163500 (16.7975 iter/s, 29.7663s/500 iters), loss = 0.215032
I0831 14:10:05.053136 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.215038 (* 1 = 0.215038 loss)
I0831 14:10:05.053146 916722 sgd_solver.cpp:106] Iteration 3163500, lr = 0.01
I0831 14:10:34.815759 916722 solver.cpp:218] Iteration 3164000 (16.7999 iter/s, 29.762s/500 iters), loss = 0.302258
I0831 14:10:34.815829 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.302264 (* 1 = 0.302264 loss)
I0831 14:10:34.815838 916722 sgd_solver.cpp:106] Iteration 3164000, lr = 0.01
I0831 14:11:04.579071 916722 solver.cpp:218] Iteration 3164500 (16.7996 iter/s, 29.7626s/500 iters), loss = 0.131941
I0831 14:11:04.579123 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131947 (* 1 = 0.131947 loss)
I0831 14:11:04.579133 916722 sgd_solver.cpp:106] Iteration 3164500, lr = 0.01
I0831 14:11:34.349798 916722 solver.cpp:218] Iteration 3165000 (16.7954 iter/s, 29.7701s/500 iters), loss = 0.0610196
I0831 14:11:34.349853 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0610256 (* 1 = 0.0610256 loss)
I0831 14:11:34.349860 916722 sgd_solver.cpp:106] Iteration 3165000, lr = 0.01
I0831 14:12:04.115767 916722 solver.cpp:218] Iteration 3165500 (16.7981 iter/s, 29.7654s/500 iters), loss = 0.425591
I0831 14:12:04.115823 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.425597 (* 1 = 0.425597 loss)
I0831 14:12:04.115833 916722 sgd_solver.cpp:106] Iteration 3165500, lr = 0.01
I0831 14:12:33.887676 916722 solver.cpp:218] Iteration 3166000 (16.7947 iter/s, 29.7713s/500 iters), loss = 0.277764
I0831 14:12:33.887735 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.27777 (* 1 = 0.27777 loss)
I0831 14:12:33.887743 916722 sgd_solver.cpp:106] Iteration 3166000, lr = 0.01
I0831 14:13:03.651933 916722 solver.cpp:218] Iteration 3166500 (16.799 iter/s, 29.7637s/500 iters), loss = 0.0700065
I0831 14:13:03.651984 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0700123 (* 1 = 0.0700123 loss)
I0831 14:13:03.651994 916722 sgd_solver.cpp:106] Iteration 3166500, lr = 0.01
I0831 14:13:33.418067 916722 solver.cpp:218] Iteration 3167000 (16.7979 iter/s, 29.7656s/500 iters), loss = 0.0277629
I0831 14:13:33.418128 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0277686 (* 1 = 0.0277686 loss)
I0831 14:13:33.418136 916722 sgd_solver.cpp:106] Iteration 3167000, lr = 0.01
I0831 14:14:03.183945 916722 solver.cpp:218] Iteration 3167500 (16.7981 iter/s, 29.7654s/500 iters), loss = 0.274597
I0831 14:14:03.183995 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.274603 (* 1 = 0.274603 loss)
I0831 14:14:03.184005 916722 sgd_solver.cpp:106] Iteration 3167500, lr = 0.01
I0831 14:14:32.953606 916722 solver.cpp:218] Iteration 3168000 (16.7959 iter/s, 29.7692s/500 iters), loss = 0.406349
I0831 14:14:32.953661 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.406355 (* 1 = 0.406355 loss)
I0831 14:14:32.953670 916722 sgd_solver.cpp:106] Iteration 3168000, lr = 0.01
I0831 14:15:02.718026 916722 solver.cpp:218] Iteration 3168500 (16.7989 iter/s, 29.7639s/500 iters), loss = 0.143454
I0831 14:15:02.718078 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.14346 (* 1 = 0.14346 loss)
I0831 14:15:02.718088 916722 sgd_solver.cpp:106] Iteration 3168500, lr = 0.01
I0831 14:15:32.484062 916722 solver.cpp:218] Iteration 3169000 (16.7979 iter/s, 29.7656s/500 iters), loss = 0.0754356
I0831 14:15:32.484120 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.075441 (* 1 = 0.075441 loss)
I0831 14:15:32.484128 916722 sgd_solver.cpp:106] Iteration 3169000, lr = 0.01
I0831 14:16:02.247280 916722 solver.cpp:218] Iteration 3169500 (16.7995 iter/s, 29.7628s/500 iters), loss = 0.0384664
I0831 14:16:02.247332 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0384718 (* 1 = 0.0384718 loss)
I0831 14:16:02.247342 916722 sgd_solver.cpp:106] Iteration 3169500, lr = 0.01
I0831 14:16:32.012990 916722 solver.cpp:218] Iteration 3170000 (16.7981 iter/s, 29.7653s/500 iters), loss = 0.0880133
I0831 14:16:32.013062 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0880185 (* 1 = 0.0880185 loss)
I0831 14:16:32.013074 916722 sgd_solver.cpp:106] Iteration 3170000, lr = 0.01
I0831 14:17:01.777654 916722 solver.cpp:218] Iteration 3170500 (16.7987 iter/s, 29.7642s/500 iters), loss = 0.156716
I0831 14:17:01.777706 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.156721 (* 1 = 0.156721 loss)
I0831 14:17:01.777716 916722 sgd_solver.cpp:106] Iteration 3170500, lr = 0.01
I0831 14:17:31.545060 916722 solver.cpp:218] Iteration 3171000 (16.7971 iter/s, 29.767s/500 iters), loss = 0.174987
I0831 14:17:31.545120 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.174992 (* 1 = 0.174992 loss)
I0831 14:17:31.545128 916722 sgd_solver.cpp:106] Iteration 3171000, lr = 0.01
I0831 14:18:01.311730 916722 solver.cpp:218] Iteration 3171500 (16.7975 iter/s, 29.7663s/500 iters), loss = 0.113119
I0831 14:18:01.311781 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.113124 (* 1 = 0.113124 loss)
I0831 14:18:01.311791 916722 sgd_solver.cpp:106] Iteration 3171500, lr = 0.01
I0831 14:18:31.078050 916722 solver.cpp:218] Iteration 3172000 (16.7977 iter/s, 29.7659s/500 iters), loss = 0.123854
I0831 14:18:31.078111 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.123859 (* 1 = 0.123859 loss)
I0831 14:18:31.078119 916722 sgd_solver.cpp:106] Iteration 3172000, lr = 0.01
I0831 14:19:00.846769 916722 solver.cpp:218] Iteration 3172500 (16.7964 iter/s, 29.7683s/500 iters), loss = 0.0582699
I0831 14:19:00.846819 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.058275 (* 1 = 0.058275 loss)
I0831 14:19:00.846827 916722 sgd_solver.cpp:106] Iteration 3172500, lr = 0.01
I0831 14:19:30.613436 916722 solver.cpp:218] Iteration 3173000 (16.7975 iter/s, 29.7663s/500 iters), loss = 0.121379
I0831 14:19:30.613497 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.121384 (* 1 = 0.121384 loss)
I0831 14:19:30.613505 916722 sgd_solver.cpp:106] Iteration 3173000, lr = 0.01
I0831 14:20:00.375547 916722 solver.cpp:218] Iteration 3173500 (16.8001 iter/s, 29.7617s/500 iters), loss = 0.262414
I0831 14:20:00.375602 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.262419 (* 1 = 0.262419 loss)
I0831 14:20:00.375610 916722 sgd_solver.cpp:106] Iteration 3173500, lr = 0.01
I0831 14:20:30.140223 916722 solver.cpp:218] Iteration 3174000 (16.7986 iter/s, 29.7643s/500 iters), loss = 0.0947597
I0831 14:20:30.140283 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.094765 (* 1 = 0.094765 loss)
I0831 14:20:30.140292 916722 sgd_solver.cpp:106] Iteration 3174000, lr = 0.01
I0831 14:20:59.903401 916722 solver.cpp:218] Iteration 3174500 (16.7995 iter/s, 29.7628s/500 iters), loss = 0.0578432
I0831 14:20:59.903455 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0578486 (* 1 = 0.0578486 loss)
I0831 14:20:59.903465 916722 sgd_solver.cpp:106] Iteration 3174500, lr = 0.01
I0831 14:21:29.667455 916722 solver.cpp:218] Iteration 3175000 (16.799 iter/s, 29.7637s/500 iters), loss = 0.0381524
I0831 14:21:29.667517 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0381578 (* 1 = 0.0381578 loss)
I0831 14:21:29.667526 916722 sgd_solver.cpp:106] Iteration 3175000, lr = 0.01
I0831 14:21:59.430438 916722 solver.cpp:218] Iteration 3175500 (16.7996 iter/s, 29.7626s/500 iters), loss = 0.040108
I0831 14:21:59.430492 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0401135 (* 1 = 0.0401135 loss)
I0831 14:21:59.430501 916722 sgd_solver.cpp:106] Iteration 3175500, lr = 0.01
I0831 14:22:29.192605 916722 solver.cpp:218] Iteration 3176000 (16.8 iter/s, 29.7618s/500 iters), loss = 0.125603
I0831 14:22:29.192667 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.125609 (* 1 = 0.125609 loss)
I0831 14:22:29.192677 916722 sgd_solver.cpp:106] Iteration 3176000, lr = 0.01
I0831 14:22:58.957356 916722 solver.cpp:218] Iteration 3176500 (16.7986 iter/s, 29.7644s/500 iters), loss = 0.044777
I0831 14:22:58.957409 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0447826 (* 1 = 0.0447826 loss)
I0831 14:22:58.957429 916722 sgd_solver.cpp:106] Iteration 3176500, lr = 0.01
I0831 14:23:28.721662 916722 solver.cpp:218] Iteration 3177000 (16.7988 iter/s, 29.764s/500 iters), loss = 0.145984
I0831 14:23:28.721733 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.14599 (* 1 = 0.14599 loss)
I0831 14:23:28.721741 916722 sgd_solver.cpp:106] Iteration 3177000, lr = 0.01
I0831 14:23:58.488656 916722 solver.cpp:218] Iteration 3177500 (16.7973 iter/s, 29.7667s/500 iters), loss = 0.262611
I0831 14:23:58.488713 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.262616 (* 1 = 0.262616 loss)
I0831 14:23:58.488723 916722 sgd_solver.cpp:106] Iteration 3177500, lr = 0.01
I0831 14:24:28.253595 916722 solver.cpp:218] Iteration 3178000 (16.7985 iter/s, 29.7646s/500 iters), loss = 0.175085
I0831 14:24:28.253657 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.17509 (* 1 = 0.17509 loss)
I0831 14:24:28.253665 916722 sgd_solver.cpp:106] Iteration 3178000, lr = 0.01
I0831 14:24:58.017007 916722 solver.cpp:218] Iteration 3178500 (16.7993 iter/s, 29.7631s/500 iters), loss = 0.128038
I0831 14:24:58.017062 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128044 (* 1 = 0.128044 loss)
I0831 14:24:58.017073 916722 sgd_solver.cpp:106] Iteration 3178500, lr = 0.01
I0831 14:25:27.785998 916722 solver.cpp:218] Iteration 3179000 (16.7962 iter/s, 29.7687s/500 iters), loss = 0.192992
I0831 14:25:27.786058 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.192997 (* 1 = 0.192997 loss)
I0831 14:25:27.786067 916722 sgd_solver.cpp:106] Iteration 3179000, lr = 0.01
I0831 14:25:57.556496 916722 solver.cpp:218] Iteration 3179500 (16.7953 iter/s, 29.7702s/500 iters), loss = 0.1318
I0831 14:25:57.556556 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131806 (* 1 = 0.131806 loss)
I0831 14:25:57.556566 916722 sgd_solver.cpp:106] Iteration 3179500, lr = 0.01
I0831 14:26:27.325455 916722 solver.cpp:218] Iteration 3180000 (16.7962 iter/s, 29.7687s/500 iters), loss = 0.106401
I0831 14:26:27.325515 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.106407 (* 1 = 0.106407 loss)
I0831 14:26:27.325523 916722 sgd_solver.cpp:106] Iteration 3180000, lr = 0.01
I0831 14:26:57.092680 916722 solver.cpp:218] Iteration 3180500 (16.7972 iter/s, 29.7669s/500 iters), loss = 0.126154
I0831 14:26:57.092736 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.126159 (* 1 = 0.126159 loss)
I0831 14:26:57.092756 916722 sgd_solver.cpp:106] Iteration 3180500, lr = 0.01
I0831 14:27:26.861277 916722 solver.cpp:218] Iteration 3181000 (16.7964 iter/s, 29.7683s/500 iters), loss = 0.14052
I0831 14:27:26.861336 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.140526 (* 1 = 0.140526 loss)
I0831 14:27:26.861346 916722 sgd_solver.cpp:106] Iteration 3181000, lr = 0.01
I0831 14:27:56.627825 916722 solver.cpp:218] Iteration 3181500 (16.7975 iter/s, 29.7663s/500 iters), loss = 0.0684234
I0831 14:27:56.627877 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0684287 (* 1 = 0.0684287 loss)
I0831 14:27:56.627887 916722 sgd_solver.cpp:106] Iteration 3181500, lr = 0.01
I0831 14:28:26.391647 916722 solver.cpp:218] Iteration 3182000 (16.7991 iter/s, 29.7636s/500 iters), loss = 0.142699
I0831 14:28:26.391705 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.142705 (* 1 = 0.142705 loss)
I0831 14:28:26.391713 916722 sgd_solver.cpp:106] Iteration 3182000, lr = 0.01
I0831 14:28:56.157076 916722 solver.cpp:218] Iteration 3182500 (16.7982 iter/s, 29.7652s/500 iters), loss = 0.124069
I0831 14:28:56.157132 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.124074 (* 1 = 0.124074 loss)
I0831 14:28:56.157142 916722 sgd_solver.cpp:106] Iteration 3182500, lr = 0.01
I0831 14:29:25.926832 916722 solver.cpp:218] Iteration 3183000 (16.7957 iter/s, 29.7695s/500 iters), loss = 0.0384189
I0831 14:29:25.926896 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0384244 (* 1 = 0.0384244 loss)
I0831 14:29:25.926905 916722 sgd_solver.cpp:106] Iteration 3183000, lr = 0.01
I0831 14:29:55.692724 916722 solver.cpp:218] Iteration 3183500 (16.7979 iter/s, 29.7656s/500 iters), loss = 0.0427583
I0831 14:29:55.692780 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0427638 (* 1 = 0.0427638 loss)
I0831 14:29:55.692788 916722 sgd_solver.cpp:106] Iteration 3183500, lr = 0.01
I0831 14:30:25.460656 916722 solver.cpp:218] Iteration 3184000 (16.7967 iter/s, 29.7677s/500 iters), loss = 0.11011
I0831 14:30:25.460731 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110115 (* 1 = 0.110115 loss)
I0831 14:30:25.460750 916722 sgd_solver.cpp:106] Iteration 3184000, lr = 0.01
I0831 14:30:55.226562 916722 solver.cpp:218] Iteration 3184500 (16.7979 iter/s, 29.7656s/500 iters), loss = 0.131264
I0831 14:30:55.226616 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13127 (* 1 = 0.13127 loss)
I0831 14:30:55.226625 916722 sgd_solver.cpp:106] Iteration 3184500, lr = 0.01
I0831 14:31:24.991871 916722 solver.cpp:218] Iteration 3185000 (16.7982 iter/s, 29.7651s/500 iters), loss = 0.0539752
I0831 14:31:24.991931 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.053981 (* 1 = 0.053981 loss)
I0831 14:31:24.991940 916722 sgd_solver.cpp:106] Iteration 3185000, lr = 0.01
I0831 14:31:54.757323 916722 solver.cpp:218] Iteration 3185500 (16.7981 iter/s, 29.7652s/500 iters), loss = 0.0478168
I0831 14:31:54.757376 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0478225 (* 1 = 0.0478225 loss)
I0831 14:31:54.757385 916722 sgd_solver.cpp:106] Iteration 3185500, lr = 0.01
I0831 14:32:24.522379 916722 solver.cpp:218] Iteration 3186000 (16.7984 iter/s, 29.7648s/500 iters), loss = 0.147078
I0831 14:32:24.522437 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.147084 (* 1 = 0.147084 loss)
I0831 14:32:24.522446 916722 sgd_solver.cpp:106] Iteration 3186000, lr = 0.01
I0831 14:32:54.288260 916722 solver.cpp:218] Iteration 3186500 (16.7979 iter/s, 29.7656s/500 iters), loss = 0.0867352
I0831 14:32:54.288316 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0867408 (* 1 = 0.0867408 loss)
I0831 14:32:54.288324 916722 sgd_solver.cpp:106] Iteration 3186500, lr = 0.01
I0831 14:33:24.054774 916722 solver.cpp:218] Iteration 3187000 (16.7975 iter/s, 29.7663s/500 iters), loss = 0.0813411
I0831 14:33:24.054836 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0813467 (* 1 = 0.0813467 loss)
I0831 14:33:24.054844 916722 sgd_solver.cpp:106] Iteration 3187000, lr = 0.01
I0831 14:33:53.820235 916722 solver.cpp:218] Iteration 3187500 (16.7981 iter/s, 29.7652s/500 iters), loss = 0.108873
I0831 14:33:53.820289 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.108879 (* 1 = 0.108879 loss)
I0831 14:33:53.820298 916722 sgd_solver.cpp:106] Iteration 3187500, lr = 0.01
I0831 14:34:23.588999 916722 solver.cpp:218] Iteration 3188000 (16.7963 iter/s, 29.7685s/500 iters), loss = 0.210902
I0831 14:34:23.589061 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.210908 (* 1 = 0.210908 loss)
I0831 14:34:23.589069 916722 sgd_solver.cpp:106] Iteration 3188000, lr = 0.01
I0831 14:34:53.350843 916722 solver.cpp:218] Iteration 3188500 (16.8002 iter/s, 29.7616s/500 iters), loss = 0.088183
I0831 14:34:53.350901 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0881886 (* 1 = 0.0881886 loss)
I0831 14:34:53.350911 916722 sgd_solver.cpp:106] Iteration 3188500, lr = 0.01
I0831 14:35:23.114099 916722 solver.cpp:218] Iteration 3189000 (16.7994 iter/s, 29.763s/500 iters), loss = 0.15416
I0831 14:35:23.114159 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.154165 (* 1 = 0.154165 loss)
I0831 14:35:23.114167 916722 sgd_solver.cpp:106] Iteration 3189000, lr = 0.01
I0831 14:35:52.873996 916722 solver.cpp:218] Iteration 3189500 (16.8013 iter/s, 29.7597s/500 iters), loss = 0.281392
I0831 14:35:52.874050 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.281397 (* 1 = 0.281397 loss)
I0831 14:35:52.874060 916722 sgd_solver.cpp:106] Iteration 3189500, lr = 0.01
I0831 14:36:22.635645 916722 solver.cpp:218] Iteration 3190000 (16.8003 iter/s, 29.7614s/500 iters), loss = 0.255174
I0831 14:36:22.635715 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.255179 (* 1 = 0.255179 loss)
I0831 14:36:22.635727 916722 sgd_solver.cpp:106] Iteration 3190000, lr = 0.01
I0831 14:36:52.398416 916722 solver.cpp:218] Iteration 3190500 (16.7992 iter/s, 29.7634s/500 iters), loss = 0.387122
I0831 14:36:52.398483 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.387127 (* 1 = 0.387127 loss)
I0831 14:36:52.398492 916722 sgd_solver.cpp:106] Iteration 3190500, lr = 0.01
I0831 14:37:22.156895 916722 solver.cpp:218] Iteration 3191000 (16.8016 iter/s, 29.7591s/500 iters), loss = 0.0892406
I0831 14:37:22.156949 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0892463 (* 1 = 0.0892463 loss)
I0831 14:37:22.156957 916722 sgd_solver.cpp:106] Iteration 3191000, lr = 0.01
I0831 14:37:51.917135 916722 solver.cpp:218] Iteration 3191500 (16.8006 iter/s, 29.7608s/500 iters), loss = 0.0313318
I0831 14:37:51.917189 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0313376 (* 1 = 0.0313376 loss)
I0831 14:37:51.917197 916722 sgd_solver.cpp:106] Iteration 3191500, lr = 0.01
I0831 14:38:21.682744 916722 solver.cpp:218] Iteration 3192000 (16.7976 iter/s, 29.7661s/500 iters), loss = 0.0171587
I0831 14:38:21.682806 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0171644 (* 1 = 0.0171644 loss)
I0831 14:38:21.682813 916722 sgd_solver.cpp:106] Iteration 3192000, lr = 0.01
I0831 14:38:51.440534 916722 solver.cpp:218] Iteration 3192500 (16.8021 iter/s, 29.7583s/500 iters), loss = 0.139086
I0831 14:38:51.440589 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139091 (* 1 = 0.139091 loss)
I0831 14:38:51.440598 916722 sgd_solver.cpp:106] Iteration 3192500, lr = 0.01
I0831 14:39:21.206665 916722 solver.cpp:218] Iteration 3193000 (16.7974 iter/s, 29.7666s/500 iters), loss = 0.0932292
I0831 14:39:21.206727 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0932351 (* 1 = 0.0932351 loss)
I0831 14:39:21.206735 916722 sgd_solver.cpp:106] Iteration 3193000, lr = 0.01
I0831 14:39:50.970528 916722 solver.cpp:218] Iteration 3193500 (16.7987 iter/s, 29.7643s/500 iters), loss = 0.273852
I0831 14:39:50.970584 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.273858 (* 1 = 0.273858 loss)
I0831 14:39:50.970594 916722 sgd_solver.cpp:106] Iteration 3193500, lr = 0.01
I0831 14:40:20.736078 916722 solver.cpp:218] Iteration 3194000 (16.7977 iter/s, 29.7659s/500 iters), loss = 0.170117
I0831 14:40:20.736137 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.170123 (* 1 = 0.170123 loss)
I0831 14:40:20.736145 916722 sgd_solver.cpp:106] Iteration 3194000, lr = 0.01
I0831 14:40:50.500694 916722 solver.cpp:218] Iteration 3194500 (16.7983 iter/s, 29.765s/500 iters), loss = 0.239331
I0831 14:40:50.500758 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.239337 (* 1 = 0.239337 loss)
I0831 14:40:50.500768 916722 sgd_solver.cpp:106] Iteration 3194500, lr = 0.01
I0831 14:41:20.262648 916722 solver.cpp:218] Iteration 3195000 (16.7998 iter/s, 29.7623s/500 iters), loss = 0.077873
I0831 14:41:20.262704 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0778787 (* 1 = 0.0778787 loss)
I0831 14:41:20.262712 916722 sgd_solver.cpp:106] Iteration 3195000, lr = 0.01
I0831 14:41:50.028712 916722 solver.cpp:218] Iteration 3195500 (16.7975 iter/s, 29.7664s/500 iters), loss = 0.203759
I0831 14:41:50.028779 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.203765 (* 1 = 0.203765 loss)
I0831 14:41:50.028789 916722 sgd_solver.cpp:106] Iteration 3195500, lr = 0.01
I0831 14:42:19.795889 916722 solver.cpp:218] Iteration 3196000 (16.7969 iter/s, 29.7675s/500 iters), loss = 0.194392
I0831 14:42:19.795953 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.194398 (* 1 = 0.194398 loss)
I0831 14:42:19.795960 916722 sgd_solver.cpp:106] Iteration 3196000, lr = 0.01
I0831 14:42:49.555920 916722 solver.cpp:218] Iteration 3196500 (16.8009 iter/s, 29.7603s/500 iters), loss = 0.0173871
I0831 14:42:49.555986 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0173928 (* 1 = 0.0173928 loss)
I0831 14:42:49.555997 916722 sgd_solver.cpp:106] Iteration 3196500, lr = 0.01
I0831 14:43:19.322098 916722 solver.cpp:218] Iteration 3197000 (16.7975 iter/s, 29.7664s/500 iters), loss = 0.146789
I0831 14:43:19.322168 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.146795 (* 1 = 0.146795 loss)
I0831 14:43:19.322177 916722 sgd_solver.cpp:106] Iteration 3197000, lr = 0.01
I0831 14:43:49.085896 916722 solver.cpp:218] Iteration 3197500 (16.7988 iter/s, 29.764s/500 iters), loss = 0.088437
I0831 14:43:49.085952 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0884425 (* 1 = 0.0884425 loss)
I0831 14:43:49.085960 916722 sgd_solver.cpp:106] Iteration 3197500, lr = 0.01
I0831 14:44:18.856235 916722 solver.cpp:218] Iteration 3198000 (16.7951 iter/s, 29.7706s/500 iters), loss = 0.221447
I0831 14:44:18.856298 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.221452 (* 1 = 0.221452 loss)
I0831 14:44:18.856307 916722 sgd_solver.cpp:106] Iteration 3198000, lr = 0.01
I0831 14:44:48.622938 916722 solver.cpp:218] Iteration 3198500 (16.7972 iter/s, 29.7669s/500 iters), loss = 0.0518916
I0831 14:44:48.622993 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0518972 (* 1 = 0.0518972 loss)
I0831 14:44:48.623001 916722 sgd_solver.cpp:106] Iteration 3198500, lr = 0.01
I0831 14:45:18.386577 916722 solver.cpp:218] Iteration 3199000 (16.7989 iter/s, 29.7638s/500 iters), loss = 0.138939
I0831 14:45:18.386636 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.138944 (* 1 = 0.138944 loss)
I0831 14:45:18.386644 916722 sgd_solver.cpp:106] Iteration 3199000, lr = 0.01
I0831 14:45:48.153129 916722 solver.cpp:218] Iteration 3199500 (16.7973 iter/s, 29.7667s/500 iters), loss = 0.113793
I0831 14:45:48.153182 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.113798 (* 1 = 0.113798 loss)
I0831 14:45:48.153192 916722 sgd_solver.cpp:106] Iteration 3199500, lr = 0.01
I0831 14:46:17.862951 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_3200000.caffemodel
I0831 14:46:17.881981 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_3200000.solverstate
I0831 14:46:17.888042 916722 solver.cpp:330] Iteration 3200000, Testing net (#0)
I0831 14:46:33.271809 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8825
I0831 14:46:33.271857 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.429776 (* 1 = 0.429776 loss)
I0831 14:46:33.330613 916722 solver.cpp:218] Iteration 3200000 (11.0674 iter/s, 45.1777s/500 iters), loss = 0.255525
I0831 14:46:33.330642 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.255531 (* 1 = 0.255531 loss)
I0831 14:46:33.330651 916722 sgd_solver.cpp:106] Iteration 3200000, lr = 0.01
I0831 14:47:03.078456 916722 solver.cpp:218] Iteration 3200500 (16.8079 iter/s, 29.748s/500 iters), loss = 0.083917
I0831 14:47:03.078516 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0839224 (* 1 = 0.0839224 loss)
I0831 14:47:03.078523 916722 sgd_solver.cpp:106] Iteration 3200500, lr = 0.01
I0831 14:47:32.834154 916722 solver.cpp:218] Iteration 3201000 (16.8034 iter/s, 29.7558s/500 iters), loss = 0.261187
I0831 14:47:32.834206 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.261192 (* 1 = 0.261192 loss)
I0831 14:47:32.834214 916722 sgd_solver.cpp:106] Iteration 3201000, lr = 0.01
I0831 14:48:02.590737 916722 solver.cpp:218] Iteration 3201500 (16.8029 iter/s, 29.7567s/500 iters), loss = 0.105645
I0831 14:48:02.590795 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105651 (* 1 = 0.105651 loss)
I0831 14:48:02.590803 916722 sgd_solver.cpp:106] Iteration 3201500, lr = 0.01
I0831 14:48:32.353863 916722 solver.cpp:218] Iteration 3202000 (16.7993 iter/s, 29.7632s/500 iters), loss = 0.0643631
I0831 14:48:32.353920 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0643687 (* 1 = 0.0643687 loss)
I0831 14:48:32.353942 916722 sgd_solver.cpp:106] Iteration 3202000, lr = 0.01
I0831 14:49:02.118098 916722 solver.cpp:218] Iteration 3202500 (16.7986 iter/s, 29.7643s/500 iters), loss = 0.133316
I0831 14:49:02.118165 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133322 (* 1 = 0.133322 loss)
I0831 14:49:02.118175 916722 sgd_solver.cpp:106] Iteration 3202500, lr = 0.01
I0831 14:49:31.890502 916722 solver.cpp:218] Iteration 3203000 (16.794 iter/s, 29.7725s/500 iters), loss = 0.148078
I0831 14:49:31.890556 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.148083 (* 1 = 0.148083 loss)
I0831 14:49:31.890566 916722 sgd_solver.cpp:106] Iteration 3203000, lr = 0.01
I0831 14:50:01.655357 916722 solver.cpp:218] Iteration 3203500 (16.7983 iter/s, 29.7649s/500 iters), loss = 0.0427925
I0831 14:50:01.655416 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0427979 (* 1 = 0.0427979 loss)
I0831 14:50:01.655424 916722 sgd_solver.cpp:106] Iteration 3203500, lr = 0.01
I0831 14:50:31.421268 916722 solver.cpp:218] Iteration 3204000 (16.7977 iter/s, 29.766s/500 iters), loss = 0.115829
I0831 14:50:31.421321 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115834 (* 1 = 0.115834 loss)
I0831 14:50:31.421331 916722 sgd_solver.cpp:106] Iteration 3204000, lr = 0.01
I0831 14:51:01.188649 916722 solver.cpp:218] Iteration 3204500 (16.7969 iter/s, 29.7674s/500 iters), loss = 0.0201095
I0831 14:51:01.188707 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0201149 (* 1 = 0.0201149 loss)
I0831 14:51:01.188715 916722 sgd_solver.cpp:106] Iteration 3204500, lr = 0.01
I0831 14:51:30.958134 916722 solver.cpp:218] Iteration 3205000 (16.7957 iter/s, 29.7695s/500 iters), loss = 0.22755
I0831 14:51:30.958186 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.227555 (* 1 = 0.227555 loss)
I0831 14:51:30.958196 916722 sgd_solver.cpp:106] Iteration 3205000, lr = 0.01
I0831 14:52:00.726996 916722 solver.cpp:218] Iteration 3205500 (16.796 iter/s, 29.7689s/500 iters), loss = 0.0749192
I0831 14:52:00.727054 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0749244 (* 1 = 0.0749244 loss)
I0831 14:52:00.727062 916722 sgd_solver.cpp:106] Iteration 3205500, lr = 0.01
I0831 14:52:30.495898 916722 solver.cpp:218] Iteration 3206000 (16.796 iter/s, 29.7689s/500 iters), loss = 0.27455
I0831 14:52:30.495947 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.274555 (* 1 = 0.274555 loss)
I0831 14:52:30.495956 916722 sgd_solver.cpp:106] Iteration 3206000, lr = 0.01
I0831 14:53:00.268445 916722 solver.cpp:218] Iteration 3206500 (16.794 iter/s, 29.7726s/500 iters), loss = 0.018826
I0831 14:53:00.268508 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0188312 (* 1 = 0.0188312 loss)
I0831 14:53:00.268517 916722 sgd_solver.cpp:106] Iteration 3206500, lr = 0.01
I0831 14:53:30.039778 916722 solver.cpp:218] Iteration 3207000 (16.7947 iter/s, 29.7713s/500 iters), loss = 0.1317
I0831 14:53:30.039832 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131705 (* 1 = 0.131705 loss)
I0831 14:53:30.039840 916722 sgd_solver.cpp:106] Iteration 3207000, lr = 0.01
I0831 14:53:59.805222 916722 solver.cpp:218] Iteration 3207500 (16.798 iter/s, 29.7655s/500 iters), loss = 0.0755743
I0831 14:53:59.805284 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0755795 (* 1 = 0.0755795 loss)
I0831 14:53:59.805291 916722 sgd_solver.cpp:106] Iteration 3207500, lr = 0.01
I0831 14:54:29.575845 916722 solver.cpp:218] Iteration 3208000 (16.7951 iter/s, 29.7706s/500 iters), loss = 0.0930471
I0831 14:54:29.575898 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0930521 (* 1 = 0.0930521 loss)
I0831 14:54:29.575907 916722 sgd_solver.cpp:106] Iteration 3208000, lr = 0.01
I0831 14:54:59.345780 916722 solver.cpp:218] Iteration 3208500 (16.7955 iter/s, 29.7699s/500 iters), loss = 0.0682036
I0831 14:54:59.345852 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0682084 (* 1 = 0.0682084 loss)
I0831 14:54:59.345865 916722 sgd_solver.cpp:106] Iteration 3208500, lr = 0.01
I0831 14:55:29.113139 916722 solver.cpp:218] Iteration 3209000 (16.7969 iter/s, 29.7673s/500 iters), loss = 0.0976913
I0831 14:55:29.113195 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0976961 (* 1 = 0.0976961 loss)
I0831 14:55:29.113204 916722 sgd_solver.cpp:106] Iteration 3209000, lr = 0.01
I0831 14:55:58.879259 916722 solver.cpp:218] Iteration 3209500 (16.7976 iter/s, 29.7661s/500 iters), loss = 0.120002
I0831 14:55:58.879321 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.120007 (* 1 = 0.120007 loss)
I0831 14:55:58.879329 916722 sgd_solver.cpp:106] Iteration 3209500, lr = 0.01
I0831 14:56:28.642176 916722 solver.cpp:218] Iteration 3210000 (16.7994 iter/s, 29.7629s/500 iters), loss = 0.0594941
I0831 14:56:28.642231 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0594988 (* 1 = 0.0594988 loss)
I0831 14:56:28.642241 916722 sgd_solver.cpp:106] Iteration 3210000, lr = 0.01
I0831 14:56:58.407570 916722 solver.cpp:218] Iteration 3210500 (16.798 iter/s, 29.7654s/500 iters), loss = 0.215604
I0831 14:56:58.407632 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.215609 (* 1 = 0.215609 loss)
I0831 14:56:58.407640 916722 sgd_solver.cpp:106] Iteration 3210500, lr = 0.01
I0831 14:57:28.178225 916722 solver.cpp:218] Iteration 3211000 (16.7951 iter/s, 29.7706s/500 iters), loss = 0.192258
I0831 14:57:28.178279 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.192262 (* 1 = 0.192262 loss)
I0831 14:57:28.178288 916722 sgd_solver.cpp:106] Iteration 3211000, lr = 0.01
I0831 14:57:57.963937 916722 solver.cpp:218] Iteration 3211500 (16.7866 iter/s, 29.7857s/500 iters), loss = 0.0435472
I0831 14:57:57.964000 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0435516 (* 1 = 0.0435516 loss)
I0831 14:57:57.964010 916722 sgd_solver.cpp:106] Iteration 3211500, lr = 0.01
I0831 14:58:27.739449 916722 solver.cpp:218] Iteration 3212000 (16.7923 iter/s, 29.7755s/500 iters), loss = 0.0508243
I0831 14:58:27.739504 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0508288 (* 1 = 0.0508288 loss)
I0831 14:58:27.739516 916722 sgd_solver.cpp:106] Iteration 3212000, lr = 0.01
I0831 14:58:57.519716 916722 solver.cpp:218] Iteration 3212500 (16.7897 iter/s, 29.7802s/500 iters), loss = 0.113984
I0831 14:58:57.519773 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.113989 (* 1 = 0.113989 loss)
I0831 14:58:57.519781 916722 sgd_solver.cpp:106] Iteration 3212500, lr = 0.01
I0831 14:59:27.301227 916722 solver.cpp:218] Iteration 3213000 (16.789 iter/s, 29.7815s/500 iters), loss = 0.0645804
I0831 14:59:27.301285 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.064585 (* 1 = 0.064585 loss)
I0831 14:59:27.301295 916722 sgd_solver.cpp:106] Iteration 3213000, lr = 0.01
I0831 14:59:57.080683 916722 solver.cpp:218] Iteration 3213500 (16.7901 iter/s, 29.7794s/500 iters), loss = 0.135342
I0831 14:59:57.080744 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.135347 (* 1 = 0.135347 loss)
I0831 14:59:57.080754 916722 sgd_solver.cpp:106] Iteration 3213500, lr = 0.01
I0831 15:00:26.860903 916722 solver.cpp:218] Iteration 3214000 (16.7897 iter/s, 29.7802s/500 iters), loss = 0.112966
I0831 15:00:26.860957 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112971 (* 1 = 0.112971 loss)
I0831 15:00:26.860967 916722 sgd_solver.cpp:106] Iteration 3214000, lr = 0.01
I0831 15:00:56.647445 916722 solver.cpp:218] Iteration 3214500 (16.7861 iter/s, 29.7865s/500 iters), loss = 0.133145
I0831 15:00:56.647505 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13315 (* 1 = 0.13315 loss)
I0831 15:00:56.647513 916722 sgd_solver.cpp:106] Iteration 3214500, lr = 0.01
I0831 15:01:26.423806 916722 solver.cpp:218] Iteration 3215000 (16.7919 iter/s, 29.7763s/500 iters), loss = 0.0849425
I0831 15:01:26.423861 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0849471 (* 1 = 0.0849471 loss)
I0831 15:01:26.423884 916722 sgd_solver.cpp:106] Iteration 3215000, lr = 0.01
I0831 15:01:56.204248 916722 solver.cpp:218] Iteration 3215500 (16.7896 iter/s, 29.7804s/500 iters), loss = 0.0720435
I0831 15:01:56.204320 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0720482 (* 1 = 0.0720482 loss)
I0831 15:01:56.204329 916722 sgd_solver.cpp:106] Iteration 3215500, lr = 0.01
I0831 15:02:25.981688 916722 solver.cpp:218] Iteration 3216000 (16.7913 iter/s, 29.7774s/500 iters), loss = 0.139843
I0831 15:02:25.981739 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139847 (* 1 = 0.139847 loss)
I0831 15:02:25.981750 916722 sgd_solver.cpp:106] Iteration 3216000, lr = 0.01
I0831 15:02:55.758270 916722 solver.cpp:218] Iteration 3216500 (16.7917 iter/s, 29.7765s/500 iters), loss = 0.0160703
I0831 15:02:55.758329 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0160749 (* 1 = 0.0160749 loss)
I0831 15:02:55.758337 916722 sgd_solver.cpp:106] Iteration 3216500, lr = 0.01
I0831 15:03:25.535311 916722 solver.cpp:218] Iteration 3217000 (16.7915 iter/s, 29.777s/500 iters), loss = 0.0240547
I0831 15:03:25.535364 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0240591 (* 1 = 0.0240591 loss)
I0831 15:03:25.535374 916722 sgd_solver.cpp:106] Iteration 3217000, lr = 0.01
I0831 15:03:55.307518 916722 solver.cpp:218] Iteration 3217500 (16.7942 iter/s, 29.7722s/500 iters), loss = 0.209497
I0831 15:03:55.307585 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.209501 (* 1 = 0.209501 loss)
I0831 15:03:55.307593 916722 sgd_solver.cpp:106] Iteration 3217500, lr = 0.01
I0831 15:04:25.057762 916722 solver.cpp:218] Iteration 3218000 (16.8066 iter/s, 29.7502s/500 iters), loss = 0.167143
I0831 15:04:25.057816 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.167147 (* 1 = 0.167147 loss)
I0831 15:04:25.057826 916722 sgd_solver.cpp:106] Iteration 3218000, lr = 0.01
I0831 15:04:54.808687 916722 solver.cpp:218] Iteration 3218500 (16.8062 iter/s, 29.7509s/500 iters), loss = 0.0676594
I0831 15:04:54.808751 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0676638 (* 1 = 0.0676638 loss)
I0831 15:04:54.808759 916722 sgd_solver.cpp:106] Iteration 3218500, lr = 0.01
I0831 15:05:24.560482 916722 solver.cpp:218] Iteration 3219000 (16.8057 iter/s, 29.7517s/500 iters), loss = 0.194255
I0831 15:05:24.560535 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.194259 (* 1 = 0.194259 loss)
I0831 15:05:24.560544 916722 sgd_solver.cpp:106] Iteration 3219000, lr = 0.01
I0831 15:05:54.311846 916722 solver.cpp:218] Iteration 3219500 (16.806 iter/s, 29.7513s/500 iters), loss = 0.121457
I0831 15:05:54.311908 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.121461 (* 1 = 0.121461 loss)
I0831 15:05:54.311915 916722 sgd_solver.cpp:106] Iteration 3219500, lr = 0.01
I0831 15:06:24.066846 916722 solver.cpp:218] Iteration 3220000 (16.8039 iter/s, 29.7549s/500 iters), loss = 0.226408
I0831 15:06:24.066901 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.226412 (* 1 = 0.226412 loss)
I0831 15:06:24.066910 916722 sgd_solver.cpp:106] Iteration 3220000, lr = 0.01
I0831 15:06:53.818588 916722 solver.cpp:218] Iteration 3220500 (16.8058 iter/s, 29.7517s/500 iters), loss = 0.0965741
I0831 15:06:53.818648 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0965784 (* 1 = 0.0965784 loss)
I0831 15:06:53.818657 916722 sgd_solver.cpp:106] Iteration 3220500, lr = 0.01
I0831 15:07:23.573839 916722 solver.cpp:218] Iteration 3221000 (16.8038 iter/s, 29.7552s/500 iters), loss = 0.0893886
I0831 15:07:23.573891 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0893929 (* 1 = 0.0893929 loss)
I0831 15:07:23.573900 916722 sgd_solver.cpp:106] Iteration 3221000, lr = 0.01
I0831 15:07:53.325819 916722 solver.cpp:218] Iteration 3221500 (16.8056 iter/s, 29.7519s/500 iters), loss = 0.11531
I0831 15:07:53.325891 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115314 (* 1 = 0.115314 loss)
I0831 15:07:53.325899 916722 sgd_solver.cpp:106] Iteration 3221500, lr = 0.01
I0831 15:08:23.080577 916722 solver.cpp:218] Iteration 3222000 (16.8041 iter/s, 29.7547s/500 iters), loss = 0.0786603
I0831 15:08:23.080633 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0786645 (* 1 = 0.0786645 loss)
I0831 15:08:23.080641 916722 sgd_solver.cpp:106] Iteration 3222000, lr = 0.01
I0831 15:08:52.837699 916722 solver.cpp:218] Iteration 3222500 (16.8027 iter/s, 29.7571s/500 iters), loss = 0.19663
I0831 15:08:52.837762 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.196635 (* 1 = 0.196635 loss)
I0831 15:08:52.837770 916722 sgd_solver.cpp:106] Iteration 3222500, lr = 0.01
I0831 15:09:22.592913 916722 solver.cpp:218] Iteration 3223000 (16.8038 iter/s, 29.7551s/500 iters), loss = 0.180118
I0831 15:09:22.592969 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.180122 (* 1 = 0.180122 loss)
I0831 15:09:22.592979 916722 sgd_solver.cpp:106] Iteration 3223000, lr = 0.01
I0831 15:09:52.348403 916722 solver.cpp:218] Iteration 3223500 (16.8037 iter/s, 29.7554s/500 iters), loss = 0.0944893
I0831 15:09:52.348469 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0944935 (* 1 = 0.0944935 loss)
I0831 15:09:52.348477 916722 sgd_solver.cpp:106] Iteration 3223500, lr = 0.01
I0831 15:10:22.101306 916722 solver.cpp:218] Iteration 3224000 (16.8051 iter/s, 29.7528s/500 iters), loss = 0.263712
I0831 15:10:22.101361 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.263716 (* 1 = 0.263716 loss)
I0831 15:10:22.101370 916722 sgd_solver.cpp:106] Iteration 3224000, lr = 0.01
I0831 15:10:51.854300 916722 solver.cpp:218] Iteration 3224500 (16.8051 iter/s, 29.7529s/500 iters), loss = 0.180597
I0831 15:10:51.854359 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.180601 (* 1 = 0.180601 loss)
I0831 15:10:51.854368 916722 sgd_solver.cpp:106] Iteration 3224500, lr = 0.01
I0831 15:11:21.609861 916722 solver.cpp:218] Iteration 3225000 (16.8037 iter/s, 29.7554s/500 iters), loss = 0.193366
I0831 15:11:21.609915 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.19337 (* 1 = 0.19337 loss)
I0831 15:11:21.609925 916722 sgd_solver.cpp:106] Iteration 3225000, lr = 0.01
I0831 15:11:51.365320 916722 solver.cpp:218] Iteration 3225500 (16.8037 iter/s, 29.7553s/500 iters), loss = 0.128575
I0831 15:11:51.365376 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128579 (* 1 = 0.128579 loss)
I0831 15:11:51.365386 916722 sgd_solver.cpp:106] Iteration 3225500, lr = 0.01
I0831 15:12:21.118800 916722 solver.cpp:218] Iteration 3226000 (16.8048 iter/s, 29.7533s/500 iters), loss = 0.0643256
I0831 15:12:21.118855 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0643301 (* 1 = 0.0643301 loss)
I0831 15:12:21.118865 916722 sgd_solver.cpp:106] Iteration 3226000, lr = 0.01
I0831 15:12:50.872678 916722 solver.cpp:218] Iteration 3226500 (16.8046 iter/s, 29.7537s/500 iters), loss = 0.219859
I0831 15:12:50.872738 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.219863 (* 1 = 0.219863 loss)
I0831 15:12:50.872747 916722 sgd_solver.cpp:106] Iteration 3226500, lr = 0.01
I0831 15:13:20.626628 916722 solver.cpp:218] Iteration 3227000 (16.8046 iter/s, 29.7538s/500 iters), loss = 0.0793232
I0831 15:13:20.626683 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0793277 (* 1 = 0.0793277 loss)
I0831 15:13:20.626693 916722 sgd_solver.cpp:106] Iteration 3227000, lr = 0.01
I0831 15:13:50.384088 916722 solver.cpp:218] Iteration 3227500 (16.8026 iter/s, 29.7573s/500 iters), loss = 0.266962
I0831 15:13:50.384152 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.266966 (* 1 = 0.266966 loss)
I0831 15:13:50.384161 916722 sgd_solver.cpp:106] Iteration 3227500, lr = 0.01
I0831 15:14:20.141458 916722 solver.cpp:218] Iteration 3228000 (16.8026 iter/s, 29.7572s/500 iters), loss = 0.0239199
I0831 15:14:20.141511 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0239244 (* 1 = 0.0239244 loss)
I0831 15:14:20.141520 916722 sgd_solver.cpp:106] Iteration 3228000, lr = 0.01
I0831 15:14:49.899626 916722 solver.cpp:218] Iteration 3228500 (16.8022 iter/s, 29.758s/500 iters), loss = 0.115029
I0831 15:14:49.899699 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115034 (* 1 = 0.115034 loss)
I0831 15:14:49.899708 916722 sgd_solver.cpp:106] Iteration 3228500, lr = 0.01
I0831 15:15:19.671190 916722 solver.cpp:218] Iteration 3229000 (16.7946 iter/s, 29.7714s/500 iters), loss = 0.200644
I0831 15:15:19.671243 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.200649 (* 1 = 0.200649 loss)
I0831 15:15:19.671252 916722 sgd_solver.cpp:106] Iteration 3229000, lr = 0.01
I0831 15:15:49.437701 916722 solver.cpp:218] Iteration 3229500 (16.7975 iter/s, 29.7664s/500 iters), loss = 0.134581
I0831 15:15:49.437762 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.134585 (* 1 = 0.134585 loss)
I0831 15:15:49.437770 916722 sgd_solver.cpp:106] Iteration 3229500, lr = 0.01
I0831 15:16:19.211643 916722 solver.cpp:218] Iteration 3230000 (16.7933 iter/s, 29.7738s/500 iters), loss = 0.0251449
I0831 15:16:19.211695 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0251494 (* 1 = 0.0251494 loss)
I0831 15:16:19.211704 916722 sgd_solver.cpp:106] Iteration 3230000, lr = 0.01
I0831 15:16:48.991935 916722 solver.cpp:218] Iteration 3230500 (16.7897 iter/s, 29.7802s/500 iters), loss = 0.0444092
I0831 15:16:48.991997 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0444138 (* 1 = 0.0444138 loss)
I0831 15:16:48.992005 916722 sgd_solver.cpp:106] Iteration 3230500, lr = 0.01
I0831 15:17:18.771068 916722 solver.cpp:218] Iteration 3231000 (16.7904 iter/s, 29.779s/500 iters), loss = 0.141609
I0831 15:17:18.771121 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.141614 (* 1 = 0.141614 loss)
I0831 15:17:18.771131 916722 sgd_solver.cpp:106] Iteration 3231000, lr = 0.01
I0831 15:17:48.550520 916722 solver.cpp:218] Iteration 3231500 (16.7902 iter/s, 29.7793s/500 iters), loss = 0.12593
I0831 15:17:48.550580 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.125934 (* 1 = 0.125934 loss)
I0831 15:17:48.550588 916722 sgd_solver.cpp:106] Iteration 3231500, lr = 0.01
I0831 15:18:18.334636 916722 solver.cpp:218] Iteration 3232000 (16.7875 iter/s, 29.784s/500 iters), loss = 0.0316005
I0831 15:18:18.334690 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.031605 (* 1 = 0.031605 loss)
I0831 15:18:18.334698 916722 sgd_solver.cpp:106] Iteration 3232000, lr = 0.01
I0831 15:18:48.103698 916722 solver.cpp:218] Iteration 3232500 (16.796 iter/s, 29.769s/500 iters), loss = 0.107208
I0831 15:18:48.103762 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.107212 (* 1 = 0.107212 loss)
I0831 15:18:48.103771 916722 sgd_solver.cpp:106] Iteration 3232500, lr = 0.01
I0831 15:19:17.868477 916722 solver.cpp:218] Iteration 3233000 (16.7985 iter/s, 29.7647s/500 iters), loss = 0.242905
I0831 15:19:17.868530 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.242909 (* 1 = 0.242909 loss)
I0831 15:19:17.868541 916722 sgd_solver.cpp:106] Iteration 3233000, lr = 0.01
I0831 15:19:47.634652 916722 solver.cpp:218] Iteration 3233500 (16.7977 iter/s, 29.7661s/500 iters), loss = 0.0832935
I0831 15:19:47.634712 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.083298 (* 1 = 0.083298 loss)
I0831 15:19:47.634721 916722 sgd_solver.cpp:106] Iteration 3233500, lr = 0.01
I0831 15:20:17.395273 916722 solver.cpp:218] Iteration 3234000 (16.8008 iter/s, 29.7605s/500 iters), loss = 0.294364
I0831 15:20:17.395326 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.294369 (* 1 = 0.294369 loss)
I0831 15:20:17.395335 916722 sgd_solver.cpp:106] Iteration 3234000, lr = 0.01
I0831 15:20:47.156538 916722 solver.cpp:218] Iteration 3234500 (16.8004 iter/s, 29.7612s/500 iters), loss = 0.236176
I0831 15:20:47.156597 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.236181 (* 1 = 0.236181 loss)
I0831 15:20:47.156606 916722 sgd_solver.cpp:106] Iteration 3234500, lr = 0.01
I0831 15:21:16.914589 916722 solver.cpp:218] Iteration 3235000 (16.8022 iter/s, 29.7579s/500 iters), loss = 0.22595
I0831 15:21:16.914655 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.225954 (* 1 = 0.225954 loss)
I0831 15:21:16.914664 916722 sgd_solver.cpp:106] Iteration 3235000, lr = 0.01
I0831 15:21:46.676342 916722 solver.cpp:218] Iteration 3235500 (16.8002 iter/s, 29.7616s/500 iters), loss = 0.327321
I0831 15:21:46.676420 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.327326 (* 1 = 0.327326 loss)
I0831 15:21:46.676434 916722 sgd_solver.cpp:106] Iteration 3235500, lr = 0.01
I0831 15:22:16.445591 916722 solver.cpp:218] Iteration 3236000 (16.7959 iter/s, 29.7691s/500 iters), loss = 0.227527
I0831 15:22:16.445644 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.227531 (* 1 = 0.227531 loss)
I0831 15:22:16.445653 916722 sgd_solver.cpp:106] Iteration 3236000, lr = 0.01
I0831 15:22:46.213676 916722 solver.cpp:218] Iteration 3236500 (16.7966 iter/s, 29.768s/500 iters), loss = 0.243953
I0831 15:22:46.213737 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.243957 (* 1 = 0.243957 loss)
I0831 15:22:46.213747 916722 sgd_solver.cpp:106] Iteration 3236500, lr = 0.01
I0831 15:23:15.984181 916722 solver.cpp:218] Iteration 3237000 (16.7952 iter/s, 29.7704s/500 iters), loss = 0.00864659
I0831 15:23:15.984238 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.00865135 (* 1 = 0.00865135 loss)
I0831 15:23:15.984249 916722 sgd_solver.cpp:106] Iteration 3237000, lr = 0.01
I0831 15:23:45.757732 916722 solver.cpp:218] Iteration 3237500 (16.7935 iter/s, 29.7734s/500 iters), loss = 0.146177
I0831 15:23:45.757793 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.146182 (* 1 = 0.146182 loss)
I0831 15:23:45.757802 916722 sgd_solver.cpp:106] Iteration 3237500, lr = 0.01
I0831 15:24:15.525504 916722 solver.cpp:218] Iteration 3238000 (16.7967 iter/s, 29.7677s/500 iters), loss = 0.0680972
I0831 15:24:15.525557 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.068102 (* 1 = 0.068102 loss)
I0831 15:24:15.525568 916722 sgd_solver.cpp:106] Iteration 3238000, lr = 0.01
I0831 15:24:45.288836 916722 solver.cpp:218] Iteration 3238500 (16.7993 iter/s, 29.7632s/500 iters), loss = 0.108277
I0831 15:24:45.288892 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.108282 (* 1 = 0.108282 loss)
I0831 15:24:45.288900 916722 sgd_solver.cpp:106] Iteration 3238500, lr = 0.01
I0831 15:25:15.057122 916722 solver.cpp:218] Iteration 3239000 (16.7965 iter/s, 29.7682s/500 iters), loss = 0.215061
I0831 15:25:15.057173 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.215066 (* 1 = 0.215066 loss)
I0831 15:25:15.057183 916722 sgd_solver.cpp:106] Iteration 3239000, lr = 0.01
I0831 15:25:44.817046 916722 solver.cpp:218] Iteration 3239500 (16.8012 iter/s, 29.7598s/500 iters), loss = 0.265182
I0831 15:25:44.817106 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.265186 (* 1 = 0.265186 loss)
I0831 15:25:44.817116 916722 sgd_solver.cpp:106] Iteration 3239500, lr = 0.01
I0831 15:26:14.579133 916722 solver.cpp:218] Iteration 3240000 (16.8 iter/s, 29.762s/500 iters), loss = 0.0310048
I0831 15:26:14.579187 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0310095 (* 1 = 0.0310095 loss)
I0831 15:26:14.579198 916722 sgd_solver.cpp:106] Iteration 3240000, lr = 0.01
I0831 15:26:44.344178 916722 solver.cpp:218] Iteration 3240500 (16.7983 iter/s, 29.7649s/500 iters), loss = 0.281229
I0831 15:26:44.344238 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.281234 (* 1 = 0.281234 loss)
I0831 15:26:44.344246 916722 sgd_solver.cpp:106] Iteration 3240500, lr = 0.01
I0831 15:27:14.107597 916722 solver.cpp:218] Iteration 3241000 (16.7992 iter/s, 29.7633s/500 iters), loss = 0.195427
I0831 15:27:14.107650 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.195432 (* 1 = 0.195432 loss)
I0831 15:27:14.107661 916722 sgd_solver.cpp:106] Iteration 3241000, lr = 0.01
I0831 15:27:43.871840 916722 solver.cpp:218] Iteration 3241500 (16.7987 iter/s, 29.7641s/500 iters), loss = 0.110085
I0831 15:27:43.871919 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.11009 (* 1 = 0.11009 loss)
I0831 15:27:43.871928 916722 sgd_solver.cpp:106] Iteration 3241500, lr = 0.01
I0831 15:28:13.632359 916722 solver.cpp:218] Iteration 3242000 (16.8009 iter/s, 29.7604s/500 iters), loss = 0.189179
I0831 15:28:13.632406 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.189184 (* 1 = 0.189184 loss)
I0831 15:28:13.632416 916722 sgd_solver.cpp:106] Iteration 3242000, lr = 0.01
I0831 15:28:43.393007 916722 solver.cpp:218] Iteration 3242500 (16.8008 iter/s, 29.7605s/500 iters), loss = 0.0493229
I0831 15:28:43.393069 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0493278 (* 1 = 0.0493278 loss)
I0831 15:28:43.393079 916722 sgd_solver.cpp:106] Iteration 3242500, lr = 0.01
I0831 15:29:13.151793 916722 solver.cpp:218] Iteration 3243000 (16.8018 iter/s, 29.7587s/500 iters), loss = 0.0708388
I0831 15:29:13.151844 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0708437 (* 1 = 0.0708437 loss)
I0831 15:29:13.151852 916722 sgd_solver.cpp:106] Iteration 3243000, lr = 0.01
I0831 15:29:42.916491 916722 solver.cpp:218] Iteration 3243500 (16.7985 iter/s, 29.7646s/500 iters), loss = 0.104323
I0831 15:29:42.916553 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104328 (* 1 = 0.104328 loss)
I0831 15:29:42.916561 916722 sgd_solver.cpp:106] Iteration 3243500, lr = 0.01
I0831 15:30:12.661828 916722 solver.cpp:218] Iteration 3244000 (16.8094 iter/s, 29.7452s/500 iters), loss = 0.230317
I0831 15:30:12.661881 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.230322 (* 1 = 0.230322 loss)
I0831 15:30:12.661890 916722 sgd_solver.cpp:106] Iteration 3244000, lr = 0.01
I0831 15:30:42.410405 916722 solver.cpp:218] Iteration 3244500 (16.8076 iter/s, 29.7485s/500 iters), loss = 0.113507
I0831 15:30:42.410468 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.113512 (* 1 = 0.113512 loss)
I0831 15:30:42.410476 916722 sgd_solver.cpp:106] Iteration 3244500, lr = 0.01
I0831 15:31:12.159266 916722 solver.cpp:218] Iteration 3245000 (16.8074 iter/s, 29.7488s/500 iters), loss = 0.239551
I0831 15:31:12.159319 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.239556 (* 1 = 0.239556 loss)
I0831 15:31:12.159329 916722 sgd_solver.cpp:106] Iteration 3245000, lr = 0.01
I0831 15:31:41.908144 916722 solver.cpp:218] Iteration 3245500 (16.8074 iter/s, 29.7488s/500 iters), loss = 0.126876
I0831 15:31:41.908206 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.126881 (* 1 = 0.126881 loss)
I0831 15:31:41.908215 916722 sgd_solver.cpp:106] Iteration 3245500, lr = 0.01
I0831 15:32:11.658182 916722 solver.cpp:218] Iteration 3246000 (16.8068 iter/s, 29.7499s/500 iters), loss = 0.0336046
I0831 15:32:11.658238 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0336098 (* 1 = 0.0336098 loss)
I0831 15:32:11.658247 916722 sgd_solver.cpp:106] Iteration 3246000, lr = 0.01
I0831 15:32:41.402397 916722 solver.cpp:218] Iteration 3246500 (16.81 iter/s, 29.7441s/500 iters), loss = 0.148039
I0831 15:32:41.402457 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.148044 (* 1 = 0.148044 loss)
I0831 15:32:41.402465 916722 sgd_solver.cpp:106] Iteration 3246500, lr = 0.01
I0831 15:33:11.148517 916722 solver.cpp:218] Iteration 3247000 (16.809 iter/s, 29.746s/500 iters), loss = 0.383811
I0831 15:33:11.148571 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.383816 (* 1 = 0.383816 loss)
I0831 15:33:11.148578 916722 sgd_solver.cpp:106] Iteration 3247000, lr = 0.01
I0831 15:33:40.897433 916722 solver.cpp:218] Iteration 3247500 (16.8074 iter/s, 29.7488s/500 iters), loss = 0.0309297
I0831 15:33:40.897491 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0309349 (* 1 = 0.0309349 loss)
I0831 15:33:40.897500 916722 sgd_solver.cpp:106] Iteration 3247500, lr = 0.01
I0831 15:34:10.648030 916722 solver.cpp:218] Iteration 3248000 (16.8064 iter/s, 29.7505s/500 iters), loss = 0.0578886
I0831 15:34:10.648087 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0578939 (* 1 = 0.0578939 loss)
I0831 15:34:10.648108 916722 sgd_solver.cpp:106] Iteration 3248000, lr = 0.01
I0831 15:34:40.394517 916722 solver.cpp:218] Iteration 3248500 (16.8088 iter/s, 29.7464s/500 iters), loss = 0.0613589
I0831 15:34:40.394588 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0613643 (* 1 = 0.0613643 loss)
I0831 15:34:40.394598 916722 sgd_solver.cpp:106] Iteration 3248500, lr = 0.01
I0831 15:35:10.140832 916722 solver.cpp:218] Iteration 3249000 (16.8089 iter/s, 29.7462s/500 iters), loss = 0.0562505
I0831 15:35:10.140887 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0562559 (* 1 = 0.0562559 loss)
I0831 15:35:10.140898 916722 sgd_solver.cpp:106] Iteration 3249000, lr = 0.01
I0831 15:35:39.886289 916722 solver.cpp:218] Iteration 3249500 (16.8093 iter/s, 29.7454s/500 iters), loss = 0.172233
I0831 15:35:39.886351 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.172238 (* 1 = 0.172238 loss)
I0831 15:35:39.886359 916722 sgd_solver.cpp:106] Iteration 3249500, lr = 0.01
I0831 15:36:09.574049 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_3250000.caffemodel
I0831 15:36:09.593070 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_3250000.solverstate
I0831 15:36:09.599107 916722 solver.cpp:330] Iteration 3250000, Testing net (#0)
I0831 15:36:24.954111 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8744
I0831 15:36:24.954161 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.43142 (* 1 = 0.43142 loss)
I0831 15:36:25.012634 916722 solver.cpp:218] Iteration 3250000 (11.08 iter/s, 45.1262s/500 iters), loss = 0.375087
I0831 15:36:25.012661 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.375093 (* 1 = 0.375093 loss)
I0831 15:36:25.012670 916722 sgd_solver.cpp:106] Iteration 3250000, lr = 0.01
I0831 15:36:54.745419 916722 solver.cpp:218] Iteration 3250500 (16.8165 iter/s, 29.7327s/500 iters), loss = 0.128455
I0831 15:36:54.745476 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128461 (* 1 = 0.128461 loss)
I0831 15:36:54.745484 916722 sgd_solver.cpp:106] Iteration 3250500, lr = 0.01
I0831 15:37:24.483613 916722 solver.cpp:218] Iteration 3251000 (16.8135 iter/s, 29.7381s/500 iters), loss = 0.179666
I0831 15:37:24.483675 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.179671 (* 1 = 0.179671 loss)
I0831 15:37:24.483683 916722 sgd_solver.cpp:106] Iteration 3251000, lr = 0.01
I0831 15:37:54.222718 916722 solver.cpp:218] Iteration 3251500 (16.8129 iter/s, 29.739s/500 iters), loss = 0.310117
I0831 15:37:54.222771 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.310122 (* 1 = 0.310122 loss)
I0831 15:37:54.222781 916722 sgd_solver.cpp:106] Iteration 3251500, lr = 0.01
I0831 15:38:23.962730 916722 solver.cpp:218] Iteration 3252000 (16.8124 iter/s, 29.7399s/500 iters), loss = 0.178779
I0831 15:38:23.962790 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.178784 (* 1 = 0.178784 loss)
I0831 15:38:23.962798 916722 sgd_solver.cpp:106] Iteration 3252000, lr = 0.01
I0831 15:38:53.706010 916722 solver.cpp:218] Iteration 3252500 (16.8106 iter/s, 29.7432s/500 iters), loss = 0.171774
I0831 15:38:53.706064 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.171779 (* 1 = 0.171779 loss)
I0831 15:38:53.706075 916722 sgd_solver.cpp:106] Iteration 3252500, lr = 0.01
I0831 15:39:23.449366 916722 solver.cpp:218] Iteration 3253000 (16.8105 iter/s, 29.7433s/500 iters), loss = 0.249511
I0831 15:39:23.449425 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.249516 (* 1 = 0.249516 loss)
I0831 15:39:23.449434 916722 sgd_solver.cpp:106] Iteration 3253000, lr = 0.01
I0831 15:39:53.192898 916722 solver.cpp:218] Iteration 3253500 (16.8104 iter/s, 29.7434s/500 iters), loss = 0.181116
I0831 15:39:53.192951 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.181121 (* 1 = 0.181121 loss)
I0831 15:39:53.192972 916722 sgd_solver.cpp:106] Iteration 3253500, lr = 0.01
I0831 15:40:22.935020 916722 solver.cpp:218] Iteration 3254000 (16.8112 iter/s, 29.742s/500 iters), loss = 0.149182
I0831 15:40:22.935087 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.149187 (* 1 = 0.149187 loss)
I0831 15:40:22.935096 916722 sgd_solver.cpp:106] Iteration 3254000, lr = 0.01
I0831 15:40:52.680112 916722 solver.cpp:218] Iteration 3254500 (16.8096 iter/s, 29.745s/500 iters), loss = 0.0705543
I0831 15:40:52.680164 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0705589 (* 1 = 0.0705589 loss)
I0831 15:40:52.680174 916722 sgd_solver.cpp:106] Iteration 3254500, lr = 0.01
I0831 15:41:22.423642 916722 solver.cpp:218] Iteration 3255000 (16.8104 iter/s, 29.7434s/500 iters), loss = 0.149368
I0831 15:41:22.423704 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.149373 (* 1 = 0.149373 loss)
I0831 15:41:22.423713 916722 sgd_solver.cpp:106] Iteration 3255000, lr = 0.01
I0831 15:41:52.168378 916722 solver.cpp:218] Iteration 3255500 (16.8098 iter/s, 29.7446s/500 iters), loss = 0.165444
I0831 15:41:52.168437 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.165449 (* 1 = 0.165449 loss)
I0831 15:41:52.168448 916722 sgd_solver.cpp:106] Iteration 3255500, lr = 0.01
I0831 15:42:21.914956 916722 solver.cpp:218] Iteration 3256000 (16.8087 iter/s, 29.7465s/500 iters), loss = 0.126818
I0831 15:42:21.915019 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.126823 (* 1 = 0.126823 loss)
I0831 15:42:21.915027 916722 sgd_solver.cpp:106] Iteration 3256000, lr = 0.01
I0831 15:42:51.674129 916722 solver.cpp:218] Iteration 3256500 (16.8016 iter/s, 29.7591s/500 iters), loss = 0.149724
I0831 15:42:51.674181 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.149728 (* 1 = 0.149728 loss)
I0831 15:42:51.674190 916722 sgd_solver.cpp:106] Iteration 3256500, lr = 0.01
I0831 15:43:21.434141 916722 solver.cpp:218] Iteration 3257000 (16.8011 iter/s, 29.7599s/500 iters), loss = 0.129891
I0831 15:43:21.434201 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.129896 (* 1 = 0.129896 loss)
I0831 15:43:21.434209 916722 sgd_solver.cpp:106] Iteration 3257000, lr = 0.01
I0831 15:43:51.192018 916722 solver.cpp:218] Iteration 3257500 (16.8023 iter/s, 29.7578s/500 iters), loss = 0.0422058
I0831 15:43:51.192070 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0422103 (* 1 = 0.0422103 loss)
I0831 15:43:51.192080 916722 sgd_solver.cpp:106] Iteration 3257500, lr = 0.01
I0831 15:44:20.951393 916722 solver.cpp:218] Iteration 3258000 (16.8015 iter/s, 29.7593s/500 iters), loss = 0.173426
I0831 15:44:20.951450 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.17343 (* 1 = 0.17343 loss)
I0831 15:44:20.951458 916722 sgd_solver.cpp:106] Iteration 3258000, lr = 0.01
I0831 15:44:50.706954 916722 solver.cpp:218] Iteration 3258500 (16.8037 iter/s, 29.7553s/500 iters), loss = 0.38753
I0831 15:44:50.707005 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.387535 (* 1 = 0.387535 loss)
I0831 15:44:50.707012 916722 sgd_solver.cpp:106] Iteration 3258500, lr = 0.01
I0831 15:45:20.465550 916722 solver.cpp:218] Iteration 3259000 (16.8021 iter/s, 29.7582s/500 iters), loss = 0.184115
I0831 15:45:20.465610 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.184119 (* 1 = 0.184119 loss)
I0831 15:45:20.465618 916722 sgd_solver.cpp:106] Iteration 3259000, lr = 0.01
I0831 15:45:50.221618 916722 solver.cpp:218] Iteration 3259500 (16.8035 iter/s, 29.7556s/500 iters), loss = 0.196128
I0831 15:45:50.221671 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.196132 (* 1 = 0.196132 loss)
I0831 15:45:50.221680 916722 sgd_solver.cpp:106] Iteration 3259500, lr = 0.01
I0831 15:46:19.980908 916722 solver.cpp:218] Iteration 3260000 (16.8017 iter/s, 29.7589s/500 iters), loss = 0.0333247
I0831 15:46:19.980969 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0333291 (* 1 = 0.0333291 loss)
I0831 15:46:19.980978 916722 sgd_solver.cpp:106] Iteration 3260000, lr = 0.01
I0831 15:46:49.738937 916722 solver.cpp:218] Iteration 3260500 (16.8024 iter/s, 29.7576s/500 iters), loss = 0.12351
I0831 15:46:49.738991 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.123515 (* 1 = 0.123515 loss)
I0831 15:46:49.738999 916722 sgd_solver.cpp:106] Iteration 3260500, lr = 0.01
I0831 15:47:19.498533 916722 solver.cpp:218] Iteration 3261000 (16.8015 iter/s, 29.7592s/500 iters), loss = 0.16176
I0831 15:47:19.498606 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.161764 (* 1 = 0.161764 loss)
I0831 15:47:19.498615 916722 sgd_solver.cpp:106] Iteration 3261000, lr = 0.01
I0831 15:47:49.256582 916722 solver.cpp:218] Iteration 3261500 (16.8024 iter/s, 29.7577s/500 iters), loss = 0.0694317
I0831 15:47:49.256639 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0694362 (* 1 = 0.0694362 loss)
I0831 15:47:49.256649 916722 sgd_solver.cpp:106] Iteration 3261500, lr = 0.01
I0831 15:48:19.017954 916722 solver.cpp:218] Iteration 3262000 (16.8005 iter/s, 29.761s/500 iters), loss = 0.182093
I0831 15:48:19.018013 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.182097 (* 1 = 0.182097 loss)
I0831 15:48:19.018020 916722 sgd_solver.cpp:106] Iteration 3262000, lr = 0.01
I0831 15:48:48.775282 916722 solver.cpp:218] Iteration 3262500 (16.8028 iter/s, 29.757s/500 iters), loss = 0.147632
I0831 15:48:48.775333 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.147636 (* 1 = 0.147636 loss)
I0831 15:48:48.775343 916722 sgd_solver.cpp:106] Iteration 3262500, lr = 0.01
I0831 15:49:18.534996 916722 solver.cpp:218] Iteration 3263000 (16.8014 iter/s, 29.7594s/500 iters), loss = 0.186047
I0831 15:49:18.535055 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.186052 (* 1 = 0.186052 loss)
I0831 15:49:18.535063 916722 sgd_solver.cpp:106] Iteration 3263000, lr = 0.01
I0831 15:49:48.295819 916722 solver.cpp:218] Iteration 3263500 (16.8008 iter/s, 29.7605s/500 iters), loss = 0.046514
I0831 15:49:48.295874 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0465186 (* 1 = 0.0465186 loss)
I0831 15:49:48.295886 916722 sgd_solver.cpp:106] Iteration 3263500, lr = 0.01
I0831 15:50:18.060887 916722 solver.cpp:218] Iteration 3264000 (16.7984 iter/s, 29.7648s/500 iters), loss = 0.0602791
I0831 15:50:18.060947 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0602836 (* 1 = 0.0602836 loss)
I0831 15:50:18.060956 916722 sgd_solver.cpp:106] Iteration 3264000, lr = 0.01
I0831 15:50:47.824930 916722 solver.cpp:218] Iteration 3264500 (16.799 iter/s, 29.7637s/500 iters), loss = 0.139086
I0831 15:50:47.824985 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139091 (* 1 = 0.139091 loss)
I0831 15:50:47.824995 916722 sgd_solver.cpp:106] Iteration 3264500, lr = 0.01
I0831 15:51:17.580651 916722 solver.cpp:218] Iteration 3265000 (16.8037 iter/s, 29.7554s/500 iters), loss = 0.135668
I0831 15:51:17.580705 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.135672 (* 1 = 0.135672 loss)
I0831 15:51:17.580714 916722 sgd_solver.cpp:106] Iteration 3265000, lr = 0.01
I0831 15:51:47.349679 916722 solver.cpp:218] Iteration 3265500 (16.7961 iter/s, 29.7687s/500 iters), loss = 0.162954
I0831 15:51:47.349727 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.162958 (* 1 = 0.162958 loss)
I0831 15:51:47.349737 916722 sgd_solver.cpp:106] Iteration 3265500, lr = 0.01
I0831 15:52:17.119429 916722 solver.cpp:218] Iteration 3266000 (16.7957 iter/s, 29.7695s/500 iters), loss = 0.0516381
I0831 15:52:17.119488 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0516423 (* 1 = 0.0516423 loss)
I0831 15:52:17.119496 916722 sgd_solver.cpp:106] Iteration 3266000, lr = 0.01
I0831 15:52:46.880837 916722 solver.cpp:218] Iteration 3266500 (16.8004 iter/s, 29.7611s/500 iters), loss = 0.112975
I0831 15:52:46.880882 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112979 (* 1 = 0.112979 loss)
I0831 15:52:46.880890 916722 sgd_solver.cpp:106] Iteration 3266500, lr = 0.01
I0831 15:53:16.644600 916722 solver.cpp:218] Iteration 3267000 (16.7991 iter/s, 29.7635s/500 iters), loss = 0.201503
I0831 15:53:16.644665 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.201508 (* 1 = 0.201508 loss)
I0831 15:53:16.644675 916722 sgd_solver.cpp:106] Iteration 3267000, lr = 0.01
I0831 15:53:46.413872 916722 solver.cpp:218] Iteration 3267500 (16.796 iter/s, 29.769s/500 iters), loss = 0.143938
I0831 15:53:46.413919 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.143942 (* 1 = 0.143942 loss)
I0831 15:53:46.413929 916722 sgd_solver.cpp:106] Iteration 3267500, lr = 0.01
I0831 15:54:16.185201 916722 solver.cpp:218] Iteration 3268000 (16.7948 iter/s, 29.7711s/500 iters), loss = 0.123866
I0831 15:54:16.185262 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.12387 (* 1 = 0.12387 loss)
I0831 15:54:16.185271 916722 sgd_solver.cpp:106] Iteration 3268000, lr = 0.01
I0831 15:54:45.947619 916722 solver.cpp:218] Iteration 3268500 (16.7998 iter/s, 29.7622s/500 iters), loss = 0.157731
I0831 15:54:45.947672 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.157735 (* 1 = 0.157735 loss)
I0831 15:54:45.947682 916722 sgd_solver.cpp:106] Iteration 3268500, lr = 0.01
I0831 15:55:15.710063 916722 solver.cpp:218] Iteration 3269000 (16.7998 iter/s, 29.7622s/500 iters), loss = 0.188532
I0831 15:55:15.710122 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.188536 (* 1 = 0.188536 loss)
I0831 15:55:15.710130 916722 sgd_solver.cpp:106] Iteration 3269000, lr = 0.01
I0831 15:55:45.472141 916722 solver.cpp:218] Iteration 3269500 (16.8 iter/s, 29.7619s/500 iters), loss = 0.166969
I0831 15:55:45.472193 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.166973 (* 1 = 0.166973 loss)
I0831 15:55:45.472203 916722 sgd_solver.cpp:106] Iteration 3269500, lr = 0.01
I0831 15:56:15.233052 916722 solver.cpp:218] Iteration 3270000 (16.8007 iter/s, 29.7607s/500 iters), loss = 0.196076
I0831 15:56:15.233117 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.19608 (* 1 = 0.19608 loss)
I0831 15:56:15.233125 916722 sgd_solver.cpp:106] Iteration 3270000, lr = 0.01
I0831 15:56:44.993484 916722 solver.cpp:218] Iteration 3270500 (16.801 iter/s, 29.7602s/500 iters), loss = 0.163229
I0831 15:56:44.993537 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.163233 (* 1 = 0.163233 loss)
I0831 15:56:44.993546 916722 sgd_solver.cpp:106] Iteration 3270500, lr = 0.01
I0831 15:57:14.757447 916722 solver.cpp:218] Iteration 3271000 (16.799 iter/s, 29.7638s/500 iters), loss = 0.0593973
I0831 15:57:14.757511 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0594012 (* 1 = 0.0594012 loss)
I0831 15:57:14.757519 916722 sgd_solver.cpp:106] Iteration 3271000, lr = 0.01
I0831 15:57:44.519161 916722 solver.cpp:218] Iteration 3271500 (16.8002 iter/s, 29.7615s/500 iters), loss = 0.140982
I0831 15:57:44.519217 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.140986 (* 1 = 0.140986 loss)
I0831 15:57:44.519224 916722 sgd_solver.cpp:106] Iteration 3271500, lr = 0.01
I0831 15:58:14.279136 916722 solver.cpp:218] Iteration 3272000 (16.8012 iter/s, 29.7598s/500 iters), loss = 0.299251
I0831 15:58:14.279198 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.299255 (* 1 = 0.299255 loss)
I0831 15:58:14.279206 916722 sgd_solver.cpp:106] Iteration 3272000, lr = 0.01
I0831 15:58:44.039113 916722 solver.cpp:218] Iteration 3272500 (16.8012 iter/s, 29.7598s/500 iters), loss = 0.0688658
I0831 15:58:44.039168 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0688699 (* 1 = 0.0688699 loss)
I0831 15:58:44.039178 916722 sgd_solver.cpp:106] Iteration 3272500, lr = 0.01
I0831 15:59:13.815672 916722 solver.cpp:218] Iteration 3273000 (16.7918 iter/s, 29.7764s/500 iters), loss = 0.118617
I0831 15:59:13.815737 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.118621 (* 1 = 0.118621 loss)
I0831 15:59:13.815747 916722 sgd_solver.cpp:106] Iteration 3273000, lr = 0.01
I0831 15:59:43.580250 916722 solver.cpp:218] Iteration 3273500 (16.7986 iter/s, 29.7644s/500 iters), loss = 0.298905
I0831 15:59:43.580313 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.298909 (* 1 = 0.298909 loss)
I0831 15:59:43.580322 916722 sgd_solver.cpp:106] Iteration 3273500, lr = 0.01
I0831 16:00:13.343693 916722 solver.cpp:218] Iteration 3274000 (16.7992 iter/s, 29.7632s/500 iters), loss = 0.0681786
I0831 16:00:13.343760 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0681827 (* 1 = 0.0681827 loss)
I0831 16:00:13.343770 916722 sgd_solver.cpp:106] Iteration 3274000, lr = 0.01
I0831 16:00:43.109519 916722 solver.cpp:218] Iteration 3274500 (16.7979 iter/s, 29.7656s/500 iters), loss = 0.168425
I0831 16:00:43.109576 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.168429 (* 1 = 0.168429 loss)
I0831 16:00:43.109587 916722 sgd_solver.cpp:106] Iteration 3274500, lr = 0.01
I0831 16:01:12.874270 916722 solver.cpp:218] Iteration 3275000 (16.7985 iter/s, 29.7646s/500 iters), loss = 0.0887843
I0831 16:01:12.874326 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0887882 (* 1 = 0.0887882 loss)
I0831 16:01:12.874336 916722 sgd_solver.cpp:106] Iteration 3275000, lr = 0.01
I0831 16:01:42.636865 916722 solver.cpp:218] Iteration 3275500 (16.7997 iter/s, 29.7624s/500 iters), loss = 0.153634
I0831 16:01:42.636922 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.153638 (* 1 = 0.153638 loss)
I0831 16:01:42.636934 916722 sgd_solver.cpp:106] Iteration 3275500, lr = 0.01
I0831 16:02:12.402056 916722 solver.cpp:218] Iteration 3276000 (16.7983 iter/s, 29.765s/500 iters), loss = 0.313049
I0831 16:02:12.402117 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.313053 (* 1 = 0.313053 loss)
I0831 16:02:12.402124 916722 sgd_solver.cpp:106] Iteration 3276000, lr = 0.01
I0831 16:02:42.167822 916722 solver.cpp:218] Iteration 3276500 (16.7979 iter/s, 29.7656s/500 iters), loss = 0.126388
I0831 16:02:42.167876 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.126392 (* 1 = 0.126392 loss)
I0831 16:02:42.167886 916722 sgd_solver.cpp:106] Iteration 3276500, lr = 0.01
I0831 16:03:11.933959 916722 solver.cpp:218] Iteration 3277000 (16.7977 iter/s, 29.766s/500 iters), loss = 0.316837
I0831 16:03:11.934020 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.316841 (* 1 = 0.316841 loss)
I0831 16:03:11.934028 916722 sgd_solver.cpp:106] Iteration 3277000, lr = 0.01
I0831 16:03:41.699074 916722 solver.cpp:218] Iteration 3277500 (16.7983 iter/s, 29.7649s/500 iters), loss = 0.089535
I0831 16:03:41.699127 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0895388 (* 1 = 0.0895388 loss)
I0831 16:03:41.699137 916722 sgd_solver.cpp:106] Iteration 3277500, lr = 0.01
I0831 16:04:11.456290 916722 solver.cpp:218] Iteration 3278000 (16.8027 iter/s, 29.757s/500 iters), loss = 0.194714
I0831 16:04:11.456346 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.194718 (* 1 = 0.194718 loss)
I0831 16:04:11.456354 916722 sgd_solver.cpp:106] Iteration 3278000, lr = 0.01
I0831 16:04:41.218626 916722 solver.cpp:218] Iteration 3278500 (16.7999 iter/s, 29.7622s/500 iters), loss = 0.0975713
I0831 16:04:41.218678 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.097575 (* 1 = 0.097575 loss)
I0831 16:04:41.218688 916722 sgd_solver.cpp:106] Iteration 3278500, lr = 0.01
I0831 16:05:10.980839 916722 solver.cpp:218] Iteration 3279000 (16.7999 iter/s, 29.762s/500 iters), loss = 0.238461
I0831 16:05:10.980899 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.238465 (* 1 = 0.238465 loss)
I0831 16:05:10.980908 916722 sgd_solver.cpp:106] Iteration 3279000, lr = 0.01
I0831 16:05:40.745918 916722 solver.cpp:218] Iteration 3279500 (16.7983 iter/s, 29.7649s/500 iters), loss = 0.132677
I0831 16:05:40.745972 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.132681 (* 1 = 0.132681 loss)
I0831 16:05:40.745982 916722 sgd_solver.cpp:106] Iteration 3279500, lr = 0.01
I0831 16:06:10.508464 916722 solver.cpp:218] Iteration 3280000 (16.7997 iter/s, 29.7624s/500 iters), loss = 0.0534436
I0831 16:06:10.508538 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0534474 (* 1 = 0.0534474 loss)
I0831 16:06:10.508546 916722 sgd_solver.cpp:106] Iteration 3280000, lr = 0.01
I0831 16:06:40.273262 916722 solver.cpp:218] Iteration 3280500 (16.7985 iter/s, 29.7646s/500 iters), loss = 0.0195726
I0831 16:06:40.273317 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0195766 (* 1 = 0.0195766 loss)
I0831 16:06:40.273327 916722 sgd_solver.cpp:106] Iteration 3280500, lr = 0.01
I0831 16:07:10.038282 916722 solver.cpp:218] Iteration 3281000 (16.7983 iter/s, 29.7649s/500 iters), loss = 0.129775
I0831 16:07:10.038345 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.129779 (* 1 = 0.129779 loss)
I0831 16:07:10.038354 916722 sgd_solver.cpp:106] Iteration 3281000, lr = 0.01
I0831 16:07:39.806017 916722 solver.cpp:218] Iteration 3281500 (16.7968 iter/s, 29.7676s/500 iters), loss = 0.0923308
I0831 16:07:39.806071 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0923345 (* 1 = 0.0923345 loss)
I0831 16:07:39.806078 916722 sgd_solver.cpp:106] Iteration 3281500, lr = 0.01
I0831 16:08:09.573709 916722 solver.cpp:218] Iteration 3282000 (16.7968 iter/s, 29.7675s/500 iters), loss = 0.198423
I0831 16:08:09.573768 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.198427 (* 1 = 0.198427 loss)
I0831 16:08:09.573776 916722 sgd_solver.cpp:106] Iteration 3282000, lr = 0.01
I0831 16:08:39.339040 916722 solver.cpp:218] Iteration 3282500 (16.7982 iter/s, 29.7652s/500 iters), loss = 0.193676
I0831 16:08:39.339092 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.19368 (* 1 = 0.19368 loss)
I0831 16:08:39.339100 916722 sgd_solver.cpp:106] Iteration 3282500, lr = 0.01
I0831 16:09:09.108402 916722 solver.cpp:218] Iteration 3283000 (16.7959 iter/s, 29.7692s/500 iters), loss = 0.338645
I0831 16:09:09.108484 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.338649 (* 1 = 0.338649 loss)
I0831 16:09:09.108492 916722 sgd_solver.cpp:106] Iteration 3283000, lr = 0.01
I0831 16:09:38.874608 916722 solver.cpp:218] Iteration 3283500 (16.7977 iter/s, 29.766s/500 iters), loss = 0.0544788
I0831 16:09:38.874662 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0544826 (* 1 = 0.0544826 loss)
I0831 16:09:38.874671 916722 sgd_solver.cpp:106] Iteration 3283500, lr = 0.01
I0831 16:10:08.641435 916722 solver.cpp:218] Iteration 3284000 (16.7973 iter/s, 29.7667s/500 iters), loss = 0.451328
I0831 16:10:08.641494 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.451332 (* 1 = 0.451332 loss)
I0831 16:10:08.641503 916722 sgd_solver.cpp:106] Iteration 3284000, lr = 0.01
I0831 16:10:38.404551 916722 solver.cpp:218] Iteration 3284500 (16.7994 iter/s, 29.763s/500 iters), loss = 0.280018
I0831 16:10:38.404608 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.280021 (* 1 = 0.280021 loss)
I0831 16:10:38.404618 916722 sgd_solver.cpp:106] Iteration 3284500, lr = 0.01
I0831 16:11:08.171588 916722 solver.cpp:218] Iteration 3285000 (16.7972 iter/s, 29.7669s/500 iters), loss = 0.0490071
I0831 16:11:08.171648 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0490108 (* 1 = 0.0490108 loss)
I0831 16:11:08.171656 916722 sgd_solver.cpp:106] Iteration 3285000, lr = 0.01
I0831 16:11:37.931907 916722 solver.cpp:218] Iteration 3285500 (16.801 iter/s, 29.7602s/500 iters), loss = 0.177658
I0831 16:11:37.931963 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.177662 (* 1 = 0.177662 loss)
I0831 16:11:37.931972 916722 sgd_solver.cpp:106] Iteration 3285500, lr = 0.01
I0831 16:12:07.683591 916722 solver.cpp:218] Iteration 3286000 (16.8059 iter/s, 29.7515s/500 iters), loss = 0.00952038
I0831 16:12:07.683652 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.00952415 (* 1 = 0.00952415 loss)
I0831 16:12:07.683661 916722 sgd_solver.cpp:106] Iteration 3286000, lr = 0.01
I0831 16:12:37.437386 916722 solver.cpp:218] Iteration 3286500 (16.8047 iter/s, 29.7536s/500 iters), loss = 0.161321
I0831 16:12:37.437441 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.161324 (* 1 = 0.161324 loss)
I0831 16:12:37.437463 916722 sgd_solver.cpp:106] Iteration 3286500, lr = 0.01
I0831 16:13:07.190764 916722 solver.cpp:218] Iteration 3287000 (16.8049 iter/s, 29.7532s/500 iters), loss = 0.171737
I0831 16:13:07.190831 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.171741 (* 1 = 0.171741 loss)
I0831 16:13:07.190840 916722 sgd_solver.cpp:106] Iteration 3287000, lr = 0.01
I0831 16:13:36.940857 916722 solver.cpp:218] Iteration 3287500 (16.8068 iter/s, 29.7499s/500 iters), loss = 0.122356
I0831 16:13:36.940909 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.12236 (* 1 = 0.12236 loss)
I0831 16:13:36.940918 916722 sgd_solver.cpp:106] Iteration 3287500, lr = 0.01
I0831 16:14:06.692950 916722 solver.cpp:218] Iteration 3288000 (16.8056 iter/s, 29.7519s/500 iters), loss = 0.0272537
I0831 16:14:06.693008 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0272575 (* 1 = 0.0272575 loss)
I0831 16:14:06.693017 916722 sgd_solver.cpp:106] Iteration 3288000, lr = 0.01
I0831 16:14:36.447252 916722 solver.cpp:218] Iteration 3288500 (16.8044 iter/s, 29.7542s/500 iters), loss = 0.124566
I0831 16:14:36.447307 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.12457 (* 1 = 0.12457 loss)
I0831 16:14:36.447319 916722 sgd_solver.cpp:106] Iteration 3288500, lr = 0.01
I0831 16:15:06.196182 916722 solver.cpp:218] Iteration 3289000 (16.8074 iter/s, 29.7488s/500 iters), loss = 0.0809938
I0831 16:15:06.196240 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0809976 (* 1 = 0.0809976 loss)
I0831 16:15:06.196249 916722 sgd_solver.cpp:106] Iteration 3289000, lr = 0.01
I0831 16:15:35.946403 916722 solver.cpp:218] Iteration 3289500 (16.8067 iter/s, 29.7501s/500 iters), loss = 0.21975
I0831 16:15:35.946458 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.219753 (* 1 = 0.219753 loss)
I0831 16:15:35.946468 916722 sgd_solver.cpp:106] Iteration 3289500, lr = 0.01
I0831 16:16:05.693028 916722 solver.cpp:218] Iteration 3290000 (16.8087 iter/s, 29.7465s/500 iters), loss = 0.330829
I0831 16:16:05.693090 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.330832 (* 1 = 0.330832 loss)
I0831 16:16:05.693099 916722 sgd_solver.cpp:106] Iteration 3290000, lr = 0.01
I0831 16:16:35.441198 916722 solver.cpp:218] Iteration 3290500 (16.8078 iter/s, 29.748s/500 iters), loss = 0.190138
I0831 16:16:35.441252 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.190142 (* 1 = 0.190142 loss)
I0831 16:16:35.441262 916722 sgd_solver.cpp:106] Iteration 3290500, lr = 0.01
I0831 16:17:05.193300 916722 solver.cpp:218] Iteration 3291000 (16.8056 iter/s, 29.752s/500 iters), loss = 0.416734
I0831 16:17:05.193356 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.416738 (* 1 = 0.416738 loss)
I0831 16:17:05.193365 916722 sgd_solver.cpp:106] Iteration 3291000, lr = 0.01
I0831 16:17:34.947993 916722 solver.cpp:218] Iteration 3291500 (16.8042 iter/s, 29.7545s/500 iters), loss = 0.0371315
I0831 16:17:34.948043 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0371349 (* 1 = 0.0371349 loss)
I0831 16:17:34.948053 916722 sgd_solver.cpp:106] Iteration 3291500, lr = 0.01
I0831 16:18:04.698135 916722 solver.cpp:218] Iteration 3292000 (16.8067 iter/s, 29.75s/500 iters), loss = 0.0931005
I0831 16:18:04.698191 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.093104 (* 1 = 0.093104 loss)
I0831 16:18:04.698199 916722 sgd_solver.cpp:106] Iteration 3292000, lr = 0.01
I0831 16:18:34.451052 916722 solver.cpp:218] Iteration 3292500 (16.8052 iter/s, 29.7528s/500 iters), loss = 0.351014
I0831 16:18:34.451105 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.351017 (* 1 = 0.351017 loss)
I0831 16:18:34.451117 916722 sgd_solver.cpp:106] Iteration 3292500, lr = 0.01
I0831 16:19:04.203429 916722 solver.cpp:218] Iteration 3293000 (16.8054 iter/s, 29.7523s/500 iters), loss = 0.0609657
I0831 16:19:04.203497 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0609693 (* 1 = 0.0609693 loss)
I0831 16:19:04.203510 916722 sgd_solver.cpp:106] Iteration 3293000, lr = 0.01
I0831 16:19:33.958782 916722 solver.cpp:218] Iteration 3293500 (16.8038 iter/s, 29.7553s/500 iters), loss = 0.151938
I0831 16:19:33.958838 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.151942 (* 1 = 0.151942 loss)
I0831 16:19:33.958848 916722 sgd_solver.cpp:106] Iteration 3293500, lr = 0.01
I0831 16:20:03.710176 916722 solver.cpp:218] Iteration 3294000 (16.806 iter/s, 29.7513s/500 iters), loss = 0.0984219
I0831 16:20:03.710233 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0984256 (* 1 = 0.0984256 loss)
I0831 16:20:03.710242 916722 sgd_solver.cpp:106] Iteration 3294000, lr = 0.01
I0831 16:20:33.460978 916722 solver.cpp:218] Iteration 3294500 (16.8063 iter/s, 29.7507s/500 iters), loss = 0.0841274
I0831 16:20:33.461033 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0841311 (* 1 = 0.0841311 loss)
I0831 16:20:33.461043 916722 sgd_solver.cpp:106] Iteration 3294500, lr = 0.01
I0831 16:21:03.213526 916722 solver.cpp:218] Iteration 3295000 (16.8053 iter/s, 29.7525s/500 iters), loss = 0.130522
I0831 16:21:03.213582 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130526 (* 1 = 0.130526 loss)
I0831 16:21:03.213590 916722 sgd_solver.cpp:106] Iteration 3295000, lr = 0.01
I0831 16:21:32.969100 916722 solver.cpp:218] Iteration 3295500 (16.8036 iter/s, 29.7555s/500 iters), loss = 0.0216823
I0831 16:21:32.969151 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.021686 (* 1 = 0.021686 loss)
I0831 16:21:32.969161 916722 sgd_solver.cpp:106] Iteration 3295500, lr = 0.01
I0831 16:22:02.719013 916722 solver.cpp:218] Iteration 3296000 (16.8068 iter/s, 29.7498s/500 iters), loss = 0.0514021
I0831 16:22:02.719072 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0514059 (* 1 = 0.0514059 loss)
I0831 16:22:02.719081 916722 sgd_solver.cpp:106] Iteration 3296000, lr = 0.01
I0831 16:22:32.470378 916722 solver.cpp:218] Iteration 3296500 (16.806 iter/s, 29.7513s/500 iters), loss = 0.0487896
I0831 16:22:32.470424 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0487934 (* 1 = 0.0487934 loss)
I0831 16:22:32.470432 916722 sgd_solver.cpp:106] Iteration 3296500, lr = 0.01
I0831 16:23:02.223740 916722 solver.cpp:218] Iteration 3297000 (16.8049 iter/s, 29.7533s/500 iters), loss = 0.0491786
I0831 16:23:02.223798 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0491824 (* 1 = 0.0491824 loss)
I0831 16:23:02.223806 916722 sgd_solver.cpp:106] Iteration 3297000, lr = 0.01
I0831 16:23:31.972652 916722 solver.cpp:218] Iteration 3297500 (16.8074 iter/s, 29.7488s/500 iters), loss = 0.0241745
I0831 16:23:31.972709 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0241783 (* 1 = 0.0241783 loss)
I0831 16:23:31.972720 916722 sgd_solver.cpp:106] Iteration 3297500, lr = 0.01
I0831 16:24:01.720369 916722 solver.cpp:218] Iteration 3298000 (16.8081 iter/s, 29.7476s/500 iters), loss = 0.145366
I0831 16:24:01.720435 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.14537 (* 1 = 0.14537 loss)
I0831 16:24:01.720445 916722 sgd_solver.cpp:106] Iteration 3298000, lr = 0.01
I0831 16:24:31.470980 916722 solver.cpp:218] Iteration 3298500 (16.8064 iter/s, 29.7505s/500 iters), loss = 0.0986015
I0831 16:24:31.471036 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0986052 (* 1 = 0.0986052 loss)
I0831 16:24:31.471045 916722 sgd_solver.cpp:106] Iteration 3298500, lr = 0.01
I0831 16:25:01.221567 916722 solver.cpp:218] Iteration 3299000 (16.8064 iter/s, 29.7505s/500 iters), loss = 0.174178
I0831 16:25:01.221626 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.174182 (* 1 = 0.174182 loss)
I0831 16:25:01.221634 916722 sgd_solver.cpp:106] Iteration 3299000, lr = 0.01
I0831 16:25:30.973074 916722 solver.cpp:218] Iteration 3299500 (16.8059 iter/s, 29.7514s/500 iters), loss = 0.0855189
I0831 16:25:30.973129 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0855225 (* 1 = 0.0855225 loss)
I0831 16:25:30.973137 916722 sgd_solver.cpp:106] Iteration 3299500, lr = 0.01
I0831 16:26:00.666096 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_3300000.caffemodel
I0831 16:26:00.685170 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_3300000.solverstate
I0831 16:26:00.691238 916722 solver.cpp:330] Iteration 3300000, Testing net (#0)
I0831 16:26:16.117797 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8827
I0831 16:26:16.117841 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.424241 (* 1 = 0.424241 loss)
I0831 16:26:16.176384 916722 solver.cpp:218] Iteration 3300000 (11.0612 iter/s, 45.2032s/500 iters), loss = 0.194951
I0831 16:26:16.176411 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.194955 (* 1 = 0.194955 loss)
I0831 16:26:16.176419 916722 sgd_solver.cpp:106] Iteration 3300000, lr = 0.01
I0831 16:26:45.911026 916722 solver.cpp:218] Iteration 3300500 (16.8155 iter/s, 29.7345s/500 iters), loss = 0.0787536
I0831 16:26:45.911087 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0787571 (* 1 = 0.0787571 loss)
I0831 16:26:45.911096 916722 sgd_solver.cpp:106] Iteration 3300500, lr = 0.01
I0831 16:27:15.659461 916722 solver.cpp:218] Iteration 3301000 (16.8077 iter/s, 29.7483s/500 iters), loss = 0.0510758
I0831 16:27:15.659518 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0510793 (* 1 = 0.0510793 loss)
I0831 16:27:15.659528 916722 sgd_solver.cpp:106] Iteration 3301000, lr = 0.01
I0831 16:27:45.413334 916722 solver.cpp:218] Iteration 3301500 (16.8046 iter/s, 29.7537s/500 iters), loss = 0.0854246
I0831 16:27:45.413399 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.085428 (* 1 = 0.085428 loss)
I0831 16:27:45.413409 916722 sgd_solver.cpp:106] Iteration 3301500, lr = 0.01
I0831 16:28:15.165588 916722 solver.cpp:218] Iteration 3302000 (16.8055 iter/s, 29.7521s/500 iters), loss = 0.0478567
I0831 16:28:15.165642 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.04786 (* 1 = 0.04786 loss)
I0831 16:28:15.165652 916722 sgd_solver.cpp:106] Iteration 3302000, lr = 0.01
I0831 16:28:44.914117 916722 solver.cpp:218] Iteration 3302500 (16.8076 iter/s, 29.7484s/500 iters), loss = 0.0958877
I0831 16:28:44.914175 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0958909 (* 1 = 0.0958909 loss)
I0831 16:28:44.914183 916722 sgd_solver.cpp:106] Iteration 3302500, lr = 0.01
I0831 16:29:14.662976 916722 solver.cpp:218] Iteration 3303000 (16.8074 iter/s, 29.7487s/500 iters), loss = 0.141207
I0831 16:29:14.663025 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.14121 (* 1 = 0.14121 loss)
I0831 16:29:14.663034 916722 sgd_solver.cpp:106] Iteration 3303000, lr = 0.01
I0831 16:29:44.416566 916722 solver.cpp:218] Iteration 3303500 (16.8048 iter/s, 29.7535s/500 iters), loss = 0.0271739
I0831 16:29:44.416628 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0271772 (* 1 = 0.0271772 loss)
I0831 16:29:44.416637 916722 sgd_solver.cpp:106] Iteration 3303500, lr = 0.01
I0831 16:30:14.168234 916722 solver.cpp:218] Iteration 3304000 (16.8059 iter/s, 29.7515s/500 iters), loss = 0.25273
I0831 16:30:14.168288 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.252734 (* 1 = 0.252734 loss)
I0831 16:30:14.168298 916722 sgd_solver.cpp:106] Iteration 3304000, lr = 0.01
I0831 16:30:43.920224 916722 solver.cpp:218] Iteration 3304500 (16.8057 iter/s, 29.7519s/500 iters), loss = 0.101076
I0831 16:30:43.920286 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101079 (* 1 = 0.101079 loss)
I0831 16:30:43.920295 916722 sgd_solver.cpp:106] Iteration 3304500, lr = 0.01
I0831 16:31:13.671262 916722 solver.cpp:218] Iteration 3305000 (16.8062 iter/s, 29.7509s/500 iters), loss = 0.27414
I0831 16:31:13.671314 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.274143 (* 1 = 0.274143 loss)
I0831 16:31:13.671322 916722 sgd_solver.cpp:106] Iteration 3305000, lr = 0.01
I0831 16:31:43.427033 916722 solver.cpp:218] Iteration 3305500 (16.8035 iter/s, 29.7557s/500 iters), loss = 0.185766
I0831 16:31:43.427110 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.185769 (* 1 = 0.185769 loss)
I0831 16:31:43.427119 916722 sgd_solver.cpp:106] Iteration 3305500, lr = 0.01
I0831 16:32:13.180912 916722 solver.cpp:218] Iteration 3306000 (16.8046 iter/s, 29.7537s/500 iters), loss = 0.124384
I0831 16:32:13.180966 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.124387 (* 1 = 0.124387 loss)
I0831 16:32:13.180975 916722 sgd_solver.cpp:106] Iteration 3306000, lr = 0.01
I0831 16:32:42.932512 916722 solver.cpp:218] Iteration 3306500 (16.8059 iter/s, 29.7515s/500 iters), loss = 0.0588443
I0831 16:32:42.932571 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0588477 (* 1 = 0.0588477 loss)
I0831 16:32:42.932580 916722 sgd_solver.cpp:106] Iteration 3306500, lr = 0.01
I0831 16:33:12.685721 916722 solver.cpp:218] Iteration 3307000 (16.805 iter/s, 29.7531s/500 iters), loss = 0.0426762
I0831 16:33:12.685776 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0426796 (* 1 = 0.0426796 loss)
I0831 16:33:12.685786 916722 sgd_solver.cpp:106] Iteration 3307000, lr = 0.01
I0831 16:33:42.437294 916722 solver.cpp:218] Iteration 3307500 (16.8059 iter/s, 29.7515s/500 iters), loss = 0.143861
I0831 16:33:42.437350 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.143864 (* 1 = 0.143864 loss)
I0831 16:33:42.437357 916722 sgd_solver.cpp:106] Iteration 3307500, lr = 0.01
I0831 16:34:12.188993 916722 solver.cpp:218] Iteration 3308000 (16.8058 iter/s, 29.7516s/500 iters), loss = 0.172746
I0831 16:34:12.189050 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.172749 (* 1 = 0.172749 loss)
I0831 16:34:12.189060 916722 sgd_solver.cpp:106] Iteration 3308000, lr = 0.01
I0831 16:34:41.942307 916722 solver.cpp:218] Iteration 3308500 (16.8049 iter/s, 29.7532s/500 iters), loss = 0.109028
I0831 16:34:41.942369 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109031 (* 1 = 0.109031 loss)
I0831 16:34:41.942378 916722 sgd_solver.cpp:106] Iteration 3308500, lr = 0.01
I0831 16:35:11.695398 916722 solver.cpp:218] Iteration 3309000 (16.805 iter/s, 29.753s/500 iters), loss = 0.15894
I0831 16:35:11.695452 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.158943 (* 1 = 0.158943 loss)
I0831 16:35:11.695462 916722 sgd_solver.cpp:106] Iteration 3309000, lr = 0.01
I0831 16:35:41.447839 916722 solver.cpp:218] Iteration 3309500 (16.8054 iter/s, 29.7523s/500 iters), loss = 0.0954419
I0831 16:35:41.447902 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0954452 (* 1 = 0.0954452 loss)
I0831 16:35:41.447911 916722 sgd_solver.cpp:106] Iteration 3309500, lr = 0.01
I0831 16:36:11.202322 916722 solver.cpp:218] Iteration 3310000 (16.8043 iter/s, 29.7544s/500 iters), loss = 0.0736172
I0831 16:36:11.202378 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0736204 (* 1 = 0.0736204 loss)
I0831 16:36:11.202387 916722 sgd_solver.cpp:106] Iteration 3310000, lr = 0.01
I0831 16:36:40.956104 916722 solver.cpp:218] Iteration 3310500 (16.8047 iter/s, 29.7537s/500 iters), loss = 0.0350227
I0831 16:36:40.956164 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0350258 (* 1 = 0.0350258 loss)
I0831 16:36:40.956173 916722 sgd_solver.cpp:106] Iteration 3310500, lr = 0.01
I0831 16:37:10.715756 916722 solver.cpp:218] Iteration 3311000 (16.8013 iter/s, 29.7595s/500 iters), loss = 0.168173
I0831 16:37:10.715811 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.168176 (* 1 = 0.168176 loss)
I0831 16:37:10.715821 916722 sgd_solver.cpp:106] Iteration 3311000, lr = 0.01
I0831 16:37:40.466790 916722 solver.cpp:218] Iteration 3311500 (16.8062 iter/s, 29.7509s/500 iters), loss = 0.0132996
I0831 16:37:40.466846 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0133026 (* 1 = 0.0133026 loss)
I0831 16:37:40.466854 916722 sgd_solver.cpp:106] Iteration 3311500, lr = 0.01
I0831 16:38:10.221036 916722 solver.cpp:218] Iteration 3312000 (16.8044 iter/s, 29.7541s/500 iters), loss = 0.0198354
I0831 16:38:10.221096 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0198382 (* 1 = 0.0198382 loss)
I0831 16:38:10.221107 916722 sgd_solver.cpp:106] Iteration 3312000, lr = 0.01
I0831 16:38:39.976052 916722 solver.cpp:218] Iteration 3312500 (16.804 iter/s, 29.7549s/500 iters), loss = 0.132048
I0831 16:38:39.976127 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13205 (* 1 = 0.13205 loss)
I0831 16:38:39.976137 916722 sgd_solver.cpp:106] Iteration 3312500, lr = 0.01
I0831 16:39:09.728648 916722 solver.cpp:218] Iteration 3313000 (16.8053 iter/s, 29.7524s/500 iters), loss = 0.231067
I0831 16:39:09.728703 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.23107 (* 1 = 0.23107 loss)
I0831 16:39:09.728713 916722 sgd_solver.cpp:106] Iteration 3313000, lr = 0.01
I0831 16:39:39.480733 916722 solver.cpp:218] Iteration 3313500 (16.8056 iter/s, 29.752s/500 iters), loss = 0.126968
I0831 16:39:39.480806 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.126971 (* 1 = 0.126971 loss)
I0831 16:39:39.480814 916722 sgd_solver.cpp:106] Iteration 3313500, lr = 0.01
I0831 16:40:09.228338 916722 solver.cpp:218] Iteration 3314000 (16.8082 iter/s, 29.7475s/500 iters), loss = 0.406949
I0831 16:40:09.228391 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.406951 (* 1 = 0.406951 loss)
I0831 16:40:09.228400 916722 sgd_solver.cpp:106] Iteration 3314000, lr = 0.01
I0831 16:40:38.991055 916722 solver.cpp:218] Iteration 3314500 (16.7996 iter/s, 29.7626s/500 iters), loss = 0.0334352
I0831 16:40:38.991122 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.033438 (* 1 = 0.033438 loss)
I0831 16:40:38.991130 916722 sgd_solver.cpp:106] Iteration 3314500, lr = 0.01
I0831 16:41:08.741330 916722 solver.cpp:218] Iteration 3315000 (16.8066 iter/s, 29.7501s/500 iters), loss = 0.121635
I0831 16:41:08.741386 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.121638 (* 1 = 0.121638 loss)
I0831 16:41:08.741395 916722 sgd_solver.cpp:106] Iteration 3315000, lr = 0.01
I0831 16:41:38.493093 916722 solver.cpp:218] Iteration 3315500 (16.8058 iter/s, 29.7516s/500 iters), loss = 0.279667
I0831 16:41:38.493152 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.279669 (* 1 = 0.279669 loss)
I0831 16:41:38.493160 916722 sgd_solver.cpp:106] Iteration 3315500, lr = 0.01
I0831 16:42:08.243129 916722 solver.cpp:218] Iteration 3316000 (16.8068 iter/s, 29.7499s/500 iters), loss = 0.100515
I0831 16:42:08.243180 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.100518 (* 1 = 0.100518 loss)
I0831 16:42:08.243188 916722 sgd_solver.cpp:106] Iteration 3316000, lr = 0.01
I0831 16:42:37.996160 916722 solver.cpp:218] Iteration 3316500 (16.8051 iter/s, 29.7529s/500 iters), loss = 0.135975
I0831 16:42:37.996222 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.135978 (* 1 = 0.135978 loss)
I0831 16:42:37.996232 916722 sgd_solver.cpp:106] Iteration 3316500, lr = 0.01
I0831 16:43:07.748173 916722 solver.cpp:218] Iteration 3317000 (16.8057 iter/s, 29.7519s/500 iters), loss = 0.0937896
I0831 16:43:07.748225 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0937926 (* 1 = 0.0937926 loss)
I0831 16:43:07.748234 916722 sgd_solver.cpp:106] Iteration 3317000, lr = 0.01
I0831 16:43:37.504793 916722 solver.cpp:218] Iteration 3317500 (16.8031 iter/s, 29.7565s/500 iters), loss = 0.0589543
I0831 16:43:37.504859 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0589574 (* 1 = 0.0589574 loss)
I0831 16:43:37.504868 916722 sgd_solver.cpp:106] Iteration 3317500, lr = 0.01
I0831 16:44:07.258929 916722 solver.cpp:218] Iteration 3318000 (16.8045 iter/s, 29.754s/500 iters), loss = 0.110426
I0831 16:44:07.258989 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110429 (* 1 = 0.110429 loss)
I0831 16:44:07.258998 916722 sgd_solver.cpp:106] Iteration 3318000, lr = 0.01
I0831 16:44:37.011885 916722 solver.cpp:218] Iteration 3318500 (16.8051 iter/s, 29.7528s/500 iters), loss = 0.0986468
I0831 16:44:37.011963 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0986498 (* 1 = 0.0986498 loss)
I0831 16:44:37.011972 916722 sgd_solver.cpp:106] Iteration 3318500, lr = 0.01
I0831 16:45:06.765240 916722 solver.cpp:218] Iteration 3319000 (16.8049 iter/s, 29.7532s/500 iters), loss = 0.0533184
I0831 16:45:06.765296 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0533213 (* 1 = 0.0533213 loss)
I0831 16:45:06.765306 916722 sgd_solver.cpp:106] Iteration 3319000, lr = 0.01
I0831 16:45:36.519575 916722 solver.cpp:218] Iteration 3319500 (16.8043 iter/s, 29.7542s/500 iters), loss = 0.129327
I0831 16:45:36.519636 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.12933 (* 1 = 0.12933 loss)
I0831 16:45:36.519645 916722 sgd_solver.cpp:106] Iteration 3319500, lr = 0.01
I0831 16:46:06.268299 916722 solver.cpp:218] Iteration 3320000 (16.8075 iter/s, 29.7486s/500 iters), loss = 0.228124
I0831 16:46:06.268349 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.228127 (* 1 = 0.228127 loss)
I0831 16:46:06.268359 916722 sgd_solver.cpp:106] Iteration 3320000, lr = 0.01
I0831 16:46:36.022544 916722 solver.cpp:218] Iteration 3320500 (16.8044 iter/s, 29.7541s/500 iters), loss = 0.135323
I0831 16:46:36.022600 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.135326 (* 1 = 0.135326 loss)
I0831 16:46:36.022609 916722 sgd_solver.cpp:106] Iteration 3320500, lr = 0.01
I0831 16:47:05.776077 916722 solver.cpp:218] Iteration 3321000 (16.8048 iter/s, 29.7534s/500 iters), loss = 0.263234
I0831 16:47:05.776129 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.263237 (* 1 = 0.263237 loss)
I0831 16:47:05.776140 916722 sgd_solver.cpp:106] Iteration 3321000, lr = 0.01
I0831 16:47:35.524678 916722 solver.cpp:218] Iteration 3321500 (16.8076 iter/s, 29.7485s/500 iters), loss = 0.239834
I0831 16:47:35.524737 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.239837 (* 1 = 0.239837 loss)
I0831 16:47:35.524745 916722 sgd_solver.cpp:106] Iteration 3321500, lr = 0.01
I0831 16:48:05.276289 916722 solver.cpp:218] Iteration 3322000 (16.8059 iter/s, 29.7515s/500 iters), loss = 0.096149
I0831 16:48:05.276341 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0961517 (* 1 = 0.0961517 loss)
I0831 16:48:05.276351 916722 sgd_solver.cpp:106] Iteration 3322000, lr = 0.01
I0831 16:48:35.021090 916722 solver.cpp:218] Iteration 3322500 (16.8097 iter/s, 29.7447s/500 iters), loss = 0.139105
I0831 16:48:35.021150 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139107 (* 1 = 0.139107 loss)
I0831 16:48:35.021158 916722 sgd_solver.cpp:106] Iteration 3322500, lr = 0.01
I0831 16:49:04.768801 916722 solver.cpp:218] Iteration 3323000 (16.8081 iter/s, 29.7476s/500 iters), loss = 0.114314
I0831 16:49:04.768852 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.114317 (* 1 = 0.114317 loss)
I0831 16:49:04.768862 916722 sgd_solver.cpp:106] Iteration 3323000, lr = 0.01
I0831 16:49:34.515026 916722 solver.cpp:218] Iteration 3323500 (16.8089 iter/s, 29.7461s/500 iters), loss = 0.252308
I0831 16:49:34.515085 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.252311 (* 1 = 0.252311 loss)
I0831 16:49:34.515094 916722 sgd_solver.cpp:106] Iteration 3323500, lr = 0.01
I0831 16:50:04.266947 916722 solver.cpp:218] Iteration 3324000 (16.8057 iter/s, 29.7518s/500 iters), loss = 0.0654249
I0831 16:50:04.266999 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0654275 (* 1 = 0.0654275 loss)
I0831 16:50:04.267009 916722 sgd_solver.cpp:106] Iteration 3324000, lr = 0.01
I0831 16:50:34.016492 916722 solver.cpp:218] Iteration 3324500 (16.8071 iter/s, 29.7494s/500 iters), loss = 0.158669
I0831 16:50:34.016554 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.158671 (* 1 = 0.158671 loss)
I0831 16:50:34.016562 916722 sgd_solver.cpp:106] Iteration 3324500, lr = 0.01
I0831 16:51:03.766422 916722 solver.cpp:218] Iteration 3325000 (16.8068 iter/s, 29.7498s/500 iters), loss = 0.122822
I0831 16:51:03.766474 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.122824 (* 1 = 0.122824 loss)
I0831 16:51:03.766494 916722 sgd_solver.cpp:106] Iteration 3325000, lr = 0.01
I0831 16:51:33.519502 916722 solver.cpp:218] Iteration 3325500 (16.8051 iter/s, 29.7529s/500 iters), loss = 0.0583961
I0831 16:51:33.519574 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0583987 (* 1 = 0.0583987 loss)
I0831 16:51:33.519583 916722 sgd_solver.cpp:106] Iteration 3325500, lr = 0.01
I0831 16:52:03.270720 916722 solver.cpp:218] Iteration 3326000 (16.8061 iter/s, 29.7511s/500 iters), loss = 0.292489
I0831 16:52:03.270772 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.292492 (* 1 = 0.292492 loss)
I0831 16:52:03.270781 916722 sgd_solver.cpp:106] Iteration 3326000, lr = 0.01
I0831 16:52:33.022807 916722 solver.cpp:218] Iteration 3326500 (16.8056 iter/s, 29.752s/500 iters), loss = 0.0849127
I0831 16:52:33.022867 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0849154 (* 1 = 0.0849154 loss)
I0831 16:52:33.022876 916722 sgd_solver.cpp:106] Iteration 3326500, lr = 0.01
I0831 16:53:02.773844 916722 solver.cpp:218] Iteration 3327000 (16.8062 iter/s, 29.751s/500 iters), loss = 0.17993
I0831 16:53:02.773895 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.179933 (* 1 = 0.179933 loss)
I0831 16:53:02.773902 916722 sgd_solver.cpp:106] Iteration 3327000, lr = 0.01
I0831 16:53:32.523484 916722 solver.cpp:218] Iteration 3327500 (16.8068 iter/s, 29.7498s/500 iters), loss = 0.0578033
I0831 16:53:32.523541 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0578064 (* 1 = 0.0578064 loss)
I0831 16:53:32.523550 916722 sgd_solver.cpp:106] Iteration 3327500, lr = 0.01
I0831 16:54:02.274742 916722 solver.cpp:218] Iteration 3328000 (16.8059 iter/s, 29.7514s/500 iters), loss = 0.0982341
I0831 16:54:02.274794 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.098237 (* 1 = 0.098237 loss)
I0831 16:54:02.274802 916722 sgd_solver.cpp:106] Iteration 3328000, lr = 0.01
I0831 16:54:32.014974 916722 solver.cpp:218] Iteration 3328500 (16.8122 iter/s, 29.7404s/500 iters), loss = 0.274943
I0831 16:54:32.015039 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.274946 (* 1 = 0.274946 loss)
I0831 16:54:32.015048 916722 sgd_solver.cpp:106] Iteration 3328500, lr = 0.01
I0831 16:55:01.748785 916722 solver.cpp:218] Iteration 3329000 (16.8158 iter/s, 29.7339s/500 iters), loss = 0.0438284
I0831 16:55:01.748838 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0438313 (* 1 = 0.0438313 loss)
I0831 16:55:01.748849 916722 sgd_solver.cpp:106] Iteration 3329000, lr = 0.01
I0831 16:55:31.476186 916722 solver.cpp:218] Iteration 3329500 (16.8194 iter/s, 29.7275s/500 iters), loss = 0.361039
I0831 16:55:31.476244 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.361042 (* 1 = 0.361042 loss)
I0831 16:55:31.476253 916722 sgd_solver.cpp:106] Iteration 3329500, lr = 0.01
I0831 16:56:01.205314 916722 solver.cpp:218] Iteration 3330000 (16.8185 iter/s, 29.7292s/500 iters), loss = 0.402445
I0831 16:56:01.205365 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.402448 (* 1 = 0.402448 loss)
I0831 16:56:01.205375 916722 sgd_solver.cpp:106] Iteration 3330000, lr = 0.01
I0831 16:56:30.928403 916722 solver.cpp:218] Iteration 3330500 (16.8219 iter/s, 29.7232s/500 iters), loss = 0.150892
I0831 16:56:30.928467 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.150895 (* 1 = 0.150895 loss)
I0831 16:56:30.928474 916722 sgd_solver.cpp:106] Iteration 3330500, lr = 0.01
I0831 16:57:00.655159 916722 solver.cpp:218] Iteration 3331000 (16.8198 iter/s, 29.7268s/500 iters), loss = 0.126647
I0831 16:57:00.655210 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.12665 (* 1 = 0.12665 loss)
I0831 16:57:00.655220 916722 sgd_solver.cpp:106] Iteration 3331000, lr = 0.01
I0831 16:57:30.377796 916722 solver.cpp:218] Iteration 3331500 (16.8222 iter/s, 29.7227s/500 iters), loss = 0.202714
I0831 16:57:30.377864 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.202717 (* 1 = 0.202717 loss)
I0831 16:57:30.377877 916722 sgd_solver.cpp:106] Iteration 3331500, lr = 0.01
I0831 16:58:00.105041 916722 solver.cpp:218] Iteration 3332000 (16.8196 iter/s, 29.7273s/500 iters), loss = 0.254453
I0831 16:58:00.105095 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.254456 (* 1 = 0.254456 loss)
I0831 16:58:00.105105 916722 sgd_solver.cpp:106] Iteration 3332000, lr = 0.01
I0831 16:58:29.827880 916722 solver.cpp:218] Iteration 3332500 (16.8221 iter/s, 29.7229s/500 iters), loss = 0.257374
I0831 16:58:29.827942 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.257377 (* 1 = 0.257377 loss)
I0831 16:58:29.827950 916722 sgd_solver.cpp:106] Iteration 3332500, lr = 0.01
I0831 16:58:59.554862 916722 solver.cpp:218] Iteration 3333000 (16.8197 iter/s, 29.727s/500 iters), loss = 0.178169
I0831 16:58:59.554914 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.178172 (* 1 = 0.178172 loss)
I0831 16:58:59.554924 916722 sgd_solver.cpp:106] Iteration 3333000, lr = 0.01
I0831 16:59:29.282351 916722 solver.cpp:218] Iteration 3333500 (16.8194 iter/s, 29.7275s/500 iters), loss = 0.163712
I0831 16:59:29.282414 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.163715 (* 1 = 0.163715 loss)
I0831 16:59:29.282423 916722 sgd_solver.cpp:106] Iteration 3333500, lr = 0.01
I0831 16:59:59.007791 916722 solver.cpp:218] Iteration 3334000 (16.8206 iter/s, 29.7255s/500 iters), loss = 0.085884
I0831 16:59:59.007840 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0858872 (* 1 = 0.0858872 loss)
I0831 16:59:59.007849 916722 sgd_solver.cpp:106] Iteration 3334000, lr = 0.01
I0831 17:00:28.729951 916722 solver.cpp:218] Iteration 3334500 (16.8225 iter/s, 29.7222s/500 iters), loss = 0.205655
I0831 17:00:28.730010 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.205658 (* 1 = 0.205658 loss)
I0831 17:00:28.730018 916722 sgd_solver.cpp:106] Iteration 3334500, lr = 0.01
I0831 17:00:58.455327 916722 solver.cpp:218] Iteration 3335000 (16.8206 iter/s, 29.7254s/500 iters), loss = 0.400274
I0831 17:00:58.455379 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.400277 (* 1 = 0.400277 loss)
I0831 17:00:58.455390 916722 sgd_solver.cpp:106] Iteration 3335000, lr = 0.01
I0831 17:01:28.185858 916722 solver.cpp:218] Iteration 3335500 (16.8177 iter/s, 29.7305s/500 iters), loss = 0.279729
I0831 17:01:28.185918 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.279732 (* 1 = 0.279732 loss)
I0831 17:01:28.185926 916722 sgd_solver.cpp:106] Iteration 3335500, lr = 0.01
I0831 17:01:57.910182 916722 solver.cpp:218] Iteration 3336000 (16.8212 iter/s, 29.7243s/500 iters), loss = 0.210902
I0831 17:01:57.910230 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.210905 (* 1 = 0.210905 loss)
I0831 17:01:57.910239 916722 sgd_solver.cpp:106] Iteration 3336000, lr = 0.01
I0831 17:02:27.636747 916722 solver.cpp:218] Iteration 3336500 (16.82 iter/s, 29.7266s/500 iters), loss = 0.183802
I0831 17:02:27.636807 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.183805 (* 1 = 0.183805 loss)
I0831 17:02:27.636816 916722 sgd_solver.cpp:106] Iteration 3336500, lr = 0.01
I0831 17:02:57.364883 916722 solver.cpp:218] Iteration 3337000 (16.8191 iter/s, 29.7281s/500 iters), loss = 0.192025
I0831 17:02:57.364936 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.192028 (* 1 = 0.192028 loss)
I0831 17:02:57.364945 916722 sgd_solver.cpp:106] Iteration 3337000, lr = 0.01
I0831 17:03:27.096015 916722 solver.cpp:218] Iteration 3337500 (16.8174 iter/s, 29.7311s/500 iters), loss = 0.194631
I0831 17:03:27.096076 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.194634 (* 1 = 0.194634 loss)
I0831 17:03:27.096086 916722 sgd_solver.cpp:106] Iteration 3337500, lr = 0.01
I0831 17:03:56.822777 916722 solver.cpp:218] Iteration 3338000 (16.8199 iter/s, 29.7267s/500 iters), loss = 0.0994733
I0831 17:03:56.822832 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0994764 (* 1 = 0.0994764 loss)
I0831 17:03:56.822840 916722 sgd_solver.cpp:106] Iteration 3338000, lr = 0.01
I0831 17:04:26.547148 916722 solver.cpp:218] Iteration 3338500 (16.8212 iter/s, 29.7244s/500 iters), loss = 0.322765
I0831 17:04:26.547219 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.322768 (* 1 = 0.322768 loss)
I0831 17:04:26.547228 916722 sgd_solver.cpp:106] Iteration 3338500, lr = 0.01
I0831 17:04:56.274992 916722 solver.cpp:218] Iteration 3339000 (16.8193 iter/s, 29.7278s/500 iters), loss = 0.064684
I0831 17:04:56.275046 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.064687 (* 1 = 0.064687 loss)
I0831 17:04:56.275054 916722 sgd_solver.cpp:106] Iteration 3339000, lr = 0.01
I0831 17:05:26.000356 916722 solver.cpp:218] Iteration 3339500 (16.8207 iter/s, 29.7253s/500 iters), loss = 0.256127
I0831 17:05:26.000414 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.25613 (* 1 = 0.25613 loss)
I0831 17:05:26.000427 916722 sgd_solver.cpp:106] Iteration 3339500, lr = 0.01
I0831 17:05:55.728590 916722 solver.cpp:218] Iteration 3340000 (16.819 iter/s, 29.7282s/500 iters), loss = 0.0266838
I0831 17:05:55.728642 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0266867 (* 1 = 0.0266867 loss)
I0831 17:05:55.728652 916722 sgd_solver.cpp:106] Iteration 3340000, lr = 0.01
I0831 17:06:25.454516 916722 solver.cpp:218] Iteration 3340500 (16.8203 iter/s, 29.7259s/500 iters), loss = 0.113354
I0831 17:06:25.454571 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.113357 (* 1 = 0.113357 loss)
I0831 17:06:25.454579 916722 sgd_solver.cpp:106] Iteration 3340500, lr = 0.01
I0831 17:06:55.184754 916722 solver.cpp:218] Iteration 3341000 (16.8179 iter/s, 29.7302s/500 iters), loss = 0.052236
I0831 17:06:55.184808 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0522387 (* 1 = 0.0522387 loss)
I0831 17:06:55.184816 916722 sgd_solver.cpp:106] Iteration 3341000, lr = 0.01
I0831 17:07:24.907511 916722 solver.cpp:218] Iteration 3341500 (16.8221 iter/s, 29.7227s/500 iters), loss = 0.0340307
I0831 17:07:24.907573 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0340335 (* 1 = 0.0340335 loss)
I0831 17:07:24.907582 916722 sgd_solver.cpp:106] Iteration 3341500, lr = 0.01
I0831 17:07:54.636802 916722 solver.cpp:218] Iteration 3342000 (16.8185 iter/s, 29.7292s/500 iters), loss = 0.0166924
I0831 17:07:54.636858 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.016695 (* 1 = 0.016695 loss)
I0831 17:07:54.636868 916722 sgd_solver.cpp:106] Iteration 3342000, lr = 0.01
I0831 17:08:24.367362 916722 solver.cpp:218] Iteration 3342500 (16.8177 iter/s, 29.7305s/500 iters), loss = 0.0673932
I0831 17:08:24.367421 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0673956 (* 1 = 0.0673956 loss)
I0831 17:08:24.367429 916722 sgd_solver.cpp:106] Iteration 3342500, lr = 0.01
I0831 17:08:54.093894 916722 solver.cpp:218] Iteration 3343000 (16.82 iter/s, 29.7265s/500 iters), loss = 0.066363
I0831 17:08:54.093947 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0663654 (* 1 = 0.0663654 loss)
I0831 17:08:54.093957 916722 sgd_solver.cpp:106] Iteration 3343000, lr = 0.01
I0831 17:09:23.822146 916722 solver.cpp:218] Iteration 3343500 (16.819 iter/s, 29.7282s/500 iters), loss = 0.182582
I0831 17:09:23.822204 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.182584 (* 1 = 0.182584 loss)
I0831 17:09:23.822212 916722 sgd_solver.cpp:106] Iteration 3343500, lr = 0.01
I0831 17:09:53.548010 916722 solver.cpp:218] Iteration 3344000 (16.8204 iter/s, 29.7258s/500 iters), loss = 0.475766
I0831 17:09:53.548063 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.475768 (* 1 = 0.475768 loss)
I0831 17:09:53.548071 916722 sgd_solver.cpp:106] Iteration 3344000, lr = 0.01
I0831 17:10:23.273367 916722 solver.cpp:218] Iteration 3344500 (16.8207 iter/s, 29.7253s/500 iters), loss = 0.271827
I0831 17:10:23.273425 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.27183 (* 1 = 0.27183 loss)
I0831 17:10:23.273433 916722 sgd_solver.cpp:106] Iteration 3344500, lr = 0.01
I0831 17:10:52.995787 916722 solver.cpp:218] Iteration 3345000 (16.8223 iter/s, 29.7224s/500 iters), loss = 0.122767
I0831 17:10:52.995839 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.12277 (* 1 = 0.12277 loss)
I0831 17:10:52.995849 916722 sgd_solver.cpp:106] Iteration 3345000, lr = 0.01
I0831 17:11:22.720626 916722 solver.cpp:218] Iteration 3345500 (16.821 iter/s, 29.7248s/500 iters), loss = 0.195404
I0831 17:11:22.720697 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.195407 (* 1 = 0.195407 loss)
I0831 17:11:22.720707 916722 sgd_solver.cpp:106] Iteration 3345500, lr = 0.01
I0831 17:11:52.446568 916722 solver.cpp:218] Iteration 3346000 (16.8204 iter/s, 29.7259s/500 iters), loss = 0.13853
I0831 17:11:52.446620 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.138532 (* 1 = 0.138532 loss)
I0831 17:11:52.446630 916722 sgd_solver.cpp:106] Iteration 3346000, lr = 0.01
I0831 17:12:22.173645 916722 solver.cpp:218] Iteration 3346500 (16.8197 iter/s, 29.727s/500 iters), loss = 0.120604
I0831 17:12:22.173702 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.120606 (* 1 = 0.120606 loss)
I0831 17:12:22.173710 916722 sgd_solver.cpp:106] Iteration 3346500, lr = 0.01
I0831 17:12:51.902509 916722 solver.cpp:218] Iteration 3347000 (16.8187 iter/s, 29.7288s/500 iters), loss = 0.111784
I0831 17:12:51.902562 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111786 (* 1 = 0.111786 loss)
I0831 17:12:51.902572 916722 sgd_solver.cpp:106] Iteration 3347000, lr = 0.01
I0831 17:13:21.630388 916722 solver.cpp:218] Iteration 3347500 (16.8193 iter/s, 29.7278s/500 iters), loss = 0.166456
I0831 17:13:21.630450 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.166459 (* 1 = 0.166459 loss)
I0831 17:13:21.630457 916722 sgd_solver.cpp:106] Iteration 3347500, lr = 0.01
I0831 17:13:51.359689 916722 solver.cpp:218] Iteration 3348000 (16.8185 iter/s, 29.7292s/500 iters), loss = 0.149594
I0831 17:13:51.359740 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.149596 (* 1 = 0.149596 loss)
I0831 17:13:51.359747 916722 sgd_solver.cpp:106] Iteration 3348000, lr = 0.01
I0831 17:14:21.086030 916722 solver.cpp:218] Iteration 3348500 (16.8201 iter/s, 29.7263s/500 iters), loss = 0.0233925
I0831 17:14:21.086086 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0233949 (* 1 = 0.0233949 loss)
I0831 17:14:21.086094 916722 sgd_solver.cpp:106] Iteration 3348500, lr = 0.01
I0831 17:14:50.813699 916722 solver.cpp:218] Iteration 3349000 (16.8194 iter/s, 29.7276s/500 iters), loss = 0.197885
I0831 17:14:50.813750 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.197887 (* 1 = 0.197887 loss)
I0831 17:14:50.813760 916722 sgd_solver.cpp:106] Iteration 3349000, lr = 0.01
I0831 17:15:20.536895 916722 solver.cpp:218] Iteration 3349500 (16.8219 iter/s, 29.7231s/500 iters), loss = 0.0913295
I0831 17:15:20.536954 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.091332 (* 1 = 0.091332 loss)
I0831 17:15:20.536963 916722 sgd_solver.cpp:106] Iteration 3349500, lr = 0.01
I0831 17:15:50.204712 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_3350000.caffemodel
I0831 17:15:50.223655 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_3350000.solverstate
I0831 17:15:50.229719 916722 solver.cpp:330] Iteration 3350000, Testing net (#0)
I0831 17:16:05.666270 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8606
I0831 17:16:05.666319 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.487409 (* 1 = 0.487409 loss)
I0831 17:16:05.724917 916722 solver.cpp:218] Iteration 3350000 (11.0649 iter/s, 45.1879s/500 iters), loss = 0.170377
I0831 17:16:05.724946 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.17038 (* 1 = 0.17038 loss)
I0831 17:16:05.724954 916722 sgd_solver.cpp:106] Iteration 3350000, lr = 0.01
I0831 17:16:35.439901 916722 solver.cpp:218] Iteration 3350500 (16.8266 iter/s, 29.7149s/500 iters), loss = 0.0589847
I0831 17:16:35.439963 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0589872 (* 1 = 0.0589872 loss)
I0831 17:16:35.439972 916722 sgd_solver.cpp:106] Iteration 3350500, lr = 0.01
I0831 17:17:05.160496 916722 solver.cpp:218] Iteration 3351000 (16.8234 iter/s, 29.7205s/500 iters), loss = 0.0590904
I0831 17:17:05.160570 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0590927 (* 1 = 0.0590927 loss)
I0831 17:17:05.160579 916722 sgd_solver.cpp:106] Iteration 3351000, lr = 0.01
I0831 17:17:34.887125 916722 solver.cpp:218] Iteration 3351500 (16.82 iter/s, 29.7265s/500 iters), loss = 0.05334
I0831 17:17:34.887176 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0533424 (* 1 = 0.0533424 loss)
I0831 17:17:34.887187 916722 sgd_solver.cpp:106] Iteration 3351500, lr = 0.01
I0831 17:18:04.609951 916722 solver.cpp:218] Iteration 3352000 (16.8221 iter/s, 29.7227s/500 iters), loss = 0.358962
I0831 17:18:04.610010 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.358964 (* 1 = 0.358964 loss)
I0831 17:18:04.610018 916722 sgd_solver.cpp:106] Iteration 3352000, lr = 0.01
I0831 17:18:34.337303 916722 solver.cpp:218] Iteration 3352500 (16.8196 iter/s, 29.7273s/500 iters), loss = 0.266792
I0831 17:18:34.337355 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.266795 (* 1 = 0.266795 loss)
I0831 17:18:34.337363 916722 sgd_solver.cpp:106] Iteration 3352500, lr = 0.01
I0831 17:19:04.061551 916722 solver.cpp:218] Iteration 3353000 (16.8213 iter/s, 29.7242s/500 iters), loss = 0.0894349
I0831 17:19:04.061611 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0894374 (* 1 = 0.0894374 loss)
I0831 17:19:04.061619 916722 sgd_solver.cpp:106] Iteration 3353000, lr = 0.01
I0831 17:19:33.789381 916722 solver.cpp:218] Iteration 3353500 (16.8193 iter/s, 29.7277s/500 iters), loss = 0.089612
I0831 17:19:33.789434 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0896145 (* 1 = 0.0896145 loss)
I0831 17:19:33.789443 916722 sgd_solver.cpp:106] Iteration 3353500, lr = 0.01
I0831 17:20:03.518396 916722 solver.cpp:218] Iteration 3354000 (16.8186 iter/s, 29.7289s/500 iters), loss = 0.209091
I0831 17:20:03.518455 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.209094 (* 1 = 0.209094 loss)
I0831 17:20:03.518463 916722 sgd_solver.cpp:106] Iteration 3354000, lr = 0.01
I0831 17:20:33.249660 916722 solver.cpp:218] Iteration 3354500 (16.8174 iter/s, 29.7312s/500 iters), loss = 0.169078
I0831 17:20:33.249712 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.16908 (* 1 = 0.16908 loss)
I0831 17:20:33.249722 916722 sgd_solver.cpp:106] Iteration 3354500, lr = 0.01
I0831 17:21:02.980530 916722 solver.cpp:218] Iteration 3355000 (16.8176 iter/s, 29.7308s/500 iters), loss = 0.13395
I0831 17:21:02.980588 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133953 (* 1 = 0.133953 loss)
I0831 17:21:02.980597 916722 sgd_solver.cpp:106] Iteration 3355000, lr = 0.01
I0831 17:21:32.709292 916722 solver.cpp:218] Iteration 3355500 (16.8188 iter/s, 29.7287s/500 iters), loss = 0.0623823
I0831 17:21:32.709342 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0623846 (* 1 = 0.0623846 loss)
I0831 17:21:32.709349 916722 sgd_solver.cpp:106] Iteration 3355500, lr = 0.01
I0831 17:22:02.436885 916722 solver.cpp:218] Iteration 3356000 (16.8194 iter/s, 29.7275s/500 iters), loss = 0.143364
I0831 17:22:02.436944 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.143366 (* 1 = 0.143366 loss)
I0831 17:22:02.436952 916722 sgd_solver.cpp:106] Iteration 3356000, lr = 0.01
I0831 17:22:32.162904 916722 solver.cpp:218] Iteration 3356500 (16.8203 iter/s, 29.7259s/500 iters), loss = 0.0700133
I0831 17:22:32.162958 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0700156 (* 1 = 0.0700156 loss)
I0831 17:22:32.162968 916722 sgd_solver.cpp:106] Iteration 3356500, lr = 0.01
I0831 17:23:01.892253 916722 solver.cpp:218] Iteration 3357000 (16.8184 iter/s, 29.7293s/500 iters), loss = 0.280466
I0831 17:23:01.892320 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.280468 (* 1 = 0.280468 loss)
I0831 17:23:01.892333 916722 sgd_solver.cpp:106] Iteration 3357000, lr = 0.01
I0831 17:23:31.621696 916722 solver.cpp:218] Iteration 3357500 (16.8184 iter/s, 29.7293s/500 iters), loss = 0.0719443
I0831 17:23:31.621752 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0719465 (* 1 = 0.0719465 loss)
I0831 17:23:31.621760 916722 sgd_solver.cpp:106] Iteration 3357500, lr = 0.01
I0831 17:24:01.349334 916722 solver.cpp:218] Iteration 3358000 (16.8194 iter/s, 29.7275s/500 iters), loss = 0.17365
I0831 17:24:01.349390 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.173653 (* 1 = 0.173653 loss)
I0831 17:24:01.349398 916722 sgd_solver.cpp:106] Iteration 3358000, lr = 0.01
I0831 17:24:31.077915 916722 solver.cpp:218] Iteration 3358500 (16.8189 iter/s, 29.7285s/500 iters), loss = 0.137936
I0831 17:24:31.077966 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.137938 (* 1 = 0.137938 loss)
I0831 17:24:31.077976 916722 sgd_solver.cpp:106] Iteration 3358500, lr = 0.01
I0831 17:25:00.804242 916722 solver.cpp:218] Iteration 3359000 (16.8202 iter/s, 29.7262s/500 iters), loss = 0.0999674
I0831 17:25:00.804298 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0999696 (* 1 = 0.0999696 loss)
I0831 17:25:00.804306 916722 sgd_solver.cpp:106] Iteration 3359000, lr = 0.01
I0831 17:25:30.530942 916722 solver.cpp:218] Iteration 3359500 (16.8199 iter/s, 29.7266s/500 iters), loss = 0.0642787
I0831 17:25:30.530992 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0642809 (* 1 = 0.0642809 loss)
I0831 17:25:30.531002 916722 sgd_solver.cpp:106] Iteration 3359500, lr = 0.01
I0831 17:26:00.259712 916722 solver.cpp:218] Iteration 3360000 (16.8188 iter/s, 29.7287s/500 iters), loss = 0.149137
I0831 17:26:00.259768 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.14914 (* 1 = 0.14914 loss)
I0831 17:26:00.259776 916722 sgd_solver.cpp:106] Iteration 3360000, lr = 0.01
I0831 17:26:29.986311 916722 solver.cpp:218] Iteration 3360500 (16.82 iter/s, 29.7265s/500 iters), loss = 0.019095
I0831 17:26:29.986366 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0190976 (* 1 = 0.0190976 loss)
I0831 17:26:29.986375 916722 sgd_solver.cpp:106] Iteration 3360500, lr = 0.01
I0831 17:26:59.711267 916722 solver.cpp:218] Iteration 3361000 (16.8209 iter/s, 29.7249s/500 iters), loss = 0.314669
I0831 17:26:59.711325 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.314672 (* 1 = 0.314672 loss)
I0831 17:26:59.711333 916722 sgd_solver.cpp:106] Iteration 3361000, lr = 0.01
I0831 17:27:29.438715 916722 solver.cpp:218] Iteration 3361500 (16.8196 iter/s, 29.7272s/500 iters), loss = 0.301455
I0831 17:27:29.438768 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.301458 (* 1 = 0.301458 loss)
I0831 17:27:29.438778 916722 sgd_solver.cpp:106] Iteration 3361500, lr = 0.01
I0831 17:27:59.163708 916722 solver.cpp:218] Iteration 3362000 (16.821 iter/s, 29.7247s/500 iters), loss = 0.215541
I0831 17:27:59.163770 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.215544 (* 1 = 0.215544 loss)
I0831 17:27:59.163779 916722 sgd_solver.cpp:106] Iteration 3362000, lr = 0.01
I0831 17:28:28.890134 916722 solver.cpp:218] Iteration 3362500 (16.8202 iter/s, 29.7261s/500 iters), loss = 0.131715
I0831 17:28:28.890187 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131718 (* 1 = 0.131718 loss)
I0831 17:28:28.890194 916722 sgd_solver.cpp:106] Iteration 3362500, lr = 0.01
I0831 17:28:58.617411 916722 solver.cpp:218] Iteration 3363000 (16.8197 iter/s, 29.727s/500 iters), loss = 0.103986
I0831 17:28:58.617471 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.103988 (* 1 = 0.103988 loss)
I0831 17:28:58.617480 916722 sgd_solver.cpp:106] Iteration 3363000, lr = 0.01
I0831 17:29:28.344458 916722 solver.cpp:218] Iteration 3363500 (16.8199 iter/s, 29.7268s/500 iters), loss = 0.0549945
I0831 17:29:28.344509 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0549971 (* 1 = 0.0549971 loss)
I0831 17:29:28.344530 916722 sgd_solver.cpp:106] Iteration 3363500, lr = 0.01
I0831 17:29:58.069744 916722 solver.cpp:218] Iteration 3364000 (16.8208 iter/s, 29.725s/500 iters), loss = 0.0870563
I0831 17:29:58.069810 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0870589 (* 1 = 0.0870589 loss)
I0831 17:29:58.069818 916722 sgd_solver.cpp:106] Iteration 3364000, lr = 0.01
I0831 17:30:27.798941 916722 solver.cpp:218] Iteration 3364500 (16.8186 iter/s, 29.7289s/500 iters), loss = 0.262522
I0831 17:30:27.798995 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.262525 (* 1 = 0.262525 loss)
I0831 17:30:27.799005 916722 sgd_solver.cpp:106] Iteration 3364500, lr = 0.01
I0831 17:30:57.527951 916722 solver.cpp:218] Iteration 3365000 (16.8187 iter/s, 29.7288s/500 iters), loss = 0.138238
I0831 17:30:57.528012 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13824 (* 1 = 0.13824 loss)
I0831 17:30:57.528019 916722 sgd_solver.cpp:106] Iteration 3365000, lr = 0.01
I0831 17:31:27.257251 916722 solver.cpp:218] Iteration 3365500 (16.8186 iter/s, 29.7291s/500 iters), loss = 0.0685668
I0831 17:31:27.257306 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0685692 (* 1 = 0.0685692 loss)
I0831 17:31:27.257316 916722 sgd_solver.cpp:106] Iteration 3365500, lr = 0.01
I0831 17:31:56.984880 916722 solver.cpp:218] Iteration 3366000 (16.8195 iter/s, 29.7274s/500 iters), loss = 0.0596262
I0831 17:31:56.984941 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0596286 (* 1 = 0.0596286 loss)
I0831 17:31:56.984949 916722 sgd_solver.cpp:106] Iteration 3366000, lr = 0.01
I0831 17:32:26.711930 916722 solver.cpp:218] Iteration 3366500 (16.8198 iter/s, 29.7268s/500 iters), loss = 0.236017
I0831 17:32:26.711983 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.236019 (* 1 = 0.236019 loss)
I0831 17:32:26.711992 916722 sgd_solver.cpp:106] Iteration 3366500, lr = 0.01
I0831 17:32:56.440721 916722 solver.cpp:218] Iteration 3367000 (16.8188 iter/s, 29.7286s/500 iters), loss = 0.0656971
I0831 17:32:56.440794 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0656994 (* 1 = 0.0656994 loss)
I0831 17:32:56.440804 916722 sgd_solver.cpp:106] Iteration 3367000, lr = 0.01
I0831 17:33:26.174935 916722 solver.cpp:218] Iteration 3367500 (16.8158 iter/s, 29.734s/500 iters), loss = 0.0818014
I0831 17:33:26.174988 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0818038 (* 1 = 0.0818038 loss)
I0831 17:33:26.174998 916722 sgd_solver.cpp:106] Iteration 3367500, lr = 0.01
I0831 17:33:55.905567 916722 solver.cpp:218] Iteration 3368000 (16.8178 iter/s, 29.7304s/500 iters), loss = 0.0243106
I0831 17:33:55.905629 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0243128 (* 1 = 0.0243128 loss)
I0831 17:33:55.905637 916722 sgd_solver.cpp:106] Iteration 3368000, lr = 0.01
I0831 17:34:25.638101 916722 solver.cpp:218] Iteration 3368500 (16.8167 iter/s, 29.7323s/500 iters), loss = 0.10055
I0831 17:34:25.638149 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.100552 (* 1 = 0.100552 loss)
I0831 17:34:25.638157 916722 sgd_solver.cpp:106] Iteration 3368500, lr = 0.01
I0831 17:34:55.367362 916722 solver.cpp:218] Iteration 3369000 (16.8186 iter/s, 29.7291s/500 iters), loss = 0.168537
I0831 17:34:55.367424 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.16854 (* 1 = 0.16854 loss)
I0831 17:34:55.367431 916722 sgd_solver.cpp:106] Iteration 3369000, lr = 0.01
I0831 17:35:25.096319 916722 solver.cpp:218] Iteration 3369500 (16.8187 iter/s, 29.7288s/500 iters), loss = 0.217885
I0831 17:35:25.096372 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.217887 (* 1 = 0.217887 loss)
I0831 17:35:25.096381 916722 sgd_solver.cpp:106] Iteration 3369500, lr = 0.01
I0831 17:35:54.835886 916722 solver.cpp:218] Iteration 3370000 (16.8127 iter/s, 29.7394s/500 iters), loss = 0.0684426
I0831 17:35:54.835958 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.068445 (* 1 = 0.068445 loss)
I0831 17:35:54.835969 916722 sgd_solver.cpp:106] Iteration 3370000, lr = 0.01
I0831 17:36:24.577154 916722 solver.cpp:218] Iteration 3370500 (16.8118 iter/s, 29.7411s/500 iters), loss = 0.131866
I0831 17:36:24.577206 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131868 (* 1 = 0.131868 loss)
I0831 17:36:24.577214 916722 sgd_solver.cpp:106] Iteration 3370500, lr = 0.01
I0831 17:36:54.315443 916722 solver.cpp:218] Iteration 3371000 (16.8134 iter/s, 29.7381s/500 iters), loss = 0.0653118
I0831 17:36:54.315502 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0653141 (* 1 = 0.0653141 loss)
I0831 17:36:54.315511 916722 sgd_solver.cpp:106] Iteration 3371000, lr = 0.01
I0831 17:37:24.055600 916722 solver.cpp:218] Iteration 3371500 (16.8124 iter/s, 29.74s/500 iters), loss = 0.0794684
I0831 17:37:24.055652 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0794708 (* 1 = 0.0794708 loss)
I0831 17:37:24.055660 916722 sgd_solver.cpp:106] Iteration 3371500, lr = 0.01
I0831 17:37:53.793031 916722 solver.cpp:218] Iteration 3372000 (16.8139 iter/s, 29.7373s/500 iters), loss = 0.105475
I0831 17:37:53.793090 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105477 (* 1 = 0.105477 loss)
I0831 17:37:53.793098 916722 sgd_solver.cpp:106] Iteration 3372000, lr = 0.01
I0831 17:38:23.535483 916722 solver.cpp:218] Iteration 3372500 (16.8111 iter/s, 29.7423s/500 iters), loss = 0.148364
I0831 17:38:23.535532 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.148367 (* 1 = 0.148367 loss)
I0831 17:38:23.535540 916722 sgd_solver.cpp:106] Iteration 3372500, lr = 0.01
I0831 17:38:53.271710 916722 solver.cpp:218] Iteration 3373000 (16.8146 iter/s, 29.7361s/500 iters), loss = 0.177356
I0831 17:38:53.271768 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.177358 (* 1 = 0.177358 loss)
I0831 17:38:53.271776 916722 sgd_solver.cpp:106] Iteration 3373000, lr = 0.01
I0831 17:39:22.999444 916722 solver.cpp:218] Iteration 3373500 (16.8194 iter/s, 29.7276s/500 iters), loss = 0.109923
I0831 17:39:22.999500 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109926 (* 1 = 0.109926 loss)
I0831 17:39:22.999508 916722 sgd_solver.cpp:106] Iteration 3373500, lr = 0.01
I0831 17:39:52.728992 916722 solver.cpp:218] Iteration 3374000 (16.8184 iter/s, 29.7294s/500 iters), loss = 0.0219202
I0831 17:39:52.729053 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0219231 (* 1 = 0.0219231 loss)
I0831 17:39:52.729060 916722 sgd_solver.cpp:106] Iteration 3374000, lr = 0.01
I0831 17:40:22.454193 916722 solver.cpp:218] Iteration 3374500 (16.8208 iter/s, 29.725s/500 iters), loss = 0.276266
I0831 17:40:22.454246 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.276269 (* 1 = 0.276269 loss)
I0831 17:40:22.454255 916722 sgd_solver.cpp:106] Iteration 3374500, lr = 0.01
I0831 17:40:52.180126 916722 solver.cpp:218] Iteration 3375000 (16.8204 iter/s, 29.7258s/500 iters), loss = 0.0579939
I0831 17:40:52.180186 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0579967 (* 1 = 0.0579967 loss)
I0831 17:40:52.180194 916722 sgd_solver.cpp:106] Iteration 3375000, lr = 0.01
I0831 17:41:21.908282 916722 solver.cpp:218] Iteration 3375500 (16.8192 iter/s, 29.728s/500 iters), loss = 0.228876
I0831 17:41:21.908334 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.228878 (* 1 = 0.228878 loss)
I0831 17:41:21.908342 916722 sgd_solver.cpp:106] Iteration 3375500, lr = 0.01
I0831 17:41:51.642520 916722 solver.cpp:218] Iteration 3376000 (16.8157 iter/s, 29.7341s/500 iters), loss = 0.175789
I0831 17:41:51.642581 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.175791 (* 1 = 0.175791 loss)
I0831 17:41:51.642589 916722 sgd_solver.cpp:106] Iteration 3376000, lr = 0.01
I0831 17:42:21.364972 916722 solver.cpp:218] Iteration 3376500 (16.8224 iter/s, 29.7223s/500 iters), loss = 0.0571118
I0831 17:42:21.365028 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0571143 (* 1 = 0.0571143 loss)
I0831 17:42:21.365038 916722 sgd_solver.cpp:106] Iteration 3376500, lr = 0.01
I0831 17:42:51.090212 916722 solver.cpp:218] Iteration 3377000 (16.8208 iter/s, 29.7251s/500 iters), loss = 0.567456
I0831 17:42:51.090273 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.567459 (* 1 = 0.567459 loss)
I0831 17:42:51.090281 916722 sgd_solver.cpp:106] Iteration 3377000, lr = 0.01
I0831 17:43:20.820263 916722 solver.cpp:218] Iteration 3377500 (16.8181 iter/s, 29.7299s/500 iters), loss = 0.0989792
I0831 17:43:20.820318 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0989818 (* 1 = 0.0989818 loss)
I0831 17:43:20.820327 916722 sgd_solver.cpp:106] Iteration 3377500, lr = 0.01
I0831 17:43:50.538414 916722 solver.cpp:218] Iteration 3378000 (16.8248 iter/s, 29.718s/500 iters), loss = 0.0709044
I0831 17:43:50.538473 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.070907 (* 1 = 0.070907 loss)
I0831 17:43:50.538482 916722 sgd_solver.cpp:106] Iteration 3378000, lr = 0.01
I0831 17:44:20.263800 916722 solver.cpp:218] Iteration 3378500 (16.8207 iter/s, 29.7252s/500 iters), loss = 0.071452
I0831 17:44:20.263856 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0714546 (* 1 = 0.0714546 loss)
I0831 17:44:20.263866 916722 sgd_solver.cpp:106] Iteration 3378500, lr = 0.01
I0831 17:44:49.985998 916722 solver.cpp:218] Iteration 3379000 (16.8225 iter/s, 29.722s/500 iters), loss = 0.117884
I0831 17:44:49.986054 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.117887 (* 1 = 0.117887 loss)
I0831 17:44:49.986063 916722 sgd_solver.cpp:106] Iteration 3379000, lr = 0.01
I0831 17:45:19.708781 916722 solver.cpp:218] Iteration 3379500 (16.8222 iter/s, 29.7226s/500 iters), loss = 0.0912313
I0831 17:45:19.708828 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0912339 (* 1 = 0.0912339 loss)
I0831 17:45:19.708838 916722 sgd_solver.cpp:106] Iteration 3379500, lr = 0.01
I0831 17:45:49.429854 916722 solver.cpp:218] Iteration 3380000 (16.8232 iter/s, 29.7209s/500 iters), loss = 0.157298
I0831 17:45:49.429913 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.1573 (* 1 = 0.1573 loss)
I0831 17:45:49.429921 916722 sgd_solver.cpp:106] Iteration 3380000, lr = 0.01
I0831 17:46:19.151567 916722 solver.cpp:218] Iteration 3380500 (16.8228 iter/s, 29.7216s/500 iters), loss = 0.0253341
I0831 17:46:19.151621 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0253367 (* 1 = 0.0253367 loss)
I0831 17:46:19.151631 916722 sgd_solver.cpp:106] Iteration 3380500, lr = 0.01
I0831 17:46:48.874358 916722 solver.cpp:218] Iteration 3381000 (16.8222 iter/s, 29.7226s/500 iters), loss = 0.0904665
I0831 17:46:48.874419 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0904691 (* 1 = 0.0904691 loss)
I0831 17:46:48.874428 916722 sgd_solver.cpp:106] Iteration 3381000, lr = 0.01
I0831 17:47:18.601035 916722 solver.cpp:218] Iteration 3381500 (16.82 iter/s, 29.7265s/500 iters), loss = 0.164021
I0831 17:47:18.601091 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.164024 (* 1 = 0.164024 loss)
I0831 17:47:18.601100 916722 sgd_solver.cpp:106] Iteration 3381500, lr = 0.01
I0831 17:47:48.323642 916722 solver.cpp:218] Iteration 3382000 (16.8223 iter/s, 29.7225s/500 iters), loss = 0.090129
I0831 17:47:48.323702 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0901318 (* 1 = 0.0901318 loss)
I0831 17:47:48.323710 916722 sgd_solver.cpp:106] Iteration 3382000, lr = 0.01
I0831 17:48:18.046684 916722 solver.cpp:218] Iteration 3382500 (16.822 iter/s, 29.7229s/500 iters), loss = 0.20564
I0831 17:48:18.046736 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.205642 (* 1 = 0.205642 loss)
I0831 17:48:18.046746 916722 sgd_solver.cpp:106] Iteration 3382500, lr = 0.01
I0831 17:48:47.770426 916722 solver.cpp:218] Iteration 3383000 (16.8216 iter/s, 29.7236s/500 iters), loss = 0.129239
I0831 17:48:47.770484 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.129242 (* 1 = 0.129242 loss)
I0831 17:48:47.770493 916722 sgd_solver.cpp:106] Iteration 3383000, lr = 0.01
I0831 17:49:17.494419 916722 solver.cpp:218] Iteration 3383500 (16.8215 iter/s, 29.7239s/500 iters), loss = 0.221361
I0831 17:49:17.494470 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.221364 (* 1 = 0.221364 loss)
I0831 17:49:17.494480 916722 sgd_solver.cpp:106] Iteration 3383500, lr = 0.01
I0831 17:49:47.218818 916722 solver.cpp:218] Iteration 3384000 (16.8213 iter/s, 29.7243s/500 iters), loss = 0.105769
I0831 17:49:47.218894 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105772 (* 1 = 0.105772 loss)
I0831 17:49:47.218904 916722 sgd_solver.cpp:106] Iteration 3384000, lr = 0.01
I0831 17:50:16.940708 916722 solver.cpp:218] Iteration 3384500 (16.8227 iter/s, 29.7217s/500 iters), loss = 0.0825355
I0831 17:50:16.940766 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0825384 (* 1 = 0.0825384 loss)
I0831 17:50:16.940775 916722 sgd_solver.cpp:106] Iteration 3384500, lr = 0.01
I0831 17:50:46.664309 916722 solver.cpp:218] Iteration 3385000 (16.8217 iter/s, 29.7235s/500 iters), loss = 0.0296987
I0831 17:50:46.664368 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0297016 (* 1 = 0.0297016 loss)
I0831 17:50:46.664376 916722 sgd_solver.cpp:106] Iteration 3385000, lr = 0.01
I0831 17:51:16.386023 916722 solver.cpp:218] Iteration 3385500 (16.8228 iter/s, 29.7216s/500 iters), loss = 0.167635
I0831 17:51:16.386076 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.167638 (* 1 = 0.167638 loss)
I0831 17:51:16.386085 916722 sgd_solver.cpp:106] Iteration 3385500, lr = 0.01
I0831 17:51:46.107591 916722 solver.cpp:218] Iteration 3386000 (16.8229 iter/s, 29.7214s/500 iters), loss = 0.0518299
I0831 17:51:46.107645 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0518328 (* 1 = 0.0518328 loss)
I0831 17:51:46.107653 916722 sgd_solver.cpp:106] Iteration 3386000, lr = 0.01
I0831 17:52:15.831634 916722 solver.cpp:218] Iteration 3386500 (16.8215 iter/s, 29.7239s/500 iters), loss = 0.0905278
I0831 17:52:15.831687 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0905307 (* 1 = 0.0905307 loss)
I0831 17:52:15.831697 916722 sgd_solver.cpp:106] Iteration 3386500, lr = 0.01
I0831 17:52:45.554894 916722 solver.cpp:218] Iteration 3387000 (16.8219 iter/s, 29.7231s/500 iters), loss = 0.25152
I0831 17:52:45.554951 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.251523 (* 1 = 0.251523 loss)
I0831 17:52:45.554960 916722 sgd_solver.cpp:106] Iteration 3387000, lr = 0.01
I0831 17:53:15.276645 916722 solver.cpp:218] Iteration 3387500 (16.8228 iter/s, 29.7216s/500 iters), loss = 0.0772549
I0831 17:53:15.276698 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0772575 (* 1 = 0.0772575 loss)
I0831 17:53:15.276708 916722 sgd_solver.cpp:106] Iteration 3387500, lr = 0.01
I0831 17:53:44.997828 916722 solver.cpp:218] Iteration 3388000 (16.8231 iter/s, 29.721s/500 iters), loss = 0.281619
I0831 17:53:44.997884 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.281621 (* 1 = 0.281621 loss)
I0831 17:53:44.997891 916722 sgd_solver.cpp:106] Iteration 3388000, lr = 0.01
I0831 17:54:14.720096 916722 solver.cpp:218] Iteration 3388500 (16.8225 iter/s, 29.7221s/500 iters), loss = 0.0463251
I0831 17:54:14.720150 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0463277 (* 1 = 0.0463277 loss)
I0831 17:54:14.720160 916722 sgd_solver.cpp:106] Iteration 3388500, lr = 0.01
I0831 17:54:44.443246 916722 solver.cpp:218] Iteration 3389000 (16.822 iter/s, 29.723s/500 iters), loss = 0.124036
I0831 17:54:44.443305 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.124038 (* 1 = 0.124038 loss)
I0831 17:54:44.443313 916722 sgd_solver.cpp:106] Iteration 3389000, lr = 0.01
I0831 17:55:14.168246 916722 solver.cpp:218] Iteration 3389500 (16.8209 iter/s, 29.7249s/500 iters), loss = 0.0681963
I0831 17:55:14.168301 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0681988 (* 1 = 0.0681988 loss)
I0831 17:55:14.168311 916722 sgd_solver.cpp:106] Iteration 3389500, lr = 0.01
I0831 17:55:43.892138 916722 solver.cpp:218] Iteration 3390000 (16.8216 iter/s, 29.7238s/500 iters), loss = 0.144849
I0831 17:55:43.892213 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.144851 (* 1 = 0.144851 loss)
I0831 17:55:43.892222 916722 sgd_solver.cpp:106] Iteration 3390000, lr = 0.01
I0831 17:56:13.617472 916722 solver.cpp:218] Iteration 3390500 (16.8208 iter/s, 29.7252s/500 iters), loss = 0.211181
I0831 17:56:13.617525 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.211183 (* 1 = 0.211183 loss)
I0831 17:56:13.617533 916722 sgd_solver.cpp:106] Iteration 3390500, lr = 0.01
I0831 17:56:43.336980 916722 solver.cpp:218] Iteration 3391000 (16.824 iter/s, 29.7194s/500 iters), loss = 0.202129
I0831 17:56:43.337040 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.202131 (* 1 = 0.202131 loss)
I0831 17:56:43.337049 916722 sgd_solver.cpp:106] Iteration 3391000, lr = 0.01
I0831 17:57:13.059116 916722 solver.cpp:218] Iteration 3391500 (16.8226 iter/s, 29.722s/500 iters), loss = 0.0333823
I0831 17:57:13.059170 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0333845 (* 1 = 0.0333845 loss)
I0831 17:57:13.059177 916722 sgd_solver.cpp:106] Iteration 3391500, lr = 0.01
I0831 17:57:42.786057 916722 solver.cpp:218] Iteration 3392000 (16.8198 iter/s, 29.7268s/500 iters), loss = 0.201633
I0831 17:57:42.786113 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.201636 (* 1 = 0.201636 loss)
I0831 17:57:42.786120 916722 sgd_solver.cpp:106] Iteration 3392000, lr = 0.01
I0831 17:58:12.510480 916722 solver.cpp:218] Iteration 3392500 (16.8213 iter/s, 29.7243s/500 iters), loss = 0.0859937
I0831 17:58:12.510535 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0859961 (* 1 = 0.0859961 loss)
I0831 17:58:12.510543 916722 sgd_solver.cpp:106] Iteration 3392500, lr = 0.01
I0831 17:58:42.234503 916722 solver.cpp:218] Iteration 3393000 (16.8215 iter/s, 29.7239s/500 iters), loss = 0.043469
I0831 17:58:42.234562 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0434715 (* 1 = 0.0434715 loss)
I0831 17:58:42.234571 916722 sgd_solver.cpp:106] Iteration 3393000, lr = 0.01
I0831 17:59:11.957995 916722 solver.cpp:218] Iteration 3393500 (16.8218 iter/s, 29.7234s/500 iters), loss = 0.180424
I0831 17:59:11.958047 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.180427 (* 1 = 0.180427 loss)
I0831 17:59:11.958056 916722 sgd_solver.cpp:106] Iteration 3393500, lr = 0.01
I0831 17:59:41.683282 916722 solver.cpp:218] Iteration 3394000 (16.8208 iter/s, 29.7252s/500 iters), loss = 0.161879
I0831 17:59:41.683341 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.161882 (* 1 = 0.161882 loss)
I0831 17:59:41.683349 916722 sgd_solver.cpp:106] Iteration 3394000, lr = 0.01
I0831 18:00:11.407923 916722 solver.cpp:218] Iteration 3394500 (16.8211 iter/s, 29.7245s/500 iters), loss = 0.122332
I0831 18:00:11.407976 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.122334 (* 1 = 0.122334 loss)
I0831 18:00:11.407985 916722 sgd_solver.cpp:106] Iteration 3394500, lr = 0.01
I0831 18:00:41.136819 916722 solver.cpp:218] Iteration 3395000 (16.8187 iter/s, 29.7288s/500 iters), loss = 0.127429
I0831 18:00:41.136878 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.127431 (* 1 = 0.127431 loss)
I0831 18:00:41.136886 916722 sgd_solver.cpp:106] Iteration 3395000, lr = 0.01
I0831 18:01:10.861829 916722 solver.cpp:218] Iteration 3395500 (16.8209 iter/s, 29.7249s/500 iters), loss = 0.221244
I0831 18:01:10.861879 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.221247 (* 1 = 0.221247 loss)
I0831 18:01:10.861888 916722 sgd_solver.cpp:106] Iteration 3395500, lr = 0.01
I0831 18:01:40.582680 916722 solver.cpp:218] Iteration 3396000 (16.8233 iter/s, 29.7207s/500 iters), loss = 0.0665057
I0831 18:01:40.582741 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0665084 (* 1 = 0.0665084 loss)
I0831 18:01:40.582748 916722 sgd_solver.cpp:106] Iteration 3396000, lr = 0.01
I0831 18:02:10.305946 916722 solver.cpp:218] Iteration 3396500 (16.8221 iter/s, 29.7227s/500 iters), loss = 0.104584
I0831 18:02:10.306010 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104587 (* 1 = 0.104587 loss)
I0831 18:02:10.306020 916722 sgd_solver.cpp:106] Iteration 3396500, lr = 0.01
I0831 18:02:40.035550 916722 solver.cpp:218] Iteration 3397000 (16.8186 iter/s, 29.729s/500 iters), loss = 0.0799133
I0831 18:02:40.035620 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.079916 (* 1 = 0.079916 loss)
I0831 18:02:40.035629 916722 sgd_solver.cpp:106] Iteration 3397000, lr = 0.01
I0831 18:03:09.756757 916722 solver.cpp:218] Iteration 3397500 (16.8233 iter/s, 29.7207s/500 iters), loss = 0.0428177
I0831 18:03:09.756810 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0428206 (* 1 = 0.0428206 loss)
I0831 18:03:09.756820 916722 sgd_solver.cpp:106] Iteration 3397500, lr = 0.01
I0831 18:03:39.481178 916722 solver.cpp:218] Iteration 3398000 (16.8215 iter/s, 29.7239s/500 iters), loss = 0.0695435
I0831 18:03:39.481237 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0695465 (* 1 = 0.0695465 loss)
I0831 18:03:39.481245 916722 sgd_solver.cpp:106] Iteration 3398000, lr = 0.01
I0831 18:04:09.204814 916722 solver.cpp:218] Iteration 3398500 (16.8219 iter/s, 29.7231s/500 iters), loss = 0.182256
I0831 18:04:09.204866 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.182259 (* 1 = 0.182259 loss)
I0831 18:04:09.204876 916722 sgd_solver.cpp:106] Iteration 3398500, lr = 0.01
I0831 18:04:38.927778 916722 solver.cpp:218] Iteration 3399000 (16.8223 iter/s, 29.7225s/500 iters), loss = 0.101123
I0831 18:04:38.927837 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101126 (* 1 = 0.101126 loss)
I0831 18:04:38.927845 916722 sgd_solver.cpp:106] Iteration 3399000, lr = 0.01
I0831 18:05:08.651044 916722 solver.cpp:218] Iteration 3399500 (16.8221 iter/s, 29.7228s/500 iters), loss = 0.175959
I0831 18:05:08.651096 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.175962 (* 1 = 0.175962 loss)
I0831 18:05:08.651106 916722 sgd_solver.cpp:106] Iteration 3399500, lr = 0.01
I0831 18:05:38.313678 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_3400000.caffemodel
I0831 18:05:38.332587 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_3400000.solverstate
I0831 18:05:38.338666 916722 solver.cpp:330] Iteration 3400000, Testing net (#0)
I0831 18:05:53.652364 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8429
I0831 18:05:53.652413 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.574756 (* 1 = 0.574756 loss)
I0831 18:05:53.710997 916722 solver.cpp:218] Iteration 3400000 (11.0965 iter/s, 45.0593s/500 iters), loss = 0.095834
I0831 18:05:53.711024 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0958368 (* 1 = 0.0958368 loss)
I0831 18:05:53.711032 916722 sgd_solver.cpp:106] Iteration 3400000, lr = 0.01
I0831 18:06:23.389043 916722 solver.cpp:218] Iteration 3400500 (16.8477 iter/s, 29.6776s/500 iters), loss = 0.185707
I0831 18:06:23.389102 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.18571 (* 1 = 0.18571 loss)
I0831 18:06:23.389111 916722 sgd_solver.cpp:106] Iteration 3400500, lr = 0.01
I0831 18:06:53.078750 916722 solver.cpp:218] Iteration 3401000 (16.8411 iter/s, 29.6893s/500 iters), loss = 0.297444
I0831 18:06:53.078804 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.297446 (* 1 = 0.297446 loss)
I0831 18:06:53.078814 916722 sgd_solver.cpp:106] Iteration 3401000, lr = 0.01
I0831 18:07:22.771966 916722 solver.cpp:218] Iteration 3401500 (16.8391 iter/s, 29.6928s/500 iters), loss = 0.0927298
I0831 18:07:22.772025 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0927324 (* 1 = 0.0927324 loss)
I0831 18:07:22.772033 916722 sgd_solver.cpp:106] Iteration 3401500, lr = 0.01
I0831 18:07:52.465749 916722 solver.cpp:218] Iteration 3402000 (16.8388 iter/s, 29.6934s/500 iters), loss = 0.152831
I0831 18:07:52.465799 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152833 (* 1 = 0.152833 loss)
I0831 18:07:52.465823 916722 sgd_solver.cpp:106] Iteration 3402000, lr = 0.01
I0831 18:08:22.161335 916722 solver.cpp:218] Iteration 3402500 (16.8377 iter/s, 29.6952s/500 iters), loss = 0.294702
I0831 18:08:22.161404 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.294704 (* 1 = 0.294704 loss)
I0831 18:08:22.161413 916722 sgd_solver.cpp:106] Iteration 3402500, lr = 0.01
I0831 18:08:51.856402 916722 solver.cpp:218] Iteration 3403000 (16.838 iter/s, 29.6947s/500 iters), loss = 0.155695
I0831 18:08:51.856468 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.155697 (* 1 = 0.155697 loss)
I0831 18:08:51.856478 916722 sgd_solver.cpp:106] Iteration 3403000, lr = 0.01
I0831 18:09:21.552894 916722 solver.cpp:218] Iteration 3403500 (16.8372 iter/s, 29.6961s/500 iters), loss = 0.0521051
I0831 18:09:21.552954 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0521076 (* 1 = 0.0521076 loss)
I0831 18:09:21.552963 916722 sgd_solver.cpp:106] Iteration 3403500, lr = 0.01
I0831 18:09:51.246090 916722 solver.cpp:218] Iteration 3404000 (16.8391 iter/s, 29.6929s/500 iters), loss = 0.0655079
I0831 18:09:51.246145 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0655104 (* 1 = 0.0655104 loss)
I0831 18:09:51.246155 916722 sgd_solver.cpp:106] Iteration 3404000, lr = 0.01
I0831 18:10:20.941041 916722 solver.cpp:218] Iteration 3404500 (16.8381 iter/s, 29.6946s/500 iters), loss = 0.0608463
I0831 18:10:20.941099 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0608487 (* 1 = 0.0608487 loss)
I0831 18:10:20.941108 916722 sgd_solver.cpp:106] Iteration 3404500, lr = 0.01
I0831 18:10:50.638181 916722 solver.cpp:218] Iteration 3405000 (16.8368 iter/s, 29.6968s/500 iters), loss = 0.106932
I0831 18:10:50.638235 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.106935 (* 1 = 0.106935 loss)
I0831 18:10:50.638245 916722 sgd_solver.cpp:106] Iteration 3405000, lr = 0.01
I0831 18:11:20.334874 916722 solver.cpp:218] Iteration 3405500 (16.8371 iter/s, 29.6964s/500 iters), loss = 0.114319
I0831 18:11:20.334935 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.114321 (* 1 = 0.114321 loss)
I0831 18:11:20.334944 916722 sgd_solver.cpp:106] Iteration 3405500, lr = 0.01
I0831 18:11:50.034600 916722 solver.cpp:218] Iteration 3406000 (16.8354 iter/s, 29.6994s/500 iters), loss = 0.169915
I0831 18:11:50.034652 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.169917 (* 1 = 0.169917 loss)
I0831 18:11:50.034662 916722 sgd_solver.cpp:106] Iteration 3406000, lr = 0.01
I0831 18:12:19.733003 916722 solver.cpp:218] Iteration 3406500 (16.8361 iter/s, 29.6981s/500 iters), loss = 0.0828672
I0831 18:12:19.733062 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0828691 (* 1 = 0.0828691 loss)
I0831 18:12:19.733070 916722 sgd_solver.cpp:106] Iteration 3406500, lr = 0.01
I0831 18:12:49.431983 916722 solver.cpp:218] Iteration 3407000 (16.8358 iter/s, 29.6987s/500 iters), loss = 0.195876
I0831 18:12:49.432032 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.195878 (* 1 = 0.195878 loss)
I0831 18:12:49.432042 916722 sgd_solver.cpp:106] Iteration 3407000, lr = 0.01
I0831 18:13:19.128896 916722 solver.cpp:218] Iteration 3407500 (16.8369 iter/s, 29.6966s/500 iters), loss = 0.130003
I0831 18:13:19.128957 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130005 (* 1 = 0.130005 loss)
I0831 18:13:19.128964 916722 sgd_solver.cpp:106] Iteration 3407500, lr = 0.01
I0831 18:13:48.827339 916722 solver.cpp:218] Iteration 3408000 (16.8361 iter/s, 29.6982s/500 iters), loss = 0.018609
I0831 18:13:48.827392 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.018611 (* 1 = 0.018611 loss)
I0831 18:13:48.827402 916722 sgd_solver.cpp:106] Iteration 3408000, lr = 0.01
I0831 18:14:18.525647 916722 solver.cpp:218] Iteration 3408500 (16.8361 iter/s, 29.698s/500 iters), loss = 0.174568
I0831 18:14:18.525717 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.17457 (* 1 = 0.17457 loss)
I0831 18:14:18.525730 916722 sgd_solver.cpp:106] Iteration 3408500, lr = 0.01
I0831 18:14:48.219652 916722 solver.cpp:218] Iteration 3409000 (16.8386 iter/s, 29.6937s/500 iters), loss = 0.0915847
I0831 18:14:48.219705 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0915868 (* 1 = 0.0915868 loss)
I0831 18:14:48.219715 916722 sgd_solver.cpp:106] Iteration 3409000, lr = 0.01
I0831 18:15:17.919236 916722 solver.cpp:218] Iteration 3409500 (16.8354 iter/s, 29.6993s/500 iters), loss = 0.223997
I0831 18:15:17.919296 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.223999 (* 1 = 0.223999 loss)
I0831 18:15:17.919304 916722 sgd_solver.cpp:106] Iteration 3409500, lr = 0.01
I0831 18:15:47.618654 916722 solver.cpp:218] Iteration 3410000 (16.8355 iter/s, 29.6991s/500 iters), loss = 0.088385
I0831 18:15:47.618708 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0883869 (* 1 = 0.0883869 loss)
I0831 18:15:47.618718 916722 sgd_solver.cpp:106] Iteration 3410000, lr = 0.01
I0831 18:16:17.318431 916722 solver.cpp:218] Iteration 3410500 (16.8353 iter/s, 29.6995s/500 iters), loss = 0.253951
I0831 18:16:17.318488 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.253953 (* 1 = 0.253953 loss)
I0831 18:16:17.318497 916722 sgd_solver.cpp:106] Iteration 3410500, lr = 0.01
I0831 18:16:47.016249 916722 solver.cpp:218] Iteration 3411000 (16.8364 iter/s, 29.6976s/500 iters), loss = 0.019125
I0831 18:16:47.016302 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0191269 (* 1 = 0.0191269 loss)
I0831 18:16:47.016312 916722 sgd_solver.cpp:106] Iteration 3411000, lr = 0.01
I0831 18:17:16.711010 916722 solver.cpp:218] Iteration 3411500 (16.8381 iter/s, 29.6945s/500 iters), loss = 0.153873
I0831 18:17:16.711073 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.153875 (* 1 = 0.153875 loss)
I0831 18:17:16.711081 916722 sgd_solver.cpp:106] Iteration 3411500, lr = 0.01
I0831 18:17:46.407567 916722 solver.cpp:218] Iteration 3412000 (16.8371 iter/s, 29.6963s/500 iters), loss = 0.0694137
I0831 18:17:46.407620 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0694158 (* 1 = 0.0694158 loss)
I0831 18:17:46.407630 916722 sgd_solver.cpp:106] Iteration 3412000, lr = 0.01
I0831 18:18:16.104308 916722 solver.cpp:218] Iteration 3412500 (16.837 iter/s, 29.6965s/500 iters), loss = 0.109563
I0831 18:18:16.104367 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109566 (* 1 = 0.109566 loss)
I0831 18:18:16.104375 916722 sgd_solver.cpp:106] Iteration 3412500, lr = 0.01
I0831 18:18:45.801371 916722 solver.cpp:218] Iteration 3413000 (16.8368 iter/s, 29.6968s/500 iters), loss = 0.108579
I0831 18:18:45.801425 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.108582 (* 1 = 0.108582 loss)
I0831 18:18:45.801435 916722 sgd_solver.cpp:106] Iteration 3413000, lr = 0.01
I0831 18:19:15.500705 916722 solver.cpp:218] Iteration 3413500 (16.8355 iter/s, 29.6991s/500 iters), loss = 0.166324
I0831 18:19:15.500777 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.166326 (* 1 = 0.166326 loss)
I0831 18:19:15.500785 916722 sgd_solver.cpp:106] Iteration 3413500, lr = 0.01
I0831 18:19:45.197651 916722 solver.cpp:218] Iteration 3414000 (16.8369 iter/s, 29.6967s/500 iters), loss = 0.0893712
I0831 18:19:45.197705 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0893734 (* 1 = 0.0893734 loss)
I0831 18:19:45.197715 916722 sgd_solver.cpp:106] Iteration 3414000, lr = 0.01
I0831 18:20:14.895351 916722 solver.cpp:218] Iteration 3414500 (16.8365 iter/s, 29.6975s/500 iters), loss = 0.101047
I0831 18:20:14.895411 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.10105 (* 1 = 0.10105 loss)
I0831 18:20:14.895418 916722 sgd_solver.cpp:106] Iteration 3414500, lr = 0.01
I0831 18:20:44.592702 916722 solver.cpp:218] Iteration 3415000 (16.8367 iter/s, 29.6971s/500 iters), loss = 0.174011
I0831 18:20:44.592772 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.174013 (* 1 = 0.174013 loss)
I0831 18:20:44.592782 916722 sgd_solver.cpp:106] Iteration 3415000, lr = 0.01
I0831 18:21:14.290112 916722 solver.cpp:218] Iteration 3415500 (16.8366 iter/s, 29.6972s/500 iters), loss = 0.157382
I0831 18:21:14.290181 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.157385 (* 1 = 0.157385 loss)
I0831 18:21:14.290189 916722 sgd_solver.cpp:106] Iteration 3415500, lr = 0.01
I0831 18:21:43.988341 916722 solver.cpp:218] Iteration 3416000 (16.8362 iter/s, 29.698s/500 iters), loss = 0.0786076
I0831 18:21:43.988389 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0786099 (* 1 = 0.0786099 loss)
I0831 18:21:43.988396 916722 sgd_solver.cpp:106] Iteration 3416000, lr = 0.01
I0831 18:22:13.686659 916722 solver.cpp:218] Iteration 3416500 (16.8361 iter/s, 29.6981s/500 iters), loss = 0.24974
I0831 18:22:13.686718 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.249742 (* 1 = 0.249742 loss)
I0831 18:22:13.686726 916722 sgd_solver.cpp:106] Iteration 3416500, lr = 0.01
I0831 18:22:43.381095 916722 solver.cpp:218] Iteration 3417000 (16.8383 iter/s, 29.6942s/500 iters), loss = 0.245399
I0831 18:22:43.381148 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.245402 (* 1 = 0.245402 loss)
I0831 18:22:43.381157 916722 sgd_solver.cpp:106] Iteration 3417000, lr = 0.01
I0831 18:23:13.081833 916722 solver.cpp:218] Iteration 3417500 (16.8347 iter/s, 29.7005s/500 iters), loss = 0.0502039
I0831 18:23:13.081893 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0502063 (* 1 = 0.0502063 loss)
I0831 18:23:13.081902 916722 sgd_solver.cpp:106] Iteration 3417500, lr = 0.01
I0831 18:23:42.778643 916722 solver.cpp:218] Iteration 3418000 (16.837 iter/s, 29.6966s/500 iters), loss = 0.199019
I0831 18:23:42.778697 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.199022 (* 1 = 0.199022 loss)
I0831 18:23:42.778705 916722 sgd_solver.cpp:106] Iteration 3418000, lr = 0.01
I0831 18:24:12.475541 916722 solver.cpp:218] Iteration 3418500 (16.8369 iter/s, 29.6967s/500 iters), loss = 0.0980232
I0831 18:24:12.475601 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0980256 (* 1 = 0.0980256 loss)
I0831 18:24:12.475610 916722 sgd_solver.cpp:106] Iteration 3418500, lr = 0.01
I0831 18:24:42.181109 916722 solver.cpp:218] Iteration 3419000 (16.832 iter/s, 29.7053s/500 iters), loss = 0.247919
I0831 18:24:42.181164 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.247921 (* 1 = 0.247921 loss)
I0831 18:24:42.181174 916722 sgd_solver.cpp:106] Iteration 3419000, lr = 0.01
I0831 18:25:11.876948 916722 solver.cpp:218] Iteration 3419500 (16.8375 iter/s, 29.6956s/500 iters), loss = 0.161875
I0831 18:25:11.877007 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.161878 (* 1 = 0.161878 loss)
I0831 18:25:11.877017 916722 sgd_solver.cpp:106] Iteration 3419500, lr = 0.01
I0831 18:25:41.571460 916722 solver.cpp:218] Iteration 3420000 (16.8383 iter/s, 29.6943s/500 iters), loss = 0.191749
I0831 18:25:41.571511 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.191751 (* 1 = 0.191751 loss)
I0831 18:25:41.571521 916722 sgd_solver.cpp:106] Iteration 3420000, lr = 0.01
I0831 18:26:11.270412 916722 solver.cpp:218] Iteration 3420500 (16.8357 iter/s, 29.6987s/500 iters), loss = 0.0748516
I0831 18:26:11.270474 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.074854 (* 1 = 0.074854 loss)
I0831 18:26:11.270483 916722 sgd_solver.cpp:106] Iteration 3420500, lr = 0.01
I0831 18:26:40.963706 916722 solver.cpp:218] Iteration 3421000 (16.8389 iter/s, 29.6931s/500 iters), loss = 0.112444
I0831 18:26:40.963759 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112446 (* 1 = 0.112446 loss)
I0831 18:26:40.963768 916722 sgd_solver.cpp:106] Iteration 3421000, lr = 0.01
I0831 18:27:10.659731 916722 solver.cpp:218] Iteration 3421500 (16.8374 iter/s, 29.6958s/500 iters), loss = 0.0762409
I0831 18:27:10.659793 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0762434 (* 1 = 0.0762434 loss)
I0831 18:27:10.659801 916722 sgd_solver.cpp:106] Iteration 3421500, lr = 0.01
I0831 18:27:40.356385 916722 solver.cpp:218] Iteration 3422000 (16.837 iter/s, 29.6964s/500 iters), loss = 0.182841
I0831 18:27:40.356441 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.182844 (* 1 = 0.182844 loss)
I0831 18:27:40.356451 916722 sgd_solver.cpp:106] Iteration 3422000, lr = 0.01
I0831 18:28:10.054270 916722 solver.cpp:218] Iteration 3422500 (16.8363 iter/s, 29.6977s/500 iters), loss = 0.0589146
I0831 18:28:10.054342 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.058917 (* 1 = 0.058917 loss)
I0831 18:28:10.054352 916722 sgd_solver.cpp:106] Iteration 3422500, lr = 0.01
I0831 18:28:39.748929 916722 solver.cpp:218] Iteration 3423000 (16.8382 iter/s, 29.6944s/500 iters), loss = 0.0274806
I0831 18:28:39.748983 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.027483 (* 1 = 0.027483 loss)
I0831 18:28:39.748993 916722 sgd_solver.cpp:106] Iteration 3423000, lr = 0.01
I0831 18:29:09.445292 916722 solver.cpp:218] Iteration 3423500 (16.8372 iter/s, 29.6961s/500 iters), loss = 0.230933
I0831 18:29:09.445349 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.230935 (* 1 = 0.230935 loss)
I0831 18:29:09.445358 916722 sgd_solver.cpp:106] Iteration 3423500, lr = 0.01
I0831 18:29:39.141752 916722 solver.cpp:218] Iteration 3424000 (16.8371 iter/s, 29.6962s/500 iters), loss = 0.0722892
I0831 18:29:39.141804 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0722915 (* 1 = 0.0722915 loss)
I0831 18:29:39.141814 916722 sgd_solver.cpp:106] Iteration 3424000, lr = 0.01
I0831 18:30:08.836930 916722 solver.cpp:218] Iteration 3424500 (16.8379 iter/s, 29.695s/500 iters), loss = 0.106425
I0831 18:30:08.836983 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.106427 (* 1 = 0.106427 loss)
I0831 18:30:08.836992 916722 sgd_solver.cpp:106] Iteration 3424500, lr = 0.01
I0831 18:30:38.533419 916722 solver.cpp:218] Iteration 3425000 (16.8371 iter/s, 29.6963s/500 iters), loss = 0.041209
I0831 18:30:38.533473 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0412113 (* 1 = 0.0412113 loss)
I0831 18:30:38.533483 916722 sgd_solver.cpp:106] Iteration 3425000, lr = 0.01
I0831 18:31:08.228760 916722 solver.cpp:218] Iteration 3425500 (16.8378 iter/s, 29.6951s/500 iters), loss = 0.0930523
I0831 18:31:08.228821 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0930546 (* 1 = 0.0930546 loss)
I0831 18:31:08.228828 916722 sgd_solver.cpp:106] Iteration 3425500, lr = 0.01
I0831 18:31:37.923780 916722 solver.cpp:218] Iteration 3426000 (16.838 iter/s, 29.6948s/500 iters), loss = 0.235553
I0831 18:31:37.923832 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.235556 (* 1 = 0.235556 loss)
I0831 18:31:37.923842 916722 sgd_solver.cpp:106] Iteration 3426000, lr = 0.01
I0831 18:32:07.615978 916722 solver.cpp:218] Iteration 3426500 (16.8396 iter/s, 29.692s/500 iters), loss = 0.152179
I0831 18:32:07.616037 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152181 (* 1 = 0.152181 loss)
I0831 18:32:07.616045 916722 sgd_solver.cpp:106] Iteration 3426500, lr = 0.01
I0831 18:32:37.308694 916722 solver.cpp:218] Iteration 3427000 (16.8393 iter/s, 29.6925s/500 iters), loss = 0.0336939
I0831 18:32:37.308760 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0336962 (* 1 = 0.0336962 loss)
I0831 18:32:37.308770 916722 sgd_solver.cpp:106] Iteration 3427000, lr = 0.01
I0831 18:33:07.001601 916722 solver.cpp:218] Iteration 3427500 (16.8392 iter/s, 29.6927s/500 iters), loss = 0.131259
I0831 18:33:07.001663 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131261 (* 1 = 0.131261 loss)
I0831 18:33:07.001672 916722 sgd_solver.cpp:106] Iteration 3427500, lr = 0.01
I0831 18:33:36.693969 916722 solver.cpp:218] Iteration 3428000 (16.8395 iter/s, 29.6922s/500 iters), loss = 0.0209885
I0831 18:33:36.694022 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0209906 (* 1 = 0.0209906 loss)
I0831 18:33:36.694031 916722 sgd_solver.cpp:106] Iteration 3428000, lr = 0.01
I0831 18:34:06.381943 916722 solver.cpp:218] Iteration 3428500 (16.842 iter/s, 29.6878s/500 iters), loss = 0.0916963
I0831 18:34:06.382010 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0916982 (* 1 = 0.0916982 loss)
I0831 18:34:06.382019 916722 sgd_solver.cpp:106] Iteration 3428500, lr = 0.01
I0831 18:34:36.074115 916722 solver.cpp:218] Iteration 3429000 (16.8396 iter/s, 29.692s/500 iters), loss = 0.399469
I0831 18:34:36.074168 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.399471 (* 1 = 0.399471 loss)
I0831 18:34:36.074177 916722 sgd_solver.cpp:106] Iteration 3429000, lr = 0.01
I0831 18:35:05.764652 916722 solver.cpp:218] Iteration 3429500 (16.8405 iter/s, 29.6903s/500 iters), loss = 0.24725
I0831 18:35:05.764714 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.247252 (* 1 = 0.247252 loss)
I0831 18:35:05.764722 916722 sgd_solver.cpp:106] Iteration 3429500, lr = 0.01
I0831 18:35:35.454207 916722 solver.cpp:218] Iteration 3430000 (16.8411 iter/s, 29.6893s/500 iters), loss = 0.214802
I0831 18:35:35.454259 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.214803 (* 1 = 0.214803 loss)
I0831 18:35:35.454269 916722 sgd_solver.cpp:106] Iteration 3430000, lr = 0.01
I0831 18:36:05.144822 916722 solver.cpp:218] Iteration 3430500 (16.8403 iter/s, 29.6906s/500 iters), loss = 0.359336
I0831 18:36:05.144881 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.359338 (* 1 = 0.359338 loss)
I0831 18:36:05.144888 916722 sgd_solver.cpp:106] Iteration 3430500, lr = 0.01
I0831 18:36:34.834897 916722 solver.cpp:218] Iteration 3431000 (16.8405 iter/s, 29.6904s/500 iters), loss = 0.0888257
I0831 18:36:34.834949 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0888272 (* 1 = 0.0888272 loss)
I0831 18:36:34.834959 916722 sgd_solver.cpp:106] Iteration 3431000, lr = 0.01
I0831 18:37:04.526767 916722 solver.cpp:218] Iteration 3431500 (16.8394 iter/s, 29.6922s/500 iters), loss = 0.0910551
I0831 18:37:04.526823 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0910565 (* 1 = 0.0910565 loss)
I0831 18:37:04.526831 916722 sgd_solver.cpp:106] Iteration 3431500, lr = 0.01
I0831 18:37:34.220643 916722 solver.cpp:218] Iteration 3432000 (16.8383 iter/s, 29.6942s/500 iters), loss = 0.18659
I0831 18:37:34.220695 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.186591 (* 1 = 0.186591 loss)
I0831 18:37:34.220705 916722 sgd_solver.cpp:106] Iteration 3432000, lr = 0.01
I0831 18:38:03.912513 916722 solver.cpp:218] Iteration 3432500 (16.8395 iter/s, 29.6921s/500 iters), loss = 0.360672
I0831 18:38:03.912575 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.360673 (* 1 = 0.360673 loss)
I0831 18:38:03.912585 916722 sgd_solver.cpp:106] Iteration 3432500, lr = 0.01
I0831 18:38:33.602713 916722 solver.cpp:218] Iteration 3433000 (16.8404 iter/s, 29.6904s/500 iters), loss = 0.121783
I0831 18:38:33.602764 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.121784 (* 1 = 0.121784 loss)
I0831 18:38:33.602772 916722 sgd_solver.cpp:106] Iteration 3433000, lr = 0.01
I0831 18:39:03.293300 916722 solver.cpp:218] Iteration 3433500 (16.8402 iter/s, 29.6908s/500 iters), loss = 0.115782
I0831 18:39:03.293359 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115783 (* 1 = 0.115783 loss)
I0831 18:39:03.293366 916722 sgd_solver.cpp:106] Iteration 3433500, lr = 0.01
I0831 18:39:32.988293 916722 solver.cpp:218] Iteration 3434000 (16.8377 iter/s, 29.6952s/500 iters), loss = 0.0602235
I0831 18:39:32.988346 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0602247 (* 1 = 0.0602247 loss)
I0831 18:39:32.988355 916722 sgd_solver.cpp:106] Iteration 3434000, lr = 0.01
I0831 18:40:02.680176 916722 solver.cpp:218] Iteration 3434500 (16.8395 iter/s, 29.6921s/500 iters), loss = 0.18091
I0831 18:40:02.680233 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.180911 (* 1 = 0.180911 loss)
I0831 18:40:02.680241 916722 sgd_solver.cpp:106] Iteration 3434500, lr = 0.01
I0831 18:40:32.375042 916722 solver.cpp:218] Iteration 3435000 (16.8378 iter/s, 29.695s/500 iters), loss = 0.130569
I0831 18:40:32.375106 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13057 (* 1 = 0.13057 loss)
I0831 18:40:32.375115 916722 sgd_solver.cpp:106] Iteration 3435000, lr = 0.01
I0831 18:41:02.070122 916722 solver.cpp:218] Iteration 3435500 (16.8377 iter/s, 29.6952s/500 iters), loss = 0.044184
I0831 18:41:02.070189 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0441848 (* 1 = 0.0441848 loss)
I0831 18:41:02.070199 916722 sgd_solver.cpp:106] Iteration 3435500, lr = 0.01
I0831 18:41:31.769316 916722 solver.cpp:218] Iteration 3436000 (16.8354 iter/s, 29.6993s/500 iters), loss = 0.0563419
I0831 18:41:31.769371 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0563426 (* 1 = 0.0563426 loss)
I0831 18:41:31.769379 916722 sgd_solver.cpp:106] Iteration 3436000, lr = 0.01
I0831 18:42:01.469928 916722 solver.cpp:218] Iteration 3436500 (16.8346 iter/s, 29.7007s/500 iters), loss = 0.23361
I0831 18:42:01.469986 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.233611 (* 1 = 0.233611 loss)
I0831 18:42:01.469995 916722 sgd_solver.cpp:106] Iteration 3436500, lr = 0.01
I0831 18:42:31.164173 916722 solver.cpp:218] Iteration 3437000 (16.8382 iter/s, 29.6944s/500 iters), loss = 0.0802136
I0831 18:42:31.164225 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0802145 (* 1 = 0.0802145 loss)
I0831 18:42:31.164233 916722 sgd_solver.cpp:106] Iteration 3437000, lr = 0.01
I0831 18:43:00.857867 916722 solver.cpp:218] Iteration 3437500 (16.8385 iter/s, 29.6938s/500 iters), loss = 0.131348
I0831 18:43:00.857925 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131349 (* 1 = 0.131349 loss)
I0831 18:43:00.857933 916722 sgd_solver.cpp:106] Iteration 3437500, lr = 0.01
I0831 18:43:30.550942 916722 solver.cpp:218] Iteration 3438000 (16.8389 iter/s, 29.6932s/500 iters), loss = 0.177509
I0831 18:43:30.550995 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.17751 (* 1 = 0.17751 loss)
I0831 18:43:30.551004 916722 sgd_solver.cpp:106] Iteration 3438000, lr = 0.01
I0831 18:44:00.244859 916722 solver.cpp:218] Iteration 3438500 (16.8384 iter/s, 29.694s/500 iters), loss = 0.134259
I0831 18:44:00.244917 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13426 (* 1 = 0.13426 loss)
I0831 18:44:00.244926 916722 sgd_solver.cpp:106] Iteration 3438500, lr = 0.01
I0831 18:44:29.939783 916722 solver.cpp:218] Iteration 3439000 (16.8379 iter/s, 29.695s/500 iters), loss = 0.22776
I0831 18:44:29.939834 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.227761 (* 1 = 0.227761 loss)
I0831 18:44:29.939843 916722 sgd_solver.cpp:106] Iteration 3439000, lr = 0.01
I0831 18:44:59.636204 916722 solver.cpp:218] Iteration 3439500 (16.837 iter/s, 29.6965s/500 iters), loss = 0.139935
I0831 18:44:59.636261 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139936 (* 1 = 0.139936 loss)
I0831 18:44:59.636269 916722 sgd_solver.cpp:106] Iteration 3439500, lr = 0.01
I0831 18:45:29.329453 916722 solver.cpp:218] Iteration 3440000 (16.8388 iter/s, 29.6933s/500 iters), loss = 0.19754
I0831 18:45:29.329507 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.197541 (* 1 = 0.197541 loss)
I0831 18:45:29.329515 916722 sgd_solver.cpp:106] Iteration 3440000, lr = 0.01
I0831 18:45:59.027618 916722 solver.cpp:218] Iteration 3440500 (16.836 iter/s, 29.6982s/500 iters), loss = 0.0469102
I0831 18:45:59.027678 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0469113 (* 1 = 0.0469113 loss)
I0831 18:45:59.027686 916722 sgd_solver.cpp:106] Iteration 3440500, lr = 0.01
I0831 18:46:28.724042 916722 solver.cpp:218] Iteration 3441000 (16.837 iter/s, 29.6964s/500 iters), loss = 0.0434036
I0831 18:46:28.724098 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0434048 (* 1 = 0.0434048 loss)
I0831 18:46:28.724108 916722 sgd_solver.cpp:106] Iteration 3441000, lr = 0.01
I0831 18:46:58.430974 916722 solver.cpp:218] Iteration 3441500 (16.8311 iter/s, 29.707s/500 iters), loss = 0.140157
I0831 18:46:58.431047 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.140158 (* 1 = 0.140158 loss)
I0831 18:46:58.431061 916722 sgd_solver.cpp:106] Iteration 3441500, lr = 0.01
I0831 18:47:28.130287 916722 solver.cpp:218] Iteration 3442000 (16.8354 iter/s, 29.6993s/500 iters), loss = 0.129824
I0831 18:47:28.130340 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.129825 (* 1 = 0.129825 loss)
I0831 18:47:28.130350 916722 sgd_solver.cpp:106] Iteration 3442000, lr = 0.01
I0831 18:47:57.831939 916722 solver.cpp:218] Iteration 3442500 (16.8341 iter/s, 29.7017s/500 iters), loss = 0.151308
I0831 18:47:57.831997 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.151309 (* 1 = 0.151309 loss)
I0831 18:47:57.832006 916722 sgd_solver.cpp:106] Iteration 3442500, lr = 0.01
I0831 18:48:27.530225 916722 solver.cpp:218] Iteration 3443000 (16.836 iter/s, 29.6983s/500 iters), loss = 0.192208
I0831 18:48:27.530277 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.192209 (* 1 = 0.192209 loss)
I0831 18:48:27.530287 916722 sgd_solver.cpp:106] Iteration 3443000, lr = 0.01
I0831 18:48:57.230085 916722 solver.cpp:218] Iteration 3443500 (16.8351 iter/s, 29.6999s/500 iters), loss = 0.365496
I0831 18:48:57.230141 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.365497 (* 1 = 0.365497 loss)
I0831 18:48:57.230149 916722 sgd_solver.cpp:106] Iteration 3443500, lr = 0.01
I0831 18:49:26.924028 916722 solver.cpp:218] Iteration 3444000 (16.8385 iter/s, 29.6939s/500 iters), loss = 0.334076
I0831 18:49:26.924077 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.334077 (* 1 = 0.334077 loss)
I0831 18:49:26.924086 916722 sgd_solver.cpp:106] Iteration 3444000, lr = 0.01
I0831 18:49:56.616708 916722 solver.cpp:218] Iteration 3444500 (16.8392 iter/s, 29.6927s/500 iters), loss = 0.119186
I0831 18:49:56.616780 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.119188 (* 1 = 0.119188 loss)
I0831 18:49:56.616787 916722 sgd_solver.cpp:106] Iteration 3444500, lr = 0.01
I0831 18:50:26.309001 916722 solver.cpp:218] Iteration 3445000 (16.8394 iter/s, 29.6923s/500 iters), loss = 0.109029
I0831 18:50:26.309056 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109031 (* 1 = 0.109031 loss)
I0831 18:50:26.309065 916722 sgd_solver.cpp:106] Iteration 3445000, lr = 0.01
I0831 18:50:56.001093 916722 solver.cpp:218] Iteration 3445500 (16.8395 iter/s, 29.6921s/500 iters), loss = 0.274627
I0831 18:50:56.001155 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.274629 (* 1 = 0.274629 loss)
I0831 18:50:56.001164 916722 sgd_solver.cpp:106] Iteration 3445500, lr = 0.01
I0831 18:51:25.694272 916722 solver.cpp:218] Iteration 3446000 (16.8389 iter/s, 29.6931s/500 iters), loss = 0.0153829
I0831 18:51:25.694324 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0153843 (* 1 = 0.0153843 loss)
I0831 18:51:25.694332 916722 sgd_solver.cpp:106] Iteration 3446000, lr = 0.01
I0831 18:51:55.386219 916722 solver.cpp:218] Iteration 3446500 (16.8396 iter/s, 29.6919s/500 iters), loss = 0.0465113
I0831 18:51:55.386279 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0465128 (* 1 = 0.0465128 loss)
I0831 18:51:55.386287 916722 sgd_solver.cpp:106] Iteration 3446500, lr = 0.01
I0831 18:52:25.080229 916722 solver.cpp:218] Iteration 3447000 (16.8384 iter/s, 29.694s/500 iters), loss = 0.0350865
I0831 18:52:25.080281 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.035088 (* 1 = 0.035088 loss)
I0831 18:52:25.080289 916722 sgd_solver.cpp:106] Iteration 3447000, lr = 0.01
I0831 18:52:54.778506 916722 solver.cpp:218] Iteration 3447500 (16.836 iter/s, 29.6982s/500 iters), loss = 0.122013
I0831 18:52:54.778564 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.122015 (* 1 = 0.122015 loss)
I0831 18:52:54.778573 916722 sgd_solver.cpp:106] Iteration 3447500, lr = 0.01
I0831 18:53:24.471009 916722 solver.cpp:218] Iteration 3448000 (16.8393 iter/s, 29.6925s/500 iters), loss = 0.0478685
I0831 18:53:24.471058 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0478699 (* 1 = 0.0478699 loss)
I0831 18:53:24.471078 916722 sgd_solver.cpp:106] Iteration 3448000, lr = 0.01
I0831 18:53:54.162405 916722 solver.cpp:218] Iteration 3448500 (16.8399 iter/s, 29.6914s/500 iters), loss = 0.267684
I0831 18:53:54.162475 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.267685 (* 1 = 0.267685 loss)
I0831 18:53:54.162483 916722 sgd_solver.cpp:106] Iteration 3448500, lr = 0.01
I0831 18:54:23.853379 916722 solver.cpp:218] Iteration 3449000 (16.8402 iter/s, 29.6909s/500 iters), loss = 0.373668
I0831 18:54:23.853430 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.37367 (* 1 = 0.37367 loss)
I0831 18:54:23.853439 916722 sgd_solver.cpp:106] Iteration 3449000, lr = 0.01
I0831 18:54:53.547953 916722 solver.cpp:218] Iteration 3449500 (16.8381 iter/s, 29.6945s/500 iters), loss = 0.168139
I0831 18:54:53.548007 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.16814 (* 1 = 0.16814 loss)
I0831 18:54:53.548015 916722 sgd_solver.cpp:106] Iteration 3449500, lr = 0.01
I0831 18:55:23.181720 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_3450000.caffemodel
I0831 18:55:23.200765 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_3450000.solverstate
I0831 18:55:23.206774 916722 solver.cpp:330] Iteration 3450000, Testing net (#0)
I0831 18:55:38.516093 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8764
I0831 18:55:38.516144 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.429417 (* 1 = 0.429417 loss)
I0831 18:55:38.574769 916722 solver.cpp:218] Iteration 3450000 (11.1045 iter/s, 45.0267s/500 iters), loss = 0.0840487
I0831 18:55:38.574795 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0840498 (* 1 = 0.0840498 loss)
I0831 18:55:38.574805 916722 sgd_solver.cpp:106] Iteration 3450000, lr = 0.01
I0831 18:56:08.267498 916722 solver.cpp:218] Iteration 3450500 (16.8392 iter/s, 29.6927s/500 iters), loss = 0.188337
I0831 18:56:08.267547 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.188338 (* 1 = 0.188338 loss)
I0831 18:56:08.267556 916722 sgd_solver.cpp:106] Iteration 3450500, lr = 0.01
I0831 18:56:37.977933 916722 solver.cpp:218] Iteration 3451000 (16.8292 iter/s, 29.7104s/500 iters), loss = 0.122595
I0831 18:56:37.977994 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.122596 (* 1 = 0.122596 loss)
I0831 18:56:37.978003 916722 sgd_solver.cpp:106] Iteration 3451000, lr = 0.01
I0831 18:57:07.686879 916722 solver.cpp:218] Iteration 3451500 (16.83 iter/s, 29.7089s/500 iters), loss = 0.199791
I0831 18:57:07.686933 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.199793 (* 1 = 0.199793 loss)
I0831 18:57:07.686942 916722 sgd_solver.cpp:106] Iteration 3451500, lr = 0.01
I0831 18:57:37.399544 916722 solver.cpp:218] Iteration 3452000 (16.8279 iter/s, 29.7126s/500 iters), loss = 0.0223939
I0831 18:57:37.399603 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0223952 (* 1 = 0.0223952 loss)
I0831 18:57:37.399611 916722 sgd_solver.cpp:106] Iteration 3452000, lr = 0.01
I0831 18:58:07.117266 916722 solver.cpp:218] Iteration 3452500 (16.825 iter/s, 29.7176s/500 iters), loss = 0.185874
I0831 18:58:07.117321 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.185875 (* 1 = 0.185875 loss)
I0831 18:58:07.117331 916722 sgd_solver.cpp:106] Iteration 3452500, lr = 0.01
I0831 18:58:36.835974 916722 solver.cpp:218] Iteration 3453000 (16.8245 iter/s, 29.7186s/500 iters), loss = 0.202059
I0831 18:58:36.836033 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.202061 (* 1 = 0.202061 loss)
I0831 18:58:36.836042 916722 sgd_solver.cpp:106] Iteration 3453000, lr = 0.01
I0831 18:59:06.552752 916722 solver.cpp:218] Iteration 3453500 (16.8256 iter/s, 29.7167s/500 iters), loss = 0.0985585
I0831 18:59:06.552806 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0985597 (* 1 = 0.0985597 loss)
I0831 18:59:06.552815 916722 sgd_solver.cpp:106] Iteration 3453500, lr = 0.01
I0831 18:59:36.267961 916722 solver.cpp:218] Iteration 3454000 (16.8264 iter/s, 29.7151s/500 iters), loss = 0.264375
I0831 18:59:36.268033 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.264377 (* 1 = 0.264377 loss)
I0831 18:59:36.268041 916722 sgd_solver.cpp:106] Iteration 3454000, lr = 0.01
I0831 19:00:05.984601 916722 solver.cpp:218] Iteration 3454500 (16.8256 iter/s, 29.7165s/500 iters), loss = 0.0173037
I0831 19:00:05.984653 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0173051 (* 1 = 0.0173051 loss)
I0831 19:00:05.984663 916722 sgd_solver.cpp:106] Iteration 3454500, lr = 0.01
I0831 19:00:35.700760 916722 solver.cpp:218] Iteration 3455000 (16.8259 iter/s, 29.7161s/500 iters), loss = 0.104587
I0831 19:00:35.700820 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104588 (* 1 = 0.104588 loss)
I0831 19:00:35.700829 916722 sgd_solver.cpp:106] Iteration 3455000, lr = 0.01
I0831 19:01:05.417919 916722 solver.cpp:218] Iteration 3455500 (16.8253 iter/s, 29.7171s/500 iters), loss = 0.248199
I0831 19:01:05.417969 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.2482 (* 1 = 0.2482 loss)
I0831 19:01:05.417977 916722 sgd_solver.cpp:106] Iteration 3455500, lr = 0.01
I0831 19:01:35.133651 916722 solver.cpp:218] Iteration 3456000 (16.8261 iter/s, 29.7157s/500 iters), loss = 0.143681
I0831 19:01:35.133709 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.143683 (* 1 = 0.143683 loss)
I0831 19:01:35.133718 916722 sgd_solver.cpp:106] Iteration 3456000, lr = 0.01
I0831 19:02:04.852277 916722 solver.cpp:218] Iteration 3456500 (16.8245 iter/s, 29.7185s/500 iters), loss = 0.133852
I0831 19:02:04.852327 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133854 (* 1 = 0.133854 loss)
I0831 19:02:04.852335 916722 sgd_solver.cpp:106] Iteration 3456500, lr = 0.01
I0831 19:02:34.571859 916722 solver.cpp:218] Iteration 3457000 (16.824 iter/s, 29.7195s/500 iters), loss = 0.113368
I0831 19:02:34.571918 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.113369 (* 1 = 0.113369 loss)
I0831 19:02:34.571925 916722 sgd_solver.cpp:106] Iteration 3457000, lr = 0.01
I0831 19:03:04.288411 916722 solver.cpp:218] Iteration 3457500 (16.8257 iter/s, 29.7165s/500 iters), loss = 0.096801
I0831 19:03:04.288472 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0968028 (* 1 = 0.0968028 loss)
I0831 19:03:04.288480 916722 sgd_solver.cpp:106] Iteration 3457500, lr = 0.01
I0831 19:03:34.005816 916722 solver.cpp:218] Iteration 3458000 (16.8252 iter/s, 29.7173s/500 iters), loss = 0.11013
I0831 19:03:34.005877 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110132 (* 1 = 0.110132 loss)
I0831 19:03:34.005885 916722 sgd_solver.cpp:106] Iteration 3458000, lr = 0.01
I0831 19:04:03.721060 916722 solver.cpp:218] Iteration 3458500 (16.8264 iter/s, 29.7151s/500 iters), loss = 0.0911651
I0831 19:04:03.721110 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0911668 (* 1 = 0.0911668 loss)
I0831 19:04:03.721119 916722 sgd_solver.cpp:106] Iteration 3458500, lr = 0.01
I0831 19:04:33.434275 916722 solver.cpp:218] Iteration 3459000 (16.8276 iter/s, 29.7131s/500 iters), loss = 0.476998
I0831 19:04:33.434334 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.477 (* 1 = 0.477 loss)
I0831 19:04:33.434342 916722 sgd_solver.cpp:106] Iteration 3459000, lr = 0.01
I0831 19:05:03.150627 916722 solver.cpp:218] Iteration 3459500 (16.8258 iter/s, 29.7162s/500 iters), loss = 0.0758576
I0831 19:05:03.150681 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0758594 (* 1 = 0.0758594 loss)
I0831 19:05:03.150691 916722 sgd_solver.cpp:106] Iteration 3459500, lr = 0.01
I0831 19:05:32.866287 916722 solver.cpp:218] Iteration 3460000 (16.8262 iter/s, 29.7156s/500 iters), loss = 0.363468
I0831 19:05:32.866348 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.36347 (* 1 = 0.36347 loss)
I0831 19:05:32.866355 916722 sgd_solver.cpp:106] Iteration 3460000, lr = 0.01
I0831 19:06:02.583772 916722 solver.cpp:218] Iteration 3460500 (16.8252 iter/s, 29.7174s/500 iters), loss = 0.0184728
I0831 19:06:02.583835 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0184747 (* 1 = 0.0184747 loss)
I0831 19:06:02.583845 916722 sgd_solver.cpp:106] Iteration 3460500, lr = 0.01
I0831 19:06:32.302675 916722 solver.cpp:218] Iteration 3461000 (16.8244 iter/s, 29.7188s/500 iters), loss = 0.236146
I0831 19:06:32.302747 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.236148 (* 1 = 0.236148 loss)
I0831 19:06:32.302757 916722 sgd_solver.cpp:106] Iteration 3461000, lr = 0.01
I0831 19:07:02.016538 916722 solver.cpp:218] Iteration 3461500 (16.8272 iter/s, 29.7137s/500 iters), loss = 0.0459964
I0831 19:07:02.016592 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0459984 (* 1 = 0.0459984 loss)
I0831 19:07:02.016602 916722 sgd_solver.cpp:106] Iteration 3461500, lr = 0.01
I0831 19:07:31.736681 916722 solver.cpp:218] Iteration 3462000 (16.8237 iter/s, 29.72s/500 iters), loss = 0.209196
I0831 19:07:31.736750 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.209198 (* 1 = 0.209198 loss)
I0831 19:07:31.736758 916722 sgd_solver.cpp:106] Iteration 3462000, lr = 0.01
I0831 19:08:01.451956 916722 solver.cpp:218] Iteration 3462500 (16.8264 iter/s, 29.7152s/500 iters), loss = 0.085981
I0831 19:08:01.452006 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0859828 (* 1 = 0.0859828 loss)
I0831 19:08:01.452015 916722 sgd_solver.cpp:106] Iteration 3462500, lr = 0.01
I0831 19:08:31.168462 916722 solver.cpp:218] Iteration 3463000 (16.8257 iter/s, 29.7164s/500 iters), loss = 0.293394
I0831 19:08:31.168520 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.293396 (* 1 = 0.293396 loss)
I0831 19:08:31.168529 916722 sgd_solver.cpp:106] Iteration 3463000, lr = 0.01
I0831 19:09:00.885941 916722 solver.cpp:218] Iteration 3463500 (16.8252 iter/s, 29.7174s/500 iters), loss = 0.49383
I0831 19:09:00.885990 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.493831 (* 1 = 0.493831 loss)
I0831 19:09:00.886000 916722 sgd_solver.cpp:106] Iteration 3463500, lr = 0.01
I0831 19:09:30.603339 916722 solver.cpp:218] Iteration 3464000 (16.8252 iter/s, 29.7173s/500 iters), loss = 0.060648
I0831 19:09:30.603399 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0606497 (* 1 = 0.0606497 loss)
I0831 19:09:30.603407 916722 sgd_solver.cpp:106] Iteration 3464000, lr = 0.01
I0831 19:10:00.321615 916722 solver.cpp:218] Iteration 3464500 (16.8247 iter/s, 29.7182s/500 iters), loss = 0.181967
I0831 19:10:00.321671 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.181969 (* 1 = 0.181969 loss)
I0831 19:10:00.321681 916722 sgd_solver.cpp:106] Iteration 3464500, lr = 0.01
I0831 19:10:30.036149 916722 solver.cpp:218] Iteration 3465000 (16.8268 iter/s, 29.7144s/500 iters), loss = 0.149135
I0831 19:10:30.036211 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.149136 (* 1 = 0.149136 loss)
I0831 19:10:30.036219 916722 sgd_solver.cpp:106] Iteration 3465000, lr = 0.01
I0831 19:10:59.750644 916722 solver.cpp:218] Iteration 3465500 (16.8269 iter/s, 29.7144s/500 iters), loss = 0.0934366
I0831 19:10:59.750697 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0934386 (* 1 = 0.0934386 loss)
I0831 19:10:59.750706 916722 sgd_solver.cpp:106] Iteration 3465500, lr = 0.01
I0831 19:11:29.473084 916722 solver.cpp:218] Iteration 3466000 (16.8224 iter/s, 29.7223s/500 iters), loss = 0.0950618
I0831 19:11:29.473145 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0950639 (* 1 = 0.0950639 loss)
I0831 19:11:29.473152 916722 sgd_solver.cpp:106] Iteration 3466000, lr = 0.01
I0831 19:11:59.189416 916722 solver.cpp:218] Iteration 3466500 (16.8258 iter/s, 29.7162s/500 iters), loss = 0.209004
I0831 19:11:59.189469 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.209006 (* 1 = 0.209006 loss)
I0831 19:11:59.189477 916722 sgd_solver.cpp:106] Iteration 3466500, lr = 0.01
I0831 19:12:28.906381 916722 solver.cpp:218] Iteration 3467000 (16.8255 iter/s, 29.7169s/500 iters), loss = 0.111433
I0831 19:12:28.906453 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111435 (* 1 = 0.111435 loss)
I0831 19:12:28.906461 916722 sgd_solver.cpp:106] Iteration 3467000, lr = 0.01
I0831 19:12:58.622303 916722 solver.cpp:218] Iteration 3467500 (16.8261 iter/s, 29.7158s/500 iters), loss = 0.201049
I0831 19:12:58.622350 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.201051 (* 1 = 0.201051 loss)
I0831 19:12:58.622359 916722 sgd_solver.cpp:106] Iteration 3467500, lr = 0.01
I0831 19:13:28.339315 916722 solver.cpp:218] Iteration 3468000 (16.8254 iter/s, 29.7169s/500 iters), loss = 0.0417381
I0831 19:13:28.339376 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0417401 (* 1 = 0.0417401 loss)
I0831 19:13:28.339385 916722 sgd_solver.cpp:106] Iteration 3468000, lr = 0.01
I0831 19:13:58.055826 916722 solver.cpp:218] Iteration 3468500 (16.8257 iter/s, 29.7164s/500 iters), loss = 0.253498
I0831 19:13:58.055879 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.2535 (* 1 = 0.2535 loss)
I0831 19:13:58.055888 916722 sgd_solver.cpp:106] Iteration 3468500, lr = 0.01
I0831 19:14:27.770691 916722 solver.cpp:218] Iteration 3469000 (16.8267 iter/s, 29.7148s/500 iters), loss = 0.141923
I0831 19:14:27.770751 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.141925 (* 1 = 0.141925 loss)
I0831 19:14:27.770759 916722 sgd_solver.cpp:106] Iteration 3469000, lr = 0.01
I0831 19:14:57.485749 916722 solver.cpp:218] Iteration 3469500 (16.8266 iter/s, 29.7149s/500 iters), loss = 0.213041
I0831 19:14:57.485802 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.213043 (* 1 = 0.213043 loss)
I0831 19:14:57.485811 916722 sgd_solver.cpp:106] Iteration 3469500, lr = 0.01
I0831 19:15:27.204282 916722 solver.cpp:218] Iteration 3470000 (16.8246 iter/s, 29.7184s/500 iters), loss = 0.146662
I0831 19:15:27.204339 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.146664 (* 1 = 0.146664 loss)
I0831 19:15:27.204349 916722 sgd_solver.cpp:106] Iteration 3470000, lr = 0.01
I0831 19:15:56.919749 916722 solver.cpp:218] Iteration 3470500 (16.8263 iter/s, 29.7153s/500 iters), loss = 0.0690649
I0831 19:15:56.919804 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0690671 (* 1 = 0.0690671 loss)
I0831 19:15:56.919814 916722 sgd_solver.cpp:106] Iteration 3470500, lr = 0.01
I0831 19:16:26.633378 916722 solver.cpp:218] Iteration 3471000 (16.8274 iter/s, 29.7135s/500 iters), loss = 0.17084
I0831 19:16:26.633431 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.170843 (* 1 = 0.170843 loss)
I0831 19:16:26.633440 916722 sgd_solver.cpp:106] Iteration 3471000, lr = 0.01
I0831 19:16:56.349666 916722 solver.cpp:218] Iteration 3471500 (16.8259 iter/s, 29.7162s/500 iters), loss = 0.0806995
I0831 19:16:56.349716 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0807017 (* 1 = 0.0807017 loss)
I0831 19:16:56.349725 916722 sgd_solver.cpp:106] Iteration 3471500, lr = 0.01
I0831 19:17:26.063566 916722 solver.cpp:218] Iteration 3472000 (16.8272 iter/s, 29.7138s/500 iters), loss = 0.137989
I0831 19:17:26.063627 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.137991 (* 1 = 0.137991 loss)
I0831 19:17:26.063637 916722 sgd_solver.cpp:106] Iteration 3472000, lr = 0.01
I0831 19:17:55.780776 916722 solver.cpp:218] Iteration 3472500 (16.8253 iter/s, 29.7171s/500 iters), loss = 0.0835306
I0831 19:17:55.780829 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.083533 (* 1 = 0.083533 loss)
I0831 19:17:55.780838 916722 sgd_solver.cpp:106] Iteration 3472500, lr = 0.01
I0831 19:18:25.496774 916722 solver.cpp:218] Iteration 3473000 (16.826 iter/s, 29.7159s/500 iters), loss = 0.219486
I0831 19:18:25.496835 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.219489 (* 1 = 0.219489 loss)
I0831 19:18:25.496845 916722 sgd_solver.cpp:106] Iteration 3473000, lr = 0.01
I0831 19:18:55.211143 916722 solver.cpp:218] Iteration 3473500 (16.8269 iter/s, 29.7142s/500 iters), loss = 0.127599
I0831 19:18:55.211196 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.127601 (* 1 = 0.127601 loss)
I0831 19:18:55.211215 916722 sgd_solver.cpp:106] Iteration 3473500, lr = 0.01
I0831 19:19:24.927019 916722 solver.cpp:218] Iteration 3474000 (16.8261 iter/s, 29.7158s/500 iters), loss = 0.0438289
I0831 19:19:24.927090 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0438311 (* 1 = 0.0438311 loss)
I0831 19:19:24.927098 916722 sgd_solver.cpp:106] Iteration 3474000, lr = 0.01
I0831 19:19:54.646827 916722 solver.cpp:218] Iteration 3474500 (16.8239 iter/s, 29.7197s/500 iters), loss = 0.0692744
I0831 19:19:54.646883 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0692766 (* 1 = 0.0692766 loss)
I0831 19:19:54.646893 916722 sgd_solver.cpp:106] Iteration 3474500, lr = 0.01
I0831 19:20:24.364030 916722 solver.cpp:218] Iteration 3475000 (16.8253 iter/s, 29.7171s/500 iters), loss = 0.202883
I0831 19:20:24.364094 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.202885 (* 1 = 0.202885 loss)
I0831 19:20:24.364102 916722 sgd_solver.cpp:106] Iteration 3475000, lr = 0.01
I0831 19:20:54.077495 916722 solver.cpp:218] Iteration 3475500 (16.8275 iter/s, 29.7133s/500 iters), loss = 0.223836
I0831 19:20:54.077548 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.223838 (* 1 = 0.223838 loss)
I0831 19:20:54.077558 916722 sgd_solver.cpp:106] Iteration 3475500, lr = 0.01
I0831 19:21:23.792269 916722 solver.cpp:218] Iteration 3476000 (16.8267 iter/s, 29.7147s/500 iters), loss = 0.131127
I0831 19:21:23.792325 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131129 (* 1 = 0.131129 loss)
I0831 19:21:23.792333 916722 sgd_solver.cpp:106] Iteration 3476000, lr = 0.01
I0831 19:21:53.511425 916722 solver.cpp:218] Iteration 3476500 (16.8242 iter/s, 29.719s/500 iters), loss = 0.286923
I0831 19:21:53.511478 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.286926 (* 1 = 0.286926 loss)
I0831 19:21:53.511488 916722 sgd_solver.cpp:106] Iteration 3476500, lr = 0.01
I0831 19:22:23.230741 916722 solver.cpp:218] Iteration 3477000 (16.8241 iter/s, 29.7192s/500 iters), loss = 0.062009
I0831 19:22:23.230800 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0620115 (* 1 = 0.0620115 loss)
I0831 19:22:23.230808 916722 sgd_solver.cpp:106] Iteration 3477000, lr = 0.01
I0831 19:22:52.947670 916722 solver.cpp:218] Iteration 3477500 (16.8255 iter/s, 29.7168s/500 iters), loss = 0.0507154
I0831 19:22:52.947726 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0507179 (* 1 = 0.0507179 loss)
I0831 19:22:52.947736 916722 sgd_solver.cpp:106] Iteration 3477500, lr = 0.01
I0831 19:23:22.663034 916722 solver.cpp:218] Iteration 3478000 (16.8264 iter/s, 29.7152s/500 iters), loss = 0.0367253
I0831 19:23:22.663094 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0367278 (* 1 = 0.0367278 loss)
I0831 19:23:22.663101 916722 sgd_solver.cpp:106] Iteration 3478000, lr = 0.01
I0831 19:23:52.379374 916722 solver.cpp:218] Iteration 3478500 (16.8258 iter/s, 29.7162s/500 iters), loss = 0.0746508
I0831 19:23:52.379426 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0746531 (* 1 = 0.0746531 loss)
I0831 19:23:52.379436 916722 sgd_solver.cpp:106] Iteration 3478500, lr = 0.01
I0831 19:24:22.092236 916722 solver.cpp:218] Iteration 3479000 (16.8278 iter/s, 29.7127s/500 iters), loss = 0.256028
I0831 19:24:22.092293 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.256031 (* 1 = 0.256031 loss)
I0831 19:24:22.092301 916722 sgd_solver.cpp:106] Iteration 3479000, lr = 0.01
I0831 19:24:51.805900 916722 solver.cpp:218] Iteration 3479500 (16.8273 iter/s, 29.7135s/500 iters), loss = 0.0792955
I0831 19:24:51.805953 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0792977 (* 1 = 0.0792977 loss)
I0831 19:24:51.805963 916722 sgd_solver.cpp:106] Iteration 3479500, lr = 0.01
I0831 19:25:21.520792 916722 solver.cpp:218] Iteration 3480000 (16.8266 iter/s, 29.7148s/500 iters), loss = 0.182992
I0831 19:25:21.520862 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.182994 (* 1 = 0.182994 loss)
I0831 19:25:21.520875 916722 sgd_solver.cpp:106] Iteration 3480000, lr = 0.01
I0831 19:25:51.239306 916722 solver.cpp:218] Iteration 3480500 (16.8246 iter/s, 29.7184s/500 iters), loss = 0.0901291
I0831 19:25:51.239360 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.090131 (* 1 = 0.090131 loss)
I0831 19:25:51.239368 916722 sgd_solver.cpp:106] Iteration 3480500, lr = 0.01
I0831 19:26:20.953228 916722 solver.cpp:218] Iteration 3481000 (16.8272 iter/s, 29.7138s/500 iters), loss = 0.122415
I0831 19:26:20.953290 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.122417 (* 1 = 0.122417 loss)
I0831 19:26:20.953298 916722 sgd_solver.cpp:106] Iteration 3481000, lr = 0.01
I0831 19:26:50.671432 916722 solver.cpp:218] Iteration 3481500 (16.8248 iter/s, 29.7181s/500 iters), loss = 0.222235
I0831 19:26:50.671484 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.222236 (* 1 = 0.222236 loss)
I0831 19:26:50.671492 916722 sgd_solver.cpp:106] Iteration 3481500, lr = 0.01
I0831 19:27:20.389580 916722 solver.cpp:218] Iteration 3482000 (16.8248 iter/s, 29.718s/500 iters), loss = 0.170918
I0831 19:27:20.389639 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.17092 (* 1 = 0.17092 loss)
I0831 19:27:20.389648 916722 sgd_solver.cpp:106] Iteration 3482000, lr = 0.01
I0831 19:27:50.109160 916722 solver.cpp:218] Iteration 3482500 (16.824 iter/s, 29.7195s/500 iters), loss = 0.0678904
I0831 19:27:50.109215 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0678919 (* 1 = 0.0678919 loss)
I0831 19:27:50.109222 916722 sgd_solver.cpp:106] Iteration 3482500, lr = 0.01
I0831 19:28:19.823611 916722 solver.cpp:218] Iteration 3483000 (16.8269 iter/s, 29.7143s/500 iters), loss = 0.0514336
I0831 19:28:19.823671 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0514352 (* 1 = 0.0514352 loss)
I0831 19:28:19.823679 916722 sgd_solver.cpp:106] Iteration 3483000, lr = 0.01
I0831 19:28:49.538254 916722 solver.cpp:218] Iteration 3483500 (16.8268 iter/s, 29.7145s/500 iters), loss = 0.0786415
I0831 19:28:49.538306 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0786432 (* 1 = 0.0786432 loss)
I0831 19:28:49.538314 916722 sgd_solver.cpp:106] Iteration 3483500, lr = 0.01
I0831 19:29:19.254506 916722 solver.cpp:218] Iteration 3484000 (16.8259 iter/s, 29.7161s/500 iters), loss = 0.0943635
I0831 19:29:19.254565 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0943652 (* 1 = 0.0943652 loss)
I0831 19:29:19.254573 916722 sgd_solver.cpp:106] Iteration 3484000, lr = 0.01
I0831 19:29:48.968293 916722 solver.cpp:218] Iteration 3484500 (16.8273 iter/s, 29.7137s/500 iters), loss = 0.118968
I0831 19:29:48.968343 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.11897 (* 1 = 0.11897 loss)
I0831 19:29:48.968350 916722 sgd_solver.cpp:106] Iteration 3484500, lr = 0.01
I0831 19:30:18.683147 916722 solver.cpp:218] Iteration 3485000 (16.8267 iter/s, 29.7147s/500 iters), loss = 0.190645
I0831 19:30:18.683204 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.190647 (* 1 = 0.190647 loss)
I0831 19:30:18.683212 916722 sgd_solver.cpp:106] Iteration 3485000, lr = 0.01
I0831 19:30:48.401458 916722 solver.cpp:218] Iteration 3485500 (16.8247 iter/s, 29.7182s/500 iters), loss = 0.204455
I0831 19:30:48.401510 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.204457 (* 1 = 0.204457 loss)
I0831 19:30:48.401517 916722 sgd_solver.cpp:106] Iteration 3485500, lr = 0.01
I0831 19:31:18.121913 916722 solver.cpp:218] Iteration 3486000 (16.8235 iter/s, 29.7203s/500 iters), loss = 0.122207
I0831 19:31:18.121975 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.122209 (* 1 = 0.122209 loss)
I0831 19:31:18.121984 916722 sgd_solver.cpp:106] Iteration 3486000, lr = 0.01
I0831 19:31:47.837121 916722 solver.cpp:218] Iteration 3486500 (16.8265 iter/s, 29.7151s/500 iters), loss = 0.261843
I0831 19:31:47.837174 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.261845 (* 1 = 0.261845 loss)
I0831 19:31:47.837194 916722 sgd_solver.cpp:106] Iteration 3486500, lr = 0.01
I0831 19:32:17.553889 916722 solver.cpp:218] Iteration 3487000 (16.8256 iter/s, 29.7167s/500 iters), loss = 0.00736076
I0831 19:32:17.553963 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.00736251 (* 1 = 0.00736251 loss)
I0831 19:32:17.553983 916722 sgd_solver.cpp:106] Iteration 3487000, lr = 0.01
I0831 19:32:47.271811 916722 solver.cpp:218] Iteration 3487500 (16.8249 iter/s, 29.7178s/500 iters), loss = 0.205342
I0831 19:32:47.271863 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.205344 (* 1 = 0.205344 loss)
I0831 19:32:47.271872 916722 sgd_solver.cpp:106] Iteration 3487500, lr = 0.01
I0831 19:33:16.990722 916722 solver.cpp:218] Iteration 3488000 (16.8244 iter/s, 29.7188s/500 iters), loss = 0.384399
I0831 19:33:16.990782 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.384401 (* 1 = 0.384401 loss)
I0831 19:33:16.990789 916722 sgd_solver.cpp:106] Iteration 3488000, lr = 0.01
I0831 19:33:46.706254 916722 solver.cpp:218] Iteration 3488500 (16.8263 iter/s, 29.7154s/500 iters), loss = 0.197676
I0831 19:33:46.706306 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.197678 (* 1 = 0.197678 loss)
I0831 19:33:46.706315 916722 sgd_solver.cpp:106] Iteration 3488500, lr = 0.01
I0831 19:34:16.423736 916722 solver.cpp:218] Iteration 3489000 (16.8252 iter/s, 29.7174s/500 iters), loss = 0.0422267
I0831 19:34:16.423791 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0422285 (* 1 = 0.0422285 loss)
I0831 19:34:16.423799 916722 sgd_solver.cpp:106] Iteration 3489000, lr = 0.01
I0831 19:34:46.141567 916722 solver.cpp:218] Iteration 3489500 (16.825 iter/s, 29.7177s/500 iters), loss = 0.154238
I0831 19:34:46.141619 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.15424 (* 1 = 0.15424 loss)
I0831 19:34:46.141628 916722 sgd_solver.cpp:106] Iteration 3489500, lr = 0.01
I0831 19:35:15.856299 916722 solver.cpp:218] Iteration 3490000 (16.8267 iter/s, 29.7146s/500 iters), loss = 0.269075
I0831 19:35:15.856359 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.269077 (* 1 = 0.269077 loss)
I0831 19:35:15.856369 916722 sgd_solver.cpp:106] Iteration 3490000, lr = 0.01
I0831 19:35:45.582427 916722 solver.cpp:218] Iteration 3490500 (16.8203 iter/s, 29.726s/500 iters), loss = 0.217881
I0831 19:35:45.582482 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.217883 (* 1 = 0.217883 loss)
I0831 19:35:45.582492 916722 sgd_solver.cpp:106] Iteration 3490500, lr = 0.01
I0831 19:36:15.300071 916722 solver.cpp:218] Iteration 3491000 (16.8251 iter/s, 29.7175s/500 iters), loss = 0.103377
I0831 19:36:15.300129 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.103379 (* 1 = 0.103379 loss)
I0831 19:36:15.300137 916722 sgd_solver.cpp:106] Iteration 3491000, lr = 0.01
I0831 19:36:45.017593 916722 solver.cpp:218] Iteration 3491500 (16.8252 iter/s, 29.7174s/500 iters), loss = 0.186438
I0831 19:36:45.017645 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.18644 (* 1 = 0.18644 loss)
I0831 19:36:45.017655 916722 sgd_solver.cpp:106] Iteration 3491500, lr = 0.01
I0831 19:37:14.733680 916722 solver.cpp:218] Iteration 3492000 (16.826 iter/s, 29.716s/500 iters), loss = 0.0162929
I0831 19:37:14.733741 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0162951 (* 1 = 0.0162951 loss)
I0831 19:37:14.733748 916722 sgd_solver.cpp:106] Iteration 3492000, lr = 0.01
I0831 19:37:44.447422 916722 solver.cpp:218] Iteration 3492500 (16.8273 iter/s, 29.7136s/500 iters), loss = 0.17074
I0831 19:37:44.447474 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.170742 (* 1 = 0.170742 loss)
I0831 19:37:44.447484 916722 sgd_solver.cpp:106] Iteration 3492500, lr = 0.01
I0831 19:38:14.163409 916722 solver.cpp:218] Iteration 3493000 (16.826 iter/s, 29.7159s/500 iters), loss = 0.12933
I0831 19:38:14.163467 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.129332 (* 1 = 0.129332 loss)
I0831 19:38:14.163475 916722 sgd_solver.cpp:106] Iteration 3493000, lr = 0.01
I0831 19:38:43.879441 916722 solver.cpp:218] Iteration 3493500 (16.826 iter/s, 29.7159s/500 iters), loss = 0.222746
I0831 19:38:43.879495 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.222748 (* 1 = 0.222748 loss)
I0831 19:38:43.879504 916722 sgd_solver.cpp:106] Iteration 3493500, lr = 0.01
I0831 19:39:13.598121 916722 solver.cpp:218] Iteration 3494000 (16.8245 iter/s, 29.7186s/500 iters), loss = 0.108841
I0831 19:39:13.598191 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.108843 (* 1 = 0.108843 loss)
I0831 19:39:13.598201 916722 sgd_solver.cpp:106] Iteration 3494000, lr = 0.01
I0831 19:39:43.313683 916722 solver.cpp:218] Iteration 3494500 (16.8263 iter/s, 29.7154s/500 iters), loss = 0.165506
I0831 19:39:43.313736 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.165508 (* 1 = 0.165508 loss)
I0831 19:39:43.313746 916722 sgd_solver.cpp:106] Iteration 3494500, lr = 0.01
I0831 19:40:13.030964 916722 solver.cpp:218] Iteration 3495000 (16.8253 iter/s, 29.7172s/500 iters), loss = 0.350405
I0831 19:40:13.031023 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.350407 (* 1 = 0.350407 loss)
I0831 19:40:13.031030 916722 sgd_solver.cpp:106] Iteration 3495000, lr = 0.01
I0831 19:40:42.747534 916722 solver.cpp:218] Iteration 3495500 (16.8257 iter/s, 29.7165s/500 iters), loss = 0.063532
I0831 19:40:42.747587 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0635341 (* 1 = 0.0635341 loss)
I0831 19:40:42.747597 916722 sgd_solver.cpp:106] Iteration 3495500, lr = 0.01
I0831 19:41:12.464923 916722 solver.cpp:218] Iteration 3496000 (16.8252 iter/s, 29.7173s/500 iters), loss = 0.0448564
I0831 19:41:12.464983 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0448583 (* 1 = 0.0448583 loss)
I0831 19:41:12.464991 916722 sgd_solver.cpp:106] Iteration 3496000, lr = 0.01
I0831 19:41:42.181757 916722 solver.cpp:218] Iteration 3496500 (16.8255 iter/s, 29.7167s/500 iters), loss = 0.0166404
I0831 19:41:42.181810 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0166422 (* 1 = 0.0166422 loss)
I0831 19:41:42.181820 916722 sgd_solver.cpp:106] Iteration 3496500, lr = 0.01
I0831 19:42:11.897540 916722 solver.cpp:218] Iteration 3497000 (16.8261 iter/s, 29.7157s/500 iters), loss = 0.0870257
I0831 19:42:11.897601 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0870275 (* 1 = 0.0870275 loss)
I0831 19:42:11.897609 916722 sgd_solver.cpp:106] Iteration 3497000, lr = 0.01
I0831 19:42:41.617192 916722 solver.cpp:218] Iteration 3497500 (16.824 iter/s, 29.7195s/500 iters), loss = 0.258406
I0831 19:42:41.617245 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.258408 (* 1 = 0.258408 loss)
I0831 19:42:41.617256 916722 sgd_solver.cpp:106] Iteration 3497500, lr = 0.01
I0831 19:43:11.333755 916722 solver.cpp:218] Iteration 3498000 (16.8257 iter/s, 29.7164s/500 iters), loss = 0.201148
I0831 19:43:11.333813 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.20115 (* 1 = 0.20115 loss)
I0831 19:43:11.333822 916722 sgd_solver.cpp:106] Iteration 3498000, lr = 0.01
I0831 19:43:41.051836 916722 solver.cpp:218] Iteration 3498500 (16.8248 iter/s, 29.718s/500 iters), loss = 0.0835181
I0831 19:43:41.051889 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0835204 (* 1 = 0.0835204 loss)
I0831 19:43:41.051899 916722 sgd_solver.cpp:106] Iteration 3498500, lr = 0.01
I0831 19:44:10.767858 916722 solver.cpp:218] Iteration 3499000 (16.826 iter/s, 29.7159s/500 iters), loss = 0.263937
I0831 19:44:10.767915 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.263939 (* 1 = 0.263939 loss)
I0831 19:44:10.767922 916722 sgd_solver.cpp:106] Iteration 3499000, lr = 0.01
I0831 19:44:40.482156 916722 solver.cpp:218] Iteration 3499500 (16.8274 iter/s, 29.7134s/500 iters), loss = 0.227075
I0831 19:44:40.482209 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.227077 (* 1 = 0.227077 loss)
I0831 19:44:40.482218 916722 sgd_solver.cpp:106] Iteration 3499500, lr = 0.01
I0831 19:45:10.137733 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_3500000.caffemodel
I0831 19:45:10.156769 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_3500000.solverstate
I0831 19:45:10.162779 916722 solver.cpp:330] Iteration 3500000, Testing net (#0)
I0831 19:45:25.506651 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8933
I0831 19:45:25.506703 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.364196 (* 1 = 0.364196 loss)
I0831 19:45:25.565146 916722 solver.cpp:218] Iteration 3500000 (11.091 iter/s, 45.0818s/500 iters), loss = 0.371638
I0831 19:45:25.565173 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.371641 (* 1 = 0.371641 loss)
I0831 19:45:25.565181 916722 sgd_solver.cpp:106] Iteration 3500000, lr = 0.01
I0831 19:45:55.236698 916722 solver.cpp:218] Iteration 3500500 (16.8516 iter/s, 29.6708s/500 iters), loss = 0.148311
I0831 19:45:55.236769 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.148314 (* 1 = 0.148314 loss)
I0831 19:45:55.236778 916722 sgd_solver.cpp:106] Iteration 3500500, lr = 0.01
I0831 19:46:24.949682 916722 solver.cpp:218] Iteration 3501000 (16.8281 iter/s, 29.7122s/500 iters), loss = 0.0565223
I0831 19:46:24.949733 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0565245 (* 1 = 0.0565245 loss)
I0831 19:46:24.949743 916722 sgd_solver.cpp:106] Iteration 3501000, lr = 0.01
I0831 19:46:54.668573 916722 solver.cpp:218] Iteration 3501500 (16.8247 iter/s, 29.7182s/500 iters), loss = 0.13313
I0831 19:46:54.668635 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133132 (* 1 = 0.133132 loss)
I0831 19:46:54.668644 916722 sgd_solver.cpp:106] Iteration 3501500, lr = 0.01
I0831 19:47:24.386355 916722 solver.cpp:218] Iteration 3502000 (16.8253 iter/s, 29.7171s/500 iters), loss = 0.216961
I0831 19:47:24.386409 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.216963 (* 1 = 0.216963 loss)
I0831 19:47:24.386418 916722 sgd_solver.cpp:106] Iteration 3502000, lr = 0.01
I0831 19:47:54.106968 916722 solver.cpp:218] Iteration 3502500 (16.8237 iter/s, 29.7199s/500 iters), loss = 0.0545621
I0831 19:47:54.107028 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0545642 (* 1 = 0.0545642 loss)
I0831 19:47:54.107036 916722 sgd_solver.cpp:106] Iteration 3502500, lr = 0.01
I0831 19:48:23.830440 916722 solver.cpp:218] Iteration 3503000 (16.8221 iter/s, 29.7228s/500 iters), loss = 0.140189
I0831 19:48:23.830494 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.140191 (* 1 = 0.140191 loss)
I0831 19:48:23.830504 916722 sgd_solver.cpp:106] Iteration 3503000, lr = 0.01
I0831 19:48:53.548271 916722 solver.cpp:218] Iteration 3503500 (16.8253 iter/s, 29.7172s/500 iters), loss = 0.132183
I0831 19:48:53.548331 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.132185 (* 1 = 0.132185 loss)
I0831 19:48:53.548339 916722 sgd_solver.cpp:106] Iteration 3503500, lr = 0.01
I0831 19:49:23.267215 916722 solver.cpp:218] Iteration 3504000 (16.8246 iter/s, 29.7183s/500 iters), loss = 0.117021
I0831 19:49:23.267269 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.117023 (* 1 = 0.117023 loss)
I0831 19:49:23.267279 916722 sgd_solver.cpp:106] Iteration 3504000, lr = 0.01
I0831 19:49:52.989332 916722 solver.cpp:218] Iteration 3504500 (16.8228 iter/s, 29.7215s/500 iters), loss = 0.143387
I0831 19:49:52.989394 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.143389 (* 1 = 0.143389 loss)
I0831 19:49:52.989403 916722 sgd_solver.cpp:106] Iteration 3504500, lr = 0.01
I0831 19:50:22.708070 916722 solver.cpp:218] Iteration 3505000 (16.8247 iter/s, 29.7182s/500 iters), loss = 0.340714
I0831 19:50:22.708120 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.340716 (* 1 = 0.340716 loss)
I0831 19:50:22.708128 916722 sgd_solver.cpp:106] Iteration 3505000, lr = 0.01
I0831 19:50:52.425525 916722 solver.cpp:218] Iteration 3505500 (16.8254 iter/s, 29.7169s/500 iters), loss = 0.225269
I0831 19:50:52.425597 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.225271 (* 1 = 0.225271 loss)
I0831 19:50:52.425606 916722 sgd_solver.cpp:106] Iteration 3505500, lr = 0.01
I0831 19:51:22.155769 916722 solver.cpp:218] Iteration 3506000 (16.8182 iter/s, 29.7297s/500 iters), loss = 0.26073
I0831 19:51:22.155817 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.260732 (* 1 = 0.260732 loss)
I0831 19:51:22.155824 916722 sgd_solver.cpp:106] Iteration 3506000, lr = 0.01
I0831 19:51:51.896189 916722 solver.cpp:218] Iteration 3506500 (16.8124 iter/s, 29.7399s/500 iters), loss = 0.107184
I0831 19:51:51.896245 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.107186 (* 1 = 0.107186 loss)
I0831 19:51:51.896255 916722 sgd_solver.cpp:106] Iteration 3506500, lr = 0.01
I0831 19:52:21.629842 916722 solver.cpp:218] Iteration 3507000 (16.8162 iter/s, 29.7332s/500 iters), loss = 0.12466
I0831 19:52:21.629889 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.124662 (* 1 = 0.124662 loss)
I0831 19:52:21.629899 916722 sgd_solver.cpp:106] Iteration 3507000, lr = 0.01
I0831 19:52:51.368885 916722 solver.cpp:218] Iteration 3507500 (16.8132 iter/s, 29.7386s/500 iters), loss = 0.0494618
I0831 19:52:51.368938 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0494639 (* 1 = 0.0494639 loss)
I0831 19:52:51.368947 916722 sgd_solver.cpp:106] Iteration 3507500, lr = 0.01
I0831 19:53:21.144332 916722 solver.cpp:218] Iteration 3508000 (16.7926 iter/s, 29.775s/500 iters), loss = 0.0464826
I0831 19:53:21.144382 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0464849 (* 1 = 0.0464849 loss)
I0831 19:53:21.144392 916722 sgd_solver.cpp:106] Iteration 3508000, lr = 0.01
I0831 19:53:50.927762 916722 solver.cpp:218] Iteration 3508500 (16.7881 iter/s, 29.783s/500 iters), loss = 0.0970258
I0831 19:53:50.927820 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0970281 (* 1 = 0.0970281 loss)
I0831 19:53:50.927829 916722 sgd_solver.cpp:106] Iteration 3508500, lr = 0.01
I0831 19:54:20.700204 916722 solver.cpp:218] Iteration 3509000 (16.7943 iter/s, 29.772s/500 iters), loss = 0.0198865
I0831 19:54:20.700263 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0198887 (* 1 = 0.0198887 loss)
I0831 19:54:20.700274 916722 sgd_solver.cpp:106] Iteration 3509000, lr = 0.01
I0831 19:54:50.462177 916722 solver.cpp:218] Iteration 3509500 (16.8002 iter/s, 29.7615s/500 iters), loss = 0.108389
I0831 19:54:50.462240 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.108391 (* 1 = 0.108391 loss)
I0831 19:54:50.462249 916722 sgd_solver.cpp:106] Iteration 3509500, lr = 0.01
I0831 19:55:20.232128 916722 solver.cpp:218] Iteration 3510000 (16.7957 iter/s, 29.7695s/500 iters), loss = 0.221567
I0831 19:55:20.232183 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.22157 (* 1 = 0.22157 loss)
I0831 19:55:20.232193 916722 sgd_solver.cpp:106] Iteration 3510000, lr = 0.01
I0831 19:55:49.994303 916722 solver.cpp:218] Iteration 3510500 (16.8001 iter/s, 29.7618s/500 iters), loss = 0.0918487
I0831 19:55:49.994365 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0918512 (* 1 = 0.0918512 loss)
I0831 19:55:49.994374 916722 sgd_solver.cpp:106] Iteration 3510500, lr = 0.01
I0831 19:56:19.761366 916722 solver.cpp:218] Iteration 3511000 (16.7973 iter/s, 29.7667s/500 iters), loss = 0.135872
I0831 19:56:19.761420 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.135874 (* 1 = 0.135874 loss)
I0831 19:56:19.761430 916722 sgd_solver.cpp:106] Iteration 3511000, lr = 0.01
I0831 19:56:49.525149 916722 solver.cpp:218] Iteration 3511500 (16.7992 iter/s, 29.7634s/500 iters), loss = 0.0161512
I0831 19:56:49.525209 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0161536 (* 1 = 0.0161536 loss)
I0831 19:56:49.525218 916722 sgd_solver.cpp:106] Iteration 3511500, lr = 0.01
I0831 19:57:19.294714 916722 solver.cpp:218] Iteration 3512000 (16.7959 iter/s, 29.7692s/500 iters), loss = 0.0501076
I0831 19:57:19.294767 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0501099 (* 1 = 0.0501099 loss)
I0831 19:57:19.294790 916722 sgd_solver.cpp:106] Iteration 3512000, lr = 0.01
I0831 19:57:49.062882 916722 solver.cpp:218] Iteration 3512500 (16.7967 iter/s, 29.7678s/500 iters), loss = 0.06538
I0831 19:57:49.062949 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0653823 (* 1 = 0.0653823 loss)
I0831 19:57:49.062958 916722 sgd_solver.cpp:106] Iteration 3512500, lr = 0.01
I0831 19:58:18.838742 916722 solver.cpp:218] Iteration 3513000 (16.7923 iter/s, 29.7755s/500 iters), loss = 0.0935659
I0831 19:58:18.838799 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0935683 (* 1 = 0.0935683 loss)
I0831 19:58:18.838810 916722 sgd_solver.cpp:106] Iteration 3513000, lr = 0.01
I0831 19:58:48.599035 916722 solver.cpp:218] Iteration 3513500 (16.8011 iter/s, 29.7599s/500 iters), loss = 0.14415
I0831 19:58:48.599098 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.144153 (* 1 = 0.144153 loss)
I0831 19:58:48.599107 916722 sgd_solver.cpp:106] Iteration 3513500, lr = 0.01
I0831 19:59:18.364058 916722 solver.cpp:218] Iteration 3514000 (16.7984 iter/s, 29.7647s/500 iters), loss = 0.104366
I0831 19:59:18.364112 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104368 (* 1 = 0.104368 loss)
I0831 19:59:18.364122 916722 sgd_solver.cpp:106] Iteration 3514000, lr = 0.01
I0831 19:59:48.124214 916722 solver.cpp:218] Iteration 3514500 (16.8012 iter/s, 29.7598s/500 iters), loss = 0.174546
I0831 19:59:48.124279 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.174548 (* 1 = 0.174548 loss)
I0831 19:59:48.124287 916722 sgd_solver.cpp:106] Iteration 3514500, lr = 0.01
I0831 20:00:17.887373 916722 solver.cpp:218] Iteration 3515000 (16.7995 iter/s, 29.7628s/500 iters), loss = 0.0660989
I0831 20:00:17.887428 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0661014 (* 1 = 0.0661014 loss)
I0831 20:00:17.887437 916722 sgd_solver.cpp:106] Iteration 3515000, lr = 0.01
I0831 20:00:47.645431 916722 solver.cpp:218] Iteration 3515500 (16.8024 iter/s, 29.7577s/500 iters), loss = 0.141368
I0831 20:00:47.645490 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.14137 (* 1 = 0.14137 loss)
I0831 20:00:47.645498 916722 sgd_solver.cpp:106] Iteration 3515500, lr = 0.01
I0831 20:01:17.403959 916722 solver.cpp:218] Iteration 3516000 (16.8021 iter/s, 29.7582s/500 iters), loss = 0.105398
I0831 20:01:17.404011 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105401 (* 1 = 0.105401 loss)
I0831 20:01:17.404019 916722 sgd_solver.cpp:106] Iteration 3516000, lr = 0.01
I0831 20:01:47.163606 916722 solver.cpp:218] Iteration 3516500 (16.8014 iter/s, 29.7593s/500 iters), loss = 0.0617315
I0831 20:01:47.163669 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0617344 (* 1 = 0.0617344 loss)
I0831 20:01:47.163677 916722 sgd_solver.cpp:106] Iteration 3516500, lr = 0.01
I0831 20:02:16.920883 916722 solver.cpp:218] Iteration 3517000 (16.8028 iter/s, 29.757s/500 iters), loss = 0.24782
I0831 20:02:16.920938 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.247823 (* 1 = 0.247823 loss)
I0831 20:02:16.920948 916722 sgd_solver.cpp:106] Iteration 3517000, lr = 0.01
I0831 20:02:46.682564 916722 solver.cpp:218] Iteration 3517500 (16.8003 iter/s, 29.7614s/500 iters), loss = 0.153578
I0831 20:02:46.682626 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.153581 (* 1 = 0.153581 loss)
I0831 20:02:46.682636 916722 sgd_solver.cpp:106] Iteration 3517500, lr = 0.01
I0831 20:03:16.443797 916722 solver.cpp:218] Iteration 3518000 (16.8006 iter/s, 29.7609s/500 iters), loss = 0.182187
I0831 20:03:16.443852 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.18219 (* 1 = 0.18219 loss)
I0831 20:03:16.443861 916722 sgd_solver.cpp:106] Iteration 3518000, lr = 0.01
I0831 20:03:46.204139 916722 solver.cpp:218] Iteration 3518500 (16.801 iter/s, 29.7601s/500 iters), loss = 0.252185
I0831 20:03:46.204213 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.252188 (* 1 = 0.252188 loss)
I0831 20:03:46.204227 916722 sgd_solver.cpp:106] Iteration 3518500, lr = 0.01
I0831 20:04:15.961890 916722 solver.cpp:218] Iteration 3519000 (16.8025 iter/s, 29.7574s/500 iters), loss = 0.135555
I0831 20:04:15.961942 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.135558 (* 1 = 0.135558 loss)
I0831 20:04:15.961951 916722 sgd_solver.cpp:106] Iteration 3519000, lr = 0.01
I0831 20:04:45.723476 916722 solver.cpp:218] Iteration 3519500 (16.8003 iter/s, 29.7613s/500 iters), loss = 0.256068
I0831 20:04:45.723537 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.256071 (* 1 = 0.256071 loss)
I0831 20:04:45.723546 916722 sgd_solver.cpp:106] Iteration 3519500, lr = 0.01
I0831 20:05:15.487587 916722 solver.cpp:218] Iteration 3520000 (16.7989 iter/s, 29.7638s/500 iters), loss = 0.17928
I0831 20:05:15.487638 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.179283 (* 1 = 0.179283 loss)
I0831 20:05:15.487648 916722 sgd_solver.cpp:106] Iteration 3520000, lr = 0.01
I0831 20:05:45.252620 916722 solver.cpp:218] Iteration 3520500 (16.7984 iter/s, 29.7648s/500 iters), loss = 0.248277
I0831 20:05:45.252682 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.248279 (* 1 = 0.248279 loss)
I0831 20:05:45.252691 916722 sgd_solver.cpp:106] Iteration 3520500, lr = 0.01
I0831 20:06:15.013134 916722 solver.cpp:218] Iteration 3521000 (16.8009 iter/s, 29.7602s/500 iters), loss = 0.081627
I0831 20:06:15.013190 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0816296 (* 1 = 0.0816296 loss)
I0831 20:06:15.013201 916722 sgd_solver.cpp:106] Iteration 3521000, lr = 0.01
I0831 20:06:44.773538 916722 solver.cpp:218] Iteration 3521500 (16.801 iter/s, 29.7601s/500 iters), loss = 0.190473
I0831 20:06:44.773599 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.190476 (* 1 = 0.190476 loss)
I0831 20:06:44.773607 916722 sgd_solver.cpp:106] Iteration 3521500, lr = 0.01
I0831 20:07:14.537403 916722 solver.cpp:218] Iteration 3522000 (16.799 iter/s, 29.7636s/500 iters), loss = 0.359189
I0831 20:07:14.537457 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.359192 (* 1 = 0.359192 loss)
I0831 20:07:14.537467 916722 sgd_solver.cpp:106] Iteration 3522000, lr = 0.01
I0831 20:07:44.301307 916722 solver.cpp:218] Iteration 3522500 (16.799 iter/s, 29.7636s/500 iters), loss = 0.207612
I0831 20:07:44.301367 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.207614 (* 1 = 0.207614 loss)
I0831 20:07:44.301376 916722 sgd_solver.cpp:106] Iteration 3522500, lr = 0.01
I0831 20:08:14.061781 916722 solver.cpp:218] Iteration 3523000 (16.801 iter/s, 29.7602s/500 iters), loss = 0.125438
I0831 20:08:14.061836 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.125441 (* 1 = 0.125441 loss)
I0831 20:08:14.061846 916722 sgd_solver.cpp:106] Iteration 3523000, lr = 0.01
I0831 20:08:43.825737 916722 solver.cpp:218] Iteration 3523500 (16.799 iter/s, 29.7637s/500 iters), loss = 0.0897844
I0831 20:08:43.825794 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0897868 (* 1 = 0.0897868 loss)
I0831 20:08:43.825803 916722 sgd_solver.cpp:106] Iteration 3523500, lr = 0.01
I0831 20:09:13.583876 916722 solver.cpp:218] Iteration 3524000 (16.8023 iter/s, 29.7579s/500 iters), loss = 0.0865087
I0831 20:09:13.583928 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0865112 (* 1 = 0.0865112 loss)
I0831 20:09:13.583938 916722 sgd_solver.cpp:106] Iteration 3524000, lr = 0.01
I0831 20:09:43.344281 916722 solver.cpp:218] Iteration 3524500 (16.801 iter/s, 29.7601s/500 iters), loss = 0.169163
I0831 20:09:43.344341 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.169165 (* 1 = 0.169165 loss)
I0831 20:09:43.344349 916722 sgd_solver.cpp:106] Iteration 3524500, lr = 0.01
I0831 20:10:13.099566 916722 solver.cpp:218] Iteration 3525000 (16.8039 iter/s, 29.755s/500 iters), loss = 0.210829
I0831 20:10:13.099619 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.210832 (* 1 = 0.210832 loss)
I0831 20:10:13.099629 916722 sgd_solver.cpp:106] Iteration 3525000, lr = 0.01
I0831 20:10:42.861109 916722 solver.cpp:218] Iteration 3525500 (16.8004 iter/s, 29.7613s/500 iters), loss = 0.190678
I0831 20:10:42.861181 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.19068 (* 1 = 0.19068 loss)
I0831 20:10:42.861189 916722 sgd_solver.cpp:106] Iteration 3525500, lr = 0.01
I0831 20:11:12.623661 916722 solver.cpp:218] Iteration 3526000 (16.7998 iter/s, 29.7623s/500 iters), loss = 0.134319
I0831 20:11:12.623715 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.134321 (* 1 = 0.134321 loss)
I0831 20:11:12.623725 916722 sgd_solver.cpp:106] Iteration 3526000, lr = 0.01
I0831 20:11:42.381455 916722 solver.cpp:218] Iteration 3526500 (16.8025 iter/s, 29.7575s/500 iters), loss = 0.0394507
I0831 20:11:42.381515 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0394531 (* 1 = 0.0394531 loss)
I0831 20:11:42.381523 916722 sgd_solver.cpp:106] Iteration 3526500, lr = 0.01
I0831 20:12:12.142494 916722 solver.cpp:218] Iteration 3527000 (16.8006 iter/s, 29.7608s/500 iters), loss = 0.110374
I0831 20:12:12.142545 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110376 (* 1 = 0.110376 loss)
I0831 20:12:12.142555 916722 sgd_solver.cpp:106] Iteration 3527000, lr = 0.01
I0831 20:12:41.904673 916722 solver.cpp:218] Iteration 3527500 (16.8 iter/s, 29.7619s/500 iters), loss = 0.0610295
I0831 20:12:41.904731 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.061032 (* 1 = 0.061032 loss)
I0831 20:12:41.904740 916722 sgd_solver.cpp:106] Iteration 3527500, lr = 0.01
I0831 20:13:11.665913 916722 solver.cpp:218] Iteration 3528000 (16.8005 iter/s, 29.761s/500 iters), loss = 0.0342313
I0831 20:13:11.665967 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0342338 (* 1 = 0.0342338 loss)
I0831 20:13:11.665977 916722 sgd_solver.cpp:106] Iteration 3528000, lr = 0.01
I0831 20:13:41.422435 916722 solver.cpp:218] Iteration 3528500 (16.8032 iter/s, 29.7563s/500 iters), loss = 0.0369734
I0831 20:13:41.422497 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0369761 (* 1 = 0.0369761 loss)
I0831 20:13:41.422504 916722 sgd_solver.cpp:106] Iteration 3528500, lr = 0.01
I0831 20:14:11.182941 916722 solver.cpp:218] Iteration 3529000 (16.8009 iter/s, 29.7603s/500 iters), loss = 0.0982763
I0831 20:14:11.183008 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0982789 (* 1 = 0.0982789 loss)
I0831 20:14:11.183019 916722 sgd_solver.cpp:106] Iteration 3529000, lr = 0.01
I0831 20:14:40.943658 916722 solver.cpp:218] Iteration 3529500 (16.8008 iter/s, 29.7605s/500 iters), loss = 0.099714
I0831 20:14:40.943720 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0997166 (* 1 = 0.0997166 loss)
I0831 20:14:40.943728 916722 sgd_solver.cpp:106] Iteration 3529500, lr = 0.01
I0831 20:15:10.707054 916722 solver.cpp:218] Iteration 3530000 (16.7993 iter/s, 29.7631s/500 iters), loss = 0.0871597
I0831 20:15:10.707109 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0871623 (* 1 = 0.0871623 loss)
I0831 20:15:10.707119 916722 sgd_solver.cpp:106] Iteration 3530000, lr = 0.01
I0831 20:15:40.469383 916722 solver.cpp:218] Iteration 3530500 (16.7999 iter/s, 29.7621s/500 iters), loss = 0.0988707
I0831 20:15:40.469444 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0988733 (* 1 = 0.0988733 loss)
I0831 20:15:40.469451 916722 sgd_solver.cpp:106] Iteration 3530500, lr = 0.01
I0831 20:16:10.224612 916722 solver.cpp:218] Iteration 3531000 (16.8039 iter/s, 29.755s/500 iters), loss = 0.241574
I0831 20:16:10.224664 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.241576 (* 1 = 0.241576 loss)
I0831 20:16:10.224675 916722 sgd_solver.cpp:106] Iteration 3531000, lr = 0.01
I0831 20:16:39.983119 916722 solver.cpp:218] Iteration 3531500 (16.8021 iter/s, 29.7583s/500 iters), loss = 0.394048
I0831 20:16:39.983182 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.39405 (* 1 = 0.39405 loss)
I0831 20:16:39.983191 916722 sgd_solver.cpp:106] Iteration 3531500, lr = 0.01
I0831 20:17:09.746824 916722 solver.cpp:218] Iteration 3532000 (16.7991 iter/s, 29.7635s/500 iters), loss = 0.0458386
I0831 20:17:09.746882 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0458411 (* 1 = 0.0458411 loss)
I0831 20:17:09.746891 916722 sgd_solver.cpp:106] Iteration 3532000, lr = 0.01
I0831 20:17:39.507795 916722 solver.cpp:218] Iteration 3532500 (16.8007 iter/s, 29.7607s/500 iters), loss = 0.0868237
I0831 20:17:39.507879 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0868261 (* 1 = 0.0868261 loss)
I0831 20:17:39.507891 916722 sgd_solver.cpp:106] Iteration 3532500, lr = 0.01
I0831 20:18:09.269403 916722 solver.cpp:218] Iteration 3533000 (16.8003 iter/s, 29.7613s/500 iters), loss = 0.136267
I0831 20:18:09.269457 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13627 (* 1 = 0.13627 loss)
I0831 20:18:09.269466 916722 sgd_solver.cpp:106] Iteration 3533000, lr = 0.01
I0831 20:18:39.038759 916722 solver.cpp:218] Iteration 3533500 (16.7958 iter/s, 29.7694s/500 iters), loss = 0.450351
I0831 20:18:39.038823 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.450353 (* 1 = 0.450353 loss)
I0831 20:18:39.038832 916722 sgd_solver.cpp:106] Iteration 3533500, lr = 0.01
I0831 20:19:08.807255 916722 solver.cpp:218] Iteration 3534000 (16.7962 iter/s, 29.7686s/500 iters), loss = 0.066437
I0831 20:19:08.807308 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0664392 (* 1 = 0.0664392 loss)
I0831 20:19:08.807317 916722 sgd_solver.cpp:106] Iteration 3534000, lr = 0.01
I0831 20:19:38.576974 916722 solver.cpp:218] Iteration 3534500 (16.7955 iter/s, 29.7698s/500 iters), loss = 0.0877568
I0831 20:19:38.577034 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.087759 (* 1 = 0.087759 loss)
I0831 20:19:38.577044 916722 sgd_solver.cpp:106] Iteration 3534500, lr = 0.01
I0831 20:20:08.346884 916722 solver.cpp:218] Iteration 3535000 (16.7954 iter/s, 29.77s/500 iters), loss = 0.0691378
I0831 20:20:08.346935 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.06914 (* 1 = 0.06914 loss)
I0831 20:20:08.346943 916722 sgd_solver.cpp:106] Iteration 3535000, lr = 0.01
I0831 20:20:38.120975 916722 solver.cpp:218] Iteration 3535500 (16.7931 iter/s, 29.7742s/500 iters), loss = 0.101377
I0831 20:20:38.121034 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101379 (* 1 = 0.101379 loss)
I0831 20:20:38.121042 916722 sgd_solver.cpp:106] Iteration 3535500, lr = 0.01
I0831 20:21:07.892002 916722 solver.cpp:218] Iteration 3536000 (16.7948 iter/s, 29.7711s/500 iters), loss = 0.139743
I0831 20:21:07.892055 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139746 (* 1 = 0.139746 loss)
I0831 20:21:07.892063 916722 sgd_solver.cpp:106] Iteration 3536000, lr = 0.01
I0831 20:21:37.667186 916722 solver.cpp:218] Iteration 3536500 (16.7925 iter/s, 29.7752s/500 iters), loss = 0.0504815
I0831 20:21:37.667245 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0504837 (* 1 = 0.0504837 loss)
I0831 20:21:37.667254 916722 sgd_solver.cpp:106] Iteration 3536500, lr = 0.01
I0831 20:22:07.428508 916722 solver.cpp:218] Iteration 3537000 (16.8003 iter/s, 29.7613s/500 iters), loss = 0.113264
I0831 20:22:07.428563 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.113267 (* 1 = 0.113267 loss)
I0831 20:22:07.428573 916722 sgd_solver.cpp:106] Iteration 3537000, lr = 0.01
I0831 20:22:37.197690 916722 solver.cpp:218] Iteration 3537500 (16.7959 iter/s, 29.7692s/500 iters), loss = 0.0622729
I0831 20:22:37.197751 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.062275 (* 1 = 0.062275 loss)
I0831 20:22:37.197759 916722 sgd_solver.cpp:106] Iteration 3537500, lr = 0.01
I0831 20:23:06.966078 916722 solver.cpp:218] Iteration 3538000 (16.7963 iter/s, 29.7684s/500 iters), loss = 0.0493257
I0831 20:23:06.966131 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0493278 (* 1 = 0.0493278 loss)
I0831 20:23:06.966141 916722 sgd_solver.cpp:106] Iteration 3538000, lr = 0.01
I0831 20:23:36.734514 916722 solver.cpp:218] Iteration 3538500 (16.7963 iter/s, 29.7684s/500 iters), loss = 0.28282
I0831 20:23:36.734591 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.282822 (* 1 = 0.282822 loss)
I0831 20:23:36.734601 916722 sgd_solver.cpp:106] Iteration 3538500, lr = 0.01
I0831 20:24:06.499459 916722 solver.cpp:218] Iteration 3539000 (16.7983 iter/s, 29.7649s/500 iters), loss = 0.303423
I0831 20:24:06.499511 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.303425 (* 1 = 0.303425 loss)
I0831 20:24:06.499522 916722 sgd_solver.cpp:106] Iteration 3539000, lr = 0.01
I0831 20:24:36.257254 916722 solver.cpp:218] Iteration 3539500 (16.8023 iter/s, 29.7578s/500 iters), loss = 0.127314
I0831 20:24:36.257313 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.127316 (* 1 = 0.127316 loss)
I0831 20:24:36.257321 916722 sgd_solver.cpp:106] Iteration 3539500, lr = 0.01
I0831 20:25:06.026613 916722 solver.cpp:218] Iteration 3540000 (16.7958 iter/s, 29.7693s/500 iters), loss = 0.287844
I0831 20:25:06.026667 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.287846 (* 1 = 0.287846 loss)
I0831 20:25:06.026677 916722 sgd_solver.cpp:106] Iteration 3540000, lr = 0.01
I0831 20:25:35.803081 916722 solver.cpp:218] Iteration 3540500 (16.7918 iter/s, 29.7764s/500 iters), loss = 0.063269
I0831 20:25:35.803141 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0632711 (* 1 = 0.0632711 loss)
I0831 20:25:35.803149 916722 sgd_solver.cpp:106] Iteration 3540500, lr = 0.01
I0831 20:26:05.567361 916722 solver.cpp:218] Iteration 3541000 (16.7987 iter/s, 29.7642s/500 iters), loss = 0.280178
I0831 20:26:05.567415 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.28018 (* 1 = 0.28018 loss)
I0831 20:26:05.567425 916722 sgd_solver.cpp:106] Iteration 3541000, lr = 0.01
I0831 20:26:35.337631 916722 solver.cpp:218] Iteration 3541500 (16.7953 iter/s, 29.7702s/500 iters), loss = 0.168427
I0831 20:26:35.337690 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.16843 (* 1 = 0.16843 loss)
I0831 20:26:35.337699 916722 sgd_solver.cpp:106] Iteration 3541500, lr = 0.01
I0831 20:27:05.110069 916722 solver.cpp:218] Iteration 3542000 (16.7941 iter/s, 29.7724s/500 iters), loss = 0.0391482
I0831 20:27:05.110121 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0391504 (* 1 = 0.0391504 loss)
I0831 20:27:05.110131 916722 sgd_solver.cpp:106] Iteration 3542000, lr = 0.01
I0831 20:27:34.877422 916722 solver.cpp:218] Iteration 3542500 (16.797 iter/s, 29.7673s/500 iters), loss = 0.156443
I0831 20:27:34.877480 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.156445 (* 1 = 0.156445 loss)
I0831 20:27:34.877488 916722 sgd_solver.cpp:106] Iteration 3542500, lr = 0.01
I0831 20:28:04.644172 916722 solver.cpp:218] Iteration 3543000 (16.7973 iter/s, 29.7667s/500 iters), loss = 0.161829
I0831 20:28:04.644225 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.161831 (* 1 = 0.161831 loss)
I0831 20:28:04.644235 916722 sgd_solver.cpp:106] Iteration 3543000, lr = 0.01
I0831 20:28:34.412357 916722 solver.cpp:218] Iteration 3543500 (16.7965 iter/s, 29.7681s/500 iters), loss = 0.250346
I0831 20:28:34.412421 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.250347 (* 1 = 0.250347 loss)
I0831 20:28:34.412436 916722 sgd_solver.cpp:106] Iteration 3543500, lr = 0.01
I0831 20:29:04.183786 916722 solver.cpp:218] Iteration 3544000 (16.7947 iter/s, 29.7713s/500 iters), loss = 0.154818
I0831 20:29:04.183840 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.15482 (* 1 = 0.15482 loss)
I0831 20:29:04.183847 916722 sgd_solver.cpp:106] Iteration 3544000, lr = 0.01
I0831 20:29:33.954824 916722 solver.cpp:218] Iteration 3544500 (16.7949 iter/s, 29.771s/500 iters), loss = 0.0641204
I0831 20:29:33.954885 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0641224 (* 1 = 0.0641224 loss)
I0831 20:29:33.954893 916722 sgd_solver.cpp:106] Iteration 3544500, lr = 0.01
I0831 20:30:03.723786 916722 solver.cpp:218] Iteration 3545000 (16.7961 iter/s, 29.7689s/500 iters), loss = 0.0766523
I0831 20:30:03.723850 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0766544 (* 1 = 0.0766544 loss)
I0831 20:30:03.723857 916722 sgd_solver.cpp:106] Iteration 3545000, lr = 0.01
I0831 20:30:33.490625 916722 solver.cpp:218] Iteration 3545500 (16.7973 iter/s, 29.7667s/500 iters), loss = 0.14075
I0831 20:30:33.490694 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.140752 (* 1 = 0.140752 loss)
I0831 20:30:33.490702 916722 sgd_solver.cpp:106] Iteration 3545500, lr = 0.01
I0831 20:31:03.262666 916722 solver.cpp:218] Iteration 3546000 (16.7943 iter/s, 29.7719s/500 iters), loss = 0.188533
I0831 20:31:03.262727 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.188535 (* 1 = 0.188535 loss)
I0831 20:31:03.262735 916722 sgd_solver.cpp:106] Iteration 3546000, lr = 0.01
I0831 20:31:33.034152 916722 solver.cpp:218] Iteration 3546500 (16.7947 iter/s, 29.7714s/500 iters), loss = 0.0564271
I0831 20:31:33.034214 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0564292 (* 1 = 0.0564292 loss)
I0831 20:31:33.034224 916722 sgd_solver.cpp:106] Iteration 3546500, lr = 0.01
I0831 20:32:02.796032 916722 solver.cpp:218] Iteration 3547000 (16.8001 iter/s, 29.7618s/500 iters), loss = 0.135228
I0831 20:32:02.796084 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13523 (* 1 = 0.13523 loss)
I0831 20:32:02.796093 916722 sgd_solver.cpp:106] Iteration 3547000, lr = 0.01
I0831 20:32:32.552821 916722 solver.cpp:218] Iteration 3547500 (16.803 iter/s, 29.7567s/500 iters), loss = 0.0605507
I0831 20:32:32.552883 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0605525 (* 1 = 0.0605525 loss)
I0831 20:32:32.552892 916722 sgd_solver.cpp:106] Iteration 3547500, lr = 0.01
I0831 20:33:02.320888 916722 solver.cpp:218] Iteration 3548000 (16.7966 iter/s, 29.7679s/500 iters), loss = 0.0200987
I0831 20:33:02.320940 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0201006 (* 1 = 0.0201006 loss)
I0831 20:33:02.320948 916722 sgd_solver.cpp:106] Iteration 3548000, lr = 0.01
I0831 20:33:32.082119 916722 solver.cpp:218] Iteration 3548500 (16.8004 iter/s, 29.7611s/500 iters), loss = 0.0857438
I0831 20:33:32.082180 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0857457 (* 1 = 0.0857457 loss)
I0831 20:33:32.082190 916722 sgd_solver.cpp:106] Iteration 3548500, lr = 0.01
I0831 20:34:01.840567 916722 solver.cpp:218] Iteration 3549000 (16.802 iter/s, 29.7583s/500 iters), loss = 0.124652
I0831 20:34:01.840624 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.124654 (* 1 = 0.124654 loss)
I0831 20:34:01.840634 916722 sgd_solver.cpp:106] Iteration 3549000, lr = 0.01
I0831 20:34:31.596060 916722 solver.cpp:218] Iteration 3549500 (16.8037 iter/s, 29.7554s/500 iters), loss = 0.242475
I0831 20:34:31.596123 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.242477 (* 1 = 0.242477 loss)
I0831 20:34:31.596132 916722 sgd_solver.cpp:106] Iteration 3549500, lr = 0.01
I0831 20:35:01.297369 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_3550000.caffemodel
I0831 20:35:01.316421 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_3550000.solverstate
I0831 20:35:01.322451 916722 solver.cpp:330] Iteration 3550000, Testing net (#0)
I0831 20:35:16.754659 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8547
I0831 20:35:16.754704 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.502345 (* 1 = 0.502345 loss)
I0831 20:35:16.813131 916722 solver.cpp:218] Iteration 3550000 (11.0578 iter/s, 45.2169s/500 iters), loss = 0.244302
I0831 20:35:16.813158 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.244304 (* 1 = 0.244304 loss)
I0831 20:35:16.813166 916722 sgd_solver.cpp:106] Iteration 3550000, lr = 0.01
I0831 20:35:46.482671 916722 solver.cpp:218] Iteration 3550500 (16.8524 iter/s, 29.6694s/500 iters), loss = 0.0818343
I0831 20:35:46.482726 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.081836 (* 1 = 0.081836 loss)
I0831 20:35:46.482746 916722 sgd_solver.cpp:106] Iteration 3550500, lr = 0.01
I0831 20:36:16.231559 916722 solver.cpp:218] Iteration 3551000 (16.8074 iter/s, 29.7487s/500 iters), loss = 0.0788172
I0831 20:36:16.231631 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.078819 (* 1 = 0.078819 loss)
I0831 20:36:16.231638 916722 sgd_solver.cpp:106] Iteration 3551000, lr = 0.01
I0831 20:36:45.986429 916722 solver.cpp:218] Iteration 3551500 (16.8041 iter/s, 29.7547s/500 iters), loss = 0.0187893
I0831 20:36:45.986485 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0187913 (* 1 = 0.0187913 loss)
I0831 20:36:45.986493 916722 sgd_solver.cpp:106] Iteration 3551500, lr = 0.01
I0831 20:37:15.743649 916722 solver.cpp:218] Iteration 3552000 (16.8027 iter/s, 29.7571s/500 iters), loss = 0.164107
I0831 20:37:15.743708 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.164109 (* 1 = 0.164109 loss)
I0831 20:37:15.743716 916722 sgd_solver.cpp:106] Iteration 3552000, lr = 0.01
I0831 20:37:45.499346 916722 solver.cpp:218] Iteration 3552500 (16.8036 iter/s, 29.7555s/500 iters), loss = 0.204897
I0831 20:37:45.499400 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.204899 (* 1 = 0.204899 loss)
I0831 20:37:45.499411 916722 sgd_solver.cpp:106] Iteration 3552500, lr = 0.01
I0831 20:38:15.254957 916722 solver.cpp:218] Iteration 3553000 (16.8036 iter/s, 29.7555s/500 iters), loss = 0.0888733
I0831 20:38:15.255018 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0888754 (* 1 = 0.0888754 loss)
I0831 20:38:15.255026 916722 sgd_solver.cpp:106] Iteration 3553000, lr = 0.01
I0831 20:38:45.010629 916722 solver.cpp:218] Iteration 3553500 (16.8036 iter/s, 29.7555s/500 iters), loss = 0.101909
I0831 20:38:45.010682 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101911 (* 1 = 0.101911 loss)
I0831 20:38:45.010692 916722 sgd_solver.cpp:106] Iteration 3553500, lr = 0.01
I0831 20:39:14.767586 916722 solver.cpp:218] Iteration 3554000 (16.8029 iter/s, 29.7568s/500 iters), loss = 0.0257474
I0831 20:39:14.767645 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0257496 (* 1 = 0.0257496 loss)
I0831 20:39:14.767653 916722 sgd_solver.cpp:106] Iteration 3554000, lr = 0.01
I0831 20:39:44.528157 916722 solver.cpp:218] Iteration 3554500 (16.8008 iter/s, 29.7604s/500 iters), loss = 0.0372238
I0831 20:39:44.528208 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0372259 (* 1 = 0.0372259 loss)
I0831 20:39:44.528218 916722 sgd_solver.cpp:106] Iteration 3554500, lr = 0.01
I0831 20:40:14.281703 916722 solver.cpp:218] Iteration 3555000 (16.8048 iter/s, 29.7534s/500 iters), loss = 0.136144
I0831 20:40:14.281764 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.136147 (* 1 = 0.136147 loss)
I0831 20:40:14.281772 916722 sgd_solver.cpp:106] Iteration 3555000, lr = 0.01
I0831 20:40:44.038684 916722 solver.cpp:218] Iteration 3555500 (16.8029 iter/s, 29.7568s/500 iters), loss = 0.0175015
I0831 20:40:44.038739 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0175038 (* 1 = 0.0175038 loss)
I0831 20:40:44.038750 916722 sgd_solver.cpp:106] Iteration 3555500, lr = 0.01
I0831 20:41:13.793061 916722 solver.cpp:218] Iteration 3556000 (16.8043 iter/s, 29.7542s/500 iters), loss = 0.153753
I0831 20:41:13.793123 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.153755 (* 1 = 0.153755 loss)
I0831 20:41:13.793131 916722 sgd_solver.cpp:106] Iteration 3556000, lr = 0.01
I0831 20:41:43.547780 916722 solver.cpp:218] Iteration 3556500 (16.8041 iter/s, 29.7546s/500 iters), loss = 0.0860956
I0831 20:41:43.547838 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.086098 (* 1 = 0.086098 loss)
I0831 20:41:43.547849 916722 sgd_solver.cpp:106] Iteration 3556500, lr = 0.01
I0831 20:42:13.308828 916722 solver.cpp:218] Iteration 3557000 (16.8006 iter/s, 29.7609s/500 iters), loss = 0.133808
I0831 20:42:13.308902 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13381 (* 1 = 0.13381 loss)
I0831 20:42:13.308917 916722 sgd_solver.cpp:106] Iteration 3557000, lr = 0.01
I0831 20:42:43.037413 916722 solver.cpp:218] Iteration 3557500 (16.8189 iter/s, 29.7284s/500 iters), loss = 0.047096
I0831 20:42:43.037469 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0470982 (* 1 = 0.0470982 loss)
I0831 20:42:43.037479 916722 sgd_solver.cpp:106] Iteration 3557500, lr = 0.01
I0831 20:43:12.766613 916722 solver.cpp:218] Iteration 3558000 (16.8186 iter/s, 29.729s/500 iters), loss = 0.13158
I0831 20:43:12.766675 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131582 (* 1 = 0.131582 loss)
I0831 20:43:12.766685 916722 sgd_solver.cpp:106] Iteration 3558000, lr = 0.01
I0831 20:43:42.496176 916722 solver.cpp:218] Iteration 3558500 (16.8184 iter/s, 29.7294s/500 iters), loss = 0.182868
I0831 20:43:42.496227 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.18287 (* 1 = 0.18287 loss)
I0831 20:43:42.496235 916722 sgd_solver.cpp:106] Iteration 3558500, lr = 0.01
I0831 20:44:12.223381 916722 solver.cpp:218] Iteration 3559000 (16.8197 iter/s, 29.7271s/500 iters), loss = 0.188613
I0831 20:44:12.223440 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.188615 (* 1 = 0.188615 loss)
I0831 20:44:12.223448 916722 sgd_solver.cpp:106] Iteration 3559000, lr = 0.01
I0831 20:44:41.951929 916722 solver.cpp:218] Iteration 3559500 (16.8189 iter/s, 29.7284s/500 iters), loss = 0.110243
I0831 20:44:41.951983 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110245 (* 1 = 0.110245 loss)
I0831 20:44:41.951992 916722 sgd_solver.cpp:106] Iteration 3559500, lr = 0.01
I0831 20:45:11.686949 916722 solver.cpp:218] Iteration 3560000 (16.8153 iter/s, 29.7349s/500 iters), loss = 0.0836418
I0831 20:45:11.687009 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0836438 (* 1 = 0.0836438 loss)
I0831 20:45:11.687018 916722 sgd_solver.cpp:106] Iteration 3560000, lr = 0.01
I0831 20:45:41.428222 916722 solver.cpp:218] Iteration 3560500 (16.8118 iter/s, 29.7411s/500 iters), loss = 0.136834
I0831 20:45:41.428277 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.136836 (* 1 = 0.136836 loss)
I0831 20:45:41.428285 916722 sgd_solver.cpp:106] Iteration 3560500, lr = 0.01
I0831 20:46:11.170122 916722 solver.cpp:218] Iteration 3561000 (16.8114 iter/s, 29.7417s/500 iters), loss = 0.12205
I0831 20:46:11.170182 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.122052 (* 1 = 0.122052 loss)
I0831 20:46:11.170192 916722 sgd_solver.cpp:106] Iteration 3561000, lr = 0.01
I0831 20:46:40.909471 916722 solver.cpp:218] Iteration 3561500 (16.8128 iter/s, 29.7392s/500 iters), loss = 0.228545
I0831 20:46:40.909525 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.228547 (* 1 = 0.228547 loss)
I0831 20:46:40.909533 916722 sgd_solver.cpp:106] Iteration 3561500, lr = 0.01
I0831 20:47:10.651348 916722 solver.cpp:218] Iteration 3562000 (16.8114 iter/s, 29.7417s/500 iters), loss = 0.307426
I0831 20:47:10.651408 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.307428 (* 1 = 0.307428 loss)
I0831 20:47:10.651417 916722 sgd_solver.cpp:106] Iteration 3562000, lr = 0.01
I0831 20:47:40.394542 916722 solver.cpp:218] Iteration 3562500 (16.8107 iter/s, 29.743s/500 iters), loss = 0.0642946
I0831 20:47:40.394598 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0642966 (* 1 = 0.0642966 loss)
I0831 20:47:40.394608 916722 sgd_solver.cpp:106] Iteration 3562500, lr = 0.01
I0831 20:48:10.132284 916722 solver.cpp:218] Iteration 3563000 (16.8137 iter/s, 29.7376s/500 iters), loss = 0.0438018
I0831 20:48:10.132339 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0438039 (* 1 = 0.0438039 loss)
I0831 20:48:10.132347 916722 sgd_solver.cpp:106] Iteration 3563000, lr = 0.01
I0831 20:48:39.871090 916722 solver.cpp:218] Iteration 3563500 (16.8131 iter/s, 29.7386s/500 iters), loss = 0.132954
I0831 20:48:39.871142 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.132956 (* 1 = 0.132956 loss)
I0831 20:48:39.871152 916722 sgd_solver.cpp:106] Iteration 3563500, lr = 0.01
I0831 20:49:09.611264 916722 solver.cpp:218] Iteration 3564000 (16.8124 iter/s, 29.74s/500 iters), loss = 0.0475935
I0831 20:49:09.611333 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0475956 (* 1 = 0.0475956 loss)
I0831 20:49:09.611342 916722 sgd_solver.cpp:106] Iteration 3564000, lr = 0.01
I0831 20:49:39.352459 916722 solver.cpp:218] Iteration 3564500 (16.8118 iter/s, 29.741s/500 iters), loss = 0.155124
I0831 20:49:39.352512 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.155126 (* 1 = 0.155126 loss)
I0831 20:49:39.352524 916722 sgd_solver.cpp:106] Iteration 3564500, lr = 0.01
I0831 20:50:09.090559 916722 solver.cpp:218] Iteration 3565000 (16.8135 iter/s, 29.7379s/500 iters), loss = 0.19136
I0831 20:50:09.090617 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.191362 (* 1 = 0.191362 loss)
I0831 20:50:09.090626 916722 sgd_solver.cpp:106] Iteration 3565000, lr = 0.01
I0831 20:50:38.832600 916722 solver.cpp:218] Iteration 3565500 (16.8113 iter/s, 29.7419s/500 iters), loss = 0.271607
I0831 20:50:38.832654 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.271609 (* 1 = 0.271609 loss)
I0831 20:50:38.832664 916722 sgd_solver.cpp:106] Iteration 3565500, lr = 0.01
I0831 20:51:08.574069 916722 solver.cpp:218] Iteration 3566000 (16.8116 iter/s, 29.7413s/500 iters), loss = 0.224938
I0831 20:51:08.574126 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.22494 (* 1 = 0.22494 loss)
I0831 20:51:08.574134 916722 sgd_solver.cpp:106] Iteration 3566000, lr = 0.01
I0831 20:51:38.317126 916722 solver.cpp:218] Iteration 3566500 (16.8107 iter/s, 29.7429s/500 iters), loss = 0.338792
I0831 20:51:38.317178 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.338794 (* 1 = 0.338794 loss)
I0831 20:51:38.317188 916722 sgd_solver.cpp:106] Iteration 3566500, lr = 0.01
I0831 20:52:08.060825 916722 solver.cpp:218] Iteration 3567000 (16.8104 iter/s, 29.7435s/500 iters), loss = 0.0841852
I0831 20:52:08.060885 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0841872 (* 1 = 0.0841872 loss)
I0831 20:52:08.060894 916722 sgd_solver.cpp:106] Iteration 3567000, lr = 0.01
I0831 20:52:37.798771 916722 solver.cpp:218] Iteration 3567500 (16.8136 iter/s, 29.7378s/500 iters), loss = 0.245406
I0831 20:52:37.798822 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.245408 (* 1 = 0.245408 loss)
I0831 20:52:37.798833 916722 sgd_solver.cpp:106] Iteration 3567500, lr = 0.01
I0831 20:53:07.541828 916722 solver.cpp:218] Iteration 3568000 (16.8107 iter/s, 29.7429s/500 iters), loss = 0.122622
I0831 20:53:07.541887 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.122624 (* 1 = 0.122624 loss)
I0831 20:53:07.541895 916722 sgd_solver.cpp:106] Iteration 3568000, lr = 0.01
I0831 20:53:37.280910 916722 solver.cpp:218] Iteration 3568500 (16.813 iter/s, 29.7389s/500 iters), loss = 0.367582
I0831 20:53:37.280963 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.367584 (* 1 = 0.367584 loss)
I0831 20:53:37.280972 916722 sgd_solver.cpp:106] Iteration 3568500, lr = 0.01
I0831 20:54:07.023046 916722 solver.cpp:218] Iteration 3569000 (16.8113 iter/s, 29.742s/500 iters), loss = 0.228493
I0831 20:54:07.023108 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.228495 (* 1 = 0.228495 loss)
I0831 20:54:07.023116 916722 sgd_solver.cpp:106] Iteration 3569000, lr = 0.01
I0831 20:54:36.763741 916722 solver.cpp:218] Iteration 3569500 (16.8121 iter/s, 29.7405s/500 iters), loss = 0.251236
I0831 20:54:36.763794 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.251238 (* 1 = 0.251238 loss)
I0831 20:54:36.763803 916722 sgd_solver.cpp:106] Iteration 3569500, lr = 0.01
I0831 20:55:06.499125 916722 solver.cpp:218] Iteration 3570000 (16.8151 iter/s, 29.7352s/500 iters), loss = 0.339529
I0831 20:55:06.499186 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.339531 (* 1 = 0.339531 loss)
I0831 20:55:06.499194 916722 sgd_solver.cpp:106] Iteration 3570000, lr = 0.01
I0831 20:55:36.239421 916722 solver.cpp:218] Iteration 3570500 (16.8123 iter/s, 29.7401s/500 iters), loss = 0.076925
I0831 20:55:36.239485 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0769268 (* 1 = 0.0769268 loss)
I0831 20:55:36.239495 916722 sgd_solver.cpp:106] Iteration 3570500, lr = 0.01
I0831 20:56:05.979583 916722 solver.cpp:218] Iteration 3571000 (16.8124 iter/s, 29.74s/500 iters), loss = 0.237393
I0831 20:56:05.979652 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.237395 (* 1 = 0.237395 loss)
I0831 20:56:05.979661 916722 sgd_solver.cpp:106] Iteration 3571000, lr = 0.01
I0831 20:56:35.718721 916722 solver.cpp:218] Iteration 3571500 (16.813 iter/s, 29.739s/500 iters), loss = 0.599044
I0831 20:56:35.718771 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.599046 (* 1 = 0.599046 loss)
I0831 20:56:35.718780 916722 sgd_solver.cpp:106] Iteration 3571500, lr = 0.01
I0831 20:57:05.460199 916722 solver.cpp:218] Iteration 3572000 (16.8116 iter/s, 29.7413s/500 iters), loss = 0.164782
I0831 20:57:05.460258 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.164784 (* 1 = 0.164784 loss)
I0831 20:57:05.460265 916722 sgd_solver.cpp:106] Iteration 3572000, lr = 0.01
I0831 20:57:35.200990 916722 solver.cpp:218] Iteration 3572500 (16.812 iter/s, 29.7406s/500 iters), loss = 0.132152
I0831 20:57:35.201043 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.132154 (* 1 = 0.132154 loss)
I0831 20:57:35.201052 916722 sgd_solver.cpp:106] Iteration 3572500, lr = 0.01
I0831 20:58:04.942268 916722 solver.cpp:218] Iteration 3573000 (16.8117 iter/s, 29.7411s/500 iters), loss = 0.373143
I0831 20:58:04.942327 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.373145 (* 1 = 0.373145 loss)
I0831 20:58:04.942335 916722 sgd_solver.cpp:106] Iteration 3573000, lr = 0.01
I0831 20:58:34.684988 916722 solver.cpp:218] Iteration 3573500 (16.8109 iter/s, 29.7425s/500 iters), loss = 0.235974
I0831 20:58:34.685045 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.235976 (* 1 = 0.235976 loss)
I0831 20:58:34.685055 916722 sgd_solver.cpp:106] Iteration 3573500, lr = 0.01
I0831 20:59:04.426106 916722 solver.cpp:218] Iteration 3574000 (16.8118 iter/s, 29.7409s/500 iters), loss = 0.0964846
I0831 20:59:04.426163 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0964866 (* 1 = 0.0964866 loss)
I0831 20:59:04.426172 916722 sgd_solver.cpp:106] Iteration 3574000, lr = 0.01
I0831 20:59:34.171269 916722 solver.cpp:218] Iteration 3574500 (16.8096 iter/s, 29.745s/500 iters), loss = 0.0514325
I0831 20:59:34.171321 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0514346 (* 1 = 0.0514346 loss)
I0831 20:59:34.171331 916722 sgd_solver.cpp:106] Iteration 3574500, lr = 0.01
I0831 21:00:03.917277 916722 solver.cpp:218] Iteration 3575000 (16.8091 iter/s, 29.7458s/500 iters), loss = 0.200398
I0831 21:00:03.917333 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.2004 (* 1 = 0.2004 loss)
I0831 21:00:03.917342 916722 sgd_solver.cpp:106] Iteration 3575000, lr = 0.01
I0831 21:00:33.656730 916722 solver.cpp:218] Iteration 3575500 (16.8128 iter/s, 29.7393s/500 iters), loss = 0.139004
I0831 21:00:33.656795 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139006 (* 1 = 0.139006 loss)
I0831 21:00:33.656805 916722 sgd_solver.cpp:106] Iteration 3575500, lr = 0.01
I0831 21:01:03.400018 916722 solver.cpp:218] Iteration 3576000 (16.8106 iter/s, 29.7431s/500 iters), loss = 0.147398
I0831 21:01:03.400072 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.1474 (* 1 = 0.1474 loss)
I0831 21:01:03.400080 916722 sgd_solver.cpp:106] Iteration 3576000, lr = 0.01
I0831 21:01:33.138536 916722 solver.cpp:218] Iteration 3576500 (16.8133 iter/s, 29.7384s/500 iters), loss = 0.137403
I0831 21:01:33.138583 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.137405 (* 1 = 0.137405 loss)
I0831 21:01:33.138593 916722 sgd_solver.cpp:106] Iteration 3576500, lr = 0.01
I0831 21:02:02.880856 916722 solver.cpp:218] Iteration 3577000 (16.8112 iter/s, 29.7422s/500 iters), loss = 0.177143
I0831 21:02:02.880928 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.177145 (* 1 = 0.177145 loss)
I0831 21:02:02.880935 916722 sgd_solver.cpp:106] Iteration 3577000, lr = 0.01
I0831 21:02:32.622166 916722 solver.cpp:218] Iteration 3577500 (16.8117 iter/s, 29.7411s/500 iters), loss = 0.214175
I0831 21:02:32.622220 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.214177 (* 1 = 0.214177 loss)
I0831 21:02:32.622231 916722 sgd_solver.cpp:106] Iteration 3577500, lr = 0.01
I0831 21:03:02.362483 916722 solver.cpp:218] Iteration 3578000 (16.8123 iter/s, 29.7401s/500 iters), loss = 0.00999319
I0831 21:03:02.362541 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0099952 (* 1 = 0.0099952 loss)
I0831 21:03:02.362550 916722 sgd_solver.cpp:106] Iteration 3578000, lr = 0.01
I0831 21:03:32.104873 916722 solver.cpp:218] Iteration 3578500 (16.8111 iter/s, 29.7422s/500 iters), loss = 0.141599
I0831 21:03:32.104928 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.141601 (* 1 = 0.141601 loss)
I0831 21:03:32.104938 916722 sgd_solver.cpp:106] Iteration 3578500, lr = 0.01
I0831 21:04:01.845417 916722 solver.cpp:218] Iteration 3579000 (16.8122 iter/s, 29.7404s/500 iters), loss = 0.256579
I0831 21:04:01.845474 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.256581 (* 1 = 0.256581 loss)
I0831 21:04:01.845482 916722 sgd_solver.cpp:106] Iteration 3579000, lr = 0.01
I0831 21:04:31.584524 916722 solver.cpp:218] Iteration 3579500 (16.813 iter/s, 29.7389s/500 iters), loss = 0.193519
I0831 21:04:31.584575 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.193521 (* 1 = 0.193521 loss)
I0831 21:04:31.584586 916722 sgd_solver.cpp:106] Iteration 3579500, lr = 0.01
I0831 21:05:01.325294 916722 solver.cpp:218] Iteration 3580000 (16.812 iter/s, 29.7406s/500 iters), loss = 0.300584
I0831 21:05:01.325347 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.300586 (* 1 = 0.300586 loss)
I0831 21:05:01.325356 916722 sgd_solver.cpp:106] Iteration 3580000, lr = 0.01
I0831 21:05:31.066640 916722 solver.cpp:218] Iteration 3580500 (16.8117 iter/s, 29.7412s/500 iters), loss = 0.0553976
I0831 21:05:31.066689 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0553997 (* 1 = 0.0553997 loss)
I0831 21:05:31.066699 916722 sgd_solver.cpp:106] Iteration 3580500, lr = 0.01
I0831 21:06:00.805667 916722 solver.cpp:218] Iteration 3581000 (16.813 iter/s, 29.7389s/500 iters), loss = 0.121343
I0831 21:06:00.805721 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.121346 (* 1 = 0.121346 loss)
I0831 21:06:00.805728 916722 sgd_solver.cpp:106] Iteration 3581000, lr = 0.01
I0831 21:06:30.548812 916722 solver.cpp:218] Iteration 3581500 (16.8107 iter/s, 29.743s/500 iters), loss = 0.197586
I0831 21:06:30.548862 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.197589 (* 1 = 0.197589 loss)
I0831 21:06:30.548872 916722 sgd_solver.cpp:106] Iteration 3581500, lr = 0.01
I0831 21:07:00.288626 916722 solver.cpp:218] Iteration 3582000 (16.8126 iter/s, 29.7396s/500 iters), loss = 0.0971381
I0831 21:07:00.288682 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0971404 (* 1 = 0.0971404 loss)
I0831 21:07:00.288691 916722 sgd_solver.cpp:106] Iteration 3582000, lr = 0.01
I0831 21:07:30.027002 916722 solver.cpp:218] Iteration 3582500 (16.8134 iter/s, 29.7382s/500 iters), loss = 0.500341
I0831 21:07:30.027050 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.500343 (* 1 = 0.500343 loss)
I0831 21:07:30.027060 916722 sgd_solver.cpp:106] Iteration 3582500, lr = 0.01
I0831 21:07:59.765252 916722 solver.cpp:218] Iteration 3583000 (16.8135 iter/s, 29.7381s/500 iters), loss = 0.039605
I0831 21:07:59.765309 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0396074 (* 1 = 0.0396074 loss)
I0831 21:07:59.765318 916722 sgd_solver.cpp:106] Iteration 3583000, lr = 0.01
I0831 21:08:29.511909 916722 solver.cpp:218] Iteration 3583500 (16.8087 iter/s, 29.7465s/500 iters), loss = 0.0142984
I0831 21:08:29.511982 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0143009 (* 1 = 0.0143009 loss)
I0831 21:08:29.511993 916722 sgd_solver.cpp:106] Iteration 3583500, lr = 0.01
I0831 21:08:59.252712 916722 solver.cpp:218] Iteration 3584000 (16.812 iter/s, 29.7406s/500 iters), loss = 0.053133
I0831 21:08:59.252789 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0531355 (* 1 = 0.0531355 loss)
I0831 21:08:59.252799 916722 sgd_solver.cpp:106] Iteration 3584000, lr = 0.01
I0831 21:09:29.002946 916722 solver.cpp:218] Iteration 3584500 (16.8067 iter/s, 29.75s/500 iters), loss = 0.241124
I0831 21:09:29.002995 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.241127 (* 1 = 0.241127 loss)
I0831 21:09:29.003005 916722 sgd_solver.cpp:106] Iteration 3584500, lr = 0.01
I0831 21:09:58.744877 916722 solver.cpp:218] Iteration 3585000 (16.8114 iter/s, 29.7418s/500 iters), loss = 0.0987898
I0831 21:09:58.744932 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0987923 (* 1 = 0.0987923 loss)
I0831 21:09:58.744940 916722 sgd_solver.cpp:106] Iteration 3585000, lr = 0.01
I0831 21:10:28.486073 916722 solver.cpp:218] Iteration 3585500 (16.8118 iter/s, 29.741s/500 iters), loss = 0.510688
I0831 21:10:28.486119 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.510691 (* 1 = 0.510691 loss)
I0831 21:10:28.486128 916722 sgd_solver.cpp:106] Iteration 3585500, lr = 0.01
I0831 21:10:58.220597 916722 solver.cpp:218] Iteration 3586000 (16.8156 iter/s, 29.7344s/500 iters), loss = 0.131589
I0831 21:10:58.220652 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131591 (* 1 = 0.131591 loss)
I0831 21:10:58.220661 916722 sgd_solver.cpp:106] Iteration 3586000, lr = 0.01
I0831 21:11:27.958263 916722 solver.cpp:218] Iteration 3586500 (16.8138 iter/s, 29.7375s/500 iters), loss = 0.0800372
I0831 21:11:27.958312 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0800396 (* 1 = 0.0800396 loss)
I0831 21:11:27.958320 916722 sgd_solver.cpp:106] Iteration 3586500, lr = 0.01
I0831 21:11:57.704229 916722 solver.cpp:218] Iteration 3587000 (16.8091 iter/s, 29.7458s/500 iters), loss = 0.194501
I0831 21:11:57.704283 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.194503 (* 1 = 0.194503 loss)
I0831 21:11:57.704293 916722 sgd_solver.cpp:106] Iteration 3587000, lr = 0.01
I0831 21:12:27.443157 916722 solver.cpp:218] Iteration 3587500 (16.8131 iter/s, 29.7388s/500 iters), loss = 0.227586
I0831 21:12:27.443205 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.227589 (* 1 = 0.227589 loss)
I0831 21:12:27.443214 916722 sgd_solver.cpp:106] Iteration 3587500, lr = 0.01
I0831 21:12:57.180805 916722 solver.cpp:218] Iteration 3588000 (16.8138 iter/s, 29.7375s/500 iters), loss = 0.0784009
I0831 21:12:57.180860 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0784034 (* 1 = 0.0784034 loss)
I0831 21:12:57.180868 916722 sgd_solver.cpp:106] Iteration 3588000, lr = 0.01
I0831 21:13:26.917881 916722 solver.cpp:218] Iteration 3588500 (16.8141 iter/s, 29.7369s/500 iters), loss = 0.0618669
I0831 21:13:26.917930 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0618693 (* 1 = 0.0618693 loss)
I0831 21:13:26.917940 916722 sgd_solver.cpp:106] Iteration 3588500, lr = 0.01
I0831 21:13:56.663031 916722 solver.cpp:218] Iteration 3589000 (16.8096 iter/s, 29.745s/500 iters), loss = 0.0887915
I0831 21:13:56.663086 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0887939 (* 1 = 0.0887939 loss)
I0831 21:13:56.663094 916722 sgd_solver.cpp:106] Iteration 3589000, lr = 0.01
I0831 21:14:26.412348 916722 solver.cpp:218] Iteration 3589500 (16.8072 iter/s, 29.7491s/500 iters), loss = 0.256488
I0831 21:14:26.412395 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.256491 (* 1 = 0.256491 loss)
I0831 21:14:26.412405 916722 sgd_solver.cpp:106] Iteration 3589500, lr = 0.01
I0831 21:14:56.161461 916722 solver.cpp:218] Iteration 3590000 (16.8073 iter/s, 29.7489s/500 iters), loss = 0.0915015
I0831 21:14:56.161530 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.091504 (* 1 = 0.091504 loss)
I0831 21:14:56.161543 916722 sgd_solver.cpp:106] Iteration 3590000, lr = 0.01
I0831 21:15:25.908545 916722 solver.cpp:218] Iteration 3590500 (16.8085 iter/s, 29.7469s/500 iters), loss = 0.138277
I0831 21:15:25.908587 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13828 (* 1 = 0.13828 loss)
I0831 21:15:25.908596 916722 sgd_solver.cpp:106] Iteration 3590500, lr = 0.01
I0831 21:15:55.658272 916722 solver.cpp:218] Iteration 3591000 (16.807 iter/s, 29.7496s/500 iters), loss = 0.336401
I0831 21:15:55.658327 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.336404 (* 1 = 0.336404 loss)
I0831 21:15:55.658335 916722 sgd_solver.cpp:106] Iteration 3591000, lr = 0.01
I0831 21:16:25.408149 916722 solver.cpp:218] Iteration 3591500 (16.8069 iter/s, 29.7497s/500 iters), loss = 0.119409
I0831 21:16:25.408198 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.119411 (* 1 = 0.119411 loss)
I0831 21:16:25.408207 916722 sgd_solver.cpp:106] Iteration 3591500, lr = 0.01
I0831 21:16:55.158740 916722 solver.cpp:218] Iteration 3592000 (16.8065 iter/s, 29.7504s/500 iters), loss = 0.0759334
I0831 21:16:55.158795 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0759358 (* 1 = 0.0759358 loss)
I0831 21:16:55.158804 916722 sgd_solver.cpp:106] Iteration 3592000, lr = 0.01
I0831 21:17:24.908699 916722 solver.cpp:218] Iteration 3592500 (16.8068 iter/s, 29.7498s/500 iters), loss = 0.0253937
I0831 21:17:24.908746 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0253961 (* 1 = 0.0253961 loss)
I0831 21:17:24.908754 916722 sgd_solver.cpp:106] Iteration 3592500, lr = 0.01
I0831 21:17:54.661007 916722 solver.cpp:218] Iteration 3593000 (16.8055 iter/s, 29.7521s/500 iters), loss = 0.172628
I0831 21:17:54.661062 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.17263 (* 1 = 0.17263 loss)
I0831 21:17:54.661069 916722 sgd_solver.cpp:106] Iteration 3593000, lr = 0.01
I0831 21:18:24.410462 916722 solver.cpp:218] Iteration 3593500 (16.8071 iter/s, 29.7493s/500 iters), loss = 0.11132
I0831 21:18:24.410511 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111322 (* 1 = 0.111322 loss)
I0831 21:18:24.410521 916722 sgd_solver.cpp:106] Iteration 3593500, lr = 0.01
I0831 21:18:54.161895 916722 solver.cpp:218] Iteration 3594000 (16.806 iter/s, 29.7513s/500 iters), loss = 0.351879
I0831 21:18:54.161947 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.351881 (* 1 = 0.351881 loss)
I0831 21:18:54.161954 916722 sgd_solver.cpp:106] Iteration 3594000, lr = 0.01
I0831 21:19:23.905527 916722 solver.cpp:218] Iteration 3594500 (16.8104 iter/s, 29.7435s/500 iters), loss = 0.366096
I0831 21:19:23.905577 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.366099 (* 1 = 0.366099 loss)
I0831 21:19:23.905588 916722 sgd_solver.cpp:106] Iteration 3594500, lr = 0.01
I0831 21:19:53.648140 916722 solver.cpp:218] Iteration 3595000 (16.811 iter/s, 29.7424s/500 iters), loss = 0.0887845
I0831 21:19:53.648196 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.088787 (* 1 = 0.088787 loss)
I0831 21:19:53.648205 916722 sgd_solver.cpp:106] Iteration 3595000, lr = 0.01
I0831 21:20:23.395766 916722 solver.cpp:218] Iteration 3595500 (16.8082 iter/s, 29.7475s/500 iters), loss = 0.101706
I0831 21:20:23.395817 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101709 (* 1 = 0.101709 loss)
I0831 21:20:23.395826 916722 sgd_solver.cpp:106] Iteration 3595500, lr = 0.01
I0831 21:20:53.146435 916722 solver.cpp:218] Iteration 3596000 (16.8064 iter/s, 29.7505s/500 iters), loss = 0.173139
I0831 21:20:53.146494 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.173142 (* 1 = 0.173142 loss)
I0831 21:20:53.146502 916722 sgd_solver.cpp:106] Iteration 3596000, lr = 0.01
I0831 21:21:22.897172 916722 solver.cpp:218] Iteration 3596500 (16.8064 iter/s, 29.7506s/500 iters), loss = 0.0657555
I0831 21:21:22.897223 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0657579 (* 1 = 0.0657579 loss)
I0831 21:21:22.897244 916722 sgd_solver.cpp:106] Iteration 3596500, lr = 0.01
I0831 21:21:52.647800 916722 solver.cpp:218] Iteration 3597000 (16.8065 iter/s, 29.7505s/500 iters), loss = 0.137597
I0831 21:21:52.647869 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.137599 (* 1 = 0.137599 loss)
I0831 21:21:52.647878 916722 sgd_solver.cpp:106] Iteration 3597000, lr = 0.01
I0831 21:22:22.399453 916722 solver.cpp:218] Iteration 3597500 (16.8059 iter/s, 29.7515s/500 iters), loss = 0.0196922
I0831 21:22:22.399506 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0196947 (* 1 = 0.0196947 loss)
I0831 21:22:22.399516 916722 sgd_solver.cpp:106] Iteration 3597500, lr = 0.01
I0831 21:22:52.149679 916722 solver.cpp:218] Iteration 3598000 (16.8067 iter/s, 29.75s/500 iters), loss = 0.0701746
I0831 21:22:52.149732 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0701771 (* 1 = 0.0701771 loss)
I0831 21:22:52.149741 916722 sgd_solver.cpp:106] Iteration 3598000, lr = 0.01
I0831 21:23:21.898346 916722 solver.cpp:218] Iteration 3598500 (16.8076 iter/s, 29.7485s/500 iters), loss = 0.17179
I0831 21:23:21.898401 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.171793 (* 1 = 0.171793 loss)
I0831 21:23:21.898411 916722 sgd_solver.cpp:106] Iteration 3598500, lr = 0.01
I0831 21:23:51.643544 916722 solver.cpp:218] Iteration 3599000 (16.8095 iter/s, 29.745s/500 iters), loss = 0.185803
I0831 21:23:51.643606 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.185806 (* 1 = 0.185806 loss)
I0831 21:23:51.643615 916722 sgd_solver.cpp:106] Iteration 3599000, lr = 0.01
I0831 21:24:21.393083 916722 solver.cpp:218] Iteration 3599500 (16.8071 iter/s, 29.7494s/500 iters), loss = 0.0608013
I0831 21:24:21.393138 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0608041 (* 1 = 0.0608041 loss)
I0831 21:24:21.393147 916722 sgd_solver.cpp:106] Iteration 3599500, lr = 0.01
I0831 21:24:51.082520 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_3600000.caffemodel
I0831 21:24:51.101747 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_3600000.solverstate
I0831 21:24:51.107791 916722 solver.cpp:330] Iteration 3600000, Testing net (#0)
I0831 21:25:06.567160 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8905
I0831 21:25:06.567209 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.360026 (* 1 = 0.360026 loss)
I0831 21:25:06.625833 916722 solver.cpp:218] Iteration 3600000 (11.054 iter/s, 45.2325s/500 iters), loss = 0.0861244
I0831 21:25:06.625862 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0861272 (* 1 = 0.0861272 loss)
I0831 21:25:06.625871 916722 sgd_solver.cpp:106] Iteration 3600000, lr = 0.01
I0831 21:25:36.279652 916722 solver.cpp:218] Iteration 3600500 (16.8613 iter/s, 29.6536s/500 iters), loss = 0.222045
I0831 21:25:36.279716 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.222048 (* 1 = 0.222048 loss)
I0831 21:25:36.279724 916722 sgd_solver.cpp:106] Iteration 3600500, lr = 0.01
I0831 21:26:06.030619 916722 solver.cpp:218] Iteration 3601000 (16.8063 iter/s, 29.7508s/500 iters), loss = 0.0393665
I0831 21:26:06.030674 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0393691 (* 1 = 0.0393691 loss)
I0831 21:26:06.030683 916722 sgd_solver.cpp:106] Iteration 3601000, lr = 0.01
I0831 21:26:35.782079 916722 solver.cpp:218] Iteration 3601500 (16.806 iter/s, 29.7513s/500 iters), loss = 0.0181849
I0831 21:26:35.782140 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0181874 (* 1 = 0.0181874 loss)
I0831 21:26:35.782150 916722 sgd_solver.cpp:106] Iteration 3601500, lr = 0.01
I0831 21:27:05.533411 916722 solver.cpp:218] Iteration 3602000 (16.8058 iter/s, 29.7515s/500 iters), loss = 0.0753761
I0831 21:27:05.533465 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0753786 (* 1 = 0.0753786 loss)
I0831 21:27:05.533474 916722 sgd_solver.cpp:106] Iteration 3602000, lr = 0.01
I0831 21:27:35.286165 916722 solver.cpp:218] Iteration 3602500 (16.805 iter/s, 29.753s/500 iters), loss = 0.137507
I0831 21:27:35.286235 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.137509 (* 1 = 0.137509 loss)
I0831 21:27:35.286244 916722 sgd_solver.cpp:106] Iteration 3602500, lr = 0.01
I0831 21:28:05.040349 916722 solver.cpp:218] Iteration 3603000 (16.8043 iter/s, 29.7544s/500 iters), loss = 0.0463561
I0831 21:28:05.040403 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0463587 (* 1 = 0.0463587 loss)
I0831 21:28:05.040414 916722 sgd_solver.cpp:106] Iteration 3603000, lr = 0.01
I0831 21:28:34.796239 916722 solver.cpp:218] Iteration 3603500 (16.8033 iter/s, 29.7561s/500 iters), loss = 0.0814329
I0831 21:28:34.796298 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0814355 (* 1 = 0.0814355 loss)
I0831 21:28:34.796306 916722 sgd_solver.cpp:106] Iteration 3603500, lr = 0.01
I0831 21:29:04.554821 916722 solver.cpp:218] Iteration 3604000 (16.8018 iter/s, 29.7587s/500 iters), loss = 0.241344
I0831 21:29:04.554872 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.241347 (* 1 = 0.241347 loss)
I0831 21:29:04.554881 916722 sgd_solver.cpp:106] Iteration 3604000, lr = 0.01
I0831 21:29:34.312950 916722 solver.cpp:218] Iteration 3604500 (16.802 iter/s, 29.7583s/500 iters), loss = 0.255026
I0831 21:29:34.313006 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.255029 (* 1 = 0.255029 loss)
I0831 21:29:34.313014 916722 sgd_solver.cpp:106] Iteration 3604500, lr = 0.01
I0831 21:30:04.067188 916722 solver.cpp:218] Iteration 3605000 (16.8043 iter/s, 29.7544s/500 iters), loss = 0.0861007
I0831 21:30:04.067239 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0861033 (* 1 = 0.0861033 loss)
I0831 21:30:04.067250 916722 sgd_solver.cpp:106] Iteration 3605000, lr = 0.01
I0831 21:30:33.819998 916722 solver.cpp:218] Iteration 3605500 (16.8051 iter/s, 29.7529s/500 iters), loss = 0.0822247
I0831 21:30:33.820060 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0822273 (* 1 = 0.0822273 loss)
I0831 21:30:33.820067 916722 sgd_solver.cpp:106] Iteration 3605500, lr = 0.01
I0831 21:31:03.574525 916722 solver.cpp:218] Iteration 3606000 (16.8041 iter/s, 29.7546s/500 iters), loss = 0.115666
I0831 21:31:03.574577 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115669 (* 1 = 0.115669 loss)
I0831 21:31:03.574587 916722 sgd_solver.cpp:106] Iteration 3606000, lr = 0.01
I0831 21:31:33.335604 916722 solver.cpp:218] Iteration 3606500 (16.8004 iter/s, 29.7612s/500 iters), loss = 0.132912
I0831 21:31:33.335662 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.132914 (* 1 = 0.132914 loss)
I0831 21:31:33.335670 916722 sgd_solver.cpp:106] Iteration 3606500, lr = 0.01
I0831 21:32:03.084340 916722 solver.cpp:218] Iteration 3607000 (16.8074 iter/s, 29.7488s/500 iters), loss = 0.105756
I0831 21:32:03.084393 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105759 (* 1 = 0.105759 loss)
I0831 21:32:03.084403 916722 sgd_solver.cpp:106] Iteration 3607000, lr = 0.01
I0831 21:32:32.835115 916722 solver.cpp:218] Iteration 3607500 (16.8062 iter/s, 29.7508s/500 iters), loss = 0.0520564
I0831 21:32:32.835175 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0520588 (* 1 = 0.0520588 loss)
I0831 21:32:32.835182 916722 sgd_solver.cpp:106] Iteration 3607500, lr = 0.01
I0831 21:33:02.583492 916722 solver.cpp:218] Iteration 3608000 (16.8076 iter/s, 29.7484s/500 iters), loss = 0.110465
I0831 21:33:02.583544 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110468 (* 1 = 0.110468 loss)
I0831 21:33:02.583554 916722 sgd_solver.cpp:106] Iteration 3608000, lr = 0.01
I0831 21:33:32.338488 916722 solver.cpp:218] Iteration 3608500 (16.8039 iter/s, 29.755s/500 iters), loss = 0.150438
I0831 21:33:32.338546 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.15044 (* 1 = 0.15044 loss)
I0831 21:33:32.338554 916722 sgd_solver.cpp:106] Iteration 3608500, lr = 0.01
I0831 21:34:02.087726 916722 solver.cpp:218] Iteration 3609000 (16.8071 iter/s, 29.7493s/500 iters), loss = 0.246647
I0831 21:34:02.087788 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.24665 (* 1 = 0.24665 loss)
I0831 21:34:02.087798 916722 sgd_solver.cpp:106] Iteration 3609000, lr = 0.01
I0831 21:34:31.830129 916722 solver.cpp:218] Iteration 3609500 (16.811 iter/s, 29.7424s/500 iters), loss = 0.109699
I0831 21:34:31.830200 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109701 (* 1 = 0.109701 loss)
I0831 21:34:31.830209 916722 sgd_solver.cpp:106] Iteration 3609500, lr = 0.01
I0831 21:35:01.572878 916722 solver.cpp:218] Iteration 3610000 (16.8108 iter/s, 29.7428s/500 iters), loss = 0.0167836
I0831 21:35:01.572930 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0167859 (* 1 = 0.0167859 loss)
I0831 21:35:01.572940 916722 sgd_solver.cpp:106] Iteration 3610000, lr = 0.01
I0831 21:35:31.315071 916722 solver.cpp:218] Iteration 3610500 (16.8111 iter/s, 29.7422s/500 iters), loss = 0.101464
I0831 21:35:31.315130 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101466 (* 1 = 0.101466 loss)
I0831 21:35:31.315138 916722 sgd_solver.cpp:106] Iteration 3610500, lr = 0.01
I0831 21:36:01.062873 916722 solver.cpp:218] Iteration 3611000 (16.808 iter/s, 29.7478s/500 iters), loss = 0.181068
I0831 21:36:01.062923 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.18107 (* 1 = 0.18107 loss)
I0831 21:36:01.062933 916722 sgd_solver.cpp:106] Iteration 3611000, lr = 0.01
I0831 21:36:30.803839 916722 solver.cpp:218] Iteration 3611500 (16.8118 iter/s, 29.741s/500 iters), loss = 0.09844
I0831 21:36:30.803895 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0984423 (* 1 = 0.0984423 loss)
I0831 21:36:30.803903 916722 sgd_solver.cpp:106] Iteration 3611500, lr = 0.01
I0831 21:37:00.542873 916722 solver.cpp:218] Iteration 3612000 (16.8129 iter/s, 29.739s/500 iters), loss = 0.0991869
I0831 21:37:00.542924 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0991893 (* 1 = 0.0991893 loss)
I0831 21:37:00.542934 916722 sgd_solver.cpp:106] Iteration 3612000, lr = 0.01
I0831 21:37:30.287923 916722 solver.cpp:218] Iteration 3612500 (16.8095 iter/s, 29.745s/500 iters), loss = 0.0673394
I0831 21:37:30.287986 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0673417 (* 1 = 0.0673417 loss)
I0831 21:37:30.287994 916722 sgd_solver.cpp:106] Iteration 3612500, lr = 0.01
I0831 21:38:00.027380 916722 solver.cpp:218] Iteration 3613000 (16.8127 iter/s, 29.7394s/500 iters), loss = 0.416321
I0831 21:38:00.027431 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.416324 (* 1 = 0.416324 loss)
I0831 21:38:00.027438 916722 sgd_solver.cpp:106] Iteration 3613000, lr = 0.01
I0831 21:38:29.768108 916722 solver.cpp:218] Iteration 3613500 (16.812 iter/s, 29.7407s/500 iters), loss = 0.233694
I0831 21:38:29.768169 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.233696 (* 1 = 0.233696 loss)
I0831 21:38:29.768177 916722 sgd_solver.cpp:106] Iteration 3613500, lr = 0.01
I0831 21:38:59.510040 916722 solver.cpp:218] Iteration 3614000 (16.8113 iter/s, 29.7419s/500 iters), loss = 0.155214
I0831 21:38:59.510093 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.155216 (* 1 = 0.155216 loss)
I0831 21:38:59.510103 916722 sgd_solver.cpp:106] Iteration 3614000, lr = 0.01
I0831 21:39:29.252687 916722 solver.cpp:218] Iteration 3614500 (16.8109 iter/s, 29.7426s/500 iters), loss = 0.396454
I0831 21:39:29.252758 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.396457 (* 1 = 0.396457 loss)
I0831 21:39:29.252768 916722 sgd_solver.cpp:106] Iteration 3614500, lr = 0.01
I0831 21:39:58.994910 916722 solver.cpp:218] Iteration 3615000 (16.8112 iter/s, 29.7422s/500 iters), loss = 0.0120623
I0831 21:39:58.994966 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0120645 (* 1 = 0.0120645 loss)
I0831 21:39:58.994976 916722 sgd_solver.cpp:106] Iteration 3615000, lr = 0.01
I0831 21:40:28.731835 916722 solver.cpp:218] Iteration 3615500 (16.8141 iter/s, 29.7369s/500 iters), loss = 0.220326
I0831 21:40:28.731905 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.220328 (* 1 = 0.220328 loss)
I0831 21:40:28.731914 916722 sgd_solver.cpp:106] Iteration 3615500, lr = 0.01
I0831 21:40:58.478209 916722 solver.cpp:218] Iteration 3616000 (16.8088 iter/s, 29.7463s/500 iters), loss = 0.35998
I0831 21:40:58.478257 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.359982 (* 1 = 0.359982 loss)
I0831 21:40:58.478267 916722 sgd_solver.cpp:106] Iteration 3616000, lr = 0.01
I0831 21:41:28.224642 916722 solver.cpp:218] Iteration 3616500 (16.8088 iter/s, 29.7464s/500 iters), loss = 0.170299
I0831 21:41:28.224702 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.170301 (* 1 = 0.170301 loss)
I0831 21:41:28.224710 916722 sgd_solver.cpp:106] Iteration 3616500, lr = 0.01
I0831 21:41:57.975643 916722 solver.cpp:218] Iteration 3617000 (16.8062 iter/s, 29.7509s/500 iters), loss = 0.211626
I0831 21:41:57.975699 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.211629 (* 1 = 0.211629 loss)
I0831 21:41:57.975709 916722 sgd_solver.cpp:106] Iteration 3617000, lr = 0.01
I0831 21:42:27.725028 916722 solver.cpp:218] Iteration 3617500 (16.8071 iter/s, 29.7493s/500 iters), loss = 0.378943
I0831 21:42:27.725088 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.378945 (* 1 = 0.378945 loss)
I0831 21:42:27.725097 916722 sgd_solver.cpp:106] Iteration 3617500, lr = 0.01
I0831 21:42:57.480944 916722 solver.cpp:218] Iteration 3618000 (16.8034 iter/s, 29.7558s/500 iters), loss = 0.13586
I0831 21:42:57.480999 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.135862 (* 1 = 0.135862 loss)
I0831 21:42:57.481009 916722 sgd_solver.cpp:106] Iteration 3618000, lr = 0.01
I0831 21:43:27.235020 916722 solver.cpp:218] Iteration 3618500 (16.8045 iter/s, 29.754s/500 iters), loss = 0.092881
I0831 21:43:27.235082 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0928832 (* 1 = 0.0928832 loss)
I0831 21:43:27.235090 916722 sgd_solver.cpp:106] Iteration 3618500, lr = 0.01
I0831 21:43:56.989522 916722 solver.cpp:218] Iteration 3619000 (16.8042 iter/s, 29.7544s/500 iters), loss = 0.0850426
I0831 21:43:56.989576 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0850447 (* 1 = 0.0850447 loss)
I0831 21:43:56.989586 916722 sgd_solver.cpp:106] Iteration 3619000, lr = 0.01
I0831 21:44:26.747108 916722 solver.cpp:218] Iteration 3619500 (16.8025 iter/s, 29.7575s/500 iters), loss = 0.327334
I0831 21:44:26.747169 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.327336 (* 1 = 0.327336 loss)
I0831 21:44:26.747179 916722 sgd_solver.cpp:106] Iteration 3619500, lr = 0.01
I0831 21:44:56.495177 916722 solver.cpp:218] Iteration 3620000 (16.8079 iter/s, 29.748s/500 iters), loss = 0.0239433
I0831 21:44:56.495229 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0239452 (* 1 = 0.0239452 loss)
I0831 21:44:56.495239 916722 sgd_solver.cpp:106] Iteration 3620000, lr = 0.01
I0831 21:45:26.245097 916722 solver.cpp:218] Iteration 3620500 (16.8068 iter/s, 29.7498s/500 iters), loss = 0.224033
I0831 21:45:26.245160 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.224035 (* 1 = 0.224035 loss)
I0831 21:45:26.245169 916722 sgd_solver.cpp:106] Iteration 3620500, lr = 0.01
I0831 21:45:55.996620 916722 solver.cpp:218] Iteration 3621000 (16.8059 iter/s, 29.7514s/500 iters), loss = 0.0446314
I0831 21:45:55.996676 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0446332 (* 1 = 0.0446332 loss)
I0831 21:45:55.996685 916722 sgd_solver.cpp:106] Iteration 3621000, lr = 0.01
I0831 21:46:25.749728 916722 solver.cpp:218] Iteration 3621500 (16.805 iter/s, 29.753s/500 iters), loss = 0.349741
I0831 21:46:25.749791 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.349743 (* 1 = 0.349743 loss)
I0831 21:46:25.749799 916722 sgd_solver.cpp:106] Iteration 3621500, lr = 0.01
I0831 21:46:55.500458 916722 solver.cpp:218] Iteration 3622000 (16.8064 iter/s, 29.7506s/500 iters), loss = 0.211689
I0831 21:46:55.500530 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.211691 (* 1 = 0.211691 loss)
I0831 21:46:55.500538 916722 sgd_solver.cpp:106] Iteration 3622000, lr = 0.01
I0831 21:47:25.255874 916722 solver.cpp:218] Iteration 3622500 (16.8037 iter/s, 29.7553s/500 iters), loss = 0.0643368
I0831 21:47:25.255947 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0643386 (* 1 = 0.0643386 loss)
I0831 21:47:25.255956 916722 sgd_solver.cpp:106] Iteration 3622500, lr = 0.01
I0831 21:47:55.010426 916722 solver.cpp:218] Iteration 3623000 (16.8042 iter/s, 29.7544s/500 iters), loss = 0.0730912
I0831 21:47:55.010478 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0730928 (* 1 = 0.0730928 loss)
I0831 21:47:55.010488 916722 sgd_solver.cpp:106] Iteration 3623000, lr = 0.01
I0831 21:48:24.763242 916722 solver.cpp:218] Iteration 3623500 (16.8052 iter/s, 29.7527s/500 iters), loss = 0.0780522
I0831 21:48:24.763298 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0780537 (* 1 = 0.0780537 loss)
I0831 21:48:24.763306 916722 sgd_solver.cpp:106] Iteration 3623500, lr = 0.01
I0831 21:48:54.507699 916722 solver.cpp:218] Iteration 3624000 (16.8099 iter/s, 29.7444s/500 iters), loss = 0.0664937
I0831 21:48:54.507752 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0664952 (* 1 = 0.0664952 loss)
I0831 21:48:54.507762 916722 sgd_solver.cpp:106] Iteration 3624000, lr = 0.01
I0831 21:49:24.263868 916722 solver.cpp:218] Iteration 3624500 (16.8033 iter/s, 29.7561s/500 iters), loss = 0.0428157
I0831 21:49:24.263924 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0428174 (* 1 = 0.0428174 loss)
I0831 21:49:24.263932 916722 sgd_solver.cpp:106] Iteration 3624500, lr = 0.01
I0831 21:49:54.020056 916722 solver.cpp:218] Iteration 3625000 (16.8033 iter/s, 29.7561s/500 iters), loss = 0.21118
I0831 21:49:54.020108 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.211182 (* 1 = 0.211182 loss)
I0831 21:49:54.020118 916722 sgd_solver.cpp:106] Iteration 3625000, lr = 0.01
I0831 21:50:23.773600 916722 solver.cpp:218] Iteration 3625500 (16.8048 iter/s, 29.7534s/500 iters), loss = 0.0625543
I0831 21:50:23.773660 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.062556 (* 1 = 0.062556 loss)
I0831 21:50:23.773669 916722 sgd_solver.cpp:106] Iteration 3625500, lr = 0.01
I0831 21:50:53.524296 916722 solver.cpp:218] Iteration 3626000 (16.8064 iter/s, 29.7506s/500 iters), loss = 0.258054
I0831 21:50:53.524350 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.258056 (* 1 = 0.258056 loss)
I0831 21:50:53.524360 916722 sgd_solver.cpp:106] Iteration 3626000, lr = 0.01
I0831 21:51:23.275599 916722 solver.cpp:218] Iteration 3626500 (16.8061 iter/s, 29.7512s/500 iters), loss = 0.0437419
I0831 21:51:23.275660 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0437439 (* 1 = 0.0437439 loss)
I0831 21:51:23.275667 916722 sgd_solver.cpp:106] Iteration 3626500, lr = 0.01
I0831 21:51:53.029212 916722 solver.cpp:218] Iteration 3627000 (16.8047 iter/s, 29.7535s/500 iters), loss = 0.143909
I0831 21:51:53.029266 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.143911 (* 1 = 0.143911 loss)
I0831 21:51:53.029276 916722 sgd_solver.cpp:106] Iteration 3627000, lr = 0.01
I0831 21:52:22.784068 916722 solver.cpp:218] Iteration 3627500 (16.804 iter/s, 29.7547s/500 iters), loss = 0.0529763
I0831 21:52:22.784128 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0529783 (* 1 = 0.0529783 loss)
I0831 21:52:22.784137 916722 sgd_solver.cpp:106] Iteration 3627500, lr = 0.01
I0831 21:52:52.535033 916722 solver.cpp:218] Iteration 3628000 (16.8062 iter/s, 29.7508s/500 iters), loss = 0.281235
I0831 21:52:52.535085 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.281237 (* 1 = 0.281237 loss)
I0831 21:52:52.535096 916722 sgd_solver.cpp:106] Iteration 3628000, lr = 0.01
I0831 21:53:22.292970 916722 solver.cpp:218] Iteration 3628500 (16.8023 iter/s, 29.7578s/500 iters), loss = 0.282073
I0831 21:53:22.293038 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.282075 (* 1 = 0.282075 loss)
I0831 21:53:22.293051 916722 sgd_solver.cpp:106] Iteration 3628500, lr = 0.01
I0831 21:53:52.046536 916722 solver.cpp:218] Iteration 3629000 (16.8048 iter/s, 29.7534s/500 iters), loss = 0.345408
I0831 21:53:52.046586 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.34541 (* 1 = 0.34541 loss)
I0831 21:53:52.046597 916722 sgd_solver.cpp:106] Iteration 3629000, lr = 0.01
I0831 21:54:21.794642 916722 solver.cpp:218] Iteration 3629500 (16.8079 iter/s, 29.748s/500 iters), loss = 0.224931
I0831 21:54:21.794705 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.224933 (* 1 = 0.224933 loss)
I0831 21:54:21.794714 916722 sgd_solver.cpp:106] Iteration 3629500, lr = 0.01
I0831 21:54:51.547503 916722 solver.cpp:218] Iteration 3630000 (16.8052 iter/s, 29.7527s/500 iters), loss = 0.36966
I0831 21:54:51.547556 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.369662 (* 1 = 0.369662 loss)
I0831 21:54:51.547565 916722 sgd_solver.cpp:106] Iteration 3630000, lr = 0.01
I0831 21:55:21.300437 916722 solver.cpp:218] Iteration 3630500 (16.8051 iter/s, 29.7528s/500 iters), loss = 0.28678
I0831 21:55:21.300498 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.286781 (* 1 = 0.286781 loss)
I0831 21:55:21.300508 916722 sgd_solver.cpp:106] Iteration 3630500, lr = 0.01
I0831 21:55:51.054086 916722 solver.cpp:218] Iteration 3631000 (16.8047 iter/s, 29.7535s/500 iters), loss = 0.0209553
I0831 21:55:51.054141 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0209572 (* 1 = 0.0209572 loss)
I0831 21:55:51.054149 916722 sgd_solver.cpp:106] Iteration 3631000, lr = 0.01
I0831 21:56:20.804869 916722 solver.cpp:218] Iteration 3631500 (16.8063 iter/s, 29.7507s/500 iters), loss = 0.208487
I0831 21:56:20.804929 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.208489 (* 1 = 0.208489 loss)
I0831 21:56:20.804939 916722 sgd_solver.cpp:106] Iteration 3631500, lr = 0.01
I0831 21:56:50.563050 916722 solver.cpp:218] Iteration 3632000 (16.8022 iter/s, 29.758s/500 iters), loss = 0.0304511
I0831 21:56:50.563103 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0304531 (* 1 = 0.0304531 loss)
I0831 21:56:50.563112 916722 sgd_solver.cpp:106] Iteration 3632000, lr = 0.01
I0831 21:57:20.311143 916722 solver.cpp:218] Iteration 3632500 (16.8079 iter/s, 29.748s/500 iters), loss = 0.379039
I0831 21:57:20.311203 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.379041 (* 1 = 0.379041 loss)
I0831 21:57:20.311213 916722 sgd_solver.cpp:106] Iteration 3632500, lr = 0.01
I0831 21:57:50.060712 916722 solver.cpp:218] Iteration 3633000 (16.807 iter/s, 29.7494s/500 iters), loss = 0.475916
I0831 21:57:50.060786 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.475918 (* 1 = 0.475918 loss)
I0831 21:57:50.060793 916722 sgd_solver.cpp:106] Iteration 3633000, lr = 0.01
I0831 21:58:19.810686 916722 solver.cpp:218] Iteration 3633500 (16.8068 iter/s, 29.7498s/500 iters), loss = 0.128462
I0831 21:58:19.810743 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128463 (* 1 = 0.128463 loss)
I0831 21:58:19.810751 916722 sgd_solver.cpp:106] Iteration 3633500, lr = 0.01
I0831 21:58:49.560678 916722 solver.cpp:218] Iteration 3634000 (16.8068 iter/s, 29.7499s/500 iters), loss = 0.0306878
I0831 21:58:49.560734 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0306897 (* 1 = 0.0306897 loss)
I0831 21:58:49.560743 916722 sgd_solver.cpp:106] Iteration 3634000, lr = 0.01
I0831 21:59:19.320019 916722 solver.cpp:218] Iteration 3634500 (16.8015 iter/s, 29.7592s/500 iters), loss = 0.123669
I0831 21:59:19.320081 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.123671 (* 1 = 0.123671 loss)
I0831 21:59:19.320091 916722 sgd_solver.cpp:106] Iteration 3634500, lr = 0.01
I0831 21:59:49.076862 916722 solver.cpp:218] Iteration 3635000 (16.8029 iter/s, 29.7567s/500 iters), loss = 0.189781
I0831 21:59:49.076920 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.189783 (* 1 = 0.189783 loss)
I0831 21:59:49.076942 916722 sgd_solver.cpp:106] Iteration 3635000, lr = 0.01
I0831 22:00:18.835942 916722 solver.cpp:218] Iteration 3635500 (16.8017 iter/s, 29.7589s/500 iters), loss = 0.121958
I0831 22:00:18.836011 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.12196 (* 1 = 0.12196 loss)
I0831 22:00:18.836031 916722 sgd_solver.cpp:106] Iteration 3635500, lr = 0.01
I0831 22:00:48.592402 916722 solver.cpp:218] Iteration 3636000 (16.8031 iter/s, 29.7564s/500 iters), loss = 0.0284747
I0831 22:00:48.592471 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0284769 (* 1 = 0.0284769 loss)
I0831 22:00:48.592483 916722 sgd_solver.cpp:106] Iteration 3636000, lr = 0.01
I0831 22:01:18.327327 916722 solver.cpp:218] Iteration 3636500 (16.815 iter/s, 29.7353s/500 iters), loss = 0.215415
I0831 22:01:18.327384 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.215417 (* 1 = 0.215417 loss)
I0831 22:01:18.327394 916722 sgd_solver.cpp:106] Iteration 3636500, lr = 0.01
I0831 22:01:48.060573 916722 solver.cpp:218] Iteration 3637000 (16.816 iter/s, 29.7336s/500 iters), loss = 0.278229
I0831 22:01:48.060626 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.278231 (* 1 = 0.278231 loss)
I0831 22:01:48.060637 916722 sgd_solver.cpp:106] Iteration 3637000, lr = 0.01
I0831 22:02:17.792160 916722 solver.cpp:218] Iteration 3637500 (16.8169 iter/s, 29.732s/500 iters), loss = 0.111725
I0831 22:02:17.792218 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111727 (* 1 = 0.111727 loss)
I0831 22:02:17.792227 916722 sgd_solver.cpp:106] Iteration 3637500, lr = 0.01
I0831 22:02:47.521631 916722 solver.cpp:218] Iteration 3638000 (16.8181 iter/s, 29.7298s/500 iters), loss = 0.328045
I0831 22:02:47.521682 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.328047 (* 1 = 0.328047 loss)
I0831 22:02:47.521693 916722 sgd_solver.cpp:106] Iteration 3638000, lr = 0.01
I0831 22:03:17.251794 916722 solver.cpp:218] Iteration 3638500 (16.8178 iter/s, 29.7305s/500 iters), loss = 0.0612247
I0831 22:03:17.251853 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.061227 (* 1 = 0.061227 loss)
I0831 22:03:17.251861 916722 sgd_solver.cpp:106] Iteration 3638500, lr = 0.01
I0831 22:03:46.983366 916722 solver.cpp:218] Iteration 3639000 (16.817 iter/s, 29.7319s/500 iters), loss = 0.0593544
I0831 22:03:46.983417 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0593569 (* 1 = 0.0593569 loss)
I0831 22:03:46.983425 916722 sgd_solver.cpp:106] Iteration 3639000, lr = 0.01
I0831 22:04:16.715407 916722 solver.cpp:218] Iteration 3639500 (16.8167 iter/s, 29.7323s/500 iters), loss = 0.237607
I0831 22:04:16.715469 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.237609 (* 1 = 0.237609 loss)
I0831 22:04:16.715477 916722 sgd_solver.cpp:106] Iteration 3639500, lr = 0.01
I0831 22:04:46.450664 916722 solver.cpp:218] Iteration 3640000 (16.8149 iter/s, 29.7355s/500 iters), loss = 0.0864113
I0831 22:04:46.450721 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0864137 (* 1 = 0.0864137 loss)
I0831 22:04:46.450731 916722 sgd_solver.cpp:106] Iteration 3640000, lr = 0.01
I0831 22:05:16.181129 916722 solver.cpp:218] Iteration 3640500 (16.8176 iter/s, 29.7307s/500 iters), loss = 0.0969125
I0831 22:05:16.181190 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.096915 (* 1 = 0.096915 loss)
I0831 22:05:16.181198 916722 sgd_solver.cpp:106] Iteration 3640500, lr = 0.01
I0831 22:05:45.913619 916722 solver.cpp:218] Iteration 3641000 (16.8165 iter/s, 29.7327s/500 iters), loss = 0.0295732
I0831 22:05:45.913672 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0295757 (* 1 = 0.0295757 loss)
I0831 22:05:45.913682 916722 sgd_solver.cpp:106] Iteration 3641000, lr = 0.01
I0831 22:06:15.647464 916722 solver.cpp:218] Iteration 3641500 (16.8157 iter/s, 29.734s/500 iters), loss = 0.0450377
I0831 22:06:15.647536 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0450402 (* 1 = 0.0450402 loss)
I0831 22:06:15.647550 916722 sgd_solver.cpp:106] Iteration 3641500, lr = 0.01
I0831 22:06:45.377285 916722 solver.cpp:218] Iteration 3642000 (16.818 iter/s, 29.73s/500 iters), loss = 0.207767
I0831 22:06:45.377337 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.207769 (* 1 = 0.207769 loss)
I0831 22:06:45.377347 916722 sgd_solver.cpp:106] Iteration 3642000, lr = 0.01
I0831 22:07:15.104812 916722 solver.cpp:218] Iteration 3642500 (16.8193 iter/s, 29.7277s/500 iters), loss = 0.161108
I0831 22:07:15.104872 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.161111 (* 1 = 0.161111 loss)
I0831 22:07:15.104880 916722 sgd_solver.cpp:106] Iteration 3642500, lr = 0.01
I0831 22:07:44.836529 916722 solver.cpp:218] Iteration 3643000 (16.817 iter/s, 29.7319s/500 iters), loss = 0.43542
I0831 22:07:44.836585 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.435423 (* 1 = 0.435423 loss)
I0831 22:07:44.836596 916722 sgd_solver.cpp:106] Iteration 3643000, lr = 0.01
I0831 22:08:14.566745 916722 solver.cpp:218] Iteration 3643500 (16.8178 iter/s, 29.7304s/500 iters), loss = 0.15649
I0831 22:08:14.566804 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.156492 (* 1 = 0.156492 loss)
I0831 22:08:14.566813 916722 sgd_solver.cpp:106] Iteration 3643500, lr = 0.01
I0831 22:08:44.297053 916722 solver.cpp:218] Iteration 3644000 (16.8178 iter/s, 29.7304s/500 iters), loss = 0.163565
I0831 22:08:44.297108 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.163567 (* 1 = 0.163567 loss)
I0831 22:08:44.297118 916722 sgd_solver.cpp:106] Iteration 3644000, lr = 0.01
I0831 22:09:14.026639 916722 solver.cpp:218] Iteration 3644500 (16.8182 iter/s, 29.7297s/500 iters), loss = 0.0834714
I0831 22:09:14.026702 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0834741 (* 1 = 0.0834741 loss)
I0831 22:09:14.026711 916722 sgd_solver.cpp:106] Iteration 3644500, lr = 0.01
I0831 22:09:43.758628 916722 solver.cpp:218] Iteration 3645000 (16.8168 iter/s, 29.7321s/500 iters), loss = 0.300173
I0831 22:09:43.758682 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.300176 (* 1 = 0.300176 loss)
I0831 22:09:43.758692 916722 sgd_solver.cpp:106] Iteration 3645000, lr = 0.01
I0831 22:10:13.485394 916722 solver.cpp:218] Iteration 3645500 (16.8198 iter/s, 29.7269s/500 iters), loss = 0.158263
I0831 22:10:13.485453 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.158266 (* 1 = 0.158266 loss)
I0831 22:10:13.485461 916722 sgd_solver.cpp:106] Iteration 3645500, lr = 0.01
I0831 22:10:43.213716 916722 solver.cpp:218] Iteration 3646000 (16.8189 iter/s, 29.7284s/500 iters), loss = 0.277757
I0831 22:10:43.213766 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.27776 (* 1 = 0.27776 loss)
I0831 22:10:43.213775 916722 sgd_solver.cpp:106] Iteration 3646000, lr = 0.01
I0831 22:11:12.943933 916722 solver.cpp:218] Iteration 3646500 (16.8179 iter/s, 29.7303s/500 iters), loss = 0.223075
I0831 22:11:12.943990 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.223078 (* 1 = 0.223078 loss)
I0831 22:11:12.943998 916722 sgd_solver.cpp:106] Iteration 3646500, lr = 0.01
I0831 22:11:42.669574 916722 solver.cpp:218] Iteration 3647000 (16.8205 iter/s, 29.7257s/500 iters), loss = 0.130918
I0831 22:11:42.669629 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130921 (* 1 = 0.130921 loss)
I0831 22:11:42.669637 916722 sgd_solver.cpp:106] Iteration 3647000, lr = 0.01
I0831 22:12:12.398243 916722 solver.cpp:218] Iteration 3647500 (16.8187 iter/s, 29.7287s/500 iters), loss = 0.133365
I0831 22:12:12.398304 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133368 (* 1 = 0.133368 loss)
I0831 22:12:12.398312 916722 sgd_solver.cpp:106] Iteration 3647500, lr = 0.01
I0831 22:12:42.126758 916722 solver.cpp:218] Iteration 3648000 (16.8188 iter/s, 29.7286s/500 iters), loss = 0.144043
I0831 22:12:42.126811 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.144046 (* 1 = 0.144046 loss)
I0831 22:12:42.126819 916722 sgd_solver.cpp:106] Iteration 3648000, lr = 0.01
I0831 22:13:11.861861 916722 solver.cpp:218] Iteration 3648500 (16.8151 iter/s, 29.7352s/500 iters), loss = 0.079435
I0831 22:13:11.861938 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0794378 (* 1 = 0.0794378 loss)
I0831 22:13:11.861948 916722 sgd_solver.cpp:106] Iteration 3648500, lr = 0.01
I0831 22:13:41.563413 916722 solver.cpp:218] Iteration 3649000 (16.8341 iter/s, 29.7016s/500 iters), loss = 0.127871
I0831 22:13:41.563467 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.127874 (* 1 = 0.127874 loss)
I0831 22:13:41.563475 916722 sgd_solver.cpp:106] Iteration 3649000, lr = 0.01
I0831 22:14:11.268203 916722 solver.cpp:218] Iteration 3649500 (16.8323 iter/s, 29.7048s/500 iters), loss = 0.120793
I0831 22:14:11.268263 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.120796 (* 1 = 0.120796 loss)
I0831 22:14:11.268272 916722 sgd_solver.cpp:106] Iteration 3649500, lr = 0.01
I0831 22:14:40.910596 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_3650000.caffemodel
I0831 22:14:40.929605 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_3650000.solverstate
I0831 22:14:40.935667 916722 solver.cpp:330] Iteration 3650000, Testing net (#0)
I0831 22:14:56.276300 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8842
I0831 22:14:56.276356 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.4365 (* 1 = 0.4365 loss)
I0831 22:14:56.334766 916722 solver.cpp:218] Iteration 3650000 (11.0947 iter/s, 45.0666s/500 iters), loss = 0.0644713
I0831 22:14:56.334794 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0644741 (* 1 = 0.0644741 loss)
I0831 22:14:56.334801 916722 sgd_solver.cpp:106] Iteration 3650000, lr = 0.01
I0831 22:15:25.905342 916722 solver.cpp:218] Iteration 3650500 (16.9087 iter/s, 29.5706s/500 iters), loss = 0.0216474
I0831 22:15:25.905395 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0216501 (* 1 = 0.0216501 loss)
I0831 22:15:25.905403 916722 sgd_solver.cpp:106] Iteration 3650500, lr = 0.01
I0831 22:15:55.602428 916722 solver.cpp:218] Iteration 3651000 (16.8367 iter/s, 29.6971s/500 iters), loss = 0.100892
I0831 22:15:55.602490 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.100894 (* 1 = 0.100894 loss)
I0831 22:15:55.602499 916722 sgd_solver.cpp:106] Iteration 3651000, lr = 0.01
I0831 22:16:25.298346 916722 solver.cpp:218] Iteration 3651500 (16.8373 iter/s, 29.6959s/500 iters), loss = 0.112796
I0831 22:16:25.298400 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112799 (* 1 = 0.112799 loss)
I0831 22:16:25.298408 916722 sgd_solver.cpp:106] Iteration 3651500, lr = 0.01
I0831 22:16:54.996476 916722 solver.cpp:218] Iteration 3652000 (16.8361 iter/s, 29.6981s/500 iters), loss = 0.0641928
I0831 22:16:54.996538 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0641952 (* 1 = 0.0641952 loss)
I0831 22:16:54.996547 916722 sgd_solver.cpp:106] Iteration 3652000, lr = 0.01
I0831 22:17:24.697757 916722 solver.cpp:218] Iteration 3652500 (16.8343 iter/s, 29.7013s/500 iters), loss = 0.22139
I0831 22:17:24.697808 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.221393 (* 1 = 0.221393 loss)
I0831 22:17:24.697815 916722 sgd_solver.cpp:106] Iteration 3652500, lr = 0.01
I0831 22:17:54.407542 916722 solver.cpp:218] Iteration 3653000 (16.8295 iter/s, 29.7098s/500 iters), loss = 0.0107314
I0831 22:17:54.407598 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0107337 (* 1 = 0.0107337 loss)
I0831 22:17:54.407605 916722 sgd_solver.cpp:106] Iteration 3653000, lr = 0.01
I0831 22:18:24.109618 916722 solver.cpp:218] Iteration 3653500 (16.8338 iter/s, 29.7021s/500 iters), loss = 0.123324
I0831 22:18:24.109673 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.123326 (* 1 = 0.123326 loss)
I0831 22:18:24.109683 916722 sgd_solver.cpp:106] Iteration 3653500, lr = 0.01
I0831 22:18:53.813369 916722 solver.cpp:218] Iteration 3654000 (16.8329 iter/s, 29.7037s/500 iters), loss = 0.164022
I0831 22:18:53.813446 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.164024 (* 1 = 0.164024 loss)
I0831 22:18:53.813453 916722 sgd_solver.cpp:106] Iteration 3654000, lr = 0.01
I0831 22:19:23.515457 916722 solver.cpp:218] Iteration 3654500 (16.8339 iter/s, 29.7021s/500 iters), loss = 0.0382993
I0831 22:19:23.515513 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0383016 (* 1 = 0.0383016 loss)
I0831 22:19:23.515523 916722 sgd_solver.cpp:106] Iteration 3654500, lr = 0.01
I0831 22:19:53.218549 916722 solver.cpp:218] Iteration 3655000 (16.8333 iter/s, 29.7031s/500 iters), loss = 0.0753406
I0831 22:19:53.218608 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0753429 (* 1 = 0.0753429 loss)
I0831 22:19:53.218617 916722 sgd_solver.cpp:106] Iteration 3655000, lr = 0.01
I0831 22:20:22.919718 916722 solver.cpp:218] Iteration 3655500 (16.8344 iter/s, 29.7011s/500 iters), loss = 0.128161
I0831 22:20:22.919770 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128164 (* 1 = 0.128164 loss)
I0831 22:20:22.919780 916722 sgd_solver.cpp:106] Iteration 3655500, lr = 0.01
I0831 22:20:52.621098 916722 solver.cpp:218] Iteration 3656000 (16.8342 iter/s, 29.7014s/500 iters), loss = 0.329828
I0831 22:20:52.621156 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.32983 (* 1 = 0.32983 loss)
I0831 22:20:52.621165 916722 sgd_solver.cpp:106] Iteration 3656000, lr = 0.01
I0831 22:21:22.322191 916722 solver.cpp:218] Iteration 3656500 (16.8344 iter/s, 29.7011s/500 iters), loss = 0.1467
I0831 22:21:22.322243 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.146702 (* 1 = 0.146702 loss)
I0831 22:21:22.322252 916722 sgd_solver.cpp:106] Iteration 3656500, lr = 0.01
I0831 22:21:52.023124 916722 solver.cpp:218] Iteration 3657000 (16.8345 iter/s, 29.7009s/500 iters), loss = 0.109427
I0831 22:21:52.023180 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109429 (* 1 = 0.109429 loss)
I0831 22:21:52.023188 916722 sgd_solver.cpp:106] Iteration 3657000, lr = 0.01
I0831 22:22:21.719789 916722 solver.cpp:218] Iteration 3657500 (16.8369 iter/s, 29.6966s/500 iters), loss = 0.0534547
I0831 22:22:21.719841 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0534571 (* 1 = 0.0534571 loss)
I0831 22:22:21.719851 916722 sgd_solver.cpp:106] Iteration 3657500, lr = 0.01
I0831 22:22:51.420467 916722 solver.cpp:218] Iteration 3658000 (16.8347 iter/s, 29.7006s/500 iters), loss = 0.092617
I0831 22:22:51.420527 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0926193 (* 1 = 0.0926193 loss)
I0831 22:22:51.420536 916722 sgd_solver.cpp:106] Iteration 3658000, lr = 0.01
I0831 22:23:21.117466 916722 solver.cpp:218] Iteration 3658500 (16.8367 iter/s, 29.697s/500 iters), loss = 0.0960077
I0831 22:23:21.117519 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.09601 (* 1 = 0.09601 loss)
I0831 22:23:21.117529 916722 sgd_solver.cpp:106] Iteration 3658500, lr = 0.01
I0831 22:23:50.819916 916722 solver.cpp:218] Iteration 3659000 (16.8337 iter/s, 29.7024s/500 iters), loss = 0.145286
I0831 22:23:50.819974 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.145289 (* 1 = 0.145289 loss)
I0831 22:23:50.819983 916722 sgd_solver.cpp:106] Iteration 3659000, lr = 0.01
I0831 22:24:20.520298 916722 solver.cpp:218] Iteration 3659500 (16.8348 iter/s, 29.7003s/500 iters), loss = 0.155291
I0831 22:24:20.520350 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.155294 (* 1 = 0.155294 loss)
I0831 22:24:20.520360 916722 sgd_solver.cpp:106] Iteration 3659500, lr = 0.01
I0831 22:24:50.221830 916722 solver.cpp:218] Iteration 3660000 (16.8342 iter/s, 29.7015s/500 iters), loss = 0.105944
I0831 22:24:50.221889 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105946 (* 1 = 0.105946 loss)
I0831 22:24:50.221897 916722 sgd_solver.cpp:106] Iteration 3660000, lr = 0.01
I0831 22:25:19.923527 916722 solver.cpp:218] Iteration 3660500 (16.8341 iter/s, 29.7017s/500 iters), loss = 0.183473
I0831 22:25:19.923581 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.183476 (* 1 = 0.183476 loss)
I0831 22:25:19.923602 916722 sgd_solver.cpp:106] Iteration 3660500, lr = 0.01
I0831 22:25:49.626359 916722 solver.cpp:218] Iteration 3661000 (16.8334 iter/s, 29.7028s/500 iters), loss = 0.0405903
I0831 22:25:49.626428 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0405925 (* 1 = 0.0405925 loss)
I0831 22:25:49.626451 916722 sgd_solver.cpp:106] Iteration 3661000, lr = 0.01
I0831 22:26:19.327189 916722 solver.cpp:218] Iteration 3661500 (16.8346 iter/s, 29.7008s/500 iters), loss = 0.309458
I0831 22:26:19.327242 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.309461 (* 1 = 0.309461 loss)
I0831 22:26:19.327252 916722 sgd_solver.cpp:106] Iteration 3661500, lr = 0.01
I0831 22:26:49.027307 916722 solver.cpp:218] Iteration 3662000 (16.835 iter/s, 29.7001s/500 iters), loss = 0.0607425
I0831 22:26:49.027366 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0607449 (* 1 = 0.0607449 loss)
I0831 22:26:49.027374 916722 sgd_solver.cpp:106] Iteration 3662000, lr = 0.01
I0831 22:27:18.726477 916722 solver.cpp:218] Iteration 3662500 (16.8355 iter/s, 29.6991s/500 iters), loss = 0.242229
I0831 22:27:18.726531 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.242231 (* 1 = 0.242231 loss)
I0831 22:27:18.726541 916722 sgd_solver.cpp:106] Iteration 3662500, lr = 0.01
I0831 22:27:48.428566 916722 solver.cpp:218] Iteration 3663000 (16.8339 iter/s, 29.702s/500 iters), loss = 0.173736
I0831 22:27:48.428625 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.173738 (* 1 = 0.173738 loss)
I0831 22:27:48.428633 916722 sgd_solver.cpp:106] Iteration 3663000, lr = 0.01
I0831 22:28:18.129549 916722 solver.cpp:218] Iteration 3663500 (16.8345 iter/s, 29.7009s/500 iters), loss = 0.25333
I0831 22:28:18.129599 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.253332 (* 1 = 0.253332 loss)
I0831 22:28:18.129609 916722 sgd_solver.cpp:106] Iteration 3663500, lr = 0.01
I0831 22:28:47.834863 916722 solver.cpp:218] Iteration 3664000 (16.832 iter/s, 29.7053s/500 iters), loss = 0.174962
I0831 22:28:47.834923 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.174964 (* 1 = 0.174964 loss)
I0831 22:28:47.834930 916722 sgd_solver.cpp:106] Iteration 3664000, lr = 0.01
I0831 22:29:17.535691 916722 solver.cpp:218] Iteration 3664500 (16.8346 iter/s, 29.7008s/500 iters), loss = 0.0746003
I0831 22:29:17.535745 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0746026 (* 1 = 0.0746026 loss)
I0831 22:29:17.535753 916722 sgd_solver.cpp:106] Iteration 3664500, lr = 0.01
I0831 22:29:47.237118 916722 solver.cpp:218] Iteration 3665000 (16.8342 iter/s, 29.7014s/500 iters), loss = 0.184888
I0831 22:29:47.237179 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.18489 (* 1 = 0.18489 loss)
I0831 22:29:47.237186 916722 sgd_solver.cpp:106] Iteration 3665000, lr = 0.01
I0831 22:30:16.938673 916722 solver.cpp:218] Iteration 3665500 (16.8342 iter/s, 29.7015s/500 iters), loss = 0.191751
I0831 22:30:16.938726 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.191753 (* 1 = 0.191753 loss)
I0831 22:30:16.938735 916722 sgd_solver.cpp:106] Iteration 3665500, lr = 0.01
I0831 22:30:46.644488 916722 solver.cpp:218] Iteration 3666000 (16.8318 iter/s, 29.7058s/500 iters), loss = 0.0315396
I0831 22:30:46.644551 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0315417 (* 1 = 0.0315417 loss)
I0831 22:30:46.644560 916722 sgd_solver.cpp:106] Iteration 3666000, lr = 0.01
I0831 22:31:16.347575 916722 solver.cpp:218] Iteration 3666500 (16.8333 iter/s, 29.703s/500 iters), loss = 0.116041
I0831 22:31:16.347628 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.116044 (* 1 = 0.116044 loss)
I0831 22:31:16.347637 916722 sgd_solver.cpp:106] Iteration 3666500, lr = 0.01
I0831 22:31:46.047143 916722 solver.cpp:218] Iteration 3667000 (16.8353 iter/s, 29.6995s/500 iters), loss = 0.0253696
I0831 22:31:46.047214 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0253718 (* 1 = 0.0253718 loss)
I0831 22:31:46.047227 916722 sgd_solver.cpp:106] Iteration 3667000, lr = 0.01
I0831 22:32:15.746598 916722 solver.cpp:218] Iteration 3667500 (16.8354 iter/s, 29.6994s/500 iters), loss = 0.0891411
I0831 22:32:15.746650 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0891434 (* 1 = 0.0891434 loss)
I0831 22:32:15.746659 916722 sgd_solver.cpp:106] Iteration 3667500, lr = 0.01
I0831 22:32:45.449340 916722 solver.cpp:218] Iteration 3668000 (16.8335 iter/s, 29.7027s/500 iters), loss = 0.0410931
I0831 22:32:45.449398 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0410954 (* 1 = 0.0410954 loss)
I0831 22:32:45.449406 916722 sgd_solver.cpp:106] Iteration 3668000, lr = 0.01
I0831 22:33:15.148128 916722 solver.cpp:218] Iteration 3668500 (16.8357 iter/s, 29.6987s/500 iters), loss = 0.0424762
I0831 22:33:15.148185 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0424785 (* 1 = 0.0424785 loss)
I0831 22:33:15.148195 916722 sgd_solver.cpp:106] Iteration 3668500, lr = 0.01
I0831 22:33:44.852705 916722 solver.cpp:218] Iteration 3669000 (16.8325 iter/s, 29.7045s/500 iters), loss = 0.133384
I0831 22:33:44.852763 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133386 (* 1 = 0.133386 loss)
I0831 22:33:44.852772 916722 sgd_solver.cpp:106] Iteration 3669000, lr = 0.01
I0831 22:34:14.555483 916722 solver.cpp:218] Iteration 3669500 (16.8335 iter/s, 29.7027s/500 iters), loss = 0.088809
I0831 22:34:14.555538 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0888113 (* 1 = 0.0888113 loss)
I0831 22:34:14.555547 916722 sgd_solver.cpp:106] Iteration 3669500, lr = 0.01
I0831 22:34:44.254932 916722 solver.cpp:218] Iteration 3670000 (16.8354 iter/s, 29.6994s/500 iters), loss = 0.214569
I0831 22:34:44.254990 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.214572 (* 1 = 0.214572 loss)
I0831 22:34:44.254999 916722 sgd_solver.cpp:106] Iteration 3670000, lr = 0.01
I0831 22:35:13.956164 916722 solver.cpp:218] Iteration 3670500 (16.835 iter/s, 29.7001s/500 iters), loss = 0.179872
I0831 22:35:13.956218 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.179875 (* 1 = 0.179875 loss)
I0831 22:35:13.956228 916722 sgd_solver.cpp:106] Iteration 3670500, lr = 0.01
I0831 22:35:43.659075 916722 solver.cpp:218] Iteration 3671000 (16.8342 iter/s, 29.7015s/500 iters), loss = 0.116323
I0831 22:35:43.659133 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.116325 (* 1 = 0.116325 loss)
I0831 22:35:43.659142 916722 sgd_solver.cpp:106] Iteration 3671000, lr = 0.01
I0831 22:36:13.360668 916722 solver.cpp:218] Iteration 3671500 (16.8349 iter/s, 29.7002s/500 iters), loss = 0.0138067
I0831 22:36:13.360723 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0138091 (* 1 = 0.0138091 loss)
I0831 22:36:13.360733 916722 sgd_solver.cpp:106] Iteration 3671500, lr = 0.01
I0831 22:36:43.062331 916722 solver.cpp:218] Iteration 3672000 (16.8348 iter/s, 29.7004s/500 iters), loss = 0.0448586
I0831 22:36:43.062388 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0448611 (* 1 = 0.0448611 loss)
I0831 22:36:43.062397 916722 sgd_solver.cpp:106] Iteration 3672000, lr = 0.01
I0831 22:37:12.765241 916722 solver.cpp:218] Iteration 3672500 (16.8341 iter/s, 29.7017s/500 iters), loss = 0.170232
I0831 22:37:12.765291 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.170234 (* 1 = 0.170234 loss)
I0831 22:37:12.765301 916722 sgd_solver.cpp:106] Iteration 3672500, lr = 0.01
I0831 22:37:42.468708 916722 solver.cpp:218] Iteration 3673000 (16.8337 iter/s, 29.7023s/500 iters), loss = 0.0385078
I0831 22:37:42.468782 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0385104 (* 1 = 0.0385104 loss)
I0831 22:37:42.468791 916722 sgd_solver.cpp:106] Iteration 3673000, lr = 0.01
I0831 22:38:12.171293 916722 solver.cpp:218] Iteration 3673500 (16.8342 iter/s, 29.7014s/500 iters), loss = 0.145139
I0831 22:38:12.171345 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.145142 (* 1 = 0.145142 loss)
I0831 22:38:12.171365 916722 sgd_solver.cpp:106] Iteration 3673500, lr = 0.01
I0831 22:38:41.874244 916722 solver.cpp:218] Iteration 3674000 (16.834 iter/s, 29.7019s/500 iters), loss = 0.165499
I0831 22:38:41.874315 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.165502 (* 1 = 0.165502 loss)
I0831 22:38:41.874322 916722 sgd_solver.cpp:106] Iteration 3674000, lr = 0.01
I0831 22:39:11.578258 916722 solver.cpp:218] Iteration 3674500 (16.8333 iter/s, 29.703s/500 iters), loss = 0.112346
I0831 22:39:11.578311 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112349 (* 1 = 0.112349 loss)
I0831 22:39:11.578320 916722 sgd_solver.cpp:106] Iteration 3674500, lr = 0.01
I0831 22:39:41.279543 916722 solver.cpp:218] Iteration 3675000 (16.8349 iter/s, 29.7003s/500 iters), loss = 0.188413
I0831 22:39:41.279601 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.188415 (* 1 = 0.188415 loss)
I0831 22:39:41.279610 916722 sgd_solver.cpp:106] Iteration 3675000, lr = 0.01
I0831 22:40:10.981894 916722 solver.cpp:218] Iteration 3675500 (16.8342 iter/s, 29.7014s/500 iters), loss = 0.0421449
I0831 22:40:10.981945 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0421477 (* 1 = 0.0421477 loss)
I0831 22:40:10.981954 916722 sgd_solver.cpp:106] Iteration 3675500, lr = 0.01
I0831 22:40:40.692740 916722 solver.cpp:218] Iteration 3676000 (16.8294 iter/s, 29.7099s/500 iters), loss = 0.226074
I0831 22:40:40.692802 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.226077 (* 1 = 0.226077 loss)
I0831 22:40:40.692811 916722 sgd_solver.cpp:106] Iteration 3676000, lr = 0.01
I0831 22:41:10.392516 916722 solver.cpp:218] Iteration 3676500 (16.8357 iter/s, 29.6989s/500 iters), loss = 0.156797
I0831 22:41:10.392566 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.156799 (* 1 = 0.156799 loss)
I0831 22:41:10.392575 916722 sgd_solver.cpp:106] Iteration 3676500, lr = 0.01
I0831 22:41:40.091136 916722 solver.cpp:218] Iteration 3677000 (16.8363 iter/s, 29.6978s/500 iters), loss = 0.0669536
I0831 22:41:40.091194 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0669562 (* 1 = 0.0669562 loss)
I0831 22:41:40.091202 916722 sgd_solver.cpp:106] Iteration 3677000, lr = 0.01
I0831 22:42:09.785751 916722 solver.cpp:218] Iteration 3677500 (16.8385 iter/s, 29.6938s/500 iters), loss = 0.305911
I0831 22:42:09.785805 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.305914 (* 1 = 0.305914 loss)
I0831 22:42:09.785815 916722 sgd_solver.cpp:106] Iteration 3677500, lr = 0.01
I0831 22:42:39.484797 916722 solver.cpp:218] Iteration 3678000 (16.836 iter/s, 29.6983s/500 iters), loss = 0.0498563
I0831 22:42:39.484858 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0498589 (* 1 = 0.0498589 loss)
I0831 22:42:39.484866 916722 sgd_solver.cpp:106] Iteration 3678000, lr = 0.01
I0831 22:43:09.184672 916722 solver.cpp:218] Iteration 3678500 (16.8355 iter/s, 29.6991s/500 iters), loss = 0.124754
I0831 22:43:09.184724 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.124756 (* 1 = 0.124756 loss)
I0831 22:43:09.184733 916722 sgd_solver.cpp:106] Iteration 3678500, lr = 0.01
I0831 22:43:38.886970 916722 solver.cpp:218] Iteration 3679000 (16.8341 iter/s, 29.7016s/500 iters), loss = 0.0610282
I0831 22:43:38.887030 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0610308 (* 1 = 0.0610308 loss)
I0831 22:43:38.887038 916722 sgd_solver.cpp:106] Iteration 3679000, lr = 0.01
I0831 22:44:08.586009 916722 solver.cpp:218] Iteration 3679500 (16.836 iter/s, 29.6983s/500 iters), loss = 0.0880445
I0831 22:44:08.586061 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.088047 (* 1 = 0.088047 loss)
I0831 22:44:08.586071 916722 sgd_solver.cpp:106] Iteration 3679500, lr = 0.01
I0831 22:44:38.288128 916722 solver.cpp:218] Iteration 3680000 (16.8342 iter/s, 29.7014s/500 iters), loss = 0.406177
I0831 22:44:38.288201 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.406179 (* 1 = 0.406179 loss)
I0831 22:44:38.288210 916722 sgd_solver.cpp:106] Iteration 3680000, lr = 0.01
I0831 22:45:07.989701 916722 solver.cpp:218] Iteration 3680500 (16.8345 iter/s, 29.7009s/500 iters), loss = 0.123789
I0831 22:45:07.989755 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.123792 (* 1 = 0.123792 loss)
I0831 22:45:07.989765 916722 sgd_solver.cpp:106] Iteration 3680500, lr = 0.01
I0831 22:45:37.690963 916722 solver.cpp:218] Iteration 3681000 (16.8347 iter/s, 29.7006s/500 iters), loss = 0.319941
I0831 22:45:37.691020 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.319944 (* 1 = 0.319944 loss)
I0831 22:45:37.691028 916722 sgd_solver.cpp:106] Iteration 3681000, lr = 0.01
I0831 22:46:07.392436 916722 solver.cpp:218] Iteration 3681500 (16.8345 iter/s, 29.7008s/500 iters), loss = 0.375558
I0831 22:46:07.392485 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.375561 (* 1 = 0.375561 loss)
I0831 22:46:07.392495 916722 sgd_solver.cpp:106] Iteration 3681500, lr = 0.01
I0831 22:46:37.093771 916722 solver.cpp:218] Iteration 3682000 (16.8346 iter/s, 29.7007s/500 iters), loss = 0.240212
I0831 22:46:37.093828 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.240215 (* 1 = 0.240215 loss)
I0831 22:46:37.093837 916722 sgd_solver.cpp:106] Iteration 3682000, lr = 0.01
I0831 22:47:06.791576 916722 solver.cpp:218] Iteration 3682500 (16.8366 iter/s, 29.6972s/500 iters), loss = 0.0708884
I0831 22:47:06.791628 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0708909 (* 1 = 0.0708909 loss)
I0831 22:47:06.791638 916722 sgd_solver.cpp:106] Iteration 3682500, lr = 0.01
I0831 22:47:36.485275 916722 solver.cpp:218] Iteration 3683000 (16.8389 iter/s, 29.6931s/500 iters), loss = 0.108564
I0831 22:47:36.485333 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.108566 (* 1 = 0.108566 loss)
I0831 22:47:36.485342 916722 sgd_solver.cpp:106] Iteration 3683000, lr = 0.01
I0831 22:48:06.170918 916722 solver.cpp:218] Iteration 3683500 (16.8435 iter/s, 29.6851s/500 iters), loss = 0.0443484
I0831 22:48:06.170971 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.044351 (* 1 = 0.044351 loss)
I0831 22:48:06.170981 916722 sgd_solver.cpp:106] Iteration 3683500, lr = 0.01
I0831 22:48:35.852584 916722 solver.cpp:218] Iteration 3684000 (16.8457 iter/s, 29.6811s/500 iters), loss = 0.236487
I0831 22:48:35.852643 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.23649 (* 1 = 0.23649 loss)
I0831 22:48:35.852650 916722 sgd_solver.cpp:106] Iteration 3684000, lr = 0.01
I0831 22:49:05.541960 916722 solver.cpp:218] Iteration 3684500 (16.8413 iter/s, 29.6888s/500 iters), loss = 0.119625
I0831 22:49:05.542009 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.119627 (* 1 = 0.119627 loss)
I0831 22:49:05.542019 916722 sgd_solver.cpp:106] Iteration 3684500, lr = 0.01
I0831 22:49:35.228971 916722 solver.cpp:218] Iteration 3685000 (16.8427 iter/s, 29.6865s/500 iters), loss = 0.0898869
I0831 22:49:35.229028 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0898894 (* 1 = 0.0898894 loss)
I0831 22:49:35.229038 916722 sgd_solver.cpp:106] Iteration 3685000, lr = 0.01
I0831 22:50:04.915514 916722 solver.cpp:218] Iteration 3685500 (16.8429 iter/s, 29.686s/500 iters), loss = 0.154161
I0831 22:50:04.915565 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.154163 (* 1 = 0.154163 loss)
I0831 22:50:04.915575 916722 sgd_solver.cpp:106] Iteration 3685500, lr = 0.01
I0831 22:50:34.614223 916722 solver.cpp:218] Iteration 3686000 (16.836 iter/s, 29.6982s/500 iters), loss = 0.24426
I0831 22:50:34.614280 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.244263 (* 1 = 0.244263 loss)
I0831 22:50:34.614289 916722 sgd_solver.cpp:106] Iteration 3686000, lr = 0.01
I0831 22:51:04.323006 916722 solver.cpp:218] Iteration 3686500 (16.8303 iter/s, 29.7083s/500 iters), loss = 0.24317
I0831 22:51:04.323058 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.243173 (* 1 = 0.243173 loss)
I0831 22:51:04.323068 916722 sgd_solver.cpp:106] Iteration 3686500, lr = 0.01
I0831 22:51:34.031780 916722 solver.cpp:218] Iteration 3687000 (16.8303 iter/s, 29.7083s/500 iters), loss = 0.0703625
I0831 22:51:34.031852 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.070365 (* 1 = 0.070365 loss)
I0831 22:51:34.031859 916722 sgd_solver.cpp:106] Iteration 3687000, lr = 0.01
I0831 22:52:03.742743 916722 solver.cpp:218] Iteration 3687500 (16.8291 iter/s, 29.7105s/500 iters), loss = 0.0309813
I0831 22:52:03.742794 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0309837 (* 1 = 0.0309837 loss)
I0831 22:52:03.742805 916722 sgd_solver.cpp:106] Iteration 3687500, lr = 0.01
I0831 22:52:33.452515 916722 solver.cpp:218] Iteration 3688000 (16.8297 iter/s, 29.7093s/500 iters), loss = 0.362674
I0831 22:52:33.452572 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.362676 (* 1 = 0.362676 loss)
I0831 22:52:33.452580 916722 sgd_solver.cpp:106] Iteration 3688000, lr = 0.01
I0831 22:53:03.165253 916722 solver.cpp:218] Iteration 3688500 (16.828 iter/s, 29.7123s/500 iters), loss = 0.174252
I0831 22:53:03.165304 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.174255 (* 1 = 0.174255 loss)
I0831 22:53:03.165314 916722 sgd_solver.cpp:106] Iteration 3688500, lr = 0.01
I0831 22:53:32.875588 916722 solver.cpp:218] Iteration 3689000 (16.8294 iter/s, 29.7099s/500 iters), loss = 0.0954525
I0831 22:53:32.875646 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0954551 (* 1 = 0.0954551 loss)
I0831 22:53:32.875654 916722 sgd_solver.cpp:106] Iteration 3689000, lr = 0.01
I0831 22:54:02.583045 916722 solver.cpp:218] Iteration 3689500 (16.831 iter/s, 29.707s/500 iters), loss = 0.251241
I0831 22:54:02.583094 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.251244 (* 1 = 0.251244 loss)
I0831 22:54:02.583104 916722 sgd_solver.cpp:106] Iteration 3689500, lr = 0.01
I0831 22:54:32.291457 916722 solver.cpp:218] Iteration 3690000 (16.8305 iter/s, 29.708s/500 iters), loss = 0.0483221
I0831 22:54:32.291518 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0483247 (* 1 = 0.0483247 loss)
I0831 22:54:32.291527 916722 sgd_solver.cpp:106] Iteration 3690000, lr = 0.01
I0831 22:55:02.001863 916722 solver.cpp:218] Iteration 3690500 (16.8294 iter/s, 29.71s/500 iters), loss = 0.273758
I0831 22:55:02.001914 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.273761 (* 1 = 0.273761 loss)
I0831 22:55:02.001922 916722 sgd_solver.cpp:106] Iteration 3690500, lr = 0.01
I0831 22:55:31.709100 916722 solver.cpp:218] Iteration 3691000 (16.8311 iter/s, 29.7068s/500 iters), loss = 0.544708
I0831 22:55:31.709158 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.544711 (* 1 = 0.544711 loss)
I0831 22:55:31.709167 916722 sgd_solver.cpp:106] Iteration 3691000, lr = 0.01
I0831 22:56:01.422646 916722 solver.cpp:218] Iteration 3691500 (16.8276 iter/s, 29.7131s/500 iters), loss = 0.184207
I0831 22:56:01.422698 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.18421 (* 1 = 0.18421 loss)
I0831 22:56:01.422706 916722 sgd_solver.cpp:106] Iteration 3691500, lr = 0.01
I0831 22:56:31.137444 916722 solver.cpp:218] Iteration 3692000 (16.8269 iter/s, 29.7144s/500 iters), loss = 0.065087
I0831 22:56:31.137506 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0650897 (* 1 = 0.0650897 loss)
I0831 22:56:31.137513 916722 sgd_solver.cpp:106] Iteration 3692000, lr = 0.01
I0831 22:57:00.848016 916722 solver.cpp:218] Iteration 3692500 (16.8293 iter/s, 29.7102s/500 iters), loss = 0.0953882
I0831 22:57:00.848067 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.095391 (* 1 = 0.095391 loss)
I0831 22:57:00.848074 916722 sgd_solver.cpp:106] Iteration 3692500, lr = 0.01
I0831 22:57:30.556272 916722 solver.cpp:218] Iteration 3693000 (16.8306 iter/s, 29.7079s/500 iters), loss = 0.130045
I0831 22:57:30.556329 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130048 (* 1 = 0.130048 loss)
I0831 22:57:30.556339 916722 sgd_solver.cpp:106] Iteration 3693000, lr = 0.01
I0831 22:58:00.267465 916722 solver.cpp:218] Iteration 3693500 (16.8289 iter/s, 29.7108s/500 iters), loss = 0.207312
I0831 22:58:00.267529 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.207315 (* 1 = 0.207315 loss)
I0831 22:58:00.267539 916722 sgd_solver.cpp:106] Iteration 3693500, lr = 0.01
I0831 22:58:29.978338 916722 solver.cpp:218] Iteration 3694000 (16.8291 iter/s, 29.7105s/500 iters), loss = 0.0164106
I0831 22:58:29.978405 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0164133 (* 1 = 0.0164133 loss)
I0831 22:58:29.978413 916722 sgd_solver.cpp:106] Iteration 3694000, lr = 0.01
I0831 22:58:59.689324 916722 solver.cpp:218] Iteration 3694500 (16.829 iter/s, 29.7106s/500 iters), loss = 0.160848
I0831 22:58:59.689380 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.160851 (* 1 = 0.160851 loss)
I0831 22:58:59.689390 916722 sgd_solver.cpp:106] Iteration 3694500, lr = 0.01
I0831 22:59:29.399441 916722 solver.cpp:218] Iteration 3695000 (16.8295 iter/s, 29.7097s/500 iters), loss = 0.107268
I0831 22:59:29.399498 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.107271 (* 1 = 0.107271 loss)
I0831 22:59:29.399507 916722 sgd_solver.cpp:106] Iteration 3695000, lr = 0.01
I0831 22:59:59.112998 916722 solver.cpp:218] Iteration 3695500 (16.8275 iter/s, 29.7132s/500 iters), loss = 0.158323
I0831 22:59:59.113049 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.158326 (* 1 = 0.158326 loss)
I0831 22:59:59.113059 916722 sgd_solver.cpp:106] Iteration 3695500, lr = 0.01
I0831 23:00:28.823195 916722 solver.cpp:218] Iteration 3696000 (16.8294 iter/s, 29.7098s/500 iters), loss = 0.145295
I0831 23:00:28.823251 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.145297 (* 1 = 0.145297 loss)
I0831 23:00:28.823259 916722 sgd_solver.cpp:106] Iteration 3696000, lr = 0.01
I0831 23:00:58.534849 916722 solver.cpp:218] Iteration 3696500 (16.8286 iter/s, 29.7113s/500 iters), loss = 0.136412
I0831 23:00:58.534901 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.136414 (* 1 = 0.136414 loss)
I0831 23:00:58.534911 916722 sgd_solver.cpp:106] Iteration 3696500, lr = 0.01
I0831 23:01:28.242462 916722 solver.cpp:218] Iteration 3697000 (16.8309 iter/s, 29.7073s/500 iters), loss = 0.15904
I0831 23:01:28.242519 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159043 (* 1 = 0.159043 loss)
I0831 23:01:28.242528 916722 sgd_solver.cpp:106] Iteration 3697000, lr = 0.01
I0831 23:01:57.955538 916722 solver.cpp:218] Iteration 3697500 (16.8278 iter/s, 29.7127s/500 iters), loss = 0.0992467
I0831 23:01:57.955590 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0992494 (* 1 = 0.0992494 loss)
I0831 23:01:57.955600 916722 sgd_solver.cpp:106] Iteration 3697500, lr = 0.01
I0831 23:02:27.667771 916722 solver.cpp:218] Iteration 3698000 (16.8283 iter/s, 29.7119s/500 iters), loss = 0.067937
I0831 23:02:27.667829 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0679396 (* 1 = 0.0679396 loss)
I0831 23:02:27.667837 916722 sgd_solver.cpp:106] Iteration 3698000, lr = 0.01
I0831 23:02:57.375360 916722 solver.cpp:218] Iteration 3698500 (16.8309 iter/s, 29.7072s/500 iters), loss = 0.0582345
I0831 23:02:57.375411 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0582372 (* 1 = 0.0582372 loss)
I0831 23:02:57.375422 916722 sgd_solver.cpp:106] Iteration 3698500, lr = 0.01
I0831 23:03:27.085088 916722 solver.cpp:218] Iteration 3699000 (16.8297 iter/s, 29.7094s/500 iters), loss = 0.16377
I0831 23:03:27.085151 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.163773 (* 1 = 0.163773 loss)
I0831 23:03:27.085160 916722 sgd_solver.cpp:106] Iteration 3699000, lr = 0.01
I0831 23:03:56.790944 916722 solver.cpp:218] Iteration 3699500 (16.8319 iter/s, 29.7055s/500 iters), loss = 0.0495637
I0831 23:03:56.790995 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0495665 (* 1 = 0.0495665 loss)
I0831 23:03:56.791004 916722 sgd_solver.cpp:106] Iteration 3699500, lr = 0.01
I0831 23:04:26.441519 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_3700000.caffemodel
I0831 23:04:26.460753 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_3700000.solverstate
I0831 23:04:26.466933 916722 solver.cpp:330] Iteration 3700000, Testing net (#0)
I0831 23:04:41.822546 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8759
I0831 23:04:41.822593 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.40855 (* 1 = 0.40855 loss)
I0831 23:04:41.881161 916722 solver.cpp:218] Iteration 3700000 (11.089 iter/s, 45.0897s/500 iters), loss = 0.150589
I0831 23:04:41.881189 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.150592 (* 1 = 0.150592 loss)
I0831 23:04:41.881198 916722 sgd_solver.cpp:106] Iteration 3700000, lr = 0.01
I0831 23:05:11.462551 916722 solver.cpp:218] Iteration 3700500 (16.9027 iter/s, 29.5811s/500 iters), loss = 0.206211
I0831 23:05:11.462608 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.206214 (* 1 = 0.206214 loss)
I0831 23:05:11.462617 916722 sgd_solver.cpp:106] Iteration 3700500, lr = 0.01
I0831 23:05:41.164026 916722 solver.cpp:218] Iteration 3701000 (16.8344 iter/s, 29.7011s/500 iters), loss = 0.199279
I0831 23:05:41.164079 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.199281 (* 1 = 0.199281 loss)
I0831 23:05:41.164088 916722 sgd_solver.cpp:106] Iteration 3701000, lr = 0.01
I0831 23:06:10.865836 916722 solver.cpp:218] Iteration 3701500 (16.8342 iter/s, 29.7015s/500 iters), loss = 0.0711028
I0831 23:06:10.865897 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0711053 (* 1 = 0.0711053 loss)
I0831 23:06:10.865906 916722 sgd_solver.cpp:106] Iteration 3701500, lr = 0.01
I0831 23:06:40.573477 916722 solver.cpp:218] Iteration 3702000 (16.8309 iter/s, 29.7073s/500 iters), loss = 0.0698777
I0831 23:06:40.573529 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0698801 (* 1 = 0.0698801 loss)
I0831 23:06:40.573539 916722 sgd_solver.cpp:106] Iteration 3702000, lr = 0.01
I0831 23:07:10.285157 916722 solver.cpp:218] Iteration 3702500 (16.8286 iter/s, 29.7114s/500 iters), loss = 0.148239
I0831 23:07:10.285216 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.148241 (* 1 = 0.148241 loss)
I0831 23:07:10.285224 916722 sgd_solver.cpp:106] Iteration 3702500, lr = 0.01
I0831 23:07:39.992456 916722 solver.cpp:218] Iteration 3703000 (16.8311 iter/s, 29.707s/500 iters), loss = 0.284954
I0831 23:07:39.992509 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.284957 (* 1 = 0.284957 loss)
I0831 23:07:39.992518 916722 sgd_solver.cpp:106] Iteration 3703000, lr = 0.01
I0831 23:08:09.702322 916722 solver.cpp:218] Iteration 3703500 (16.8296 iter/s, 29.7095s/500 iters), loss = 0.128442
I0831 23:08:09.702380 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128444 (* 1 = 0.128444 loss)
I0831 23:08:09.702389 916722 sgd_solver.cpp:106] Iteration 3703500, lr = 0.01
I0831 23:08:39.408949 916722 solver.cpp:218] Iteration 3704000 (16.8314 iter/s, 29.7063s/500 iters), loss = 0.183385
I0831 23:08:39.409001 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.183388 (* 1 = 0.183388 loss)
I0831 23:08:39.409010 916722 sgd_solver.cpp:106] Iteration 3704000, lr = 0.01
I0831 23:09:09.118301 916722 solver.cpp:218] Iteration 3704500 (16.8296 iter/s, 29.7096s/500 iters), loss = 0.0563167
I0831 23:09:09.118357 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0563191 (* 1 = 0.0563191 loss)
I0831 23:09:09.118366 916722 sgd_solver.cpp:106] Iteration 3704500, lr = 0.01
I0831 23:09:38.824167 916722 solver.cpp:218] Iteration 3705000 (16.831 iter/s, 29.707s/500 iters), loss = 0.0691643
I0831 23:09:38.824215 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0691668 (* 1 = 0.0691668 loss)
I0831 23:09:38.824223 916722 sgd_solver.cpp:106] Iteration 3705000, lr = 0.01
I0831 23:10:08.529260 916722 solver.cpp:218] Iteration 3705500 (16.8315 iter/s, 29.7062s/500 iters), loss = 0.144919
I0831 23:10:08.529328 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.144921 (* 1 = 0.144921 loss)
I0831 23:10:08.529341 916722 sgd_solver.cpp:106] Iteration 3705500, lr = 0.01
I0831 23:10:38.232250 916722 solver.cpp:218] Iteration 3706000 (16.8327 iter/s, 29.704s/500 iters), loss = 0.0731346
I0831 23:10:38.232302 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0731373 (* 1 = 0.0731373 loss)
I0831 23:10:38.232311 916722 sgd_solver.cpp:106] Iteration 3706000, lr = 0.01
I0831 23:11:07.939380 916722 solver.cpp:218] Iteration 3706500 (16.8304 iter/s, 29.7081s/500 iters), loss = 0.0580928
I0831 23:11:07.939440 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0580954 (* 1 = 0.0580954 loss)
I0831 23:11:07.939447 916722 sgd_solver.cpp:106] Iteration 3706500, lr = 0.01
I0831 23:11:37.647035 916722 solver.cpp:218] Iteration 3707000 (16.8302 iter/s, 29.7086s/500 iters), loss = 0.181175
I0831 23:11:37.647084 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.181178 (* 1 = 0.181178 loss)
I0831 23:11:37.647094 916722 sgd_solver.cpp:106] Iteration 3707000, lr = 0.01
I0831 23:12:07.355319 916722 solver.cpp:218] Iteration 3707500 (16.8298 iter/s, 29.7091s/500 iters), loss = 0.185028
I0831 23:12:07.355377 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.185031 (* 1 = 0.185031 loss)
I0831 23:12:07.355386 916722 sgd_solver.cpp:106] Iteration 3707500, lr = 0.01
I0831 23:12:37.067090 916722 solver.cpp:218] Iteration 3708000 (16.8279 iter/s, 29.7126s/500 iters), loss = 0.216951
I0831 23:12:37.067142 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.216954 (* 1 = 0.216954 loss)
I0831 23:12:37.067152 916722 sgd_solver.cpp:106] Iteration 3708000, lr = 0.01
I0831 23:13:06.778188 916722 solver.cpp:218] Iteration 3708500 (16.8283 iter/s, 29.7118s/500 iters), loss = 0.0340882
I0831 23:13:06.778245 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0340909 (* 1 = 0.0340909 loss)
I0831 23:13:06.778254 916722 sgd_solver.cpp:106] Iteration 3708500, lr = 0.01
I0831 23:13:36.486675 916722 solver.cpp:218] Iteration 3709000 (16.8298 iter/s, 29.7092s/500 iters), loss = 0.33967
I0831 23:13:36.486724 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.339672 (* 1 = 0.339672 loss)
I0831 23:13:36.486733 916722 sgd_solver.cpp:106] Iteration 3709000, lr = 0.01
I0831 23:14:06.192117 916722 solver.cpp:218] Iteration 3709500 (16.8316 iter/s, 29.7061s/500 iters), loss = 0.0785869
I0831 23:14:06.192178 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0785896 (* 1 = 0.0785896 loss)
I0831 23:14:06.192185 916722 sgd_solver.cpp:106] Iteration 3709500, lr = 0.01
I0831 23:14:35.902940 916722 solver.cpp:218] Iteration 3710000 (16.8285 iter/s, 29.7114s/500 iters), loss = 0.221499
I0831 23:14:35.902989 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.221502 (* 1 = 0.221502 loss)
I0831 23:14:35.902999 916722 sgd_solver.cpp:106] Iteration 3710000, lr = 0.01
I0831 23:15:05.611477 916722 solver.cpp:218] Iteration 3710500 (16.8299 iter/s, 29.7091s/500 iters), loss = 0.0781173
I0831 23:15:05.611536 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0781202 (* 1 = 0.0781202 loss)
I0831 23:15:05.611543 916722 sgd_solver.cpp:106] Iteration 3710500, lr = 0.01
I0831 23:15:35.322485 916722 solver.cpp:218] Iteration 3711000 (16.8285 iter/s, 29.7115s/500 iters), loss = 0.0740378
I0831 23:15:35.322537 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0740405 (* 1 = 0.0740405 loss)
I0831 23:15:35.322547 916722 sgd_solver.cpp:106] Iteration 3711000, lr = 0.01
I0831 23:16:05.030598 916722 solver.cpp:218] Iteration 3711500 (16.8301 iter/s, 29.7086s/500 iters), loss = 0.166118
I0831 23:16:05.030653 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.16612 (* 1 = 0.16612 loss)
I0831 23:16:05.030661 916722 sgd_solver.cpp:106] Iteration 3711500, lr = 0.01
I0831 23:16:34.737318 916722 solver.cpp:218] Iteration 3712000 (16.8309 iter/s, 29.7072s/500 iters), loss = 0.120298
I0831 23:16:34.737368 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.120301 (* 1 = 0.120301 loss)
I0831 23:16:34.737388 916722 sgd_solver.cpp:106] Iteration 3712000, lr = 0.01
I0831 23:17:04.445096 916722 solver.cpp:218] Iteration 3712500 (16.8304 iter/s, 29.7082s/500 iters), loss = 0.0874152
I0831 23:17:04.445161 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.087418 (* 1 = 0.087418 loss)
I0831 23:17:04.445169 916722 sgd_solver.cpp:106] Iteration 3712500, lr = 0.01
I0831 23:17:34.148366 916722 solver.cpp:218] Iteration 3713000 (16.8329 iter/s, 29.7037s/500 iters), loss = 0.16314
I0831 23:17:34.148416 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.163143 (* 1 = 0.163143 loss)
I0831 23:17:34.148430 916722 sgd_solver.cpp:106] Iteration 3713000, lr = 0.01
I0831 23:18:03.853627 916722 solver.cpp:218] Iteration 3713500 (16.8318 iter/s, 29.7056s/500 iters), loss = 0.0731307
I0831 23:18:03.853685 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0731335 (* 1 = 0.0731335 loss)
I0831 23:18:03.853693 916722 sgd_solver.cpp:106] Iteration 3713500, lr = 0.01
I0831 23:18:33.561967 916722 solver.cpp:218] Iteration 3714000 (16.8301 iter/s, 29.7087s/500 iters), loss = 0.100385
I0831 23:18:33.562021 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.100387 (* 1 = 0.100387 loss)
I0831 23:18:33.562028 916722 sgd_solver.cpp:106] Iteration 3714000, lr = 0.01
I0831 23:19:03.269588 916722 solver.cpp:218] Iteration 3714500 (16.8305 iter/s, 29.7079s/500 iters), loss = 0.25873
I0831 23:19:03.269645 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.258733 (* 1 = 0.258733 loss)
I0831 23:19:03.269654 916722 sgd_solver.cpp:106] Iteration 3714500, lr = 0.01
I0831 23:19:32.977753 916722 solver.cpp:218] Iteration 3715000 (16.8302 iter/s, 29.7084s/500 iters), loss = 0.192185
I0831 23:19:32.977805 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.192187 (* 1 = 0.192187 loss)
I0831 23:19:32.977814 916722 sgd_solver.cpp:106] Iteration 3715000, lr = 0.01
I0831 23:20:02.685825 916722 solver.cpp:218] Iteration 3715500 (16.8303 iter/s, 29.7083s/500 iters), loss = 0.289268
I0831 23:20:02.685883 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.289271 (* 1 = 0.289271 loss)
I0831 23:20:02.685890 916722 sgd_solver.cpp:106] Iteration 3715500, lr = 0.01
I0831 23:20:32.394665 916722 solver.cpp:218] Iteration 3716000 (16.8299 iter/s, 29.7091s/500 iters), loss = 0.0733208
I0831 23:20:32.394717 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0733237 (* 1 = 0.0733237 loss)
I0831 23:20:32.394726 916722 sgd_solver.cpp:106] Iteration 3716000, lr = 0.01
I0831 23:21:02.154161 916722 solver.cpp:218] Iteration 3716500 (16.8012 iter/s, 29.7597s/500 iters), loss = 0.274996
I0831 23:21:02.154222 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.274999 (* 1 = 0.274999 loss)
I0831 23:21:02.154229 916722 sgd_solver.cpp:106] Iteration 3716500, lr = 0.01
I0831 23:21:31.905061 916722 solver.cpp:218] Iteration 3717000 (16.8061 iter/s, 29.7511s/500 iters), loss = 0.0710786
I0831 23:21:31.905115 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0710813 (* 1 = 0.0710813 loss)
I0831 23:21:31.905124 916722 sgd_solver.cpp:106] Iteration 3717000, lr = 0.01
I0831 23:22:01.653658 916722 solver.cpp:218] Iteration 3717500 (16.8074 iter/s, 29.7488s/500 iters), loss = 0.102501
I0831 23:22:01.653720 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.102503 (* 1 = 0.102503 loss)
I0831 23:22:01.653729 916722 sgd_solver.cpp:106] Iteration 3717500, lr = 0.01
I0831 23:22:31.401196 916722 solver.cpp:218] Iteration 3718000 (16.808 iter/s, 29.7477s/500 iters), loss = 0.0414436
I0831 23:22:31.401250 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0414463 (* 1 = 0.0414463 loss)
I0831 23:22:31.401258 916722 sgd_solver.cpp:106] Iteration 3718000, lr = 0.01
I0831 23:23:01.144722 916722 solver.cpp:218] Iteration 3718500 (16.8103 iter/s, 29.7437s/500 iters), loss = 0.13708
I0831 23:23:01.144793 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.137083 (* 1 = 0.137083 loss)
I0831 23:23:01.144802 916722 sgd_solver.cpp:106] Iteration 3718500, lr = 0.01
I0831 23:23:30.890486 916722 solver.cpp:218] Iteration 3719000 (16.8091 iter/s, 29.7459s/500 iters), loss = 0.149121
I0831 23:23:30.890537 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.149124 (* 1 = 0.149124 loss)
I0831 23:23:30.890545 916722 sgd_solver.cpp:106] Iteration 3719000, lr = 0.01
I0831 23:24:00.633610 916722 solver.cpp:218] Iteration 3719500 (16.8105 iter/s, 29.7432s/500 iters), loss = 0.0833244
I0831 23:24:00.633679 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0833271 (* 1 = 0.0833271 loss)
I0831 23:24:00.633687 916722 sgd_solver.cpp:106] Iteration 3719500, lr = 0.01
I0831 23:24:30.379103 916722 solver.cpp:218] Iteration 3720000 (16.8092 iter/s, 29.7456s/500 iters), loss = 0.18093
I0831 23:24:30.379153 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.180932 (* 1 = 0.180932 loss)
I0831 23:24:30.379163 916722 sgd_solver.cpp:106] Iteration 3720000, lr = 0.01
I0831 23:25:00.130740 916722 solver.cpp:218] Iteration 3720500 (16.8057 iter/s, 29.7517s/500 iters), loss = 0.115483
I0831 23:25:00.130802 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115485 (* 1 = 0.115485 loss)
I0831 23:25:00.130810 916722 sgd_solver.cpp:106] Iteration 3720500, lr = 0.01
I0831 23:25:29.876909 916722 solver.cpp:218] Iteration 3721000 (16.8088 iter/s, 29.7462s/500 iters), loss = 0.2289
I0831 23:25:29.876963 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.228903 (* 1 = 0.228903 loss)
I0831 23:25:29.876972 916722 sgd_solver.cpp:106] Iteration 3721000, lr = 0.01
I0831 23:25:59.622676 916722 solver.cpp:218] Iteration 3721500 (16.8091 iter/s, 29.7458s/500 iters), loss = 0.135187
I0831 23:25:59.622737 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13519 (* 1 = 0.13519 loss)
I0831 23:25:59.622746 916722 sgd_solver.cpp:106] Iteration 3721500, lr = 0.01
I0831 23:26:29.368901 916722 solver.cpp:218] Iteration 3722000 (16.8088 iter/s, 29.7463s/500 iters), loss = 0.0849196
I0831 23:26:29.368957 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0849227 (* 1 = 0.0849227 loss)
I0831 23:26:29.368965 916722 sgd_solver.cpp:106] Iteration 3722000, lr = 0.01
I0831 23:26:59.118500 916722 solver.cpp:218] Iteration 3722500 (16.8069 iter/s, 29.7496s/500 iters), loss = 0.0216919
I0831 23:26:59.118562 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0216949 (* 1 = 0.0216949 loss)
I0831 23:26:59.118571 916722 sgd_solver.cpp:106] Iteration 3722500, lr = 0.01
I0831 23:27:28.865428 916722 solver.cpp:218] Iteration 3723000 (16.8084 iter/s, 29.747s/500 iters), loss = 0.187853
I0831 23:27:28.865482 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.187856 (* 1 = 0.187856 loss)
I0831 23:27:28.865491 916722 sgd_solver.cpp:106] Iteration 3723000, lr = 0.01
I0831 23:27:58.614102 916722 solver.cpp:218] Iteration 3723500 (16.8075 iter/s, 29.7487s/500 iters), loss = 0.459623
I0831 23:27:58.614162 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.459626 (* 1 = 0.459626 loss)
I0831 23:27:58.614171 916722 sgd_solver.cpp:106] Iteration 3723500, lr = 0.01
I0831 23:28:28.360919 916722 solver.cpp:218] Iteration 3724000 (16.8085 iter/s, 29.7468s/500 iters), loss = 0.141467
I0831 23:28:28.360973 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.14147 (* 1 = 0.14147 loss)
I0831 23:28:28.360985 916722 sgd_solver.cpp:106] Iteration 3724000, lr = 0.01
I0831 23:28:58.109521 916722 solver.cpp:218] Iteration 3724500 (16.8075 iter/s, 29.7486s/500 iters), loss = 0.158693
I0831 23:28:58.109577 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.158696 (* 1 = 0.158696 loss)
I0831 23:28:58.109586 916722 sgd_solver.cpp:106] Iteration 3724500, lr = 0.01
I0831 23:29:27.855849 916722 solver.cpp:218] Iteration 3725000 (16.8088 iter/s, 29.7463s/500 iters), loss = 0.0491315
I0831 23:29:27.855902 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0491346 (* 1 = 0.0491346 loss)
I0831 23:29:27.855912 916722 sgd_solver.cpp:106] Iteration 3725000, lr = 0.01
I0831 23:29:57.606935 916722 solver.cpp:218] Iteration 3725500 (16.8061 iter/s, 29.7511s/500 iters), loss = 0.025533
I0831 23:29:57.607005 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0255362 (* 1 = 0.0255362 loss)
I0831 23:29:57.607014 916722 sgd_solver.cpp:106] Iteration 3725500, lr = 0.01
I0831 23:30:27.352385 916722 solver.cpp:218] Iteration 3726000 (16.8093 iter/s, 29.7454s/500 iters), loss = 0.165168
I0831 23:30:27.352442 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.165172 (* 1 = 0.165172 loss)
I0831 23:30:27.352452 916722 sgd_solver.cpp:106] Iteration 3726000, lr = 0.01
I0831 23:30:57.102185 916722 solver.cpp:218] Iteration 3726500 (16.8068 iter/s, 29.7498s/500 iters), loss = 0.273251
I0831 23:30:57.102246 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.273254 (* 1 = 0.273254 loss)
I0831 23:30:57.102255 916722 sgd_solver.cpp:106] Iteration 3726500, lr = 0.01
I0831 23:31:26.848348 916722 solver.cpp:218] Iteration 3727000 (16.8089 iter/s, 29.7461s/500 iters), loss = 0.0835236
I0831 23:31:26.848402 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0835268 (* 1 = 0.0835268 loss)
I0831 23:31:26.848410 916722 sgd_solver.cpp:106] Iteration 3727000, lr = 0.01
I0831 23:31:56.595733 916722 solver.cpp:218] Iteration 3727500 (16.8082 iter/s, 29.7474s/500 iters), loss = 0.617905
I0831 23:31:56.595794 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.617908 (* 1 = 0.617908 loss)
I0831 23:31:56.595803 916722 sgd_solver.cpp:106] Iteration 3727500, lr = 0.01
I0831 23:32:26.345618 916722 solver.cpp:218] Iteration 3728000 (16.8068 iter/s, 29.7498s/500 iters), loss = 0.0814523
I0831 23:32:26.345670 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0814553 (* 1 = 0.0814553 loss)
I0831 23:32:26.345679 916722 sgd_solver.cpp:106] Iteration 3728000, lr = 0.01
I0831 23:32:56.094745 916722 solver.cpp:218] Iteration 3728500 (16.8072 iter/s, 29.7491s/500 iters), loss = 0.122397
I0831 23:32:56.094805 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.122399 (* 1 = 0.122399 loss)
I0831 23:32:56.094813 916722 sgd_solver.cpp:106] Iteration 3728500, lr = 0.01
I0831 23:33:25.842952 916722 solver.cpp:218] Iteration 3729000 (16.8078 iter/s, 29.7482s/500 iters), loss = 0.0215995
I0831 23:33:25.843004 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0216023 (* 1 = 0.0216023 loss)
I0831 23:33:25.843012 916722 sgd_solver.cpp:106] Iteration 3729000, lr = 0.01
I0831 23:33:55.593966 916722 solver.cpp:218] Iteration 3729500 (16.8062 iter/s, 29.751s/500 iters), loss = 0.0664385
I0831 23:33:55.594028 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0664411 (* 1 = 0.0664411 loss)
I0831 23:33:55.594036 916722 sgd_solver.cpp:106] Iteration 3729500, lr = 0.01
I0831 23:34:25.343066 916722 solver.cpp:218] Iteration 3730000 (16.8073 iter/s, 29.749s/500 iters), loss = 0.244429
I0831 23:34:25.343122 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.244432 (* 1 = 0.244432 loss)
I0831 23:34:25.343132 916722 sgd_solver.cpp:106] Iteration 3730000, lr = 0.01
I0831 23:34:55.090561 916722 solver.cpp:218] Iteration 3730500 (16.8082 iter/s, 29.7474s/500 iters), loss = 0.0988592
I0831 23:34:55.090623 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0988618 (* 1 = 0.0988618 loss)
I0831 23:34:55.090631 916722 sgd_solver.cpp:106] Iteration 3730500, lr = 0.01
I0831 23:35:24.840258 916722 solver.cpp:218] Iteration 3731000 (16.8069 iter/s, 29.7496s/500 iters), loss = 0.129684
I0831 23:35:24.840312 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.129687 (* 1 = 0.129687 loss)
I0831 23:35:24.840322 916722 sgd_solver.cpp:106] Iteration 3731000, lr = 0.01
I0831 23:35:54.589917 916722 solver.cpp:218] Iteration 3731500 (16.807 iter/s, 29.7496s/500 iters), loss = 0.264732
I0831 23:35:54.589975 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.264735 (* 1 = 0.264735 loss)
I0831 23:35:54.589984 916722 sgd_solver.cpp:106] Iteration 3731500, lr = 0.01
I0831 23:36:24.341161 916722 solver.cpp:218] Iteration 3732000 (16.8061 iter/s, 29.7512s/500 iters), loss = 0.0344436
I0831 23:36:24.341230 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0344461 (* 1 = 0.0344461 loss)
I0831 23:36:24.341240 916722 sgd_solver.cpp:106] Iteration 3732000, lr = 0.01
I0831 23:36:54.092967 916722 solver.cpp:218] Iteration 3732500 (16.8058 iter/s, 29.7517s/500 iters), loss = 0.239741
I0831 23:36:54.093036 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.239743 (* 1 = 0.239743 loss)
I0831 23:36:54.093045 916722 sgd_solver.cpp:106] Iteration 3732500, lr = 0.01
I0831 23:37:23.842283 916722 solver.cpp:218] Iteration 3733000 (16.8072 iter/s, 29.7492s/500 iters), loss = 0.40645
I0831 23:37:23.842334 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.406453 (* 1 = 0.406453 loss)
I0831 23:37:23.842344 916722 sgd_solver.cpp:106] Iteration 3733000, lr = 0.01
I0831 23:37:53.591588 916722 solver.cpp:218] Iteration 3733500 (16.8072 iter/s, 29.7492s/500 iters), loss = 0.396034
I0831 23:37:53.591645 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.396036 (* 1 = 0.396036 loss)
I0831 23:37:53.591653 916722 sgd_solver.cpp:106] Iteration 3733500, lr = 0.01
I0831 23:38:23.346297 916722 solver.cpp:218] Iteration 3734000 (16.8041 iter/s, 29.7546s/500 iters), loss = 0.128668
I0831 23:38:23.346351 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128671 (* 1 = 0.128671 loss)
I0831 23:38:23.346361 916722 sgd_solver.cpp:106] Iteration 3734000, lr = 0.01
I0831 23:38:53.102825 916722 solver.cpp:218] Iteration 3734500 (16.8031 iter/s, 29.7564s/500 iters), loss = 0.0316131
I0831 23:38:53.102885 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0316154 (* 1 = 0.0316154 loss)
I0831 23:38:53.102893 916722 sgd_solver.cpp:106] Iteration 3734500, lr = 0.01
I0831 23:39:22.850956 916722 solver.cpp:218] Iteration 3735000 (16.8078 iter/s, 29.748s/500 iters), loss = 0.281267
I0831 23:39:22.851008 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.28127 (* 1 = 0.28127 loss)
I0831 23:39:22.851018 916722 sgd_solver.cpp:106] Iteration 3735000, lr = 0.01
I0831 23:39:52.602684 916722 solver.cpp:218] Iteration 3735500 (16.8058 iter/s, 29.7516s/500 iters), loss = 0.243526
I0831 23:39:52.602746 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.243528 (* 1 = 0.243528 loss)
I0831 23:39:52.602756 916722 sgd_solver.cpp:106] Iteration 3735500, lr = 0.01
I0831 23:40:22.352888 916722 solver.cpp:218] Iteration 3736000 (16.8067 iter/s, 29.7501s/500 iters), loss = 0.167513
I0831 23:40:22.352941 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.167515 (* 1 = 0.167515 loss)
I0831 23:40:22.352949 916722 sgd_solver.cpp:106] Iteration 3736000, lr = 0.01
I0831 23:40:52.100842 916722 solver.cpp:218] Iteration 3736500 (16.8079 iter/s, 29.7479s/500 iters), loss = 0.200331
I0831 23:40:52.100903 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.200333 (* 1 = 0.200333 loss)
I0831 23:40:52.100910 916722 sgd_solver.cpp:106] Iteration 3736500, lr = 0.01
I0831 23:41:21.846715 916722 solver.cpp:218] Iteration 3737000 (16.8091 iter/s, 29.7458s/500 iters), loss = 0.0391549
I0831 23:41:21.846768 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0391573 (* 1 = 0.0391573 loss)
I0831 23:41:21.846777 916722 sgd_solver.cpp:106] Iteration 3737000, lr = 0.01
I0831 23:41:51.594585 916722 solver.cpp:218] Iteration 3737500 (16.808 iter/s, 29.7478s/500 iters), loss = 0.142778
I0831 23:41:51.594645 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.14278 (* 1 = 0.14278 loss)
I0831 23:41:51.594655 916722 sgd_solver.cpp:106] Iteration 3737500, lr = 0.01
I0831 23:42:21.340324 916722 solver.cpp:218] Iteration 3738000 (16.8092 iter/s, 29.7456s/500 iters), loss = 0.16822
I0831 23:42:21.340377 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.168222 (* 1 = 0.168222 loss)
I0831 23:42:21.340386 916722 sgd_solver.cpp:106] Iteration 3738000, lr = 0.01
I0831 23:42:51.092939 916722 solver.cpp:218] Iteration 3738500 (16.8053 iter/s, 29.7525s/500 iters), loss = 0.087468
I0831 23:42:51.093014 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0874703 (* 1 = 0.0874703 loss)
I0831 23:42:51.093024 916722 sgd_solver.cpp:106] Iteration 3738500, lr = 0.01
I0831 23:43:20.839033 916722 solver.cpp:218] Iteration 3739000 (16.8092 iter/s, 29.7456s/500 iters), loss = 0.0750374
I0831 23:43:20.839088 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0750398 (* 1 = 0.0750398 loss)
I0831 23:43:20.839097 916722 sgd_solver.cpp:106] Iteration 3739000, lr = 0.01
I0831 23:43:50.584720 916722 solver.cpp:218] Iteration 3739500 (16.8096 iter/s, 29.7449s/500 iters), loss = 0.0607394
I0831 23:43:50.584792 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.060742 (* 1 = 0.060742 loss)
I0831 23:43:50.584801 916722 sgd_solver.cpp:106] Iteration 3739500, lr = 0.01
I0831 23:44:20.333714 916722 solver.cpp:218] Iteration 3740000 (16.8078 iter/s, 29.7482s/500 iters), loss = 0.159017
I0831 23:44:20.333767 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159019 (* 1 = 0.159019 loss)
I0831 23:44:20.333776 916722 sgd_solver.cpp:106] Iteration 3740000, lr = 0.01
I0831 23:44:50.084627 916722 solver.cpp:218] Iteration 3740500 (16.8066 iter/s, 29.7501s/500 iters), loss = 0.579977
I0831 23:44:50.084688 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.579979 (* 1 = 0.579979 loss)
I0831 23:44:50.084697 916722 sgd_solver.cpp:106] Iteration 3740500, lr = 0.01
I0831 23:45:19.833186 916722 solver.cpp:218] Iteration 3741000 (16.808 iter/s, 29.7478s/500 iters), loss = 0.131856
I0831 23:45:19.833240 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131859 (* 1 = 0.131859 loss)
I0831 23:45:19.833250 916722 sgd_solver.cpp:106] Iteration 3741000, lr = 0.01
I0831 23:45:49.585458 916722 solver.cpp:218] Iteration 3741500 (16.8058 iter/s, 29.7516s/500 iters), loss = 0.0708087
I0831 23:45:49.585515 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0708112 (* 1 = 0.0708112 loss)
I0831 23:45:49.585523 916722 sgd_solver.cpp:106] Iteration 3741500, lr = 0.01
I0831 23:46:19.333881 916722 solver.cpp:218] Iteration 3742000 (16.808 iter/s, 29.7477s/500 iters), loss = 0.120404
I0831 23:46:19.333931 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.120407 (* 1 = 0.120407 loss)
I0831 23:46:19.333941 916722 sgd_solver.cpp:106] Iteration 3742000, lr = 0.01
I0831 23:46:49.087533 916722 solver.cpp:218] Iteration 3742500 (16.805 iter/s, 29.753s/500 iters), loss = 0.0588893
I0831 23:46:49.087591 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0588918 (* 1 = 0.0588918 loss)
I0831 23:46:49.087600 916722 sgd_solver.cpp:106] Iteration 3742500, lr = 0.01
I0831 23:47:18.842939 916722 solver.cpp:218] Iteration 3743000 (16.804 iter/s, 29.7548s/500 iters), loss = 0.318794
I0831 23:47:18.842993 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.318797 (* 1 = 0.318797 loss)
I0831 23:47:18.843003 916722 sgd_solver.cpp:106] Iteration 3743000, lr = 0.01
I0831 23:47:48.596108 916722 solver.cpp:218] Iteration 3743500 (16.8053 iter/s, 29.7526s/500 iters), loss = 0.0731409
I0831 23:47:48.596165 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0731432 (* 1 = 0.0731432 loss)
I0831 23:47:48.596174 916722 sgd_solver.cpp:106] Iteration 3743500, lr = 0.01
I0831 23:48:18.349001 916722 solver.cpp:218] Iteration 3744000 (16.8054 iter/s, 29.7523s/500 iters), loss = 0.177171
I0831 23:48:18.349053 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.177173 (* 1 = 0.177173 loss)
I0831 23:48:18.349063 916722 sgd_solver.cpp:106] Iteration 3744000, lr = 0.01
I0831 23:48:48.098007 916722 solver.cpp:218] Iteration 3744500 (16.8076 iter/s, 29.7484s/500 iters), loss = 0.172478
I0831 23:48:48.098064 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.17248 (* 1 = 0.17248 loss)
I0831 23:48:48.098073 916722 sgd_solver.cpp:106] Iteration 3744500, lr = 0.01
I0831 23:49:17.847230 916722 solver.cpp:218] Iteration 3745000 (16.8075 iter/s, 29.7487s/500 iters), loss = 0.256229
I0831 23:49:17.847282 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.256231 (* 1 = 0.256231 loss)
I0831 23:49:17.847304 916722 sgd_solver.cpp:106] Iteration 3745000, lr = 0.01
I0831 23:49:47.594364 916722 solver.cpp:218] Iteration 3745500 (16.8086 iter/s, 29.7466s/500 iters), loss = 0.223932
I0831 23:49:47.594430 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.223934 (* 1 = 0.223934 loss)
I0831 23:49:47.594439 916722 sgd_solver.cpp:106] Iteration 3745500, lr = 0.01
I0831 23:50:17.343565 916722 solver.cpp:218] Iteration 3746000 (16.8075 iter/s, 29.7487s/500 iters), loss = 0.167435
I0831 23:50:17.343616 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.167437 (* 1 = 0.167437 loss)
I0831 23:50:17.343626 916722 sgd_solver.cpp:106] Iteration 3746000, lr = 0.01
I0831 23:50:47.095628 916722 solver.cpp:218] Iteration 3746500 (16.8058 iter/s, 29.7516s/500 iters), loss = 0.041575
I0831 23:50:47.095685 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.041577 (* 1 = 0.041577 loss)
I0831 23:50:47.095693 916722 sgd_solver.cpp:106] Iteration 3746500, lr = 0.01
I0831 23:51:16.849577 916722 solver.cpp:218] Iteration 3747000 (16.8048 iter/s, 29.7535s/500 iters), loss = 0.0950043
I0831 23:51:16.849627 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0950063 (* 1 = 0.0950063 loss)
I0831 23:51:16.849635 916722 sgd_solver.cpp:106] Iteration 3747000, lr = 0.01
I0831 23:51:46.603621 916722 solver.cpp:218] Iteration 3747500 (16.8047 iter/s, 29.7536s/500 iters), loss = 0.181895
I0831 23:51:46.603679 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.181897 (* 1 = 0.181897 loss)
I0831 23:51:46.603688 916722 sgd_solver.cpp:106] Iteration 3747500, lr = 0.01
I0831 23:52:16.354024 916722 solver.cpp:218] Iteration 3748000 (16.8068 iter/s, 29.7499s/500 iters), loss = 0.135793
I0831 23:52:16.354075 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.135795 (* 1 = 0.135795 loss)
I0831 23:52:16.354084 916722 sgd_solver.cpp:106] Iteration 3748000, lr = 0.01
I0831 23:52:46.103153 916722 solver.cpp:218] Iteration 3748500 (16.8075 iter/s, 29.7487s/500 iters), loss = 0.140444
I0831 23:52:46.103212 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.140446 (* 1 = 0.140446 loss)
I0831 23:52:46.103221 916722 sgd_solver.cpp:106] Iteration 3748500, lr = 0.01
I0831 23:53:15.853142 916722 solver.cpp:218] Iteration 3749000 (16.807 iter/s, 29.7496s/500 iters), loss = 0.0987677
I0831 23:53:15.853193 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0987699 (* 1 = 0.0987699 loss)
I0831 23:53:15.853201 916722 sgd_solver.cpp:106] Iteration 3749000, lr = 0.01
I0831 23:53:45.602002 916722 solver.cpp:218] Iteration 3749500 (16.8076 iter/s, 29.7485s/500 iters), loss = 0.0115167
I0831 23:53:45.602062 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0115189 (* 1 = 0.0115189 loss)
I0831 23:53:45.602070 916722 sgd_solver.cpp:106] Iteration 3749500, lr = 0.01
I0831 23:54:15.294201 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_3750000.caffemodel
I0831 23:54:15.313920 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_3750000.solverstate
I0831 23:54:15.319962 916722 solver.cpp:330] Iteration 3750000, Testing net (#0)
I0831 23:54:30.755620 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8677
I0831 23:54:30.755673 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.441069 (* 1 = 0.441069 loss)
I0831 23:54:30.814160 916722 solver.cpp:218] Iteration 3750000 (11.0591 iter/s, 45.2116s/500 iters), loss = 0.140869
I0831 23:54:30.814188 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.140871 (* 1 = 0.140871 loss)
I0831 23:54:30.814195 916722 sgd_solver.cpp:106] Iteration 3750000, lr = 0.01
I0831 23:55:00.430238 916722 solver.cpp:218] Iteration 3750500 (16.8829 iter/s, 29.6157s/500 iters), loss = 0.396493
I0831 23:55:00.430289 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.396496 (* 1 = 0.396496 loss)
I0831 23:55:00.430308 916722 sgd_solver.cpp:106] Iteration 3750500, lr = 0.01
I0831 23:55:30.143059 916722 solver.cpp:218] Iteration 3751000 (16.828 iter/s, 29.7124s/500 iters), loss = 0.0229373
I0831 23:55:30.143131 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0229399 (* 1 = 0.0229399 loss)
I0831 23:55:30.143138 916722 sgd_solver.cpp:106] Iteration 3751000, lr = 0.01
I0831 23:55:59.858947 916722 solver.cpp:218] Iteration 3751500 (16.8262 iter/s, 29.7155s/500 iters), loss = 0.0344403
I0831 23:55:59.858999 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0344428 (* 1 = 0.0344428 loss)
I0831 23:55:59.859007 916722 sgd_solver.cpp:106] Iteration 3751500, lr = 0.01
I0831 23:56:29.579936 916722 solver.cpp:218] Iteration 3752000 (16.8233 iter/s, 29.7206s/500 iters), loss = 0.0424234
I0831 23:56:29.579998 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.042426 (* 1 = 0.042426 loss)
I0831 23:56:29.580006 916722 sgd_solver.cpp:106] Iteration 3752000, lr = 0.01
I0831 23:56:59.302168 916722 solver.cpp:218] Iteration 3752500 (16.8226 iter/s, 29.7219s/500 iters), loss = 0.069562
I0831 23:56:59.302220 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0695646 (* 1 = 0.0695646 loss)
I0831 23:56:59.302229 916722 sgd_solver.cpp:106] Iteration 3752500, lr = 0.01
I0831 23:57:29.025068 916722 solver.cpp:218] Iteration 3753000 (16.8222 iter/s, 29.7226s/500 iters), loss = 0.28304
I0831 23:57:29.025125 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.283043 (* 1 = 0.283043 loss)
I0831 23:57:29.025133 916722 sgd_solver.cpp:106] Iteration 3753000, lr = 0.01
I0831 23:57:58.746909 916722 solver.cpp:218] Iteration 3753500 (16.8228 iter/s, 29.7215s/500 iters), loss = 0.115849
I0831 23:57:58.746961 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115851 (* 1 = 0.115851 loss)
I0831 23:57:58.746970 916722 sgd_solver.cpp:106] Iteration 3753500, lr = 0.01
I0831 23:58:28.474999 916722 solver.cpp:218] Iteration 3754000 (16.8193 iter/s, 29.7278s/500 iters), loss = 0.115017
I0831 23:58:28.475061 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.11502 (* 1 = 0.11502 loss)
I0831 23:58:28.475069 916722 sgd_solver.cpp:106] Iteration 3754000, lr = 0.01
I0831 23:58:58.200130 916722 solver.cpp:218] Iteration 3754500 (16.821 iter/s, 29.7248s/500 iters), loss = 0.0275006
I0831 23:58:58.200182 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0275032 (* 1 = 0.0275032 loss)
I0831 23:58:58.200191 916722 sgd_solver.cpp:106] Iteration 3754500, lr = 0.01
I0831 23:59:27.926954 916722 solver.cpp:218] Iteration 3755000 (16.82 iter/s, 29.7265s/500 iters), loss = 0.11912
I0831 23:59:27.927014 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.119123 (* 1 = 0.119123 loss)
I0831 23:59:27.927023 916722 sgd_solver.cpp:106] Iteration 3755000, lr = 0.01
I0831 23:59:57.648759 916722 solver.cpp:218] Iteration 3755500 (16.8228 iter/s, 29.7215s/500 iters), loss = 0.0454289
I0831 23:59:57.648810 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0454316 (* 1 = 0.0454316 loss)
I0831 23:59:57.648819 916722 sgd_solver.cpp:106] Iteration 3755500, lr = 0.01
I0901 00:00:27.376760 916722 solver.cpp:218] Iteration 3756000 (16.8193 iter/s, 29.7277s/500 iters), loss = 0.100767
I0901 00:00:27.376814 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.10077 (* 1 = 0.10077 loss)
I0901 00:00:27.376822 916722 sgd_solver.cpp:106] Iteration 3756000, lr = 0.01
I0901 00:00:57.101366 916722 solver.cpp:218] Iteration 3756500 (16.8212 iter/s, 29.7243s/500 iters), loss = 0.173707
I0901 00:00:57.101418 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.173709 (* 1 = 0.173709 loss)
I0901 00:00:57.101429 916722 sgd_solver.cpp:106] Iteration 3756500, lr = 0.01
I0901 00:01:26.824247 916722 solver.cpp:218] Iteration 3757000 (16.8222 iter/s, 29.7226s/500 iters), loss = 0.0402297
I0901 00:01:26.824303 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0402325 (* 1 = 0.0402325 loss)
I0901 00:01:26.824312 916722 sgd_solver.cpp:106] Iteration 3757000, lr = 0.01
I0901 00:01:56.553063 916722 solver.cpp:218] Iteration 3757500 (16.8189 iter/s, 29.7285s/500 iters), loss = 0.0640723
I0901 00:01:56.553115 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0640752 (* 1 = 0.0640752 loss)
I0901 00:01:56.553125 916722 sgd_solver.cpp:106] Iteration 3757500, lr = 0.01
I0901 00:02:26.281529 916722 solver.cpp:218] Iteration 3758000 (16.8191 iter/s, 29.7282s/500 iters), loss = 0.131033
I0901 00:02:26.281600 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131036 (* 1 = 0.131036 loss)
I0901 00:02:26.281610 916722 sgd_solver.cpp:106] Iteration 3758000, lr = 0.01
I0901 00:02:56.005710 916722 solver.cpp:218] Iteration 3758500 (16.8215 iter/s, 29.7239s/500 iters), loss = 0.0315635
I0901 00:02:56.005764 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0315665 (* 1 = 0.0315665 loss)
I0901 00:02:56.005775 916722 sgd_solver.cpp:106] Iteration 3758500, lr = 0.01
I0901 00:03:25.733819 916722 solver.cpp:218] Iteration 3759000 (16.8193 iter/s, 29.7278s/500 iters), loss = 0.264967
I0901 00:03:25.733877 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.26497 (* 1 = 0.26497 loss)
I0901 00:03:25.733886 916722 sgd_solver.cpp:106] Iteration 3759000, lr = 0.01
I0901 00:03:55.459784 916722 solver.cpp:218] Iteration 3759500 (16.8205 iter/s, 29.7257s/500 iters), loss = 0.153675
I0901 00:03:55.459836 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.153677 (* 1 = 0.153677 loss)
I0901 00:03:55.459847 916722 sgd_solver.cpp:106] Iteration 3759500, lr = 0.01
I0901 00:04:25.181346 916722 solver.cpp:218] Iteration 3760000 (16.823 iter/s, 29.7213s/500 iters), loss = 0.0573509
I0901 00:04:25.181404 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0573538 (* 1 = 0.0573538 loss)
I0901 00:04:25.181413 916722 sgd_solver.cpp:106] Iteration 3760000, lr = 0.01
I0901 00:04:54.904824 916722 solver.cpp:218] Iteration 3760500 (16.8219 iter/s, 29.7232s/500 iters), loss = 0.0384285
I0901 00:04:54.904875 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0384314 (* 1 = 0.0384314 loss)
I0901 00:04:54.904886 916722 sgd_solver.cpp:106] Iteration 3760500, lr = 0.01
I0901 00:05:24.623574 916722 solver.cpp:218] Iteration 3761000 (16.8245 iter/s, 29.7185s/500 iters), loss = 0.0681534
I0901 00:05:24.623629 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0681563 (* 1 = 0.0681563 loss)
I0901 00:05:24.623638 916722 sgd_solver.cpp:106] Iteration 3761000, lr = 0.01
I0901 00:05:54.344161 916722 solver.cpp:218] Iteration 3761500 (16.8235 iter/s, 29.7203s/500 iters), loss = 0.108697
I0901 00:05:54.344211 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.1087 (* 1 = 0.1087 loss)
I0901 00:05:54.344221 916722 sgd_solver.cpp:106] Iteration 3761500, lr = 0.01
I0901 00:06:24.069737 916722 solver.cpp:218] Iteration 3762000 (16.8207 iter/s, 29.7253s/500 iters), loss = 0.0616021
I0901 00:06:24.069798 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0616048 (* 1 = 0.0616048 loss)
I0901 00:06:24.069806 916722 sgd_solver.cpp:106] Iteration 3762000, lr = 0.01
I0901 00:06:53.791404 916722 solver.cpp:218] Iteration 3762500 (16.8229 iter/s, 29.7214s/500 iters), loss = 0.0900542
I0901 00:06:53.791457 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0900572 (* 1 = 0.0900572 loss)
I0901 00:06:53.791465 916722 sgd_solver.cpp:106] Iteration 3762500, lr = 0.01
I0901 00:07:23.512943 916722 solver.cpp:218] Iteration 3763000 (16.823 iter/s, 29.7213s/500 iters), loss = 0.116699
I0901 00:07:23.513003 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.116702 (* 1 = 0.116702 loss)
I0901 00:07:23.513012 916722 sgd_solver.cpp:106] Iteration 3763000, lr = 0.01
I0901 00:07:53.233423 916722 solver.cpp:218] Iteration 3763500 (16.8236 iter/s, 29.7202s/500 iters), loss = 0.0902139
I0901 00:07:53.233475 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0902169 (* 1 = 0.0902169 loss)
I0901 00:07:53.233484 916722 sgd_solver.cpp:106] Iteration 3763500, lr = 0.01
I0901 00:08:22.956876 916722 solver.cpp:218] Iteration 3764000 (16.8219 iter/s, 29.7232s/500 iters), loss = 0.139884
I0901 00:08:22.956943 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139887 (* 1 = 0.139887 loss)
I0901 00:08:22.956952 916722 sgd_solver.cpp:106] Iteration 3764000, lr = 0.01
I0901 00:08:52.679327 916722 solver.cpp:218] Iteration 3764500 (16.8224 iter/s, 29.7222s/500 iters), loss = 0.0899853
I0901 00:08:52.679380 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0899884 (* 1 = 0.0899884 loss)
I0901 00:08:52.679389 916722 sgd_solver.cpp:106] Iteration 3764500, lr = 0.01
I0901 00:09:22.402130 916722 solver.cpp:218] Iteration 3765000 (16.8222 iter/s, 29.7226s/500 iters), loss = 0.0128752
I0901 00:09:22.402190 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.012878 (* 1 = 0.012878 loss)
I0901 00:09:22.402199 916722 sgd_solver.cpp:106] Iteration 3765000, lr = 0.01
I0901 00:09:52.124923 916722 solver.cpp:218] Iteration 3765500 (16.8222 iter/s, 29.7225s/500 iters), loss = 0.226653
I0901 00:09:52.124975 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.226656 (* 1 = 0.226656 loss)
I0901 00:09:52.124984 916722 sgd_solver.cpp:106] Iteration 3765500, lr = 0.01
I0901 00:10:21.857345 916722 solver.cpp:218] Iteration 3766000 (16.8168 iter/s, 29.7322s/500 iters), loss = 0.0352219
I0901 00:10:21.857401 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0352248 (* 1 = 0.0352248 loss)
I0901 00:10:21.857410 916722 sgd_solver.cpp:106] Iteration 3766000, lr = 0.01
I0901 00:10:51.583570 916722 solver.cpp:218] Iteration 3766500 (16.8203 iter/s, 29.726s/500 iters), loss = 0.162605
I0901 00:10:51.583622 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.162608 (* 1 = 0.162608 loss)
I0901 00:10:51.583631 916722 sgd_solver.cpp:106] Iteration 3766500, lr = 0.01
I0901 00:11:21.314949 916722 solver.cpp:218] Iteration 3767000 (16.8174 iter/s, 29.7311s/500 iters), loss = 0.197064
I0901 00:11:21.315007 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.197067 (* 1 = 0.197067 loss)
I0901 00:11:21.315016 916722 sgd_solver.cpp:106] Iteration 3767000, lr = 0.01
I0901 00:11:51.037642 916722 solver.cpp:218] Iteration 3767500 (16.8223 iter/s, 29.7225s/500 iters), loss = 0.140718
I0901 00:11:51.037693 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.140721 (* 1 = 0.140721 loss)
I0901 00:11:51.037703 916722 sgd_solver.cpp:106] Iteration 3767500, lr = 0.01
I0901 00:12:20.759770 916722 solver.cpp:218] Iteration 3768000 (16.8226 iter/s, 29.7219s/500 iters), loss = 0.3353
I0901 00:12:20.759829 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.335303 (* 1 = 0.335303 loss)
I0901 00:12:20.759837 916722 sgd_solver.cpp:106] Iteration 3768000, lr = 0.01
I0901 00:12:50.483309 916722 solver.cpp:218] Iteration 3768500 (16.8218 iter/s, 29.7233s/500 iters), loss = 0.0719013
I0901 00:12:50.483366 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0719044 (* 1 = 0.0719044 loss)
I0901 00:12:50.483376 916722 sgd_solver.cpp:106] Iteration 3768500, lr = 0.01
I0901 00:13:20.203029 916722 solver.cpp:218] Iteration 3769000 (16.824 iter/s, 29.7195s/500 iters), loss = 0.340199
I0901 00:13:20.203086 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.340202 (* 1 = 0.340202 loss)
I0901 00:13:20.203094 916722 sgd_solver.cpp:106] Iteration 3769000, lr = 0.01
I0901 00:13:49.928297 916722 solver.cpp:218] Iteration 3769500 (16.8208 iter/s, 29.725s/500 iters), loss = 0.0453309
I0901 00:13:49.928349 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0453339 (* 1 = 0.0453339 loss)
I0901 00:13:49.928359 916722 sgd_solver.cpp:106] Iteration 3769500, lr = 0.01
I0901 00:14:19.648559 916722 solver.cpp:218] Iteration 3770000 (16.8237 iter/s, 29.72s/500 iters), loss = 0.0335819
I0901 00:14:19.648614 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0335851 (* 1 = 0.0335851 loss)
I0901 00:14:19.648623 916722 sgd_solver.cpp:106] Iteration 3770000, lr = 0.01
I0901 00:14:49.367764 916722 solver.cpp:218] Iteration 3770500 (16.8243 iter/s, 29.719s/500 iters), loss = 0.132351
I0901 00:14:49.367822 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.132355 (* 1 = 0.132355 loss)
I0901 00:14:49.367833 916722 sgd_solver.cpp:106] Iteration 3770500, lr = 0.01
I0901 00:15:19.087298 916722 solver.cpp:218] Iteration 3771000 (16.8241 iter/s, 29.7193s/500 iters), loss = 0.106472
I0901 00:15:19.087366 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.106475 (* 1 = 0.106475 loss)
I0901 00:15:19.087374 916722 sgd_solver.cpp:106] Iteration 3771000, lr = 0.01
I0901 00:15:48.805686 916722 solver.cpp:218] Iteration 3771500 (16.8247 iter/s, 29.7182s/500 iters), loss = 0.225377
I0901 00:15:48.805738 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.22538 (* 1 = 0.22538 loss)
I0901 00:15:48.805749 916722 sgd_solver.cpp:106] Iteration 3771500, lr = 0.01
I0901 00:16:18.525750 916722 solver.cpp:218] Iteration 3772000 (16.8238 iter/s, 29.7198s/500 iters), loss = 0.186187
I0901 00:16:18.525810 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.186191 (* 1 = 0.186191 loss)
I0901 00:16:18.525818 916722 sgd_solver.cpp:106] Iteration 3772000, lr = 0.01
I0901 00:16:48.247648 916722 solver.cpp:218] Iteration 3772500 (16.8227 iter/s, 29.7217s/500 iters), loss = 0.172428
I0901 00:16:48.247702 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.172431 (* 1 = 0.172431 loss)
I0901 00:16:48.247712 916722 sgd_solver.cpp:106] Iteration 3772500, lr = 0.01
I0901 00:17:17.969238 916722 solver.cpp:218] Iteration 3773000 (16.8229 iter/s, 29.7214s/500 iters), loss = 0.0544983
I0901 00:17:17.969295 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0545013 (* 1 = 0.0545013 loss)
I0901 00:17:17.969303 916722 sgd_solver.cpp:106] Iteration 3773000, lr = 0.01
I0901 00:17:47.693727 916722 solver.cpp:218] Iteration 3773500 (16.821 iter/s, 29.7247s/500 iters), loss = 0.214691
I0901 00:17:47.693784 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.214694 (* 1 = 0.214694 loss)
I0901 00:17:47.693794 916722 sgd_solver.cpp:106] Iteration 3773500, lr = 0.01
I0901 00:18:17.418464 916722 solver.cpp:218] Iteration 3774000 (16.8209 iter/s, 29.7249s/500 iters), loss = 0.0878718
I0901 00:18:17.418522 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0878747 (* 1 = 0.0878747 loss)
I0901 00:18:17.418531 916722 sgd_solver.cpp:106] Iteration 3774000, lr = 0.01
I0901 00:18:47.142887 916722 solver.cpp:218] Iteration 3774500 (16.8211 iter/s, 29.7246s/500 iters), loss = 0.0978644
I0901 00:18:47.142941 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0978674 (* 1 = 0.0978674 loss)
I0901 00:18:47.142951 916722 sgd_solver.cpp:106] Iteration 3774500, lr = 0.01
I0901 00:19:16.866874 916722 solver.cpp:218] Iteration 3775000 (16.8213 iter/s, 29.7241s/500 iters), loss = 0.196769
I0901 00:19:16.866935 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.196772 (* 1 = 0.196772 loss)
I0901 00:19:16.866945 916722 sgd_solver.cpp:106] Iteration 3775000, lr = 0.01
I0901 00:19:46.591213 916722 solver.cpp:218] Iteration 3775500 (16.8212 iter/s, 29.7245s/500 iters), loss = 0.207936
I0901 00:19:46.591266 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.207939 (* 1 = 0.207939 loss)
I0901 00:19:46.591274 916722 sgd_solver.cpp:106] Iteration 3775500, lr = 0.01
I0901 00:20:16.312839 916722 solver.cpp:218] Iteration 3776000 (16.8227 iter/s, 29.7218s/500 iters), loss = 0.0202594
I0901 00:20:16.312898 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0202626 (* 1 = 0.0202626 loss)
I0901 00:20:16.312906 916722 sgd_solver.cpp:106] Iteration 3776000, lr = 0.01
I0901 00:20:46.037794 916722 solver.cpp:218] Iteration 3776500 (16.8208 iter/s, 29.7251s/500 iters), loss = 0.0320084
I0901 00:20:46.037847 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0320115 (* 1 = 0.0320115 loss)
I0901 00:20:46.037855 916722 sgd_solver.cpp:106] Iteration 3776500, lr = 0.01
I0901 00:21:15.759552 916722 solver.cpp:218] Iteration 3777000 (16.8226 iter/s, 29.7219s/500 iters), loss = 0.194272
I0901 00:21:15.759624 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.194275 (* 1 = 0.194275 loss)
I0901 00:21:15.759631 916722 sgd_solver.cpp:106] Iteration 3777000, lr = 0.01
I0901 00:21:45.481966 916722 solver.cpp:218] Iteration 3777500 (16.8223 iter/s, 29.7225s/500 iters), loss = 0.286077
I0901 00:21:45.482014 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.28608 (* 1 = 0.28608 loss)
I0901 00:21:45.482023 916722 sgd_solver.cpp:106] Iteration 3777500, lr = 0.01
I0901 00:22:15.207439 916722 solver.cpp:218] Iteration 3778000 (16.8205 iter/s, 29.7256s/500 iters), loss = 0.158476
I0901 00:22:15.207499 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.158479 (* 1 = 0.158479 loss)
I0901 00:22:15.207506 916722 sgd_solver.cpp:106] Iteration 3778000, lr = 0.01
I0901 00:22:44.934406 916722 solver.cpp:218] Iteration 3778500 (16.8197 iter/s, 29.727s/500 iters), loss = 0.111415
I0901 00:22:44.934459 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111418 (* 1 = 0.111418 loss)
I0901 00:22:44.934468 916722 sgd_solver.cpp:106] Iteration 3778500, lr = 0.01
I0901 00:23:14.659047 916722 solver.cpp:218] Iteration 3779000 (16.821 iter/s, 29.7247s/500 iters), loss = 0.0474255
I0901 00:23:14.659106 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0474284 (* 1 = 0.0474284 loss)
I0901 00:23:14.659116 916722 sgd_solver.cpp:106] Iteration 3779000, lr = 0.01
I0901 00:23:44.383080 916722 solver.cpp:218] Iteration 3779500 (16.8214 iter/s, 29.7241s/500 iters), loss = 0.257016
I0901 00:23:44.383131 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.257019 (* 1 = 0.257019 loss)
I0901 00:23:44.383141 916722 sgd_solver.cpp:106] Iteration 3779500, lr = 0.01
I0901 00:24:14.107561 916722 solver.cpp:218] Iteration 3780000 (16.8211 iter/s, 29.7245s/500 iters), loss = 0.0484112
I0901 00:24:14.107620 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0484142 (* 1 = 0.0484142 loss)
I0901 00:24:14.107630 916722 sgd_solver.cpp:106] Iteration 3780000, lr = 0.01
I0901 00:24:43.830467 916722 solver.cpp:218] Iteration 3780500 (16.822 iter/s, 29.7229s/500 iters), loss = 0.0141512
I0901 00:24:43.830520 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0141543 (* 1 = 0.0141543 loss)
I0901 00:24:43.830529 916722 sgd_solver.cpp:106] Iteration 3780500, lr = 0.01
I0901 00:25:13.557199 916722 solver.cpp:218] Iteration 3781000 (16.8199 iter/s, 29.7267s/500 iters), loss = 0.158168
I0901 00:25:13.557256 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.158171 (* 1 = 0.158171 loss)
I0901 00:25:13.557265 916722 sgd_solver.cpp:106] Iteration 3781000, lr = 0.01
I0901 00:25:43.279220 916722 solver.cpp:218] Iteration 3781500 (16.8225 iter/s, 29.722s/500 iters), loss = 0.186832
I0901 00:25:43.279275 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.186835 (* 1 = 0.186835 loss)
I0901 00:25:43.279285 916722 sgd_solver.cpp:106] Iteration 3781500, lr = 0.01
I0901 00:26:13.005349 916722 solver.cpp:218] Iteration 3782000 (16.8202 iter/s, 29.7261s/500 iters), loss = 0.0648699
I0901 00:26:13.005403 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.064873 (* 1 = 0.064873 loss)
I0901 00:26:13.005412 916722 sgd_solver.cpp:106] Iteration 3782000, lr = 0.01
I0901 00:26:42.731724 916722 solver.cpp:218] Iteration 3782500 (16.8201 iter/s, 29.7264s/500 iters), loss = 0.223318
I0901 00:26:42.731776 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.223321 (* 1 = 0.223321 loss)
I0901 00:26:42.731786 916722 sgd_solver.cpp:106] Iteration 3782500, lr = 0.01
I0901 00:27:12.456542 916722 solver.cpp:218] Iteration 3783000 (16.821 iter/s, 29.7248s/500 iters), loss = 0.303249
I0901 00:27:12.456600 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.303252 (* 1 = 0.303252 loss)
I0901 00:27:12.456609 916722 sgd_solver.cpp:106] Iteration 3783000, lr = 0.01
I0901 00:27:42.185135 916722 solver.cpp:218] Iteration 3783500 (16.8188 iter/s, 29.7286s/500 iters), loss = 0.340883
I0901 00:27:42.185187 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.340886 (* 1 = 0.340886 loss)
I0901 00:27:42.185209 916722 sgd_solver.cpp:106] Iteration 3783500, lr = 0.01
I0901 00:28:11.912724 916722 solver.cpp:218] Iteration 3784000 (16.8194 iter/s, 29.7276s/500 iters), loss = 0.0826931
I0901 00:28:11.912801 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0826959 (* 1 = 0.0826959 loss)
I0901 00:28:11.912809 916722 sgd_solver.cpp:106] Iteration 3784000, lr = 0.01
I0901 00:28:41.639091 916722 solver.cpp:218] Iteration 3784500 (16.8201 iter/s, 29.7263s/500 iters), loss = 0.171357
I0901 00:28:41.639142 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.17136 (* 1 = 0.17136 loss)
I0901 00:28:41.639153 916722 sgd_solver.cpp:106] Iteration 3784500, lr = 0.01
I0901 00:29:11.364923 916722 solver.cpp:218] Iteration 3785000 (16.8204 iter/s, 29.7258s/500 iters), loss = 0.210338
I0901 00:29:11.364980 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.210341 (* 1 = 0.210341 loss)
I0901 00:29:11.364989 916722 sgd_solver.cpp:106] Iteration 3785000, lr = 0.01
I0901 00:29:41.093919 916722 solver.cpp:218] Iteration 3785500 (16.8186 iter/s, 29.7289s/500 iters), loss = 0.160563
I0901 00:29:41.093968 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.160566 (* 1 = 0.160566 loss)
I0901 00:29:41.093979 916722 sgd_solver.cpp:106] Iteration 3785500, lr = 0.01
I0901 00:30:10.818781 916722 solver.cpp:218] Iteration 3786000 (16.821 iter/s, 29.7248s/500 iters), loss = 0.0860603
I0901 00:30:10.818835 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.086063 (* 1 = 0.086063 loss)
I0901 00:30:10.818843 916722 sgd_solver.cpp:106] Iteration 3786000, lr = 0.01
I0901 00:30:40.547834 916722 solver.cpp:218] Iteration 3786500 (16.8186 iter/s, 29.729s/500 iters), loss = 0.200205
I0901 00:30:40.547884 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.200208 (* 1 = 0.200208 loss)
I0901 00:30:40.547894 916722 sgd_solver.cpp:106] Iteration 3786500, lr = 0.01
I0901 00:31:10.273289 916722 solver.cpp:218] Iteration 3787000 (16.8206 iter/s, 29.7254s/500 iters), loss = 0.404214
I0901 00:31:10.273350 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.404217 (* 1 = 0.404217 loss)
I0901 00:31:10.273358 916722 sgd_solver.cpp:106] Iteration 3787000, lr = 0.01
I0901 00:31:39.996788 916722 solver.cpp:218] Iteration 3787500 (16.8218 iter/s, 29.7234s/500 iters), loss = 0.11827
I0901 00:31:39.996841 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.118273 (* 1 = 0.118273 loss)
I0901 00:31:39.996850 916722 sgd_solver.cpp:106] Iteration 3787500, lr = 0.01
I0901 00:32:09.722069 916722 solver.cpp:218] Iteration 3788000 (16.8207 iter/s, 29.7252s/500 iters), loss = 0.0966922
I0901 00:32:09.722126 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0966949 (* 1 = 0.0966949 loss)
I0901 00:32:09.722134 916722 sgd_solver.cpp:106] Iteration 3788000, lr = 0.01
I0901 00:32:39.444789 916722 solver.cpp:218] Iteration 3788500 (16.8222 iter/s, 29.7226s/500 iters), loss = 0.0573704
I0901 00:32:39.444841 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.057373 (* 1 = 0.057373 loss)
I0901 00:32:39.444850 916722 sgd_solver.cpp:106] Iteration 3788500, lr = 0.01
I0901 00:33:09.172106 916722 solver.cpp:218] Iteration 3789000 (16.8196 iter/s, 29.7272s/500 iters), loss = 0.236201
I0901 00:33:09.172163 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.236204 (* 1 = 0.236204 loss)
I0901 00:33:09.172171 916722 sgd_solver.cpp:106] Iteration 3789000, lr = 0.01
I0901 00:33:38.895910 916722 solver.cpp:218] Iteration 3789500 (16.8216 iter/s, 29.7237s/500 iters), loss = 0.019367
I0901 00:33:38.895960 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0193697 (* 1 = 0.0193697 loss)
I0901 00:33:38.895969 916722 sgd_solver.cpp:106] Iteration 3789500, lr = 0.01
I0901 00:34:08.623457 916722 solver.cpp:218] Iteration 3790000 (16.8195 iter/s, 29.7275s/500 iters), loss = 0.143897
I0901 00:34:08.623524 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.1439 (* 1 = 0.1439 loss)
I0901 00:34:08.623538 916722 sgd_solver.cpp:106] Iteration 3790000, lr = 0.01
I0901 00:34:38.351591 916722 solver.cpp:218] Iteration 3790500 (16.8191 iter/s, 29.728s/500 iters), loss = 0.206298
I0901 00:34:38.351640 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.206301 (* 1 = 0.206301 loss)
I0901 00:34:38.351649 916722 sgd_solver.cpp:106] Iteration 3790500, lr = 0.01
I0901 00:35:08.079371 916722 solver.cpp:218] Iteration 3791000 (16.8193 iter/s, 29.7277s/500 iters), loss = 0.0471956
I0901 00:35:08.079425 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0471978 (* 1 = 0.0471978 loss)
I0901 00:35:08.079433 916722 sgd_solver.cpp:106] Iteration 3791000, lr = 0.01
I0901 00:35:37.806912 916722 solver.cpp:218] Iteration 3791500 (16.8195 iter/s, 29.7274s/500 iters), loss = 0.148117
I0901 00:35:37.806964 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.148119 (* 1 = 0.148119 loss)
I0901 00:35:37.806973 916722 sgd_solver.cpp:106] Iteration 3791500, lr = 0.01
I0901 00:36:07.536540 916722 solver.cpp:218] Iteration 3792000 (16.8183 iter/s, 29.7295s/500 iters), loss = 0.0973001
I0901 00:36:07.536598 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0973022 (* 1 = 0.0973022 loss)
I0901 00:36:07.536607 916722 sgd_solver.cpp:106] Iteration 3792000, lr = 0.01
I0901 00:36:37.266554 916722 solver.cpp:218] Iteration 3792500 (16.8181 iter/s, 29.7299s/500 iters), loss = 0.0571563
I0901 00:36:37.266607 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0571585 (* 1 = 0.0571585 loss)
I0901 00:36:37.266616 916722 sgd_solver.cpp:106] Iteration 3792500, lr = 0.01
I0901 00:37:06.993853 916722 solver.cpp:218] Iteration 3793000 (16.8196 iter/s, 29.7272s/500 iters), loss = 0.0329645
I0901 00:37:06.993911 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0329666 (* 1 = 0.0329666 loss)
I0901 00:37:06.993919 916722 sgd_solver.cpp:106] Iteration 3793000, lr = 0.01
I0901 00:37:36.722342 916722 solver.cpp:218] Iteration 3793500 (16.819 iter/s, 29.7284s/500 iters), loss = 0.0873248
I0901 00:37:36.722393 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0873267 (* 1 = 0.0873267 loss)
I0901 00:37:36.722401 916722 sgd_solver.cpp:106] Iteration 3793500, lr = 0.01
I0901 00:38:06.448930 916722 solver.cpp:218] Iteration 3794000 (16.82 iter/s, 29.7265s/500 iters), loss = 0.191943
I0901 00:38:06.448985 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.191945 (* 1 = 0.191945 loss)
I0901 00:38:06.448994 916722 sgd_solver.cpp:106] Iteration 3794000, lr = 0.01
I0901 00:38:36.177947 916722 solver.cpp:218] Iteration 3794500 (16.8187 iter/s, 29.7289s/500 iters), loss = 0.0771815
I0901 00:38:36.177997 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0771833 (* 1 = 0.0771833 loss)
I0901 00:38:36.178005 916722 sgd_solver.cpp:106] Iteration 3794500, lr = 0.01
I0901 00:39:05.906656 916722 solver.cpp:218] Iteration 3795000 (16.8188 iter/s, 29.7286s/500 iters), loss = 0.0763369
I0901 00:39:05.908501 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0763387 (* 1 = 0.0763387 loss)
I0901 00:39:05.908514 916722 sgd_solver.cpp:106] Iteration 3795000, lr = 0.01
I0901 00:39:35.635414 916722 solver.cpp:218] Iteration 3795500 (16.8198 iter/s, 29.7268s/500 iters), loss = 0.0830797
I0901 00:39:35.635462 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0830816 (* 1 = 0.0830816 loss)
I0901 00:39:35.635470 916722 sgd_solver.cpp:106] Iteration 3795500, lr = 0.01
I0901 00:40:05.360203 916722 solver.cpp:218] Iteration 3796000 (16.821 iter/s, 29.7247s/500 iters), loss = 0.0507269
I0901 00:40:05.360260 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0507287 (* 1 = 0.0507287 loss)
I0901 00:40:05.360268 916722 sgd_solver.cpp:106] Iteration 3796000, lr = 0.01
I0901 00:40:35.087584 916722 solver.cpp:218] Iteration 3796500 (16.8196 iter/s, 29.7272s/500 iters), loss = 0.342203
I0901 00:40:35.087633 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.342205 (* 1 = 0.342205 loss)
I0901 00:40:35.087653 916722 sgd_solver.cpp:106] Iteration 3796500, lr = 0.01
I0901 00:41:04.812654 916722 solver.cpp:218] Iteration 3797000 (16.8209 iter/s, 29.7249s/500 iters), loss = 0.102536
I0901 00:41:04.812723 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.102537 (* 1 = 0.102537 loss)
I0901 00:41:04.812733 916722 sgd_solver.cpp:106] Iteration 3797000, lr = 0.01
I0901 00:41:34.534938 916722 solver.cpp:218] Iteration 3797500 (16.8225 iter/s, 29.7221s/500 iters), loss = 0.118347
I0901 00:41:34.534991 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.118349 (* 1 = 0.118349 loss)
I0901 00:41:34.534999 916722 sgd_solver.cpp:106] Iteration 3797500, lr = 0.01
I0901 00:42:04.259934 916722 solver.cpp:218] Iteration 3798000 (16.8209 iter/s, 29.7249s/500 iters), loss = 0.0855343
I0901 00:42:04.259991 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0855362 (* 1 = 0.0855362 loss)
I0901 00:42:04.260000 916722 sgd_solver.cpp:106] Iteration 3798000, lr = 0.01
I0901 00:42:33.988765 916722 solver.cpp:218] Iteration 3798500 (16.8188 iter/s, 29.7287s/500 iters), loss = 0.0899365
I0901 00:42:33.988817 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0899384 (* 1 = 0.0899384 loss)
I0901 00:42:33.988827 916722 sgd_solver.cpp:106] Iteration 3798500, lr = 0.01
I0901 00:43:03.715778 916722 solver.cpp:218] Iteration 3799000 (16.8198 iter/s, 29.7269s/500 iters), loss = 0.462649
I0901 00:43:03.715831 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.462651 (* 1 = 0.462651 loss)
I0901 00:43:03.715840 916722 sgd_solver.cpp:106] Iteration 3799000, lr = 0.01
I0901 00:43:33.438452 916722 solver.cpp:218] Iteration 3799500 (16.8222 iter/s, 29.7225s/500 iters), loss = 0.0736775
I0901 00:43:33.438501 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0736793 (* 1 = 0.0736793 loss)
I0901 00:43:33.438511 916722 sgd_solver.cpp:106] Iteration 3799500, lr = 0.01
I0901 00:44:03.097730 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_3800000.caffemodel
I0901 00:44:03.117075 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_3800000.solverstate
I0901 00:44:03.123126 916722 solver.cpp:330] Iteration 3800000, Testing net (#0)
I0901 00:44:18.502441 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8591
I0901 00:44:18.502492 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.490618 (* 1 = 0.490618 loss)
I0901 00:44:18.561035 916722 solver.cpp:218] Iteration 3800000 (11.081 iter/s, 45.1224s/500 iters), loss = 0.0519522
I0901 00:44:18.561064 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0519541 (* 1 = 0.0519541 loss)
I0901 00:44:18.561074 916722 sgd_solver.cpp:106] Iteration 3800000, lr = 0.01
I0901 00:44:48.178452 916722 solver.cpp:218] Iteration 3800500 (16.882 iter/s, 29.6173s/500 iters), loss = 0.163903
I0901 00:44:48.178509 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.163905 (* 1 = 0.163905 loss)
I0901 00:44:48.178517 916722 sgd_solver.cpp:106] Iteration 3800500, lr = 0.01
I0901 00:45:17.912495 916722 solver.cpp:218] Iteration 3801000 (16.8158 iter/s, 29.7339s/500 iters), loss = 0.0426468
I0901 00:45:17.912549 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0426486 (* 1 = 0.0426486 loss)
I0901 00:45:17.912560 916722 sgd_solver.cpp:106] Iteration 3801000, lr = 0.01
I0901 00:45:47.645418 916722 solver.cpp:218] Iteration 3801500 (16.8165 iter/s, 29.7328s/500 iters), loss = 0.0660896
I0901 00:45:47.645489 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0660914 (* 1 = 0.0660914 loss)
I0901 00:45:47.645498 916722 sgd_solver.cpp:106] Iteration 3801500, lr = 0.01
I0901 00:46:17.362191 916722 solver.cpp:218] Iteration 3802000 (16.8256 iter/s, 29.7166s/500 iters), loss = 0.0657379
I0901 00:46:17.362241 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0657398 (* 1 = 0.0657398 loss)
I0901 00:46:17.362251 916722 sgd_solver.cpp:106] Iteration 3802000, lr = 0.01
I0901 00:46:47.076287 916722 solver.cpp:218] Iteration 3802500 (16.8271 iter/s, 29.7139s/500 iters), loss = 0.0870658
I0901 00:46:47.076356 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0870677 (* 1 = 0.0870677 loss)
I0901 00:46:47.076365 916722 sgd_solver.cpp:106] Iteration 3802500, lr = 0.01
I0901 00:47:16.789237 916722 solver.cpp:218] Iteration 3803000 (16.8278 iter/s, 29.7128s/500 iters), loss = 0.0608578
I0901 00:47:16.789289 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0608597 (* 1 = 0.0608597 loss)
I0901 00:47:16.789300 916722 sgd_solver.cpp:106] Iteration 3803000, lr = 0.01
I0901 00:47:46.504387 916722 solver.cpp:218] Iteration 3803500 (16.8265 iter/s, 29.715s/500 iters), loss = 0.162756
I0901 00:47:46.504451 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.162758 (* 1 = 0.162758 loss)
I0901 00:47:46.504458 916722 sgd_solver.cpp:106] Iteration 3803500, lr = 0.01
I0901 00:48:16.225761 916722 solver.cpp:218] Iteration 3804000 (16.823 iter/s, 29.7212s/500 iters), loss = 0.154944
I0901 00:48:16.225816 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.154946 (* 1 = 0.154946 loss)
I0901 00:48:16.225826 916722 sgd_solver.cpp:106] Iteration 3804000, lr = 0.01
I0901 00:48:45.943576 916722 solver.cpp:218] Iteration 3804500 (16.825 iter/s, 29.7177s/500 iters), loss = 0.205309
I0901 00:48:45.943634 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.205311 (* 1 = 0.205311 loss)
I0901 00:48:45.943643 916722 sgd_solver.cpp:106] Iteration 3804500, lr = 0.01
I0901 00:49:15.663004 916722 solver.cpp:218] Iteration 3805000 (16.8241 iter/s, 29.7193s/500 iters), loss = 0.340653
I0901 00:49:15.663055 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.340655 (* 1 = 0.340655 loss)
I0901 00:49:15.663065 916722 sgd_solver.cpp:106] Iteration 3805000, lr = 0.01
I0901 00:49:45.380911 916722 solver.cpp:218] Iteration 3805500 (16.825 iter/s, 29.7178s/500 iters), loss = 0.123944
I0901 00:49:45.380972 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.123945 (* 1 = 0.123945 loss)
I0901 00:49:45.380981 916722 sgd_solver.cpp:106] Iteration 3805500, lr = 0.01
I0901 00:50:15.098126 916722 solver.cpp:218] Iteration 3806000 (16.8254 iter/s, 29.7171s/500 iters), loss = 0.0549291
I0901 00:50:15.098179 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.054931 (* 1 = 0.054931 loss)
I0901 00:50:15.098188 916722 sgd_solver.cpp:106] Iteration 3806000, lr = 0.01
I0901 00:50:44.816486 916722 solver.cpp:218] Iteration 3806500 (16.8247 iter/s, 29.7182s/500 iters), loss = 0.367827
I0901 00:50:44.816543 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.367829 (* 1 = 0.367829 loss)
I0901 00:50:44.816551 916722 sgd_solver.cpp:106] Iteration 3806500, lr = 0.01
I0901 00:51:14.531499 916722 solver.cpp:218] Iteration 3807000 (16.8266 iter/s, 29.7149s/500 iters), loss = 0.0607611
I0901 00:51:14.531553 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.060763 (* 1 = 0.060763 loss)
I0901 00:51:14.531563 916722 sgd_solver.cpp:106] Iteration 3807000, lr = 0.01
I0901 00:51:44.250365 916722 solver.cpp:218] Iteration 3807500 (16.8243 iter/s, 29.7189s/500 iters), loss = 0.099653
I0901 00:51:44.250424 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0996548 (* 1 = 0.0996548 loss)
I0901 00:51:44.250433 916722 sgd_solver.cpp:106] Iteration 3807500, lr = 0.01
I0901 00:52:13.970358 916722 solver.cpp:218] Iteration 3808000 (16.8236 iter/s, 29.7201s/500 iters), loss = 0.467866
I0901 00:52:13.970410 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.467868 (* 1 = 0.467868 loss)
I0901 00:52:13.970419 916722 sgd_solver.cpp:106] Iteration 3808000, lr = 0.01
I0901 00:52:43.696509 916722 solver.cpp:218] Iteration 3808500 (16.8201 iter/s, 29.7263s/500 iters), loss = 0.065944
I0901 00:52:43.696571 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.065946 (* 1 = 0.065946 loss)
I0901 00:52:43.696580 916722 sgd_solver.cpp:106] Iteration 3808500, lr = 0.01
I0901 00:53:13.426937 916722 solver.cpp:218] Iteration 3809000 (16.8177 iter/s, 29.7305s/500 iters), loss = 0.101692
I0901 00:53:13.427006 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101694 (* 1 = 0.101694 loss)
I0901 00:53:13.427016 916722 sgd_solver.cpp:106] Iteration 3809000, lr = 0.01
I0901 00:53:43.157557 916722 solver.cpp:218] Iteration 3809500 (16.8176 iter/s, 29.7307s/500 iters), loss = 0.173055
I0901 00:53:43.157624 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.173057 (* 1 = 0.173057 loss)
I0901 00:53:43.157634 916722 sgd_solver.cpp:106] Iteration 3809500, lr = 0.01
I0901 00:54:12.877449 916722 solver.cpp:218] Iteration 3810000 (16.8237 iter/s, 29.72s/500 iters), loss = 0.0770672
I0901 00:54:12.877501 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0770694 (* 1 = 0.0770694 loss)
I0901 00:54:12.877509 916722 sgd_solver.cpp:106] Iteration 3810000, lr = 0.01
I0901 00:54:42.595436 916722 solver.cpp:218] Iteration 3810500 (16.8248 iter/s, 29.7181s/500 iters), loss = 0.111693
I0901 00:54:42.595494 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111695 (* 1 = 0.111695 loss)
I0901 00:54:42.595501 916722 sgd_solver.cpp:106] Iteration 3810500, lr = 0.01
I0901 00:55:12.314615 916722 solver.cpp:218] Iteration 3811000 (16.8241 iter/s, 29.7192s/500 iters), loss = 0.0222186
I0901 00:55:12.314667 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0222208 (* 1 = 0.0222208 loss)
I0901 00:55:12.314677 916722 sgd_solver.cpp:106] Iteration 3811000, lr = 0.01
I0901 00:55:42.031056 916722 solver.cpp:218] Iteration 3811500 (16.8257 iter/s, 29.7165s/500 iters), loss = 0.308683
I0901 00:55:42.031114 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.308685 (* 1 = 0.308685 loss)
I0901 00:55:42.031122 916722 sgd_solver.cpp:106] Iteration 3811500, lr = 0.01
I0901 00:56:11.749073 916722 solver.cpp:218] Iteration 3812000 (16.8248 iter/s, 29.7181s/500 iters), loss = 0.217347
I0901 00:56:11.749122 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.21735 (* 1 = 0.21735 loss)
I0901 00:56:11.749133 916722 sgd_solver.cpp:106] Iteration 3812000, lr = 0.01
I0901 00:56:41.461987 916722 solver.cpp:218] Iteration 3812500 (16.8277 iter/s, 29.713s/500 iters), loss = 0.172352
I0901 00:56:41.462044 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.172354 (* 1 = 0.172354 loss)
I0901 00:56:41.462054 916722 sgd_solver.cpp:106] Iteration 3812500, lr = 0.01
I0901 00:57:11.182046 916722 solver.cpp:218] Iteration 3813000 (16.8236 iter/s, 29.7201s/500 iters), loss = 0.161094
I0901 00:57:11.182096 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.161096 (* 1 = 0.161096 loss)
I0901 00:57:11.182106 916722 sgd_solver.cpp:106] Iteration 3813000, lr = 0.01
I0901 00:57:40.899129 916722 solver.cpp:218] Iteration 3813500 (16.8253 iter/s, 29.7171s/500 iters), loss = 0.0176248
I0901 00:57:40.899189 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0176272 (* 1 = 0.0176272 loss)
I0901 00:57:40.899199 916722 sgd_solver.cpp:106] Iteration 3813500, lr = 0.01
I0901 00:58:10.615597 916722 solver.cpp:218] Iteration 3814000 (16.8257 iter/s, 29.7165s/500 iters), loss = 0.264306
I0901 00:58:10.615648 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.264309 (* 1 = 0.264309 loss)
I0901 00:58:10.615658 916722 sgd_solver.cpp:106] Iteration 3814000, lr = 0.01
I0901 00:58:40.338214 916722 solver.cpp:218] Iteration 3814500 (16.8222 iter/s, 29.7226s/500 iters), loss = 0.134105
I0901 00:58:40.338270 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.134107 (* 1 = 0.134107 loss)
I0901 00:58:40.338279 916722 sgd_solver.cpp:106] Iteration 3814500, lr = 0.01
I0901 00:59:10.053908 916722 solver.cpp:218] Iteration 3815000 (16.8261 iter/s, 29.7157s/500 iters), loss = 0.112466
I0901 00:59:10.053957 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112468 (* 1 = 0.112468 loss)
I0901 00:59:10.053967 916722 sgd_solver.cpp:106] Iteration 3815000, lr = 0.01
I0901 00:59:39.775290 916722 solver.cpp:218] Iteration 3815500 (16.8229 iter/s, 29.7214s/500 iters), loss = 0.117826
I0901 00:59:39.775355 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.117829 (* 1 = 0.117829 loss)
I0901 00:59:39.775364 916722 sgd_solver.cpp:106] Iteration 3815500, lr = 0.01
I0901 01:00:09.492327 916722 solver.cpp:218] Iteration 3816000 (16.8254 iter/s, 29.717s/500 iters), loss = 0.0132115
I0901 01:00:09.492378 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.013214 (* 1 = 0.013214 loss)
I0901 01:00:09.492388 916722 sgd_solver.cpp:106] Iteration 3816000, lr = 0.01
I0901 01:00:39.212261 916722 solver.cpp:218] Iteration 3816500 (16.8237 iter/s, 29.7199s/500 iters), loss = 0.113364
I0901 01:00:39.212323 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.113366 (* 1 = 0.113366 loss)
I0901 01:00:39.212332 916722 sgd_solver.cpp:106] Iteration 3816500, lr = 0.01
I0901 01:01:08.930258 916722 solver.cpp:218] Iteration 3817000 (16.8248 iter/s, 29.718s/500 iters), loss = 0.095158
I0901 01:01:08.930305 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0951604 (* 1 = 0.0951604 loss)
I0901 01:01:08.930313 916722 sgd_solver.cpp:106] Iteration 3817000, lr = 0.01
I0901 01:01:38.645808 916722 solver.cpp:218] Iteration 3817500 (16.8262 iter/s, 29.7155s/500 iters), loss = 0.0981042
I0901 01:01:38.645866 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0981066 (* 1 = 0.0981066 loss)
I0901 01:01:38.645874 916722 sgd_solver.cpp:106] Iteration 3817500, lr = 0.01
I0901 01:02:08.360636 916722 solver.cpp:218] Iteration 3818000 (16.8266 iter/s, 29.7148s/500 iters), loss = 0.12852
I0901 01:02:08.360687 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128522 (* 1 = 0.128522 loss)
I0901 01:02:08.360697 916722 sgd_solver.cpp:106] Iteration 3818000, lr = 0.01
I0901 01:02:38.077069 916722 solver.cpp:218] Iteration 3818500 (16.8257 iter/s, 29.7164s/500 iters), loss = 0.277625
I0901 01:02:38.077124 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.277628 (* 1 = 0.277628 loss)
I0901 01:02:38.077132 916722 sgd_solver.cpp:106] Iteration 3818500, lr = 0.01
I0901 01:03:07.795964 916722 solver.cpp:218] Iteration 3819000 (16.8243 iter/s, 29.7189s/500 iters), loss = 0.168429
I0901 01:03:07.796013 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.168431 (* 1 = 0.168431 loss)
I0901 01:03:07.796025 916722 sgd_solver.cpp:106] Iteration 3819000, lr = 0.01
I0901 01:03:37.515435 916722 solver.cpp:218] Iteration 3819500 (16.824 iter/s, 29.7194s/500 iters), loss = 0.0455427
I0901 01:03:37.515491 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0455452 (* 1 = 0.0455452 loss)
I0901 01:03:37.515499 916722 sgd_solver.cpp:106] Iteration 3819500, lr = 0.01
I0901 01:04:07.234452 916722 solver.cpp:218] Iteration 3820000 (16.8243 iter/s, 29.719s/500 iters), loss = 0.0903792
I0901 01:04:07.234503 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0903817 (* 1 = 0.0903817 loss)
I0901 01:04:07.234513 916722 sgd_solver.cpp:106] Iteration 3820000, lr = 0.01
I0901 01:04:36.952570 916722 solver.cpp:218] Iteration 3820500 (16.8248 iter/s, 29.7181s/500 iters), loss = 0.0782893
I0901 01:04:36.952632 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0782917 (* 1 = 0.0782917 loss)
I0901 01:04:36.952641 916722 sgd_solver.cpp:106] Iteration 3820500, lr = 0.01
I0901 01:05:06.669456 916722 solver.cpp:218] Iteration 3821000 (16.8255 iter/s, 29.7168s/500 iters), loss = 0.0685534
I0901 01:05:06.669507 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0685559 (* 1 = 0.0685559 loss)
I0901 01:05:06.669517 916722 sgd_solver.cpp:106] Iteration 3821000, lr = 0.01
I0901 01:05:36.384656 916722 solver.cpp:218] Iteration 3821500 (16.8264 iter/s, 29.7151s/500 iters), loss = 0.191949
I0901 01:05:36.384714 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.191951 (* 1 = 0.191951 loss)
I0901 01:05:36.384723 916722 sgd_solver.cpp:106] Iteration 3821500, lr = 0.01
I0901 01:06:06.101260 916722 solver.cpp:218] Iteration 3822000 (16.8257 iter/s, 29.7165s/500 iters), loss = 0.127105
I0901 01:06:06.101310 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.127108 (* 1 = 0.127108 loss)
I0901 01:06:06.101330 916722 sgd_solver.cpp:106] Iteration 3822000, lr = 0.01
I0901 01:06:35.819784 916722 solver.cpp:218] Iteration 3822500 (16.8246 iter/s, 29.7185s/500 iters), loss = 0.189891
I0901 01:06:35.819855 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.189893 (* 1 = 0.189893 loss)
I0901 01:06:35.819867 916722 sgd_solver.cpp:106] Iteration 3822500, lr = 0.01
I0901 01:07:05.538626 916722 solver.cpp:218] Iteration 3823000 (16.8244 iter/s, 29.7188s/500 iters), loss = 0.305858
I0901 01:07:05.538678 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.30586 (* 1 = 0.30586 loss)
I0901 01:07:05.538686 916722 sgd_solver.cpp:106] Iteration 3823000, lr = 0.01
I0901 01:07:35.268787 916722 solver.cpp:218] Iteration 3823500 (16.818 iter/s, 29.7301s/500 iters), loss = 0.0458587
I0901 01:07:35.268843 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0458609 (* 1 = 0.0458609 loss)
I0901 01:07:35.268851 916722 sgd_solver.cpp:106] Iteration 3823500, lr = 0.01
I0901 01:08:04.999346 916722 solver.cpp:218] Iteration 3824000 (16.8178 iter/s, 29.7305s/500 iters), loss = 0.0650521
I0901 01:08:04.999397 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0650544 (* 1 = 0.0650544 loss)
I0901 01:08:04.999405 916722 sgd_solver.cpp:106] Iteration 3824000, lr = 0.01
I0901 01:08:34.728585 916722 solver.cpp:218] Iteration 3824500 (16.8185 iter/s, 29.7292s/500 iters), loss = 0.0613601
I0901 01:08:34.728641 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0613624 (* 1 = 0.0613624 loss)
I0901 01:08:34.728648 916722 sgd_solver.cpp:106] Iteration 3824500, lr = 0.01
I0901 01:09:04.448760 916722 solver.cpp:218] Iteration 3825000 (16.8236 iter/s, 29.7201s/500 iters), loss = 0.120379
I0901 01:09:04.448810 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.120381 (* 1 = 0.120381 loss)
I0901 01:09:04.448818 916722 sgd_solver.cpp:106] Iteration 3825000, lr = 0.01
I0901 01:09:34.166510 916722 solver.cpp:218] Iteration 3825500 (16.825 iter/s, 29.7177s/500 iters), loss = 0.293895
I0901 01:09:34.166569 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.293898 (* 1 = 0.293898 loss)
I0901 01:09:34.166579 916722 sgd_solver.cpp:106] Iteration 3825500, lr = 0.01
I0901 01:10:03.888450 916722 solver.cpp:218] Iteration 3826000 (16.8226 iter/s, 29.7219s/500 iters), loss = 0.232801
I0901 01:10:03.888504 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.232803 (* 1 = 0.232803 loss)
I0901 01:10:03.888514 916722 sgd_solver.cpp:106] Iteration 3826000, lr = 0.01
I0901 01:10:33.604336 916722 solver.cpp:218] Iteration 3826500 (16.8261 iter/s, 29.7158s/500 iters), loss = 0.183882
I0901 01:10:33.604390 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.183884 (* 1 = 0.183884 loss)
I0901 01:10:33.604399 916722 sgd_solver.cpp:106] Iteration 3826500, lr = 0.01
I0901 01:11:03.321246 916722 solver.cpp:218] Iteration 3827000 (16.8255 iter/s, 29.7168s/500 iters), loss = 0.173896
I0901 01:11:03.321295 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.173898 (* 1 = 0.173898 loss)
I0901 01:11:03.321305 916722 sgd_solver.cpp:106] Iteration 3827000, lr = 0.01
I0901 01:11:33.036623 916722 solver.cpp:218] Iteration 3827500 (16.8264 iter/s, 29.7153s/500 iters), loss = 0.186738
I0901 01:11:33.036679 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.18674 (* 1 = 0.18674 loss)
I0901 01:11:33.036687 916722 sgd_solver.cpp:106] Iteration 3827500, lr = 0.01
I0901 01:12:02.752318 916722 solver.cpp:218] Iteration 3828000 (16.8262 iter/s, 29.7156s/500 iters), loss = 0.0701987
I0901 01:12:02.752369 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0702009 (* 1 = 0.0702009 loss)
I0901 01:12:02.752379 916722 sgd_solver.cpp:106] Iteration 3828000, lr = 0.01
I0901 01:12:32.472419 916722 solver.cpp:218] Iteration 3828500 (16.8237 iter/s, 29.72s/500 iters), loss = 0.226784
I0901 01:12:32.472496 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.226786 (* 1 = 0.226786 loss)
I0901 01:12:32.472514 916722 sgd_solver.cpp:106] Iteration 3828500, lr = 0.01
I0901 01:13:02.185957 916722 solver.cpp:218] Iteration 3829000 (16.8274 iter/s, 29.7134s/500 iters), loss = 0.250828
I0901 01:13:02.186007 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.250831 (* 1 = 0.250831 loss)
I0901 01:13:02.186017 916722 sgd_solver.cpp:106] Iteration 3829000, lr = 0.01
I0901 01:13:31.902726 916722 solver.cpp:218] Iteration 3829500 (16.8256 iter/s, 29.7167s/500 iters), loss = 0.0976407
I0901 01:13:31.902786 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.097643 (* 1 = 0.097643 loss)
I0901 01:13:31.902794 916722 sgd_solver.cpp:106] Iteration 3829500, lr = 0.01
I0901 01:14:01.623474 916722 solver.cpp:218] Iteration 3830000 (16.8233 iter/s, 29.7207s/500 iters), loss = 0.203704
I0901 01:14:01.623524 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.203706 (* 1 = 0.203706 loss)
I0901 01:14:01.623534 916722 sgd_solver.cpp:106] Iteration 3830000, lr = 0.01
I0901 01:14:31.338907 916722 solver.cpp:218] Iteration 3830500 (16.8263 iter/s, 29.7153s/500 iters), loss = 0.188325
I0901 01:14:31.338968 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.188328 (* 1 = 0.188328 loss)
I0901 01:14:31.338976 916722 sgd_solver.cpp:106] Iteration 3830500, lr = 0.01
I0901 01:15:01.050503 916722 solver.cpp:218] Iteration 3831000 (16.8285 iter/s, 29.7115s/500 iters), loss = 0.090577
I0901 01:15:01.050552 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0905791 (* 1 = 0.0905791 loss)
I0901 01:15:01.050561 916722 sgd_solver.cpp:106] Iteration 3831000, lr = 0.01
I0901 01:15:30.763432 916722 solver.cpp:218] Iteration 3831500 (16.8277 iter/s, 29.7128s/500 iters), loss = 0.15942
I0901 01:15:30.763487 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159422 (* 1 = 0.159422 loss)
I0901 01:15:30.763496 916722 sgd_solver.cpp:106] Iteration 3831500, lr = 0.01
I0901 01:16:00.476230 916722 solver.cpp:218] Iteration 3832000 (16.8278 iter/s, 29.7127s/500 iters), loss = 0.174652
I0901 01:16:00.476286 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.174654 (* 1 = 0.174654 loss)
I0901 01:16:00.476295 916722 sgd_solver.cpp:106] Iteration 3832000, lr = 0.01
I0901 01:16:30.193203 916722 solver.cpp:218] Iteration 3832500 (16.8255 iter/s, 29.7169s/500 iters), loss = 0.0714091
I0901 01:16:30.193265 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0714111 (* 1 = 0.0714111 loss)
I0901 01:16:30.193274 916722 sgd_solver.cpp:106] Iteration 3832500, lr = 0.01
I0901 01:16:59.907374 916722 solver.cpp:218] Iteration 3833000 (16.8271 iter/s, 29.7141s/500 iters), loss = 0.359096
I0901 01:16:59.907426 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.359097 (* 1 = 0.359097 loss)
I0901 01:16:59.907436 916722 sgd_solver.cpp:106] Iteration 3833000, lr = 0.01
I0901 01:17:29.623163 916722 solver.cpp:218] Iteration 3833500 (16.8261 iter/s, 29.7157s/500 iters), loss = 0.0393399
I0901 01:17:29.623224 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0393418 (* 1 = 0.0393418 loss)
I0901 01:17:29.623231 916722 sgd_solver.cpp:106] Iteration 3833500, lr = 0.01
I0901 01:17:59.338009 916722 solver.cpp:218] Iteration 3834000 (16.8267 iter/s, 29.7147s/500 iters), loss = 0.21885
I0901 01:17:59.338063 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.218852 (* 1 = 0.218852 loss)
I0901 01:17:59.338071 916722 sgd_solver.cpp:106] Iteration 3834000, lr = 0.01
I0901 01:18:29.061880 916722 solver.cpp:218] Iteration 3834500 (16.8216 iter/s, 29.7238s/500 iters), loss = 0.0515728
I0901 01:18:29.061939 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0515748 (* 1 = 0.0515748 loss)
I0901 01:18:29.061949 916722 sgd_solver.cpp:106] Iteration 3834500, lr = 0.01
I0901 01:18:58.775894 916722 solver.cpp:218] Iteration 3835000 (16.8271 iter/s, 29.7139s/500 iters), loss = 0.310532
I0901 01:18:58.775945 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.310534 (* 1 = 0.310534 loss)
I0901 01:18:58.775964 916722 sgd_solver.cpp:106] Iteration 3835000, lr = 0.01
I0901 01:19:28.492071 916722 solver.cpp:218] Iteration 3835500 (16.8259 iter/s, 29.7161s/500 iters), loss = 0.075154
I0901 01:19:28.492138 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0751558 (* 1 = 0.0751558 loss)
I0901 01:19:28.492146 916722 sgd_solver.cpp:106] Iteration 3835500, lr = 0.01
I0901 01:19:58.209622 916722 solver.cpp:218] Iteration 3836000 (16.8251 iter/s, 29.7174s/500 iters), loss = 0.288865
I0901 01:19:58.209681 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.288867 (* 1 = 0.288867 loss)
I0901 01:19:58.209690 916722 sgd_solver.cpp:106] Iteration 3836000, lr = 0.01
I0901 01:20:27.927286 916722 solver.cpp:218] Iteration 3836500 (16.8251 iter/s, 29.7176s/500 iters), loss = 0.118138
I0901 01:20:27.927345 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.11814 (* 1 = 0.11814 loss)
I0901 01:20:27.927354 916722 sgd_solver.cpp:106] Iteration 3836500, lr = 0.01
I0901 01:20:57.641723 916722 solver.cpp:218] Iteration 3837000 (16.8269 iter/s, 29.7143s/500 iters), loss = 0.133139
I0901 01:20:57.641777 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133141 (* 1 = 0.133141 loss)
I0901 01:20:57.641788 916722 sgd_solver.cpp:106] Iteration 3837000, lr = 0.01
I0901 01:21:27.355759 916722 solver.cpp:218] Iteration 3837500 (16.8271 iter/s, 29.7139s/500 iters), loss = 0.184003
I0901 01:21:27.355819 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.184005 (* 1 = 0.184005 loss)
I0901 01:21:27.355829 916722 sgd_solver.cpp:106] Iteration 3837500, lr = 0.01
I0901 01:21:57.072830 916722 solver.cpp:218] Iteration 3838000 (16.8254 iter/s, 29.717s/500 iters), loss = 0.399828
I0901 01:21:57.072882 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.39983 (* 1 = 0.39983 loss)
I0901 01:21:57.072892 916722 sgd_solver.cpp:106] Iteration 3838000, lr = 0.01
I0901 01:22:26.790793 916722 solver.cpp:218] Iteration 3838500 (16.8249 iter/s, 29.7179s/500 iters), loss = 0.175412
I0901 01:22:26.790853 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.175414 (* 1 = 0.175414 loss)
I0901 01:22:26.790860 916722 sgd_solver.cpp:106] Iteration 3838500, lr = 0.01
I0901 01:22:56.508879 916722 solver.cpp:218] Iteration 3839000 (16.8248 iter/s, 29.718s/500 iters), loss = 0.217818
I0901 01:22:56.508930 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.21782 (* 1 = 0.21782 loss)
I0901 01:22:56.508940 916722 sgd_solver.cpp:106] Iteration 3839000, lr = 0.01
I0901 01:23:26.227324 916722 solver.cpp:218] Iteration 3839500 (16.8246 iter/s, 29.7183s/500 iters), loss = 0.0212814
I0901 01:23:26.227380 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0212833 (* 1 = 0.0212833 loss)
I0901 01:23:26.227388 916722 sgd_solver.cpp:106] Iteration 3839500, lr = 0.01
I0901 01:23:55.943470 916722 solver.cpp:218] Iteration 3840000 (16.8259 iter/s, 29.716s/500 iters), loss = 0.127598
I0901 01:23:55.943521 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.1276 (* 1 = 0.1276 loss)
I0901 01:23:55.943531 916722 sgd_solver.cpp:106] Iteration 3840000, lr = 0.01
I0901 01:24:25.659706 916722 solver.cpp:218] Iteration 3840500 (16.8259 iter/s, 29.7161s/500 iters), loss = 0.269921
I0901 01:24:25.659765 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.269923 (* 1 = 0.269923 loss)
I0901 01:24:25.659775 916722 sgd_solver.cpp:106] Iteration 3840500, lr = 0.01
I0901 01:24:55.375708 916722 solver.cpp:218] Iteration 3841000 (16.826 iter/s, 29.7159s/500 iters), loss = 0.19465
I0901 01:24:55.375761 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.194652 (* 1 = 0.194652 loss)
I0901 01:24:55.375770 916722 sgd_solver.cpp:106] Iteration 3841000, lr = 0.01
I0901 01:25:25.100723 916722 solver.cpp:218] Iteration 3841500 (16.8209 iter/s, 29.7249s/500 iters), loss = 0.0260433
I0901 01:25:25.100788 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0260453 (* 1 = 0.0260453 loss)
I0901 01:25:25.100797 916722 sgd_solver.cpp:106] Iteration 3841500, lr = 0.01
I0901 01:25:54.820591 916722 solver.cpp:218] Iteration 3842000 (16.8244 iter/s, 29.7188s/500 iters), loss = 0.0365995
I0901 01:25:54.820644 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0366014 (* 1 = 0.0366014 loss)
I0901 01:25:54.820654 916722 sgd_solver.cpp:106] Iteration 3842000, lr = 0.01
I0901 01:26:24.539762 916722 solver.cpp:218] Iteration 3842500 (16.8249 iter/s, 29.7178s/500 iters), loss = 0.182439
I0901 01:26:24.539832 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.182441 (* 1 = 0.182441 loss)
I0901 01:26:24.539840 916722 sgd_solver.cpp:106] Iteration 3842500, lr = 0.01
I0901 01:26:54.259582 916722 solver.cpp:218] Iteration 3843000 (16.8245 iter/s, 29.7185s/500 iters), loss = 0.164004
I0901 01:26:54.259631 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.164006 (* 1 = 0.164006 loss)
I0901 01:26:54.259641 916722 sgd_solver.cpp:106] Iteration 3843000, lr = 0.01
I0901 01:27:23.977902 916722 solver.cpp:218] Iteration 3843500 (16.8253 iter/s, 29.7171s/500 iters), loss = 0.181339
I0901 01:27:23.977959 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.181342 (* 1 = 0.181342 loss)
I0901 01:27:23.977967 916722 sgd_solver.cpp:106] Iteration 3843500, lr = 0.01
I0901 01:27:53.695096 916722 solver.cpp:218] Iteration 3844000 (16.8259 iter/s, 29.716s/500 iters), loss = 0.0289292
I0901 01:27:53.695144 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0289315 (* 1 = 0.0289315 loss)
I0901 01:27:53.695154 916722 sgd_solver.cpp:106] Iteration 3844000, lr = 0.01
I0901 01:28:23.426205 916722 solver.cpp:218] Iteration 3844500 (16.818 iter/s, 29.73s/500 iters), loss = 0.126081
I0901 01:28:23.426261 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.126083 (* 1 = 0.126083 loss)
I0901 01:28:23.426270 916722 sgd_solver.cpp:106] Iteration 3844500, lr = 0.01
I0901 01:28:53.170418 916722 solver.cpp:218] Iteration 3845000 (16.8106 iter/s, 29.7431s/500 iters), loss = 0.11942
I0901 01:28:53.170471 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.119423 (* 1 = 0.119423 loss)
I0901 01:28:53.170481 916722 sgd_solver.cpp:106] Iteration 3845000, lr = 0.01
I0901 01:29:22.915422 916722 solver.cpp:218] Iteration 3845500 (16.8101 iter/s, 29.744s/500 iters), loss = 0.157949
I0901 01:29:22.915482 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.157952 (* 1 = 0.157952 loss)
I0901 01:29:22.915491 916722 sgd_solver.cpp:106] Iteration 3845500, lr = 0.01
I0901 01:29:52.662297 916722 solver.cpp:218] Iteration 3846000 (16.809 iter/s, 29.7459s/500 iters), loss = 0.045531
I0901 01:29:52.662349 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0455334 (* 1 = 0.0455334 loss)
I0901 01:29:52.662360 916722 sgd_solver.cpp:106] Iteration 3846000, lr = 0.01
I0901 01:30:22.403360 916722 solver.cpp:218] Iteration 3846500 (16.8123 iter/s, 29.7401s/500 iters), loss = 0.119528
I0901 01:30:22.403421 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.11953 (* 1 = 0.11953 loss)
I0901 01:30:22.403430 916722 sgd_solver.cpp:106] Iteration 3846500, lr = 0.01
I0901 01:30:52.148733 916722 solver.cpp:218] Iteration 3847000 (16.8099 iter/s, 29.7445s/500 iters), loss = 0.0191744
I0901 01:30:52.148797 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0191766 (* 1 = 0.0191766 loss)
I0901 01:30:52.148805 916722 sgd_solver.cpp:106] Iteration 3847000, lr = 0.01
I0901 01:31:21.894824 916722 solver.cpp:218] Iteration 3847500 (16.8094 iter/s, 29.7452s/500 iters), loss = 0.113961
I0901 01:31:21.894882 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.113963 (* 1 = 0.113963 loss)
I0901 01:31:21.894891 916722 sgd_solver.cpp:106] Iteration 3847500, lr = 0.01
I0901 01:31:51.636802 916722 solver.cpp:218] Iteration 3848000 (16.8117 iter/s, 29.7411s/500 iters), loss = 0.303965
I0901 01:31:51.636854 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.303967 (* 1 = 0.303967 loss)
I0901 01:31:51.636863 916722 sgd_solver.cpp:106] Iteration 3848000, lr = 0.01
I0901 01:32:21.379818 916722 solver.cpp:218] Iteration 3848500 (16.8111 iter/s, 29.7422s/500 iters), loss = 0.127148
I0901 01:32:21.379890 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.12715 (* 1 = 0.12715 loss)
I0901 01:32:21.379899 916722 sgd_solver.cpp:106] Iteration 3848500, lr = 0.01
I0901 01:32:51.124810 916722 solver.cpp:218] Iteration 3849000 (16.81 iter/s, 29.7442s/500 iters), loss = 0.115052
I0901 01:32:51.124859 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115055 (* 1 = 0.115055 loss)
I0901 01:32:51.124867 916722 sgd_solver.cpp:106] Iteration 3849000, lr = 0.01
I0901 01:33:20.867542 916722 solver.cpp:218] Iteration 3849500 (16.8112 iter/s, 29.742s/500 iters), loss = 0.0902584
I0901 01:33:20.867601 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.090261 (* 1 = 0.090261 loss)
I0901 01:33:20.867609 916722 sgd_solver.cpp:106] Iteration 3849500, lr = 0.01
I0901 01:33:50.548740 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_3850000.caffemodel
I0901 01:33:50.567749 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_3850000.solverstate
I0901 01:33:50.573777 916722 solver.cpp:330] Iteration 3850000, Testing net (#0)
I0901 01:34:05.933403 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8839
I0901 01:34:05.933457 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.387061 (* 1 = 0.387061 loss)
I0901 01:34:05.991962 916722 solver.cpp:218] Iteration 3850000 (11.0807 iter/s, 45.1234s/500 iters), loss = 0.509073
I0901 01:34:05.991991 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.509076 (* 1 = 0.509076 loss)
I0901 01:34:05.991998 916722 sgd_solver.cpp:106] Iteration 3850000, lr = 0.01
I0901 01:34:35.604637 916722 solver.cpp:218] Iteration 3850500 (16.8851 iter/s, 29.612s/500 iters), loss = 0.0310708
I0901 01:34:35.604689 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0310735 (* 1 = 0.0310735 loss)
I0901 01:34:35.604698 916722 sgd_solver.cpp:106] Iteration 3850500, lr = 0.01
I0901 01:35:05.315997 916722 solver.cpp:218] Iteration 3851000 (16.829 iter/s, 29.7107s/500 iters), loss = 0.243797
I0901 01:35:05.316053 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.2438 (* 1 = 0.2438 loss)
I0901 01:35:05.316062 916722 sgd_solver.cpp:106] Iteration 3851000, lr = 0.01
I0901 01:35:35.054337 916722 solver.cpp:218] Iteration 3851500 (16.8137 iter/s, 29.7377s/500 iters), loss = 0.0972851
I0901 01:35:35.054389 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0972878 (* 1 = 0.0972878 loss)
I0901 01:35:35.054397 916722 sgd_solver.cpp:106] Iteration 3851500, lr = 0.01
I0901 01:36:04.797794 916722 solver.cpp:218] Iteration 3852000 (16.8108 iter/s, 29.7428s/500 iters), loss = 0.132801
I0901 01:36:04.797852 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.132804 (* 1 = 0.132804 loss)
I0901 01:36:04.797860 916722 sgd_solver.cpp:106] Iteration 3852000, lr = 0.01
I0901 01:36:34.535581 916722 solver.cpp:218] Iteration 3852500 (16.814 iter/s, 29.7372s/500 iters), loss = 0.0752055
I0901 01:36:34.535634 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.075208 (* 1 = 0.075208 loss)
I0901 01:36:34.535641 916722 sgd_solver.cpp:106] Iteration 3852500, lr = 0.01
I0901 01:37:04.274174 916722 solver.cpp:218] Iteration 3853000 (16.8135 iter/s, 29.738s/500 iters), loss = 0.0155858
I0901 01:37:04.274231 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0155882 (* 1 = 0.0155882 loss)
I0901 01:37:04.274240 916722 sgd_solver.cpp:106] Iteration 3853000, lr = 0.01
I0901 01:37:34.020226 916722 solver.cpp:218] Iteration 3853500 (16.8093 iter/s, 29.7455s/500 iters), loss = 0.106078
I0901 01:37:34.020278 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.10608 (* 1 = 0.10608 loss)
I0901 01:37:34.020287 916722 sgd_solver.cpp:106] Iteration 3853500, lr = 0.01
I0901 01:38:03.767239 916722 solver.cpp:218] Iteration 3854000 (16.8087 iter/s, 29.7465s/500 iters), loss = 0.227693
I0901 01:38:03.767305 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.227696 (* 1 = 0.227696 loss)
I0901 01:38:03.767321 916722 sgd_solver.cpp:106] Iteration 3854000, lr = 0.01
I0901 01:38:33.508802 916722 solver.cpp:218] Iteration 3854500 (16.8118 iter/s, 29.741s/500 iters), loss = 0.226475
I0901 01:38:33.508850 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.226478 (* 1 = 0.226478 loss)
I0901 01:38:33.508859 916722 sgd_solver.cpp:106] Iteration 3854500, lr = 0.01
I0901 01:39:03.252547 916722 solver.cpp:218] Iteration 3855000 (16.8105 iter/s, 29.7432s/500 iters), loss = 0.133746
I0901 01:39:03.252602 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133749 (* 1 = 0.133749 loss)
I0901 01:39:03.252610 916722 sgd_solver.cpp:106] Iteration 3855000, lr = 0.01
I0901 01:39:33.015262 916722 solver.cpp:218] Iteration 3855500 (16.7998 iter/s, 29.7622s/500 iters), loss = 0.265252
I0901 01:39:33.015317 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.265254 (* 1 = 0.265254 loss)
I0901 01:39:33.015328 916722 sgd_solver.cpp:106] Iteration 3855500, lr = 0.01
I0901 01:40:02.773175 916722 solver.cpp:218] Iteration 3856000 (16.8025 iter/s, 29.7574s/500 iters), loss = 0.0500514
I0901 01:40:02.773233 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0500538 (* 1 = 0.0500538 loss)
I0901 01:40:02.773242 916722 sgd_solver.cpp:106] Iteration 3856000, lr = 0.01
I0901 01:40:32.538736 916722 solver.cpp:218] Iteration 3856500 (16.7982 iter/s, 29.7651s/500 iters), loss = 0.00910766
I0901 01:40:32.538790 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.00910996 (* 1 = 0.00910996 loss)
I0901 01:40:32.538801 916722 sgd_solver.cpp:106] Iteration 3856500, lr = 0.01
I0901 01:41:02.298301 916722 solver.cpp:218] Iteration 3857000 (16.8016 iter/s, 29.7591s/500 iters), loss = 0.059985
I0901 01:41:02.298362 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0599872 (* 1 = 0.0599872 loss)
I0901 01:41:02.298369 916722 sgd_solver.cpp:106] Iteration 3857000, lr = 0.01
I0901 01:41:32.058972 916722 solver.cpp:218] Iteration 3857500 (16.8009 iter/s, 29.7602s/500 iters), loss = 0.0614724
I0901 01:41:32.059026 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0614748 (* 1 = 0.0614748 loss)
I0901 01:41:32.059036 916722 sgd_solver.cpp:106] Iteration 3857500, lr = 0.01
I0901 01:42:01.818652 916722 solver.cpp:218] Iteration 3858000 (16.8015 iter/s, 29.7592s/500 iters), loss = 0.193445
I0901 01:42:01.818708 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.193447 (* 1 = 0.193447 loss)
I0901 01:42:01.818717 916722 sgd_solver.cpp:106] Iteration 3858000, lr = 0.01
I0901 01:42:31.572306 916722 solver.cpp:218] Iteration 3858500 (16.8049 iter/s, 29.7532s/500 iters), loss = 0.315536
I0901 01:42:31.572357 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.315539 (* 1 = 0.315539 loss)
I0901 01:42:31.572368 916722 sgd_solver.cpp:106] Iteration 3858500, lr = 0.01
I0901 01:43:01.326977 916722 solver.cpp:218] Iteration 3859000 (16.8043 iter/s, 29.7543s/500 iters), loss = 0.0438374
I0901 01:43:01.327033 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.04384 (* 1 = 0.04384 loss)
I0901 01:43:01.327040 916722 sgd_solver.cpp:106] Iteration 3859000, lr = 0.01
I0901 01:43:31.078608 916722 solver.cpp:218] Iteration 3859500 (16.806 iter/s, 29.7512s/500 iters), loss = 0.0486931
I0901 01:43:31.078658 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0486957 (* 1 = 0.0486957 loss)
I0901 01:43:31.078668 916722 sgd_solver.cpp:106] Iteration 3859500, lr = 0.01
I0901 01:44:00.833178 916722 solver.cpp:218] Iteration 3860000 (16.8044 iter/s, 29.7542s/500 iters), loss = 0.211639
I0901 01:44:00.833233 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.211641 (* 1 = 0.211641 loss)
I0901 01:44:00.833242 916722 sgd_solver.cpp:106] Iteration 3860000, lr = 0.01
I0901 01:44:30.585358 916722 solver.cpp:218] Iteration 3860500 (16.8057 iter/s, 29.7518s/500 iters), loss = 0.28741
I0901 01:44:30.585412 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.287412 (* 1 = 0.287412 loss)
I0901 01:44:30.585435 916722 sgd_solver.cpp:106] Iteration 3860500, lr = 0.01
I0901 01:45:00.336176 916722 solver.cpp:218] Iteration 3861000 (16.8065 iter/s, 29.7504s/500 iters), loss = 0.0715215
I0901 01:45:00.336257 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0715243 (* 1 = 0.0715243 loss)
I0901 01:45:00.336266 916722 sgd_solver.cpp:106] Iteration 3861000, lr = 0.01
I0901 01:45:30.090936 916722 solver.cpp:218] Iteration 3861500 (16.8043 iter/s, 29.7544s/500 iters), loss = 0.0472797
I0901 01:45:30.090992 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0472824 (* 1 = 0.0472824 loss)
I0901 01:45:30.091001 916722 sgd_solver.cpp:106] Iteration 3861500, lr = 0.01
I0901 01:45:59.840378 916722 solver.cpp:218] Iteration 3862000 (16.8072 iter/s, 29.7491s/500 iters), loss = 0.0754037
I0901 01:45:59.840445 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0754063 (* 1 = 0.0754063 loss)
I0901 01:45:59.840453 916722 sgd_solver.cpp:106] Iteration 3862000, lr = 0.01
I0901 01:46:29.592924 916722 solver.cpp:218] Iteration 3862500 (16.8055 iter/s, 29.7522s/500 iters), loss = 0.0677207
I0901 01:46:29.592974 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0677235 (* 1 = 0.0677235 loss)
I0901 01:46:29.592983 916722 sgd_solver.cpp:106] Iteration 3862500, lr = 0.01
I0901 01:46:59.345216 916722 solver.cpp:218] Iteration 3863000 (16.8056 iter/s, 29.7519s/500 iters), loss = 0.330834
I0901 01:46:59.345275 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.330837 (* 1 = 0.330837 loss)
I0901 01:46:59.345284 916722 sgd_solver.cpp:106] Iteration 3863000, lr = 0.01
I0901 01:47:29.097456 916722 solver.cpp:218] Iteration 3863500 (16.8057 iter/s, 29.7519s/500 iters), loss = 0.310053
I0901 01:47:29.097508 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.310055 (* 1 = 0.310055 loss)
I0901 01:47:29.097519 916722 sgd_solver.cpp:106] Iteration 3863500, lr = 0.01
I0901 01:47:58.849057 916722 solver.cpp:218] Iteration 3864000 (16.806 iter/s, 29.7512s/500 iters), loss = 0.0636713
I0901 01:47:58.849117 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0636737 (* 1 = 0.0636737 loss)
I0901 01:47:58.849125 916722 sgd_solver.cpp:106] Iteration 3864000, lr = 0.01
I0901 01:48:28.602193 916722 solver.cpp:218] Iteration 3864500 (16.8051 iter/s, 29.7528s/500 iters), loss = 0.0554743
I0901 01:48:28.602244 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0554767 (* 1 = 0.0554767 loss)
I0901 01:48:28.602254 916722 sgd_solver.cpp:106] Iteration 3864500, lr = 0.01
I0901 01:48:58.353098 916722 solver.cpp:218] Iteration 3865000 (16.8064 iter/s, 29.7506s/500 iters), loss = 0.0474513
I0901 01:48:58.353159 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0474537 (* 1 = 0.0474537 loss)
I0901 01:48:58.353168 916722 sgd_solver.cpp:106] Iteration 3865000, lr = 0.01
I0901 01:49:28.101861 916722 solver.cpp:218] Iteration 3865500 (16.8076 iter/s, 29.7484s/500 iters), loss = 0.504307
I0901 01:49:28.101914 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.504309 (* 1 = 0.504309 loss)
I0901 01:49:28.101925 916722 sgd_solver.cpp:106] Iteration 3865500, lr = 0.01
I0901 01:49:57.832511 916722 solver.cpp:218] Iteration 3866000 (16.8179 iter/s, 29.7303s/500 iters), loss = 0.0545256
I0901 01:49:57.832577 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.054528 (* 1 = 0.054528 loss)
I0901 01:49:57.832587 916722 sgd_solver.cpp:106] Iteration 3866000, lr = 0.01
I0901 01:50:27.564491 916722 solver.cpp:218] Iteration 3866500 (16.8171 iter/s, 29.7316s/500 iters), loss = 0.419214
I0901 01:50:27.564544 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.419217 (* 1 = 0.419217 loss)
I0901 01:50:27.564553 916722 sgd_solver.cpp:106] Iteration 3866500, lr = 0.01
I0901 01:50:57.305929 916722 solver.cpp:218] Iteration 3867000 (16.8117 iter/s, 29.7411s/500 iters), loss = 0.300146
I0901 01:50:57.306003 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.300148 (* 1 = 0.300148 loss)
I0901 01:50:57.306021 916722 sgd_solver.cpp:106] Iteration 3867000, lr = 0.01
I0901 01:51:27.048135 916722 solver.cpp:218] Iteration 3867500 (16.8113 iter/s, 29.7419s/500 iters), loss = 0.176405
I0901 01:51:27.048189 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.176407 (* 1 = 0.176407 loss)
I0901 01:51:27.048198 916722 sgd_solver.cpp:106] Iteration 3867500, lr = 0.01
I0901 01:51:56.796020 916722 solver.cpp:218] Iteration 3868000 (16.8081 iter/s, 29.7476s/500 iters), loss = 0.151135
I0901 01:51:56.796077 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.151138 (* 1 = 0.151138 loss)
I0901 01:51:56.796087 916722 sgd_solver.cpp:106] Iteration 3868000, lr = 0.01
I0901 01:52:26.535048 916722 solver.cpp:218] Iteration 3868500 (16.8131 iter/s, 29.7387s/500 iters), loss = 0.159809
I0901 01:52:26.535096 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159812 (* 1 = 0.159812 loss)
I0901 01:52:26.535105 916722 sgd_solver.cpp:106] Iteration 3868500, lr = 0.01
I0901 01:52:56.258286 916722 solver.cpp:218] Iteration 3869000 (16.822 iter/s, 29.7229s/500 iters), loss = 0.0447476
I0901 01:52:56.258345 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0447498 (* 1 = 0.0447498 loss)
I0901 01:52:56.258353 916722 sgd_solver.cpp:106] Iteration 3869000, lr = 0.01
I0901 01:53:25.984346 916722 solver.cpp:218] Iteration 3869500 (16.8204 iter/s, 29.7257s/500 iters), loss = 0.113237
I0901 01:53:25.984402 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.113239 (* 1 = 0.113239 loss)
I0901 01:53:25.984411 916722 sgd_solver.cpp:106] Iteration 3869500, lr = 0.01
I0901 01:53:55.707038 916722 solver.cpp:218] Iteration 3870000 (16.8223 iter/s, 29.7224s/500 iters), loss = 0.150719
I0901 01:53:55.707099 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.150721 (* 1 = 0.150721 loss)
I0901 01:53:55.707108 916722 sgd_solver.cpp:106] Iteration 3870000, lr = 0.01
I0901 01:54:25.420905 916722 solver.cpp:218] Iteration 3870500 (16.8273 iter/s, 29.7136s/500 iters), loss = 0.0638113
I0901 01:54:25.420960 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0638133 (* 1 = 0.0638133 loss)
I0901 01:54:25.420970 916722 sgd_solver.cpp:106] Iteration 3870500, lr = 0.01
I0901 01:54:55.134536 916722 solver.cpp:218] Iteration 3871000 (16.8275 iter/s, 29.7133s/500 iters), loss = 0.0188638
I0901 01:54:55.134593 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.018866 (* 1 = 0.018866 loss)
I0901 01:54:55.134601 916722 sgd_solver.cpp:106] Iteration 3871000, lr = 0.01
I0901 01:55:24.852056 916722 solver.cpp:218] Iteration 3871500 (16.8253 iter/s, 29.7172s/500 iters), loss = 0.130172
I0901 01:55:24.852108 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130175 (* 1 = 0.130175 loss)
I0901 01:55:24.852118 916722 sgd_solver.cpp:106] Iteration 3871500, lr = 0.01
I0901 01:55:54.565133 916722 solver.cpp:218] Iteration 3872000 (16.8278 iter/s, 29.7128s/500 iters), loss = 0.107274
I0901 01:55:54.565191 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.107276 (* 1 = 0.107276 loss)
I0901 01:55:54.565199 916722 sgd_solver.cpp:106] Iteration 3872000, lr = 0.01
I0901 01:56:24.279168 916722 solver.cpp:218] Iteration 3872500 (16.8272 iter/s, 29.7137s/500 iters), loss = 0.305735
I0901 01:56:24.279219 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.305737 (* 1 = 0.305737 loss)
I0901 01:56:24.279229 916722 sgd_solver.cpp:106] Iteration 3872500, lr = 0.01
I0901 01:56:53.992228 916722 solver.cpp:218] Iteration 3873000 (16.8278 iter/s, 29.7128s/500 iters), loss = 0.320626
I0901 01:56:53.992287 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.320627 (* 1 = 0.320627 loss)
I0901 01:56:53.992295 916722 sgd_solver.cpp:106] Iteration 3873000, lr = 0.01
I0901 01:57:23.708887 916722 solver.cpp:218] Iteration 3873500 (16.8257 iter/s, 29.7164s/500 iters), loss = 0.103807
I0901 01:57:23.708937 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.103808 (* 1 = 0.103808 loss)
I0901 01:57:23.708947 916722 sgd_solver.cpp:106] Iteration 3873500, lr = 0.01
I0901 01:57:53.419989 916722 solver.cpp:218] Iteration 3874000 (16.8289 iter/s, 29.7108s/500 iters), loss = 0.137289
I0901 01:57:53.420058 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.137291 (* 1 = 0.137291 loss)
I0901 01:57:53.420068 916722 sgd_solver.cpp:106] Iteration 3874000, lr = 0.01
I0901 01:58:23.130265 916722 solver.cpp:218] Iteration 3874500 (16.8294 iter/s, 29.71s/500 iters), loss = 0.0853233
I0901 01:58:23.130316 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0853248 (* 1 = 0.0853248 loss)
I0901 01:58:23.130326 916722 sgd_solver.cpp:106] Iteration 3874500, lr = 0.01
I0901 01:58:52.840451 916722 solver.cpp:218] Iteration 3875000 (16.8294 iter/s, 29.7099s/500 iters), loss = 0.0925206
I0901 01:58:52.840510 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.092522 (* 1 = 0.092522 loss)
I0901 01:58:52.840518 916722 sgd_solver.cpp:106] Iteration 3875000, lr = 0.01
I0901 01:59:22.555053 916722 solver.cpp:218] Iteration 3875500 (16.8269 iter/s, 29.7143s/500 iters), loss = 0.408187
I0901 01:59:22.555106 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.408188 (* 1 = 0.408188 loss)
I0901 01:59:22.555116 916722 sgd_solver.cpp:106] Iteration 3875500, lr = 0.01
I0901 01:59:52.267798 916722 solver.cpp:218] Iteration 3876000 (16.8278 iter/s, 29.7127s/500 iters), loss = 0.0966391
I0901 01:59:52.267860 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0966406 (* 1 = 0.0966406 loss)
I0901 01:59:52.267868 916722 sgd_solver.cpp:106] Iteration 3876000, lr = 0.01
I0901 02:00:21.982671 916722 solver.cpp:218] Iteration 3876500 (16.8265 iter/s, 29.715s/500 iters), loss = 0.320211
I0901 02:00:21.982722 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.320213 (* 1 = 0.320213 loss)
I0901 02:00:21.982729 916722 sgd_solver.cpp:106] Iteration 3876500, lr = 0.01
I0901 02:00:51.696684 916722 solver.cpp:218] Iteration 3877000 (16.827 iter/s, 29.7142s/500 iters), loss = 0.0392574
I0901 02:00:51.696741 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0392591 (* 1 = 0.0392591 loss)
I0901 02:00:51.696750 916722 sgd_solver.cpp:106] Iteration 3877000, lr = 0.01
I0901 02:01:21.409142 916722 solver.cpp:218] Iteration 3877500 (16.8279 iter/s, 29.7126s/500 iters), loss = 0.0780569
I0901 02:01:21.409193 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0780586 (* 1 = 0.0780586 loss)
I0901 02:01:21.409202 916722 sgd_solver.cpp:106] Iteration 3877500, lr = 0.01
I0901 02:01:51.121181 916722 solver.cpp:218] Iteration 3878000 (16.8281 iter/s, 29.7122s/500 iters), loss = 0.182816
I0901 02:01:51.121237 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.182817 (* 1 = 0.182817 loss)
I0901 02:01:51.121245 916722 sgd_solver.cpp:106] Iteration 3878000, lr = 0.01
I0901 02:02:20.832824 916722 solver.cpp:218] Iteration 3878500 (16.8284 iter/s, 29.7117s/500 iters), loss = 0.131139
I0901 02:02:20.832875 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131141 (* 1 = 0.131141 loss)
I0901 02:02:20.832885 916722 sgd_solver.cpp:106] Iteration 3878500, lr = 0.01
I0901 02:02:50.547940 916722 solver.cpp:218] Iteration 3879000 (16.8264 iter/s, 29.7152s/500 iters), loss = 0.111867
I0901 02:02:50.548002 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111868 (* 1 = 0.111868 loss)
I0901 02:02:50.548010 916722 sgd_solver.cpp:106] Iteration 3879000, lr = 0.01
I0901 02:03:20.261955 916722 solver.cpp:218] Iteration 3879500 (16.827 iter/s, 29.7141s/500 iters), loss = 0.156801
I0901 02:03:20.262007 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.156803 (* 1 = 0.156803 loss)
I0901 02:03:20.262017 916722 sgd_solver.cpp:106] Iteration 3879500, lr = 0.01
I0901 02:03:49.973424 916722 solver.cpp:218] Iteration 3880000 (16.8285 iter/s, 29.7115s/500 iters), loss = 0.00891274
I0901 02:03:49.973484 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.00891434 (* 1 = 0.00891434 loss)
I0901 02:03:49.973493 916722 sgd_solver.cpp:106] Iteration 3880000, lr = 0.01
I0901 02:04:19.684541 916722 solver.cpp:218] Iteration 3880500 (16.8287 iter/s, 29.7111s/500 iters), loss = 0.285593
I0901 02:04:19.684595 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.285594 (* 1 = 0.285594 loss)
I0901 02:04:19.684605 916722 sgd_solver.cpp:106] Iteration 3880500, lr = 0.01
I0901 02:04:49.396620 916722 solver.cpp:218] Iteration 3881000 (16.8282 iter/s, 29.7121s/500 iters), loss = 0.0718578
I0901 02:04:49.396689 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0718596 (* 1 = 0.0718596 loss)
I0901 02:04:49.396698 916722 sgd_solver.cpp:106] Iteration 3881000, lr = 0.01
I0901 02:05:19.109587 916722 solver.cpp:218] Iteration 3881500 (16.8277 iter/s, 29.713s/500 iters), loss = 0.292181
I0901 02:05:19.109637 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.292183 (* 1 = 0.292183 loss)
I0901 02:05:19.109647 916722 sgd_solver.cpp:106] Iteration 3881500, lr = 0.01
I0901 02:05:48.826725 916722 solver.cpp:218] Iteration 3882000 (16.8253 iter/s, 29.7171s/500 iters), loss = 0.187756
I0901 02:05:48.826781 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.187758 (* 1 = 0.187758 loss)
I0901 02:05:48.826788 916722 sgd_solver.cpp:106] Iteration 3882000, lr = 0.01
I0901 02:06:18.539909 916722 solver.cpp:218] Iteration 3882500 (16.8276 iter/s, 29.7132s/500 iters), loss = 0.220659
I0901 02:06:18.539956 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.22066 (* 1 = 0.22066 loss)
I0901 02:06:18.539968 916722 sgd_solver.cpp:106] Iteration 3882500, lr = 0.01
I0901 02:06:48.253806 916722 solver.cpp:218] Iteration 3883000 (16.8272 iter/s, 29.7139s/500 iters), loss = 0.0851863
I0901 02:06:48.253865 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0851879 (* 1 = 0.0851879 loss)
I0901 02:06:48.253875 916722 sgd_solver.cpp:106] Iteration 3883000, lr = 0.01
I0901 02:07:17.966396 916722 solver.cpp:218] Iteration 3883500 (16.8279 iter/s, 29.7125s/500 iters), loss = 0.0296291
I0901 02:07:17.966449 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0296308 (* 1 = 0.0296308 loss)
I0901 02:07:17.966459 916722 sgd_solver.cpp:106] Iteration 3883500, lr = 0.01
I0901 02:07:47.682209 916722 solver.cpp:218] Iteration 3884000 (16.8261 iter/s, 29.7158s/500 iters), loss = 0.124973
I0901 02:07:47.682267 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.124975 (* 1 = 0.124975 loss)
I0901 02:07:47.682276 916722 sgd_solver.cpp:106] Iteration 3884000, lr = 0.01
I0901 02:08:17.396145 916722 solver.cpp:218] Iteration 3884500 (16.8272 iter/s, 29.7139s/500 iters), loss = 0.0562395
I0901 02:08:17.396196 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0562413 (* 1 = 0.0562413 loss)
I0901 02:08:17.396206 916722 sgd_solver.cpp:106] Iteration 3884500, lr = 0.01
I0901 02:08:47.107661 916722 solver.cpp:218] Iteration 3885000 (16.8285 iter/s, 29.7114s/500 iters), loss = 0.140186
I0901 02:08:47.107717 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.140188 (* 1 = 0.140188 loss)
I0901 02:08:47.107725 916722 sgd_solver.cpp:106] Iteration 3885000, lr = 0.01
I0901 02:09:16.820309 916722 solver.cpp:218] Iteration 3885500 (16.8279 iter/s, 29.7126s/500 iters), loss = 0.0731932
I0901 02:09:16.820361 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0731951 (* 1 = 0.0731951 loss)
I0901 02:09:16.820371 916722 sgd_solver.cpp:106] Iteration 3885500, lr = 0.01
I0901 02:09:46.535275 916722 solver.cpp:218] Iteration 3886000 (16.8266 iter/s, 29.7149s/500 iters), loss = 0.249838
I0901 02:09:46.535336 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.24984 (* 1 = 0.24984 loss)
I0901 02:09:46.535344 916722 sgd_solver.cpp:106] Iteration 3886000, lr = 0.01
I0901 02:10:16.250620 916722 solver.cpp:218] Iteration 3886500 (16.8264 iter/s, 29.7152s/500 iters), loss = 0.0351164
I0901 02:10:16.250671 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0351183 (* 1 = 0.0351183 loss)
I0901 02:10:16.250680 916722 sgd_solver.cpp:106] Iteration 3886500, lr = 0.01
I0901 02:10:45.965098 916722 solver.cpp:218] Iteration 3887000 (16.8269 iter/s, 29.7144s/500 iters), loss = 0.0818733
I0901 02:10:45.965174 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0818752 (* 1 = 0.0818752 loss)
I0901 02:10:45.965183 916722 sgd_solver.cpp:106] Iteration 3887000, lr = 0.01
I0901 02:11:15.674715 916722 solver.cpp:218] Iteration 3887500 (16.8296 iter/s, 29.7095s/500 iters), loss = 0.226769
I0901 02:11:15.674767 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.226771 (* 1 = 0.226771 loss)
I0901 02:11:15.674775 916722 sgd_solver.cpp:106] Iteration 3887500, lr = 0.01
I0901 02:11:45.385301 916722 solver.cpp:218] Iteration 3888000 (16.8291 iter/s, 29.7105s/500 iters), loss = 0.109799
I0901 02:11:45.385361 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109801 (* 1 = 0.109801 loss)
I0901 02:11:45.385370 916722 sgd_solver.cpp:106] Iteration 3888000, lr = 0.01
I0901 02:12:15.095131 916722 solver.cpp:218] Iteration 3888500 (16.8295 iter/s, 29.7097s/500 iters), loss = 0.134627
I0901 02:12:15.095181 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.134629 (* 1 = 0.134629 loss)
I0901 02:12:15.095191 916722 sgd_solver.cpp:106] Iteration 3888500, lr = 0.01
I0901 02:12:44.804855 916722 solver.cpp:218] Iteration 3889000 (16.8296 iter/s, 29.7096s/500 iters), loss = 0.0263976
I0901 02:12:44.804913 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0263994 (* 1 = 0.0263994 loss)
I0901 02:12:44.804921 916722 sgd_solver.cpp:106] Iteration 3889000, lr = 0.01
I0901 02:13:14.519589 916722 solver.cpp:218] Iteration 3889500 (16.8267 iter/s, 29.7146s/500 iters), loss = 0.101443
I0901 02:13:14.519641 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101445 (* 1 = 0.101445 loss)
I0901 02:13:14.519649 916722 sgd_solver.cpp:106] Iteration 3889500, lr = 0.01
I0901 02:13:44.237183 916722 solver.cpp:218] Iteration 3890000 (16.8251 iter/s, 29.7175s/500 iters), loss = 0.146158
I0901 02:13:44.237244 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.14616 (* 1 = 0.14616 loss)
I0901 02:13:44.237252 916722 sgd_solver.cpp:106] Iteration 3890000, lr = 0.01
I0901 02:14:13.951687 916722 solver.cpp:218] Iteration 3890500 (16.8269 iter/s, 29.7144s/500 iters), loss = 0.0357948
I0901 02:14:13.951742 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0357966 (* 1 = 0.0357966 loss)
I0901 02:14:13.951752 916722 sgd_solver.cpp:106] Iteration 3890500, lr = 0.01
I0901 02:14:43.663324 916722 solver.cpp:218] Iteration 3891000 (16.8285 iter/s, 29.7115s/500 iters), loss = 0.129791
I0901 02:14:43.663381 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.129793 (* 1 = 0.129793 loss)
I0901 02:14:43.663390 916722 sgd_solver.cpp:106] Iteration 3891000, lr = 0.01
I0901 02:15:13.375262 916722 solver.cpp:218] Iteration 3891500 (16.8283 iter/s, 29.7118s/500 iters), loss = 0.17911
I0901 02:15:13.375313 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.179112 (* 1 = 0.179112 loss)
I0901 02:15:13.375322 916722 sgd_solver.cpp:106] Iteration 3891500, lr = 0.01
I0901 02:15:43.089629 916722 solver.cpp:218] Iteration 3892000 (16.827 iter/s, 29.7142s/500 iters), loss = 0.0895382
I0901 02:15:43.089687 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0895401 (* 1 = 0.0895401 loss)
I0901 02:15:43.089695 916722 sgd_solver.cpp:106] Iteration 3892000, lr = 0.01
I0901 02:16:12.804729 916722 solver.cpp:218] Iteration 3892500 (16.8265 iter/s, 29.7149s/500 iters), loss = 0.223497
I0901 02:16:12.804782 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.223499 (* 1 = 0.223499 loss)
I0901 02:16:12.804792 916722 sgd_solver.cpp:106] Iteration 3892500, lr = 0.01
I0901 02:16:42.517972 916722 solver.cpp:218] Iteration 3893000 (16.8276 iter/s, 29.7131s/500 iters), loss = 0.118963
I0901 02:16:42.518029 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.118965 (* 1 = 0.118965 loss)
I0901 02:16:42.518038 916722 sgd_solver.cpp:106] Iteration 3893000, lr = 0.01
I0901 02:17:12.230705 916722 solver.cpp:218] Iteration 3893500 (16.8279 iter/s, 29.7126s/500 iters), loss = 0.0206421
I0901 02:17:12.230765 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0206441 (* 1 = 0.0206441 loss)
I0901 02:17:12.230775 916722 sgd_solver.cpp:106] Iteration 3893500, lr = 0.01
I0901 02:17:41.945363 916722 solver.cpp:218] Iteration 3894000 (16.8268 iter/s, 29.7145s/500 iters), loss = 0.250109
I0901 02:17:41.945430 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.250111 (* 1 = 0.250111 loss)
I0901 02:17:41.945438 916722 sgd_solver.cpp:106] Iteration 3894000, lr = 0.01
I0901 02:18:11.660357 916722 solver.cpp:218] Iteration 3894500 (16.8266 iter/s, 29.7148s/500 iters), loss = 0.193526
I0901 02:18:11.660409 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.193529 (* 1 = 0.193529 loss)
I0901 02:18:11.660419 916722 sgd_solver.cpp:106] Iteration 3894500, lr = 0.01
I0901 02:18:41.375222 916722 solver.cpp:218] Iteration 3895000 (16.8267 iter/s, 29.7147s/500 iters), loss = 0.0471268
I0901 02:18:41.375279 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0471292 (* 1 = 0.0471292 loss)
I0901 02:18:41.375288 916722 sgd_solver.cpp:106] Iteration 3895000, lr = 0.01
I0901 02:19:11.088302 916722 solver.cpp:218] Iteration 3895500 (16.8277 iter/s, 29.7129s/500 iters), loss = 0.140604
I0901 02:19:11.088353 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.140607 (* 1 = 0.140607 loss)
I0901 02:19:11.088363 916722 sgd_solver.cpp:106] Iteration 3895500, lr = 0.01
I0901 02:19:40.801285 916722 solver.cpp:218] Iteration 3896000 (16.8278 iter/s, 29.7128s/500 iters), loss = 0.0300829
I0901 02:19:40.801343 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0300853 (* 1 = 0.0300853 loss)
I0901 02:19:40.801352 916722 sgd_solver.cpp:106] Iteration 3896000, lr = 0.01
I0901 02:20:10.519937 916722 solver.cpp:218] Iteration 3896500 (16.8246 iter/s, 29.7185s/500 iters), loss = 0.206856
I0901 02:20:10.519987 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.206859 (* 1 = 0.206859 loss)
I0901 02:20:10.519997 916722 sgd_solver.cpp:106] Iteration 3896500, lr = 0.01
I0901 02:20:40.238462 916722 solver.cpp:218] Iteration 3897000 (16.8246 iter/s, 29.7183s/500 iters), loss = 0.238579
I0901 02:20:40.238519 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.238581 (* 1 = 0.238581 loss)
I0901 02:20:40.238528 916722 sgd_solver.cpp:106] Iteration 3897000, lr = 0.01
I0901 02:21:09.954963 916722 solver.cpp:218] Iteration 3897500 (16.8258 iter/s, 29.7163s/500 iters), loss = 0.0728584
I0901 02:21:09.955013 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0728608 (* 1 = 0.0728608 loss)
I0901 02:21:09.955022 916722 sgd_solver.cpp:106] Iteration 3897500, lr = 0.01
I0901 02:21:39.670043 916722 solver.cpp:218] Iteration 3898000 (16.8266 iter/s, 29.7149s/500 iters), loss = 0.163903
I0901 02:21:39.670097 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.163905 (* 1 = 0.163905 loss)
I0901 02:21:39.670105 916722 sgd_solver.cpp:106] Iteration 3898000, lr = 0.01
I0901 02:22:09.384999 916722 solver.cpp:218] Iteration 3898500 (16.8266 iter/s, 29.7148s/500 iters), loss = 0.167068
I0901 02:22:09.385049 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.16707 (* 1 = 0.16707 loss)
I0901 02:22:09.385061 916722 sgd_solver.cpp:106] Iteration 3898500, lr = 0.01
I0901 02:22:39.097781 916722 solver.cpp:218] Iteration 3899000 (16.8279 iter/s, 29.7126s/500 iters), loss = 0.0333879
I0901 02:22:39.097839 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0333903 (* 1 = 0.0333903 loss)
I0901 02:22:39.097848 916722 sgd_solver.cpp:106] Iteration 3899000, lr = 0.01
I0901 02:23:08.812988 916722 solver.cpp:218] Iteration 3899500 (16.8265 iter/s, 29.715s/500 iters), loss = 0.30754
I0901 02:23:08.813040 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.307542 (* 1 = 0.307542 loss)
I0901 02:23:08.813050 916722 sgd_solver.cpp:106] Iteration 3899500, lr = 0.01
I0901 02:23:38.469427 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_3900000.caffemodel
I0901 02:23:38.488447 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_3900000.solverstate
I0901 02:23:38.494469 916722 solver.cpp:330] Iteration 3900000, Testing net (#0)
I0901 02:23:53.904609 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8523
I0901 02:23:53.904649 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.51197 (* 1 = 0.51197 loss)
I0901 02:23:53.963097 916722 solver.cpp:218] Iteration 3900000 (11.0742 iter/s, 45.1499s/500 iters), loss = 0.168646
I0901 02:23:53.963124 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.168648 (* 1 = 0.168648 loss)
I0901 02:23:53.963131 916722 sgd_solver.cpp:106] Iteration 3900000, lr = 0.01
I0901 02:24:23.550376 916722 solver.cpp:218] Iteration 3900500 (16.8993 iter/s, 29.5871s/500 iters), loss = 0.0427777
I0901 02:24:23.550434 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.04278 (* 1 = 0.04278 loss)
I0901 02:24:23.550442 916722 sgd_solver.cpp:106] Iteration 3900500, lr = 0.01
I0901 02:24:53.235262 916722 solver.cpp:218] Iteration 3901000 (16.8437 iter/s, 29.6847s/500 iters), loss = 0.0652189
I0901 02:24:53.235316 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0652212 (* 1 = 0.0652212 loss)
I0901 02:24:53.235327 916722 sgd_solver.cpp:106] Iteration 3901000, lr = 0.01
I0901 02:25:22.924978 916722 solver.cpp:218] Iteration 3901500 (16.841 iter/s, 29.6895s/500 iters), loss = 0.216983
I0901 02:25:22.925038 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.216986 (* 1 = 0.216986 loss)
I0901 02:25:22.925047 916722 sgd_solver.cpp:106] Iteration 3901500, lr = 0.01
I0901 02:25:52.617908 916722 solver.cpp:218] Iteration 3902000 (16.8391 iter/s, 29.6927s/500 iters), loss = 0.0554712
I0901 02:25:52.617961 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0554738 (* 1 = 0.0554738 loss)
I0901 02:25:52.617971 916722 sgd_solver.cpp:106] Iteration 3902000, lr = 0.01
I0901 02:26:22.309196 916722 solver.cpp:218] Iteration 3902500 (16.8401 iter/s, 29.6911s/500 iters), loss = 0.228284
I0901 02:26:22.309253 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.228286 (* 1 = 0.228286 loss)
I0901 02:26:22.309262 916722 sgd_solver.cpp:106] Iteration 3902500, lr = 0.01
I0901 02:26:52.000779 916722 solver.cpp:218] Iteration 3903000 (16.8399 iter/s, 29.6914s/500 iters), loss = 0.201045
I0901 02:26:52.000831 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.201048 (* 1 = 0.201048 loss)
I0901 02:26:52.000841 916722 sgd_solver.cpp:106] Iteration 3903000, lr = 0.01
I0901 02:27:21.692906 916722 solver.cpp:218] Iteration 3903500 (16.8396 iter/s, 29.6919s/500 iters), loss = 0.114064
I0901 02:27:21.692965 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.114067 (* 1 = 0.114067 loss)
I0901 02:27:21.692975 916722 sgd_solver.cpp:106] Iteration 3903500, lr = 0.01
I0901 02:27:51.386902 916722 solver.cpp:218] Iteration 3904000 (16.8385 iter/s, 29.6938s/500 iters), loss = 0.134502
I0901 02:27:51.386955 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.134505 (* 1 = 0.134505 loss)
I0901 02:27:51.386963 916722 sgd_solver.cpp:106] Iteration 3904000, lr = 0.01
I0901 02:28:21.083595 916722 solver.cpp:218] Iteration 3904500 (16.837 iter/s, 29.6965s/500 iters), loss = 0.166291
I0901 02:28:21.083652 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.166294 (* 1 = 0.166294 loss)
I0901 02:28:21.083660 916722 sgd_solver.cpp:106] Iteration 3904500, lr = 0.01
I0901 02:28:50.777689 916722 solver.cpp:218] Iteration 3905000 (16.8385 iter/s, 29.6939s/500 iters), loss = 0.145702
I0901 02:28:50.777741 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.145705 (* 1 = 0.145705 loss)
I0901 02:28:50.777750 916722 sgd_solver.cpp:106] Iteration 3905000, lr = 0.01
I0901 02:29:20.469372 916722 solver.cpp:218] Iteration 3905500 (16.8398 iter/s, 29.6915s/500 iters), loss = 0.139407
I0901 02:29:20.469440 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139409 (* 1 = 0.139409 loss)
I0901 02:29:20.469453 916722 sgd_solver.cpp:106] Iteration 3905500, lr = 0.01
I0901 02:29:50.162477 916722 solver.cpp:218] Iteration 3906000 (16.839 iter/s, 29.6929s/500 iters), loss = 0.0523456
I0901 02:29:50.162530 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0523484 (* 1 = 0.0523484 loss)
I0901 02:29:50.162539 916722 sgd_solver.cpp:106] Iteration 3906000, lr = 0.01
I0901 02:30:19.852381 916722 solver.cpp:218] Iteration 3906500 (16.8409 iter/s, 29.6897s/500 iters), loss = 0.211258
I0901 02:30:19.852444 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.21126 (* 1 = 0.21126 loss)
I0901 02:30:19.852453 916722 sgd_solver.cpp:106] Iteration 3906500, lr = 0.01
I0901 02:30:49.542762 916722 solver.cpp:218] Iteration 3907000 (16.8406 iter/s, 29.6902s/500 iters), loss = 0.228585
I0901 02:30:49.542814 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.228588 (* 1 = 0.228588 loss)
I0901 02:30:49.542822 916722 sgd_solver.cpp:106] Iteration 3907000, lr = 0.01
I0901 02:31:19.238684 916722 solver.cpp:218] Iteration 3907500 (16.8374 iter/s, 29.6957s/500 iters), loss = 0.123318
I0901 02:31:19.238742 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.123321 (* 1 = 0.123321 loss)
I0901 02:31:19.238750 916722 sgd_solver.cpp:106] Iteration 3907500, lr = 0.01
I0901 02:31:48.931250 916722 solver.cpp:218] Iteration 3908000 (16.8393 iter/s, 29.6924s/500 iters), loss = 0.272129
I0901 02:31:48.931301 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.272132 (* 1 = 0.272132 loss)
I0901 02:31:48.931310 916722 sgd_solver.cpp:106] Iteration 3908000, lr = 0.01
I0901 02:32:18.642344 916722 solver.cpp:218] Iteration 3908500 (16.8288 iter/s, 29.7109s/500 iters), loss = 0.183701
I0901 02:32:18.642400 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.183704 (* 1 = 0.183704 loss)
I0901 02:32:18.642408 916722 sgd_solver.cpp:106] Iteration 3908500, lr = 0.01
I0901 02:32:48.357795 916722 solver.cpp:218] Iteration 3909000 (16.8264 iter/s, 29.7152s/500 iters), loss = 0.153371
I0901 02:32:48.357846 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.153373 (* 1 = 0.153373 loss)
I0901 02:32:48.357854 916722 sgd_solver.cpp:106] Iteration 3909000, lr = 0.01
I0901 02:33:18.072091 916722 solver.cpp:218] Iteration 3909500 (16.827 iter/s, 29.7141s/500 iters), loss = 0.0651196
I0901 02:33:18.072151 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0651223 (* 1 = 0.0651223 loss)
I0901 02:33:18.072160 916722 sgd_solver.cpp:106] Iteration 3909500, lr = 0.01
I0901 02:33:47.786180 916722 solver.cpp:218] Iteration 3910000 (16.8272 iter/s, 29.7139s/500 iters), loss = 0.0289489
I0901 02:33:47.786232 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0289517 (* 1 = 0.0289517 loss)
I0901 02:33:47.786242 916722 sgd_solver.cpp:106] Iteration 3910000, lr = 0.01
I0901 02:34:17.506880 916722 solver.cpp:218] Iteration 3910500 (16.8233 iter/s, 29.7207s/500 iters), loss = 0.0848818
I0901 02:34:17.506940 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0848845 (* 1 = 0.0848845 loss)
I0901 02:34:17.506949 916722 sgd_solver.cpp:106] Iteration 3910500, lr = 0.01
I0901 02:34:47.223085 916722 solver.cpp:218] Iteration 3911000 (16.8258 iter/s, 29.7162s/500 iters), loss = 0.192729
I0901 02:34:47.223138 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.192731 (* 1 = 0.192731 loss)
I0901 02:34:47.223147 916722 sgd_solver.cpp:106] Iteration 3911000, lr = 0.01
I0901 02:35:16.939873 916722 solver.cpp:218] Iteration 3911500 (16.8255 iter/s, 29.7168s/500 iters), loss = 0.0908944
I0901 02:35:16.939934 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.090897 (* 1 = 0.090897 loss)
I0901 02:35:16.939942 916722 sgd_solver.cpp:106] Iteration 3911500, lr = 0.01
I0901 02:35:46.655980 916722 solver.cpp:218] Iteration 3912000 (16.8259 iter/s, 29.7161s/500 iters), loss = 0.011494
I0901 02:35:46.656033 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0114966 (* 1 = 0.0114966 loss)
I0901 02:35:46.656041 916722 sgd_solver.cpp:106] Iteration 3912000, lr = 0.01
I0901 02:36:16.374042 916722 solver.cpp:218] Iteration 3912500 (16.8248 iter/s, 29.718s/500 iters), loss = 0.114053
I0901 02:36:16.374109 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.114056 (* 1 = 0.114056 loss)
I0901 02:36:16.374116 916722 sgd_solver.cpp:106] Iteration 3912500, lr = 0.01
I0901 02:36:46.090297 916722 solver.cpp:218] Iteration 3913000 (16.8258 iter/s, 29.7162s/500 iters), loss = 0.0122484
I0901 02:36:46.090348 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0122509 (* 1 = 0.0122509 loss)
I0901 02:36:46.090356 916722 sgd_solver.cpp:106] Iteration 3913000, lr = 0.01
I0901 02:37:15.804996 916722 solver.cpp:218] Iteration 3913500 (16.8267 iter/s, 29.7147s/500 iters), loss = 0.254728
I0901 02:37:15.805049 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.254731 (* 1 = 0.254731 loss)
I0901 02:37:15.805058 916722 sgd_solver.cpp:106] Iteration 3913500, lr = 0.01
I0901 02:37:45.522008 916722 solver.cpp:218] Iteration 3914000 (16.8254 iter/s, 29.717s/500 iters), loss = 0.196113
I0901 02:37:45.522063 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.196116 (* 1 = 0.196116 loss)
I0901 02:37:45.522073 916722 sgd_solver.cpp:106] Iteration 3914000, lr = 0.01
I0901 02:38:15.243500 916722 solver.cpp:218] Iteration 3914500 (16.8229 iter/s, 29.7214s/500 iters), loss = 0.38355
I0901 02:38:15.243558 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.383552 (* 1 = 0.383552 loss)
I0901 02:38:15.243567 916722 sgd_solver.cpp:106] Iteration 3914500, lr = 0.01
I0901 02:38:44.958334 916722 solver.cpp:218] Iteration 3915000 (16.8266 iter/s, 29.7148s/500 iters), loss = 0.345355
I0901 02:38:44.958385 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.345358 (* 1 = 0.345358 loss)
I0901 02:38:44.958396 916722 sgd_solver.cpp:106] Iteration 3915000, lr = 0.01
I0901 02:39:14.673877 916722 solver.cpp:218] Iteration 3915500 (16.8263 iter/s, 29.7155s/500 iters), loss = 0.184745
I0901 02:39:14.673933 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.184748 (* 1 = 0.184748 loss)
I0901 02:39:14.673943 916722 sgd_solver.cpp:106] Iteration 3915500, lr = 0.01
I0901 02:39:44.390516 916722 solver.cpp:218] Iteration 3916000 (16.8256 iter/s, 29.7166s/500 iters), loss = 0.0573839
I0901 02:39:44.390568 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0573864 (* 1 = 0.0573864 loss)
I0901 02:39:44.390578 916722 sgd_solver.cpp:106] Iteration 3916000, lr = 0.01
I0901 02:40:14.109803 916722 solver.cpp:218] Iteration 3916500 (16.8241 iter/s, 29.7192s/500 iters), loss = 0.0696662
I0901 02:40:14.109860 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0696689 (* 1 = 0.0696689 loss)
I0901 02:40:14.109869 916722 sgd_solver.cpp:106] Iteration 3916500, lr = 0.01
I0901 02:40:43.823549 916722 solver.cpp:218] Iteration 3917000 (16.8273 iter/s, 29.7137s/500 iters), loss = 0.0335441
I0901 02:40:43.823601 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0335467 (* 1 = 0.0335467 loss)
I0901 02:40:43.823611 916722 sgd_solver.cpp:106] Iteration 3917000, lr = 0.01
I0901 02:41:13.538305 916722 solver.cpp:218] Iteration 3917500 (16.8267 iter/s, 29.7147s/500 iters), loss = 0.1333
I0901 02:41:13.538359 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133303 (* 1 = 0.133303 loss)
I0901 02:41:13.538367 916722 sgd_solver.cpp:106] Iteration 3917500, lr = 0.01
I0901 02:41:43.253186 916722 solver.cpp:218] Iteration 3918000 (16.8266 iter/s, 29.7148s/500 iters), loss = 0.0797335
I0901 02:41:43.253237 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0797361 (* 1 = 0.0797361 loss)
I0901 02:41:43.253248 916722 sgd_solver.cpp:106] Iteration 3918000, lr = 0.01
I0901 02:42:12.970062 916722 solver.cpp:218] Iteration 3918500 (16.8255 iter/s, 29.7168s/500 iters), loss = 0.0216673
I0901 02:42:12.970118 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0216697 (* 1 = 0.0216697 loss)
I0901 02:42:12.970127 916722 sgd_solver.cpp:106] Iteration 3918500, lr = 0.01
I0901 02:42:42.685889 916722 solver.cpp:218] Iteration 3919000 (16.8261 iter/s, 29.7157s/500 iters), loss = 0.105589
I0901 02:42:42.685940 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105592 (* 1 = 0.105592 loss)
I0901 02:42:42.685951 916722 sgd_solver.cpp:106] Iteration 3919000, lr = 0.01
I0901 02:43:12.405355 916722 solver.cpp:218] Iteration 3919500 (16.8241 iter/s, 29.7194s/500 iters), loss = 0.0700092
I0901 02:43:12.405426 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0700114 (* 1 = 0.0700114 loss)
I0901 02:43:12.405436 916722 sgd_solver.cpp:106] Iteration 3919500, lr = 0.01
I0901 02:43:42.119341 916722 solver.cpp:218] Iteration 3920000 (16.8272 iter/s, 29.7139s/500 iters), loss = 0.164861
I0901 02:43:42.119392 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.164863 (* 1 = 0.164863 loss)
I0901 02:43:42.119401 916722 sgd_solver.cpp:106] Iteration 3920000, lr = 0.01
I0901 02:44:11.838452 916722 solver.cpp:218] Iteration 3920500 (16.8243 iter/s, 29.719s/500 iters), loss = 0.175186
I0901 02:44:11.838510 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.175188 (* 1 = 0.175188 loss)
I0901 02:44:11.838518 916722 sgd_solver.cpp:106] Iteration 3920500, lr = 0.01
I0901 02:44:41.553212 916722 solver.cpp:218] Iteration 3921000 (16.8267 iter/s, 29.7146s/500 iters), loss = 0.228162
I0901 02:44:41.553261 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.228164 (* 1 = 0.228164 loss)
I0901 02:44:41.553270 916722 sgd_solver.cpp:106] Iteration 3921000, lr = 0.01
I0901 02:45:11.269083 916722 solver.cpp:218] Iteration 3921500 (16.8261 iter/s, 29.7158s/500 iters), loss = 0.322074
I0901 02:45:11.269140 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.322077 (* 1 = 0.322077 loss)
I0901 02:45:11.269148 916722 sgd_solver.cpp:106] Iteration 3921500, lr = 0.01
I0901 02:45:40.981796 916722 solver.cpp:218] Iteration 3922000 (16.8279 iter/s, 29.7126s/500 iters), loss = 0.12212
I0901 02:45:40.981844 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.122123 (* 1 = 0.122123 loss)
I0901 02:45:40.981853 916722 sgd_solver.cpp:106] Iteration 3922000, lr = 0.01
I0901 02:46:10.706387 916722 solver.cpp:218] Iteration 3922500 (16.8212 iter/s, 29.7245s/500 iters), loss = 0.11322
I0901 02:46:10.706445 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.113223 (* 1 = 0.113223 loss)
I0901 02:46:10.706454 916722 sgd_solver.cpp:106] Iteration 3922500, lr = 0.01
I0901 02:46:40.417925 916722 solver.cpp:218] Iteration 3923000 (16.8286 iter/s, 29.7114s/500 iters), loss = 0.142517
I0901 02:46:40.417975 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.142519 (* 1 = 0.142519 loss)
I0901 02:46:40.417984 916722 sgd_solver.cpp:106] Iteration 3923000, lr = 0.01
I0901 02:47:10.128427 916722 solver.cpp:218] Iteration 3923500 (16.8291 iter/s, 29.7104s/500 iters), loss = 0.07618
I0901 02:47:10.128486 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0761824 (* 1 = 0.0761824 loss)
I0901 02:47:10.128495 916722 sgd_solver.cpp:106] Iteration 3923500, lr = 0.01
I0901 02:47:39.837734 916722 solver.cpp:218] Iteration 3924000 (16.8298 iter/s, 29.7092s/500 iters), loss = 0.0646355
I0901 02:47:39.837788 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.064638 (* 1 = 0.064638 loss)
I0901 02:47:39.837798 916722 sgd_solver.cpp:106] Iteration 3924000, lr = 0.01
I0901 02:48:09.548688 916722 solver.cpp:218] Iteration 3924500 (16.8289 iter/s, 29.7108s/500 iters), loss = 0.348778
I0901 02:48:09.548758 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.34878 (* 1 = 0.34878 loss)
I0901 02:48:09.548766 916722 sgd_solver.cpp:106] Iteration 3924500, lr = 0.01
I0901 02:48:39.260470 916722 solver.cpp:218] Iteration 3925000 (16.8284 iter/s, 29.7116s/500 iters), loss = 0.0558534
I0901 02:48:39.260536 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0558561 (* 1 = 0.0558561 loss)
I0901 02:48:39.260565 916722 sgd_solver.cpp:106] Iteration 3925000, lr = 0.01
I0901 02:49:08.971434 916722 solver.cpp:218] Iteration 3925500 (16.8289 iter/s, 29.7108s/500 iters), loss = 0.0486459
I0901 02:49:08.971505 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0486488 (* 1 = 0.0486488 loss)
I0901 02:49:08.971515 916722 sgd_solver.cpp:106] Iteration 3925500, lr = 0.01
I0901 02:49:38.678776 916722 solver.cpp:218] Iteration 3926000 (16.8309 iter/s, 29.7072s/500 iters), loss = 0.178528
I0901 02:49:38.678823 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.178531 (* 1 = 0.178531 loss)
I0901 02:49:38.678833 916722 sgd_solver.cpp:106] Iteration 3926000, lr = 0.01
I0901 02:50:08.386835 916722 solver.cpp:218] Iteration 3926500 (16.8305 iter/s, 29.7079s/500 iters), loss = 0.157091
I0901 02:50:08.386889 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.157094 (* 1 = 0.157094 loss)
I0901 02:50:08.386898 916722 sgd_solver.cpp:106] Iteration 3926500, lr = 0.01
I0901 02:50:38.097394 916722 solver.cpp:218] Iteration 3927000 (16.8291 iter/s, 29.7104s/500 iters), loss = 0.0392995
I0901 02:50:38.097446 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0393024 (* 1 = 0.0393024 loss)
I0901 02:50:38.097456 916722 sgd_solver.cpp:106] Iteration 3927000, lr = 0.01
I0901 02:51:07.806983 916722 solver.cpp:218] Iteration 3927500 (16.8297 iter/s, 29.7094s/500 iters), loss = 0.131433
I0901 02:51:07.807040 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131436 (* 1 = 0.131436 loss)
I0901 02:51:07.807049 916722 sgd_solver.cpp:106] Iteration 3927500, lr = 0.01
I0901 02:51:37.515779 916722 solver.cpp:218] Iteration 3928000 (16.8301 iter/s, 29.7086s/500 iters), loss = 0.0560769
I0901 02:51:37.515825 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0560796 (* 1 = 0.0560796 loss)
I0901 02:51:37.515833 916722 sgd_solver.cpp:106] Iteration 3928000, lr = 0.01
I0901 02:52:07.230260 916722 solver.cpp:218] Iteration 3928500 (16.8269 iter/s, 29.7143s/500 iters), loss = 0.0184518
I0901 02:52:07.230317 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0184544 (* 1 = 0.0184544 loss)
I0901 02:52:07.230326 916722 sgd_solver.cpp:106] Iteration 3928500, lr = 0.01
I0901 02:52:36.940810 916722 solver.cpp:218] Iteration 3929000 (16.8291 iter/s, 29.7104s/500 iters), loss = 0.190289
I0901 02:52:36.940862 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.190291 (* 1 = 0.190291 loss)
I0901 02:52:36.940872 916722 sgd_solver.cpp:106] Iteration 3929000, lr = 0.01
I0901 02:53:06.650835 916722 solver.cpp:218] Iteration 3929500 (16.8294 iter/s, 29.7099s/500 iters), loss = 0.191929
I0901 02:53:06.650890 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.191932 (* 1 = 0.191932 loss)
I0901 02:53:06.650898 916722 sgd_solver.cpp:106] Iteration 3929500, lr = 0.01
I0901 02:53:36.360891 916722 solver.cpp:218] Iteration 3930000 (16.8294 iter/s, 29.7099s/500 iters), loss = 0.0872118
I0901 02:53:36.360941 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0872143 (* 1 = 0.0872143 loss)
I0901 02:53:36.360952 916722 sgd_solver.cpp:106] Iteration 3930000, lr = 0.01
I0901 02:54:06.069983 916722 solver.cpp:218] Iteration 3930500 (16.83 iter/s, 29.7089s/500 iters), loss = 0.11018
I0901 02:54:06.070041 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110182 (* 1 = 0.110182 loss)
I0901 02:54:06.070050 916722 sgd_solver.cpp:106] Iteration 3930500, lr = 0.01
I0901 02:54:35.781669 916722 solver.cpp:218] Iteration 3931000 (16.8285 iter/s, 29.7115s/500 iters), loss = 0.276694
I0901 02:54:35.781718 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.276696 (* 1 = 0.276696 loss)
I0901 02:54:35.781728 916722 sgd_solver.cpp:106] Iteration 3931000, lr = 0.01
I0901 02:55:05.497439 916722 solver.cpp:218] Iteration 3931500 (16.8262 iter/s, 29.7156s/500 iters), loss = 0.386042
I0901 02:55:05.497494 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.386045 (* 1 = 0.386045 loss)
I0901 02:55:05.497503 916722 sgd_solver.cpp:106] Iteration 3931500, lr = 0.01
I0901 02:55:35.208699 916722 solver.cpp:218] Iteration 3932000 (16.8287 iter/s, 29.7111s/500 iters), loss = 0.0140226
I0901 02:55:35.208771 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0140255 (* 1 = 0.0140255 loss)
I0901 02:55:35.208781 916722 sgd_solver.cpp:106] Iteration 3932000, lr = 0.01
I0901 02:56:04.919936 916722 solver.cpp:218] Iteration 3932500 (16.8288 iter/s, 29.711s/500 iters), loss = 0.0326817
I0901 02:56:04.920002 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0326847 (* 1 = 0.0326847 loss)
I0901 02:56:04.920011 916722 sgd_solver.cpp:106] Iteration 3932500, lr = 0.01
I0901 02:56:34.631619 916722 solver.cpp:218] Iteration 3933000 (16.8285 iter/s, 29.7115s/500 iters), loss = 0.0312194
I0901 02:56:34.631672 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0312223 (* 1 = 0.0312223 loss)
I0901 02:56:34.631682 916722 sgd_solver.cpp:106] Iteration 3933000, lr = 0.01
I0901 02:57:04.342029 916722 solver.cpp:218] Iteration 3933500 (16.8292 iter/s, 29.7102s/500 iters), loss = 0.11275
I0901 02:57:04.342087 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112753 (* 1 = 0.112753 loss)
I0901 02:57:04.342095 916722 sgd_solver.cpp:106] Iteration 3933500, lr = 0.01
I0901 02:57:34.054692 916722 solver.cpp:218] Iteration 3934000 (16.8279 iter/s, 29.7125s/500 iters), loss = 0.233994
I0901 02:57:34.054742 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.233997 (* 1 = 0.233997 loss)
I0901 02:57:34.054754 916722 sgd_solver.cpp:106] Iteration 3934000, lr = 0.01
I0901 02:58:03.769421 916722 solver.cpp:218] Iteration 3934500 (16.8268 iter/s, 29.7146s/500 iters), loss = 0.0497006
I0901 02:58:03.769479 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0497036 (* 1 = 0.0497036 loss)
I0901 02:58:03.769486 916722 sgd_solver.cpp:106] Iteration 3934500, lr = 0.01
I0901 02:58:33.484221 916722 solver.cpp:218] Iteration 3935000 (16.8267 iter/s, 29.7146s/500 iters), loss = 0.0781268
I0901 02:58:33.484267 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0781298 (* 1 = 0.0781298 loss)
I0901 02:58:33.484277 916722 sgd_solver.cpp:106] Iteration 3935000, lr = 0.01
I0901 02:59:03.198122 916722 solver.cpp:218] Iteration 3935500 (16.8272 iter/s, 29.7137s/500 iters), loss = 0.0930351
I0901 02:59:03.198176 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.093038 (* 1 = 0.093038 loss)
I0901 02:59:03.198185 916722 sgd_solver.cpp:106] Iteration 3935500, lr = 0.01
I0901 02:59:32.906213 916722 solver.cpp:218] Iteration 3936000 (16.8305 iter/s, 29.7079s/500 iters), loss = 0.0410955
I0901 02:59:32.906265 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0410984 (* 1 = 0.0410984 loss)
I0901 02:59:32.906275 916722 sgd_solver.cpp:106] Iteration 3936000, lr = 0.01
I0901 03:00:02.616514 916722 solver.cpp:218] Iteration 3936500 (16.8293 iter/s, 29.7101s/500 iters), loss = 0.129796
I0901 03:00:02.616571 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.129798 (* 1 = 0.129798 loss)
I0901 03:00:02.616580 916722 sgd_solver.cpp:106] Iteration 3936500, lr = 0.01
I0901 03:00:32.332788 916722 solver.cpp:218] Iteration 3937000 (16.8259 iter/s, 29.7161s/500 iters), loss = 0.561564
I0901 03:00:32.332839 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.561567 (* 1 = 0.561567 loss)
I0901 03:00:32.332847 916722 sgd_solver.cpp:106] Iteration 3937000, lr = 0.01
I0901 03:01:02.048954 916722 solver.cpp:218] Iteration 3937500 (16.826 iter/s, 29.716s/500 iters), loss = 0.0750878
I0901 03:01:02.049015 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0750907 (* 1 = 0.0750907 loss)
I0901 03:01:02.049024 916722 sgd_solver.cpp:106] Iteration 3937500, lr = 0.01
I0901 03:01:31.759358 916722 solver.cpp:218] Iteration 3938000 (16.8292 iter/s, 29.7102s/500 iters), loss = 0.384317
I0901 03:01:31.759410 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.38432 (* 1 = 0.38432 loss)
I0901 03:01:31.759419 916722 sgd_solver.cpp:106] Iteration 3938000, lr = 0.01
I0901 03:02:01.470183 916722 solver.cpp:218] Iteration 3938500 (16.829 iter/s, 29.7107s/500 iters), loss = 0.0672313
I0901 03:02:01.470252 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0672342 (* 1 = 0.0672342 loss)
I0901 03:02:01.470261 916722 sgd_solver.cpp:106] Iteration 3938500, lr = 0.01
I0901 03:02:31.183414 916722 solver.cpp:218] Iteration 3939000 (16.8276 iter/s, 29.713s/500 iters), loss = 0.157467
I0901 03:02:31.183465 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.15747 (* 1 = 0.15747 loss)
I0901 03:02:31.183473 916722 sgd_solver.cpp:106] Iteration 3939000, lr = 0.01
I0901 03:03:00.897367 916722 solver.cpp:218] Iteration 3939500 (16.8272 iter/s, 29.7138s/500 iters), loss = 0.152415
I0901 03:03:00.897423 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152418 (* 1 = 0.152418 loss)
I0901 03:03:00.897431 916722 sgd_solver.cpp:106] Iteration 3939500, lr = 0.01
I0901 03:03:30.605577 916722 solver.cpp:218] Iteration 3940000 (16.8305 iter/s, 29.708s/500 iters), loss = 0.0459849
I0901 03:03:30.605631 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0459879 (* 1 = 0.0459879 loss)
I0901 03:03:30.605643 916722 sgd_solver.cpp:106] Iteration 3940000, lr = 0.01
I0901 03:04:00.314329 916722 solver.cpp:218] Iteration 3940500 (16.8302 iter/s, 29.7086s/500 iters), loss = 0.0652645
I0901 03:04:00.314388 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0652675 (* 1 = 0.0652675 loss)
I0901 03:04:00.314396 916722 sgd_solver.cpp:106] Iteration 3940500, lr = 0.01
I0901 03:04:30.023442 916722 solver.cpp:218] Iteration 3941000 (16.83 iter/s, 29.7089s/500 iters), loss = 0.0474853
I0901 03:04:30.023494 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0474883 (* 1 = 0.0474883 loss)
I0901 03:04:30.023505 916722 sgd_solver.cpp:106] Iteration 3941000, lr = 0.01
I0901 03:04:59.733054 916722 solver.cpp:218] Iteration 3941500 (16.8297 iter/s, 29.7094s/500 iters), loss = 0.0918347
I0901 03:04:59.733115 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0918378 (* 1 = 0.0918378 loss)
I0901 03:04:59.733124 916722 sgd_solver.cpp:106] Iteration 3941500, lr = 0.01
I0901 03:05:29.441138 916722 solver.cpp:218] Iteration 3942000 (16.8305 iter/s, 29.7079s/500 iters), loss = 0.0510936
I0901 03:05:29.441190 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0510968 (* 1 = 0.0510968 loss)
I0901 03:05:29.441200 916722 sgd_solver.cpp:106] Iteration 3942000, lr = 0.01
I0901 03:05:59.157851 916722 solver.cpp:218] Iteration 3942500 (16.8256 iter/s, 29.7165s/500 iters), loss = 0.166692
I0901 03:05:59.157910 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.166696 (* 1 = 0.166696 loss)
I0901 03:05:59.157918 916722 sgd_solver.cpp:106] Iteration 3942500, lr = 0.01
I0901 03:06:28.866911 916722 solver.cpp:218] Iteration 3943000 (16.83 iter/s, 29.7089s/500 iters), loss = 0.148637
I0901 03:06:28.866961 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.14864 (* 1 = 0.14864 loss)
I0901 03:06:28.866971 916722 sgd_solver.cpp:106] Iteration 3943000, lr = 0.01
I0901 03:06:58.576324 916722 solver.cpp:218] Iteration 3943500 (16.8298 iter/s, 29.7092s/500 iters), loss = 0.0278355
I0901 03:06:58.576382 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0278387 (* 1 = 0.0278387 loss)
I0901 03:06:58.576390 916722 sgd_solver.cpp:106] Iteration 3943500, lr = 0.01
I0901 03:07:28.283764 916722 solver.cpp:218] Iteration 3944000 (16.8309 iter/s, 29.7073s/500 iters), loss = 0.0631804
I0901 03:07:28.283815 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0631836 (* 1 = 0.0631836 loss)
I0901 03:07:28.283825 916722 sgd_solver.cpp:106] Iteration 3944000, lr = 0.01
I0901 03:07:57.991124 916722 solver.cpp:218] Iteration 3944500 (16.8309 iter/s, 29.7072s/500 iters), loss = 0.24414
I0901 03:07:57.991180 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.244144 (* 1 = 0.244144 loss)
I0901 03:07:57.991189 916722 sgd_solver.cpp:106] Iteration 3944500, lr = 0.01
I0901 03:08:27.701644 916722 solver.cpp:218] Iteration 3945000 (16.829 iter/s, 29.7106s/500 iters), loss = 0.231413
I0901 03:08:27.701694 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.231416 (* 1 = 0.231416 loss)
I0901 03:08:27.701717 916722 sgd_solver.cpp:106] Iteration 3945000, lr = 0.01
I0901 03:08:57.409217 916722 solver.cpp:218] Iteration 3945500 (16.8307 iter/s, 29.7077s/500 iters), loss = 0.0631342
I0901 03:08:57.409286 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0631371 (* 1 = 0.0631371 loss)
I0901 03:08:57.409293 916722 sgd_solver.cpp:106] Iteration 3945500, lr = 0.01
I0901 03:09:27.121628 916722 solver.cpp:218] Iteration 3946000 (16.8279 iter/s, 29.7125s/500 iters), loss = 0.0449616
I0901 03:09:27.121680 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0449645 (* 1 = 0.0449645 loss)
I0901 03:09:27.121688 916722 sgd_solver.cpp:106] Iteration 3946000, lr = 0.01
I0901 03:09:56.833317 916722 solver.cpp:218] Iteration 3946500 (16.8283 iter/s, 29.7118s/500 iters), loss = 0.0582173
I0901 03:09:56.833372 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0582203 (* 1 = 0.0582203 loss)
I0901 03:09:56.833380 916722 sgd_solver.cpp:106] Iteration 3946500, lr = 0.01
I0901 03:10:26.545122 916722 solver.cpp:218] Iteration 3947000 (16.8283 iter/s, 29.7119s/500 iters), loss = 0.157157
I0901 03:10:26.545172 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.15716 (* 1 = 0.15716 loss)
I0901 03:10:26.545182 916722 sgd_solver.cpp:106] Iteration 3947000, lr = 0.01
I0901 03:10:56.254946 916722 solver.cpp:218] Iteration 3947500 (16.8294 iter/s, 29.7099s/500 iters), loss = 0.265957
I0901 03:10:56.255002 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.26596 (* 1 = 0.26596 loss)
I0901 03:10:56.255012 916722 sgd_solver.cpp:106] Iteration 3947500, lr = 0.01
I0901 03:11:25.965191 916722 solver.cpp:218] Iteration 3948000 (16.8292 iter/s, 29.7103s/500 iters), loss = 0.17629
I0901 03:11:25.965243 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.176293 (* 1 = 0.176293 loss)
I0901 03:11:25.965255 916722 sgd_solver.cpp:106] Iteration 3948000, lr = 0.01
I0901 03:11:55.673588 916722 solver.cpp:218] Iteration 3948500 (16.8302 iter/s, 29.7084s/500 iters), loss = 0.0680943
I0901 03:11:55.673645 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0680973 (* 1 = 0.0680973 loss)
I0901 03:11:55.673655 916722 sgd_solver.cpp:106] Iteration 3948500, lr = 0.01
I0901 03:12:25.386335 916722 solver.cpp:218] Iteration 3949000 (16.8278 iter/s, 29.7128s/500 iters), loss = 0.160102
I0901 03:12:25.386387 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.160105 (* 1 = 0.160105 loss)
I0901 03:12:25.386397 916722 sgd_solver.cpp:106] Iteration 3949000, lr = 0.01
I0901 03:12:55.097370 916722 solver.cpp:218] Iteration 3949500 (16.8288 iter/s, 29.711s/500 iters), loss = 0.200301
I0901 03:12:55.097450 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.200304 (* 1 = 0.200304 loss)
I0901 03:12:55.097458 916722 sgd_solver.cpp:106] Iteration 3949500, lr = 0.01
I0901 03:13:24.752693 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_3950000.caffemodel
I0901 03:13:24.772038 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_3950000.solverstate
I0901 03:13:24.778069 916722 solver.cpp:330] Iteration 3950000, Testing net (#0)
I0901 03:13:40.171891 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8833
I0901 03:13:40.171939 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.396438 (* 1 = 0.396438 loss)
I0901 03:13:40.230604 916722 solver.cpp:218] Iteration 3950000 (11.0783 iter/s, 45.1333s/500 iters), loss = 0.231433
I0901 03:13:40.230633 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.231436 (* 1 = 0.231436 loss)
I0901 03:13:40.230640 916722 sgd_solver.cpp:106] Iteration 3950000, lr = 0.01
I0901 03:14:09.838488 916722 solver.cpp:218] Iteration 3950500 (16.8874 iter/s, 29.6079s/500 iters), loss = 0.0867972
I0901 03:14:09.838539 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0868004 (* 1 = 0.0868004 loss)
I0901 03:14:09.838548 916722 sgd_solver.cpp:106] Iteration 3950500, lr = 0.01
I0901 03:14:39.569332 916722 solver.cpp:218] Iteration 3951000 (16.8176 iter/s, 29.7308s/500 iters), loss = 0.0295509
I0901 03:14:39.569401 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0295541 (* 1 = 0.0295541 loss)
I0901 03:14:39.569411 916722 sgd_solver.cpp:106] Iteration 3951000, lr = 0.01
I0901 03:15:09.302958 916722 solver.cpp:218] Iteration 3951500 (16.816 iter/s, 29.7336s/500 iters), loss = 0.118114
I0901 03:15:09.303009 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.118117 (* 1 = 0.118117 loss)
I0901 03:15:09.303020 916722 sgd_solver.cpp:106] Iteration 3951500, lr = 0.01
I0901 03:15:39.035362 916722 solver.cpp:218] Iteration 3952000 (16.8167 iter/s, 29.7324s/500 iters), loss = 0.125017
I0901 03:15:39.035416 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.12502 (* 1 = 0.12502 loss)
I0901 03:15:39.035425 916722 sgd_solver.cpp:106] Iteration 3952000, lr = 0.01
I0901 03:16:08.770248 916722 solver.cpp:218] Iteration 3952500 (16.8153 iter/s, 29.7348s/500 iters), loss = 0.0949579
I0901 03:16:08.770298 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.094961 (* 1 = 0.094961 loss)
I0901 03:16:08.770308 916722 sgd_solver.cpp:106] Iteration 3952500, lr = 0.01
I0901 03:16:38.505421 916722 solver.cpp:218] Iteration 3953000 (16.8151 iter/s, 29.7351s/500 iters), loss = 0.123053
I0901 03:16:38.505475 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.123056 (* 1 = 0.123056 loss)
I0901 03:16:38.505483 916722 sgd_solver.cpp:106] Iteration 3953000, lr = 0.01
I0901 03:17:08.238946 916722 solver.cpp:218] Iteration 3953500 (16.8161 iter/s, 29.7335s/500 iters), loss = 0.084891
I0901 03:17:08.238996 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0848939 (* 1 = 0.0848939 loss)
I0901 03:17:08.239006 916722 sgd_solver.cpp:106] Iteration 3953500, lr = 0.01
I0901 03:17:37.974618 916722 solver.cpp:218] Iteration 3954000 (16.8148 iter/s, 29.7356s/500 iters), loss = 0.0163634
I0901 03:17:37.974679 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0163662 (* 1 = 0.0163662 loss)
I0901 03:17:37.974687 916722 sgd_solver.cpp:106] Iteration 3954000, lr = 0.01
I0901 03:18:07.704522 916722 solver.cpp:218] Iteration 3954500 (16.8181 iter/s, 29.7298s/500 iters), loss = 0.1335
I0901 03:18:07.704573 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133502 (* 1 = 0.133502 loss)
I0901 03:18:07.704582 916722 sgd_solver.cpp:106] Iteration 3954500, lr = 0.01
I0901 03:18:37.437008 916722 solver.cpp:218] Iteration 3955000 (16.8167 iter/s, 29.7324s/500 iters), loss = 0.161226
I0901 03:18:37.437067 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.161228 (* 1 = 0.161228 loss)
I0901 03:18:37.437075 916722 sgd_solver.cpp:106] Iteration 3955000, lr = 0.01
I0901 03:19:07.170293 916722 solver.cpp:218] Iteration 3955500 (16.8162 iter/s, 29.7332s/500 iters), loss = 0.0769153
I0901 03:19:07.170343 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0769178 (* 1 = 0.0769178 loss)
I0901 03:19:07.170351 916722 sgd_solver.cpp:106] Iteration 3955500, lr = 0.01
I0901 03:19:36.902628 916722 solver.cpp:218] Iteration 3956000 (16.8167 iter/s, 29.7323s/500 iters), loss = 0.0986532
I0901 03:19:36.902686 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0986558 (* 1 = 0.0986558 loss)
I0901 03:19:36.902694 916722 sgd_solver.cpp:106] Iteration 3956000, lr = 0.01
I0901 03:20:06.637560 916722 solver.cpp:218] Iteration 3956500 (16.8153 iter/s, 29.7349s/500 iters), loss = 0.0467458
I0901 03:20:06.637610 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0467485 (* 1 = 0.0467485 loss)
I0901 03:20:06.637619 916722 sgd_solver.cpp:106] Iteration 3956500, lr = 0.01
I0901 03:20:36.366206 916722 solver.cpp:218] Iteration 3957000 (16.8188 iter/s, 29.7286s/500 iters), loss = 0.00877774
I0901 03:20:36.366263 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.00878036 (* 1 = 0.00878036 loss)
I0901 03:20:36.366271 916722 sgd_solver.cpp:106] Iteration 3957000, lr = 0.01
I0901 03:21:06.098533 916722 solver.cpp:218] Iteration 3957500 (16.8168 iter/s, 29.7322s/500 iters), loss = 0.19575
I0901 03:21:06.098582 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.195752 (* 1 = 0.195752 loss)
I0901 03:21:06.098592 916722 sgd_solver.cpp:106] Iteration 3957500, lr = 0.01
I0901 03:21:35.827687 916722 solver.cpp:218] Iteration 3958000 (16.8185 iter/s, 29.7291s/500 iters), loss = 0.101991
I0901 03:21:35.827755 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101994 (* 1 = 0.101994 loss)
I0901 03:21:35.827780 916722 sgd_solver.cpp:106] Iteration 3958000, lr = 0.01
I0901 03:22:05.560454 916722 solver.cpp:218] Iteration 3958500 (16.8165 iter/s, 29.7327s/500 iters), loss = 0.270183
I0901 03:22:05.560505 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.270186 (* 1 = 0.270186 loss)
I0901 03:22:05.560514 916722 sgd_solver.cpp:106] Iteration 3958500, lr = 0.01
I0901 03:22:35.295022 916722 solver.cpp:218] Iteration 3959000 (16.8155 iter/s, 29.7345s/500 iters), loss = 0.151965
I0901 03:22:35.295078 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.151967 (* 1 = 0.151967 loss)
I0901 03:22:35.295086 916722 sgd_solver.cpp:106] Iteration 3959000, lr = 0.01
I0901 03:23:05.030045 916722 solver.cpp:218] Iteration 3959500 (16.8152 iter/s, 29.7349s/500 iters), loss = 0.0845636
I0901 03:23:05.030097 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0845659 (* 1 = 0.0845659 loss)
I0901 03:23:05.030107 916722 sgd_solver.cpp:106] Iteration 3959500, lr = 0.01
I0901 03:23:34.767803 916722 solver.cpp:218] Iteration 3960000 (16.8137 iter/s, 29.7377s/500 iters), loss = 0.0176432
I0901 03:23:34.767858 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0176457 (* 1 = 0.0176457 loss)
I0901 03:23:34.767868 916722 sgd_solver.cpp:106] Iteration 3960000, lr = 0.01
I0901 03:24:04.499334 916722 solver.cpp:218] Iteration 3960500 (16.8172 iter/s, 29.7314s/500 iters), loss = 0.316026
I0901 03:24:04.499383 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.316029 (* 1 = 0.316029 loss)
I0901 03:24:04.499393 916722 sgd_solver.cpp:106] Iteration 3960500, lr = 0.01
I0901 03:24:34.233569 916722 solver.cpp:218] Iteration 3961000 (16.8157 iter/s, 29.7341s/500 iters), loss = 0.264223
I0901 03:24:34.233624 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.264226 (* 1 = 0.264226 loss)
I0901 03:24:34.233633 916722 sgd_solver.cpp:106] Iteration 3961000, lr = 0.01
I0901 03:25:03.967741 916722 solver.cpp:218] Iteration 3961500 (16.8157 iter/s, 29.7341s/500 iters), loss = 0.0535927
I0901 03:25:03.967788 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0535955 (* 1 = 0.0535955 loss)
I0901 03:25:03.967799 916722 sgd_solver.cpp:106] Iteration 3961500, lr = 0.01
I0901 03:25:33.698711 916722 solver.cpp:218] Iteration 3962000 (16.8175 iter/s, 29.7309s/500 iters), loss = 0.0466869
I0901 03:25:33.698765 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0466898 (* 1 = 0.0466898 loss)
I0901 03:25:33.698773 916722 sgd_solver.cpp:106] Iteration 3962000, lr = 0.01
I0901 03:26:03.428584 916722 solver.cpp:218] Iteration 3962500 (16.8182 iter/s, 29.7298s/500 iters), loss = 0.0989627
I0901 03:26:03.428633 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0989656 (* 1 = 0.0989656 loss)
I0901 03:26:03.428644 916722 sgd_solver.cpp:106] Iteration 3962500, lr = 0.01
I0901 03:26:33.161808 916722 solver.cpp:218] Iteration 3963000 (16.8163 iter/s, 29.7331s/500 iters), loss = 0.0393053
I0901 03:26:33.161862 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0393082 (* 1 = 0.0393082 loss)
I0901 03:26:33.161870 916722 sgd_solver.cpp:106] Iteration 3963000, lr = 0.01
I0901 03:27:02.894572 916722 solver.cpp:218] Iteration 3963500 (16.8165 iter/s, 29.7327s/500 iters), loss = 0.046326
I0901 03:27:02.894621 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0463289 (* 1 = 0.0463289 loss)
I0901 03:27:02.894631 916722 sgd_solver.cpp:106] Iteration 3963500, lr = 0.01
I0901 03:27:32.627450 916722 solver.cpp:218] Iteration 3964000 (16.8165 iter/s, 29.7328s/500 iters), loss = 0.0930781
I0901 03:27:32.627522 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0930809 (* 1 = 0.0930809 loss)
I0901 03:27:32.627530 916722 sgd_solver.cpp:106] Iteration 3964000, lr = 0.01
I0901 03:28:02.359519 916722 solver.cpp:218] Iteration 3964500 (16.8169 iter/s, 29.7319s/500 iters), loss = 0.0633934
I0901 03:28:02.359570 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0633962 (* 1 = 0.0633962 loss)
I0901 03:28:02.359580 916722 sgd_solver.cpp:106] Iteration 3964500, lr = 0.01
I0901 03:28:32.094914 916722 solver.cpp:218] Iteration 3965000 (16.815 iter/s, 29.7353s/500 iters), loss = 0.139958
I0901 03:28:32.094975 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139961 (* 1 = 0.139961 loss)
I0901 03:28:32.094985 916722 sgd_solver.cpp:106] Iteration 3965000, lr = 0.01
I0901 03:29:01.830824 916722 solver.cpp:218] Iteration 3965500 (16.8148 iter/s, 29.7358s/500 iters), loss = 0.331669
I0901 03:29:01.830874 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.331671 (* 1 = 0.331671 loss)
I0901 03:29:01.830883 916722 sgd_solver.cpp:106] Iteration 3965500, lr = 0.01
I0901 03:29:31.562639 916722 solver.cpp:218] Iteration 3966000 (16.8171 iter/s, 29.7317s/500 iters), loss = 0.0753596
I0901 03:29:31.562698 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0753625 (* 1 = 0.0753625 loss)
I0901 03:29:31.562708 916722 sgd_solver.cpp:106] Iteration 3966000, lr = 0.01
I0901 03:30:01.297297 916722 solver.cpp:218] Iteration 3966500 (16.8155 iter/s, 29.7345s/500 iters), loss = 0.0699413
I0901 03:30:01.297346 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0699443 (* 1 = 0.0699443 loss)
I0901 03:30:01.297355 916722 sgd_solver.cpp:106] Iteration 3966500, lr = 0.01
I0901 03:30:31.027806 916722 solver.cpp:218] Iteration 3967000 (16.8178 iter/s, 29.7304s/500 iters), loss = 0.0237379
I0901 03:30:31.027865 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0237409 (* 1 = 0.0237409 loss)
I0901 03:30:31.027873 916722 sgd_solver.cpp:106] Iteration 3967000, lr = 0.01
I0901 03:31:00.758796 916722 solver.cpp:218] Iteration 3967500 (16.8175 iter/s, 29.7309s/500 iters), loss = 0.162694
I0901 03:31:00.758844 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.162697 (* 1 = 0.162697 loss)
I0901 03:31:00.758852 916722 sgd_solver.cpp:106] Iteration 3967500, lr = 0.01
I0901 03:31:30.492710 916722 solver.cpp:218] Iteration 3968000 (16.8159 iter/s, 29.7338s/500 iters), loss = 0.109074
I0901 03:31:30.492780 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109077 (* 1 = 0.109077 loss)
I0901 03:31:30.492789 916722 sgd_solver.cpp:106] Iteration 3968000, lr = 0.01
I0901 03:32:00.223834 916722 solver.cpp:218] Iteration 3968500 (16.8175 iter/s, 29.731s/500 iters), loss = 0.163956
I0901 03:32:00.223886 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.16396 (* 1 = 0.16396 loss)
I0901 03:32:00.223896 916722 sgd_solver.cpp:106] Iteration 3968500, lr = 0.01
I0901 03:32:29.955494 916722 solver.cpp:218] Iteration 3969000 (16.8172 iter/s, 29.7315s/500 iters), loss = 0.0805237
I0901 03:32:29.955554 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0805272 (* 1 = 0.0805272 loss)
I0901 03:32:29.955562 916722 sgd_solver.cpp:106] Iteration 3969000, lr = 0.01
I0901 03:32:59.687326 916722 solver.cpp:218] Iteration 3969500 (16.8171 iter/s, 29.7317s/500 iters), loss = 0.0616325
I0901 03:32:59.687376 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0616357 (* 1 = 0.0616357 loss)
I0901 03:32:59.687386 916722 sgd_solver.cpp:106] Iteration 3969500, lr = 0.01
I0901 03:33:29.420440 916722 solver.cpp:218] Iteration 3970000 (16.8163 iter/s, 29.733s/500 iters), loss = 0.195887
I0901 03:33:29.420497 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.195891 (* 1 = 0.195891 loss)
I0901 03:33:29.420506 916722 sgd_solver.cpp:106] Iteration 3970000, lr = 0.01
I0901 03:33:59.153311 916722 solver.cpp:218] Iteration 3970500 (16.8165 iter/s, 29.7327s/500 iters), loss = 0.156018
I0901 03:33:59.153375 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.156021 (* 1 = 0.156021 loss)
I0901 03:33:59.153403 916722 sgd_solver.cpp:106] Iteration 3970500, lr = 0.01
I0901 03:34:28.887508 916722 solver.cpp:218] Iteration 3971000 (16.8157 iter/s, 29.7341s/500 iters), loss = 0.0962345
I0901 03:34:28.887576 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.096238 (* 1 = 0.096238 loss)
I0901 03:34:28.887584 916722 sgd_solver.cpp:106] Iteration 3971000, lr = 0.01
I0901 03:34:58.619742 916722 solver.cpp:218] Iteration 3971500 (16.8168 iter/s, 29.7321s/500 iters), loss = 0.0341017
I0901 03:34:58.619796 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0341051 (* 1 = 0.0341051 loss)
I0901 03:34:58.619804 916722 sgd_solver.cpp:106] Iteration 3971500, lr = 0.01
I0901 03:35:28.350206 916722 solver.cpp:218] Iteration 3972000 (16.8178 iter/s, 29.7303s/500 iters), loss = 0.231195
I0901 03:35:28.350265 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.231199 (* 1 = 0.231199 loss)
I0901 03:35:28.350273 916722 sgd_solver.cpp:106] Iteration 3972000, lr = 0.01
I0901 03:35:58.084970 916722 solver.cpp:218] Iteration 3972500 (16.8154 iter/s, 29.7346s/500 iters), loss = 0.220425
I0901 03:35:58.085023 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.220428 (* 1 = 0.220428 loss)
I0901 03:35:58.085032 916722 sgd_solver.cpp:106] Iteration 3972500, lr = 0.01
I0901 03:36:27.829066 916722 solver.cpp:218] Iteration 3973000 (16.8101 iter/s, 29.744s/500 iters), loss = 0.0811196
I0901 03:36:27.829126 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0811231 (* 1 = 0.0811231 loss)
I0901 03:36:27.829135 916722 sgd_solver.cpp:106] Iteration 3973000, lr = 0.01
I0901 03:36:57.572129 916722 solver.cpp:218] Iteration 3973500 (16.8107 iter/s, 29.7429s/500 iters), loss = 0.119111
I0901 03:36:57.572181 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.119114 (* 1 = 0.119114 loss)
I0901 03:36:57.572190 916722 sgd_solver.cpp:106] Iteration 3973500, lr = 0.01
I0901 03:37:27.310555 916722 solver.cpp:218] Iteration 3974000 (16.8133 iter/s, 29.7383s/500 iters), loss = 0.148115
I0901 03:37:27.310611 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.148118 (* 1 = 0.148118 loss)
I0901 03:37:27.310621 916722 sgd_solver.cpp:106] Iteration 3974000, lr = 0.01
I0901 03:37:57.049316 916722 solver.cpp:218] Iteration 3974500 (16.8132 iter/s, 29.7386s/500 iters), loss = 0.265312
I0901 03:37:57.049365 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.265316 (* 1 = 0.265316 loss)
I0901 03:37:57.049374 916722 sgd_solver.cpp:106] Iteration 3974500, lr = 0.01
I0901 03:38:26.792711 916722 solver.cpp:218] Iteration 3975000 (16.8105 iter/s, 29.7433s/500 iters), loss = 0.189846
I0901 03:38:26.792768 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.189849 (* 1 = 0.189849 loss)
I0901 03:38:26.792775 916722 sgd_solver.cpp:106] Iteration 3975000, lr = 0.01
I0901 03:38:56.536267 916722 solver.cpp:218] Iteration 3975500 (16.8104 iter/s, 29.7434s/500 iters), loss = 0.202262
I0901 03:38:56.536319 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.202265 (* 1 = 0.202265 loss)
I0901 03:38:56.536329 916722 sgd_solver.cpp:106] Iteration 3975500, lr = 0.01
I0901 03:39:26.279518 916722 solver.cpp:218] Iteration 3976000 (16.8106 iter/s, 29.7431s/500 iters), loss = 0.0894674
I0901 03:39:26.279575 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0894703 (* 1 = 0.0894703 loss)
I0901 03:39:26.279583 916722 sgd_solver.cpp:106] Iteration 3976000, lr = 0.01
I0901 03:39:56.019695 916722 solver.cpp:218] Iteration 3976500 (16.8124 iter/s, 29.74s/500 iters), loss = 0.171161
I0901 03:39:56.019747 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.171163 (* 1 = 0.171163 loss)
I0901 03:39:56.019757 916722 sgd_solver.cpp:106] Iteration 3976500, lr = 0.01
I0901 03:40:25.762408 916722 solver.cpp:218] Iteration 3977000 (16.8109 iter/s, 29.7426s/500 iters), loss = 0.151151
I0901 03:40:25.762478 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.151154 (* 1 = 0.151154 loss)
I0901 03:40:25.762487 916722 sgd_solver.cpp:106] Iteration 3977000, lr = 0.01
I0901 03:40:55.503948 916722 solver.cpp:218] Iteration 3977500 (16.8116 iter/s, 29.7414s/500 iters), loss = 0.181344
I0901 03:40:55.504000 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.181346 (* 1 = 0.181346 loss)
I0901 03:40:55.504011 916722 sgd_solver.cpp:106] Iteration 3977500, lr = 0.01
I0901 03:41:25.245404 916722 solver.cpp:218] Iteration 3978000 (16.8116 iter/s, 29.7413s/500 iters), loss = 0.127165
I0901 03:41:25.245460 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.127167 (* 1 = 0.127167 loss)
I0901 03:41:25.245468 916722 sgd_solver.cpp:106] Iteration 3978000, lr = 0.01
I0901 03:41:54.985659 916722 solver.cpp:218] Iteration 3978500 (16.8123 iter/s, 29.7401s/500 iters), loss = 0.139053
I0901 03:41:54.985710 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139055 (* 1 = 0.139055 loss)
I0901 03:41:54.985720 916722 sgd_solver.cpp:106] Iteration 3978500, lr = 0.01
I0901 03:42:24.723743 916722 solver.cpp:218] Iteration 3979000 (16.8138 iter/s, 29.7375s/500 iters), loss = 0.151881
I0901 03:42:24.723798 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.151883 (* 1 = 0.151883 loss)
I0901 03:42:24.723806 916722 sgd_solver.cpp:106] Iteration 3979000, lr = 0.01
I0901 03:42:54.455166 916722 solver.cpp:218] Iteration 3979500 (16.8177 iter/s, 29.7306s/500 iters), loss = 0.131128
I0901 03:42:54.455217 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13113 (* 1 = 0.13113 loss)
I0901 03:42:54.455227 916722 sgd_solver.cpp:106] Iteration 3979500, lr = 0.01
I0901 03:43:24.186105 916722 solver.cpp:218] Iteration 3980000 (16.8179 iter/s, 29.7302s/500 iters), loss = 0.308957
I0901 03:43:24.186159 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.308959 (* 1 = 0.308959 loss)
I0901 03:43:24.186167 916722 sgd_solver.cpp:106] Iteration 3980000, lr = 0.01
I0901 03:43:53.920883 916722 solver.cpp:218] Iteration 3980500 (16.8157 iter/s, 29.734s/500 iters), loss = 0.23856
I0901 03:43:53.920936 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.238562 (* 1 = 0.238562 loss)
I0901 03:43:53.920948 916722 sgd_solver.cpp:106] Iteration 3980500, lr = 0.01
I0901 03:44:23.653582 916722 solver.cpp:218] Iteration 3981000 (16.8169 iter/s, 29.732s/500 iters), loss = 0.209072
I0901 03:44:23.653640 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.209074 (* 1 = 0.209074 loss)
I0901 03:44:23.653647 916722 sgd_solver.cpp:106] Iteration 3981000, lr = 0.01
I0901 03:44:53.386358 916722 solver.cpp:218] Iteration 3981500 (16.8168 iter/s, 29.7321s/500 iters), loss = 0.0153559
I0901 03:44:53.386412 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0153577 (* 1 = 0.0153577 loss)
I0901 03:44:53.386422 916722 sgd_solver.cpp:106] Iteration 3981500, lr = 0.01
I0901 03:45:23.118485 916722 solver.cpp:218] Iteration 3982000 (16.8172 iter/s, 29.7315s/500 iters), loss = 0.18367
I0901 03:45:23.118541 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.183672 (* 1 = 0.183672 loss)
I0901 03:45:23.118551 916722 sgd_solver.cpp:106] Iteration 3982000, lr = 0.01
I0901 03:45:52.852757 916722 solver.cpp:218] Iteration 3982500 (16.816 iter/s, 29.7336s/500 iters), loss = 0.0316127
I0901 03:45:52.852811 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0316144 (* 1 = 0.0316144 loss)
I0901 03:45:52.852821 916722 sgd_solver.cpp:106] Iteration 3982500, lr = 0.01
I0901 03:46:22.583729 916722 solver.cpp:218] Iteration 3983000 (16.8178 iter/s, 29.7304s/500 iters), loss = 0.0827318
I0901 03:46:22.583786 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0827335 (* 1 = 0.0827335 loss)
I0901 03:46:22.583794 916722 sgd_solver.cpp:106] Iteration 3983000, lr = 0.01
I0901 03:46:52.312840 916722 solver.cpp:218] Iteration 3983500 (16.8189 iter/s, 29.7285s/500 iters), loss = 0.0495928
I0901 03:46:52.312893 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0495944 (* 1 = 0.0495944 loss)
I0901 03:46:52.312914 916722 sgd_solver.cpp:106] Iteration 3983500, lr = 0.01
I0901 03:47:22.044247 916722 solver.cpp:218] Iteration 3984000 (16.8176 iter/s, 29.7308s/500 iters), loss = 0.264338
I0901 03:47:22.044315 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.26434 (* 1 = 0.26434 loss)
I0901 03:47:22.044324 916722 sgd_solver.cpp:106] Iteration 3984000, lr = 0.01
I0901 03:47:51.774705 916722 solver.cpp:218] Iteration 3984500 (16.8181 iter/s, 29.7299s/500 iters), loss = 0.0690956
I0901 03:47:51.774755 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0690973 (* 1 = 0.0690973 loss)
I0901 03:47:51.774765 916722 sgd_solver.cpp:106] Iteration 3984500, lr = 0.01
I0901 03:48:21.509666 916722 solver.cpp:218] Iteration 3985000 (16.8155 iter/s, 29.7344s/500 iters), loss = 0.113842
I0901 03:48:21.509727 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.113844 (* 1 = 0.113844 loss)
I0901 03:48:21.509735 916722 sgd_solver.cpp:106] Iteration 3985000, lr = 0.01
I0901 03:48:51.240605 916722 solver.cpp:218] Iteration 3985500 (16.8178 iter/s, 29.7304s/500 iters), loss = 0.148798
I0901 03:48:51.240658 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.1488 (* 1 = 0.1488 loss)
I0901 03:48:51.240669 916722 sgd_solver.cpp:106] Iteration 3985500, lr = 0.01
I0901 03:49:20.974936 916722 solver.cpp:218] Iteration 3986000 (16.8159 iter/s, 29.7338s/500 iters), loss = 0.125013
I0901 03:49:20.974995 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.125015 (* 1 = 0.125015 loss)
I0901 03:49:20.975004 916722 sgd_solver.cpp:106] Iteration 3986000, lr = 0.01
I0901 03:49:50.705612 916722 solver.cpp:218] Iteration 3986500 (16.8179 iter/s, 29.7302s/500 iters), loss = 0.030197
I0901 03:49:50.705665 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0301991 (* 1 = 0.0301991 loss)
I0901 03:49:50.705674 916722 sgd_solver.cpp:106] Iteration 3986500, lr = 0.01
I0901 03:50:20.438665 916722 solver.cpp:218] Iteration 3987000 (16.8166 iter/s, 29.7326s/500 iters), loss = 0.126308
I0901 03:50:20.438722 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.12631 (* 1 = 0.12631 loss)
I0901 03:50:20.438730 916722 sgd_solver.cpp:106] Iteration 3987000, lr = 0.01
I0901 03:50:50.168606 916722 solver.cpp:218] Iteration 3987500 (16.8183 iter/s, 29.7295s/500 iters), loss = 0.0199066
I0901 03:50:50.168656 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0199089 (* 1 = 0.0199089 loss)
I0901 03:50:50.168665 916722 sgd_solver.cpp:106] Iteration 3987500, lr = 0.01
I0901 03:51:19.896795 916722 solver.cpp:218] Iteration 3988000 (16.8193 iter/s, 29.7278s/500 iters), loss = 0.0684681
I0901 03:51:19.896852 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0684702 (* 1 = 0.0684702 loss)
I0901 03:51:19.896860 916722 sgd_solver.cpp:106] Iteration 3988000, lr = 0.01
I0901 03:51:49.627118 916722 solver.cpp:218] Iteration 3988500 (16.8181 iter/s, 29.7299s/500 iters), loss = 0.0316558
I0901 03:51:49.627168 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0316579 (* 1 = 0.0316579 loss)
I0901 03:51:49.627177 916722 sgd_solver.cpp:106] Iteration 3988500, lr = 0.01
I0901 03:52:19.357398 916722 solver.cpp:218] Iteration 3989000 (16.8181 iter/s, 29.7299s/500 iters), loss = 0.131691
I0901 03:52:19.357448 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131694 (* 1 = 0.131694 loss)
I0901 03:52:19.357457 916722 sgd_solver.cpp:106] Iteration 3989000, lr = 0.01
I0901 03:52:49.088935 916722 solver.cpp:218] Iteration 3989500 (16.8174 iter/s, 29.7311s/500 iters), loss = 0.128993
I0901 03:52:49.088986 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128995 (* 1 = 0.128995 loss)
I0901 03:52:49.088995 916722 sgd_solver.cpp:106] Iteration 3989500, lr = 0.01
I0901 03:53:18.823128 916722 solver.cpp:218] Iteration 3990000 (16.8159 iter/s, 29.7338s/500 iters), loss = 0.152081
I0901 03:53:18.823199 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152083 (* 1 = 0.152083 loss)
I0901 03:53:18.823211 916722 sgd_solver.cpp:106] Iteration 3990000, lr = 0.01
I0901 03:53:48.550470 916722 solver.cpp:218] Iteration 3990500 (16.8198 iter/s, 29.7269s/500 iters), loss = 0.140749
I0901 03:53:48.550523 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.140751 (* 1 = 0.140751 loss)
I0901 03:53:48.550530 916722 sgd_solver.cpp:106] Iteration 3990500, lr = 0.01
I0901 03:54:18.283713 916722 solver.cpp:218] Iteration 3991000 (16.8164 iter/s, 29.7329s/500 iters), loss = 0.114718
I0901 03:54:18.283771 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.11472 (* 1 = 0.11472 loss)
I0901 03:54:18.283779 916722 sgd_solver.cpp:106] Iteration 3991000, lr = 0.01
I0901 03:54:48.017947 916722 solver.cpp:218] Iteration 3991500 (16.8158 iter/s, 29.7339s/500 iters), loss = 0.0590732
I0901 03:54:48.018002 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0590753 (* 1 = 0.0590753 loss)
I0901 03:54:48.018013 916722 sgd_solver.cpp:106] Iteration 3991500, lr = 0.01
I0901 03:55:17.752727 916722 solver.cpp:218] Iteration 3992000 (16.8155 iter/s, 29.7344s/500 iters), loss = 0.190652
I0901 03:55:17.752792 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.190654 (* 1 = 0.190654 loss)
I0901 03:55:17.752801 916722 sgd_solver.cpp:106] Iteration 3992000, lr = 0.01
I0901 03:55:47.484141 916722 solver.cpp:218] Iteration 3992500 (16.8174 iter/s, 29.7311s/500 iters), loss = 0.0750041
I0901 03:55:47.484194 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0750063 (* 1 = 0.0750063 loss)
I0901 03:55:47.484203 916722 sgd_solver.cpp:106] Iteration 3992500, lr = 0.01
I0901 03:56:17.213658 916722 solver.cpp:218] Iteration 3993000 (16.8185 iter/s, 29.7292s/500 iters), loss = 0.0972751
I0901 03:56:17.213712 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0972774 (* 1 = 0.0972774 loss)
I0901 03:56:17.213721 916722 sgd_solver.cpp:106] Iteration 3993000, lr = 0.01
I0901 03:56:46.946724 916722 solver.cpp:218] Iteration 3993500 (16.8165 iter/s, 29.7327s/500 iters), loss = 0.104542
I0901 03:56:46.946775 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104544 (* 1 = 0.104544 loss)
I0901 03:56:46.946785 916722 sgd_solver.cpp:106] Iteration 3993500, lr = 0.01
I0901 03:57:16.677678 916722 solver.cpp:218] Iteration 3994000 (16.8177 iter/s, 29.7306s/500 iters), loss = 0.0690461
I0901 03:57:16.677734 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0690486 (* 1 = 0.0690486 loss)
I0901 03:57:16.677743 916722 sgd_solver.cpp:106] Iteration 3994000, lr = 0.01
I0901 03:57:46.407969 916722 solver.cpp:218] Iteration 3994500 (16.818 iter/s, 29.73s/500 iters), loss = 0.333527
I0901 03:57:46.408020 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.33353 (* 1 = 0.33353 loss)
I0901 03:57:46.408030 916722 sgd_solver.cpp:106] Iteration 3994500, lr = 0.01
I0901 03:58:16.138944 916722 solver.cpp:218] Iteration 3995000 (16.8177 iter/s, 29.7307s/500 iters), loss = 0.0788366
I0901 03:58:16.139003 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0788391 (* 1 = 0.0788391 loss)
I0901 03:58:16.139011 916722 sgd_solver.cpp:106] Iteration 3995000, lr = 0.01
I0901 03:58:45.870074 916722 solver.cpp:218] Iteration 3995500 (16.8176 iter/s, 29.7308s/500 iters), loss = 0.0712811
I0901 03:58:45.870126 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0712837 (* 1 = 0.0712837 loss)
I0901 03:58:45.870137 916722 sgd_solver.cpp:106] Iteration 3995500, lr = 0.01
I0901 03:59:15.601051 916722 solver.cpp:218] Iteration 3996000 (16.8176 iter/s, 29.7307s/500 iters), loss = 0.179625
I0901 03:59:15.601104 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.179628 (* 1 = 0.179628 loss)
I0901 03:59:15.601112 916722 sgd_solver.cpp:106] Iteration 3996000, lr = 0.01
I0901 03:59:45.330612 916722 solver.cpp:218] Iteration 3996500 (16.8185 iter/s, 29.7293s/500 iters), loss = 0.0294605
I0901 03:59:45.330663 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0294632 (* 1 = 0.0294632 loss)
I0901 03:59:45.330687 916722 sgd_solver.cpp:106] Iteration 3996500, lr = 0.01
I0901 04:00:15.058674 916722 solver.cpp:218] Iteration 3997000 (16.8193 iter/s, 29.7278s/500 iters), loss = 0.211025
I0901 04:00:15.058741 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.211028 (* 1 = 0.211028 loss)
I0901 04:00:15.058749 916722 sgd_solver.cpp:106] Iteration 3997000, lr = 0.01
I0901 04:00:44.785452 916722 solver.cpp:218] Iteration 3997500 (16.82 iter/s, 29.7265s/500 iters), loss = 0.14603
I0901 04:00:44.785503 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.146033 (* 1 = 0.146033 loss)
I0901 04:00:44.785513 916722 sgd_solver.cpp:106] Iteration 3997500, lr = 0.01
I0901 04:01:14.517030 916722 solver.cpp:218] Iteration 3998000 (16.8173 iter/s, 29.7313s/500 iters), loss = 0.0199677
I0901 04:01:14.517089 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0199709 (* 1 = 0.0199709 loss)
I0901 04:01:14.517097 916722 sgd_solver.cpp:106] Iteration 3998000, lr = 0.01
I0901 04:01:44.247735 916722 solver.cpp:218] Iteration 3998500 (16.8178 iter/s, 29.7304s/500 iters), loss = 0.194711
I0901 04:01:44.247786 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.194715 (* 1 = 0.194715 loss)
I0901 04:01:44.247797 916722 sgd_solver.cpp:106] Iteration 3998500, lr = 0.01
I0901 04:02:13.985556 916722 solver.cpp:218] Iteration 3999000 (16.8138 iter/s, 29.7375s/500 iters), loss = 0.0981251
I0901 04:02:13.985613 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0981284 (* 1 = 0.0981284 loss)
I0901 04:02:13.985621 916722 sgd_solver.cpp:106] Iteration 3999000, lr = 0.01
I0901 04:02:43.717856 916722 solver.cpp:218] Iteration 3999500 (16.8169 iter/s, 29.732s/500 iters), loss = 0.119195
I0901 04:02:43.717906 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.119199 (* 1 = 0.119199 loss)
I0901 04:02:43.717917 916722 sgd_solver.cpp:106] Iteration 3999500, lr = 0.01
I0901 04:03:13.387755 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_4000000.caffemodel
I0901 04:03:13.407014 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_4000000.solverstate
I0901 04:03:13.413025 916722 solver.cpp:330] Iteration 4000000, Testing net (#0)
I0901 04:03:28.827483 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8746
I0901 04:03:28.827533 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.443278 (* 1 = 0.443278 loss)
I0901 04:03:28.886023 916722 solver.cpp:218] Iteration 4000000 (11.0698 iter/s, 45.1678s/500 iters), loss = 0.0534945
I0901 04:03:28.886051 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.053498 (* 1 = 0.053498 loss)
I0901 04:03:28.886060 916722 sgd_solver.cpp:106] Iteration 4000000, lr = 0.01
I0901 04:03:58.487644 916722 solver.cpp:218] Iteration 4000500 (16.8911 iter/s, 29.6013s/500 iters), loss = 0.168857
I0901 04:03:58.487702 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.16886 (* 1 = 0.16886 loss)
I0901 04:03:58.487710 916722 sgd_solver.cpp:106] Iteration 4000500, lr = 0.01
I0901 04:04:28.139633 916722 solver.cpp:218] Iteration 4001000 (16.8624 iter/s, 29.6517s/500 iters), loss = 0.130582
I0901 04:04:28.139684 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130586 (* 1 = 0.130586 loss)
I0901 04:04:28.139694 916722 sgd_solver.cpp:106] Iteration 4001000, lr = 0.01
I0901 04:04:57.872185 916722 solver.cpp:218] Iteration 4001500 (16.8167 iter/s, 29.7323s/500 iters), loss = 0.179654
I0901 04:04:57.872246 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.179657 (* 1 = 0.179657 loss)
I0901 04:04:57.872256 916722 sgd_solver.cpp:106] Iteration 4001500, lr = 0.01
I0901 04:05:27.599114 916722 solver.cpp:218] Iteration 4002000 (16.8199 iter/s, 29.7266s/500 iters), loss = 0.359935
I0901 04:05:27.599164 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.359939 (* 1 = 0.359939 loss)
I0901 04:05:27.599171 916722 sgd_solver.cpp:106] Iteration 4002000, lr = 0.01
I0901 04:05:57.331833 916722 solver.cpp:218] Iteration 4002500 (16.8166 iter/s, 29.7325s/500 iters), loss = 0.124631
I0901 04:05:57.331907 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.124634 (* 1 = 0.124634 loss)
I0901 04:05:57.331915 916722 sgd_solver.cpp:106] Iteration 4002500, lr = 0.01
I0901 04:06:27.062006 916722 solver.cpp:218] Iteration 4003000 (16.8181 iter/s, 29.7299s/500 iters), loss = 0.256428
I0901 04:06:27.062057 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.256432 (* 1 = 0.256432 loss)
I0901 04:06:27.062067 916722 sgd_solver.cpp:106] Iteration 4003000, lr = 0.01
I0901 04:06:56.794548 916722 solver.cpp:218] Iteration 4003500 (16.8167 iter/s, 29.7323s/500 iters), loss = 0.0414305
I0901 04:06:56.794610 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0414339 (* 1 = 0.0414339 loss)
I0901 04:06:56.794618 916722 sgd_solver.cpp:106] Iteration 4003500, lr = 0.01
I0901 04:07:26.526053 916722 solver.cpp:218] Iteration 4004000 (16.8173 iter/s, 29.7312s/500 iters), loss = 0.0942027
I0901 04:07:26.526105 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0942059 (* 1 = 0.0942059 loss)
I0901 04:07:26.526113 916722 sgd_solver.cpp:106] Iteration 4004000, lr = 0.01
I0901 04:07:56.256846 916722 solver.cpp:218] Iteration 4004500 (16.8177 iter/s, 29.7305s/500 iters), loss = 0.0400338
I0901 04:07:56.256904 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0400369 (* 1 = 0.0400369 loss)
I0901 04:07:56.256913 916722 sgd_solver.cpp:106] Iteration 4004500, lr = 0.01
I0901 04:08:25.988729 916722 solver.cpp:218] Iteration 4005000 (16.8171 iter/s, 29.7316s/500 iters), loss = 0.0426123
I0901 04:08:25.988790 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0426156 (* 1 = 0.0426156 loss)
I0901 04:08:25.988798 916722 sgd_solver.cpp:106] Iteration 4005000, lr = 0.01
I0901 04:08:55.722817 916722 solver.cpp:218] Iteration 4005500 (16.8159 iter/s, 29.7338s/500 iters), loss = 0.0621783
I0901 04:08:55.722877 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0621816 (* 1 = 0.0621816 loss)
I0901 04:08:55.722887 916722 sgd_solver.cpp:106] Iteration 4005500, lr = 0.01
I0901 04:09:25.453934 916722 solver.cpp:218] Iteration 4006000 (16.8175 iter/s, 29.7309s/500 iters), loss = 0.163504
I0901 04:09:25.453984 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.163508 (* 1 = 0.163508 loss)
I0901 04:09:25.453994 916722 sgd_solver.cpp:106] Iteration 4006000, lr = 0.01
I0901 04:09:55.187139 916722 solver.cpp:218] Iteration 4006500 (16.8164 iter/s, 29.733s/500 iters), loss = 0.372301
I0901 04:09:55.187194 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.372304 (* 1 = 0.372304 loss)
I0901 04:09:55.187202 916722 sgd_solver.cpp:106] Iteration 4006500, lr = 0.01
I0901 04:10:24.918113 916722 solver.cpp:218] Iteration 4007000 (16.8176 iter/s, 29.7307s/500 iters), loss = 0.178723
I0901 04:10:24.918166 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.178726 (* 1 = 0.178726 loss)
I0901 04:10:24.918176 916722 sgd_solver.cpp:106] Iteration 4007000, lr = 0.01
I0901 04:10:54.648118 916722 solver.cpp:218] Iteration 4007500 (16.8182 iter/s, 29.7298s/500 iters), loss = 0.0521731
I0901 04:10:54.648175 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0521762 (* 1 = 0.0521762 loss)
I0901 04:10:54.648183 916722 sgd_solver.cpp:106] Iteration 4007500, lr = 0.01
I0901 04:11:24.377759 916722 solver.cpp:218] Iteration 4008000 (16.8184 iter/s, 29.7294s/500 iters), loss = 0.0558711
I0901 04:11:24.377810 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0558742 (* 1 = 0.0558742 loss)
I0901 04:11:24.377820 916722 sgd_solver.cpp:106] Iteration 4008000, lr = 0.01
I0901 04:11:54.108273 916722 solver.cpp:218] Iteration 4008500 (16.8179 iter/s, 29.7303s/500 iters), loss = 0.163954
I0901 04:11:54.108332 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.163957 (* 1 = 0.163957 loss)
I0901 04:11:54.108341 916722 sgd_solver.cpp:106] Iteration 4008500, lr = 0.01
I0901 04:12:23.835458 916722 solver.cpp:218] Iteration 4009000 (16.8198 iter/s, 29.7269s/500 iters), loss = 0.253775
I0901 04:12:23.835523 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.253778 (* 1 = 0.253778 loss)
I0901 04:12:23.835532 916722 sgd_solver.cpp:106] Iteration 4009000, lr = 0.01
I0901 04:12:53.563679 916722 solver.cpp:218] Iteration 4009500 (16.8192 iter/s, 29.728s/500 iters), loss = 0.120637
I0901 04:12:53.563750 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.12064 (* 1 = 0.12064 loss)
I0901 04:12:53.563760 916722 sgd_solver.cpp:106] Iteration 4009500, lr = 0.01
I0901 04:13:23.293406 916722 solver.cpp:218] Iteration 4010000 (16.8183 iter/s, 29.7295s/500 iters), loss = 0.151419
I0901 04:13:23.293457 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.151423 (* 1 = 0.151423 loss)
I0901 04:13:23.293467 916722 sgd_solver.cpp:106] Iteration 4010000, lr = 0.01
I0901 04:13:53.023612 916722 solver.cpp:218] Iteration 4010500 (16.818 iter/s, 29.73s/500 iters), loss = 0.0701255
I0901 04:13:53.023669 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0701287 (* 1 = 0.0701287 loss)
I0901 04:13:53.023677 916722 sgd_solver.cpp:106] Iteration 4010500, lr = 0.01
I0901 04:14:22.754299 916722 solver.cpp:218] Iteration 4011000 (16.8178 iter/s, 29.7304s/500 iters), loss = 0.0682796
I0901 04:14:22.754348 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0682829 (* 1 = 0.0682829 loss)
I0901 04:14:22.754357 916722 sgd_solver.cpp:106] Iteration 4011000, lr = 0.01
I0901 04:14:52.483511 916722 solver.cpp:218] Iteration 4011500 (16.8186 iter/s, 29.729s/500 iters), loss = 0.0757901
I0901 04:14:52.483572 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0757933 (* 1 = 0.0757933 loss)
I0901 04:14:52.483580 916722 sgd_solver.cpp:106] Iteration 4011500, lr = 0.01
I0901 04:15:22.215585 916722 solver.cpp:218] Iteration 4012000 (16.817 iter/s, 29.7318s/500 iters), loss = 0.327894
I0901 04:15:22.215638 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.327897 (* 1 = 0.327897 loss)
I0901 04:15:22.215648 916722 sgd_solver.cpp:106] Iteration 4012000, lr = 0.01
I0901 04:15:51.945047 916722 solver.cpp:218] Iteration 4012500 (16.8185 iter/s, 29.7292s/500 iters), loss = 0.121733
I0901 04:15:51.945106 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.121736 (* 1 = 0.121736 loss)
I0901 04:15:51.945116 916722 sgd_solver.cpp:106] Iteration 4012500, lr = 0.01
I0901 04:16:21.673637 916722 solver.cpp:218] Iteration 4013000 (16.8189 iter/s, 29.7285s/500 iters), loss = 0.117407
I0901 04:16:21.673686 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.11741 (* 1 = 0.11741 loss)
I0901 04:16:21.673696 916722 sgd_solver.cpp:106] Iteration 4013000, lr = 0.01
I0901 04:16:51.401818 916722 solver.cpp:218] Iteration 4013500 (16.819 iter/s, 29.7283s/500 iters), loss = 0.0596924
I0901 04:16:51.401877 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0596958 (* 1 = 0.0596958 loss)
I0901 04:16:51.401885 916722 sgd_solver.cpp:106] Iteration 4013500, lr = 0.01
I0901 04:17:21.130903 916722 solver.cpp:218] Iteration 4014000 (16.8185 iter/s, 29.7292s/500 iters), loss = 0.243388
I0901 04:17:21.130954 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.243391 (* 1 = 0.243391 loss)
I0901 04:17:21.130964 916722 sgd_solver.cpp:106] Iteration 4014000, lr = 0.01
I0901 04:17:50.860858 916722 solver.cpp:218] Iteration 4014500 (16.818 iter/s, 29.7301s/500 iters), loss = 0.180816
I0901 04:17:50.860914 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.180819 (* 1 = 0.180819 loss)
I0901 04:17:50.860922 916722 sgd_solver.cpp:106] Iteration 4014500, lr = 0.01
I0901 04:18:20.590204 916722 solver.cpp:218] Iteration 4015000 (16.8183 iter/s, 29.7294s/500 iters), loss = 0.16917
I0901 04:18:20.590251 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.169173 (* 1 = 0.169173 loss)
I0901 04:18:20.590261 916722 sgd_solver.cpp:106] Iteration 4015000, lr = 0.01
I0901 04:18:50.319191 916722 solver.cpp:218] Iteration 4015500 (16.8186 iter/s, 29.7291s/500 iters), loss = 0.191117
I0901 04:18:50.319265 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.19112 (* 1 = 0.19112 loss)
I0901 04:18:50.319274 916722 sgd_solver.cpp:106] Iteration 4015500, lr = 0.01
I0901 04:19:20.050170 916722 solver.cpp:218] Iteration 4016000 (16.8174 iter/s, 29.731s/500 iters), loss = 0.262218
I0901 04:19:20.050223 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.262222 (* 1 = 0.262222 loss)
I0901 04:19:20.050233 916722 sgd_solver.cpp:106] Iteration 4016000, lr = 0.01
I0901 04:19:49.778079 916722 solver.cpp:218] Iteration 4016500 (16.8192 iter/s, 29.728s/500 iters), loss = 0.192145
I0901 04:19:49.778137 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.192148 (* 1 = 0.192148 loss)
I0901 04:19:49.778146 916722 sgd_solver.cpp:106] Iteration 4016500, lr = 0.01
I0901 04:20:19.506670 916722 solver.cpp:218] Iteration 4017000 (16.8188 iter/s, 29.7286s/500 iters), loss = 0.228609
I0901 04:20:19.506721 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.228613 (* 1 = 0.228613 loss)
I0901 04:20:19.506732 916722 sgd_solver.cpp:106] Iteration 4017000, lr = 0.01
I0901 04:20:49.235041 916722 solver.cpp:218] Iteration 4017500 (16.8189 iter/s, 29.7284s/500 iters), loss = 0.179792
I0901 04:20:49.235105 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.179795 (* 1 = 0.179795 loss)
I0901 04:20:49.235113 916722 sgd_solver.cpp:106] Iteration 4017500, lr = 0.01
I0901 04:21:18.964946 916722 solver.cpp:218] Iteration 4018000 (16.8181 iter/s, 29.7299s/500 iters), loss = 0.147016
I0901 04:21:18.964998 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.147019 (* 1 = 0.147019 loss)
I0901 04:21:18.965008 916722 sgd_solver.cpp:106] Iteration 4018000, lr = 0.01
I0901 04:21:48.696605 916722 solver.cpp:218] Iteration 4018500 (16.8171 iter/s, 29.7317s/500 iters), loss = 0.213135
I0901 04:21:48.696664 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.213138 (* 1 = 0.213138 loss)
I0901 04:21:48.696673 916722 sgd_solver.cpp:106] Iteration 4018500, lr = 0.01
I0901 04:22:18.422791 916722 solver.cpp:218] Iteration 4019000 (16.8202 iter/s, 29.7262s/500 iters), loss = 0.156255
I0901 04:22:18.422839 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.156258 (* 1 = 0.156258 loss)
I0901 04:22:18.422848 916722 sgd_solver.cpp:106] Iteration 4019000, lr = 0.01
I0901 04:22:48.153015 916722 solver.cpp:218] Iteration 4019500 (16.8179 iter/s, 29.7302s/500 iters), loss = 0.0573013
I0901 04:22:48.153074 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0573049 (* 1 = 0.0573049 loss)
I0901 04:22:48.153081 916722 sgd_solver.cpp:106] Iteration 4019500, lr = 0.01
I0901 04:23:17.883791 916722 solver.cpp:218] Iteration 4020000 (16.8176 iter/s, 29.7307s/500 iters), loss = 0.194197
I0901 04:23:17.883838 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.194201 (* 1 = 0.194201 loss)
I0901 04:23:17.883847 916722 sgd_solver.cpp:106] Iteration 4020000, lr = 0.01
I0901 04:23:47.613565 916722 solver.cpp:218] Iteration 4020500 (16.8182 iter/s, 29.7297s/500 iters), loss = 0.167324
I0901 04:23:47.613622 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.167327 (* 1 = 0.167327 loss)
I0901 04:23:47.613631 916722 sgd_solver.cpp:106] Iteration 4020500, lr = 0.01
I0901 04:24:17.342939 916722 solver.cpp:218] Iteration 4021000 (16.8184 iter/s, 29.7293s/500 iters), loss = 0.104805
I0901 04:24:17.342991 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104808 (* 1 = 0.104808 loss)
I0901 04:24:17.343000 916722 sgd_solver.cpp:106] Iteration 4021000, lr = 0.01
I0901 04:24:47.072504 916722 solver.cpp:218] Iteration 4021500 (16.8183 iter/s, 29.7295s/500 iters), loss = 0.0917111
I0901 04:24:47.072566 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0917149 (* 1 = 0.0917149 loss)
I0901 04:24:47.072574 916722 sgd_solver.cpp:106] Iteration 4021500, lr = 0.01
I0901 04:25:16.801169 916722 solver.cpp:218] Iteration 4022000 (16.8188 iter/s, 29.7286s/500 iters), loss = 0.063951
I0901 04:25:16.801221 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0639547 (* 1 = 0.0639547 loss)
I0901 04:25:16.801240 916722 sgd_solver.cpp:106] Iteration 4022000, lr = 0.01
I0901 04:25:46.530351 916722 solver.cpp:218] Iteration 4022500 (16.8185 iter/s, 29.7291s/500 iters), loss = 0.220428
I0901 04:25:46.530418 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.220432 (* 1 = 0.220432 loss)
I0901 04:25:46.530427 916722 sgd_solver.cpp:106] Iteration 4022500, lr = 0.01
I0901 04:26:16.259946 916722 solver.cpp:218] Iteration 4023000 (16.8183 iter/s, 29.7295s/500 iters), loss = 0.18307
I0901 04:26:16.259997 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.183074 (* 1 = 0.183074 loss)
I0901 04:26:16.260006 916722 sgd_solver.cpp:106] Iteration 4023000, lr = 0.01
I0901 04:26:45.991590 916722 solver.cpp:218] Iteration 4023500 (16.8171 iter/s, 29.7316s/500 iters), loss = 0.279774
I0901 04:26:45.991647 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.279778 (* 1 = 0.279778 loss)
I0901 04:26:45.991657 916722 sgd_solver.cpp:106] Iteration 4023500, lr = 0.01
I0901 04:27:15.720434 916722 solver.cpp:218] Iteration 4024000 (16.8187 iter/s, 29.7287s/500 iters), loss = 0.118578
I0901 04:27:15.720487 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.118581 (* 1 = 0.118581 loss)
I0901 04:27:15.720497 916722 sgd_solver.cpp:106] Iteration 4024000, lr = 0.01
I0901 04:27:45.450680 916722 solver.cpp:218] Iteration 4024500 (16.8179 iter/s, 29.7301s/500 iters), loss = 0.103521
I0901 04:27:45.450733 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.103525 (* 1 = 0.103525 loss)
I0901 04:27:45.450742 916722 sgd_solver.cpp:106] Iteration 4024500, lr = 0.01
I0901 04:28:15.183184 916722 solver.cpp:218] Iteration 4025000 (16.8167 iter/s, 29.7324s/500 iters), loss = 0.0892715
I0901 04:28:15.183238 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0892753 (* 1 = 0.0892753 loss)
I0901 04:28:15.183248 916722 sgd_solver.cpp:106] Iteration 4025000, lr = 0.01
I0901 04:28:44.923233 916722 solver.cpp:218] Iteration 4025500 (16.8124 iter/s, 29.7399s/500 iters), loss = 0.238191
I0901 04:28:44.923290 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.238194 (* 1 = 0.238194 loss)
I0901 04:28:44.923298 916722 sgd_solver.cpp:106] Iteration 4025500, lr = 0.01
I0901 04:29:14.659196 916722 solver.cpp:218] Iteration 4026000 (16.8147 iter/s, 29.7359s/500 iters), loss = 0.129534
I0901 04:29:14.659247 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.129538 (* 1 = 0.129538 loss)
I0901 04:29:14.659257 916722 sgd_solver.cpp:106] Iteration 4026000, lr = 0.01
I0901 04:29:44.399364 916722 solver.cpp:218] Iteration 4026500 (16.8123 iter/s, 29.7401s/500 iters), loss = 0.0602729
I0901 04:29:44.399422 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0602769 (* 1 = 0.0602769 loss)
I0901 04:29:44.399430 916722 sgd_solver.cpp:106] Iteration 4026500, lr = 0.01
I0901 04:30:14.140151 916722 solver.cpp:218] Iteration 4027000 (16.812 iter/s, 29.7407s/500 iters), loss = 0.00567892
I0901 04:30:14.140203 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.00568293 (* 1 = 0.00568293 loss)
I0901 04:30:14.140213 916722 sgd_solver.cpp:106] Iteration 4027000, lr = 0.01
I0901 04:30:43.881531 916722 solver.cpp:218] Iteration 4027500 (16.8117 iter/s, 29.7413s/500 iters), loss = 0.109968
I0901 04:30:43.881590 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109972 (* 1 = 0.109972 loss)
I0901 04:30:43.881598 916722 sgd_solver.cpp:106] Iteration 4027500, lr = 0.01
I0901 04:31:13.624905 916722 solver.cpp:218] Iteration 4028000 (16.8105 iter/s, 29.7432s/500 iters), loss = 0.167283
I0901 04:31:13.624953 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.167287 (* 1 = 0.167287 loss)
I0901 04:31:13.624963 916722 sgd_solver.cpp:106] Iteration 4028000, lr = 0.01
I0901 04:31:43.365278 916722 solver.cpp:218] Iteration 4028500 (16.8122 iter/s, 29.7402s/500 iters), loss = 0.0435388
I0901 04:31:43.365345 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0435428 (* 1 = 0.0435428 loss)
I0901 04:31:43.365358 916722 sgd_solver.cpp:106] Iteration 4028500, lr = 0.01
I0901 04:32:13.103188 916722 solver.cpp:218] Iteration 4029000 (16.8136 iter/s, 29.7378s/500 iters), loss = 0.202411
I0901 04:32:13.103235 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.202415 (* 1 = 0.202415 loss)
I0901 04:32:13.103245 916722 sgd_solver.cpp:106] Iteration 4029000, lr = 0.01
I0901 04:32:42.847703 916722 solver.cpp:218] Iteration 4029500 (16.8099 iter/s, 29.7444s/500 iters), loss = 0.222174
I0901 04:32:42.847765 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.222178 (* 1 = 0.222178 loss)
I0901 04:32:42.847774 916722 sgd_solver.cpp:106] Iteration 4029500, lr = 0.01
I0901 04:33:12.592862 916722 solver.cpp:218] Iteration 4030000 (16.8095 iter/s, 29.745s/500 iters), loss = 0.256
I0901 04:33:12.592913 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.256004 (* 1 = 0.256004 loss)
I0901 04:33:12.592922 916722 sgd_solver.cpp:106] Iteration 4030000, lr = 0.01
I0901 04:33:42.331118 916722 solver.cpp:218] Iteration 4030500 (16.8134 iter/s, 29.7381s/500 iters), loss = 0.121654
I0901 04:33:42.331176 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.121659 (* 1 = 0.121659 loss)
I0901 04:33:42.331185 916722 sgd_solver.cpp:106] Iteration 4030500, lr = 0.01
I0901 04:34:12.071537 916722 solver.cpp:218] Iteration 4031000 (16.8122 iter/s, 29.7403s/500 iters), loss = 0.105978
I0901 04:34:12.071589 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105983 (* 1 = 0.105983 loss)
I0901 04:34:12.071599 916722 sgd_solver.cpp:106] Iteration 4031000, lr = 0.01
I0901 04:34:41.812691 916722 solver.cpp:218] Iteration 4031500 (16.8118 iter/s, 29.741s/500 iters), loss = 0.321524
I0901 04:34:41.812760 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.321528 (* 1 = 0.321528 loss)
I0901 04:34:41.812769 916722 sgd_solver.cpp:106] Iteration 4031500, lr = 0.01
I0901 04:35:11.555752 916722 solver.cpp:218] Iteration 4032000 (16.8107 iter/s, 29.7429s/500 iters), loss = 0.110524
I0901 04:35:11.555804 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110528 (* 1 = 0.110528 loss)
I0901 04:35:11.555812 916722 sgd_solver.cpp:106] Iteration 4032000, lr = 0.01
I0901 04:35:41.298709 916722 solver.cpp:218] Iteration 4032500 (16.8108 iter/s, 29.7428s/500 iters), loss = 0.136015
I0901 04:35:41.298768 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13602 (* 1 = 0.13602 loss)
I0901 04:35:41.298776 916722 sgd_solver.cpp:106] Iteration 4032500, lr = 0.01
I0901 04:36:11.041344 916722 solver.cpp:218] Iteration 4033000 (16.811 iter/s, 29.7425s/500 iters), loss = 0.00876191
I0901 04:36:11.041393 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.00876627 (* 1 = 0.00876627 loss)
I0901 04:36:11.041402 916722 sgd_solver.cpp:106] Iteration 4033000, lr = 0.01
I0901 04:36:40.783772 916722 solver.cpp:218] Iteration 4033500 (16.8111 iter/s, 29.7423s/500 iters), loss = 0.231439
I0901 04:36:40.783828 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.231443 (* 1 = 0.231443 loss)
I0901 04:36:40.783838 916722 sgd_solver.cpp:106] Iteration 4033500, lr = 0.01
I0901 04:37:10.515468 916722 solver.cpp:218] Iteration 4034000 (16.8172 iter/s, 29.7315s/500 iters), loss = 0.0671652
I0901 04:37:10.515519 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0671695 (* 1 = 0.0671695 loss)
I0901 04:37:10.515528 916722 sgd_solver.cpp:106] Iteration 4034000, lr = 0.01
I0901 04:37:40.248445 916722 solver.cpp:218] Iteration 4034500 (16.8164 iter/s, 29.7328s/500 iters), loss = 0.257431
I0901 04:37:40.248503 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.257435 (* 1 = 0.257435 loss)
I0901 04:37:40.248512 916722 sgd_solver.cpp:106] Iteration 4034500, lr = 0.01
I0901 04:38:09.978475 916722 solver.cpp:218] Iteration 4035000 (16.8181 iter/s, 29.7299s/500 iters), loss = 0.085995
I0901 04:38:09.978525 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0859994 (* 1 = 0.0859994 loss)
I0901 04:38:09.978534 916722 sgd_solver.cpp:106] Iteration 4035000, lr = 0.01
I0901 04:38:39.711725 916722 solver.cpp:218] Iteration 4035500 (16.8163 iter/s, 29.7331s/500 iters), loss = 0.236854
I0901 04:38:39.711793 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.236859 (* 1 = 0.236859 loss)
I0901 04:38:39.711802 916722 sgd_solver.cpp:106] Iteration 4035500, lr = 0.01
I0901 04:39:09.442953 916722 solver.cpp:218] Iteration 4036000 (16.8174 iter/s, 29.731s/500 iters), loss = 0.216045
I0901 04:39:09.443003 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.216049 (* 1 = 0.216049 loss)
I0901 04:39:09.443012 916722 sgd_solver.cpp:106] Iteration 4036000, lr = 0.01
I0901 04:39:39.175302 916722 solver.cpp:218] Iteration 4036500 (16.8168 iter/s, 29.7322s/500 iters), loss = 0.146641
I0901 04:39:39.175361 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.146645 (* 1 = 0.146645 loss)
I0901 04:39:39.175369 916722 sgd_solver.cpp:106] Iteration 4036500, lr = 0.01
I0901 04:40:08.906442 916722 solver.cpp:218] Iteration 4037000 (16.8175 iter/s, 29.731s/500 iters), loss = 0.051636
I0901 04:40:08.906491 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0516404 (* 1 = 0.0516404 loss)
I0901 04:40:08.906500 916722 sgd_solver.cpp:106] Iteration 4037000, lr = 0.01
I0901 04:40:38.638474 916722 solver.cpp:218] Iteration 4037500 (16.817 iter/s, 29.7319s/500 iters), loss = 0.15975
I0901 04:40:38.638532 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159755 (* 1 = 0.159755 loss)
I0901 04:40:38.638540 916722 sgd_solver.cpp:106] Iteration 4037500, lr = 0.01
I0901 04:41:08.368316 916722 solver.cpp:218] Iteration 4038000 (16.8182 iter/s, 29.7297s/500 iters), loss = 0.118563
I0901 04:41:08.368366 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.118567 (* 1 = 0.118567 loss)
I0901 04:41:08.368376 916722 sgd_solver.cpp:106] Iteration 4038000, lr = 0.01
I0901 04:41:38.108916 916722 solver.cpp:218] Iteration 4038500 (16.8121 iter/s, 29.7404s/500 iters), loss = 0.142594
I0901 04:41:38.108978 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.142599 (* 1 = 0.142599 loss)
I0901 04:41:38.108986 916722 sgd_solver.cpp:106] Iteration 4038500, lr = 0.01
I0901 04:42:07.841711 916722 solver.cpp:218] Iteration 4039000 (16.8165 iter/s, 29.7326s/500 iters), loss = 0.0258962
I0901 04:42:07.841763 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0259008 (* 1 = 0.0259008 loss)
I0901 04:42:07.841773 916722 sgd_solver.cpp:106] Iteration 4039000, lr = 0.01
I0901 04:42:37.573455 916722 solver.cpp:218] Iteration 4039500 (16.8171 iter/s, 29.7316s/500 iters), loss = 0.0171447
I0901 04:42:37.573513 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0171495 (* 1 = 0.0171495 loss)
I0901 04:42:37.573521 916722 sgd_solver.cpp:106] Iteration 4039500, lr = 0.01
I0901 04:43:07.306833 916722 solver.cpp:218] Iteration 4040000 (16.8162 iter/s, 29.7332s/500 iters), loss = 0.159137
I0901 04:43:07.306885 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159142 (* 1 = 0.159142 loss)
I0901 04:43:07.306895 916722 sgd_solver.cpp:106] Iteration 4040000, lr = 0.01
I0901 04:43:37.037703 916722 solver.cpp:218] Iteration 4040500 (16.8176 iter/s, 29.7307s/500 iters), loss = 0.0282874
I0901 04:43:37.037760 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0282921 (* 1 = 0.0282921 loss)
I0901 04:43:37.037768 916722 sgd_solver.cpp:106] Iteration 4040500, lr = 0.01
I0901 04:44:06.774721 916722 solver.cpp:218] Iteration 4041000 (16.8142 iter/s, 29.7368s/500 iters), loss = 0.0421724
I0901 04:44:06.774773 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.042177 (* 1 = 0.042177 loss)
I0901 04:44:06.774783 916722 sgd_solver.cpp:106] Iteration 4041000, lr = 0.01
I0901 04:44:36.508962 916722 solver.cpp:218] Iteration 4041500 (16.8157 iter/s, 29.7341s/500 iters), loss = 0.152482
I0901 04:44:36.509018 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152486 (* 1 = 0.152486 loss)
I0901 04:44:36.509027 916722 sgd_solver.cpp:106] Iteration 4041500, lr = 0.01
I0901 04:45:06.239782 916722 solver.cpp:218] Iteration 4042000 (16.8177 iter/s, 29.7306s/500 iters), loss = 0.154858
I0901 04:45:06.239831 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.154863 (* 1 = 0.154863 loss)
I0901 04:45:06.239841 916722 sgd_solver.cpp:106] Iteration 4042000, lr = 0.01
I0901 04:45:35.970366 916722 solver.cpp:218] Iteration 4042500 (16.8178 iter/s, 29.7304s/500 iters), loss = 0.0332578
I0901 04:45:35.970430 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0332624 (* 1 = 0.0332624 loss)
I0901 04:45:35.970439 916722 sgd_solver.cpp:106] Iteration 4042500, lr = 0.01
I0901 04:46:05.702086 916722 solver.cpp:218] Iteration 4043000 (16.8172 iter/s, 29.7315s/500 iters), loss = 0.233029
I0901 04:46:05.702139 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.233034 (* 1 = 0.233034 loss)
I0901 04:46:05.702149 916722 sgd_solver.cpp:106] Iteration 4043000, lr = 0.01
I0901 04:46:35.434130 916722 solver.cpp:218] Iteration 4043500 (16.817 iter/s, 29.7319s/500 iters), loss = 0.191141
I0901 04:46:35.434188 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.191146 (* 1 = 0.191146 loss)
I0901 04:46:35.434197 916722 sgd_solver.cpp:106] Iteration 4043500, lr = 0.01
I0901 04:47:05.167873 916722 solver.cpp:218] Iteration 4044000 (16.816 iter/s, 29.7336s/500 iters), loss = 0.240608
I0901 04:47:05.167924 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.240612 (* 1 = 0.240612 loss)
I0901 04:47:05.167934 916722 sgd_solver.cpp:106] Iteration 4044000, lr = 0.01
I0901 04:47:34.898576 916722 solver.cpp:218] Iteration 4044500 (16.8177 iter/s, 29.7305s/500 iters), loss = 0.00932986
I0901 04:47:34.898636 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.00933439 (* 1 = 0.00933439 loss)
I0901 04:47:34.898645 916722 sgd_solver.cpp:106] Iteration 4044500, lr = 0.01
I0901 04:48:04.632068 916722 solver.cpp:218] Iteration 4045000 (16.8162 iter/s, 29.7333s/500 iters), loss = 0.0956572
I0901 04:48:04.632119 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0956621 (* 1 = 0.0956621 loss)
I0901 04:48:04.632128 916722 sgd_solver.cpp:106] Iteration 4045000, lr = 0.01
I0901 04:48:34.363803 916722 solver.cpp:218] Iteration 4045500 (16.8171 iter/s, 29.7316s/500 iters), loss = 0.281407
I0901 04:48:34.363860 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.281412 (* 1 = 0.281412 loss)
I0901 04:48:34.363869 916722 sgd_solver.cpp:106] Iteration 4045500, lr = 0.01
I0901 04:49:04.096609 916722 solver.cpp:218] Iteration 4046000 (16.8165 iter/s, 29.7326s/500 iters), loss = 0.0617526
I0901 04:49:04.096657 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0617576 (* 1 = 0.0617576 loss)
I0901 04:49:04.096666 916722 sgd_solver.cpp:106] Iteration 4046000, lr = 0.01
I0901 04:49:33.826534 916722 solver.cpp:218] Iteration 4046500 (16.8182 iter/s, 29.7297s/500 iters), loss = 0.23596
I0901 04:49:33.826589 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.235965 (* 1 = 0.235965 loss)
I0901 04:49:33.826598 916722 sgd_solver.cpp:106] Iteration 4046500, lr = 0.01
I0901 04:50:03.556851 916722 solver.cpp:218] Iteration 4047000 (16.818 iter/s, 29.7301s/500 iters), loss = 0.166099
I0901 04:50:03.556900 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.166104 (* 1 = 0.166104 loss)
I0901 04:50:03.556907 916722 sgd_solver.cpp:106] Iteration 4047000, lr = 0.01
I0901 04:50:33.286550 916722 solver.cpp:218] Iteration 4047500 (16.8183 iter/s, 29.7295s/500 iters), loss = 0.156111
I0901 04:50:33.286607 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.156116 (* 1 = 0.156116 loss)
I0901 04:50:33.286614 916722 sgd_solver.cpp:106] Iteration 4047500, lr = 0.01
I0901 04:51:03.017707 916722 solver.cpp:218] Iteration 4048000 (16.8174 iter/s, 29.731s/500 iters), loss = 0.0316241
I0901 04:51:03.017758 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0316293 (* 1 = 0.0316293 loss)
I0901 04:51:03.017767 916722 sgd_solver.cpp:106] Iteration 4048000, lr = 0.01
I0901 04:51:32.771529 916722 solver.cpp:218] Iteration 4048500 (16.8046 iter/s, 29.7537s/500 iters), loss = 0.0960536
I0901 04:51:32.771595 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0960588 (* 1 = 0.0960588 loss)
I0901 04:51:32.771605 916722 sgd_solver.cpp:106] Iteration 4048500, lr = 0.01
I0901 04:52:02.510236 916722 solver.cpp:218] Iteration 4049000 (16.8132 iter/s, 29.7386s/500 iters), loss = 0.088111
I0901 04:52:02.510288 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0881162 (* 1 = 0.0881162 loss)
I0901 04:52:02.510298 916722 sgd_solver.cpp:106] Iteration 4049000, lr = 0.01
I0901 04:52:32.240526 916722 solver.cpp:218] Iteration 4049500 (16.8179 iter/s, 29.7302s/500 iters), loss = 0.0269872
I0901 04:52:32.240584 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0269922 (* 1 = 0.0269922 loss)
I0901 04:52:32.240593 916722 sgd_solver.cpp:106] Iteration 4049500, lr = 0.01
I0901 04:53:01.913702 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_4050000.caffemodel
I0901 04:53:01.933234 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_4050000.solverstate
I0901 04:53:01.939329 916722 solver.cpp:330] Iteration 4050000, Testing net (#0)
I0901 04:53:17.399102 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8867
I0901 04:53:17.399147 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.393949 (* 1 = 0.393949 loss)
I0901 04:53:17.457648 916722 solver.cpp:218] Iteration 4050000 (11.0578 iter/s, 45.2169s/500 iters), loss = 0.0947224
I0901 04:53:17.457676 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0947274 (* 1 = 0.0947274 loss)
I0901 04:53:17.457685 916722 sgd_solver.cpp:106] Iteration 4050000, lr = 0.01
I0901 04:53:47.074013 916722 solver.cpp:218] Iteration 4050500 (16.8826 iter/s, 29.6162s/500 iters), loss = 0.0569394
I0901 04:53:47.074062 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0569442 (* 1 = 0.0569442 loss)
I0901 04:53:47.074071 916722 sgd_solver.cpp:106] Iteration 4050500, lr = 0.01
I0901 04:54:16.706585 916722 solver.cpp:218] Iteration 4051000 (16.8734 iter/s, 29.6324s/500 iters), loss = 0.222547
I0901 04:54:16.706645 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.222552 (* 1 = 0.222552 loss)
I0901 04:54:16.706653 916722 sgd_solver.cpp:106] Iteration 4051000, lr = 0.01
I0901 04:54:46.439288 916722 solver.cpp:218] Iteration 4051500 (16.8166 iter/s, 29.7325s/500 iters), loss = 0.151485
I0901 04:54:46.439342 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.15149 (* 1 = 0.15149 loss)
I0901 04:54:46.439352 916722 sgd_solver.cpp:106] Iteration 4051500, lr = 0.01
I0901 04:55:16.168566 916722 solver.cpp:218] Iteration 4052000 (16.8185 iter/s, 29.7291s/500 iters), loss = 0.087315
I0901 04:55:16.168625 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0873197 (* 1 = 0.0873197 loss)
I0901 04:55:16.168634 916722 sgd_solver.cpp:106] Iteration 4052000, lr = 0.01
I0901 04:55:45.898744 916722 solver.cpp:218] Iteration 4052500 (16.818 iter/s, 29.73s/500 iters), loss = 0.141336
I0901 04:55:45.898795 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.141341 (* 1 = 0.141341 loss)
I0901 04:55:45.898805 916722 sgd_solver.cpp:106] Iteration 4052500, lr = 0.01
I0901 04:56:15.630518 916722 solver.cpp:218] Iteration 4053000 (16.8171 iter/s, 29.7316s/500 iters), loss = 0.245285
I0901 04:56:15.630571 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.24529 (* 1 = 0.24529 loss)
I0901 04:56:15.630580 916722 sgd_solver.cpp:106] Iteration 4053000, lr = 0.01
I0901 04:56:45.364857 916722 solver.cpp:218] Iteration 4053500 (16.8157 iter/s, 29.7342s/500 iters), loss = 0.114398
I0901 04:56:45.364909 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.114403 (* 1 = 0.114403 loss)
I0901 04:56:45.364918 916722 sgd_solver.cpp:106] Iteration 4053500, lr = 0.01
I0901 04:57:15.095520 916722 solver.cpp:218] Iteration 4054000 (16.8177 iter/s, 29.7305s/500 iters), loss = 0.0171829
I0901 04:57:15.095595 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0171877 (* 1 = 0.0171877 loss)
I0901 04:57:15.095604 916722 sgd_solver.cpp:106] Iteration 4054000, lr = 0.01
I0901 04:57:44.827033 916722 solver.cpp:218] Iteration 4054500 (16.8173 iter/s, 29.7313s/500 iters), loss = 0.06824
I0901 04:57:44.827086 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0682449 (* 1 = 0.0682449 loss)
I0901 04:57:44.827096 916722 sgd_solver.cpp:106] Iteration 4054500, lr = 0.01
I0901 04:58:14.562947 916722 solver.cpp:218] Iteration 4055000 (16.8148 iter/s, 29.7358s/500 iters), loss = 0.116881
I0901 04:58:14.563004 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.116886 (* 1 = 0.116886 loss)
I0901 04:58:14.563012 916722 sgd_solver.cpp:106] Iteration 4055000, lr = 0.01
I0901 04:58:44.294494 916722 solver.cpp:218] Iteration 4055500 (16.8172 iter/s, 29.7314s/500 iters), loss = 0.138064
I0901 04:58:44.294545 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.138069 (* 1 = 0.138069 loss)
I0901 04:58:44.294555 916722 sgd_solver.cpp:106] Iteration 4055500, lr = 0.01
I0901 04:59:14.024729 916722 solver.cpp:218] Iteration 4056000 (16.818 iter/s, 29.7301s/500 iters), loss = 0.124196
I0901 04:59:14.024798 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.124201 (* 1 = 0.124201 loss)
I0901 04:59:14.024806 916722 sgd_solver.cpp:106] Iteration 4056000, lr = 0.01
I0901 04:59:43.754283 916722 solver.cpp:218] Iteration 4056500 (16.8184 iter/s, 29.7294s/500 iters), loss = 0.30325
I0901 04:59:43.754336 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.303255 (* 1 = 0.303255 loss)
I0901 04:59:43.754346 916722 sgd_solver.cpp:106] Iteration 4056500, lr = 0.01
I0901 05:00:13.482645 916722 solver.cpp:218] Iteration 4057000 (16.8191 iter/s, 29.7282s/500 iters), loss = 0.143751
I0901 05:00:13.482707 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.143756 (* 1 = 0.143756 loss)
I0901 05:00:13.482714 916722 sgd_solver.cpp:106] Iteration 4057000, lr = 0.01
I0901 05:00:43.216763 916722 solver.cpp:218] Iteration 4057500 (16.8158 iter/s, 29.7339s/500 iters), loss = 0.318315
I0901 05:00:43.216814 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.31832 (* 1 = 0.31832 loss)
I0901 05:00:43.216823 916722 sgd_solver.cpp:106] Iteration 4057500, lr = 0.01
I0901 05:01:12.948860 916722 solver.cpp:218] Iteration 4058000 (16.8169 iter/s, 29.7319s/500 iters), loss = 0.0423025
I0901 05:01:12.948920 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0423071 (* 1 = 0.0423071 loss)
I0901 05:01:12.948927 916722 sgd_solver.cpp:106] Iteration 4058000, lr = 0.01
I0901 05:01:42.679049 916722 solver.cpp:218] Iteration 4058500 (16.818 iter/s, 29.73s/500 iters), loss = 0.19272
I0901 05:01:42.679101 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.192724 (* 1 = 0.192724 loss)
I0901 05:01:42.679111 916722 sgd_solver.cpp:106] Iteration 4058500, lr = 0.01
I0901 05:02:12.406491 916722 solver.cpp:218] Iteration 4059000 (16.8196 iter/s, 29.7273s/500 iters), loss = 0.337677
I0901 05:02:12.406548 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.337682 (* 1 = 0.337682 loss)
I0901 05:02:12.406556 916722 sgd_solver.cpp:106] Iteration 4059000, lr = 0.01
I0901 05:02:42.138257 916722 solver.cpp:218] Iteration 4059500 (16.8171 iter/s, 29.7316s/500 iters), loss = 0.0607705
I0901 05:02:42.138307 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.060775 (* 1 = 0.060775 loss)
I0901 05:02:42.138316 916722 sgd_solver.cpp:106] Iteration 4059500, lr = 0.01
I0901 05:03:11.870590 916722 solver.cpp:218] Iteration 4060000 (16.8168 iter/s, 29.7322s/500 iters), loss = 0.149478
I0901 05:03:11.870644 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.149482 (* 1 = 0.149482 loss)
I0901 05:03:11.870653 916722 sgd_solver.cpp:106] Iteration 4060000, lr = 0.01
I0901 05:03:41.603024 916722 solver.cpp:218] Iteration 4060500 (16.8168 iter/s, 29.7323s/500 iters), loss = 0.116455
I0901 05:03:41.603075 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.11646 (* 1 = 0.11646 loss)
I0901 05:03:41.603094 916722 sgd_solver.cpp:106] Iteration 4060500, lr = 0.01
I0901 05:04:11.335410 916722 solver.cpp:218] Iteration 4061000 (16.8168 iter/s, 29.7322s/500 iters), loss = 0.101669
I0901 05:04:11.335479 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101674 (* 1 = 0.101674 loss)
I0901 05:04:11.335487 916722 sgd_solver.cpp:106] Iteration 4061000, lr = 0.01
I0901 05:04:41.065068 916722 solver.cpp:218] Iteration 4061500 (16.8183 iter/s, 29.7295s/500 iters), loss = 0.274917
I0901 05:04:41.065121 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.274921 (* 1 = 0.274921 loss)
I0901 05:04:41.065131 916722 sgd_solver.cpp:106] Iteration 4061500, lr = 0.01
I0901 05:05:10.795672 916722 solver.cpp:218] Iteration 4062000 (16.8178 iter/s, 29.7304s/500 iters), loss = 0.306249
I0901 05:05:10.795730 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.306253 (* 1 = 0.306253 loss)
I0901 05:05:10.795739 916722 sgd_solver.cpp:106] Iteration 4062000, lr = 0.01
I0901 05:05:40.526145 916722 solver.cpp:218] Iteration 4062500 (16.8179 iter/s, 29.7303s/500 iters), loss = 0.0432196
I0901 05:05:40.526201 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0432241 (* 1 = 0.0432241 loss)
I0901 05:05:40.526211 916722 sgd_solver.cpp:106] Iteration 4062500, lr = 0.01
I0901 05:06:10.256219 916722 solver.cpp:218] Iteration 4063000 (16.8181 iter/s, 29.7299s/500 iters), loss = 0.0556999
I0901 05:06:10.256278 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0557044 (* 1 = 0.0557044 loss)
I0901 05:06:10.256286 916722 sgd_solver.cpp:106] Iteration 4063000, lr = 0.01
I0901 05:06:39.988360 916722 solver.cpp:218] Iteration 4063500 (16.8169 iter/s, 29.732s/500 iters), loss = 0.0655832
I0901 05:06:39.988411 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0655878 (* 1 = 0.0655878 loss)
I0901 05:06:39.988422 916722 sgd_solver.cpp:106] Iteration 4063500, lr = 0.01
I0901 05:07:09.722282 916722 solver.cpp:218] Iteration 4064000 (16.8159 iter/s, 29.7337s/500 iters), loss = 0.13506
I0901 05:07:09.722337 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.135065 (* 1 = 0.135065 loss)
I0901 05:07:09.722345 916722 sgd_solver.cpp:106] Iteration 4064000, lr = 0.01
I0901 05:07:39.452811 916722 solver.cpp:218] Iteration 4064500 (16.8178 iter/s, 29.7304s/500 iters), loss = 0.0940379
I0901 05:07:39.452857 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0940427 (* 1 = 0.0940427 loss)
I0901 05:07:39.452865 916722 sgd_solver.cpp:106] Iteration 4064500, lr = 0.01
I0901 05:08:09.182904 916722 solver.cpp:218] Iteration 4065000 (16.8181 iter/s, 29.7299s/500 iters), loss = 0.0989573
I0901 05:08:09.182960 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0989621 (* 1 = 0.0989621 loss)
I0901 05:08:09.182969 916722 sgd_solver.cpp:106] Iteration 4065000, lr = 0.01
I0901 05:08:38.913412 916722 solver.cpp:218] Iteration 4065500 (16.8178 iter/s, 29.7303s/500 iters), loss = 0.269884
I0901 05:08:38.913465 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.269889 (* 1 = 0.269889 loss)
I0901 05:08:38.913473 916722 sgd_solver.cpp:106] Iteration 4065500, lr = 0.01
I0901 05:09:08.643100 916722 solver.cpp:218] Iteration 4066000 (16.8183 iter/s, 29.7295s/500 iters), loss = 0.172563
I0901 05:09:08.643157 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.172567 (* 1 = 0.172567 loss)
I0901 05:09:08.643167 916722 sgd_solver.cpp:106] Iteration 4066000, lr = 0.01
I0901 05:09:38.373227 916722 solver.cpp:218] Iteration 4066500 (16.8181 iter/s, 29.7299s/500 iters), loss = 0.20988
I0901 05:09:38.373279 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.209885 (* 1 = 0.209885 loss)
I0901 05:09:38.373288 916722 sgd_solver.cpp:106] Iteration 4066500, lr = 0.01
I0901 05:10:08.104346 916722 solver.cpp:218] Iteration 4067000 (16.8175 iter/s, 29.7309s/500 iters), loss = 0.205131
I0901 05:10:08.104411 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.205136 (* 1 = 0.205136 loss)
I0901 05:10:08.104430 916722 sgd_solver.cpp:106] Iteration 4067000, lr = 0.01
I0901 05:10:37.838340 916722 solver.cpp:218] Iteration 4067500 (16.8159 iter/s, 29.7338s/500 iters), loss = 0.191363
I0901 05:10:37.838392 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.191367 (* 1 = 0.191367 loss)
I0901 05:10:37.838403 916722 sgd_solver.cpp:106] Iteration 4067500, lr = 0.01
I0901 05:11:07.567484 916722 solver.cpp:218] Iteration 4068000 (16.8186 iter/s, 29.729s/500 iters), loss = 0.178227
I0901 05:11:07.567536 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.178231 (* 1 = 0.178231 loss)
I0901 05:11:07.567544 916722 sgd_solver.cpp:106] Iteration 4068000, lr = 0.01
I0901 05:11:37.300959 916722 solver.cpp:218] Iteration 4068500 (16.8162 iter/s, 29.7333s/500 iters), loss = 0.0714533
I0901 05:11:37.301010 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0714575 (* 1 = 0.0714575 loss)
I0901 05:11:37.301020 916722 sgd_solver.cpp:106] Iteration 4068500, lr = 0.01
I0901 05:12:07.032342 916722 solver.cpp:218] Iteration 4069000 (16.8173 iter/s, 29.7312s/500 iters), loss = 0.064625
I0901 05:12:07.032397 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0646291 (* 1 = 0.0646291 loss)
I0901 05:12:07.032407 916722 sgd_solver.cpp:106] Iteration 4069000, lr = 0.01
I0901 05:12:36.765332 916722 solver.cpp:218] Iteration 4069500 (16.8164 iter/s, 29.7328s/500 iters), loss = 0.13233
I0901 05:12:36.765385 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.132334 (* 1 = 0.132334 loss)
I0901 05:12:36.765396 916722 sgd_solver.cpp:106] Iteration 4069500, lr = 0.01
I0901 05:13:06.494612 916722 solver.cpp:218] Iteration 4070000 (16.8185 iter/s, 29.7291s/500 iters), loss = 0.089378
I0901 05:13:06.494669 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0893822 (* 1 = 0.0893822 loss)
I0901 05:13:06.494678 916722 sgd_solver.cpp:106] Iteration 4070000, lr = 0.01
I0901 05:13:36.226624 916722 solver.cpp:218] Iteration 4070500 (16.817 iter/s, 29.7318s/500 iters), loss = 0.338863
I0901 05:13:36.226675 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.338867 (* 1 = 0.338867 loss)
I0901 05:13:36.226686 916722 sgd_solver.cpp:106] Iteration 4070500, lr = 0.01
I0901 05:14:05.957537 916722 solver.cpp:218] Iteration 4071000 (16.8176 iter/s, 29.7307s/500 iters), loss = 0.288604
I0901 05:14:05.957592 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.288608 (* 1 = 0.288608 loss)
I0901 05:14:05.957602 916722 sgd_solver.cpp:106] Iteration 4071000, lr = 0.01
I0901 05:14:35.687597 916722 solver.cpp:218] Iteration 4071500 (16.8181 iter/s, 29.7299s/500 iters), loss = 0.0486081
I0901 05:14:35.687649 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0486123 (* 1 = 0.0486123 loss)
I0901 05:14:35.687659 916722 sgd_solver.cpp:106] Iteration 4071500, lr = 0.01
I0901 05:15:05.417141 916722 solver.cpp:218] Iteration 4072000 (16.8184 iter/s, 29.7294s/500 iters), loss = 0.0919977
I0901 05:15:05.417196 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.092002 (* 1 = 0.092002 loss)
I0901 05:15:05.417205 916722 sgd_solver.cpp:106] Iteration 4072000, lr = 0.01
I0901 05:15:35.149310 916722 solver.cpp:218] Iteration 4072500 (16.8169 iter/s, 29.732s/500 iters), loss = 0.0800266
I0901 05:15:35.149360 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0800311 (* 1 = 0.0800311 loss)
I0901 05:15:35.149371 916722 sgd_solver.cpp:106] Iteration 4072500, lr = 0.01
I0901 05:16:04.882725 916722 solver.cpp:218] Iteration 4073000 (16.8162 iter/s, 29.7332s/500 iters), loss = 0.102164
I0901 05:16:04.882784 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.102168 (* 1 = 0.102168 loss)
I0901 05:16:04.882793 916722 sgd_solver.cpp:106] Iteration 4073000, lr = 0.01
I0901 05:16:34.615830 916722 solver.cpp:218] Iteration 4073500 (16.8164 iter/s, 29.7329s/500 iters), loss = 0.0376806
I0901 05:16:34.615880 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.037685 (* 1 = 0.037685 loss)
I0901 05:16:34.615888 916722 sgd_solver.cpp:106] Iteration 4073500, lr = 0.01
I0901 05:17:04.347759 916722 solver.cpp:218] Iteration 4074000 (16.817 iter/s, 29.7318s/500 iters), loss = 0.133715
I0901 05:17:04.347824 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133719 (* 1 = 0.133719 loss)
I0901 05:17:04.347833 916722 sgd_solver.cpp:106] Iteration 4074000, lr = 0.01
I0901 05:17:34.079008 916722 solver.cpp:218] Iteration 4074500 (16.8174 iter/s, 29.7311s/500 iters), loss = 0.267179
I0901 05:17:34.079061 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.267183 (* 1 = 0.267183 loss)
I0901 05:17:34.079069 916722 sgd_solver.cpp:106] Iteration 4074500, lr = 0.01
I0901 05:18:03.813679 916722 solver.cpp:218] Iteration 4075000 (16.8155 iter/s, 29.7345s/500 iters), loss = 0.14805
I0901 05:18:03.813735 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.148055 (* 1 = 0.148055 loss)
I0901 05:18:03.813742 916722 sgd_solver.cpp:106] Iteration 4075000, lr = 0.01
I0901 05:18:33.542961 916722 solver.cpp:218] Iteration 4075500 (16.8185 iter/s, 29.7291s/500 iters), loss = 0.0363584
I0901 05:18:33.543015 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0363625 (* 1 = 0.0363625 loss)
I0901 05:18:33.543023 916722 sgd_solver.cpp:106] Iteration 4075500, lr = 0.01
I0901 05:19:03.274410 916722 solver.cpp:218] Iteration 4076000 (16.8173 iter/s, 29.7313s/500 iters), loss = 0.034878
I0901 05:19:03.274466 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0348822 (* 1 = 0.0348822 loss)
I0901 05:19:03.274473 916722 sgd_solver.cpp:106] Iteration 4076000, lr = 0.01
I0901 05:19:33.006078 916722 solver.cpp:218] Iteration 4076500 (16.8172 iter/s, 29.7315s/500 iters), loss = 0.0683079
I0901 05:19:33.006129 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.068312 (* 1 = 0.068312 loss)
I0901 05:19:33.006139 916722 sgd_solver.cpp:106] Iteration 4076500, lr = 0.01
I0901 05:20:02.740042 916722 solver.cpp:218] Iteration 4077000 (16.8159 iter/s, 29.7338s/500 iters), loss = 0.16908
I0901 05:20:02.740097 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.169084 (* 1 = 0.169084 loss)
I0901 05:20:02.740106 916722 sgd_solver.cpp:106] Iteration 4077000, lr = 0.01
I0901 05:20:32.471807 916722 solver.cpp:218] Iteration 4077500 (16.8171 iter/s, 29.7316s/500 iters), loss = 0.132548
I0901 05:20:32.471855 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.132553 (* 1 = 0.132553 loss)
I0901 05:20:32.471864 916722 sgd_solver.cpp:106] Iteration 4077500, lr = 0.01
I0901 05:21:02.206476 916722 solver.cpp:218] Iteration 4078000 (16.8155 iter/s, 29.7345s/500 iters), loss = 0.064928
I0901 05:21:02.206533 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0649322 (* 1 = 0.0649322 loss)
I0901 05:21:02.206542 916722 sgd_solver.cpp:106] Iteration 4078000, lr = 0.01
I0901 05:21:31.941013 916722 solver.cpp:218] Iteration 4078500 (16.8156 iter/s, 29.7343s/500 iters), loss = 0.167556
I0901 05:21:31.941068 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.167561 (* 1 = 0.167561 loss)
I0901 05:21:31.941078 916722 sgd_solver.cpp:106] Iteration 4078500, lr = 0.01
I0901 05:22:01.671525 916722 solver.cpp:218] Iteration 4079000 (16.8178 iter/s, 29.7303s/500 iters), loss = 0.268407
I0901 05:22:01.671579 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.268412 (* 1 = 0.268412 loss)
I0901 05:22:01.671588 916722 sgd_solver.cpp:106] Iteration 4079000, lr = 0.01
I0901 05:22:31.402659 916722 solver.cpp:218] Iteration 4079500 (16.8175 iter/s, 29.731s/500 iters), loss = 0.0607745
I0901 05:22:31.402710 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0607787 (* 1 = 0.0607787 loss)
I0901 05:22:31.402720 916722 sgd_solver.cpp:106] Iteration 4079500, lr = 0.01
I0901 05:23:01.133335 916722 solver.cpp:218] Iteration 4080000 (16.8177 iter/s, 29.7305s/500 iters), loss = 0.293567
I0901 05:23:01.133390 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.293571 (* 1 = 0.293571 loss)
I0901 05:23:01.133399 916722 sgd_solver.cpp:106] Iteration 4080000, lr = 0.01
I0901 05:23:30.864014 916722 solver.cpp:218] Iteration 4080500 (16.8177 iter/s, 29.7305s/500 iters), loss = 0.0235904
I0901 05:23:30.864065 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0235946 (* 1 = 0.0235946 loss)
I0901 05:23:30.864075 916722 sgd_solver.cpp:106] Iteration 4080500, lr = 0.01
I0901 05:24:00.596336 916722 solver.cpp:218] Iteration 4081000 (16.8168 iter/s, 29.7321s/500 iters), loss = 0.291172
I0901 05:24:00.596398 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.291176 (* 1 = 0.291176 loss)
I0901 05:24:00.596407 916722 sgd_solver.cpp:106] Iteration 4081000, lr = 0.01
I0901 05:24:30.324141 916722 solver.cpp:218] Iteration 4081500 (16.8194 iter/s, 29.7276s/500 iters), loss = 0.135578
I0901 05:24:30.324187 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.135582 (* 1 = 0.135582 loss)
I0901 05:24:30.324198 916722 sgd_solver.cpp:106] Iteration 4081500, lr = 0.01
I0901 05:25:00.055158 916722 solver.cpp:218] Iteration 4082000 (16.8176 iter/s, 29.7308s/500 iters), loss = 0.161925
I0901 05:25:00.055212 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.161929 (* 1 = 0.161929 loss)
I0901 05:25:00.055222 916722 sgd_solver.cpp:106] Iteration 4082000, lr = 0.01
I0901 05:25:29.785588 916722 solver.cpp:218] Iteration 4082500 (16.8179 iter/s, 29.7302s/500 iters), loss = 0.0163289
I0901 05:25:29.785635 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0163328 (* 1 = 0.0163328 loss)
I0901 05:25:29.785645 916722 sgd_solver.cpp:106] Iteration 4082500, lr = 0.01
I0901 05:25:59.518950 916722 solver.cpp:218] Iteration 4083000 (16.8162 iter/s, 29.7332s/500 iters), loss = 0.19353
I0901 05:25:59.519012 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.193534 (* 1 = 0.193534 loss)
I0901 05:25:59.519021 916722 sgd_solver.cpp:106] Iteration 4083000, lr = 0.01
I0901 05:26:29.251816 916722 solver.cpp:218] Iteration 4083500 (16.8165 iter/s, 29.7327s/500 iters), loss = 0.127941
I0901 05:26:29.251869 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.127945 (* 1 = 0.127945 loss)
I0901 05:26:29.251879 916722 sgd_solver.cpp:106] Iteration 4083500, lr = 0.01
I0901 05:26:58.985071 916722 solver.cpp:218] Iteration 4084000 (16.8163 iter/s, 29.7331s/500 iters), loss = 0.296675
I0901 05:26:58.985134 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.296679 (* 1 = 0.296679 loss)
I0901 05:26:58.985143 916722 sgd_solver.cpp:106] Iteration 4084000, lr = 0.01
I0901 05:27:28.718789 916722 solver.cpp:218] Iteration 4084500 (16.816 iter/s, 29.7335s/500 iters), loss = 0.11502
I0901 05:27:28.718842 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115024 (* 1 = 0.115024 loss)
I0901 05:27:28.718850 916722 sgd_solver.cpp:106] Iteration 4084500, lr = 0.01
I0901 05:27:58.448335 916722 solver.cpp:218] Iteration 4085000 (16.8184 iter/s, 29.7294s/500 iters), loss = 0.134721
I0901 05:27:58.448392 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.134725 (* 1 = 0.134725 loss)
I0901 05:27:58.448401 916722 sgd_solver.cpp:106] Iteration 4085000, lr = 0.01
I0901 05:28:28.176919 916722 solver.cpp:218] Iteration 4085500 (16.8189 iter/s, 29.7284s/500 iters), loss = 0.180364
I0901 05:28:28.176970 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.180368 (* 1 = 0.180368 loss)
I0901 05:28:28.176980 916722 sgd_solver.cpp:106] Iteration 4085500, lr = 0.01
I0901 05:28:57.904670 916722 solver.cpp:218] Iteration 4086000 (16.8194 iter/s, 29.7276s/500 iters), loss = 0.063516
I0901 05:28:57.904728 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0635204 (* 1 = 0.0635204 loss)
I0901 05:28:57.904748 916722 sgd_solver.cpp:106] Iteration 4086000, lr = 0.01
I0901 05:29:27.635583 916722 solver.cpp:218] Iteration 4086500 (16.8176 iter/s, 29.7307s/500 iters), loss = 0.0529605
I0901 05:29:27.635632 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0529649 (* 1 = 0.0529649 loss)
I0901 05:29:27.635640 916722 sgd_solver.cpp:106] Iteration 4086500, lr = 0.01
I0901 05:29:57.364053 916722 solver.cpp:218] Iteration 4087000 (16.819 iter/s, 29.7283s/500 iters), loss = 0.06722
I0901 05:29:57.364120 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0672245 (* 1 = 0.0672245 loss)
I0901 05:29:57.364128 916722 sgd_solver.cpp:106] Iteration 4087000, lr = 0.01
I0901 05:30:27.094990 916722 solver.cpp:218] Iteration 4087500 (16.8176 iter/s, 29.7307s/500 iters), loss = 0.0578584
I0901 05:30:27.095038 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0578627 (* 1 = 0.0578627 loss)
I0901 05:30:27.095047 916722 sgd_solver.cpp:106] Iteration 4087500, lr = 0.01
I0901 05:30:56.826452 916722 solver.cpp:218] Iteration 4088000 (16.8173 iter/s, 29.7313s/500 iters), loss = 0.120868
I0901 05:30:56.826516 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.120873 (* 1 = 0.120873 loss)
I0901 05:30:56.826524 916722 sgd_solver.cpp:106] Iteration 4088000, lr = 0.01
I0901 05:31:26.558215 916722 solver.cpp:218] Iteration 4088500 (16.8171 iter/s, 29.7316s/500 iters), loss = 0.0367662
I0901 05:31:26.558267 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0367706 (* 1 = 0.0367706 loss)
I0901 05:31:26.558276 916722 sgd_solver.cpp:106] Iteration 4088500, lr = 0.01
I0901 05:31:56.288656 916722 solver.cpp:218] Iteration 4089000 (16.8179 iter/s, 29.7303s/500 iters), loss = 0.131907
I0901 05:31:56.288717 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131912 (* 1 = 0.131912 loss)
I0901 05:31:56.288727 916722 sgd_solver.cpp:106] Iteration 4089000, lr = 0.01
I0901 05:32:26.019256 916722 solver.cpp:218] Iteration 4089500 (16.8178 iter/s, 29.7304s/500 iters), loss = 0.0508895
I0901 05:32:26.019312 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0508938 (* 1 = 0.0508938 loss)
I0901 05:32:26.019323 916722 sgd_solver.cpp:106] Iteration 4089500, lr = 0.01
I0901 05:32:55.753082 916722 solver.cpp:218] Iteration 4090000 (16.816 iter/s, 29.7336s/500 iters), loss = 0.0652834
I0901 05:32:55.753136 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0652877 (* 1 = 0.0652877 loss)
I0901 05:32:55.753144 916722 sgd_solver.cpp:106] Iteration 4090000, lr = 0.01
I0901 05:33:25.480543 916722 solver.cpp:218] Iteration 4090500 (16.8196 iter/s, 29.7273s/500 iters), loss = 0.122497
I0901 05:33:25.480593 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.122501 (* 1 = 0.122501 loss)
I0901 05:33:25.480602 916722 sgd_solver.cpp:106] Iteration 4090500, lr = 0.01
I0901 05:33:55.213021 916722 solver.cpp:218] Iteration 4091000 (16.8167 iter/s, 29.7323s/500 iters), loss = 0.0901405
I0901 05:33:55.213078 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0901448 (* 1 = 0.0901448 loss)
I0901 05:33:55.213086 916722 sgd_solver.cpp:106] Iteration 4091000, lr = 0.01
I0901 05:34:24.940198 916722 solver.cpp:218] Iteration 4091500 (16.8197 iter/s, 29.727s/500 iters), loss = 0.0498757
I0901 05:34:24.940248 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.04988 (* 1 = 0.04988 loss)
I0901 05:34:24.940256 916722 sgd_solver.cpp:106] Iteration 4091500, lr = 0.01
I0901 05:34:54.671480 916722 solver.cpp:218] Iteration 4092000 (16.8174 iter/s, 29.7311s/500 iters), loss = 0.03334
I0901 05:34:54.671541 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0333443 (* 1 = 0.0333443 loss)
I0901 05:34:54.671550 916722 sgd_solver.cpp:106] Iteration 4092000, lr = 0.01
I0901 05:35:24.398777 916722 solver.cpp:218] Iteration 4092500 (16.8197 iter/s, 29.7271s/500 iters), loss = 0.327852
I0901 05:35:24.398829 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.327856 (* 1 = 0.327856 loss)
I0901 05:35:24.398838 916722 sgd_solver.cpp:106] Iteration 4092500, lr = 0.01
I0901 05:35:54.130666 916722 solver.cpp:218] Iteration 4093000 (16.8171 iter/s, 29.7317s/500 iters), loss = 0.046558
I0901 05:35:54.130726 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0465623 (* 1 = 0.0465623 loss)
I0901 05:35:54.130734 916722 sgd_solver.cpp:106] Iteration 4093000, lr = 0.01
I0901 05:36:23.861415 916722 solver.cpp:218] Iteration 4093500 (16.8177 iter/s, 29.7306s/500 iters), loss = 0.230821
I0901 05:36:23.861482 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.230826 (* 1 = 0.230826 loss)
I0901 05:36:23.861492 916722 sgd_solver.cpp:106] Iteration 4093500, lr = 0.01
I0901 05:36:53.591266 916722 solver.cpp:218] Iteration 4094000 (16.8182 iter/s, 29.7296s/500 iters), loss = 0.376136
I0901 05:36:53.591337 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.376141 (* 1 = 0.376141 loss)
I0901 05:36:53.591346 916722 sgd_solver.cpp:106] Iteration 4094000, lr = 0.01
I0901 05:37:23.319427 916722 solver.cpp:218] Iteration 4094500 (16.8192 iter/s, 29.728s/500 iters), loss = 0.051109
I0901 05:37:23.319476 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0511134 (* 1 = 0.0511134 loss)
I0901 05:37:23.319486 916722 sgd_solver.cpp:106] Iteration 4094500, lr = 0.01
I0901 05:37:53.049088 916722 solver.cpp:218] Iteration 4095000 (16.8183 iter/s, 29.7295s/500 iters), loss = 0.0196748
I0901 05:37:53.049146 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0196792 (* 1 = 0.0196792 loss)
I0901 05:37:53.049154 916722 sgd_solver.cpp:106] Iteration 4095000, lr = 0.01
I0901 05:38:22.778501 916722 solver.cpp:218] Iteration 4095500 (16.8185 iter/s, 29.7292s/500 iters), loss = 0.0718058
I0901 05:38:22.778545 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0718102 (* 1 = 0.0718102 loss)
I0901 05:38:22.778553 916722 sgd_solver.cpp:106] Iteration 4095500, lr = 0.01
I0901 05:38:52.509428 916722 solver.cpp:218] Iteration 4096000 (16.8176 iter/s, 29.7307s/500 iters), loss = 0.0513149
I0901 05:38:52.509482 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0513191 (* 1 = 0.0513191 loss)
I0901 05:38:52.509490 916722 sgd_solver.cpp:106] Iteration 4096000, lr = 0.01
I0901 05:39:22.239712 916722 solver.cpp:218] Iteration 4096500 (16.818 iter/s, 29.7301s/500 iters), loss = 0.295888
I0901 05:39:22.239764 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.295892 (* 1 = 0.295892 loss)
I0901 05:39:22.239774 916722 sgd_solver.cpp:106] Iteration 4096500, lr = 0.01
I0901 05:39:51.970402 916722 solver.cpp:218] Iteration 4097000 (16.8177 iter/s, 29.7305s/500 iters), loss = 0.284058
I0901 05:39:51.970461 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.284062 (* 1 = 0.284062 loss)
I0901 05:39:51.970470 916722 sgd_solver.cpp:106] Iteration 4097000, lr = 0.01
I0901 05:40:21.699658 916722 solver.cpp:218] Iteration 4097500 (16.8186 iter/s, 29.7291s/500 iters), loss = 0.0692439
I0901 05:40:21.699710 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.069248 (* 1 = 0.069248 loss)
I0901 05:40:21.699720 916722 sgd_solver.cpp:106] Iteration 4097500, lr = 0.01
I0901 05:40:51.428865 916722 solver.cpp:218] Iteration 4098000 (16.8186 iter/s, 29.729s/500 iters), loss = 0.508649
I0901 05:40:51.428923 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.508653 (* 1 = 0.508653 loss)
I0901 05:40:51.428931 916722 sgd_solver.cpp:106] Iteration 4098000, lr = 0.01
I0901 05:41:21.157702 916722 solver.cpp:218] Iteration 4098500 (16.8188 iter/s, 29.7286s/500 iters), loss = 0.0705591
I0901 05:41:21.157753 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0705634 (* 1 = 0.0705634 loss)
I0901 05:41:21.157763 916722 sgd_solver.cpp:106] Iteration 4098500, lr = 0.01
I0901 05:41:50.889394 916722 solver.cpp:218] Iteration 4099000 (16.8172 iter/s, 29.7315s/500 iters), loss = 0.215525
I0901 05:41:50.889454 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.215529 (* 1 = 0.215529 loss)
I0901 05:41:50.889463 916722 sgd_solver.cpp:106] Iteration 4099000, lr = 0.01
I0901 05:42:20.618989 916722 solver.cpp:218] Iteration 4099500 (16.8184 iter/s, 29.7294s/500 iters), loss = 0.142275
I0901 05:42:20.619037 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.142279 (* 1 = 0.142279 loss)
I0901 05:42:20.619046 916722 sgd_solver.cpp:106] Iteration 4099500, lr = 0.01
I0901 05:42:50.290594 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_4100000.caffemodel
I0901 05:42:50.309887 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_4100000.solverstate
I0901 05:42:50.315901 916722 solver.cpp:330] Iteration 4100000, Testing net (#0)
I0901 05:43:05.722961 916722 solver.cpp:397]     Test net output #0: accuracy = 0.867
I0901 05:43:05.723011 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.429891 (* 1 = 0.429891 loss)
I0901 05:43:05.781669 916722 solver.cpp:218] Iteration 4100000 (11.0711 iter/s, 45.1624s/500 iters), loss = 0.167348
I0901 05:43:05.781700 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.167352 (* 1 = 0.167352 loss)
I0901 05:43:05.781709 916722 sgd_solver.cpp:106] Iteration 4100000, lr = 0.01
I0901 05:43:35.358759 916722 solver.cpp:218] Iteration 4100500 (16.9051 iter/s, 29.5769s/500 iters), loss = 0.0337372
I0901 05:43:35.358819 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0337415 (* 1 = 0.0337415 loss)
I0901 05:43:35.358826 916722 sgd_solver.cpp:106] Iteration 4100500, lr = 0.01
I0901 05:44:04.960894 916722 solver.cpp:218] Iteration 4101000 (16.8908 iter/s, 29.6019s/500 iters), loss = 0.0169425
I0901 05:44:04.960942 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0169467 (* 1 = 0.0169467 loss)
I0901 05:44:04.960950 916722 sgd_solver.cpp:106] Iteration 4101000, lr = 0.01
I0901 05:44:34.640756 916722 solver.cpp:218] Iteration 4101500 (16.8465 iter/s, 29.6797s/500 iters), loss = 0.129258
I0901 05:44:34.640813 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.129262 (* 1 = 0.129262 loss)
I0901 05:44:34.640821 916722 sgd_solver.cpp:106] Iteration 4101500, lr = 0.01
I0901 05:45:04.321805 916722 solver.cpp:218] Iteration 4102000 (16.8459 iter/s, 29.6809s/500 iters), loss = 0.161255
I0901 05:45:04.321853 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.16126 (* 1 = 0.16126 loss)
I0901 05:45:04.321862 916722 sgd_solver.cpp:106] Iteration 4102000, lr = 0.01
I0901 05:45:34.009667 916722 solver.cpp:218] Iteration 4102500 (16.842 iter/s, 29.6877s/500 iters), loss = 0.0445037
I0901 05:45:34.009727 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0445081 (* 1 = 0.0445081 loss)
I0901 05:45:34.009735 916722 sgd_solver.cpp:106] Iteration 4102500, lr = 0.01
I0901 05:46:03.689841 916722 solver.cpp:218] Iteration 4103000 (16.8464 iter/s, 29.68s/500 iters), loss = 0.165022
I0901 05:46:03.689894 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.165026 (* 1 = 0.165026 loss)
I0901 05:46:03.689904 916722 sgd_solver.cpp:106] Iteration 4103000, lr = 0.01
I0901 05:46:33.373456 916722 solver.cpp:218] Iteration 4103500 (16.8444 iter/s, 29.6834s/500 iters), loss = 0.0800167
I0901 05:46:33.373515 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0800211 (* 1 = 0.0800211 loss)
I0901 05:46:33.373523 916722 sgd_solver.cpp:106] Iteration 4103500, lr = 0.01
I0901 05:47:03.058756 916722 solver.cpp:218] Iteration 4104000 (16.8435 iter/s, 29.6851s/500 iters), loss = 0.22843
I0901 05:47:03.058805 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.228435 (* 1 = 0.228435 loss)
I0901 05:47:03.058815 916722 sgd_solver.cpp:106] Iteration 4104000, lr = 0.01
I0901 05:47:32.740823 916722 solver.cpp:218] Iteration 4104500 (16.8453 iter/s, 29.6819s/500 iters), loss = 0.0808494
I0901 05:47:32.740881 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0808539 (* 1 = 0.0808539 loss)
I0901 05:47:32.740890 916722 sgd_solver.cpp:106] Iteration 4104500, lr = 0.01
I0901 05:48:02.423405 916722 solver.cpp:218] Iteration 4105000 (16.845 iter/s, 29.6824s/500 iters), loss = 0.131515
I0901 05:48:02.423453 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131519 (* 1 = 0.131519 loss)
I0901 05:48:02.423465 916722 sgd_solver.cpp:106] Iteration 4105000, lr = 0.01
I0901 05:48:32.105341 916722 solver.cpp:218] Iteration 4105500 (16.8454 iter/s, 29.6818s/500 iters), loss = 0.0492307
I0901 05:48:32.105410 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0492351 (* 1 = 0.0492351 loss)
I0901 05:48:32.105424 916722 sgd_solver.cpp:106] Iteration 4105500, lr = 0.01
I0901 05:49:01.786337 916722 solver.cpp:218] Iteration 4106000 (16.8459 iter/s, 29.6808s/500 iters), loss = 0.216759
I0901 05:49:01.786384 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.216763 (* 1 = 0.216763 loss)
I0901 05:49:01.786394 916722 sgd_solver.cpp:106] Iteration 4106000, lr = 0.01
I0901 05:49:31.467289 916722 solver.cpp:218] Iteration 4106500 (16.8459 iter/s, 29.6808s/500 iters), loss = 0.107393
I0901 05:49:31.467344 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.107397 (* 1 = 0.107397 loss)
I0901 05:49:31.467352 916722 sgd_solver.cpp:106] Iteration 4106500, lr = 0.01
I0901 05:50:01.148239 916722 solver.cpp:218] Iteration 4107000 (16.8459 iter/s, 29.6808s/500 iters), loss = 0.138232
I0901 05:50:01.148290 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.138236 (* 1 = 0.138236 loss)
I0901 05:50:01.148300 916722 sgd_solver.cpp:106] Iteration 4107000, lr = 0.01
I0901 05:50:30.828886 916722 solver.cpp:218] Iteration 4107500 (16.8461 iter/s, 29.6805s/500 iters), loss = 0.120436
I0901 05:50:30.828944 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.12044 (* 1 = 0.12044 loss)
I0901 05:50:30.828953 916722 sgd_solver.cpp:106] Iteration 4107500, lr = 0.01
I0901 05:51:00.508908 916722 solver.cpp:218] Iteration 4108000 (16.8465 iter/s, 29.6798s/500 iters), loss = 0.173488
I0901 05:51:00.508962 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.173493 (* 1 = 0.173493 loss)
I0901 05:51:00.508972 916722 sgd_solver.cpp:106] Iteration 4108000, lr = 0.01
I0901 05:51:30.190992 916722 solver.cpp:218] Iteration 4108500 (16.8453 iter/s, 29.6819s/500 iters), loss = 0.175987
I0901 05:51:30.191054 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.175992 (* 1 = 0.175992 loss)
I0901 05:51:30.191063 916722 sgd_solver.cpp:106] Iteration 4108500, lr = 0.01
I0901 05:51:59.880591 916722 solver.cpp:218] Iteration 4109000 (16.841 iter/s, 29.6894s/500 iters), loss = 0.318686
I0901 05:51:59.880641 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.31869 (* 1 = 0.31869 loss)
I0901 05:51:59.880650 916722 sgd_solver.cpp:106] Iteration 4109000, lr = 0.01
I0901 05:52:29.563652 916722 solver.cpp:218] Iteration 4109500 (16.8447 iter/s, 29.6829s/500 iters), loss = 0.122334
I0901 05:52:29.563715 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.122338 (* 1 = 0.122338 loss)
I0901 05:52:29.563724 916722 sgd_solver.cpp:106] Iteration 4109500, lr = 0.01
I0901 05:52:59.240748 916722 solver.cpp:218] Iteration 4110000 (16.8481 iter/s, 29.6769s/500 iters), loss = 0.117069
I0901 05:52:59.240804 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.117073 (* 1 = 0.117073 loss)
I0901 05:52:59.240813 916722 sgd_solver.cpp:106] Iteration 4110000, lr = 0.01
I0901 05:53:28.919392 916722 solver.cpp:218] Iteration 4110500 (16.8472 iter/s, 29.6785s/500 iters), loss = 0.0730726
I0901 05:53:28.919447 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0730769 (* 1 = 0.0730769 loss)
I0901 05:53:28.919456 916722 sgd_solver.cpp:106] Iteration 4110500, lr = 0.01
I0901 05:53:58.599105 916722 solver.cpp:218] Iteration 4111000 (16.8466 iter/s, 29.6795s/500 iters), loss = 0.138483
I0901 05:53:58.599154 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.138487 (* 1 = 0.138487 loss)
I0901 05:53:58.599164 916722 sgd_solver.cpp:106] Iteration 4111000, lr = 0.01
I0901 05:54:28.284049 916722 solver.cpp:218] Iteration 4111500 (16.8437 iter/s, 29.6848s/500 iters), loss = 0.138939
I0901 05:54:28.284109 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.138943 (* 1 = 0.138943 loss)
I0901 05:54:28.284117 916722 sgd_solver.cpp:106] Iteration 4111500, lr = 0.01
I0901 05:54:57.962915 916722 solver.cpp:218] Iteration 4112000 (16.8471 iter/s, 29.6787s/500 iters), loss = 0.092827
I0901 05:54:57.962967 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0928313 (* 1 = 0.0928313 loss)
I0901 05:54:57.962976 916722 sgd_solver.cpp:106] Iteration 4112000, lr = 0.01
I0901 05:55:27.640605 916722 solver.cpp:218] Iteration 4112500 (16.8478 iter/s, 29.6775s/500 iters), loss = 0.14097
I0901 05:55:27.640672 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.140974 (* 1 = 0.140974 loss)
I0901 05:55:27.640681 916722 sgd_solver.cpp:106] Iteration 4112500, lr = 0.01
I0901 05:55:57.319392 916722 solver.cpp:218] Iteration 4113000 (16.8472 iter/s, 29.6786s/500 iters), loss = 0.0737659
I0901 05:55:57.319440 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0737702 (* 1 = 0.0737702 loss)
I0901 05:55:57.319449 916722 sgd_solver.cpp:106] Iteration 4113000, lr = 0.01
I0901 05:56:26.998832 916722 solver.cpp:218] Iteration 4113500 (16.8468 iter/s, 29.6793s/500 iters), loss = 0.140139
I0901 05:56:26.998888 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.140143 (* 1 = 0.140143 loss)
I0901 05:56:26.998896 916722 sgd_solver.cpp:106] Iteration 4113500, lr = 0.01
I0901 05:56:56.674500 916722 solver.cpp:218] Iteration 4114000 (16.8489 iter/s, 29.6755s/500 iters), loss = 0.240655
I0901 05:56:56.674554 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.24066 (* 1 = 0.24066 loss)
I0901 05:56:56.674563 916722 sgd_solver.cpp:106] Iteration 4114000, lr = 0.01
I0901 05:57:26.354918 916722 solver.cpp:218] Iteration 4114500 (16.8462 iter/s, 29.6802s/500 iters), loss = 0.238264
I0901 05:57:26.354977 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.238269 (* 1 = 0.238269 loss)
I0901 05:57:26.354986 916722 sgd_solver.cpp:106] Iteration 4114500, lr = 0.01
I0901 05:57:56.032809 916722 solver.cpp:218] Iteration 4115000 (16.8477 iter/s, 29.6777s/500 iters), loss = 0.17896
I0901 05:57:56.032864 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.178964 (* 1 = 0.178964 loss)
I0901 05:57:56.032876 916722 sgd_solver.cpp:106] Iteration 4115000, lr = 0.01
I0901 05:58:25.711724 916722 solver.cpp:218] Iteration 4115500 (16.8471 iter/s, 29.6787s/500 iters), loss = 0.0991217
I0901 05:58:25.711781 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0991265 (* 1 = 0.0991265 loss)
I0901 05:58:25.711788 916722 sgd_solver.cpp:106] Iteration 4115500, lr = 0.01
I0901 05:58:55.388832 916722 solver.cpp:218] Iteration 4116000 (16.8482 iter/s, 29.6768s/500 iters), loss = 0.205886
I0901 05:58:55.388883 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.20589 (* 1 = 0.20589 loss)
I0901 05:58:55.388893 916722 sgd_solver.cpp:106] Iteration 4116000, lr = 0.01
I0901 05:59:25.067442 916722 solver.cpp:218] Iteration 4116500 (16.8474 iter/s, 29.6782s/500 iters), loss = 0.151087
I0901 05:59:25.067497 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.151092 (* 1 = 0.151092 loss)
I0901 05:59:25.067507 916722 sgd_solver.cpp:106] Iteration 4116500, lr = 0.01
I0901 05:59:54.745869 916722 solver.cpp:218] Iteration 4117000 (16.8475 iter/s, 29.6781s/500 iters), loss = 0.342101
I0901 05:59:54.745918 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.342105 (* 1 = 0.342105 loss)
I0901 05:59:54.745929 916722 sgd_solver.cpp:106] Iteration 4117000, lr = 0.01
I0901 06:00:24.424242 916722 solver.cpp:218] Iteration 4117500 (16.8475 iter/s, 29.678s/500 iters), loss = 0.012622
I0901 06:00:24.424296 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0126267 (* 1 = 0.0126267 loss)
I0901 06:00:24.424304 916722 sgd_solver.cpp:106] Iteration 4117500, lr = 0.01
I0901 06:00:54.113178 916722 solver.cpp:218] Iteration 4118000 (16.8415 iter/s, 29.6886s/500 iters), loss = 0.20904
I0901 06:00:54.113231 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.209044 (* 1 = 0.209044 loss)
I0901 06:00:54.113241 916722 sgd_solver.cpp:106] Iteration 4118000, lr = 0.01
I0901 06:01:23.798426 916722 solver.cpp:218] Iteration 4118500 (16.8436 iter/s, 29.6849s/500 iters), loss = 0.107852
I0901 06:01:23.798486 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.107857 (* 1 = 0.107857 loss)
I0901 06:01:23.798496 916722 sgd_solver.cpp:106] Iteration 4118500, lr = 0.01
I0901 06:01:53.481868 916722 solver.cpp:218] Iteration 4119000 (16.8446 iter/s, 29.6831s/500 iters), loss = 0.13561
I0901 06:01:53.481935 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.135615 (* 1 = 0.135615 loss)
I0901 06:01:53.481945 916722 sgd_solver.cpp:106] Iteration 4119000, lr = 0.01
I0901 06:02:23.163112 916722 solver.cpp:218] Iteration 4119500 (16.8459 iter/s, 29.6809s/500 iters), loss = 0.0535762
I0901 06:02:23.163184 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.053581 (* 1 = 0.053581 loss)
I0901 06:02:23.163193 916722 sgd_solver.cpp:106] Iteration 4119500, lr = 0.01
I0901 06:02:52.842365 916722 solver.cpp:218] Iteration 4120000 (16.847 iter/s, 29.6789s/500 iters), loss = 0.218704
I0901 06:02:52.842417 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.218709 (* 1 = 0.218709 loss)
I0901 06:02:52.842425 916722 sgd_solver.cpp:106] Iteration 4120000, lr = 0.01
I0901 06:03:22.521203 916722 solver.cpp:218] Iteration 4120500 (16.8472 iter/s, 29.6785s/500 iters), loss = 0.0854878
I0901 06:03:22.521262 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0854925 (* 1 = 0.0854925 loss)
I0901 06:03:22.521271 916722 sgd_solver.cpp:106] Iteration 4120500, lr = 0.01
I0901 06:03:52.202039 916722 solver.cpp:218] Iteration 4121000 (16.8461 iter/s, 29.6805s/500 iters), loss = 0.107106
I0901 06:03:52.202088 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.107111 (* 1 = 0.107111 loss)
I0901 06:03:52.202097 916722 sgd_solver.cpp:106] Iteration 4121000, lr = 0.01
I0901 06:04:21.883495 916722 solver.cpp:218] Iteration 4121500 (16.8457 iter/s, 29.6812s/500 iters), loss = 0.159817
I0901 06:04:21.883549 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159822 (* 1 = 0.159822 loss)
I0901 06:04:21.883558 916722 sgd_solver.cpp:106] Iteration 4121500, lr = 0.01
I0901 06:04:51.564065 916722 solver.cpp:218] Iteration 4122000 (16.8462 iter/s, 29.6803s/500 iters), loss = 0.110843
I0901 06:04:51.564113 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110848 (* 1 = 0.110848 loss)
I0901 06:04:51.564122 916722 sgd_solver.cpp:106] Iteration 4122000, lr = 0.01
I0901 06:05:21.242353 916722 solver.cpp:218] Iteration 4122500 (16.8475 iter/s, 29.678s/500 iters), loss = 0.133696
I0901 06:05:21.242411 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133701 (* 1 = 0.133701 loss)
I0901 06:05:21.242420 916722 sgd_solver.cpp:106] Iteration 4122500, lr = 0.01
I0901 06:05:50.924047 916722 solver.cpp:218] Iteration 4123000 (16.8456 iter/s, 29.6814s/500 iters), loss = 0.0733
I0901 06:05:50.924100 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0733048 (* 1 = 0.0733048 loss)
I0901 06:05:50.924109 916722 sgd_solver.cpp:106] Iteration 4123000, lr = 0.01
I0901 06:06:20.605273 916722 solver.cpp:218] Iteration 4123500 (16.8458 iter/s, 29.6809s/500 iters), loss = 0.184393
I0901 06:06:20.605329 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.184397 (* 1 = 0.184397 loss)
I0901 06:06:20.605337 916722 sgd_solver.cpp:106] Iteration 4123500, lr = 0.01
I0901 06:06:50.284924 916722 solver.cpp:218] Iteration 4124000 (16.8467 iter/s, 29.6794s/500 iters), loss = 0.327269
I0901 06:06:50.284976 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.327274 (* 1 = 0.327274 loss)
I0901 06:06:50.284984 916722 sgd_solver.cpp:106] Iteration 4124000, lr = 0.01
I0901 06:07:19.965965 916722 solver.cpp:218] Iteration 4124500 (16.8459 iter/s, 29.6808s/500 iters), loss = 0.115723
I0901 06:07:19.966022 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115728 (* 1 = 0.115728 loss)
I0901 06:07:19.966032 916722 sgd_solver.cpp:106] Iteration 4124500, lr = 0.01
I0901 06:07:49.646883 916722 solver.cpp:218] Iteration 4125000 (16.846 iter/s, 29.6806s/500 iters), loss = 0.0588621
I0901 06:07:49.646935 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0588666 (* 1 = 0.0588666 loss)
I0901 06:07:49.646945 916722 sgd_solver.cpp:106] Iteration 4125000, lr = 0.01
I0901 06:08:19.325702 916722 solver.cpp:218] Iteration 4125500 (16.8472 iter/s, 29.6785s/500 iters), loss = 0.0319475
I0901 06:08:19.325771 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0319519 (* 1 = 0.0319519 loss)
I0901 06:08:19.325780 916722 sgd_solver.cpp:106] Iteration 4125500, lr = 0.01
I0901 06:08:49.009771 916722 solver.cpp:218] Iteration 4126000 (16.8442 iter/s, 29.6838s/500 iters), loss = 0.357773
I0901 06:08:49.009819 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.357777 (* 1 = 0.357777 loss)
I0901 06:08:49.009830 916722 sgd_solver.cpp:106] Iteration 4126000, lr = 0.01
I0901 06:09:18.693037 916722 solver.cpp:218] Iteration 4126500 (16.8447 iter/s, 29.683s/500 iters), loss = 0.0510108
I0901 06:09:18.693089 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0510151 (* 1 = 0.0510151 loss)
I0901 06:09:18.693097 916722 sgd_solver.cpp:106] Iteration 4126500, lr = 0.01
I0901 06:09:48.373308 916722 solver.cpp:218] Iteration 4127000 (16.8464 iter/s, 29.68s/500 iters), loss = 0.185104
I0901 06:09:48.373363 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.185108 (* 1 = 0.185108 loss)
I0901 06:09:48.373373 916722 sgd_solver.cpp:106] Iteration 4127000, lr = 0.01
I0901 06:10:18.056025 916722 solver.cpp:218] Iteration 4127500 (16.845 iter/s, 29.6825s/500 iters), loss = 0.0759579
I0901 06:10:18.056083 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0759625 (* 1 = 0.0759625 loss)
I0901 06:10:18.056092 916722 sgd_solver.cpp:106] Iteration 4127500, lr = 0.01
I0901 06:10:47.745672 916722 solver.cpp:218] Iteration 4128000 (16.841 iter/s, 29.6894s/500 iters), loss = 0.172463
I0901 06:10:47.745724 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.172467 (* 1 = 0.172467 loss)
I0901 06:10:47.745734 916722 sgd_solver.cpp:106] Iteration 4128000, lr = 0.01
I0901 06:11:17.436976 916722 solver.cpp:218] Iteration 4128500 (16.8401 iter/s, 29.691s/500 iters), loss = 0.0650683
I0901 06:11:17.437036 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0650729 (* 1 = 0.0650729 loss)
I0901 06:11:17.437044 916722 sgd_solver.cpp:106] Iteration 4128500, lr = 0.01
I0901 06:11:47.125537 916722 solver.cpp:218] Iteration 4129000 (16.8416 iter/s, 29.6883s/500 iters), loss = 0.191044
I0901 06:11:47.125586 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.191049 (* 1 = 0.191049 loss)
I0901 06:11:47.125594 916722 sgd_solver.cpp:106] Iteration 4129000, lr = 0.01
I0901 06:12:16.813061 916722 solver.cpp:218] Iteration 4129500 (16.8422 iter/s, 29.6873s/500 iters), loss = 0.209841
I0901 06:12:16.813117 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.209846 (* 1 = 0.209846 loss)
I0901 06:12:16.813127 916722 sgd_solver.cpp:106] Iteration 4129500, lr = 0.01
I0901 06:12:46.502305 916722 solver.cpp:218] Iteration 4130000 (16.8413 iter/s, 29.689s/500 iters), loss = 0.16529
I0901 06:12:46.502353 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.165295 (* 1 = 0.165295 loss)
I0901 06:12:46.502363 916722 sgd_solver.cpp:106] Iteration 4130000, lr = 0.01
I0901 06:13:16.195387 916722 solver.cpp:218] Iteration 4130500 (16.8391 iter/s, 29.6928s/500 iters), loss = 0.193245
I0901 06:13:16.195441 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.193249 (* 1 = 0.193249 loss)
I0901 06:13:16.195449 916722 sgd_solver.cpp:106] Iteration 4130500, lr = 0.01
I0901 06:13:45.889315 916722 solver.cpp:218] Iteration 4131000 (16.8386 iter/s, 29.6937s/500 iters), loss = 0.217539
I0901 06:13:45.889364 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.217544 (* 1 = 0.217544 loss)
I0901 06:13:45.889374 916722 sgd_solver.cpp:106] Iteration 4131000, lr = 0.01
I0901 06:14:15.577543 916722 solver.cpp:218] Iteration 4131500 (16.8418 iter/s, 29.688s/500 iters), loss = 0.0881045
I0901 06:14:15.577601 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0881091 (* 1 = 0.0881091 loss)
I0901 06:14:15.577610 916722 sgd_solver.cpp:106] Iteration 4131500, lr = 0.01
I0901 06:14:45.266258 916722 solver.cpp:218] Iteration 4132000 (16.8416 iter/s, 29.6885s/500 iters), loss = 0.149346
I0901 06:14:45.266324 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.149351 (* 1 = 0.149351 loss)
I0901 06:14:45.266335 916722 sgd_solver.cpp:106] Iteration 4132000, lr = 0.01
I0901 06:15:14.955242 916722 solver.cpp:218] Iteration 4132500 (16.8414 iter/s, 29.6887s/500 iters), loss = 0.163294
I0901 06:15:14.955312 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.163299 (* 1 = 0.163299 loss)
I0901 06:15:14.955319 916722 sgd_solver.cpp:106] Iteration 4132500, lr = 0.01
I0901 06:15:44.645807 916722 solver.cpp:218] Iteration 4133000 (16.8405 iter/s, 29.6903s/500 iters), loss = 0.123797
I0901 06:15:44.645853 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.123802 (* 1 = 0.123802 loss)
I0901 06:15:44.645861 916722 sgd_solver.cpp:106] Iteration 4133000, lr = 0.01
I0901 06:16:14.335100 916722 solver.cpp:218] Iteration 4133500 (16.8412 iter/s, 29.6891s/500 iters), loss = 0.0377501
I0901 06:16:14.335157 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0377547 (* 1 = 0.0377547 loss)
I0901 06:16:14.335165 916722 sgd_solver.cpp:106] Iteration 4133500, lr = 0.01
I0901 06:16:44.026796 916722 solver.cpp:218] Iteration 4134000 (16.8399 iter/s, 29.6915s/500 iters), loss = 0.087191
I0901 06:16:44.026845 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0871956 (* 1 = 0.0871956 loss)
I0901 06:16:44.026855 916722 sgd_solver.cpp:106] Iteration 4134000, lr = 0.01
I0901 06:17:13.714530 916722 solver.cpp:218] Iteration 4134500 (16.8421 iter/s, 29.6875s/500 iters), loss = 0.039823
I0901 06:17:13.714584 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0398275 (* 1 = 0.0398275 loss)
I0901 06:17:13.714593 916722 sgd_solver.cpp:106] Iteration 4134500, lr = 0.01
I0901 06:17:43.406867 916722 solver.cpp:218] Iteration 4135000 (16.8395 iter/s, 29.6921s/500 iters), loss = 0.0707138
I0901 06:17:43.406914 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0707182 (* 1 = 0.0707182 loss)
I0901 06:17:43.406924 916722 sgd_solver.cpp:106] Iteration 4135000, lr = 0.01
I0901 06:18:13.099357 916722 solver.cpp:218] Iteration 4135500 (16.8394 iter/s, 29.6923s/500 iters), loss = 0.0883099
I0901 06:18:13.099412 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0883143 (* 1 = 0.0883143 loss)
I0901 06:18:13.099421 916722 sgd_solver.cpp:106] Iteration 4135500, lr = 0.01
I0901 06:18:42.790390 916722 solver.cpp:218] Iteration 4136000 (16.8402 iter/s, 29.6908s/500 iters), loss = 0.0888098
I0901 06:18:42.790437 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0888144 (* 1 = 0.0888144 loss)
I0901 06:18:42.790446 916722 sgd_solver.cpp:106] Iteration 4136000, lr = 0.01
I0901 06:19:12.485589 916722 solver.cpp:218] Iteration 4136500 (16.8379 iter/s, 29.695s/500 iters), loss = 0.179228
I0901 06:19:12.485646 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.179232 (* 1 = 0.179232 loss)
I0901 06:19:12.485654 916722 sgd_solver.cpp:106] Iteration 4136500, lr = 0.01
I0901 06:19:42.169064 916722 solver.cpp:218] Iteration 4137000 (16.8445 iter/s, 29.6832s/500 iters), loss = 0.0394311
I0901 06:19:42.169116 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0394359 (* 1 = 0.0394359 loss)
I0901 06:19:42.169126 916722 sgd_solver.cpp:106] Iteration 4137000, lr = 0.01
I0901 06:20:11.856376 916722 solver.cpp:218] Iteration 4137500 (16.8423 iter/s, 29.6871s/500 iters), loss = 0.136829
I0901 06:20:11.856442 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.136834 (* 1 = 0.136834 loss)
I0901 06:20:11.856452 916722 sgd_solver.cpp:106] Iteration 4137500, lr = 0.01
I0901 06:20:41.572163 916722 solver.cpp:218] Iteration 4138000 (16.8262 iter/s, 29.7155s/500 iters), loss = 0.149399
I0901 06:20:41.572213 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.149404 (* 1 = 0.149404 loss)
I0901 06:20:41.572223 916722 sgd_solver.cpp:106] Iteration 4138000, lr = 0.01
I0901 06:21:11.291978 916722 solver.cpp:218] Iteration 4138500 (16.8239 iter/s, 29.7196s/500 iters), loss = 0.0240705
I0901 06:21:11.292052 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0240751 (* 1 = 0.0240751 loss)
I0901 06:21:11.292065 916722 sgd_solver.cpp:106] Iteration 4138500, lr = 0.01
I0901 06:21:41.009666 916722 solver.cpp:218] Iteration 4139000 (16.8251 iter/s, 29.7174s/500 iters), loss = 0.164033
I0901 06:21:41.009717 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.164037 (* 1 = 0.164037 loss)
I0901 06:21:41.009727 916722 sgd_solver.cpp:106] Iteration 4139000, lr = 0.01
I0901 06:22:10.726948 916722 solver.cpp:218] Iteration 4139500 (16.8254 iter/s, 29.7171s/500 iters), loss = 0.157335
I0901 06:22:10.727005 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.15734 (* 1 = 0.15734 loss)
I0901 06:22:10.727015 916722 sgd_solver.cpp:106] Iteration 4139500, lr = 0.01
I0901 06:22:40.443569 916722 solver.cpp:218] Iteration 4140000 (16.8257 iter/s, 29.7164s/500 iters), loss = 0.161874
I0901 06:22:40.443615 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.161878 (* 1 = 0.161878 loss)
I0901 06:22:40.443624 916722 sgd_solver.cpp:106] Iteration 4140000, lr = 0.01
I0901 06:23:10.163350 916722 solver.cpp:218] Iteration 4140500 (16.8239 iter/s, 29.7196s/500 iters), loss = 0.24623
I0901 06:23:10.163408 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.246235 (* 1 = 0.246235 loss)
I0901 06:23:10.163415 916722 sgd_solver.cpp:106] Iteration 4140500, lr = 0.01
I0901 06:23:39.879604 916722 solver.cpp:218] Iteration 4141000 (16.8259 iter/s, 29.716s/500 iters), loss = 0.263533
I0901 06:23:39.879660 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.263538 (* 1 = 0.263538 loss)
I0901 06:23:39.879670 916722 sgd_solver.cpp:106] Iteration 4141000, lr = 0.01
I0901 06:24:09.594820 916722 solver.cpp:218] Iteration 4141500 (16.8265 iter/s, 29.715s/500 iters), loss = 0.0678631
I0901 06:24:09.594879 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0678678 (* 1 = 0.0678678 loss)
I0901 06:24:09.594888 916722 sgd_solver.cpp:106] Iteration 4141500, lr = 0.01
I0901 06:24:39.312144 916722 solver.cpp:218] Iteration 4142000 (16.8253 iter/s, 29.7171s/500 iters), loss = 0.0731367
I0901 06:24:39.312196 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0731413 (* 1 = 0.0731413 loss)
I0901 06:24:39.312207 916722 sgd_solver.cpp:106] Iteration 4142000, lr = 0.01
I0901 06:25:09.030542 916722 solver.cpp:218] Iteration 4142500 (16.8247 iter/s, 29.7182s/500 iters), loss = 0.0719075
I0901 06:25:09.030596 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0719121 (* 1 = 0.0719121 loss)
I0901 06:25:09.030606 916722 sgd_solver.cpp:106] Iteration 4142500, lr = 0.01
I0901 06:25:38.746937 916722 solver.cpp:218] Iteration 4143000 (16.8259 iter/s, 29.7162s/500 iters), loss = 0.0561606
I0901 06:25:38.746990 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0561651 (* 1 = 0.0561651 loss)
I0901 06:25:38.747000 916722 sgd_solver.cpp:106] Iteration 4143000, lr = 0.01
I0901 06:26:08.463155 916722 solver.cpp:218] Iteration 4143500 (16.826 iter/s, 29.716s/500 iters), loss = 0.0527267
I0901 06:26:08.463207 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0527311 (* 1 = 0.0527311 loss)
I0901 06:26:08.463217 916722 sgd_solver.cpp:106] Iteration 4143500, lr = 0.01
I0901 06:26:38.181973 916722 solver.cpp:218] Iteration 4144000 (16.8245 iter/s, 29.7186s/500 iters), loss = 0.269343
I0901 06:26:38.182024 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.269347 (* 1 = 0.269347 loss)
I0901 06:26:38.182034 916722 sgd_solver.cpp:106] Iteration 4144000, lr = 0.01
I0901 06:27:07.899456 916722 solver.cpp:218] Iteration 4144500 (16.8252 iter/s, 29.7173s/500 iters), loss = 0.20141
I0901 06:27:07.899508 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.201414 (* 1 = 0.201414 loss)
I0901 06:27:07.899518 916722 sgd_solver.cpp:106] Iteration 4144500, lr = 0.01
I0901 06:27:37.615083 916722 solver.cpp:218] Iteration 4145000 (16.8263 iter/s, 29.7154s/500 iters), loss = 0.106295
I0901 06:27:37.615135 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.1063 (* 1 = 0.1063 loss)
I0901 06:27:37.615159 916722 sgd_solver.cpp:106] Iteration 4145000, lr = 0.01
I0901 06:28:07.330806 916722 solver.cpp:218] Iteration 4145500 (16.8262 iter/s, 29.7155s/500 iters), loss = 0.203733
I0901 06:28:07.330869 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.203737 (* 1 = 0.203737 loss)
I0901 06:28:07.330878 916722 sgd_solver.cpp:106] Iteration 4145500, lr = 0.01
I0901 06:28:37.050494 916722 solver.cpp:218] Iteration 4146000 (16.824 iter/s, 29.7195s/500 iters), loss = 0.344935
I0901 06:28:37.050541 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.344939 (* 1 = 0.344939 loss)
I0901 06:28:37.050551 916722 sgd_solver.cpp:106] Iteration 4146000, lr = 0.01
I0901 06:29:06.767354 916722 solver.cpp:218] Iteration 4146500 (16.8256 iter/s, 29.7166s/500 iters), loss = 0.192425
I0901 06:29:06.767410 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.19243 (* 1 = 0.19243 loss)
I0901 06:29:06.767419 916722 sgd_solver.cpp:106] Iteration 4146500, lr = 0.01
I0901 06:29:36.484189 916722 solver.cpp:218] Iteration 4147000 (16.8256 iter/s, 29.7166s/500 iters), loss = 0.240269
I0901 06:29:36.484236 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.240274 (* 1 = 0.240274 loss)
I0901 06:29:36.484246 916722 sgd_solver.cpp:106] Iteration 4147000, lr = 0.01
I0901 06:30:06.205943 916722 solver.cpp:218] Iteration 4147500 (16.8228 iter/s, 29.7215s/500 iters), loss = 0.0434579
I0901 06:30:06.206002 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0434622 (* 1 = 0.0434622 loss)
I0901 06:30:06.206012 916722 sgd_solver.cpp:106] Iteration 4147500, lr = 0.01
I0901 06:30:35.925478 916722 solver.cpp:218] Iteration 4148000 (16.8241 iter/s, 29.7193s/500 iters), loss = 0.104951
I0901 06:30:35.925526 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104955 (* 1 = 0.104955 loss)
I0901 06:30:35.925535 916722 sgd_solver.cpp:106] Iteration 4148000, lr = 0.01
I0901 06:31:05.645892 916722 solver.cpp:218] Iteration 4148500 (16.8236 iter/s, 29.7202s/500 iters), loss = 0.49359
I0901 06:31:05.645951 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.493594 (* 1 = 0.493594 loss)
I0901 06:31:05.645959 916722 sgd_solver.cpp:106] Iteration 4148500, lr = 0.01
I0901 06:31:35.363780 916722 solver.cpp:218] Iteration 4149000 (16.825 iter/s, 29.7177s/500 iters), loss = 0.16267
I0901 06:31:35.363828 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.162674 (* 1 = 0.162674 loss)
I0901 06:31:35.363837 916722 sgd_solver.cpp:106] Iteration 4149000, lr = 0.01
I0901 06:32:05.083185 916722 solver.cpp:218] Iteration 4149500 (16.8241 iter/s, 29.7192s/500 iters), loss = 0.0303646
I0901 06:32:05.083245 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0303683 (* 1 = 0.0303683 loss)
I0901 06:32:05.083253 916722 sgd_solver.cpp:106] Iteration 4149500, lr = 0.01
I0901 06:32:34.741235 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_4150000.caffemodel
I0901 06:32:34.760368 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_4150000.solverstate
I0901 06:32:34.766458 916722 solver.cpp:330] Iteration 4150000, Testing net (#0)
I0901 06:32:50.164242 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8577
I0901 06:32:50.164299 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.502039 (* 1 = 0.502039 loss)
I0901 06:32:50.222879 916722 solver.cpp:218] Iteration 4150000 (11.0768 iter/s, 45.1395s/500 iters), loss = 0.271508
I0901 06:32:50.222906 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.271512 (* 1 = 0.271512 loss)
I0901 06:32:50.222914 916722 sgd_solver.cpp:106] Iteration 4150000, lr = 0.01
I0901 06:33:19.825947 916722 solver.cpp:218] Iteration 4150500 (16.8899 iter/s, 29.6035s/500 iters), loss = 0.298738
I0901 06:33:19.825990 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.298742 (* 1 = 0.298742 loss)
I0901 06:33:19.825999 916722 sgd_solver.cpp:106] Iteration 4150500, lr = 0.01
I0901 06:33:49.449486 916722 solver.cpp:218] Iteration 4151000 (16.8782 iter/s, 29.624s/500 iters), loss = 0.126292
I0901 06:33:49.449548 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.126295 (* 1 = 0.126295 loss)
I0901 06:33:49.449555 916722 sgd_solver.cpp:106] Iteration 4151000, lr = 0.01
I0901 06:34:19.185189 916722 solver.cpp:218] Iteration 4151500 (16.8146 iter/s, 29.7361s/500 iters), loss = 0.0599506
I0901 06:34:19.185241 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0599544 (* 1 = 0.0599544 loss)
I0901 06:34:19.185251 916722 sgd_solver.cpp:106] Iteration 4151500, lr = 0.01
I0901 06:34:48.916831 916722 solver.cpp:218] Iteration 4152000 (16.8169 iter/s, 29.732s/500 iters), loss = 0.10065
I0901 06:34:48.916890 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.100654 (* 1 = 0.100654 loss)
I0901 06:34:48.916899 916722 sgd_solver.cpp:106] Iteration 4152000, lr = 0.01
I0901 06:35:18.652505 916722 solver.cpp:218] Iteration 4152500 (16.8146 iter/s, 29.736s/500 iters), loss = 0.284432
I0901 06:35:18.652559 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.284436 (* 1 = 0.284436 loss)
I0901 06:35:18.652568 916722 sgd_solver.cpp:106] Iteration 4152500, lr = 0.01
I0901 06:35:48.386595 916722 solver.cpp:218] Iteration 4153000 (16.8155 iter/s, 29.7344s/500 iters), loss = 0.0946744
I0901 06:35:48.386653 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0946782 (* 1 = 0.0946782 loss)
I0901 06:35:48.386662 916722 sgd_solver.cpp:106] Iteration 4153000, lr = 0.01
I0901 06:36:18.122700 916722 solver.cpp:218] Iteration 4153500 (16.8144 iter/s, 29.7364s/500 iters), loss = 0.0260613
I0901 06:36:18.122752 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0260651 (* 1 = 0.0260651 loss)
I0901 06:36:18.122762 916722 sgd_solver.cpp:106] Iteration 4153500, lr = 0.01
I0901 06:36:47.862187 916722 solver.cpp:218] Iteration 4154000 (16.8125 iter/s, 29.7398s/500 iters), loss = 0.0741527
I0901 06:36:47.862247 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0741565 (* 1 = 0.0741565 loss)
I0901 06:36:47.862257 916722 sgd_solver.cpp:106] Iteration 4154000, lr = 0.01
I0901 06:37:17.597362 916722 solver.cpp:218] Iteration 4154500 (16.815 iter/s, 29.7354s/500 iters), loss = 0.286226
I0901 06:37:17.597407 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.28623 (* 1 = 0.28623 loss)
I0901 06:37:17.597416 916722 sgd_solver.cpp:106] Iteration 4154500, lr = 0.01
I0901 06:37:47.333945 916722 solver.cpp:218] Iteration 4155000 (16.8142 iter/s, 29.7368s/500 iters), loss = 0.0218868
I0901 06:37:47.334003 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0218905 (* 1 = 0.0218905 loss)
I0901 06:37:47.334012 916722 sgd_solver.cpp:106] Iteration 4155000, lr = 0.01
I0901 06:38:17.068838 916722 solver.cpp:218] Iteration 4155500 (16.8151 iter/s, 29.7351s/500 iters), loss = 0.211741
I0901 06:38:17.068886 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.211744 (* 1 = 0.211744 loss)
I0901 06:38:17.068894 916722 sgd_solver.cpp:106] Iteration 4155500, lr = 0.01
I0901 06:38:46.801384 916722 solver.cpp:218] Iteration 4156000 (16.8165 iter/s, 29.7327s/500 iters), loss = 0.08505
I0901 06:38:46.801446 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0850538 (* 1 = 0.0850538 loss)
I0901 06:38:46.801455 916722 sgd_solver.cpp:106] Iteration 4156000, lr = 0.01
I0901 06:39:16.532876 916722 solver.cpp:218] Iteration 4156500 (16.8171 iter/s, 29.7316s/500 iters), loss = 0.307827
I0901 06:39:16.532930 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.30783 (* 1 = 0.30783 loss)
I0901 06:39:16.532939 916722 sgd_solver.cpp:106] Iteration 4156500, lr = 0.01
I0901 06:39:46.267069 916722 solver.cpp:218] Iteration 4157000 (16.8156 iter/s, 29.7343s/500 iters), loss = 0.156167
I0901 06:39:46.267129 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.156171 (* 1 = 0.156171 loss)
I0901 06:39:46.267138 916722 sgd_solver.cpp:106] Iteration 4157000, lr = 0.01
I0901 06:40:16.000164 916722 solver.cpp:218] Iteration 4157500 (16.8162 iter/s, 29.7332s/500 iters), loss = 0.111121
I0901 06:40:16.000228 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111124 (* 1 = 0.111124 loss)
I0901 06:40:16.000238 916722 sgd_solver.cpp:106] Iteration 4157500, lr = 0.01
I0901 06:40:45.734344 916722 solver.cpp:218] Iteration 4158000 (16.8156 iter/s, 29.7343s/500 iters), loss = 0.0322313
I0901 06:40:45.734412 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0322348 (* 1 = 0.0322348 loss)
I0901 06:40:45.734421 916722 sgd_solver.cpp:106] Iteration 4158000, lr = 0.01
I0901 06:41:15.472223 916722 solver.cpp:218] Iteration 4158500 (16.8135 iter/s, 29.738s/500 iters), loss = 0.181247
I0901 06:41:15.472275 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.181251 (* 1 = 0.181251 loss)
I0901 06:41:15.472283 916722 sgd_solver.cpp:106] Iteration 4158500, lr = 0.01
I0901 06:41:45.208845 916722 solver.cpp:218] Iteration 4159000 (16.8142 iter/s, 29.7367s/500 iters), loss = 0.0837222
I0901 06:41:45.208901 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0837255 (* 1 = 0.0837255 loss)
I0901 06:41:45.208910 916722 sgd_solver.cpp:106] Iteration 4159000, lr = 0.01
I0901 06:42:14.941972 916722 solver.cpp:218] Iteration 4159500 (16.8162 iter/s, 29.7332s/500 iters), loss = 0.168895
I0901 06:42:14.942023 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.168899 (* 1 = 0.168899 loss)
I0901 06:42:14.942032 916722 sgd_solver.cpp:106] Iteration 4159500, lr = 0.01
I0901 06:42:44.682554 916722 solver.cpp:218] Iteration 4160000 (16.812 iter/s, 29.7407s/500 iters), loss = 0.0515044
I0901 06:42:44.682610 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0515078 (* 1 = 0.0515078 loss)
I0901 06:42:44.682617 916722 sgd_solver.cpp:106] Iteration 4160000, lr = 0.01
I0901 06:43:14.428187 916722 solver.cpp:218] Iteration 4160500 (16.8092 iter/s, 29.7457s/500 iters), loss = 0.474554
I0901 06:43:14.428241 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.474557 (* 1 = 0.474557 loss)
I0901 06:43:14.428251 916722 sgd_solver.cpp:106] Iteration 4160500, lr = 0.01
I0901 06:43:44.175648 916722 solver.cpp:218] Iteration 4161000 (16.8081 iter/s, 29.7475s/500 iters), loss = 0.111613
I0901 06:43:44.175704 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111616 (* 1 = 0.111616 loss)
I0901 06:43:44.175714 916722 sgd_solver.cpp:106] Iteration 4161000, lr = 0.01
I0901 06:44:13.920995 916722 solver.cpp:218] Iteration 4161500 (16.8093 iter/s, 29.7454s/500 iters), loss = 0.144382
I0901 06:44:13.921046 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.144386 (* 1 = 0.144386 loss)
I0901 06:44:13.921056 916722 sgd_solver.cpp:106] Iteration 4161500, lr = 0.01
I0901 06:44:43.669672 916722 solver.cpp:218] Iteration 4162000 (16.8075 iter/s, 29.7487s/500 iters), loss = 0.165557
I0901 06:44:43.669728 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.16556 (* 1 = 0.16556 loss)
I0901 06:44:43.669737 916722 sgd_solver.cpp:106] Iteration 4162000, lr = 0.01
I0901 06:45:13.414568 916722 solver.cpp:218] Iteration 4162500 (16.8096 iter/s, 29.7449s/500 iters), loss = 0.223195
I0901 06:45:13.414616 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.223198 (* 1 = 0.223198 loss)
I0901 06:45:13.414628 916722 sgd_solver.cpp:106] Iteration 4162500, lr = 0.01
I0901 06:45:43.157863 916722 solver.cpp:218] Iteration 4163000 (16.8105 iter/s, 29.7433s/500 iters), loss = 0.115629
I0901 06:45:43.157920 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115632 (* 1 = 0.115632 loss)
I0901 06:45:43.157929 916722 sgd_solver.cpp:106] Iteration 4163000, lr = 0.01
I0901 06:46:12.905655 916722 solver.cpp:218] Iteration 4163500 (16.808 iter/s, 29.7478s/500 iters), loss = 0.198343
I0901 06:46:12.905707 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.198346 (* 1 = 0.198346 loss)
I0901 06:46:12.905719 916722 sgd_solver.cpp:106] Iteration 4163500, lr = 0.01
I0901 06:46:42.650712 916722 solver.cpp:218] Iteration 4164000 (16.8095 iter/s, 29.745s/500 iters), loss = 0.250574
I0901 06:46:42.650780 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.250578 (* 1 = 0.250578 loss)
I0901 06:46:42.650789 916722 sgd_solver.cpp:106] Iteration 4164000, lr = 0.01
I0901 06:47:12.400010 916722 solver.cpp:218] Iteration 4164500 (16.8071 iter/s, 29.7493s/500 iters), loss = 0.267322
I0901 06:47:12.400061 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.267326 (* 1 = 0.267326 loss)
I0901 06:47:12.400071 916722 sgd_solver.cpp:106] Iteration 4164500, lr = 0.01
I0901 06:47:42.163987 916722 solver.cpp:218] Iteration 4165000 (16.7988 iter/s, 29.764s/500 iters), loss = 0.064972
I0901 06:47:42.164052 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0649755 (* 1 = 0.0649755 loss)
I0901 06:47:42.164062 916722 sgd_solver.cpp:106] Iteration 4165000, lr = 0.01
I0901 06:48:11.926079 916722 solver.cpp:218] Iteration 4165500 (16.7999 iter/s, 29.7621s/500 iters), loss = 0.202629
I0901 06:48:11.926136 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.202633 (* 1 = 0.202633 loss)
I0901 06:48:11.926144 916722 sgd_solver.cpp:106] Iteration 4165500, lr = 0.01
I0901 06:48:41.690397 916722 solver.cpp:218] Iteration 4166000 (16.7987 iter/s, 29.7643s/500 iters), loss = 0.0580901
I0901 06:48:41.690457 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0580935 (* 1 = 0.0580935 loss)
I0901 06:48:41.690466 916722 sgd_solver.cpp:106] Iteration 4166000, lr = 0.01
I0901 06:49:11.449940 916722 solver.cpp:218] Iteration 4166500 (16.8014 iter/s, 29.7595s/500 iters), loss = 0.188013
I0901 06:49:11.449992 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.188017 (* 1 = 0.188017 loss)
I0901 06:49:11.450001 916722 sgd_solver.cpp:106] Iteration 4166500, lr = 0.01
I0901 06:49:41.203800 916722 solver.cpp:218] Iteration 4167000 (16.8046 iter/s, 29.7538s/500 iters), loss = 0.165801
I0901 06:49:41.203860 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.165805 (* 1 = 0.165805 loss)
I0901 06:49:41.203868 916722 sgd_solver.cpp:106] Iteration 4167000, lr = 0.01
I0901 06:50:10.951355 916722 solver.cpp:218] Iteration 4167500 (16.8081 iter/s, 29.7475s/500 iters), loss = 0.276348
I0901 06:50:10.951408 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.276352 (* 1 = 0.276352 loss)
I0901 06:50:10.951417 916722 sgd_solver.cpp:106] Iteration 4167500, lr = 0.01
I0901 06:50:40.700767 916722 solver.cpp:218] Iteration 4168000 (16.8071 iter/s, 29.7494s/500 iters), loss = 0.033704
I0901 06:50:40.700830 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0337078 (* 1 = 0.0337078 loss)
I0901 06:50:40.700839 916722 sgd_solver.cpp:106] Iteration 4168000, lr = 0.01
I0901 06:51:10.446588 916722 solver.cpp:218] Iteration 4168500 (16.8091 iter/s, 29.7457s/500 iters), loss = 0.182203
I0901 06:51:10.446640 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.182207 (* 1 = 0.182207 loss)
I0901 06:51:10.446650 916722 sgd_solver.cpp:106] Iteration 4168500, lr = 0.01
I0901 06:51:40.192703 916722 solver.cpp:218] Iteration 4169000 (16.809 iter/s, 29.7461s/500 iters), loss = 0.153047
I0901 06:51:40.192781 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.153051 (* 1 = 0.153051 loss)
I0901 06:51:40.192801 916722 sgd_solver.cpp:106] Iteration 4169000, lr = 0.01
I0901 06:52:09.939052 916722 solver.cpp:218] Iteration 4169500 (16.8088 iter/s, 29.7463s/500 iters), loss = 0.131795
I0901 06:52:09.939103 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131798 (* 1 = 0.131798 loss)
I0901 06:52:09.939112 916722 sgd_solver.cpp:106] Iteration 4169500, lr = 0.01
I0901 06:52:39.688251 916722 solver.cpp:218] Iteration 4170000 (16.8072 iter/s, 29.7491s/500 iters), loss = 0.0772399
I0901 06:52:39.688310 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0772434 (* 1 = 0.0772434 loss)
I0901 06:52:39.688319 916722 sgd_solver.cpp:106] Iteration 4170000, lr = 0.01
I0901 06:53:09.436849 916722 solver.cpp:218] Iteration 4170500 (16.8076 iter/s, 29.7485s/500 iters), loss = 0.199475
I0901 06:53:09.436904 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.199479 (* 1 = 0.199479 loss)
I0901 06:53:09.436925 916722 sgd_solver.cpp:106] Iteration 4170500, lr = 0.01
I0901 06:53:39.180975 916722 solver.cpp:218] Iteration 4171000 (16.8101 iter/s, 29.744s/500 iters), loss = 0.351507
I0901 06:53:39.181049 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.351511 (* 1 = 0.351511 loss)
I0901 06:53:39.181059 916722 sgd_solver.cpp:106] Iteration 4171000, lr = 0.01
I0901 06:54:08.928964 916722 solver.cpp:218] Iteration 4171500 (16.8079 iter/s, 29.7479s/500 iters), loss = 0.137372
I0901 06:54:08.929015 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.137376 (* 1 = 0.137376 loss)
I0901 06:54:08.929025 916722 sgd_solver.cpp:106] Iteration 4171500, lr = 0.01
I0901 06:54:38.675496 916722 solver.cpp:218] Iteration 4172000 (16.8087 iter/s, 29.7464s/500 iters), loss = 0.22324
I0901 06:54:38.675555 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.223244 (* 1 = 0.223244 loss)
I0901 06:54:38.675565 916722 sgd_solver.cpp:106] Iteration 4172000, lr = 0.01
I0901 06:55:08.422740 916722 solver.cpp:218] Iteration 4172500 (16.8083 iter/s, 29.7472s/500 iters), loss = 0.227244
I0901 06:55:08.422791 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.227248 (* 1 = 0.227248 loss)
I0901 06:55:08.422801 916722 sgd_solver.cpp:106] Iteration 4172500, lr = 0.01
I0901 06:55:38.168612 916722 solver.cpp:218] Iteration 4173000 (16.8091 iter/s, 29.7458s/500 iters), loss = 0.197894
I0901 06:55:38.168668 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.197898 (* 1 = 0.197898 loss)
I0901 06:55:38.168678 916722 sgd_solver.cpp:106] Iteration 4173000, lr = 0.01
I0901 06:56:07.916239 916722 solver.cpp:218] Iteration 4173500 (16.8081 iter/s, 29.7475s/500 iters), loss = 0.0384802
I0901 06:56:07.916290 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.038484 (* 1 = 0.038484 loss)
I0901 06:56:07.916299 916722 sgd_solver.cpp:106] Iteration 4173500, lr = 0.01
I0901 06:56:37.668165 916722 solver.cpp:218] Iteration 4174000 (16.8057 iter/s, 29.7518s/500 iters), loss = 0.215209
I0901 06:56:37.668220 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.215213 (* 1 = 0.215213 loss)
I0901 06:56:37.668229 916722 sgd_solver.cpp:106] Iteration 4174000, lr = 0.01
I0901 06:57:07.418946 916722 solver.cpp:218] Iteration 4174500 (16.8063 iter/s, 29.7507s/500 iters), loss = 0.0602883
I0901 06:57:07.418998 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0602921 (* 1 = 0.0602921 loss)
I0901 06:57:07.419008 916722 sgd_solver.cpp:106] Iteration 4174500, lr = 0.01
I0901 06:57:37.169673 916722 solver.cpp:218] Iteration 4175000 (16.8064 iter/s, 29.7506s/500 iters), loss = 0.187404
I0901 06:57:37.169734 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.187407 (* 1 = 0.187407 loss)
I0901 06:57:37.169741 916722 sgd_solver.cpp:106] Iteration 4175000, lr = 0.01
I0901 06:58:06.919039 916722 solver.cpp:218] Iteration 4175500 (16.8071 iter/s, 29.7493s/500 iters), loss = 0.084478
I0901 06:58:06.919091 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0844815 (* 1 = 0.0844815 loss)
I0901 06:58:06.919102 916722 sgd_solver.cpp:106] Iteration 4175500, lr = 0.01
I0901 06:58:36.668623 916722 solver.cpp:218] Iteration 4176000 (16.807 iter/s, 29.7495s/500 iters), loss = 0.29005
I0901 06:58:36.668689 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.290053 (* 1 = 0.290053 loss)
I0901 06:58:36.668697 916722 sgd_solver.cpp:106] Iteration 4176000, lr = 0.01
I0901 06:59:06.420750 916722 solver.cpp:218] Iteration 4176500 (16.8056 iter/s, 29.752s/500 iters), loss = 0.11778
I0901 06:59:06.420799 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.117784 (* 1 = 0.117784 loss)
I0901 06:59:06.420809 916722 sgd_solver.cpp:106] Iteration 4176500, lr = 0.01
I0901 06:59:36.171792 916722 solver.cpp:218] Iteration 4177000 (16.8062 iter/s, 29.7509s/500 iters), loss = 0.0410521
I0901 06:59:36.171859 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0410553 (* 1 = 0.0410553 loss)
I0901 06:59:36.171872 916722 sgd_solver.cpp:106] Iteration 4177000, lr = 0.01
I0901 07:00:05.929772 916722 solver.cpp:218] Iteration 4177500 (16.8023 iter/s, 29.7579s/500 iters), loss = 0.124455
I0901 07:00:05.929821 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.124458 (* 1 = 0.124458 loss)
I0901 07:00:05.929829 916722 sgd_solver.cpp:106] Iteration 4177500, lr = 0.01
I0901 07:00:35.690044 916722 solver.cpp:218] Iteration 4178000 (16.801 iter/s, 29.7602s/500 iters), loss = 0.131591
I0901 07:00:35.690100 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131594 (* 1 = 0.131594 loss)
I0901 07:00:35.690109 916722 sgd_solver.cpp:106] Iteration 4178000, lr = 0.01
I0901 07:01:05.452015 916722 solver.cpp:218] Iteration 4178500 (16.8 iter/s, 29.7619s/500 iters), loss = 0.0777779
I0901 07:01:05.452067 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0777814 (* 1 = 0.0777814 loss)
I0901 07:01:05.452075 916722 sgd_solver.cpp:106] Iteration 4178500, lr = 0.01
I0901 07:01:35.211661 916722 solver.cpp:218] Iteration 4179000 (16.8013 iter/s, 29.7595s/500 iters), loss = 0.100179
I0901 07:01:35.211724 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.100183 (* 1 = 0.100183 loss)
I0901 07:01:35.211732 916722 sgd_solver.cpp:106] Iteration 4179000, lr = 0.01
I0901 07:02:04.972460 916722 solver.cpp:218] Iteration 4179500 (16.8007 iter/s, 29.7607s/500 iters), loss = 0.146242
I0901 07:02:04.972512 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.146245 (* 1 = 0.146245 loss)
I0901 07:02:04.972520 916722 sgd_solver.cpp:106] Iteration 4179500, lr = 0.01
I0901 07:02:34.734122 916722 solver.cpp:218] Iteration 4180000 (16.8002 iter/s, 29.7616s/500 iters), loss = 0.152696
I0901 07:02:34.734179 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152699 (* 1 = 0.152699 loss)
I0901 07:02:34.734189 916722 sgd_solver.cpp:106] Iteration 4180000, lr = 0.01
I0901 07:03:04.495213 916722 solver.cpp:218] Iteration 4180500 (16.8005 iter/s, 29.761s/500 iters), loss = 0.316047
I0901 07:03:04.495261 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.316051 (* 1 = 0.316051 loss)
I0901 07:03:04.495270 916722 sgd_solver.cpp:106] Iteration 4180500, lr = 0.01
I0901 07:03:34.258661 916722 solver.cpp:218] Iteration 4181000 (16.7992 iter/s, 29.7633s/500 iters), loss = 0.267187
I0901 07:03:34.258718 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.26719 (* 1 = 0.26719 loss)
I0901 07:03:34.258728 916722 sgd_solver.cpp:106] Iteration 4181000, lr = 0.01
I0901 07:04:04.016957 916722 solver.cpp:218] Iteration 4181500 (16.8021 iter/s, 29.7582s/500 iters), loss = 0.255655
I0901 07:04:04.017009 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.255658 (* 1 = 0.255658 loss)
I0901 07:04:04.017017 916722 sgd_solver.cpp:106] Iteration 4181500, lr = 0.01
I0901 07:04:33.777886 916722 solver.cpp:218] Iteration 4182000 (16.8006 iter/s, 29.7608s/500 iters), loss = 0.156548
I0901 07:04:33.777941 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.156551 (* 1 = 0.156551 loss)
I0901 07:04:33.777951 916722 sgd_solver.cpp:106] Iteration 4182000, lr = 0.01
I0901 07:05:03.540159 916722 solver.cpp:218] Iteration 4182500 (16.7999 iter/s, 29.7621s/500 iters), loss = 0.121796
I0901 07:05:03.540210 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.121799 (* 1 = 0.121799 loss)
I0901 07:05:03.540220 916722 sgd_solver.cpp:106] Iteration 4182500, lr = 0.01
I0901 07:05:33.302942 916722 solver.cpp:218] Iteration 4183000 (16.7996 iter/s, 29.7627s/500 iters), loss = 0.19112
I0901 07:05:33.303002 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.191123 (* 1 = 0.191123 loss)
I0901 07:05:33.303011 916722 sgd_solver.cpp:106] Iteration 4183000, lr = 0.01
I0901 07:06:03.064801 916722 solver.cpp:218] Iteration 4183500 (16.8001 iter/s, 29.7617s/500 iters), loss = 0.0661313
I0901 07:06:03.064850 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0661341 (* 1 = 0.0661341 loss)
I0901 07:06:03.064869 916722 sgd_solver.cpp:106] Iteration 4183500, lr = 0.01
I0901 07:06:32.822242 916722 solver.cpp:218] Iteration 4184000 (16.8026 iter/s, 29.7573s/500 iters), loss = 0.108339
I0901 07:06:32.822312 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.108342 (* 1 = 0.108342 loss)
I0901 07:06:32.822321 916722 sgd_solver.cpp:106] Iteration 4184000, lr = 0.01
I0901 07:07:02.585014 916722 solver.cpp:218] Iteration 4184500 (16.7997 iter/s, 29.7624s/500 iters), loss = 0.190027
I0901 07:07:02.585063 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.19003 (* 1 = 0.19003 loss)
I0901 07:07:02.585072 916722 sgd_solver.cpp:106] Iteration 4184500, lr = 0.01
I0901 07:07:32.350303 916722 solver.cpp:218] Iteration 4185000 (16.7986 iter/s, 29.7644s/500 iters), loss = 0.0830704
I0901 07:07:32.350363 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.083073 (* 1 = 0.083073 loss)
I0901 07:07:32.350371 916722 sgd_solver.cpp:106] Iteration 4185000, lr = 0.01
I0901 07:08:02.113453 916722 solver.cpp:218] Iteration 4185500 (16.7998 iter/s, 29.7623s/500 iters), loss = 0.0408927
I0901 07:08:02.113505 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0408954 (* 1 = 0.0408954 loss)
I0901 07:08:02.113515 916722 sgd_solver.cpp:106] Iteration 4185500, lr = 0.01
I0901 07:08:31.875770 916722 solver.cpp:218] Iteration 4186000 (16.8002 iter/s, 29.7615s/500 iters), loss = 0.13729
I0901 07:08:31.875830 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.137292 (* 1 = 0.137292 loss)
I0901 07:08:31.875839 916722 sgd_solver.cpp:106] Iteration 4186000, lr = 0.01
I0901 07:09:01.638444 916722 solver.cpp:218] Iteration 4186500 (16.8 iter/s, 29.7619s/500 iters), loss = 0.0339644
I0901 07:09:01.638495 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0339671 (* 1 = 0.0339671 loss)
I0901 07:09:01.638505 916722 sgd_solver.cpp:106] Iteration 4186500, lr = 0.01
I0901 07:09:31.400933 916722 solver.cpp:218] Iteration 4187000 (16.8001 iter/s, 29.7618s/500 iters), loss = 0.0923581
I0901 07:09:31.400993 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0923609 (* 1 = 0.0923609 loss)
I0901 07:09:31.401002 916722 sgd_solver.cpp:106] Iteration 4187000, lr = 0.01
I0901 07:10:01.162559 916722 solver.cpp:218] Iteration 4187500 (16.8006 iter/s, 29.7609s/500 iters), loss = 0.0995452
I0901 07:10:01.162611 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0995479 (* 1 = 0.0995479 loss)
I0901 07:10:01.162621 916722 sgd_solver.cpp:106] Iteration 4187500, lr = 0.01
I0901 07:10:30.924098 916722 solver.cpp:218] Iteration 4188000 (16.8006 iter/s, 29.7609s/500 iters), loss = 0.144621
I0901 07:10:30.924160 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.144623 (* 1 = 0.144623 loss)
I0901 07:10:30.924168 916722 sgd_solver.cpp:106] Iteration 4188000, lr = 0.01
I0901 07:11:00.687196 916722 solver.cpp:218] Iteration 4188500 (16.7997 iter/s, 29.7624s/500 iters), loss = 0.0415474
I0901 07:11:00.687245 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0415502 (* 1 = 0.0415502 loss)
I0901 07:11:00.687255 916722 sgd_solver.cpp:106] Iteration 4188500, lr = 0.01
I0901 07:11:30.449663 916722 solver.cpp:218] Iteration 4189000 (16.8 iter/s, 29.7618s/500 iters), loss = 0.150214
I0901 07:11:30.449719 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.150217 (* 1 = 0.150217 loss)
I0901 07:11:30.449728 916722 sgd_solver.cpp:106] Iteration 4189000, lr = 0.01
I0901 07:12:00.210934 916722 solver.cpp:218] Iteration 4189500 (16.8007 iter/s, 29.7607s/500 iters), loss = 0.16912
I0901 07:12:00.210985 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.169123 (* 1 = 0.169123 loss)
I0901 07:12:00.210995 916722 sgd_solver.cpp:106] Iteration 4189500, lr = 0.01
I0901 07:12:29.971155 916722 solver.cpp:218] Iteration 4190000 (16.8013 iter/s, 29.7596s/500 iters), loss = 0.0665764
I0901 07:12:29.971216 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0665793 (* 1 = 0.0665793 loss)
I0901 07:12:29.971225 916722 sgd_solver.cpp:106] Iteration 4190000, lr = 0.01
I0901 07:12:59.733944 916722 solver.cpp:218] Iteration 4190500 (16.7998 iter/s, 29.7622s/500 iters), loss = 0.120549
I0901 07:12:59.733999 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.120552 (* 1 = 0.120552 loss)
I0901 07:12:59.734009 916722 sgd_solver.cpp:106] Iteration 4190500, lr = 0.01
I0901 07:13:29.499361 916722 solver.cpp:218] Iteration 4191000 (16.7983 iter/s, 29.7649s/500 iters), loss = 0.147366
I0901 07:13:29.499434 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.147369 (* 1 = 0.147369 loss)
I0901 07:13:29.499444 916722 sgd_solver.cpp:106] Iteration 4191000, lr = 0.01
I0901 07:13:59.261914 916722 solver.cpp:218] Iteration 4191500 (16.7999 iter/s, 29.762s/500 iters), loss = 0.0371679
I0901 07:13:59.261965 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0371709 (* 1 = 0.0371709 loss)
I0901 07:13:59.261974 916722 sgd_solver.cpp:106] Iteration 4191500, lr = 0.01
I0901 07:14:29.025106 916722 solver.cpp:218] Iteration 4192000 (16.7996 iter/s, 29.7627s/500 iters), loss = 0.101938
I0901 07:14:29.025166 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101941 (* 1 = 0.101941 loss)
I0901 07:14:29.025173 916722 sgd_solver.cpp:106] Iteration 4192000, lr = 0.01
I0901 07:14:58.787254 916722 solver.cpp:218] Iteration 4192500 (16.8001 iter/s, 29.7616s/500 iters), loss = 0.0740875
I0901 07:14:58.787305 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0740907 (* 1 = 0.0740907 loss)
I0901 07:14:58.787314 916722 sgd_solver.cpp:106] Iteration 4192500, lr = 0.01
I0901 07:15:28.553750 916722 solver.cpp:218] Iteration 4193000 (16.7977 iter/s, 29.766s/500 iters), loss = 0.288026
I0901 07:15:28.553807 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.288029 (* 1 = 0.288029 loss)
I0901 07:15:28.553817 916722 sgd_solver.cpp:106] Iteration 4193000, lr = 0.01
I0901 07:15:58.316571 916722 solver.cpp:218] Iteration 4193500 (16.7997 iter/s, 29.7624s/500 iters), loss = 0.342779
I0901 07:15:58.316622 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.342782 (* 1 = 0.342782 loss)
I0901 07:15:58.316630 916722 sgd_solver.cpp:106] Iteration 4193500, lr = 0.01
I0901 07:16:28.079349 916722 solver.cpp:218] Iteration 4194000 (16.7998 iter/s, 29.7623s/500 iters), loss = 0.0505355
I0901 07:16:28.079413 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0505388 (* 1 = 0.0505388 loss)
I0901 07:16:28.079422 916722 sgd_solver.cpp:106] Iteration 4194000, lr = 0.01
I0901 07:16:57.841430 916722 solver.cpp:218] Iteration 4194500 (16.8002 iter/s, 29.7616s/500 iters), loss = 0.0527649
I0901 07:16:57.841487 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0527684 (* 1 = 0.0527684 loss)
I0901 07:16:57.841496 916722 sgd_solver.cpp:106] Iteration 4194500, lr = 0.01
I0901 07:17:27.603397 916722 solver.cpp:218] Iteration 4195000 (16.8002 iter/s, 29.7615s/500 iters), loss = 0.104426
I0901 07:17:27.603459 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.10443 (* 1 = 0.10443 loss)
I0901 07:17:27.603468 916722 sgd_solver.cpp:106] Iteration 4195000, lr = 0.01
I0901 07:17:57.365200 916722 solver.cpp:218] Iteration 4195500 (16.8003 iter/s, 29.7614s/500 iters), loss = 0.126012
I0901 07:17:57.365252 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.126016 (* 1 = 0.126016 loss)
I0901 07:17:57.365260 916722 sgd_solver.cpp:106] Iteration 4195500, lr = 0.01
I0901 07:18:27.127437 916722 solver.cpp:218] Iteration 4196000 (16.8 iter/s, 29.7618s/500 iters), loss = 0.171992
I0901 07:18:27.127497 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.171996 (* 1 = 0.171996 loss)
I0901 07:18:27.127506 916722 sgd_solver.cpp:106] Iteration 4196000, lr = 0.01
I0901 07:18:56.890257 916722 solver.cpp:218] Iteration 4196500 (16.7997 iter/s, 29.7624s/500 iters), loss = 0.0531161
I0901 07:18:56.890309 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0531199 (* 1 = 0.0531199 loss)
I0901 07:18:56.890321 916722 sgd_solver.cpp:106] Iteration 4196500, lr = 0.01
I0901 07:19:26.653471 916722 solver.cpp:218] Iteration 4197000 (16.7995 iter/s, 29.7628s/500 iters), loss = 0.216947
I0901 07:19:26.653537 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.216951 (* 1 = 0.216951 loss)
I0901 07:19:26.653546 916722 sgd_solver.cpp:106] Iteration 4197000, lr = 0.01
I0901 07:19:56.418334 916722 solver.cpp:218] Iteration 4197500 (16.7985 iter/s, 29.7645s/500 iters), loss = 0.0403
I0901 07:19:56.418391 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0403037 (* 1 = 0.0403037 loss)
I0901 07:19:56.418401 916722 sgd_solver.cpp:106] Iteration 4197500, lr = 0.01
I0901 07:20:26.181658 916722 solver.cpp:218] Iteration 4198000 (16.7994 iter/s, 29.763s/500 iters), loss = 0.093017
I0901 07:20:26.181720 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0930207 (* 1 = 0.0930207 loss)
I0901 07:20:26.181730 916722 sgd_solver.cpp:106] Iteration 4198000, lr = 0.01
I0901 07:20:55.943657 916722 solver.cpp:218] Iteration 4198500 (16.8001 iter/s, 29.7616s/500 iters), loss = 0.256405
I0901 07:20:55.943712 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.256409 (* 1 = 0.256409 loss)
I0901 07:20:55.943722 916722 sgd_solver.cpp:106] Iteration 4198500, lr = 0.01
I0901 07:21:25.706017 916722 solver.cpp:218] Iteration 4199000 (16.7999 iter/s, 29.762s/500 iters), loss = 0.0585767
I0901 07:21:25.706080 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0585803 (* 1 = 0.0585803 loss)
I0901 07:21:25.706089 916722 sgd_solver.cpp:106] Iteration 4199000, lr = 0.01
I0901 07:21:55.467998 916722 solver.cpp:218] Iteration 4199500 (16.8001 iter/s, 29.7616s/500 iters), loss = 0.403797
I0901 07:21:55.468046 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.403801 (* 1 = 0.403801 loss)
I0901 07:21:55.468055 916722 sgd_solver.cpp:106] Iteration 4199500, lr = 0.01
I0901 07:22:25.171500 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_4200000.caffemodel
I0901 07:22:25.190923 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_4200000.solverstate
I0901 07:22:25.196954 916722 solver.cpp:330] Iteration 4200000, Testing net (#0)
I0901 07:22:40.668597 916722 solver.cpp:397]     Test net output #0: accuracy = 0.9075
I0901 07:22:40.668643 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.330305 (* 1 = 0.330305 loss)
I0901 07:22:40.727327 916722 solver.cpp:218] Iteration 4200000 (11.0476 iter/s, 45.2589s/500 iters), loss = 0.107081
I0901 07:22:40.727356 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.107085 (* 1 = 0.107085 loss)
I0901 07:22:40.727365 916722 sgd_solver.cpp:106] Iteration 4200000, lr = 0.01
I0901 07:23:10.360486 916722 solver.cpp:218] Iteration 4200500 (16.8732 iter/s, 29.6328s/500 iters), loss = 0.129715
I0901 07:23:10.360548 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.129718 (* 1 = 0.129718 loss)
I0901 07:23:10.360556 916722 sgd_solver.cpp:106] Iteration 4200500, lr = 0.01
I0901 07:23:40.019711 916722 solver.cpp:218] Iteration 4201000 (16.8584 iter/s, 29.6589s/500 iters), loss = 0.311769
I0901 07:23:40.019766 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.311773 (* 1 = 0.311773 loss)
I0901 07:23:40.019776 916722 sgd_solver.cpp:106] Iteration 4201000, lr = 0.01
I0901 07:24:09.778568 916722 solver.cpp:218] Iteration 4201500 (16.8019 iter/s, 29.7585s/500 iters), loss = 0.123144
I0901 07:24:09.778626 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.123148 (* 1 = 0.123148 loss)
I0901 07:24:09.778635 916722 sgd_solver.cpp:106] Iteration 4201500, lr = 0.01
I0901 07:24:39.537897 916722 solver.cpp:218] Iteration 4202000 (16.8016 iter/s, 29.759s/500 iters), loss = 0.414631
I0901 07:24:39.537947 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.414634 (* 1 = 0.414634 loss)
I0901 07:24:39.537957 916722 sgd_solver.cpp:106] Iteration 4202000, lr = 0.01
I0901 07:25:09.300900 916722 solver.cpp:218] Iteration 4202500 (16.7996 iter/s, 29.7627s/500 iters), loss = 0.0190599
I0901 07:25:09.300968 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0190635 (* 1 = 0.0190635 loss)
I0901 07:25:09.300977 916722 sgd_solver.cpp:106] Iteration 4202500, lr = 0.01
I0901 07:25:39.061347 916722 solver.cpp:218] Iteration 4203000 (16.801 iter/s, 29.7601s/500 iters), loss = 0.194261
I0901 07:25:39.061401 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.194264 (* 1 = 0.194264 loss)
I0901 07:25:39.061412 916722 sgd_solver.cpp:106] Iteration 4203000, lr = 0.01
I0901 07:26:08.817525 916722 solver.cpp:218] Iteration 4203500 (16.8034 iter/s, 29.7559s/500 iters), loss = 0.162113
I0901 07:26:08.817581 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.162117 (* 1 = 0.162117 loss)
I0901 07:26:08.817590 916722 sgd_solver.cpp:106] Iteration 4203500, lr = 0.01
I0901 07:26:38.578383 916722 solver.cpp:218] Iteration 4204000 (16.8008 iter/s, 29.7606s/500 iters), loss = 0.287796
I0901 07:26:38.578436 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.287799 (* 1 = 0.287799 loss)
I0901 07:26:38.578447 916722 sgd_solver.cpp:106] Iteration 4204000, lr = 0.01
I0901 07:27:08.339942 916722 solver.cpp:218] Iteration 4204500 (16.8004 iter/s, 29.7613s/500 iters), loss = 0.205126
I0901 07:27:08.339998 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.205129 (* 1 = 0.205129 loss)
I0901 07:27:08.340008 916722 sgd_solver.cpp:106] Iteration 4204500, lr = 0.01
I0901 07:27:38.104032 916722 solver.cpp:218] Iteration 4205000 (16.7989 iter/s, 29.7638s/500 iters), loss = 0.132089
I0901 07:27:38.104084 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.132092 (* 1 = 0.132092 loss)
I0901 07:27:38.104094 916722 sgd_solver.cpp:106] Iteration 4205000, lr = 0.01
I0901 07:28:07.869485 916722 solver.cpp:218] Iteration 4205500 (16.7982 iter/s, 29.7652s/500 iters), loss = 0.136808
I0901 07:28:07.869545 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.136812 (* 1 = 0.136812 loss)
I0901 07:28:07.869554 916722 sgd_solver.cpp:106] Iteration 4205500, lr = 0.01
I0901 07:28:37.633764 916722 solver.cpp:218] Iteration 4206000 (16.7988 iter/s, 29.764s/500 iters), loss = 0.159089
I0901 07:28:37.633814 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159093 (* 1 = 0.159093 loss)
I0901 07:28:37.633823 916722 sgd_solver.cpp:106] Iteration 4206000, lr = 0.01
I0901 07:29:07.401854 916722 solver.cpp:218] Iteration 4206500 (16.7967 iter/s, 29.7678s/500 iters), loss = 0.105672
I0901 07:29:07.401911 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105676 (* 1 = 0.105676 loss)
I0901 07:29:07.401921 916722 sgd_solver.cpp:106] Iteration 4206500, lr = 0.01
I0901 07:29:37.165169 916722 solver.cpp:218] Iteration 4207000 (16.7994 iter/s, 29.763s/500 iters), loss = 0.124908
I0901 07:29:37.165218 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.124912 (* 1 = 0.124912 loss)
I0901 07:29:37.165226 916722 sgd_solver.cpp:106] Iteration 4207000, lr = 0.01
I0901 07:30:06.929999 916722 solver.cpp:218] Iteration 4207500 (16.7985 iter/s, 29.7646s/500 iters), loss = 0.348547
I0901 07:30:06.930058 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.348551 (* 1 = 0.348551 loss)
I0901 07:30:06.930068 916722 sgd_solver.cpp:106] Iteration 4207500, lr = 0.01
I0901 07:30:36.691756 916722 solver.cpp:218] Iteration 4208000 (16.8002 iter/s, 29.7615s/500 iters), loss = 0.181004
I0901 07:30:36.691810 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.181008 (* 1 = 0.181008 loss)
I0901 07:30:36.691819 916722 sgd_solver.cpp:106] Iteration 4208000, lr = 0.01
I0901 07:31:06.455207 916722 solver.cpp:218] Iteration 4208500 (16.7993 iter/s, 29.7632s/500 iters), loss = 0.150457
I0901 07:31:06.455265 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.150461 (* 1 = 0.150461 loss)
I0901 07:31:06.455273 916722 sgd_solver.cpp:106] Iteration 4208500, lr = 0.01
I0901 07:31:36.217433 916722 solver.cpp:218] Iteration 4209000 (16.8 iter/s, 29.762s/500 iters), loss = 0.0632431
I0901 07:31:36.217487 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.063247 (* 1 = 0.063247 loss)
I0901 07:31:36.217506 916722 sgd_solver.cpp:106] Iteration 4209000, lr = 0.01
I0901 07:32:05.977825 916722 solver.cpp:218] Iteration 4209500 (16.801 iter/s, 29.7601s/500 iters), loss = 0.14288
I0901 07:32:05.977893 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.142884 (* 1 = 0.142884 loss)
I0901 07:32:05.977902 916722 sgd_solver.cpp:106] Iteration 4209500, lr = 0.01
I0901 07:32:35.742882 916722 solver.cpp:218] Iteration 4210000 (16.7984 iter/s, 29.7648s/500 iters), loss = 0.172349
I0901 07:32:35.742936 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.172353 (* 1 = 0.172353 loss)
I0901 07:32:35.742946 916722 sgd_solver.cpp:106] Iteration 4210000, lr = 0.01
I0901 07:33:05.481962 916722 solver.cpp:218] Iteration 4210500 (16.813 iter/s, 29.7388s/500 iters), loss = 0.0995533
I0901 07:33:05.482018 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0995574 (* 1 = 0.0995574 loss)
I0901 07:33:05.482028 916722 sgd_solver.cpp:106] Iteration 4210500, lr = 0.01
I0901 07:33:35.219415 916722 solver.cpp:218] Iteration 4211000 (16.814 iter/s, 29.7372s/500 iters), loss = 0.0823619
I0901 07:33:35.219470 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.082366 (* 1 = 0.082366 loss)
I0901 07:33:35.219481 916722 sgd_solver.cpp:106] Iteration 4211000, lr = 0.01
I0901 07:34:04.963152 916722 solver.cpp:218] Iteration 4211500 (16.8104 iter/s, 29.7435s/500 iters), loss = 0.129058
I0901 07:34:04.963208 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.129063 (* 1 = 0.129063 loss)
I0901 07:34:04.963217 916722 sgd_solver.cpp:106] Iteration 4211500, lr = 0.01
I0901 07:34:34.713681 916722 solver.cpp:218] Iteration 4212000 (16.8066 iter/s, 29.7503s/500 iters), loss = 0.23321
I0901 07:34:34.713737 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.233214 (* 1 = 0.233214 loss)
I0901 07:34:34.713747 916722 sgd_solver.cpp:106] Iteration 4212000, lr = 0.01
I0901 07:35:04.457569 916722 solver.cpp:218] Iteration 4212500 (16.8103 iter/s, 29.7436s/500 iters), loss = 0.124387
I0901 07:35:04.457628 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.124391 (* 1 = 0.124391 loss)
I0901 07:35:04.457636 916722 sgd_solver.cpp:106] Iteration 4212500, lr = 0.01
I0901 07:35:34.202726 916722 solver.cpp:218] Iteration 4213000 (16.8096 iter/s, 29.7449s/500 iters), loss = 0.0768824
I0901 07:35:34.202780 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0768867 (* 1 = 0.0768867 loss)
I0901 07:35:34.202790 916722 sgd_solver.cpp:106] Iteration 4213000, lr = 0.01
I0901 07:36:03.946218 916722 solver.cpp:218] Iteration 4213500 (16.8105 iter/s, 29.7432s/500 iters), loss = 0.0547633
I0901 07:36:03.946274 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0547675 (* 1 = 0.0547675 loss)
I0901 07:36:03.946283 916722 sgd_solver.cpp:106] Iteration 4213500, lr = 0.01
I0901 07:36:33.691886 916722 solver.cpp:218] Iteration 4214000 (16.8093 iter/s, 29.7454s/500 iters), loss = 0.0438651
I0901 07:36:33.691939 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0438695 (* 1 = 0.0438695 loss)
I0901 07:36:33.691949 916722 sgd_solver.cpp:106] Iteration 4214000, lr = 0.01
I0901 07:37:03.432735 916722 solver.cpp:218] Iteration 4214500 (16.812 iter/s, 29.7406s/500 iters), loss = 0.297461
I0901 07:37:03.432791 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.297466 (* 1 = 0.297466 loss)
I0901 07:37:03.432801 916722 sgd_solver.cpp:106] Iteration 4214500, lr = 0.01
I0901 07:37:33.173775 916722 solver.cpp:218] Iteration 4215000 (16.8119 iter/s, 29.7408s/500 iters), loss = 0.116699
I0901 07:37:33.173826 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.116703 (* 1 = 0.116703 loss)
I0901 07:37:33.173837 916722 sgd_solver.cpp:106] Iteration 4215000, lr = 0.01
I0901 07:38:02.917495 916722 solver.cpp:218] Iteration 4215500 (16.8104 iter/s, 29.7435s/500 iters), loss = 0.415368
I0901 07:38:02.917563 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.415372 (* 1 = 0.415372 loss)
I0901 07:38:02.917577 916722 sgd_solver.cpp:106] Iteration 4215500, lr = 0.01
I0901 07:38:32.661514 916722 solver.cpp:218] Iteration 4216000 (16.8102 iter/s, 29.7438s/500 iters), loss = 0.107689
I0901 07:38:32.661564 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.107693 (* 1 = 0.107693 loss)
I0901 07:38:32.661574 916722 sgd_solver.cpp:106] Iteration 4216000, lr = 0.01
I0901 07:39:02.405372 916722 solver.cpp:218] Iteration 4216500 (16.8103 iter/s, 29.7436s/500 iters), loss = 0.0346379
I0901 07:39:02.405431 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0346422 (* 1 = 0.0346422 loss)
I0901 07:39:02.405439 916722 sgd_solver.cpp:106] Iteration 4216500, lr = 0.01
I0901 07:39:32.147735 916722 solver.cpp:218] Iteration 4217000 (16.8112 iter/s, 29.7421s/500 iters), loss = 0.150792
I0901 07:39:32.147789 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.150796 (* 1 = 0.150796 loss)
I0901 07:39:32.147800 916722 sgd_solver.cpp:106] Iteration 4217000, lr = 0.01
I0901 07:40:01.894086 916722 solver.cpp:218] Iteration 4217500 (16.8089 iter/s, 29.7461s/500 iters), loss = 0.253217
I0901 07:40:01.894142 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.253221 (* 1 = 0.253221 loss)
I0901 07:40:01.894151 916722 sgd_solver.cpp:106] Iteration 4217500, lr = 0.01
I0901 07:40:31.643589 916722 solver.cpp:218] Iteration 4218000 (16.8071 iter/s, 29.7493s/500 iters), loss = 0.0833001
I0901 07:40:31.643643 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0833041 (* 1 = 0.0833041 loss)
I0901 07:40:31.643654 916722 sgd_solver.cpp:106] Iteration 4218000, lr = 0.01
I0901 07:41:01.393134 916722 solver.cpp:218] Iteration 4218500 (16.8071 iter/s, 29.7493s/500 iters), loss = 0.34483
I0901 07:41:01.393191 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.344834 (* 1 = 0.344834 loss)
I0901 07:41:01.393200 916722 sgd_solver.cpp:106] Iteration 4218500, lr = 0.01
I0901 07:41:31.140555 916722 solver.cpp:218] Iteration 4219000 (16.8079 iter/s, 29.7478s/500 iters), loss = 0.100657
I0901 07:41:31.140607 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.100661 (* 1 = 0.100661 loss)
I0901 07:41:31.140616 916722 sgd_solver.cpp:106] Iteration 4219000, lr = 0.01
I0901 07:42:00.888999 916722 solver.cpp:218] Iteration 4219500 (16.8074 iter/s, 29.7489s/500 iters), loss = 0.216299
I0901 07:42:00.889053 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.216303 (* 1 = 0.216303 loss)
I0901 07:42:00.889061 916722 sgd_solver.cpp:106] Iteration 4219500, lr = 0.01
I0901 07:42:30.632009 916722 solver.cpp:218] Iteration 4220000 (16.8105 iter/s, 29.7434s/500 iters), loss = 0.146623
I0901 07:42:30.632058 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.146627 (* 1 = 0.146627 loss)
I0901 07:42:30.632067 916722 sgd_solver.cpp:106] Iteration 4220000, lr = 0.01
I0901 07:43:00.376981 916722 solver.cpp:218] Iteration 4220500 (16.8094 iter/s, 29.7453s/500 iters), loss = 0.0949131
I0901 07:43:00.377039 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.094917 (* 1 = 0.094917 loss)
I0901 07:43:00.377048 916722 sgd_solver.cpp:106] Iteration 4220500, lr = 0.01
I0901 07:43:30.120096 916722 solver.cpp:218] Iteration 4221000 (16.8104 iter/s, 29.7434s/500 iters), loss = 0.0493567
I0901 07:43:30.120152 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0493607 (* 1 = 0.0493607 loss)
I0901 07:43:30.120162 916722 sgd_solver.cpp:106] Iteration 4221000, lr = 0.01
I0901 07:43:59.862326 916722 solver.cpp:218] Iteration 4221500 (16.8109 iter/s, 29.7425s/500 iters), loss = 0.362096
I0901 07:43:59.862390 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.3621 (* 1 = 0.3621 loss)
I0901 07:43:59.862398 916722 sgd_solver.cpp:106] Iteration 4221500, lr = 0.01
I0901 07:44:29.605429 916722 solver.cpp:218] Iteration 4222000 (16.8105 iter/s, 29.7434s/500 iters), loss = 0.2033
I0901 07:44:29.605481 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.203304 (* 1 = 0.203304 loss)
I0901 07:44:29.605490 916722 sgd_solver.cpp:106] Iteration 4222000, lr = 0.01
I0901 07:44:59.352381 916722 solver.cpp:218] Iteration 4222500 (16.8083 iter/s, 29.7472s/500 iters), loss = 0.084388
I0901 07:44:59.352456 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0843921 (* 1 = 0.0843921 loss)
I0901 07:44:59.352465 916722 sgd_solver.cpp:106] Iteration 4222500, lr = 0.01
I0901 07:45:29.096827 916722 solver.cpp:218] Iteration 4223000 (16.8097 iter/s, 29.7447s/500 iters), loss = 0.0983556
I0901 07:45:29.096881 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0983597 (* 1 = 0.0983597 loss)
I0901 07:45:29.096891 916722 sgd_solver.cpp:106] Iteration 4223000, lr = 0.01
I0901 07:45:58.839998 916722 solver.cpp:218] Iteration 4223500 (16.8105 iter/s, 29.7434s/500 iters), loss = 0.244566
I0901 07:45:58.840051 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.24457 (* 1 = 0.24457 loss)
I0901 07:45:58.840059 916722 sgd_solver.cpp:106] Iteration 4223500, lr = 0.01
I0901 07:46:28.582257 916722 solver.cpp:218] Iteration 4224000 (16.811 iter/s, 29.7425s/500 iters), loss = 0.0461963
I0901 07:46:28.582310 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0462006 (* 1 = 0.0462006 loss)
I0901 07:46:28.582321 916722 sgd_solver.cpp:106] Iteration 4224000, lr = 0.01
I0901 07:46:58.328003 916722 solver.cpp:218] Iteration 4224500 (16.809 iter/s, 29.7459s/500 iters), loss = 0.134977
I0901 07:46:58.328055 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.134981 (* 1 = 0.134981 loss)
I0901 07:46:58.328063 916722 sgd_solver.cpp:106] Iteration 4224500, lr = 0.01
I0901 07:47:28.074206 916722 solver.cpp:218] Iteration 4225000 (16.8088 iter/s, 29.7464s/500 iters), loss = 0.119913
I0901 07:47:28.074263 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.119917 (* 1 = 0.119917 loss)
I0901 07:47:28.074275 916722 sgd_solver.cpp:106] Iteration 4225000, lr = 0.01
I0901 07:47:57.818802 916722 solver.cpp:218] Iteration 4225500 (16.8097 iter/s, 29.7447s/500 iters), loss = 0.137116
I0901 07:47:57.818861 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.137121 (* 1 = 0.137121 loss)
I0901 07:47:57.818868 916722 sgd_solver.cpp:106] Iteration 4225500, lr = 0.01
I0901 07:48:27.560539 916722 solver.cpp:218] Iteration 4226000 (16.8113 iter/s, 29.7419s/500 iters), loss = 0.127014
I0901 07:48:27.560592 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.127018 (* 1 = 0.127018 loss)
I0901 07:48:27.560603 916722 sgd_solver.cpp:106] Iteration 4226000, lr = 0.01
I0901 07:48:57.305629 916722 solver.cpp:218] Iteration 4226500 (16.8094 iter/s, 29.7452s/500 iters), loss = 0.0793244
I0901 07:48:57.305686 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0793287 (* 1 = 0.0793287 loss)
I0901 07:48:57.305696 916722 sgd_solver.cpp:106] Iteration 4226500, lr = 0.01
I0901 07:49:27.048447 916722 solver.cpp:218] Iteration 4227000 (16.8107 iter/s, 29.7429s/500 iters), loss = 0.0199497
I0901 07:49:27.048513 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.019954 (* 1 = 0.019954 loss)
I0901 07:49:27.048524 916722 sgd_solver.cpp:106] Iteration 4227000, lr = 0.01
I0901 07:49:56.792956 916722 solver.cpp:218] Iteration 4227500 (16.8098 iter/s, 29.7446s/500 iters), loss = 0.389789
I0901 07:49:56.793010 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.389794 (* 1 = 0.389794 loss)
I0901 07:49:56.793018 916722 sgd_solver.cpp:106] Iteration 4227500, lr = 0.01
I0901 07:50:26.536979 916722 solver.cpp:218] Iteration 4228000 (16.81 iter/s, 29.7441s/500 iters), loss = 0.247872
I0901 07:50:26.537032 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.247876 (* 1 = 0.247876 loss)
I0901 07:50:26.537042 916722 sgd_solver.cpp:106] Iteration 4228000, lr = 0.01
I0901 07:50:56.277046 916722 solver.cpp:218] Iteration 4228500 (16.8123 iter/s, 29.7401s/500 iters), loss = 0.145255
I0901 07:50:56.277105 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.145259 (* 1 = 0.145259 loss)
I0901 07:50:56.277114 916722 sgd_solver.cpp:106] Iteration 4228500, lr = 0.01
I0901 07:51:26.014600 916722 solver.cpp:218] Iteration 4229000 (16.8137 iter/s, 29.7376s/500 iters), loss = 0.164552
I0901 07:51:26.014652 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.164556 (* 1 = 0.164556 loss)
I0901 07:51:26.014662 916722 sgd_solver.cpp:106] Iteration 4229000, lr = 0.01
I0901 07:51:55.754190 916722 solver.cpp:218] Iteration 4229500 (16.8126 iter/s, 29.7396s/500 iters), loss = 0.0515343
I0901 07:51:55.754264 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0515383 (* 1 = 0.0515383 loss)
I0901 07:51:55.754273 916722 sgd_solver.cpp:106] Iteration 4229500, lr = 0.01
I0901 07:52:25.491115 916722 solver.cpp:218] Iteration 4230000 (16.8141 iter/s, 29.7369s/500 iters), loss = 0.11221
I0901 07:52:25.491166 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112213 (* 1 = 0.112213 loss)
I0901 07:52:25.491175 916722 sgd_solver.cpp:106] Iteration 4230000, lr = 0.01
I0901 07:52:55.226846 916722 solver.cpp:218] Iteration 4230500 (16.8148 iter/s, 29.7358s/500 iters), loss = 0.153674
I0901 07:52:55.226903 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.153678 (* 1 = 0.153678 loss)
I0901 07:52:55.226912 916722 sgd_solver.cpp:106] Iteration 4230500, lr = 0.01
I0901 07:53:24.964645 916722 solver.cpp:218] Iteration 4231000 (16.8136 iter/s, 29.7378s/500 iters), loss = 0.219386
I0901 07:53:24.964696 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.21939 (* 1 = 0.21939 loss)
I0901 07:53:24.964705 916722 sgd_solver.cpp:106] Iteration 4231000, lr = 0.01
I0901 07:53:54.699563 916722 solver.cpp:218] Iteration 4231500 (16.8152 iter/s, 29.7349s/500 iters), loss = 0.124551
I0901 07:53:54.699618 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.124555 (* 1 = 0.124555 loss)
I0901 07:53:54.699626 916722 sgd_solver.cpp:106] Iteration 4231500, lr = 0.01
I0901 07:54:24.438017 916722 solver.cpp:218] Iteration 4232000 (16.8132 iter/s, 29.7385s/500 iters), loss = 0.124337
I0901 07:54:24.438066 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.124341 (* 1 = 0.124341 loss)
I0901 07:54:24.438076 916722 sgd_solver.cpp:106] Iteration 4232000, lr = 0.01
I0901 07:54:54.176224 916722 solver.cpp:218] Iteration 4232500 (16.8134 iter/s, 29.7382s/500 iters), loss = 0.0266951
I0901 07:54:54.176287 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0266992 (* 1 = 0.0266992 loss)
I0901 07:54:54.176296 916722 sgd_solver.cpp:106] Iteration 4232500, lr = 0.01
I0901 07:55:23.915412 916722 solver.cpp:218] Iteration 4233000 (16.8128 iter/s, 29.7392s/500 iters), loss = 0.0286342
I0901 07:55:23.915465 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0286383 (* 1 = 0.0286383 loss)
I0901 07:55:23.915474 916722 sgd_solver.cpp:106] Iteration 4233000, lr = 0.01
I0901 07:55:53.648828 916722 solver.cpp:218] Iteration 4233500 (16.8161 iter/s, 29.7334s/500 iters), loss = 0.16125
I0901 07:55:53.648890 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.161254 (* 1 = 0.161254 loss)
I0901 07:55:53.648898 916722 sgd_solver.cpp:106] Iteration 4233500, lr = 0.01
I0901 07:56:23.381940 916722 solver.cpp:218] Iteration 4234000 (16.8163 iter/s, 29.7331s/500 iters), loss = 0.10302
I0901 07:56:23.381992 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.103024 (* 1 = 0.103024 loss)
I0901 07:56:23.382001 916722 sgd_solver.cpp:106] Iteration 4234000, lr = 0.01
I0901 07:56:53.117516 916722 solver.cpp:218] Iteration 4234500 (16.8149 iter/s, 29.7356s/500 iters), loss = 0.156762
I0901 07:56:53.117585 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.156766 (* 1 = 0.156766 loss)
I0901 07:56:53.117594 916722 sgd_solver.cpp:106] Iteration 4234500, lr = 0.01
I0901 07:57:22.850270 916722 solver.cpp:218] Iteration 4235000 (16.8165 iter/s, 29.7327s/500 iters), loss = 0.244129
I0901 07:57:22.850322 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.244133 (* 1 = 0.244133 loss)
I0901 07:57:22.850330 916722 sgd_solver.cpp:106] Iteration 4235000, lr = 0.01
I0901 07:57:52.584985 916722 solver.cpp:218] Iteration 4235500 (16.8154 iter/s, 29.7347s/500 iters), loss = 0.139332
I0901 07:57:52.585057 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139336 (* 1 = 0.139336 loss)
I0901 07:57:52.585065 916722 sgd_solver.cpp:106] Iteration 4235500, lr = 0.01
I0901 07:58:22.319380 916722 solver.cpp:218] Iteration 4236000 (16.8156 iter/s, 29.7343s/500 iters), loss = 0.0384467
I0901 07:58:22.319432 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0384508 (* 1 = 0.0384508 loss)
I0901 07:58:22.319442 916722 sgd_solver.cpp:106] Iteration 4236000, lr = 0.01
I0901 07:58:52.056950 916722 solver.cpp:218] Iteration 4236500 (16.8138 iter/s, 29.7375s/500 iters), loss = 0.0646212
I0901 07:58:52.057006 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0646253 (* 1 = 0.0646253 loss)
I0901 07:58:52.057015 916722 sgd_solver.cpp:106] Iteration 4236500, lr = 0.01
I0901 07:59:21.790959 916722 solver.cpp:218] Iteration 4237000 (16.8158 iter/s, 29.734s/500 iters), loss = 0.170745
I0901 07:59:21.791013 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.170749 (* 1 = 0.170749 loss)
I0901 07:59:21.791023 916722 sgd_solver.cpp:106] Iteration 4237000, lr = 0.01
I0901 07:59:51.524960 916722 solver.cpp:218] Iteration 4237500 (16.8158 iter/s, 29.734s/500 iters), loss = 0.0238763
I0901 07:59:51.525022 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0238804 (* 1 = 0.0238804 loss)
I0901 07:59:51.525030 916722 sgd_solver.cpp:106] Iteration 4237500, lr = 0.01
I0901 08:00:21.262018 916722 solver.cpp:218] Iteration 4238000 (16.8141 iter/s, 29.737s/500 iters), loss = 0.217807
I0901 08:00:21.262070 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.217811 (* 1 = 0.217811 loss)
I0901 08:00:21.262080 916722 sgd_solver.cpp:106] Iteration 4238000, lr = 0.01
I0901 08:00:50.995641 916722 solver.cpp:218] Iteration 4238500 (16.816 iter/s, 29.7336s/500 iters), loss = 0.217183
I0901 08:00:50.995700 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.217187 (* 1 = 0.217187 loss)
I0901 08:00:50.995709 916722 sgd_solver.cpp:106] Iteration 4238500, lr = 0.01
I0901 08:01:20.728302 916722 solver.cpp:218] Iteration 4239000 (16.8166 iter/s, 29.7326s/500 iters), loss = 0.17961
I0901 08:01:20.728353 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.179614 (* 1 = 0.179614 loss)
I0901 08:01:20.728363 916722 sgd_solver.cpp:106] Iteration 4239000, lr = 0.01
I0901 08:01:50.459317 916722 solver.cpp:218] Iteration 4239500 (16.8175 iter/s, 29.731s/500 iters), loss = 0.185892
I0901 08:01:50.459374 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.185896 (* 1 = 0.185896 loss)
I0901 08:01:50.459383 916722 sgd_solver.cpp:106] Iteration 4239500, lr = 0.01
I0901 08:02:20.190043 916722 solver.cpp:218] Iteration 4240000 (16.8177 iter/s, 29.7307s/500 iters), loss = 0.306917
I0901 08:02:20.190093 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.306921 (* 1 = 0.306921 loss)
I0901 08:02:20.190102 916722 sgd_solver.cpp:106] Iteration 4240000, lr = 0.01
I0901 08:02:49.919919 916722 solver.cpp:218] Iteration 4240500 (16.8181 iter/s, 29.7298s/500 iters), loss = 0.0905865
I0901 08:02:49.919973 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0905907 (* 1 = 0.0905907 loss)
I0901 08:02:49.919981 916722 sgd_solver.cpp:106] Iteration 4240500, lr = 0.01
I0901 08:03:19.653030 916722 solver.cpp:218] Iteration 4241000 (16.8163 iter/s, 29.733s/500 iters), loss = 0.174728
I0901 08:03:19.653080 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.174732 (* 1 = 0.174732 loss)
I0901 08:03:19.653090 916722 sgd_solver.cpp:106] Iteration 4241000, lr = 0.01
I0901 08:03:49.387411 916722 solver.cpp:218] Iteration 4241500 (16.8156 iter/s, 29.7343s/500 iters), loss = 0.0719918
I0901 08:03:49.387470 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0719962 (* 1 = 0.0719962 loss)
I0901 08:03:49.387478 916722 sgd_solver.cpp:106] Iteration 4241500, lr = 0.01
I0901 08:04:19.117816 916722 solver.cpp:218] Iteration 4242000 (16.8178 iter/s, 29.7303s/500 iters), loss = 0.120848
I0901 08:04:19.117880 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.120852 (* 1 = 0.120852 loss)
I0901 08:04:19.117890 916722 sgd_solver.cpp:106] Iteration 4242000, lr = 0.01
I0901 08:04:48.851876 916722 solver.cpp:218] Iteration 4242500 (16.8158 iter/s, 29.734s/500 iters), loss = 0.406662
I0901 08:04:48.851949 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.406666 (* 1 = 0.406666 loss)
I0901 08:04:48.851958 916722 sgd_solver.cpp:106] Iteration 4242500, lr = 0.01
I0901 08:05:18.583597 916722 solver.cpp:218] Iteration 4243000 (16.8171 iter/s, 29.7316s/500 iters), loss = 0.0889693
I0901 08:05:18.583649 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0889734 (* 1 = 0.0889734 loss)
I0901 08:05:18.583658 916722 sgd_solver.cpp:106] Iteration 4243000, lr = 0.01
I0901 08:05:48.316915 916722 solver.cpp:218] Iteration 4243500 (16.8162 iter/s, 29.7332s/500 iters), loss = 0.0327575
I0901 08:05:48.316973 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0327617 (* 1 = 0.0327617 loss)
I0901 08:05:48.316982 916722 sgd_solver.cpp:106] Iteration 4243500, lr = 0.01
I0901 08:06:18.047360 916722 solver.cpp:218] Iteration 4244000 (16.8178 iter/s, 29.7304s/500 iters), loss = 0.00742222
I0901 08:06:18.047411 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0074264 (* 1 = 0.0074264 loss)
I0901 08:06:18.047420 916722 sgd_solver.cpp:106] Iteration 4244000, lr = 0.01
I0901 08:06:47.780537 916722 solver.cpp:218] Iteration 4244500 (16.8163 iter/s, 29.7331s/500 iters), loss = 0.179904
I0901 08:06:47.780596 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.179908 (* 1 = 0.179908 loss)
I0901 08:06:47.780603 916722 sgd_solver.cpp:106] Iteration 4244500, lr = 0.01
I0901 08:07:17.509919 916722 solver.cpp:218] Iteration 4245000 (16.8184 iter/s, 29.7293s/500 iters), loss = 0.257191
I0901 08:07:17.509968 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.257195 (* 1 = 0.257195 loss)
I0901 08:07:17.509977 916722 sgd_solver.cpp:106] Iteration 4245000, lr = 0.01
I0901 08:07:47.254284 916722 solver.cpp:218] Iteration 4245500 (16.8099 iter/s, 29.7443s/500 iters), loss = 0.606869
I0901 08:07:47.254343 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.606873 (* 1 = 0.606873 loss)
I0901 08:07:47.254351 916722 sgd_solver.cpp:106] Iteration 4245500, lr = 0.01
I0901 08:08:16.993598 916722 solver.cpp:218] Iteration 4246000 (16.8128 iter/s, 29.7392s/500 iters), loss = 0.0315688
I0901 08:08:16.993652 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0315729 (* 1 = 0.0315729 loss)
I0901 08:08:16.993661 916722 sgd_solver.cpp:106] Iteration 4246000, lr = 0.01
I0901 08:08:46.730937 916722 solver.cpp:218] Iteration 4246500 (16.8139 iter/s, 29.7373s/500 iters), loss = 0.0461173
I0901 08:08:46.730996 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0461214 (* 1 = 0.0461214 loss)
I0901 08:08:46.731005 916722 sgd_solver.cpp:106] Iteration 4246500, lr = 0.01
I0901 08:09:16.466624 916722 solver.cpp:218] Iteration 4247000 (16.8149 iter/s, 29.7356s/500 iters), loss = 0.0880735
I0901 08:09:16.466671 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0880776 (* 1 = 0.0880776 loss)
I0901 08:09:16.466681 916722 sgd_solver.cpp:106] Iteration 4247000, lr = 0.01
I0901 08:09:46.198810 916722 solver.cpp:218] Iteration 4247500 (16.8168 iter/s, 29.7321s/500 iters), loss = 0.156095
I0901 08:09:46.198868 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.1561 (* 1 = 0.1561 loss)
I0901 08:09:46.198876 916722 sgd_solver.cpp:106] Iteration 4247500, lr = 0.01
I0901 08:10:15.932523 916722 solver.cpp:218] Iteration 4248000 (16.816 iter/s, 29.7336s/500 iters), loss = 0.0327132
I0901 08:10:15.932577 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0327173 (* 1 = 0.0327173 loss)
I0901 08:10:15.932588 916722 sgd_solver.cpp:106] Iteration 4248000, lr = 0.01
I0901 08:10:45.666262 916722 solver.cpp:218] Iteration 4248500 (16.816 iter/s, 29.7336s/500 iters), loss = 0.131637
I0901 08:10:45.666333 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131642 (* 1 = 0.131642 loss)
I0901 08:10:45.666347 916722 sgd_solver.cpp:106] Iteration 4248500, lr = 0.01
I0901 08:11:15.401820 916722 solver.cpp:218] Iteration 4249000 (16.8149 iter/s, 29.7355s/500 iters), loss = 0.0624871
I0901 08:11:15.401872 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0624913 (* 1 = 0.0624913 loss)
I0901 08:11:15.401882 916722 sgd_solver.cpp:106] Iteration 4249000, lr = 0.01
I0901 08:11:45.137189 916722 solver.cpp:218] Iteration 4249500 (16.815 iter/s, 29.7353s/500 iters), loss = 0.130106
I0901 08:11:45.137244 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13011 (* 1 = 0.13011 loss)
I0901 08:11:45.137252 916722 sgd_solver.cpp:106] Iteration 4249500, lr = 0.01
I0901 08:12:14.814625 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_4250000.caffemodel
I0901 08:12:14.834079 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_4250000.solverstate
I0901 08:12:14.840101 916722 solver.cpp:330] Iteration 4250000, Testing net (#0)
I0901 08:12:30.139883 916722 solver.cpp:397]     Test net output #0: accuracy = 0.869
I0901 08:12:30.139935 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.473292 (* 1 = 0.473292 loss)
I0901 08:12:30.198559 916722 solver.cpp:218] Iteration 4250000 (11.096 iter/s, 45.0613s/500 iters), loss = 0.0410267
I0901 08:12:30.198587 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0410309 (* 1 = 0.0410309 loss)
I0901 08:12:30.198596 916722 sgd_solver.cpp:106] Iteration 4250000, lr = 0.01
I0901 08:12:59.772450 916722 solver.cpp:218] Iteration 4250500 (16.9069 iter/s, 29.5738s/500 iters), loss = 0.252864
I0901 08:12:59.772500 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.252868 (* 1 = 0.252868 loss)
I0901 08:12:59.772509 916722 sgd_solver.cpp:106] Iteration 4250500, lr = 0.01
I0901 08:13:29.418148 916722 solver.cpp:218] Iteration 4251000 (16.8659 iter/s, 29.6456s/500 iters), loss = 0.102774
I0901 08:13:29.418205 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.102778 (* 1 = 0.102778 loss)
I0901 08:13:29.418212 916722 sgd_solver.cpp:106] Iteration 4251000, lr = 0.01
I0901 08:13:59.122807 916722 solver.cpp:218] Iteration 4251500 (16.8324 iter/s, 29.7046s/500 iters), loss = 0.143201
I0901 08:13:59.122856 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.143205 (* 1 = 0.143205 loss)
I0901 08:13:59.122866 916722 sgd_solver.cpp:106] Iteration 4251500, lr = 0.01
I0901 08:14:28.830516 916722 solver.cpp:218] Iteration 4252000 (16.8307 iter/s, 29.7076s/500 iters), loss = 0.27665
I0901 08:14:28.830571 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.276654 (* 1 = 0.276654 loss)
I0901 08:14:28.830580 916722 sgd_solver.cpp:106] Iteration 4252000, lr = 0.01
I0901 08:14:58.538712 916722 solver.cpp:218] Iteration 4252500 (16.8304 iter/s, 29.7081s/500 iters), loss = 0.171117
I0901 08:14:58.538766 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.171121 (* 1 = 0.171121 loss)
I0901 08:14:58.538777 916722 sgd_solver.cpp:106] Iteration 4252500, lr = 0.01
I0901 08:15:28.248407 916722 solver.cpp:218] Iteration 4253000 (16.8291 iter/s, 29.7105s/500 iters), loss = 0.0545983
I0901 08:15:28.248473 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0546023 (* 1 = 0.0546023 loss)
I0901 08:15:28.248481 916722 sgd_solver.cpp:106] Iteration 4253000, lr = 0.01
I0901 08:15:57.957449 916722 solver.cpp:218] Iteration 4253500 (16.8291 iter/s, 29.7104s/500 iters), loss = 0.268456
I0901 08:15:57.957504 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.268459 (* 1 = 0.268459 loss)
I0901 08:15:57.957513 916722 sgd_solver.cpp:106] Iteration 4253500, lr = 0.01
I0901 08:16:27.664238 916722 solver.cpp:218] Iteration 4254000 (16.8304 iter/s, 29.7081s/500 iters), loss = 0.0125828
I0901 08:16:27.664312 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0125868 (* 1 = 0.0125868 loss)
I0901 08:16:27.664326 916722 sgd_solver.cpp:106] Iteration 4254000, lr = 0.01
I0901 08:16:57.370301 916722 solver.cpp:218] Iteration 4254500 (16.8309 iter/s, 29.7073s/500 iters), loss = 0.163178
I0901 08:16:57.370353 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.163182 (* 1 = 0.163182 loss)
I0901 08:16:57.370362 916722 sgd_solver.cpp:106] Iteration 4254500, lr = 0.01
I0901 08:17:27.077950 916722 solver.cpp:218] Iteration 4255000 (16.83 iter/s, 29.7088s/500 iters), loss = 0.140292
I0901 08:17:27.078016 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.140296 (* 1 = 0.140296 loss)
I0901 08:17:27.078024 916722 sgd_solver.cpp:106] Iteration 4255000, lr = 0.01
I0901 08:17:56.784957 916722 solver.cpp:218] Iteration 4255500 (16.8304 iter/s, 29.7081s/500 iters), loss = 0.154234
I0901 08:17:56.785006 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.154238 (* 1 = 0.154238 loss)
I0901 08:17:56.785014 916722 sgd_solver.cpp:106] Iteration 4255500, lr = 0.01
I0901 08:18:26.489991 916722 solver.cpp:218] Iteration 4256000 (16.8316 iter/s, 29.7061s/500 iters), loss = 0.109152
I0901 08:18:26.490047 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109156 (* 1 = 0.109156 loss)
I0901 08:18:26.490056 916722 sgd_solver.cpp:106] Iteration 4256000, lr = 0.01
I0901 08:18:56.196125 916722 solver.cpp:218] Iteration 4256500 (16.831 iter/s, 29.7071s/500 iters), loss = 0.0533809
I0901 08:18:56.196175 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0533851 (* 1 = 0.0533851 loss)
I0901 08:18:56.196183 916722 sgd_solver.cpp:106] Iteration 4256500, lr = 0.01
I0901 08:19:25.906934 916722 solver.cpp:218] Iteration 4257000 (16.8284 iter/s, 29.7118s/500 iters), loss = 0.0448263
I0901 08:19:25.906994 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0448306 (* 1 = 0.0448306 loss)
I0901 08:19:25.907003 916722 sgd_solver.cpp:106] Iteration 4257000, lr = 0.01
I0901 08:19:55.618328 916722 solver.cpp:218] Iteration 4257500 (16.8281 iter/s, 29.7123s/500 iters), loss = 0.0203576
I0901 08:19:55.618381 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.020362 (* 1 = 0.020362 loss)
I0901 08:19:55.618389 916722 sgd_solver.cpp:106] Iteration 4257500, lr = 0.01
I0901 08:20:25.329789 916722 solver.cpp:218] Iteration 4258000 (16.828 iter/s, 29.7123s/500 iters), loss = 0.0491173
I0901 08:20:25.329849 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0491216 (* 1 = 0.0491216 loss)
I0901 08:20:25.329856 916722 sgd_solver.cpp:106] Iteration 4258000, lr = 0.01
I0901 08:20:55.038064 916722 solver.cpp:218] Iteration 4258500 (16.8299 iter/s, 29.7091s/500 iters), loss = 0.125541
I0901 08:20:55.038116 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.125545 (* 1 = 0.125545 loss)
I0901 08:20:55.038126 916722 sgd_solver.cpp:106] Iteration 4258500, lr = 0.01
I0901 08:21:24.748628 916722 solver.cpp:218] Iteration 4259000 (16.8286 iter/s, 29.7113s/500 iters), loss = 0.0223726
I0901 08:21:24.748687 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0223766 (* 1 = 0.0223766 loss)
I0901 08:21:24.748697 916722 sgd_solver.cpp:106] Iteration 4259000, lr = 0.01
I0901 08:21:54.459475 916722 solver.cpp:218] Iteration 4259500 (16.8285 iter/s, 29.7116s/500 iters), loss = 0.212145
I0901 08:21:54.459523 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.212149 (* 1 = 0.212149 loss)
I0901 08:21:54.459533 916722 sgd_solver.cpp:106] Iteration 4259500, lr = 0.01
I0901 08:22:24.173878 916722 solver.cpp:218] Iteration 4260000 (16.8265 iter/s, 29.7151s/500 iters), loss = 0.210615
I0901 08:22:24.173933 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.210618 (* 1 = 0.210618 loss)
I0901 08:22:24.173941 916722 sgd_solver.cpp:106] Iteration 4260000, lr = 0.01
I0901 08:22:53.886106 916722 solver.cpp:218] Iteration 4260500 (16.8277 iter/s, 29.7129s/500 iters), loss = 0.0488329
I0901 08:22:53.886153 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0488369 (* 1 = 0.0488369 loss)
I0901 08:22:53.886163 916722 sgd_solver.cpp:106] Iteration 4260500, lr = 0.01
I0901 08:23:23.596889 916722 solver.cpp:218] Iteration 4261000 (16.8286 iter/s, 29.7114s/500 iters), loss = 0.209523
I0901 08:23:23.596951 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.209527 (* 1 = 0.209527 loss)
I0901 08:23:23.596971 916722 sgd_solver.cpp:106] Iteration 4261000, lr = 0.01
I0901 08:23:53.302668 916722 solver.cpp:218] Iteration 4261500 (16.8314 iter/s, 29.7064s/500 iters), loss = 0.0394948
I0901 08:23:53.302718 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0394986 (* 1 = 0.0394986 loss)
I0901 08:23:53.302728 916722 sgd_solver.cpp:106] Iteration 4261500, lr = 0.01
I0901 08:24:23.010991 916722 solver.cpp:218] Iteration 4262000 (16.83 iter/s, 29.7089s/500 iters), loss = 0.134042
I0901 08:24:23.011047 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.134045 (* 1 = 0.134045 loss)
I0901 08:24:23.011055 916722 sgd_solver.cpp:106] Iteration 4262000, lr = 0.01
I0901 08:24:52.720232 916722 solver.cpp:218] Iteration 4262500 (16.8295 iter/s, 29.7098s/500 iters), loss = 0.145672
I0901 08:24:52.720279 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.145676 (* 1 = 0.145676 loss)
I0901 08:24:52.720289 916722 sgd_solver.cpp:106] Iteration 4262500, lr = 0.01
I0901 08:25:22.429891 916722 solver.cpp:218] Iteration 4263000 (16.8293 iter/s, 29.7102s/500 iters), loss = 0.0619953
I0901 08:25:22.429949 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.061999 (* 1 = 0.061999 loss)
I0901 08:25:22.429957 916722 sgd_solver.cpp:106] Iteration 4263000, lr = 0.01
I0901 08:25:52.134358 916722 solver.cpp:218] Iteration 4263500 (16.8322 iter/s, 29.7049s/500 iters), loss = 0.123267
I0901 08:25:52.134409 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.12327 (* 1 = 0.12327 loss)
I0901 08:25:52.134419 916722 sgd_solver.cpp:106] Iteration 4263500, lr = 0.01
I0901 08:26:21.844751 916722 solver.cpp:218] Iteration 4264000 (16.8289 iter/s, 29.7108s/500 iters), loss = 0.156112
I0901 08:26:21.844805 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.156115 (* 1 = 0.156115 loss)
I0901 08:26:21.844815 916722 sgd_solver.cpp:106] Iteration 4264000, lr = 0.01
I0901 08:26:51.551383 916722 solver.cpp:218] Iteration 4264500 (16.831 iter/s, 29.7071s/500 iters), loss = 0.117654
I0901 08:26:51.551430 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.117658 (* 1 = 0.117658 loss)
I0901 08:26:51.551440 916722 sgd_solver.cpp:106] Iteration 4264500, lr = 0.01
I0901 08:27:21.269243 916722 solver.cpp:218] Iteration 4265000 (16.8247 iter/s, 29.7183s/500 iters), loss = 0.0741261
I0901 08:27:21.269299 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0741298 (* 1 = 0.0741298 loss)
I0901 08:27:21.269309 916722 sgd_solver.cpp:106] Iteration 4265000, lr = 0.01
I0901 08:27:50.972033 916722 solver.cpp:218] Iteration 4265500 (16.8332 iter/s, 29.7032s/500 iters), loss = 0.131872
I0901 08:27:50.972076 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131875 (* 1 = 0.131875 loss)
I0901 08:27:50.972086 916722 sgd_solver.cpp:106] Iteration 4265500, lr = 0.01
I0901 08:28:20.672538 916722 solver.cpp:218] Iteration 4266000 (16.8345 iter/s, 29.7009s/500 iters), loss = 0.0816679
I0901 08:28:20.672597 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0816715 (* 1 = 0.0816715 loss)
I0901 08:28:20.672605 916722 sgd_solver.cpp:106] Iteration 4266000, lr = 0.01
I0901 08:28:50.376399 916722 solver.cpp:218] Iteration 4266500 (16.8326 iter/s, 29.7042s/500 iters), loss = 0.180245
I0901 08:28:50.376452 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.180249 (* 1 = 0.180249 loss)
I0901 08:28:50.376463 916722 sgd_solver.cpp:106] Iteration 4266500, lr = 0.01
I0901 08:29:20.080032 916722 solver.cpp:218] Iteration 4267000 (16.8328 iter/s, 29.704s/500 iters), loss = 0.0774792
I0901 08:29:20.080092 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0774825 (* 1 = 0.0774825 loss)
I0901 08:29:20.080101 916722 sgd_solver.cpp:106] Iteration 4267000, lr = 0.01
I0901 08:29:49.786224 916722 solver.cpp:218] Iteration 4267500 (16.8313 iter/s, 29.7065s/500 iters), loss = 0.167669
I0901 08:29:49.786286 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.167672 (* 1 = 0.167672 loss)
I0901 08:29:49.786296 916722 sgd_solver.cpp:106] Iteration 4267500, lr = 0.01
I0901 08:30:19.492765 916722 solver.cpp:218] Iteration 4268000 (16.8311 iter/s, 29.7068s/500 iters), loss = 0.312162
I0901 08:30:19.492832 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.312166 (* 1 = 0.312166 loss)
I0901 08:30:19.492841 916722 sgd_solver.cpp:106] Iteration 4268000, lr = 0.01
I0901 08:30:49.196362 916722 solver.cpp:218] Iteration 4268500 (16.8328 iter/s, 29.7039s/500 iters), loss = 0.192115
I0901 08:30:49.196409 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.192118 (* 1 = 0.192118 loss)
I0901 08:30:49.196419 916722 sgd_solver.cpp:106] Iteration 4268500, lr = 0.01
I0901 08:31:18.898418 916722 solver.cpp:218] Iteration 4269000 (16.8337 iter/s, 29.7023s/500 iters), loss = 0.246769
I0901 08:31:18.898473 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.246772 (* 1 = 0.246772 loss)
I0901 08:31:18.898481 916722 sgd_solver.cpp:106] Iteration 4269000, lr = 0.01
I0901 08:31:48.602578 916722 solver.cpp:218] Iteration 4269500 (16.8325 iter/s, 29.7044s/500 iters), loss = 0.0934239
I0901 08:31:48.602627 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0934274 (* 1 = 0.0934274 loss)
I0901 08:31:48.602636 916722 sgd_solver.cpp:106] Iteration 4269500, lr = 0.01
I0901 08:32:18.306038 916722 solver.cpp:218] Iteration 4270000 (16.8329 iter/s, 29.7037s/500 iters), loss = 0.0710658
I0901 08:32:18.306095 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0710693 (* 1 = 0.0710693 loss)
I0901 08:32:18.306104 916722 sgd_solver.cpp:106] Iteration 4270000, lr = 0.01
I0901 08:32:48.010416 916722 solver.cpp:218] Iteration 4270500 (16.8324 iter/s, 29.7046s/500 iters), loss = 0.367293
I0901 08:32:48.010463 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.367297 (* 1 = 0.367297 loss)
I0901 08:32:48.010471 916722 sgd_solver.cpp:106] Iteration 4270500, lr = 0.01
I0901 08:33:17.715466 916722 solver.cpp:218] Iteration 4271000 (16.832 iter/s, 29.7053s/500 iters), loss = 0.393307
I0901 08:33:17.715521 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.393311 (* 1 = 0.393311 loss)
I0901 08:33:17.715530 916722 sgd_solver.cpp:106] Iteration 4271000, lr = 0.01
I0901 08:33:47.418359 916722 solver.cpp:218] Iteration 4271500 (16.8333 iter/s, 29.7031s/500 iters), loss = 0.0943707
I0901 08:33:47.418407 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0943742 (* 1 = 0.0943742 loss)
I0901 08:33:47.418416 916722 sgd_solver.cpp:106] Iteration 4271500, lr = 0.01
I0901 08:34:17.118947 916722 solver.cpp:218] Iteration 4272000 (16.8346 iter/s, 29.7008s/500 iters), loss = 0.149288
I0901 08:34:17.119002 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.149292 (* 1 = 0.149292 loss)
I0901 08:34:17.119011 916722 sgd_solver.cpp:106] Iteration 4272000, lr = 0.01
I0901 08:34:46.819247 916722 solver.cpp:218] Iteration 4272500 (16.8347 iter/s, 29.7005s/500 iters), loss = 0.176718
I0901 08:34:46.819294 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.176721 (* 1 = 0.176721 loss)
I0901 08:34:46.819303 916722 sgd_solver.cpp:106] Iteration 4272500, lr = 0.01
I0901 08:35:16.522387 916722 solver.cpp:218] Iteration 4273000 (16.8331 iter/s, 29.7033s/500 iters), loss = 0.265408
I0901 08:35:16.522444 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.265412 (* 1 = 0.265412 loss)
I0901 08:35:16.522451 916722 sgd_solver.cpp:106] Iteration 4273000, lr = 0.01
I0901 08:35:46.225992 916722 solver.cpp:218] Iteration 4273500 (16.8329 iter/s, 29.7038s/500 iters), loss = 0.054515
I0901 08:35:46.226037 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0545183 (* 1 = 0.0545183 loss)
I0901 08:35:46.226045 916722 sgd_solver.cpp:106] Iteration 4273500, lr = 0.01
I0901 08:36:15.929294 916722 solver.cpp:218] Iteration 4274000 (16.833 iter/s, 29.7035s/500 iters), loss = 0.0667992
I0901 08:36:15.929361 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0668026 (* 1 = 0.0668026 loss)
I0901 08:36:15.929369 916722 sgd_solver.cpp:106] Iteration 4274000, lr = 0.01
I0901 08:36:45.631757 916722 solver.cpp:218] Iteration 4274500 (16.8335 iter/s, 29.7026s/500 iters), loss = 0.105302
I0901 08:36:45.631800 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105305 (* 1 = 0.105305 loss)
I0901 08:36:45.631808 916722 sgd_solver.cpp:106] Iteration 4274500, lr = 0.01
I0901 08:37:15.332835 916722 solver.cpp:218] Iteration 4275000 (16.8343 iter/s, 29.7013s/500 iters), loss = 0.0282427
I0901 08:37:15.332895 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0282459 (* 1 = 0.0282459 loss)
I0901 08:37:15.332903 916722 sgd_solver.cpp:106] Iteration 4275000, lr = 0.01
I0901 08:37:45.033743 916722 solver.cpp:218] Iteration 4275500 (16.8344 iter/s, 29.7011s/500 iters), loss = 0.114788
I0901 08:37:45.033793 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.114791 (* 1 = 0.114791 loss)
I0901 08:37:45.033802 916722 sgd_solver.cpp:106] Iteration 4275500, lr = 0.01
I0901 08:38:14.741150 916722 solver.cpp:218] Iteration 4276000 (16.8307 iter/s, 29.7076s/500 iters), loss = 0.0225848
I0901 08:38:14.741209 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0225878 (* 1 = 0.0225878 loss)
I0901 08:38:14.741216 916722 sgd_solver.cpp:106] Iteration 4276000, lr = 0.01
I0901 08:38:44.446012 916722 solver.cpp:218] Iteration 4276500 (16.8322 iter/s, 29.705s/500 iters), loss = 0.0191076
I0901 08:38:44.446059 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0191107 (* 1 = 0.0191107 loss)
I0901 08:38:44.446067 916722 sgd_solver.cpp:106] Iteration 4276500, lr = 0.01
I0901 08:39:14.153744 916722 solver.cpp:218] Iteration 4277000 (16.8305 iter/s, 29.7079s/500 iters), loss = 0.210968
I0901 08:39:14.153801 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.210972 (* 1 = 0.210972 loss)
I0901 08:39:14.153810 916722 sgd_solver.cpp:106] Iteration 4277000, lr = 0.01
I0901 08:39:43.858930 916722 solver.cpp:218] Iteration 4277500 (16.832 iter/s, 29.7053s/500 iters), loss = 0.214349
I0901 08:39:43.858981 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.214353 (* 1 = 0.214353 loss)
I0901 08:39:43.858991 916722 sgd_solver.cpp:106] Iteration 4277500, lr = 0.01
I0901 08:40:13.559892 916722 solver.cpp:218] Iteration 4278000 (16.8344 iter/s, 29.7011s/500 iters), loss = 0.119928
I0901 08:40:13.559943 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.119931 (* 1 = 0.119931 loss)
I0901 08:40:13.559952 916722 sgd_solver.cpp:106] Iteration 4278000, lr = 0.01
I0901 08:40:43.263738 916722 solver.cpp:218] Iteration 4278500 (16.8328 iter/s, 29.704s/500 iters), loss = 0.248166
I0901 08:40:43.263783 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.248169 (* 1 = 0.248169 loss)
I0901 08:40:43.263792 916722 sgd_solver.cpp:106] Iteration 4278500, lr = 0.01
I0901 08:41:12.965219 916722 solver.cpp:218] Iteration 4279000 (16.8341 iter/s, 29.7016s/500 iters), loss = 0.0496112
I0901 08:41:12.965272 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0496146 (* 1 = 0.0496146 loss)
I0901 08:41:12.965281 916722 sgd_solver.cpp:106] Iteration 4279000, lr = 0.01
I0901 08:41:42.664942 916722 solver.cpp:218] Iteration 4279500 (16.8351 iter/s, 29.6999s/500 iters), loss = 0.374668
I0901 08:41:42.664992 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.374672 (* 1 = 0.374672 loss)
I0901 08:41:42.665001 916722 sgd_solver.cpp:106] Iteration 4279500, lr = 0.01
I0901 08:42:12.366729 916722 solver.cpp:218] Iteration 4280000 (16.8339 iter/s, 29.7019s/500 iters), loss = 0.0322368
I0901 08:42:12.366786 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0322404 (* 1 = 0.0322404 loss)
I0901 08:42:12.366794 916722 sgd_solver.cpp:106] Iteration 4280000, lr = 0.01
I0901 08:42:42.071446 916722 solver.cpp:218] Iteration 4280500 (16.8323 iter/s, 29.7048s/500 iters), loss = 0.122918
I0901 08:42:42.071511 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.122922 (* 1 = 0.122922 loss)
I0901 08:42:42.071521 916722 sgd_solver.cpp:106] Iteration 4280500, lr = 0.01
I0901 08:43:11.781975 916722 solver.cpp:218] Iteration 4281000 (16.829 iter/s, 29.7106s/500 iters), loss = 0.0975511
I0901 08:43:11.782054 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0975548 (* 1 = 0.0975548 loss)
I0901 08:43:11.782063 916722 sgd_solver.cpp:106] Iteration 4281000, lr = 0.01
I0901 08:43:41.483597 916722 solver.cpp:218] Iteration 4281500 (16.834 iter/s, 29.7017s/500 iters), loss = 0.0964437
I0901 08:43:41.483647 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0964475 (* 1 = 0.0964475 loss)
I0901 08:43:41.483657 916722 sgd_solver.cpp:106] Iteration 4281500, lr = 0.01
I0901 08:44:11.185112 916722 solver.cpp:218] Iteration 4282000 (16.8341 iter/s, 29.7016s/500 iters), loss = 0.0894539
I0901 08:44:11.185169 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0894575 (* 1 = 0.0894575 loss)
I0901 08:44:11.185178 916722 sgd_solver.cpp:106] Iteration 4282000, lr = 0.01
I0901 08:44:40.887569 916722 solver.cpp:218] Iteration 4282500 (16.8336 iter/s, 29.7026s/500 iters), loss = 0.174042
I0901 08:44:40.887619 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.174045 (* 1 = 0.174045 loss)
I0901 08:44:40.887629 916722 sgd_solver.cpp:106] Iteration 4282500, lr = 0.01
I0901 08:45:10.590664 916722 solver.cpp:218] Iteration 4283000 (16.8332 iter/s, 29.7032s/500 iters), loss = 0.122677
I0901 08:45:10.590719 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.122681 (* 1 = 0.122681 loss)
I0901 08:45:10.590728 916722 sgd_solver.cpp:106] Iteration 4283000, lr = 0.01
I0901 08:45:40.293028 916722 solver.cpp:218] Iteration 4283500 (16.8336 iter/s, 29.7025s/500 iters), loss = 0.199775
I0901 08:45:40.293077 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.199778 (* 1 = 0.199778 loss)
I0901 08:45:40.293087 916722 sgd_solver.cpp:106] Iteration 4283500, lr = 0.01
I0901 08:46:09.995541 916722 solver.cpp:218] Iteration 4284000 (16.8335 iter/s, 29.7026s/500 iters), loss = 0.0762998
I0901 08:46:09.995599 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0763035 (* 1 = 0.0763035 loss)
I0901 08:46:09.995606 916722 sgd_solver.cpp:106] Iteration 4284000, lr = 0.01
I0901 08:46:39.703778 916722 solver.cpp:218] Iteration 4284500 (16.8303 iter/s, 29.7083s/500 iters), loss = 0.183114
I0901 08:46:39.703825 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.183117 (* 1 = 0.183117 loss)
I0901 08:46:39.703835 916722 sgd_solver.cpp:106] Iteration 4284500, lr = 0.01
I0901 08:47:09.410733 916722 solver.cpp:218] Iteration 4285000 (16.831 iter/s, 29.7071s/500 iters), loss = 0.138301
I0901 08:47:09.410791 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.138304 (* 1 = 0.138304 loss)
I0901 08:47:09.410799 916722 sgd_solver.cpp:106] Iteration 4285000, lr = 0.01
I0901 08:47:39.116564 916722 solver.cpp:218] Iteration 4285500 (16.8317 iter/s, 29.7059s/500 iters), loss = 0.306308
I0901 08:47:39.116616 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.306312 (* 1 = 0.306312 loss)
I0901 08:47:39.120357 916722 sgd_solver.cpp:106] Iteration 4285500, lr = 0.01
I0901 08:48:08.824112 916722 solver.cpp:218] Iteration 4286000 (16.8307 iter/s, 29.7077s/500 iters), loss = 0.198594
I0901 08:48:08.824169 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.198597 (* 1 = 0.198597 loss)
I0901 08:48:08.824177 916722 sgd_solver.cpp:106] Iteration 4286000, lr = 0.01
I0901 08:48:38.535179 916722 solver.cpp:218] Iteration 4286500 (16.8287 iter/s, 29.7112s/500 iters), loss = 0.479174
I0901 08:48:38.535224 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.479178 (* 1 = 0.479178 loss)
I0901 08:48:38.535233 916722 sgd_solver.cpp:106] Iteration 4286500, lr = 0.01
I0901 08:49:08.244096 916722 solver.cpp:218] Iteration 4287000 (16.8299 iter/s, 29.709s/500 iters), loss = 0.0886843
I0901 08:49:08.244163 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0886877 (* 1 = 0.0886877 loss)
I0901 08:49:08.244176 916722 sgd_solver.cpp:106] Iteration 4287000, lr = 0.01
I0901 08:49:37.954386 916722 solver.cpp:218] Iteration 4287500 (16.8291 iter/s, 29.7104s/500 iters), loss = 0.0446265
I0901 08:49:37.954434 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0446298 (* 1 = 0.0446298 loss)
I0901 08:49:37.954442 916722 sgd_solver.cpp:106] Iteration 4287500, lr = 0.01
I0901 08:50:07.656198 916722 solver.cpp:218] Iteration 4288000 (16.8339 iter/s, 29.7019s/500 iters), loss = 0.0326416
I0901 08:50:07.656255 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.032645 (* 1 = 0.032645 loss)
I0901 08:50:07.656263 916722 sgd_solver.cpp:106] Iteration 4288000, lr = 0.01
I0901 08:50:37.385556 916722 solver.cpp:218] Iteration 4288500 (16.8183 iter/s, 29.7294s/500 iters), loss = 0.10165
I0901 08:50:37.385609 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101653 (* 1 = 0.101653 loss)
I0901 08:50:37.385617 916722 sgd_solver.cpp:106] Iteration 4288500, lr = 0.01
I0901 08:51:07.086509 916722 solver.cpp:218] Iteration 4289000 (16.8344 iter/s, 29.701s/500 iters), loss = 0.335297
I0901 08:51:07.086566 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.335301 (* 1 = 0.335301 loss)
I0901 08:51:07.086575 916722 sgd_solver.cpp:106] Iteration 4289000, lr = 0.01
I0901 08:51:36.789645 916722 solver.cpp:218] Iteration 4289500 (16.8332 iter/s, 29.7032s/500 iters), loss = 0.126726
I0901 08:51:36.789697 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.126729 (* 1 = 0.126729 loss)
I0901 08:51:36.789707 916722 sgd_solver.cpp:106] Iteration 4289500, lr = 0.01
I0901 08:52:06.562484 916722 solver.cpp:218] Iteration 4290000 (16.7938 iter/s, 29.7729s/500 iters), loss = 0.11344
I0901 08:52:06.562547 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.113443 (* 1 = 0.113443 loss)
I0901 08:52:06.562556 916722 sgd_solver.cpp:106] Iteration 4290000, lr = 0.01
I0901 08:52:36.290119 916722 solver.cpp:218] Iteration 4290500 (16.8193 iter/s, 29.7277s/500 iters), loss = 0.0620319
I0901 08:52:36.290170 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0620354 (* 1 = 0.0620354 loss)
I0901 08:52:36.290179 916722 sgd_solver.cpp:106] Iteration 4290500, lr = 0.01
I0901 08:53:06.028370 916722 solver.cpp:218] Iteration 4291000 (16.8133 iter/s, 29.7383s/500 iters), loss = 0.076498
I0901 08:53:06.028434 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0765014 (* 1 = 0.0765014 loss)
I0901 08:53:06.028443 916722 sgd_solver.cpp:106] Iteration 4291000, lr = 0.01
I0901 08:53:35.836532 916722 solver.cpp:218] Iteration 4291500 (16.7739 iter/s, 29.8082s/500 iters), loss = 0.0300946
I0901 08:53:35.836591 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.030098 (* 1 = 0.030098 loss)
I0901 08:53:35.836601 916722 sgd_solver.cpp:106] Iteration 4291500, lr = 0.01
I0901 08:54:05.574710 916722 solver.cpp:218] Iteration 4292000 (16.8134 iter/s, 29.7383s/500 iters), loss = 0.105251
I0901 08:54:05.574767 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105255 (* 1 = 0.105255 loss)
I0901 08:54:05.574776 916722 sgd_solver.cpp:106] Iteration 4292000, lr = 0.01
I0901 08:54:35.307740 916722 solver.cpp:218] Iteration 4292500 (16.8163 iter/s, 29.7331s/500 iters), loss = 0.130781
I0901 08:54:35.307791 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130784 (* 1 = 0.130784 loss)
I0901 08:54:35.307802 916722 sgd_solver.cpp:106] Iteration 4292500, lr = 0.01
I0901 08:55:05.041471 916722 solver.cpp:218] Iteration 4293000 (16.8159 iter/s, 29.7338s/500 iters), loss = 0.340594
I0901 08:55:05.041527 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.340597 (* 1 = 0.340597 loss)
I0901 08:55:05.041534 916722 sgd_solver.cpp:106] Iteration 4293000, lr = 0.01
I0901 08:55:34.799289 916722 solver.cpp:218] Iteration 4293500 (16.8023 iter/s, 29.7579s/500 iters), loss = 0.0421783
I0901 08:55:34.799342 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0421815 (* 1 = 0.0421815 loss)
I0901 08:55:34.799365 916722 sgd_solver.cpp:106] Iteration 4293500, lr = 0.01
I0901 08:56:04.530081 916722 solver.cpp:218] Iteration 4294000 (16.8175 iter/s, 29.7309s/500 iters), loss = 0.645533
I0901 08:56:04.530144 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.645536 (* 1 = 0.645536 loss)
I0901 08:56:04.530153 916722 sgd_solver.cpp:106] Iteration 4294000, lr = 0.01
I0901 08:56:34.260411 916722 solver.cpp:218] Iteration 4294500 (16.8178 iter/s, 29.7304s/500 iters), loss = 0.111071
I0901 08:56:34.260479 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111074 (* 1 = 0.111074 loss)
I0901 08:56:34.260490 916722 sgd_solver.cpp:106] Iteration 4294500, lr = 0.01
I0901 08:57:03.992058 916722 solver.cpp:218] Iteration 4295000 (16.8171 iter/s, 29.7317s/500 iters), loss = 0.0782972
I0901 08:57:03.992115 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0783004 (* 1 = 0.0783004 loss)
I0901 08:57:03.992122 916722 sgd_solver.cpp:106] Iteration 4295000, lr = 0.01
I0901 08:57:33.727104 916722 solver.cpp:218] Iteration 4295500 (16.8151 iter/s, 29.7351s/500 iters), loss = 0.230338
I0901 08:57:33.727154 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.230341 (* 1 = 0.230341 loss)
I0901 08:57:33.727165 916722 sgd_solver.cpp:106] Iteration 4295500, lr = 0.01
I0901 08:58:03.462541 916722 solver.cpp:218] Iteration 4296000 (16.8149 iter/s, 29.7355s/500 iters), loss = 0.0648931
I0901 08:58:03.462591 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0648961 (* 1 = 0.0648961 loss)
I0901 08:58:03.462599 916722 sgd_solver.cpp:106] Iteration 4296000, lr = 0.01
I0901 08:58:33.192829 916722 solver.cpp:218] Iteration 4296500 (16.8178 iter/s, 29.7304s/500 iters), loss = 0.245096
I0901 08:58:33.192879 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.245099 (* 1 = 0.245099 loss)
I0901 08:58:33.192890 916722 sgd_solver.cpp:106] Iteration 4296500, lr = 0.01
I0901 08:59:02.920940 916722 solver.cpp:218] Iteration 4297000 (16.8191 iter/s, 29.7282s/500 iters), loss = 0.0303545
I0901 08:59:02.920997 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0303576 (* 1 = 0.0303576 loss)
I0901 08:59:02.921006 916722 sgd_solver.cpp:106] Iteration 4297000, lr = 0.01
I0901 08:59:32.649816 916722 solver.cpp:218] Iteration 4297500 (16.8186 iter/s, 29.7289s/500 iters), loss = 0.0199937
I0901 08:59:32.649864 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0199969 (* 1 = 0.0199969 loss)
I0901 08:59:32.649873 916722 sgd_solver.cpp:106] Iteration 4297500, lr = 0.01
I0901 09:00:02.376660 916722 solver.cpp:218] Iteration 4298000 (16.8198 iter/s, 29.7269s/500 iters), loss = 0.220801
I0901 09:00:02.376716 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.220804 (* 1 = 0.220804 loss)
I0901 09:00:02.376725 916722 sgd_solver.cpp:106] Iteration 4298000, lr = 0.01
I0901 09:00:32.130228 916722 solver.cpp:218] Iteration 4298500 (16.8047 iter/s, 29.7536s/500 iters), loss = 0.139782
I0901 09:00:32.130280 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139785 (* 1 = 0.139785 loss)
I0901 09:00:32.130290 916722 sgd_solver.cpp:106] Iteration 4298500, lr = 0.01
I0901 09:01:01.867120 916722 solver.cpp:218] Iteration 4299000 (16.8141 iter/s, 29.737s/500 iters), loss = 0.337813
I0901 09:01:01.867179 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.337816 (* 1 = 0.337816 loss)
I0901 09:01:01.867188 916722 sgd_solver.cpp:106] Iteration 4299000, lr = 0.01
I0901 09:01:31.602622 916722 solver.cpp:218] Iteration 4299500 (16.8149 iter/s, 29.7356s/500 iters), loss = 0.255127
I0901 09:01:31.602676 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.25513 (* 1 = 0.25513 loss)
I0901 09:01:31.602685 916722 sgd_solver.cpp:106] Iteration 4299500, lr = 0.01
I0901 09:02:01.279363 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_4300000.caffemodel
I0901 09:02:01.298884 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_4300000.solverstate
I0901 09:02:01.305052 916722 solver.cpp:330] Iteration 4300000, Testing net (#0)
I0901 09:02:16.703408 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8658
I0901 09:02:16.703449 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.471341 (* 1 = 0.471341 loss)
I0901 09:02:16.762017 916722 solver.cpp:218] Iteration 4300000 (11.0719 iter/s, 45.1595s/500 iters), loss = 0.140341
I0901 09:02:16.762043 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.140344 (* 1 = 0.140344 loss)
I0901 09:02:16.762051 916722 sgd_solver.cpp:106] Iteration 4300000, lr = 0.01
I0901 09:02:46.372429 916722 solver.cpp:218] Iteration 4300500 (16.8859 iter/s, 29.6105s/500 iters), loss = 0.141188
I0901 09:02:46.372499 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.141191 (* 1 = 0.141191 loss)
I0901 09:02:46.372509 916722 sgd_solver.cpp:106] Iteration 4300500, lr = 0.01
I0901 09:03:16.048676 916722 solver.cpp:218] Iteration 4301000 (16.8485 iter/s, 29.6763s/500 iters), loss = 0.0664072
I0901 09:03:16.048727 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0664101 (* 1 = 0.0664101 loss)
I0901 09:03:16.048736 916722 sgd_solver.cpp:106] Iteration 4301000, lr = 0.01
I0901 09:03:45.781781 916722 solver.cpp:218] Iteration 4301500 (16.8162 iter/s, 29.7332s/500 iters), loss = 0.103875
I0901 09:03:45.781841 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.103878 (* 1 = 0.103878 loss)
I0901 09:03:45.781849 916722 sgd_solver.cpp:106] Iteration 4301500, lr = 0.01
I0901 09:04:15.512130 916722 solver.cpp:218] Iteration 4302000 (16.8178 iter/s, 29.7304s/500 iters), loss = 0.0993021
I0901 09:04:15.512181 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.099305 (* 1 = 0.099305 loss)
I0901 09:04:15.512188 916722 sgd_solver.cpp:106] Iteration 4302000, lr = 0.01
I0901 09:04:45.246495 916722 solver.cpp:218] Iteration 4302500 (16.8155 iter/s, 29.7344s/500 iters), loss = 0.107819
I0901 09:04:45.246553 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.107822 (* 1 = 0.107822 loss)
I0901 09:04:45.246562 916722 sgd_solver.cpp:106] Iteration 4302500, lr = 0.01
I0901 09:05:14.990442 916722 solver.cpp:218] Iteration 4303000 (16.8101 iter/s, 29.744s/500 iters), loss = 0.133018
I0901 09:05:14.990491 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133021 (* 1 = 0.133021 loss)
I0901 09:05:14.990500 916722 sgd_solver.cpp:106] Iteration 4303000, lr = 0.01
I0901 09:05:44.726440 916722 solver.cpp:218] Iteration 4303500 (16.8146 iter/s, 29.7361s/500 iters), loss = 0.140655
I0901 09:05:44.726495 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.140658 (* 1 = 0.140658 loss)
I0901 09:05:44.726505 916722 sgd_solver.cpp:106] Iteration 4303500, lr = 0.01
I0901 09:06:14.465377 916722 solver.cpp:218] Iteration 4304000 (16.8129 iter/s, 29.739s/500 iters), loss = 0.0388439
I0901 09:06:14.465430 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0388468 (* 1 = 0.0388468 loss)
I0901 09:06:14.465438 916722 sgd_solver.cpp:106] Iteration 4304000, lr = 0.01
I0901 09:06:44.249104 916722 solver.cpp:218] Iteration 4304500 (16.7876 iter/s, 29.7838s/500 iters), loss = 0.212542
I0901 09:06:44.249161 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.212545 (* 1 = 0.212545 loss)
I0901 09:06:44.249169 916722 sgd_solver.cpp:106] Iteration 4304500, lr = 0.01
I0901 09:07:13.991705 916722 solver.cpp:218] Iteration 4305000 (16.8109 iter/s, 29.7427s/500 iters), loss = 0.206285
I0901 09:07:13.991762 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.206288 (* 1 = 0.206288 loss)
I0901 09:07:13.991772 916722 sgd_solver.cpp:106] Iteration 4305000, lr = 0.01
I0901 09:07:43.727058 916722 solver.cpp:218] Iteration 4305500 (16.815 iter/s, 29.7354s/500 iters), loss = 0.199114
I0901 09:07:43.727115 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.199117 (* 1 = 0.199117 loss)
I0901 09:07:43.727123 916722 sgd_solver.cpp:106] Iteration 4305500, lr = 0.01
I0901 09:08:13.457885 916722 solver.cpp:218] Iteration 4306000 (16.8175 iter/s, 29.7309s/500 iters), loss = 0.100777
I0901 09:08:13.457948 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.10078 (* 1 = 0.10078 loss)
I0901 09:08:13.457959 916722 sgd_solver.cpp:106] Iteration 4306000, lr = 0.01
I0901 09:08:43.190765 916722 solver.cpp:218] Iteration 4306500 (16.8164 iter/s, 29.7329s/500 iters), loss = 0.387178
I0901 09:08:43.190834 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.387181 (* 1 = 0.387181 loss)
I0901 09:08:43.190841 916722 sgd_solver.cpp:106] Iteration 4306500, lr = 0.01
I0901 09:09:12.923123 916722 solver.cpp:218] Iteration 4307000 (16.8167 iter/s, 29.7324s/500 iters), loss = 0.159582
I0901 09:09:12.923177 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159585 (* 1 = 0.159585 loss)
I0901 09:09:12.923187 916722 sgd_solver.cpp:106] Iteration 4307000, lr = 0.01
I0901 09:09:42.665812 916722 solver.cpp:218] Iteration 4307500 (16.8108 iter/s, 29.7428s/500 iters), loss = 0.055697
I0901 09:09:42.665874 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0556998 (* 1 = 0.0556998 loss)
I0901 09:09:42.665884 916722 sgd_solver.cpp:106] Iteration 4307500, lr = 0.01
I0901 09:10:12.459990 916722 solver.cpp:218] Iteration 4308000 (16.7818 iter/s, 29.7942s/500 iters), loss = 0.0867209
I0901 09:10:12.460049 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0867237 (* 1 = 0.0867237 loss)
I0901 09:10:12.460059 916722 sgd_solver.cpp:106] Iteration 4308000, lr = 0.01
I0901 09:10:42.214191 916722 solver.cpp:218] Iteration 4308500 (16.8043 iter/s, 29.7543s/500 iters), loss = 0.134543
I0901 09:10:42.214247 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.134546 (* 1 = 0.134546 loss)
I0901 09:10:42.214257 916722 sgd_solver.cpp:106] Iteration 4308500, lr = 0.01
I0901 09:11:11.968055 916722 solver.cpp:218] Iteration 4309000 (16.8045 iter/s, 29.7539s/500 iters), loss = 0.0201997
I0901 09:11:11.968103 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0202025 (* 1 = 0.0202025 loss)
I0901 09:11:11.968113 916722 sgd_solver.cpp:106] Iteration 4309000, lr = 0.01
I0901 09:11:41.719811 916722 solver.cpp:218] Iteration 4309500 (16.8057 iter/s, 29.7518s/500 iters), loss = 0.145168
I0901 09:11:41.719877 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.145171 (* 1 = 0.145171 loss)
I0901 09:11:41.719885 916722 sgd_solver.cpp:106] Iteration 4309500, lr = 0.01
I0901 09:12:11.467871 916722 solver.cpp:218] Iteration 4310000 (16.8078 iter/s, 29.7481s/500 iters), loss = 0.100149
I0901 09:12:11.467922 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.100152 (* 1 = 0.100152 loss)
I0901 09:12:11.467931 916722 sgd_solver.cpp:106] Iteration 4310000, lr = 0.01
I0901 09:12:41.219441 916722 solver.cpp:218] Iteration 4310500 (16.8058 iter/s, 29.7516s/500 iters), loss = 0.121468
I0901 09:12:41.219502 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.121471 (* 1 = 0.121471 loss)
I0901 09:12:41.219511 916722 sgd_solver.cpp:106] Iteration 4310500, lr = 0.01
I0901 09:13:10.964908 916722 solver.cpp:218] Iteration 4311000 (16.8092 iter/s, 29.7455s/500 iters), loss = 0.189945
I0901 09:13:10.964962 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.189948 (* 1 = 0.189948 loss)
I0901 09:13:10.964972 916722 sgd_solver.cpp:106] Iteration 4311000, lr = 0.01
I0901 09:13:40.714506 916722 solver.cpp:218] Iteration 4311500 (16.8069 iter/s, 29.7497s/500 iters), loss = 0.129769
I0901 09:13:40.714565 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.129772 (* 1 = 0.129772 loss)
I0901 09:13:40.714572 916722 sgd_solver.cpp:106] Iteration 4311500, lr = 0.01
I0901 09:14:10.462097 916722 solver.cpp:218] Iteration 4312000 (16.808 iter/s, 29.7477s/500 iters), loss = 0.203558
I0901 09:14:10.462148 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.203561 (* 1 = 0.203561 loss)
I0901 09:14:10.462157 916722 sgd_solver.cpp:106] Iteration 4312000, lr = 0.01
I0901 09:14:40.211689 916722 solver.cpp:218] Iteration 4312500 (16.8069 iter/s, 29.7497s/500 iters), loss = 0.0632497
I0901 09:14:40.211764 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0632523 (* 1 = 0.0632523 loss)
I0901 09:14:40.211772 916722 sgd_solver.cpp:106] Iteration 4312500, lr = 0.01
I0901 09:15:09.962571 916722 solver.cpp:218] Iteration 4313000 (16.8062 iter/s, 29.7509s/500 iters), loss = 0.11085
I0901 09:15:09.962626 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110852 (* 1 = 0.110852 loss)
I0901 09:15:09.962635 916722 sgd_solver.cpp:106] Iteration 4313000, lr = 0.01
I0901 09:15:39.711671 916722 solver.cpp:218] Iteration 4313500 (16.8072 iter/s, 29.7492s/500 iters), loss = 0.0825632
I0901 09:15:39.711731 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0825657 (* 1 = 0.0825657 loss)
I0901 09:15:39.711740 916722 sgd_solver.cpp:106] Iteration 4313500, lr = 0.01
I0901 09:16:09.460116 916722 solver.cpp:218] Iteration 4314000 (16.8076 iter/s, 29.7485s/500 iters), loss = 0.101985
I0901 09:16:09.460170 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101987 (* 1 = 0.101987 loss)
I0901 09:16:09.460178 916722 sgd_solver.cpp:106] Iteration 4314000, lr = 0.01
I0901 09:16:39.211030 916722 solver.cpp:218] Iteration 4314500 (16.8062 iter/s, 29.751s/500 iters), loss = 0.0388057
I0901 09:16:39.211091 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0388083 (* 1 = 0.0388083 loss)
I0901 09:16:39.211100 916722 sgd_solver.cpp:106] Iteration 4314500, lr = 0.01
I0901 09:17:08.963575 916722 solver.cpp:218] Iteration 4315000 (16.8052 iter/s, 29.7526s/500 iters), loss = 0.225371
I0901 09:17:08.963634 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.225374 (* 1 = 0.225374 loss)
I0901 09:17:08.963644 916722 sgd_solver.cpp:106] Iteration 4315000, lr = 0.01
I0901 09:17:38.686059 916722 solver.cpp:218] Iteration 4315500 (16.8222 iter/s, 29.7226s/500 iters), loss = 0.0785678
I0901 09:17:38.686122 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0785705 (* 1 = 0.0785705 loss)
I0901 09:17:38.686131 916722 sgd_solver.cpp:106] Iteration 4315500, lr = 0.01
I0901 09:18:08.407063 916722 solver.cpp:218] Iteration 4316000 (16.8231 iter/s, 29.7211s/500 iters), loss = 0.187198
I0901 09:18:08.407115 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.1872 (* 1 = 0.1872 loss)
I0901 09:18:08.407125 916722 sgd_solver.cpp:106] Iteration 4316000, lr = 0.01
I0901 09:18:38.128422 916722 solver.cpp:218] Iteration 4316500 (16.8229 iter/s, 29.7214s/500 iters), loss = 0.171213
I0901 09:18:38.128490 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.171216 (* 1 = 0.171216 loss)
I0901 09:18:38.128499 916722 sgd_solver.cpp:106] Iteration 4316500, lr = 0.01
I0901 09:19:07.848698 916722 solver.cpp:218] Iteration 4317000 (16.8235 iter/s, 29.7203s/500 iters), loss = 0.547073
I0901 09:19:07.848749 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.547076 (* 1 = 0.547076 loss)
I0901 09:19:07.848758 916722 sgd_solver.cpp:106] Iteration 4317000, lr = 0.01
I0901 09:19:37.574072 916722 solver.cpp:218] Iteration 4317500 (16.8206 iter/s, 29.7255s/500 iters), loss = 0.0627223
I0901 09:19:37.574133 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0627254 (* 1 = 0.0627254 loss)
I0901 09:19:37.574142 916722 sgd_solver.cpp:106] Iteration 4317500, lr = 0.01
I0901 09:20:07.295701 916722 solver.cpp:218] Iteration 4318000 (16.8227 iter/s, 29.7217s/500 iters), loss = 0.0859408
I0901 09:20:07.295754 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.085944 (* 1 = 0.085944 loss)
I0901 09:20:07.295763 916722 sgd_solver.cpp:106] Iteration 4318000, lr = 0.01
I0901 09:20:37.033015 916722 solver.cpp:218] Iteration 4318500 (16.8138 iter/s, 29.7374s/500 iters), loss = 0.0555169
I0901 09:20:37.033074 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.05552 (* 1 = 0.05552 loss)
I0901 09:20:37.033083 916722 sgd_solver.cpp:106] Iteration 4318500, lr = 0.01
I0901 09:21:06.767892 916722 solver.cpp:218] Iteration 4319000 (16.8152 iter/s, 29.7349s/500 iters), loss = 0.0855684
I0901 09:21:06.767957 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0855716 (* 1 = 0.0855716 loss)
I0901 09:21:06.767968 916722 sgd_solver.cpp:106] Iteration 4319000, lr = 0.01
I0901 09:21:36.535768 916722 solver.cpp:218] Iteration 4319500 (16.7966 iter/s, 29.7679s/500 iters), loss = 0.191549
I0901 09:21:36.535830 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.191552 (* 1 = 0.191552 loss)
I0901 09:21:36.535838 916722 sgd_solver.cpp:106] Iteration 4319500, lr = 0.01
I0901 09:22:06.278017 916722 solver.cpp:218] Iteration 4320000 (16.8111 iter/s, 29.7423s/500 iters), loss = 0.144394
I0901 09:22:06.278065 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.144397 (* 1 = 0.144397 loss)
I0901 09:22:06.278075 916722 sgd_solver.cpp:106] Iteration 4320000, lr = 0.01
I0901 09:22:36.021386 916722 solver.cpp:218] Iteration 4320500 (16.8104 iter/s, 29.7434s/500 iters), loss = 0.17537
I0901 09:22:36.021443 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.175373 (* 1 = 0.175373 loss)
I0901 09:22:36.021452 916722 sgd_solver.cpp:106] Iteration 4320500, lr = 0.01
I0901 09:23:05.766072 916722 solver.cpp:218] Iteration 4321000 (16.8097 iter/s, 29.7448s/500 iters), loss = 0.0356181
I0901 09:23:05.766120 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0356212 (* 1 = 0.0356212 loss)
I0901 09:23:05.766130 916722 sgd_solver.cpp:106] Iteration 4321000, lr = 0.01
I0901 09:23:35.505440 916722 solver.cpp:218] Iteration 4321500 (16.8133 iter/s, 29.7384s/500 iters), loss = 0.0673913
I0901 09:23:35.505494 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0673944 (* 1 = 0.0673944 loss)
I0901 09:23:35.505502 916722 sgd_solver.cpp:106] Iteration 4321500, lr = 0.01
I0901 09:24:05.249882 916722 solver.cpp:218] Iteration 4322000 (16.8121 iter/s, 29.7404s/500 iters), loss = 0.271804
I0901 09:24:05.249931 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.271807 (* 1 = 0.271807 loss)
I0901 09:24:05.249941 916722 sgd_solver.cpp:106] Iteration 4322000, lr = 0.01
I0901 09:24:34.987295 916722 solver.cpp:218] Iteration 4322500 (16.816 iter/s, 29.7336s/500 iters), loss = 0.0980235
I0901 09:24:34.987356 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0980267 (* 1 = 0.0980267 loss)
I0901 09:24:34.987365 916722 sgd_solver.cpp:106] Iteration 4322500, lr = 0.01
I0901 09:25:04.728076 916722 solver.cpp:218] Iteration 4323000 (16.814 iter/s, 29.7371s/500 iters), loss = 0.116207
I0901 09:25:04.728129 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.11621 (* 1 = 0.11621 loss)
I0901 09:25:04.728139 916722 sgd_solver.cpp:106] Iteration 4323000, lr = 0.01
I0901 09:25:34.469419 916722 solver.cpp:218] Iteration 4323500 (16.8136 iter/s, 29.7379s/500 iters), loss = 0.110664
I0901 09:25:34.469477 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110667 (* 1 = 0.110667 loss)
I0901 09:25:34.469486 916722 sgd_solver.cpp:106] Iteration 4323500, lr = 0.01
I0901 09:26:04.209283 916722 solver.cpp:218] Iteration 4324000 (16.8143 iter/s, 29.7365s/500 iters), loss = 0.233436
I0901 09:26:04.209336 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.233439 (* 1 = 0.233439 loss)
I0901 09:26:04.209347 916722 sgd_solver.cpp:106] Iteration 4324000, lr = 0.01
I0901 09:26:33.949050 916722 solver.cpp:218] Iteration 4324500 (16.8143 iter/s, 29.7366s/500 iters), loss = 0.144611
I0901 09:26:33.949112 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.144614 (* 1 = 0.144614 loss)
I0901 09:26:33.949121 916722 sgd_solver.cpp:106] Iteration 4324500, lr = 0.01
I0901 09:27:03.686810 916722 solver.cpp:218] Iteration 4325000 (16.8153 iter/s, 29.7347s/500 iters), loss = 0.0534417
I0901 09:27:03.686863 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.053445 (* 1 = 0.053445 loss)
I0901 09:27:03.686872 916722 sgd_solver.cpp:106] Iteration 4325000, lr = 0.01
I0901 09:27:33.423677 916722 solver.cpp:218] Iteration 4325500 (16.8158 iter/s, 29.734s/500 iters), loss = 0.327823
I0901 09:27:33.423751 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.327826 (* 1 = 0.327826 loss)
I0901 09:27:33.423765 916722 sgd_solver.cpp:106] Iteration 4325500, lr = 0.01
I0901 09:28:03.162947 916722 solver.cpp:218] Iteration 4326000 (16.8143 iter/s, 29.7365s/500 iters), loss = 0.136739
I0901 09:28:03.162997 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.136742 (* 1 = 0.136742 loss)
I0901 09:28:03.163007 916722 sgd_solver.cpp:106] Iteration 4326000, lr = 0.01
I0901 09:28:32.900322 916722 solver.cpp:218] Iteration 4326500 (16.8153 iter/s, 29.7348s/500 iters), loss = 0.241316
I0901 09:28:32.900382 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.241319 (* 1 = 0.241319 loss)
I0901 09:28:32.900390 916722 sgd_solver.cpp:106] Iteration 4326500, lr = 0.01
I0901 09:29:02.639159 916722 solver.cpp:218] Iteration 4327000 (16.8144 iter/s, 29.7363s/500 iters), loss = 0.0367164
I0901 09:29:02.639209 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0367195 (* 1 = 0.0367195 loss)
I0901 09:29:02.639218 916722 sgd_solver.cpp:106] Iteration 4327000, lr = 0.01
I0901 09:29:32.375994 916722 solver.cpp:218] Iteration 4327500 (16.8155 iter/s, 29.7345s/500 iters), loss = 0.43873
I0901 09:29:32.376052 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.438733 (* 1 = 0.438733 loss)
I0901 09:29:32.376060 916722 sgd_solver.cpp:106] Iteration 4327500, lr = 0.01
I0901 09:30:02.123281 916722 solver.cpp:218] Iteration 4328000 (16.8095 iter/s, 29.745s/500 iters), loss = 0.0812049
I0901 09:30:02.123333 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0812082 (* 1 = 0.0812082 loss)
I0901 09:30:02.123342 916722 sgd_solver.cpp:106] Iteration 4328000, lr = 0.01
I0901 09:30:31.854169 916722 solver.cpp:218] Iteration 4328500 (16.8188 iter/s, 29.7287s/500 iters), loss = 0.104067
I0901 09:30:31.854231 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104071 (* 1 = 0.104071 loss)
I0901 09:30:31.854240 916722 sgd_solver.cpp:106] Iteration 4328500, lr = 0.01
I0901 09:31:01.586968 916722 solver.cpp:218] Iteration 4329000 (16.8176 iter/s, 29.7307s/500 iters), loss = 0.150546
I0901 09:31:01.587019 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.150549 (* 1 = 0.150549 loss)
I0901 09:31:01.587028 916722 sgd_solver.cpp:106] Iteration 4329000, lr = 0.01
I0901 09:31:31.315552 916722 solver.cpp:218] Iteration 4329500 (16.82 iter/s, 29.7266s/500 iters), loss = 0.184097
I0901 09:31:31.315613 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.1841 (* 1 = 0.1841 loss)
I0901 09:31:31.315621 916722 sgd_solver.cpp:106] Iteration 4329500, lr = 0.01
I0901 09:32:01.048214 916722 solver.cpp:218] Iteration 4330000 (16.8176 iter/s, 29.7307s/500 iters), loss = 0.0770085
I0901 09:32:01.048265 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.077012 (* 1 = 0.077012 loss)
I0901 09:32:01.048276 916722 sgd_solver.cpp:106] Iteration 4330000, lr = 0.01
I0901 09:32:30.778419 916722 solver.cpp:218] Iteration 4330500 (16.8189 iter/s, 29.7284s/500 iters), loss = 0.176522
I0901 09:32:30.778472 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.176525 (* 1 = 0.176525 loss)
I0901 09:32:30.778481 916722 sgd_solver.cpp:106] Iteration 4330500, lr = 0.01
I0901 09:33:00.507845 916722 solver.cpp:218] Iteration 4331000 (16.8193 iter/s, 29.7277s/500 iters), loss = 0.159442
I0901 09:33:00.507898 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159445 (* 1 = 0.159445 loss)
I0901 09:33:00.507910 916722 sgd_solver.cpp:106] Iteration 4331000, lr = 0.01
I0901 09:33:30.238133 916722 solver.cpp:218] Iteration 4331500 (16.8188 iter/s, 29.7286s/500 iters), loss = 0.0894072
I0901 09:33:30.238193 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0894104 (* 1 = 0.0894104 loss)
I0901 09:33:30.238200 916722 sgd_solver.cpp:106] Iteration 4331500, lr = 0.01
I0901 09:33:59.967993 916722 solver.cpp:218] Iteration 4332000 (16.819 iter/s, 29.7282s/500 iters), loss = 0.232157
I0901 09:33:59.968046 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.23216 (* 1 = 0.23216 loss)
I0901 09:33:59.968070 916722 sgd_solver.cpp:106] Iteration 4332000, lr = 0.01
I0901 09:34:29.697561 916722 solver.cpp:218] Iteration 4332500 (16.8192 iter/s, 29.728s/500 iters), loss = 0.126403
I0901 09:34:29.697628 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.126407 (* 1 = 0.126407 loss)
I0901 09:34:29.697636 916722 sgd_solver.cpp:106] Iteration 4332500, lr = 0.01
I0901 09:34:59.430598 916722 solver.cpp:218] Iteration 4333000 (16.8172 iter/s, 29.7315s/500 iters), loss = 0.0447783
I0901 09:34:59.430649 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0447816 (* 1 = 0.0447816 loss)
I0901 09:34:59.430660 916722 sgd_solver.cpp:106] Iteration 4333000, lr = 0.01
I0901 09:35:29.164911 916722 solver.cpp:218] Iteration 4333500 (16.8164 iter/s, 29.7329s/500 iters), loss = 0.110664
I0901 09:35:29.164971 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110667 (* 1 = 0.110667 loss)
I0901 09:35:29.164980 916722 sgd_solver.cpp:106] Iteration 4333500, lr = 0.01
I0901 09:35:58.892212 916722 solver.cpp:218] Iteration 4334000 (16.8203 iter/s, 29.7259s/500 iters), loss = 0.080444
I0901 09:35:58.892263 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0804476 (* 1 = 0.0804476 loss)
I0901 09:35:58.892274 916722 sgd_solver.cpp:106] Iteration 4334000, lr = 0.01
I0901 09:36:28.625774 916722 solver.cpp:218] Iteration 4334500 (16.8168 iter/s, 29.7322s/500 iters), loss = 0.524874
I0901 09:36:28.625833 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.524877 (* 1 = 0.524877 loss)
I0901 09:36:28.625841 916722 sgd_solver.cpp:106] Iteration 4334500, lr = 0.01
I0901 09:36:58.357746 916722 solver.cpp:218] Iteration 4335000 (16.8176 iter/s, 29.7307s/500 iters), loss = 0.0496786
I0901 09:36:58.357797 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0496822 (* 1 = 0.0496822 loss)
I0901 09:36:58.357807 916722 sgd_solver.cpp:106] Iteration 4335000, lr = 0.01
I0901 09:37:28.089555 916722 solver.cpp:218] Iteration 4335500 (16.8177 iter/s, 29.7306s/500 iters), loss = 0.152559
I0901 09:37:28.089620 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152563 (* 1 = 0.152563 loss)
I0901 09:37:28.089630 916722 sgd_solver.cpp:106] Iteration 4335500, lr = 0.01
I0901 09:37:57.823827 916722 solver.cpp:218] Iteration 4336000 (16.8163 iter/s, 29.7331s/500 iters), loss = 0.254927
I0901 09:37:57.823880 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.254931 (* 1 = 0.254931 loss)
I0901 09:37:57.823889 916722 sgd_solver.cpp:106] Iteration 4336000, lr = 0.01
I0901 09:38:27.556468 916722 solver.cpp:218] Iteration 4336500 (16.8172 iter/s, 29.7315s/500 iters), loss = 0.149218
I0901 09:38:27.556524 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.149222 (* 1 = 0.149222 loss)
I0901 09:38:27.556532 916722 sgd_solver.cpp:106] Iteration 4336500, lr = 0.01
I0901 09:38:57.286962 916722 solver.cpp:218] Iteration 4337000 (16.8184 iter/s, 29.7294s/500 iters), loss = 0.0210584
I0901 09:38:57.287019 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0210619 (* 1 = 0.0210619 loss)
I0901 09:38:57.287029 916722 sgd_solver.cpp:106] Iteration 4337000, lr = 0.01
I0901 09:39:27.014859 916722 solver.cpp:218] Iteration 4337500 (16.8198 iter/s, 29.7268s/500 iters), loss = 0.137968
I0901 09:39:27.014919 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.137971 (* 1 = 0.137971 loss)
I0901 09:39:27.014927 916722 sgd_solver.cpp:106] Iteration 4337500, lr = 0.01
I0901 09:39:56.749150 916722 solver.cpp:218] Iteration 4338000 (16.8162 iter/s, 29.7332s/500 iters), loss = 0.105807
I0901 09:39:56.749207 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.10581 (* 1 = 0.10581 loss)
I0901 09:39:56.749217 916722 sgd_solver.cpp:106] Iteration 4338000, lr = 0.01
I0901 09:40:26.479790 916722 solver.cpp:218] Iteration 4338500 (16.8182 iter/s, 29.7296s/500 iters), loss = 0.17489
I0901 09:40:26.479862 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.174894 (* 1 = 0.174894 loss)
I0901 09:40:26.479871 916722 sgd_solver.cpp:106] Iteration 4338500, lr = 0.01
I0901 09:40:56.209434 916722 solver.cpp:218] Iteration 4339000 (16.8188 iter/s, 29.7286s/500 iters), loss = 0.130144
I0901 09:40:56.209486 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130147 (* 1 = 0.130147 loss)
I0901 09:40:56.209496 916722 sgd_solver.cpp:106] Iteration 4339000, lr = 0.01
I0901 09:41:25.940766 916722 solver.cpp:218] Iteration 4339500 (16.8178 iter/s, 29.7304s/500 iters), loss = 0.0337962
I0901 09:41:25.940826 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0337997 (* 1 = 0.0337997 loss)
I0901 09:41:25.940834 916722 sgd_solver.cpp:106] Iteration 4339500, lr = 0.01
I0901 09:41:55.743503 916722 solver.cpp:218] Iteration 4340000 (16.7775 iter/s, 29.8018s/500 iters), loss = 0.269281
I0901 09:41:55.743554 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.269285 (* 1 = 0.269285 loss)
I0901 09:41:55.743564 916722 sgd_solver.cpp:106] Iteration 4340000, lr = 0.01
I0901 09:42:25.548607 916722 solver.cpp:218] Iteration 4340500 (16.7762 iter/s, 29.8042s/500 iters), loss = 0.270011
I0901 09:42:25.548663 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.270014 (* 1 = 0.270014 loss)
I0901 09:42:25.548672 916722 sgd_solver.cpp:106] Iteration 4340500, lr = 0.01
I0901 09:42:55.350503 916722 solver.cpp:218] Iteration 4341000 (16.778 iter/s, 29.801s/500 iters), loss = 0.306209
I0901 09:42:55.350554 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.306213 (* 1 = 0.306213 loss)
I0901 09:42:55.350564 916722 sgd_solver.cpp:106] Iteration 4341000, lr = 0.01
I0901 09:43:25.156078 916722 solver.cpp:218] Iteration 4341500 (16.7759 iter/s, 29.8047s/500 iters), loss = 0.0462397
I0901 09:43:25.156139 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0462432 (* 1 = 0.0462432 loss)
I0901 09:43:25.156148 916722 sgd_solver.cpp:106] Iteration 4341500, lr = 0.01
I0901 09:43:54.955333 916722 solver.cpp:218] Iteration 4342000 (16.7794 iter/s, 29.7984s/500 iters), loss = 0.195117
I0901 09:43:54.955384 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.195121 (* 1 = 0.195121 loss)
I0901 09:43:54.955392 916722 sgd_solver.cpp:106] Iteration 4342000, lr = 0.01
I0901 09:44:24.754323 916722 solver.cpp:218] Iteration 4342500 (16.7796 iter/s, 29.7982s/500 iters), loss = 0.0920052
I0901 09:44:24.754385 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0920088 (* 1 = 0.0920088 loss)
I0901 09:44:24.754393 916722 sgd_solver.cpp:106] Iteration 4342500, lr = 0.01
I0901 09:44:54.554260 916722 solver.cpp:218] Iteration 4343000 (16.779 iter/s, 29.7991s/500 iters), loss = 0.256293
I0901 09:44:54.554312 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.256297 (* 1 = 0.256297 loss)
I0901 09:44:54.554322 916722 sgd_solver.cpp:106] Iteration 4343000, lr = 0.01
I0901 09:45:24.354189 916722 solver.cpp:218] Iteration 4343500 (16.779 iter/s, 29.7991s/500 iters), loss = 0.0153444
I0901 09:45:24.354255 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0153478 (* 1 = 0.0153478 loss)
I0901 09:45:24.354264 916722 sgd_solver.cpp:106] Iteration 4343500, lr = 0.01
I0901 09:45:54.153225 916722 solver.cpp:218] Iteration 4344000 (16.7795 iter/s, 29.7982s/500 iters), loss = 0.0609631
I0901 09:45:54.153277 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0609665 (* 1 = 0.0609665 loss)
I0901 09:45:54.153286 916722 sgd_solver.cpp:106] Iteration 4344000, lr = 0.01
I0901 09:46:23.953249 916722 solver.cpp:218] Iteration 4344500 (16.7789 iter/s, 29.7993s/500 iters), loss = 0.081493
I0901 09:46:23.953310 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0814964 (* 1 = 0.0814964 loss)
I0901 09:46:23.953320 916722 sgd_solver.cpp:106] Iteration 4344500, lr = 0.01
I0901 09:46:53.756031 916722 solver.cpp:218] Iteration 4345000 (16.7774 iter/s, 29.802s/500 iters), loss = 0.107263
I0901 09:46:53.756083 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.107267 (* 1 = 0.107267 loss)
I0901 09:46:53.756091 916722 sgd_solver.cpp:106] Iteration 4345000, lr = 0.01
I0901 09:47:23.558987 916722 solver.cpp:218] Iteration 4345500 (16.7773 iter/s, 29.8022s/500 iters), loss = 0.122327
I0901 09:47:23.559059 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.122331 (* 1 = 0.122331 loss)
I0901 09:47:23.559068 916722 sgd_solver.cpp:106] Iteration 4345500, lr = 0.01
I0901 09:47:53.362298 916722 solver.cpp:218] Iteration 4346000 (16.7771 iter/s, 29.8026s/500 iters), loss = 0.471332
I0901 09:47:53.362349 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.471335 (* 1 = 0.471335 loss)
I0901 09:47:53.362357 916722 sgd_solver.cpp:106] Iteration 4346000, lr = 0.01
I0901 09:48:23.164728 916722 solver.cpp:218] Iteration 4346500 (16.7775 iter/s, 29.8017s/500 iters), loss = 0.163214
I0901 09:48:23.164791 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.163217 (* 1 = 0.163217 loss)
I0901 09:48:23.164800 916722 sgd_solver.cpp:106] Iteration 4346500, lr = 0.01
I0901 09:48:52.964932 916722 solver.cpp:218] Iteration 4347000 (16.7788 iter/s, 29.7995s/500 iters), loss = 0.121485
I0901 09:48:52.964983 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.121488 (* 1 = 0.121488 loss)
I0901 09:48:52.964993 916722 sgd_solver.cpp:106] Iteration 4347000, lr = 0.01
I0901 09:49:22.770951 916722 solver.cpp:218] Iteration 4347500 (16.7755 iter/s, 29.8053s/500 iters), loss = 0.516887
I0901 09:49:22.771013 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.51689 (* 1 = 0.51689 loss)
I0901 09:49:22.771021 916722 sgd_solver.cpp:106] Iteration 4347500, lr = 0.01
I0901 09:49:52.569739 916722 solver.cpp:218] Iteration 4348000 (16.7796 iter/s, 29.7981s/500 iters), loss = 0.0398819
I0901 09:49:52.569793 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0398851 (* 1 = 0.0398851 loss)
I0901 09:49:52.569802 916722 sgd_solver.cpp:106] Iteration 4348000, lr = 0.01
I0901 09:50:22.367326 916722 solver.cpp:218] Iteration 4348500 (16.7803 iter/s, 29.7969s/500 iters), loss = 0.0509513
I0901 09:50:22.367389 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0509547 (* 1 = 0.0509547 loss)
I0901 09:50:22.367398 916722 sgd_solver.cpp:106] Iteration 4348500, lr = 0.01
I0901 09:50:52.097362 916722 solver.cpp:218] Iteration 4349000 (16.8184 iter/s, 29.7294s/500 iters), loss = 0.143147
I0901 09:50:52.097415 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.14315 (* 1 = 0.14315 loss)
I0901 09:50:52.097425 916722 sgd_solver.cpp:106] Iteration 4349000, lr = 0.01
I0901 09:51:21.830229 916722 solver.cpp:218] Iteration 4349500 (16.8168 iter/s, 29.7322s/500 iters), loss = 0.139477
I0901 09:51:21.830291 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139481 (* 1 = 0.139481 loss)
I0901 09:51:21.830299 916722 sgd_solver.cpp:106] Iteration 4349500, lr = 0.01
I0901 09:51:51.501969 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_4350000.caffemodel
I0901 09:51:51.521237 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_4350000.solverstate
I0901 09:51:51.527388 916722 solver.cpp:330] Iteration 4350000, Testing net (#0)
I0901 09:52:06.929615 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8714
I0901 09:52:06.929666 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.43168 (* 1 = 0.43168 loss)
I0901 09:52:06.988194 916722 solver.cpp:218] Iteration 4350000 (11.0725 iter/s, 45.157s/500 iters), loss = 0.119821
I0901 09:52:06.988221 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.119824 (* 1 = 0.119824 loss)
I0901 09:52:06.988229 916722 sgd_solver.cpp:106] Iteration 4350000, lr = 0.01
I0901 09:52:36.596474 916722 solver.cpp:218] Iteration 4350500 (16.8875 iter/s, 29.6077s/500 iters), loss = 0.129459
I0901 09:52:36.596529 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.129463 (* 1 = 0.129463 loss)
I0901 09:52:36.596537 916722 sgd_solver.cpp:106] Iteration 4350500, lr = 0.01
I0901 09:53:06.324434 916722 solver.cpp:218] Iteration 4351000 (16.8195 iter/s, 29.7273s/500 iters), loss = 0.0676989
I0901 09:53:06.324508 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0677025 (* 1 = 0.0677025 loss)
I0901 09:53:06.324517 916722 sgd_solver.cpp:106] Iteration 4351000, lr = 0.01
I0901 09:53:36.052680 916722 solver.cpp:218] Iteration 4351500 (16.8194 iter/s, 29.7276s/500 iters), loss = 0.243646
I0901 09:53:36.052731 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.243649 (* 1 = 0.243649 loss)
I0901 09:53:36.052740 916722 sgd_solver.cpp:106] Iteration 4351500, lr = 0.01
I0901 09:54:05.782590 916722 solver.cpp:218] Iteration 4352000 (16.8184 iter/s, 29.7293s/500 iters), loss = 0.105796
I0901 09:54:05.782649 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105799 (* 1 = 0.105799 loss)
I0901 09:54:05.782658 916722 sgd_solver.cpp:106] Iteration 4352000, lr = 0.01
I0901 09:54:35.511335 916722 solver.cpp:218] Iteration 4352500 (16.8191 iter/s, 29.7281s/500 iters), loss = 0.101757
I0901 09:54:35.511384 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101761 (* 1 = 0.101761 loss)
I0901 09:54:35.511394 916722 sgd_solver.cpp:106] Iteration 4352500, lr = 0.01
I0901 09:55:05.242564 916722 solver.cpp:218] Iteration 4353000 (16.8177 iter/s, 29.7306s/500 iters), loss = 0.0372827
I0901 09:55:05.242621 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0372864 (* 1 = 0.0372864 loss)
I0901 09:55:05.242630 916722 sgd_solver.cpp:106] Iteration 4353000, lr = 0.01
I0901 09:55:34.971001 916722 solver.cpp:218] Iteration 4353500 (16.8192 iter/s, 29.7278s/500 iters), loss = 0.0964054
I0901 09:55:34.971048 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0964091 (* 1 = 0.0964091 loss)
I0901 09:55:34.971057 916722 sgd_solver.cpp:106] Iteration 4353500, lr = 0.01
I0901 09:56:04.704526 916722 solver.cpp:218] Iteration 4354000 (16.8164 iter/s, 29.7329s/500 iters), loss = 0.0364024
I0901 09:56:04.704586 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0364062 (* 1 = 0.0364062 loss)
I0901 09:56:04.704593 916722 sgd_solver.cpp:106] Iteration 4354000, lr = 0.01
I0901 09:56:34.434460 916722 solver.cpp:218] Iteration 4354500 (16.8184 iter/s, 29.7294s/500 iters), loss = 0.253799
I0901 09:56:34.434509 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.253803 (* 1 = 0.253803 loss)
I0901 09:56:34.434520 916722 sgd_solver.cpp:106] Iteration 4354500, lr = 0.01
I0901 09:57:04.164773 916722 solver.cpp:218] Iteration 4355000 (16.8182 iter/s, 29.7297s/500 iters), loss = 0.138019
I0901 09:57:04.164830 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.138023 (* 1 = 0.138023 loss)
I0901 09:57:04.164839 916722 sgd_solver.cpp:106] Iteration 4355000, lr = 0.01
I0901 09:57:33.893265 916722 solver.cpp:218] Iteration 4355500 (16.8192 iter/s, 29.7279s/500 iters), loss = 0.0116241
I0901 09:57:33.893313 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.011628 (* 1 = 0.011628 loss)
I0901 09:57:33.893323 916722 sgd_solver.cpp:106] Iteration 4355500, lr = 0.01
I0901 09:58:03.622745 916722 solver.cpp:218] Iteration 4356000 (16.8181 iter/s, 29.73s/500 iters), loss = 0.11965
I0901 09:58:03.622807 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.119654 (* 1 = 0.119654 loss)
I0901 09:58:03.622814 916722 sgd_solver.cpp:106] Iteration 4356000, lr = 0.01
I0901 09:58:33.352861 916722 solver.cpp:218] Iteration 4356500 (16.8177 iter/s, 29.7306s/500 iters), loss = 0.0584189
I0901 09:58:33.352912 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0584229 (* 1 = 0.0584229 loss)
I0901 09:58:33.352921 916722 sgd_solver.cpp:106] Iteration 4356500, lr = 0.01
I0901 09:59:03.082973 916722 solver.cpp:218] Iteration 4357000 (16.8177 iter/s, 29.7306s/500 iters), loss = 0.134087
I0901 09:59:03.083029 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.134091 (* 1 = 0.134091 loss)
I0901 09:59:03.083036 916722 sgd_solver.cpp:106] Iteration 4357000, lr = 0.01
I0901 09:59:32.809854 916722 solver.cpp:218] Iteration 4357500 (16.8196 iter/s, 29.7273s/500 iters), loss = 0.0242184
I0901 09:59:32.809916 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0242222 (* 1 = 0.0242222 loss)
I0901 09:59:32.809924 916722 sgd_solver.cpp:106] Iteration 4357500, lr = 0.01
I0901 10:00:02.539660 916722 solver.cpp:218] Iteration 4358000 (16.8179 iter/s, 29.7302s/500 iters), loss = 0.0764814
I0901 10:00:02.539731 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0764853 (* 1 = 0.0764853 loss)
I0901 10:00:02.539739 916722 sgd_solver.cpp:106] Iteration 4358000, lr = 0.01
I0901 10:00:32.267666 916722 solver.cpp:218] Iteration 4358500 (16.819 iter/s, 29.7283s/500 iters), loss = 0.0797877
I0901 10:00:32.267717 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0797914 (* 1 = 0.0797914 loss)
I0901 10:00:32.267726 916722 sgd_solver.cpp:106] Iteration 4358500, lr = 0.01
I0901 10:01:01.996431 916722 solver.cpp:218] Iteration 4359000 (16.8186 iter/s, 29.7291s/500 iters), loss = 0.0349279
I0901 10:01:01.996490 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0349317 (* 1 = 0.0349317 loss)
I0901 10:01:01.996498 916722 sgd_solver.cpp:106] Iteration 4359000, lr = 0.01
I0901 10:01:31.726490 916722 solver.cpp:218] Iteration 4359500 (16.8179 iter/s, 29.7303s/500 iters), loss = 0.079652
I0901 10:01:31.726541 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0796559 (* 1 = 0.0796559 loss)
I0901 10:01:31.726549 916722 sgd_solver.cpp:106] Iteration 4359500, lr = 0.01
I0901 10:02:01.454483 916722 solver.cpp:218] Iteration 4360000 (16.819 iter/s, 29.7282s/500 iters), loss = 0.0790723
I0901 10:02:01.454540 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0790764 (* 1 = 0.0790764 loss)
I0901 10:02:01.454550 916722 sgd_solver.cpp:106] Iteration 4360000, lr = 0.01
I0901 10:02:31.182180 916722 solver.cpp:218] Iteration 4360500 (16.8192 iter/s, 29.7279s/500 iters), loss = 0.186717
I0901 10:02:31.182231 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.186721 (* 1 = 0.186721 loss)
I0901 10:02:31.182240 916722 sgd_solver.cpp:106] Iteration 4360500, lr = 0.01
I0901 10:03:00.911026 916722 solver.cpp:218] Iteration 4361000 (16.8186 iter/s, 29.729s/500 iters), loss = 0.46248
I0901 10:03:00.911083 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.462484 (* 1 = 0.462484 loss)
I0901 10:03:00.911092 916722 sgd_solver.cpp:106] Iteration 4361000, lr = 0.01
I0901 10:03:30.641408 916722 solver.cpp:218] Iteration 4361500 (16.8178 iter/s, 29.7305s/500 iters), loss = 0.0901673
I0901 10:03:30.641460 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0901717 (* 1 = 0.0901717 loss)
I0901 10:03:30.641470 916722 sgd_solver.cpp:106] Iteration 4361500, lr = 0.01
I0901 10:04:00.368377 916722 solver.cpp:218] Iteration 4362000 (16.8197 iter/s, 29.7271s/500 iters), loss = 0.187779
I0901 10:04:00.368436 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.187784 (* 1 = 0.187784 loss)
I0901 10:04:00.368445 916722 sgd_solver.cpp:106] Iteration 4362000, lr = 0.01
I0901 10:04:30.096730 916722 solver.cpp:218] Iteration 4362500 (16.8189 iter/s, 29.7284s/500 iters), loss = 0.115466
I0901 10:04:30.096791 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.11547 (* 1 = 0.11547 loss)
I0901 10:04:30.096798 916722 sgd_solver.cpp:106] Iteration 4362500, lr = 0.01
I0901 10:04:59.824914 916722 solver.cpp:218] Iteration 4363000 (16.819 iter/s, 29.7282s/500 iters), loss = 0.123512
I0901 10:04:59.824977 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.123516 (* 1 = 0.123516 loss)
I0901 10:04:59.824985 916722 sgd_solver.cpp:106] Iteration 4363000, lr = 0.01
I0901 10:05:29.550770 916722 solver.cpp:218] Iteration 4363500 (16.8204 iter/s, 29.7259s/500 iters), loss = 0.0459963
I0901 10:05:29.550822 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0460005 (* 1 = 0.0460005 loss)
I0901 10:05:29.550829 916722 sgd_solver.cpp:106] Iteration 4363500, lr = 0.01
I0901 10:05:59.276357 916722 solver.cpp:218] Iteration 4364000 (16.8205 iter/s, 29.7256s/500 iters), loss = 0.0928505
I0901 10:05:59.276437 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0928547 (* 1 = 0.0928547 loss)
I0901 10:05:59.276450 916722 sgd_solver.cpp:106] Iteration 4364000, lr = 0.01
I0901 10:06:29.001137 916722 solver.cpp:218] Iteration 4364500 (16.821 iter/s, 29.7247s/500 iters), loss = 0.0867584
I0901 10:06:29.001188 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0867626 (* 1 = 0.0867626 loss)
I0901 10:06:29.001195 916722 sgd_solver.cpp:106] Iteration 4364500, lr = 0.01
I0901 10:06:58.729565 916722 solver.cpp:218] Iteration 4365000 (16.8189 iter/s, 29.7284s/500 iters), loss = 0.222871
I0901 10:06:58.729626 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.222875 (* 1 = 0.222875 loss)
I0901 10:06:58.729635 916722 sgd_solver.cpp:106] Iteration 4365000, lr = 0.01
I0901 10:07:28.454810 916722 solver.cpp:218] Iteration 4365500 (16.8208 iter/s, 29.7252s/500 iters), loss = 0.102355
I0901 10:07:28.454864 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.102359 (* 1 = 0.102359 loss)
I0901 10:07:28.454871 916722 sgd_solver.cpp:106] Iteration 4365500, lr = 0.01
I0901 10:07:58.181582 916722 solver.cpp:218] Iteration 4366000 (16.8199 iter/s, 29.7267s/500 iters), loss = 0.143848
I0901 10:07:58.181641 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.143852 (* 1 = 0.143852 loss)
I0901 10:07:58.181650 916722 sgd_solver.cpp:106] Iteration 4366000, lr = 0.01
I0901 10:08:27.909165 916722 solver.cpp:218] Iteration 4366500 (16.8195 iter/s, 29.7275s/500 iters), loss = 0.254002
I0901 10:08:27.909216 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.254006 (* 1 = 0.254006 loss)
I0901 10:08:27.909225 916722 sgd_solver.cpp:106] Iteration 4366500, lr = 0.01
I0901 10:08:57.637466 916722 solver.cpp:218] Iteration 4367000 (16.8191 iter/s, 29.7282s/500 iters), loss = 0.0496533
I0901 10:08:57.637521 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0496575 (* 1 = 0.0496575 loss)
I0901 10:08:57.637529 916722 sgd_solver.cpp:106] Iteration 4367000, lr = 0.01
I0901 10:09:27.364845 916722 solver.cpp:218] Iteration 4367500 (16.8196 iter/s, 29.7272s/500 iters), loss = 0.0432698
I0901 10:09:27.364895 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0432739 (* 1 = 0.0432739 loss)
I0901 10:09:27.364904 916722 sgd_solver.cpp:106] Iteration 4367500, lr = 0.01
I0901 10:09:57.092901 916722 solver.cpp:218] Iteration 4368000 (16.8192 iter/s, 29.7279s/500 iters), loss = 0.150602
I0901 10:09:57.092962 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.150606 (* 1 = 0.150606 loss)
I0901 10:09:57.092970 916722 sgd_solver.cpp:106] Iteration 4368000, lr = 0.01
I0901 10:10:26.821333 916722 solver.cpp:218] Iteration 4368500 (16.819 iter/s, 29.7283s/500 iters), loss = 0.265747
I0901 10:10:26.821384 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.265751 (* 1 = 0.265751 loss)
I0901 10:10:26.821394 916722 sgd_solver.cpp:106] Iteration 4368500, lr = 0.01
I0901 10:10:56.549048 916722 solver.cpp:218] Iteration 4369000 (16.8194 iter/s, 29.7275s/500 iters), loss = 0.282413
I0901 10:10:56.549108 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.282417 (* 1 = 0.282417 loss)
I0901 10:10:56.549115 916722 sgd_solver.cpp:106] Iteration 4369000, lr = 0.01
I0901 10:11:26.279093 916722 solver.cpp:218] Iteration 4369500 (16.8181 iter/s, 29.7299s/500 iters), loss = 0.0407508
I0901 10:11:26.279145 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0407546 (* 1 = 0.0407546 loss)
I0901 10:11:26.279155 916722 sgd_solver.cpp:106] Iteration 4369500, lr = 0.01
I0901 10:11:56.006150 916722 solver.cpp:218] Iteration 4370000 (16.8198 iter/s, 29.7269s/500 iters), loss = 0.103163
I0901 10:11:56.006208 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.103167 (* 1 = 0.103167 loss)
I0901 10:11:56.006217 916722 sgd_solver.cpp:106] Iteration 4370000, lr = 0.01
I0901 10:12:25.734966 916722 solver.cpp:218] Iteration 4370500 (16.8188 iter/s, 29.7286s/500 iters), loss = 0.153813
I0901 10:12:25.735015 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.153817 (* 1 = 0.153817 loss)
I0901 10:12:25.735038 916722 sgd_solver.cpp:106] Iteration 4370500, lr = 0.01
I0901 10:12:55.461629 916722 solver.cpp:218] Iteration 4371000 (16.82 iter/s, 29.7264s/500 iters), loss = 0.13209
I0901 10:12:55.461701 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.132093 (* 1 = 0.132093 loss)
I0901 10:12:55.461709 916722 sgd_solver.cpp:106] Iteration 4371000, lr = 0.01
I0901 10:13:25.189730 916722 solver.cpp:218] Iteration 4371500 (16.8192 iter/s, 29.7279s/500 iters), loss = 0.233613
I0901 10:13:25.189777 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.233617 (* 1 = 0.233617 loss)
I0901 10:13:25.189785 916722 sgd_solver.cpp:106] Iteration 4371500, lr = 0.01
I0901 10:13:54.918294 916722 solver.cpp:218] Iteration 4372000 (16.819 iter/s, 29.7283s/500 iters), loss = 0.064013
I0901 10:13:54.918356 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0640169 (* 1 = 0.0640169 loss)
I0901 10:13:54.918365 916722 sgd_solver.cpp:106] Iteration 4372000, lr = 0.01
I0901 10:14:24.644348 916722 solver.cpp:218] Iteration 4372500 (16.8204 iter/s, 29.7258s/500 iters), loss = 0.067683
I0901 10:14:24.644402 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0676868 (* 1 = 0.0676868 loss)
I0901 10:14:24.644409 916722 sgd_solver.cpp:106] Iteration 4372500, lr = 0.01
I0901 10:14:54.369285 916722 solver.cpp:218] Iteration 4373000 (16.821 iter/s, 29.7247s/500 iters), loss = 0.288763
I0901 10:14:54.369346 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.288767 (* 1 = 0.288767 loss)
I0901 10:14:54.369355 916722 sgd_solver.cpp:106] Iteration 4373000, lr = 0.01
I0901 10:15:24.093916 916722 solver.cpp:218] Iteration 4373500 (16.8212 iter/s, 29.7244s/500 iters), loss = 0.16318
I0901 10:15:24.093968 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.163184 (* 1 = 0.163184 loss)
I0901 10:15:24.093976 916722 sgd_solver.cpp:106] Iteration 4373500, lr = 0.01
I0901 10:15:53.824645 916722 solver.cpp:218] Iteration 4374000 (16.8178 iter/s, 29.7305s/500 iters), loss = 0.0491846
I0901 10:15:53.824707 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0491887 (* 1 = 0.0491887 loss)
I0901 10:15:53.824715 916722 sgd_solver.cpp:106] Iteration 4374000, lr = 0.01
I0901 10:16:23.551054 916722 solver.cpp:218] Iteration 4374500 (16.8202 iter/s, 29.7261s/500 iters), loss = 0.0633837
I0901 10:16:23.551103 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0633878 (* 1 = 0.0633878 loss)
I0901 10:16:23.551112 916722 sgd_solver.cpp:106] Iteration 4374500, lr = 0.01
I0901 10:16:53.283123 916722 solver.cpp:218] Iteration 4375000 (16.817 iter/s, 29.7318s/500 iters), loss = 0.0124363
I0901 10:16:53.283183 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0124404 (* 1 = 0.0124404 loss)
I0901 10:16:53.283191 916722 sgd_solver.cpp:106] Iteration 4375000, lr = 0.01
I0901 10:17:23.013684 916722 solver.cpp:218] Iteration 4375500 (16.8179 iter/s, 29.7303s/500 iters), loss = 0.129429
I0901 10:17:23.013731 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.129433 (* 1 = 0.129433 loss)
I0901 10:17:23.013739 916722 sgd_solver.cpp:106] Iteration 4375500, lr = 0.01
I0901 10:17:52.745702 916722 solver.cpp:218] Iteration 4376000 (16.817 iter/s, 29.7317s/500 iters), loss = 0.101267
I0901 10:17:52.745759 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101271 (* 1 = 0.101271 loss)
I0901 10:17:52.745766 916722 sgd_solver.cpp:106] Iteration 4376000, lr = 0.01
I0901 10:18:22.475212 916722 solver.cpp:218] Iteration 4376500 (16.8185 iter/s, 29.7292s/500 iters), loss = 0.270615
I0901 10:18:22.475262 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.270619 (* 1 = 0.270619 loss)
I0901 10:18:22.475272 916722 sgd_solver.cpp:106] Iteration 4376500, lr = 0.01
I0901 10:18:52.206784 916722 solver.cpp:218] Iteration 4377000 (16.8173 iter/s, 29.7313s/500 iters), loss = 0.0737675
I0901 10:18:52.206856 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0737715 (* 1 = 0.0737715 loss)
I0901 10:18:52.206864 916722 sgd_solver.cpp:106] Iteration 4377000, lr = 0.01
I0901 10:19:21.935253 916722 solver.cpp:218] Iteration 4377500 (16.8191 iter/s, 29.7282s/500 iters), loss = 0.0180522
I0901 10:19:21.935303 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0180561 (* 1 = 0.0180561 loss)
I0901 10:19:21.935313 916722 sgd_solver.cpp:106] Iteration 4377500, lr = 0.01
I0901 10:19:51.663723 916722 solver.cpp:218] Iteration 4378000 (16.8191 iter/s, 29.7282s/500 iters), loss = 0.104873
I0901 10:19:51.663784 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104877 (* 1 = 0.104877 loss)
I0901 10:19:51.663794 916722 sgd_solver.cpp:106] Iteration 4378000, lr = 0.01
I0901 10:20:21.392683 916722 solver.cpp:218] Iteration 4378500 (16.8188 iter/s, 29.7286s/500 iters), loss = 0.339251
I0901 10:20:21.392735 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.339255 (* 1 = 0.339255 loss)
I0901 10:20:21.392755 916722 sgd_solver.cpp:106] Iteration 4378500, lr = 0.01
I0901 10:20:51.122560 916722 solver.cpp:218] Iteration 4379000 (16.8183 iter/s, 29.7296s/500 iters), loss = 0.252879
I0901 10:20:51.122617 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.252883 (* 1 = 0.252883 loss)
I0901 10:20:51.122625 916722 sgd_solver.cpp:106] Iteration 4379000, lr = 0.01
I0901 10:21:20.851994 916722 solver.cpp:218] Iteration 4379500 (16.8185 iter/s, 29.7291s/500 iters), loss = 0.20257
I0901 10:21:20.852044 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.202574 (* 1 = 0.202574 loss)
I0901 10:21:20.852053 916722 sgd_solver.cpp:106] Iteration 4379500, lr = 0.01
I0901 10:21:50.580051 916722 solver.cpp:218] Iteration 4380000 (16.8193 iter/s, 29.7277s/500 iters), loss = 0.13391
I0901 10:21:50.580107 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133914 (* 1 = 0.133914 loss)
I0901 10:21:50.580116 916722 sgd_solver.cpp:106] Iteration 4380000, lr = 0.01
I0901 10:22:20.307646 916722 solver.cpp:218] Iteration 4380500 (16.8196 iter/s, 29.7273s/500 iters), loss = 0.028381
I0901 10:22:20.307695 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0283848 (* 1 = 0.0283848 loss)
I0901 10:22:20.307705 916722 sgd_solver.cpp:106] Iteration 4380500, lr = 0.01
I0901 10:22:50.036960 916722 solver.cpp:218] Iteration 4381000 (16.8186 iter/s, 29.729s/500 iters), loss = 0.104222
I0901 10:22:50.037020 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104226 (* 1 = 0.104226 loss)
I0901 10:22:50.037029 916722 sgd_solver.cpp:106] Iteration 4381000, lr = 0.01
I0901 10:23:19.766743 916722 solver.cpp:218] Iteration 4381500 (16.8183 iter/s, 29.7295s/500 iters), loss = 0.0786656
I0901 10:23:19.766795 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0786691 (* 1 = 0.0786691 loss)
I0901 10:23:19.766805 916722 sgd_solver.cpp:106] Iteration 4381500, lr = 0.01
I0901 10:23:49.501955 916722 solver.cpp:218] Iteration 4382000 (16.8153 iter/s, 29.7349s/500 iters), loss = 0.100956
I0901 10:23:49.502017 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.10096 (* 1 = 0.10096 loss)
I0901 10:23:49.502027 916722 sgd_solver.cpp:106] Iteration 4382000, lr = 0.01
I0901 10:24:19.230751 916722 solver.cpp:218] Iteration 4382500 (16.8189 iter/s, 29.7285s/500 iters), loss = 0.207643
I0901 10:24:19.230803 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.207647 (* 1 = 0.207647 loss)
I0901 10:24:19.230811 916722 sgd_solver.cpp:106] Iteration 4382500, lr = 0.01
I0901 10:24:48.963137 916722 solver.cpp:218] Iteration 4383000 (16.8169 iter/s, 29.7321s/500 iters), loss = 0.0798494
I0901 10:24:48.963198 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.079853 (* 1 = 0.079853 loss)
I0901 10:24:48.963207 916722 sgd_solver.cpp:106] Iteration 4383000, lr = 0.01
I0901 10:25:18.692515 916722 solver.cpp:218] Iteration 4383500 (16.8186 iter/s, 29.729s/500 iters), loss = 0.0123302
I0901 10:25:18.692567 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0123337 (* 1 = 0.0123337 loss)
I0901 10:25:18.692575 916722 sgd_solver.cpp:106] Iteration 4383500, lr = 0.01
I0901 10:25:48.425386 916722 solver.cpp:218] Iteration 4384000 (16.8166 iter/s, 29.7325s/500 iters), loss = 0.0618491
I0901 10:25:48.425457 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0618527 (* 1 = 0.0618527 loss)
I0901 10:25:48.425467 916722 sgd_solver.cpp:106] Iteration 4384000, lr = 0.01
I0901 10:26:18.155457 916722 solver.cpp:218] Iteration 4384500 (16.8182 iter/s, 29.7297s/500 iters), loss = 0.0750291
I0901 10:26:18.155508 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0750325 (* 1 = 0.0750325 loss)
I0901 10:26:18.155516 916722 sgd_solver.cpp:106] Iteration 4384500, lr = 0.01
I0901 10:26:47.885682 916722 solver.cpp:218] Iteration 4385000 (16.8181 iter/s, 29.7299s/500 iters), loss = 0.33669
I0901 10:26:47.885740 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.336693 (* 1 = 0.336693 loss)
I0901 10:26:47.885747 916722 sgd_solver.cpp:106] Iteration 4385000, lr = 0.01
I0901 10:27:17.616272 916722 solver.cpp:218] Iteration 4385500 (16.8179 iter/s, 29.7302s/500 iters), loss = 0.0725774
I0901 10:27:17.616323 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0725808 (* 1 = 0.0725808 loss)
I0901 10:27:17.616333 916722 sgd_solver.cpp:106] Iteration 4385500, lr = 0.01
I0901 10:27:47.345125 916722 solver.cpp:218] Iteration 4386000 (16.8189 iter/s, 29.7285s/500 iters), loss = 0.0633149
I0901 10:27:47.345188 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0633183 (* 1 = 0.0633183 loss)
I0901 10:27:47.345196 916722 sgd_solver.cpp:106] Iteration 4386000, lr = 0.01
I0901 10:28:17.074477 916722 solver.cpp:218] Iteration 4386500 (16.8186 iter/s, 29.729s/500 iters), loss = 0.321902
I0901 10:28:17.074528 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.321905 (* 1 = 0.321905 loss)
I0901 10:28:17.074537 916722 sgd_solver.cpp:106] Iteration 4386500, lr = 0.01
I0901 10:28:46.803627 916722 solver.cpp:218] Iteration 4387000 (16.8187 iter/s, 29.7288s/500 iters), loss = 0.0996407
I0901 10:28:46.803689 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0996441 (* 1 = 0.0996441 loss)
I0901 10:28:46.803696 916722 sgd_solver.cpp:106] Iteration 4387000, lr = 0.01
I0901 10:29:16.531780 916722 solver.cpp:218] Iteration 4387500 (16.8193 iter/s, 29.7278s/500 iters), loss = 0.0878288
I0901 10:29:16.531832 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0878321 (* 1 = 0.0878321 loss)
I0901 10:29:16.531841 916722 sgd_solver.cpp:106] Iteration 4387500, lr = 0.01
I0901 10:29:46.259668 916722 solver.cpp:218] Iteration 4388000 (16.8194 iter/s, 29.7275s/500 iters), loss = 0.0468791
I0901 10:29:46.259729 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0468825 (* 1 = 0.0468825 loss)
I0901 10:29:46.259737 916722 sgd_solver.cpp:106] Iteration 4388000, lr = 0.01
I0901 10:30:15.989702 916722 solver.cpp:218] Iteration 4388500 (16.8182 iter/s, 29.7297s/500 iters), loss = 0.0535033
I0901 10:30:15.989754 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0535066 (* 1 = 0.0535066 loss)
I0901 10:30:15.989764 916722 sgd_solver.cpp:106] Iteration 4388500, lr = 0.01
I0901 10:30:45.715780 916722 solver.cpp:218] Iteration 4389000 (16.8204 iter/s, 29.7257s/500 iters), loss = 0.0808092
I0901 10:30:45.715840 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0808124 (* 1 = 0.0808124 loss)
I0901 10:30:45.715848 916722 sgd_solver.cpp:106] Iteration 4389000, lr = 0.01
I0901 10:31:15.447531 916722 solver.cpp:218] Iteration 4389500 (16.8172 iter/s, 29.7314s/500 iters), loss = 0.0993851
I0901 10:31:15.447582 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0993883 (* 1 = 0.0993883 loss)
I0901 10:31:15.447590 916722 sgd_solver.cpp:106] Iteration 4389500, lr = 0.01
I0901 10:31:45.176542 916722 solver.cpp:218] Iteration 4390000 (16.8188 iter/s, 29.7287s/500 iters), loss = 0.102
I0901 10:31:45.176599 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.102003 (* 1 = 0.102003 loss)
I0901 10:31:45.176606 916722 sgd_solver.cpp:106] Iteration 4390000, lr = 0.01
I0901 10:32:14.903992 916722 solver.cpp:218] Iteration 4390500 (16.8192 iter/s, 29.728s/500 iters), loss = 0.0893209
I0901 10:32:14.904055 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.089324 (* 1 = 0.089324 loss)
I0901 10:32:14.904067 916722 sgd_solver.cpp:106] Iteration 4390500, lr = 0.01
I0901 10:32:44.635179 916722 solver.cpp:218] Iteration 4391000 (16.8171 iter/s, 29.7317s/500 iters), loss = 0.176555
I0901 10:32:44.635251 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.176558 (* 1 = 0.176558 loss)
I0901 10:32:44.635260 916722 sgd_solver.cpp:106] Iteration 4391000, lr = 0.01
I0901 10:33:14.363415 916722 solver.cpp:218] Iteration 4391500 (16.8188 iter/s, 29.7287s/500 iters), loss = 0.33005
I0901 10:33:14.363464 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.330053 (* 1 = 0.330053 loss)
I0901 10:33:14.363474 916722 sgd_solver.cpp:106] Iteration 4391500, lr = 0.01
I0901 10:33:44.094606 916722 solver.cpp:218] Iteration 4392000 (16.8171 iter/s, 29.7316s/500 iters), loss = 0.182875
I0901 10:33:44.094666 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.182878 (* 1 = 0.182878 loss)
I0901 10:33:44.094673 916722 sgd_solver.cpp:106] Iteration 4392000, lr = 0.01
I0901 10:34:13.823546 916722 solver.cpp:218] Iteration 4392500 (16.8184 iter/s, 29.7293s/500 iters), loss = 0.228521
I0901 10:34:13.823596 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.228524 (* 1 = 0.228524 loss)
I0901 10:34:13.823606 916722 sgd_solver.cpp:106] Iteration 4392500, lr = 0.01
I0901 10:34:43.554176 916722 solver.cpp:218] Iteration 4393000 (16.8175 iter/s, 29.731s/500 iters), loss = 0.0226871
I0901 10:34:43.554236 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0226901 (* 1 = 0.0226901 loss)
I0901 10:34:43.554244 916722 sgd_solver.cpp:106] Iteration 4393000, lr = 0.01
I0901 10:35:13.284018 916722 solver.cpp:218] Iteration 4393500 (16.818 iter/s, 29.7301s/500 iters), loss = 0.172371
I0901 10:35:13.284066 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.172374 (* 1 = 0.172374 loss)
I0901 10:35:13.284076 916722 sgd_solver.cpp:106] Iteration 4393500, lr = 0.01
I0901 10:35:43.012547 916722 solver.cpp:218] Iteration 4394000 (16.8187 iter/s, 29.7288s/500 iters), loss = 0.425004
I0901 10:35:43.012604 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.425008 (* 1 = 0.425008 loss)
I0901 10:35:43.012614 916722 sgd_solver.cpp:106] Iteration 4394000, lr = 0.01
I0901 10:36:12.745296 916722 solver.cpp:218] Iteration 4394500 (16.8163 iter/s, 29.733s/500 iters), loss = 0.0592839
I0901 10:36:12.745345 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.059287 (* 1 = 0.059287 loss)
I0901 10:36:12.745355 916722 sgd_solver.cpp:106] Iteration 4394500, lr = 0.01
I0901 10:36:42.471788 916722 solver.cpp:218] Iteration 4395000 (16.8199 iter/s, 29.7267s/500 iters), loss = 0.175914
I0901 10:36:42.471850 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.175917 (* 1 = 0.175917 loss)
I0901 10:36:42.471858 916722 sgd_solver.cpp:106] Iteration 4395000, lr = 0.01
I0901 10:37:12.196725 916722 solver.cpp:218] Iteration 4395500 (16.8208 iter/s, 29.7251s/500 iters), loss = 0.0280062
I0901 10:37:12.196789 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0280094 (* 1 = 0.0280094 loss)
I0901 10:37:12.196797 916722 sgd_solver.cpp:106] Iteration 4395500, lr = 0.01
I0901 10:37:41.923584 916722 solver.cpp:218] Iteration 4396000 (16.8197 iter/s, 29.727s/500 iters), loss = 0.137333
I0901 10:37:41.923642 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.137336 (* 1 = 0.137336 loss)
I0901 10:37:41.923651 916722 sgd_solver.cpp:106] Iteration 4396000, lr = 0.01
I0901 10:38:11.650796 916722 solver.cpp:218] Iteration 4396500 (16.8195 iter/s, 29.7273s/500 iters), loss = 0.0448889
I0901 10:38:11.650846 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0448923 (* 1 = 0.0448923 loss)
I0901 10:38:11.650854 916722 sgd_solver.cpp:106] Iteration 4396500, lr = 0.01
I0901 10:38:41.376724 916722 solver.cpp:218] Iteration 4397000 (16.8203 iter/s, 29.726s/500 iters), loss = 0.0811042
I0901 10:38:41.376812 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0811076 (* 1 = 0.0811076 loss)
I0901 10:38:41.376821 916722 sgd_solver.cpp:106] Iteration 4397000, lr = 0.01
I0901 10:39:11.106024 916722 solver.cpp:218] Iteration 4397500 (16.8184 iter/s, 29.7293s/500 iters), loss = 0.158251
I0901 10:39:11.106074 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.158254 (* 1 = 0.158254 loss)
I0901 10:39:11.106084 916722 sgd_solver.cpp:106] Iteration 4397500, lr = 0.01
I0901 10:39:40.836951 916722 solver.cpp:218] Iteration 4398000 (16.8175 iter/s, 29.731s/500 iters), loss = 0.070254
I0901 10:39:40.837013 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0702573 (* 1 = 0.0702573 loss)
I0901 10:39:40.837023 916722 sgd_solver.cpp:106] Iteration 4398000, lr = 0.01
I0901 10:40:10.571408 916722 solver.cpp:218] Iteration 4398500 (16.8155 iter/s, 29.7345s/500 iters), loss = 0.248252
I0901 10:40:10.571460 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.248255 (* 1 = 0.248255 loss)
I0901 10:40:10.571468 916722 sgd_solver.cpp:106] Iteration 4398500, lr = 0.01
I0901 10:40:40.303661 916722 solver.cpp:218] Iteration 4399000 (16.8167 iter/s, 29.7323s/500 iters), loss = 0.230339
I0901 10:40:40.303722 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.230343 (* 1 = 0.230343 loss)
I0901 10:40:40.303730 916722 sgd_solver.cpp:106] Iteration 4399000, lr = 0.01
I0901 10:41:10.033900 916722 solver.cpp:218] Iteration 4399500 (16.8179 iter/s, 29.7302s/500 iters), loss = 0.0371869
I0901 10:41:10.033949 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0371901 (* 1 = 0.0371901 loss)
I0901 10:41:10.033957 916722 sgd_solver.cpp:106] Iteration 4399500, lr = 0.01
I0901 10:41:39.706647 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_4400000.caffemodel
I0901 10:41:39.725772 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_4400000.solverstate
I0901 10:41:39.731837 916722 solver.cpp:330] Iteration 4400000, Testing net (#0)
I0901 10:41:55.143172 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8828
I0901 10:41:55.143215 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.407947 (* 1 = 0.407947 loss)
I0901 10:41:55.201841 916722 solver.cpp:218] Iteration 4400000 (11.0698 iter/s, 45.168s/500 iters), loss = 0.134449
I0901 10:41:55.201870 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.134452 (* 1 = 0.134452 loss)
I0901 10:41:55.201879 916722 sgd_solver.cpp:106] Iteration 4400000, lr = 0.01
I0901 10:42:24.836279 916722 solver.cpp:218] Iteration 4400500 (16.8723 iter/s, 29.6344s/500 iters), loss = 0.126955
I0901 10:42:24.836342 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.126958 (* 1 = 0.126958 loss)
I0901 10:42:24.836350 916722 sgd_solver.cpp:106] Iteration 4400500, lr = 0.01
I0901 10:42:54.538408 916722 solver.cpp:218] Iteration 4401000 (16.8339 iter/s, 29.7021s/500 iters), loss = 0.130001
I0901 10:42:54.538460 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130004 (* 1 = 0.130004 loss)
I0901 10:42:54.538467 916722 sgd_solver.cpp:106] Iteration 4401000, lr = 0.01
I0901 10:43:24.245769 916722 solver.cpp:218] Iteration 4401500 (16.8309 iter/s, 29.7073s/500 iters), loss = 0.0817417
I0901 10:43:24.245831 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0817448 (* 1 = 0.0817448 loss)
I0901 10:43:24.245841 916722 sgd_solver.cpp:106] Iteration 4401500, lr = 0.01
I0901 10:43:53.952082 916722 solver.cpp:218] Iteration 4402000 (16.8315 iter/s, 29.7062s/500 iters), loss = 0.433092
I0901 10:43:53.952136 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.433095 (* 1 = 0.433095 loss)
I0901 10:43:53.952145 916722 sgd_solver.cpp:106] Iteration 4402000, lr = 0.01
I0901 10:44:23.659577 916722 solver.cpp:218] Iteration 4402500 (16.8308 iter/s, 29.7074s/500 iters), loss = 0.103642
I0901 10:44:23.659644 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.103645 (* 1 = 0.103645 loss)
I0901 10:44:23.659662 916722 sgd_solver.cpp:106] Iteration 4402500, lr = 0.01
I0901 10:44:53.365015 916722 solver.cpp:218] Iteration 4403000 (16.832 iter/s, 29.7053s/500 iters), loss = 0.0634388
I0901 10:44:53.365061 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0634422 (* 1 = 0.0634422 loss)
I0901 10:44:53.365070 916722 sgd_solver.cpp:106] Iteration 4403000, lr = 0.01
I0901 10:45:23.071998 916722 solver.cpp:218] Iteration 4403500 (16.8311 iter/s, 29.7069s/500 iters), loss = 0.120832
I0901 10:45:23.072058 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.120835 (* 1 = 0.120835 loss)
I0901 10:45:23.072067 916722 sgd_solver.cpp:106] Iteration 4403500, lr = 0.01
I0901 10:45:52.778347 916722 solver.cpp:218] Iteration 4404000 (16.8315 iter/s, 29.7062s/500 iters), loss = 0.10625
I0901 10:45:52.778398 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.106254 (* 1 = 0.106254 loss)
I0901 10:45:52.778406 916722 sgd_solver.cpp:106] Iteration 4404000, lr = 0.01
I0901 10:46:22.486210 916722 solver.cpp:218] Iteration 4404500 (16.8306 iter/s, 29.7077s/500 iters), loss = 0.0932336
I0901 10:46:22.486271 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.093237 (* 1 = 0.093237 loss)
I0901 10:46:22.486280 916722 sgd_solver.cpp:106] Iteration 4404500, lr = 0.01
I0901 10:46:52.192574 916722 solver.cpp:218] Iteration 4405000 (16.8315 iter/s, 29.7062s/500 iters), loss = 0.134598
I0901 10:46:52.192623 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.134602 (* 1 = 0.134602 loss)
I0901 10:46:52.192633 916722 sgd_solver.cpp:106] Iteration 4405000, lr = 0.01
I0901 10:47:21.900602 916722 solver.cpp:218] Iteration 4405500 (16.8305 iter/s, 29.7079s/500 iters), loss = 0.0278794
I0901 10:47:21.900666 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.027883 (* 1 = 0.027883 loss)
I0901 10:47:21.900676 916722 sgd_solver.cpp:106] Iteration 4405500, lr = 0.01
I0901 10:47:51.606760 916722 solver.cpp:218] Iteration 4406000 (16.8316 iter/s, 29.706s/500 iters), loss = 0.0652021
I0901 10:47:51.606813 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0652056 (* 1 = 0.0652056 loss)
I0901 10:47:51.606822 916722 sgd_solver.cpp:106] Iteration 4406000, lr = 0.01
I0901 10:48:21.314324 916722 solver.cpp:218] Iteration 4406500 (16.8308 iter/s, 29.7074s/500 iters), loss = 0.250924
I0901 10:48:21.314383 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.250928 (* 1 = 0.250928 loss)
I0901 10:48:21.314393 916722 sgd_solver.cpp:106] Iteration 4406500, lr = 0.01
I0901 10:48:51.022933 916722 solver.cpp:218] Iteration 4407000 (16.8302 iter/s, 29.7085s/500 iters), loss = 0.12178
I0901 10:48:51.022981 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.121784 (* 1 = 0.121784 loss)
I0901 10:48:51.022990 916722 sgd_solver.cpp:106] Iteration 4407000, lr = 0.01
I0901 10:49:20.728667 916722 solver.cpp:218] Iteration 4407500 (16.8319 iter/s, 29.7056s/500 iters), loss = 0.27329
I0901 10:49:20.728722 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.273294 (* 1 = 0.273294 loss)
I0901 10:49:20.728730 916722 sgd_solver.cpp:106] Iteration 4407500, lr = 0.01
I0901 10:49:50.434324 916722 solver.cpp:218] Iteration 4408000 (16.8319 iter/s, 29.7055s/500 iters), loss = 0.0523579
I0901 10:49:50.434376 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0523617 (* 1 = 0.0523617 loss)
I0901 10:49:50.434386 916722 sgd_solver.cpp:106] Iteration 4408000, lr = 0.01
I0901 10:50:20.138564 916722 solver.cpp:218] Iteration 4408500 (16.8327 iter/s, 29.7041s/500 iters), loss = 0.0388273
I0901 10:50:20.138626 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0388312 (* 1 = 0.0388312 loss)
I0901 10:50:20.138634 916722 sgd_solver.cpp:106] Iteration 4408500, lr = 0.01
I0901 10:50:49.845794 916722 solver.cpp:218] Iteration 4409000 (16.831 iter/s, 29.707s/500 iters), loss = 0.322183
I0901 10:50:49.845845 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.322187 (* 1 = 0.322187 loss)
I0901 10:50:49.845868 916722 sgd_solver.cpp:106] Iteration 4409000, lr = 0.01
I0901 10:51:19.554184 916722 solver.cpp:218] Iteration 4409500 (16.8304 iter/s, 29.7082s/500 iters), loss = 0.052885
I0901 10:51:19.554257 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0528889 (* 1 = 0.0528889 loss)
I0901 10:51:19.554266 916722 sgd_solver.cpp:106] Iteration 4409500, lr = 0.01
I0901 10:51:49.262795 916722 solver.cpp:218] Iteration 4410000 (16.8303 iter/s, 29.7084s/500 iters), loss = 0.0619742
I0901 10:51:49.262849 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0619779 (* 1 = 0.0619779 loss)
I0901 10:51:49.262859 916722 sgd_solver.cpp:106] Iteration 4410000, lr = 0.01
I0901 10:52:18.970034 916722 solver.cpp:218] Iteration 4410500 (16.831 iter/s, 29.707s/500 iters), loss = 0.152433
I0901 10:52:18.970095 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152437 (* 1 = 0.152437 loss)
I0901 10:52:18.970103 916722 sgd_solver.cpp:106] Iteration 4410500, lr = 0.01
I0901 10:52:48.682114 916722 solver.cpp:218] Iteration 4411000 (16.8283 iter/s, 29.7119s/500 iters), loss = 0.163909
I0901 10:52:48.682164 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.163913 (* 1 = 0.163913 loss)
I0901 10:52:48.682174 916722 sgd_solver.cpp:106] Iteration 4411000, lr = 0.01
I0901 10:53:18.392035 916722 solver.cpp:218] Iteration 4411500 (16.8295 iter/s, 29.7097s/500 iters), loss = 0.200904
I0901 10:53:18.392094 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.200908 (* 1 = 0.200908 loss)
I0901 10:53:18.392102 916722 sgd_solver.cpp:106] Iteration 4411500, lr = 0.01
I0901 10:53:48.099339 916722 solver.cpp:218] Iteration 4412000 (16.831 iter/s, 29.7071s/500 iters), loss = 0.0746686
I0901 10:53:48.099390 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0746725 (* 1 = 0.0746725 loss)
I0901 10:53:48.099398 916722 sgd_solver.cpp:106] Iteration 4412000, lr = 0.01
I0901 10:54:17.807199 916722 solver.cpp:218] Iteration 4412500 (16.8307 iter/s, 29.7077s/500 iters), loss = 0.123123
I0901 10:54:17.807260 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.123127 (* 1 = 0.123127 loss)
I0901 10:54:17.807267 916722 sgd_solver.cpp:106] Iteration 4412500, lr = 0.01
I0901 10:54:47.515261 916722 solver.cpp:218] Iteration 4413000 (16.8306 iter/s, 29.7078s/500 iters), loss = 0.162592
I0901 10:54:47.515311 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.162596 (* 1 = 0.162596 loss)
I0901 10:54:47.515321 916722 sgd_solver.cpp:106] Iteration 4413000, lr = 0.01
I0901 10:55:17.222002 916722 solver.cpp:218] Iteration 4413500 (16.8313 iter/s, 29.7065s/500 iters), loss = 0.0650811
I0901 10:55:17.222064 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0650848 (* 1 = 0.0650848 loss)
I0901 10:55:17.222074 916722 sgd_solver.cpp:106] Iteration 4413500, lr = 0.01
I0901 10:55:46.926132 916722 solver.cpp:218] Iteration 4414000 (16.8328 iter/s, 29.7039s/500 iters), loss = 0.09867
I0901 10:55:46.926184 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0986738 (* 1 = 0.0986738 loss)
I0901 10:55:46.926192 916722 sgd_solver.cpp:106] Iteration 4414000, lr = 0.01
I0901 10:56:16.637825 916722 solver.cpp:218] Iteration 4414500 (16.8285 iter/s, 29.7115s/500 iters), loss = 0.071828
I0901 10:56:16.637887 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0718317 (* 1 = 0.0718317 loss)
I0901 10:56:16.637895 916722 sgd_solver.cpp:106] Iteration 4414500, lr = 0.01
I0901 10:56:46.345664 916722 solver.cpp:218] Iteration 4415000 (16.8307 iter/s, 29.7076s/500 iters), loss = 0.0489497
I0901 10:56:46.345713 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0489536 (* 1 = 0.0489536 loss)
I0901 10:56:46.345722 916722 sgd_solver.cpp:106] Iteration 4415000, lr = 0.01
I0901 10:57:16.054663 916722 solver.cpp:218] Iteration 4415500 (16.83 iter/s, 29.7088s/500 iters), loss = 0.0677889
I0901 10:57:16.054734 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0677926 (* 1 = 0.0677926 loss)
I0901 10:57:16.054742 916722 sgd_solver.cpp:106] Iteration 4415500, lr = 0.01
I0901 10:57:45.766001 916722 solver.cpp:218] Iteration 4416000 (16.8287 iter/s, 29.7111s/500 iters), loss = 0.0436814
I0901 10:57:45.766049 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0436852 (* 1 = 0.0436852 loss)
I0901 10:57:45.766057 916722 sgd_solver.cpp:106] Iteration 4416000, lr = 0.01
I0901 10:58:15.473640 916722 solver.cpp:218] Iteration 4416500 (16.8308 iter/s, 29.7074s/500 iters), loss = 0.208763
I0901 10:58:15.473701 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.208766 (* 1 = 0.208766 loss)
I0901 10:58:15.473711 916722 sgd_solver.cpp:106] Iteration 4416500, lr = 0.01
I0901 10:58:45.181778 916722 solver.cpp:218] Iteration 4417000 (16.8305 iter/s, 29.7079s/500 iters), loss = 0.0349382
I0901 10:58:45.181833 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0349418 (* 1 = 0.0349418 loss)
I0901 10:58:45.181843 916722 sgd_solver.cpp:106] Iteration 4417000, lr = 0.01
I0901 10:59:14.894167 916722 solver.cpp:218] Iteration 4417500 (16.8281 iter/s, 29.7122s/500 iters), loss = 0.0947942
I0901 10:59:14.894227 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0947978 (* 1 = 0.0947978 loss)
I0901 10:59:14.894234 916722 sgd_solver.cpp:106] Iteration 4417500, lr = 0.01
I0901 10:59:44.606492 916722 solver.cpp:218] Iteration 4418000 (16.8282 iter/s, 29.7121s/500 iters), loss = 0.115294
I0901 10:59:44.606544 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115298 (* 1 = 0.115298 loss)
I0901 10:59:44.606554 916722 sgd_solver.cpp:106] Iteration 4418000, lr = 0.01
I0901 11:00:14.322118 916722 solver.cpp:218] Iteration 4418500 (16.8263 iter/s, 29.7154s/500 iters), loss = 0.138029
I0901 11:00:14.322176 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.138032 (* 1 = 0.138032 loss)
I0901 11:00:14.322185 916722 sgd_solver.cpp:106] Iteration 4418500, lr = 0.01
I0901 11:00:44.032438 916722 solver.cpp:218] Iteration 4419000 (16.8293 iter/s, 29.7101s/500 iters), loss = 0.0669991
I0901 11:00:44.032487 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0670026 (* 1 = 0.0670026 loss)
I0901 11:00:44.032497 916722 sgd_solver.cpp:106] Iteration 4419000, lr = 0.01
I0901 11:01:13.741226 916722 solver.cpp:218] Iteration 4419500 (16.8302 iter/s, 29.7086s/500 iters), loss = 0.0999344
I0901 11:01:13.741287 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0999379 (* 1 = 0.0999379 loss)
I0901 11:01:13.741295 916722 sgd_solver.cpp:106] Iteration 4419500, lr = 0.01
I0901 11:01:43.452066 916722 solver.cpp:218] Iteration 4420000 (16.829 iter/s, 29.7106s/500 iters), loss = 0.141232
I0901 11:01:43.452116 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.141235 (* 1 = 0.141235 loss)
I0901 11:01:43.452126 916722 sgd_solver.cpp:106] Iteration 4420000, lr = 0.01
I0901 11:02:13.165160 916722 solver.cpp:218] Iteration 4420500 (16.8277 iter/s, 29.7129s/500 iters), loss = 0.0500641
I0901 11:02:13.165215 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0500674 (* 1 = 0.0500674 loss)
I0901 11:02:13.165223 916722 sgd_solver.cpp:106] Iteration 4420500, lr = 0.01
I0901 11:02:42.876417 916722 solver.cpp:218] Iteration 4421000 (16.8288 iter/s, 29.711s/500 iters), loss = 0.0585853
I0901 11:02:42.876471 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0585887 (* 1 = 0.0585887 loss)
I0901 11:02:42.876482 916722 sgd_solver.cpp:106] Iteration 4421000, lr = 0.01
I0901 11:03:12.587162 916722 solver.cpp:218] Iteration 4421500 (16.8291 iter/s, 29.7105s/500 iters), loss = 0.0593529
I0901 11:03:12.587224 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0593562 (* 1 = 0.0593562 loss)
I0901 11:03:12.587232 916722 sgd_solver.cpp:106] Iteration 4421500, lr = 0.01
I0901 11:03:42.300936 916722 solver.cpp:218] Iteration 4422000 (16.8273 iter/s, 29.7135s/500 iters), loss = 0.171831
I0901 11:03:42.300988 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.171834 (* 1 = 0.171834 loss)
I0901 11:03:42.300998 916722 sgd_solver.cpp:106] Iteration 4422000, lr = 0.01
I0901 11:04:11.996423 916722 solver.cpp:218] Iteration 4422500 (16.8377 iter/s, 29.6953s/500 iters), loss = 0.0293381
I0901 11:04:11.996498 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0293414 (* 1 = 0.0293414 loss)
I0901 11:04:11.996507 916722 sgd_solver.cpp:106] Iteration 4422500, lr = 0.01
I0901 11:04:41.687490 916722 solver.cpp:218] Iteration 4423000 (16.8402 iter/s, 29.6908s/500 iters), loss = 0.2073
I0901 11:04:41.687541 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.207303 (* 1 = 0.207303 loss)
I0901 11:04:41.687551 916722 sgd_solver.cpp:106] Iteration 4423000, lr = 0.01
I0901 11:05:11.383142 916722 solver.cpp:218] Iteration 4423500 (16.8376 iter/s, 29.6954s/500 iters), loss = 0.0623363
I0901 11:05:11.383203 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0623397 (* 1 = 0.0623397 loss)
I0901 11:05:11.383211 916722 sgd_solver.cpp:106] Iteration 4423500, lr = 0.01
I0901 11:05:41.073405 916722 solver.cpp:218] Iteration 4424000 (16.8407 iter/s, 29.69s/500 iters), loss = 0.166822
I0901 11:05:41.073455 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.166825 (* 1 = 0.166825 loss)
I0901 11:05:41.073465 916722 sgd_solver.cpp:106] Iteration 4424000, lr = 0.01
I0901 11:06:10.762243 916722 solver.cpp:218] Iteration 4424500 (16.8412 iter/s, 29.6892s/500 iters), loss = 0.0771464
I0901 11:06:10.762302 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0771493 (* 1 = 0.0771493 loss)
I0901 11:06:10.762311 916722 sgd_solver.cpp:106] Iteration 4424500, lr = 0.01
I0901 11:06:40.451551 916722 solver.cpp:218] Iteration 4425000 (16.8407 iter/s, 29.6899s/500 iters), loss = 0.0346376
I0901 11:06:40.451601 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0346406 (* 1 = 0.0346406 loss)
I0901 11:06:40.451609 916722 sgd_solver.cpp:106] Iteration 4425000, lr = 0.01
I0901 11:07:10.140936 916722 solver.cpp:218] Iteration 4425500 (16.8407 iter/s, 29.69s/500 iters), loss = 0.111538
I0901 11:07:10.140996 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111541 (* 1 = 0.111541 loss)
I0901 11:07:10.141005 916722 sgd_solver.cpp:106] Iteration 4425500, lr = 0.01
I0901 11:07:39.828832 916722 solver.cpp:218] Iteration 4426000 (16.8416 iter/s, 29.6885s/500 iters), loss = 0.0942676
I0901 11:07:39.828884 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0942704 (* 1 = 0.0942704 loss)
I0901 11:07:39.828894 916722 sgd_solver.cpp:106] Iteration 4426000, lr = 0.01
I0901 11:08:09.520958 916722 solver.cpp:218] Iteration 4426500 (16.8392 iter/s, 29.6926s/500 iters), loss = 0.0337793
I0901 11:08:09.521023 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0337822 (* 1 = 0.0337822 loss)
I0901 11:08:09.521030 916722 sgd_solver.cpp:106] Iteration 4426500, lr = 0.01
I0901 11:08:39.211014 916722 solver.cpp:218] Iteration 4427000 (16.8404 iter/s, 29.6905s/500 iters), loss = 0.223244
I0901 11:08:39.211064 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.223247 (* 1 = 0.223247 loss)
I0901 11:08:39.211073 916722 sgd_solver.cpp:106] Iteration 4427000, lr = 0.01
I0901 11:09:08.904707 916722 solver.cpp:218] Iteration 4427500 (16.8383 iter/s, 29.6942s/500 iters), loss = 0.148569
I0901 11:09:08.904768 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.148572 (* 1 = 0.148572 loss)
I0901 11:09:08.904778 916722 sgd_solver.cpp:106] Iteration 4427500, lr = 0.01
I0901 11:09:38.602648 916722 solver.cpp:218] Iteration 4428000 (16.836 iter/s, 29.6984s/500 iters), loss = 0.111956
I0901 11:09:38.602699 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111959 (* 1 = 0.111959 loss)
I0901 11:09:38.602712 916722 sgd_solver.cpp:106] Iteration 4428000, lr = 0.01
I0901 11:10:08.320789 916722 solver.cpp:218] Iteration 4428500 (16.8245 iter/s, 29.7185s/500 iters), loss = 0.0364901
I0901 11:10:08.320849 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0364933 (* 1 = 0.0364933 loss)
I0901 11:10:08.320858 916722 sgd_solver.cpp:106] Iteration 4428500, lr = 0.01
I0901 11:10:38.034864 916722 solver.cpp:218] Iteration 4429000 (16.8268 iter/s, 29.7144s/500 iters), loss = 0.40116
I0901 11:10:38.034912 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.401163 (* 1 = 0.401163 loss)
I0901 11:10:38.034920 916722 sgd_solver.cpp:106] Iteration 4429000, lr = 0.01
I0901 11:11:07.746345 916722 solver.cpp:218] Iteration 4429500 (16.8283 iter/s, 29.7118s/500 iters), loss = 0.219809
I0901 11:11:07.746412 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.219812 (* 1 = 0.219812 loss)
I0901 11:11:07.746421 916722 sgd_solver.cpp:106] Iteration 4429500, lr = 0.01
I0901 11:11:37.456427 916722 solver.cpp:218] Iteration 4430000 (16.8291 iter/s, 29.7104s/500 iters), loss = 0.222906
I0901 11:11:37.456483 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.222909 (* 1 = 0.222909 loss)
I0901 11:11:37.456492 916722 sgd_solver.cpp:106] Iteration 4430000, lr = 0.01
I0901 11:12:07.172283 916722 solver.cpp:218] Iteration 4430500 (16.8259 iter/s, 29.7162s/500 iters), loss = 0.173388
I0901 11:12:07.172343 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.173391 (* 1 = 0.173391 loss)
I0901 11:12:07.172350 916722 sgd_solver.cpp:106] Iteration 4430500, lr = 0.01
I0901 11:12:36.886409 916722 solver.cpp:218] Iteration 4431000 (16.8269 iter/s, 29.7144s/500 iters), loss = 0.371218
I0901 11:12:36.886459 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.371221 (* 1 = 0.371221 loss)
I0901 11:12:36.886467 916722 sgd_solver.cpp:106] Iteration 4431000, lr = 0.01
I0901 11:13:06.599447 916722 solver.cpp:218] Iteration 4431500 (16.8275 iter/s, 29.7133s/500 iters), loss = 0.17368
I0901 11:13:06.599506 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.173683 (* 1 = 0.173683 loss)
I0901 11:13:06.599514 916722 sgd_solver.cpp:106] Iteration 4431500, lr = 0.01
I0901 11:13:36.312175 916722 solver.cpp:218] Iteration 4432000 (16.8277 iter/s, 29.713s/500 iters), loss = 0.331643
I0901 11:13:36.312227 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.331645 (* 1 = 0.331645 loss)
I0901 11:13:36.312234 916722 sgd_solver.cpp:106] Iteration 4432000, lr = 0.01
I0901 11:14:06.026755 916722 solver.cpp:218] Iteration 4432500 (16.8266 iter/s, 29.7148s/500 iters), loss = 0.227912
I0901 11:14:06.026815 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.227915 (* 1 = 0.227915 loss)
I0901 11:14:06.026824 916722 sgd_solver.cpp:106] Iteration 4432500, lr = 0.01
I0901 11:14:35.738982 916722 solver.cpp:218] Iteration 4433000 (16.828 iter/s, 29.7124s/500 iters), loss = 0.147334
I0901 11:14:35.739033 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.147337 (* 1 = 0.147337 loss)
I0901 11:14:35.739042 916722 sgd_solver.cpp:106] Iteration 4433000, lr = 0.01
I0901 11:15:05.453516 916722 solver.cpp:218] Iteration 4433500 (16.8267 iter/s, 29.7147s/500 iters), loss = 0.100185
I0901 11:15:05.453573 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.100188 (* 1 = 0.100188 loss)
I0901 11:15:05.453583 916722 sgd_solver.cpp:106] Iteration 4433500, lr = 0.01
I0901 11:15:35.168735 916722 solver.cpp:218] Iteration 4434000 (16.8263 iter/s, 29.7154s/500 iters), loss = 0.0890586
I0901 11:15:35.168793 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0890614 (* 1 = 0.0890614 loss)
I0901 11:15:35.168803 916722 sgd_solver.cpp:106] Iteration 4434000, lr = 0.01
I0901 11:16:04.884732 916722 solver.cpp:218] Iteration 4434500 (16.8259 iter/s, 29.7161s/500 iters), loss = 0.194336
I0901 11:16:04.884799 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.194338 (* 1 = 0.194338 loss)
I0901 11:16:04.884809 916722 sgd_solver.cpp:106] Iteration 4434500, lr = 0.01
I0901 11:16:34.598155 916722 solver.cpp:218] Iteration 4435000 (16.8273 iter/s, 29.7136s/500 iters), loss = 0.0831474
I0901 11:16:34.598206 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0831501 (* 1 = 0.0831501 loss)
I0901 11:16:34.598217 916722 sgd_solver.cpp:106] Iteration 4435000, lr = 0.01
I0901 11:17:04.315449 916722 solver.cpp:218] Iteration 4435500 (16.8251 iter/s, 29.7174s/500 iters), loss = 0.140177
I0901 11:17:04.315521 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.140179 (* 1 = 0.140179 loss)
I0901 11:17:04.315541 916722 sgd_solver.cpp:106] Iteration 4435500, lr = 0.01
I0901 11:17:34.029768 916722 solver.cpp:218] Iteration 4436000 (16.8268 iter/s, 29.7144s/500 iters), loss = 0.101772
I0901 11:17:34.029817 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101775 (* 1 = 0.101775 loss)
I0901 11:17:34.029826 916722 sgd_solver.cpp:106] Iteration 4436000, lr = 0.01
I0901 11:18:03.743499 916722 solver.cpp:218] Iteration 4436500 (16.8272 iter/s, 29.7138s/500 iters), loss = 0.147559
I0901 11:18:03.743561 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.147561 (* 1 = 0.147561 loss)
I0901 11:18:03.743569 916722 sgd_solver.cpp:106] Iteration 4436500, lr = 0.01
I0901 11:18:33.459369 916722 solver.cpp:218] Iteration 4437000 (16.826 iter/s, 29.716s/500 iters), loss = 0.0477249
I0901 11:18:33.459419 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0477277 (* 1 = 0.0477277 loss)
I0901 11:18:33.459427 916722 sgd_solver.cpp:106] Iteration 4437000, lr = 0.01
I0901 11:19:03.177035 916722 solver.cpp:218] Iteration 4437500 (16.825 iter/s, 29.7177s/500 iters), loss = 0.126765
I0901 11:19:03.177094 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.126768 (* 1 = 0.126768 loss)
I0901 11:19:03.177103 916722 sgd_solver.cpp:106] Iteration 4437500, lr = 0.01
I0901 11:19:32.894454 916722 solver.cpp:218] Iteration 4438000 (16.8251 iter/s, 29.7175s/500 iters), loss = 0.177155
I0901 11:19:32.894501 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.177157 (* 1 = 0.177157 loss)
I0901 11:19:32.894511 916722 sgd_solver.cpp:106] Iteration 4438000, lr = 0.01
I0901 11:20:02.609532 916722 solver.cpp:218] Iteration 4438500 (16.8264 iter/s, 29.7151s/500 iters), loss = 0.253989
I0901 11:20:02.609588 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.253992 (* 1 = 0.253992 loss)
I0901 11:20:02.609597 916722 sgd_solver.cpp:106] Iteration 4438500, lr = 0.01
I0901 11:20:32.325703 916722 solver.cpp:218] Iteration 4439000 (16.8258 iter/s, 29.7162s/500 iters), loss = 0.275427
I0901 11:20:32.325753 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.275429 (* 1 = 0.275429 loss)
I0901 11:20:32.325763 916722 sgd_solver.cpp:106] Iteration 4439000, lr = 0.01
I0901 11:21:02.044296 916722 solver.cpp:218] Iteration 4439500 (16.8245 iter/s, 29.7186s/500 iters), loss = 0.0575193
I0901 11:21:02.044353 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0575221 (* 1 = 0.0575221 loss)
I0901 11:21:02.044363 916722 sgd_solver.cpp:106] Iteration 4439500, lr = 0.01
I0901 11:21:31.756038 916722 solver.cpp:218] Iteration 4440000 (16.8283 iter/s, 29.7118s/500 iters), loss = 0.219648
I0901 11:21:31.756088 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.219651 (* 1 = 0.219651 loss)
I0901 11:21:31.756098 916722 sgd_solver.cpp:106] Iteration 4440000, lr = 0.01
I0901 11:22:01.470101 916722 solver.cpp:218] Iteration 4440500 (16.827 iter/s, 29.7141s/500 iters), loss = 0.191074
I0901 11:22:01.470158 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.191077 (* 1 = 0.191077 loss)
I0901 11:22:01.470166 916722 sgd_solver.cpp:106] Iteration 4440500, lr = 0.01
I0901 11:22:31.186743 916722 solver.cpp:218] Iteration 4441000 (16.8256 iter/s, 29.7167s/500 iters), loss = 0.0565277
I0901 11:22:31.186794 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0565306 (* 1 = 0.0565306 loss)
I0901 11:22:31.186803 916722 sgd_solver.cpp:106] Iteration 4441000, lr = 0.01
I0901 11:23:00.902354 916722 solver.cpp:218] Iteration 4441500 (16.8262 iter/s, 29.7156s/500 iters), loss = 0.0945527
I0901 11:23:00.902410 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0945555 (* 1 = 0.0945555 loss)
I0901 11:23:00.902420 916722 sgd_solver.cpp:106] Iteration 4441500, lr = 0.01
I0901 11:23:30.616355 916722 solver.cpp:218] Iteration 4442000 (16.8271 iter/s, 29.714s/500 iters), loss = 0.25221
I0901 11:23:30.616418 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.252213 (* 1 = 0.252213 loss)
I0901 11:23:30.616434 916722 sgd_solver.cpp:106] Iteration 4442000, lr = 0.01
I0901 11:24:00.329288 916722 solver.cpp:218] Iteration 4442500 (16.8277 iter/s, 29.7129s/500 iters), loss = 0.090211
I0901 11:24:00.329356 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0902137 (* 1 = 0.0902137 loss)
I0901 11:24:00.329365 916722 sgd_solver.cpp:106] Iteration 4442500, lr = 0.01
I0901 11:24:30.048487 916722 solver.cpp:218] Iteration 4443000 (16.8241 iter/s, 29.7192s/500 iters), loss = 0.306107
I0901 11:24:30.048532 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.306109 (* 1 = 0.306109 loss)
I0901 11:24:30.048542 916722 sgd_solver.cpp:106] Iteration 4443000, lr = 0.01
I0901 11:24:59.764320 916722 solver.cpp:218] Iteration 4443500 (16.826 iter/s, 29.7158s/500 iters), loss = 0.214486
I0901 11:24:59.764384 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.214489 (* 1 = 0.214489 loss)
I0901 11:24:59.764391 916722 sgd_solver.cpp:106] Iteration 4443500, lr = 0.01
I0901 11:25:29.476075 916722 solver.cpp:218] Iteration 4444000 (16.8284 iter/s, 29.7117s/500 iters), loss = 0.0459077
I0901 11:25:29.476126 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0459104 (* 1 = 0.0459104 loss)
I0901 11:25:29.476135 916722 sgd_solver.cpp:106] Iteration 4444000, lr = 0.01
I0901 11:25:59.189849 916722 solver.cpp:218] Iteration 4444500 (16.8272 iter/s, 29.7138s/500 iters), loss = 0.18808
I0901 11:25:59.189908 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.188083 (* 1 = 0.188083 loss)
I0901 11:25:59.189916 916722 sgd_solver.cpp:106] Iteration 4444500, lr = 0.01
I0901 11:26:28.905755 916722 solver.cpp:218] Iteration 4445000 (16.826 iter/s, 29.7159s/500 iters), loss = 0.146843
I0901 11:26:28.905804 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.146846 (* 1 = 0.146846 loss)
I0901 11:26:28.905813 916722 sgd_solver.cpp:106] Iteration 4445000, lr = 0.01
I0901 11:26:58.623879 916722 solver.cpp:218] Iteration 4445500 (16.8248 iter/s, 29.7181s/500 iters), loss = 0.152658
I0901 11:26:58.623942 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152661 (* 1 = 0.152661 loss)
I0901 11:26:58.623951 916722 sgd_solver.cpp:106] Iteration 4445500, lr = 0.01
I0901 11:27:28.341006 916722 solver.cpp:218] Iteration 4446000 (16.8253 iter/s, 29.7171s/500 iters), loss = 0.0284279
I0901 11:27:28.341056 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0284308 (* 1 = 0.0284308 loss)
I0901 11:27:28.341064 916722 sgd_solver.cpp:106] Iteration 4446000, lr = 0.01
I0901 11:27:58.054109 916722 solver.cpp:218] Iteration 4446500 (16.8276 iter/s, 29.7131s/500 iters), loss = 0.245953
I0901 11:27:58.054167 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.245956 (* 1 = 0.245956 loss)
I0901 11:27:58.054176 916722 sgd_solver.cpp:106] Iteration 4446500, lr = 0.01
I0901 11:28:27.770226 916722 solver.cpp:218] Iteration 4447000 (16.8259 iter/s, 29.7161s/500 iters), loss = 0.0918196
I0901 11:28:27.770275 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0918226 (* 1 = 0.0918226 loss)
I0901 11:28:27.770283 916722 sgd_solver.cpp:106] Iteration 4447000, lr = 0.01
I0901 11:28:57.487279 916722 solver.cpp:218] Iteration 4447500 (16.8254 iter/s, 29.717s/500 iters), loss = 0.032254
I0901 11:28:57.487339 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0322569 (* 1 = 0.0322569 loss)
I0901 11:28:57.487349 916722 sgd_solver.cpp:106] Iteration 4447500, lr = 0.01
I0901 11:29:27.204798 916722 solver.cpp:218] Iteration 4448000 (16.8251 iter/s, 29.7175s/500 iters), loss = 0.236925
I0901 11:29:27.204849 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.236928 (* 1 = 0.236928 loss)
I0901 11:29:27.204857 916722 sgd_solver.cpp:106] Iteration 4448000, lr = 0.01
I0901 11:29:56.918498 916722 solver.cpp:218] Iteration 4448500 (16.8273 iter/s, 29.7137s/500 iters), loss = 0.212631
I0901 11:29:56.918570 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.212634 (* 1 = 0.212634 loss)
I0901 11:29:56.918583 916722 sgd_solver.cpp:106] Iteration 4448500, lr = 0.01
I0901 11:30:26.637252 916722 solver.cpp:218] Iteration 4449000 (16.8244 iter/s, 29.7187s/500 iters), loss = 0.0563085
I0901 11:30:26.637305 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0563115 (* 1 = 0.0563115 loss)
I0901 11:30:26.637315 916722 sgd_solver.cpp:106] Iteration 4449000, lr = 0.01
I0901 11:30:56.351176 916722 solver.cpp:218] Iteration 4449500 (16.8272 iter/s, 29.7139s/500 iters), loss = 0.171932
I0901 11:30:56.351236 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.171935 (* 1 = 0.171935 loss)
I0901 11:30:56.351245 916722 sgd_solver.cpp:106] Iteration 4449500, lr = 0.01
I0901 11:31:26.007346 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_4450000.caffemodel
I0901 11:31:26.026760 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_4450000.solverstate
I0901 11:31:26.032955 916722 solver.cpp:330] Iteration 4450000, Testing net (#0)
I0901 11:31:41.450071 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8633
I0901 11:31:41.450125 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.461189 (* 1 = 0.461189 loss)
I0901 11:31:41.508752 916722 solver.cpp:218] Iteration 4450000 (11.0724 iter/s, 45.1575s/500 iters), loss = 0.112893
I0901 11:31:41.508782 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112896 (* 1 = 0.112896 loss)
I0901 11:31:41.508791 916722 sgd_solver.cpp:106] Iteration 4450000, lr = 0.01
I0901 11:32:11.238657 916722 solver.cpp:218] Iteration 4450500 (16.8181 iter/s, 29.7298s/500 iters), loss = 0.275652
I0901 11:32:11.238709 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.275655 (* 1 = 0.275655 loss)
I0901 11:32:11.238718 916722 sgd_solver.cpp:106] Iteration 4450500, lr = 0.01
I0901 11:32:40.970489 916722 solver.cpp:218] Iteration 4451000 (16.817 iter/s, 29.7318s/500 iters), loss = 0.0555906
I0901 11:32:40.970548 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0555936 (* 1 = 0.0555936 loss)
I0901 11:32:40.970557 916722 sgd_solver.cpp:106] Iteration 4451000, lr = 0.01
I0901 11:33:10.707221 916722 solver.cpp:218] Iteration 4451500 (16.8143 iter/s, 29.7367s/500 iters), loss = 0.466394
I0901 11:33:10.707268 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.466397 (* 1 = 0.466397 loss)
I0901 11:33:10.707276 916722 sgd_solver.cpp:106] Iteration 4451500, lr = 0.01
I0901 11:33:40.444238 916722 solver.cpp:218] Iteration 4452000 (16.8141 iter/s, 29.737s/500 iters), loss = 0.569349
I0901 11:33:40.444301 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.569351 (* 1 = 0.569351 loss)
I0901 11:33:40.444310 916722 sgd_solver.cpp:106] Iteration 4452000, lr = 0.01
I0901 11:34:10.184757 916722 solver.cpp:218] Iteration 4452500 (16.8121 iter/s, 29.7404s/500 iters), loss = 0.293638
I0901 11:34:10.184811 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.29364 (* 1 = 0.29364 loss)
I0901 11:34:10.184821 916722 sgd_solver.cpp:106] Iteration 4452500, lr = 0.01
I0901 11:34:39.921700 916722 solver.cpp:218] Iteration 4453000 (16.8141 iter/s, 29.7369s/500 iters), loss = 0.0878144
I0901 11:34:39.921761 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.087817 (* 1 = 0.087817 loss)
I0901 11:34:39.921768 916722 sgd_solver.cpp:106] Iteration 4453000, lr = 0.01
I0901 11:35:09.660674 916722 solver.cpp:218] Iteration 4453500 (16.813 iter/s, 29.7389s/500 iters), loss = 0.170083
I0901 11:35:09.660727 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.170085 (* 1 = 0.170085 loss)
I0901 11:35:09.660737 916722 sgd_solver.cpp:106] Iteration 4453500, lr = 0.01
I0901 11:35:39.399708 916722 solver.cpp:218] Iteration 4454000 (16.813 iter/s, 29.739s/500 iters), loss = 0.0562298
I0901 11:35:39.399775 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0562323 (* 1 = 0.0562323 loss)
I0901 11:35:39.399785 916722 sgd_solver.cpp:106] Iteration 4454000, lr = 0.01
I0901 11:36:09.141064 916722 solver.cpp:218] Iteration 4454500 (16.8116 iter/s, 29.7413s/500 iters), loss = 0.337577
I0901 11:36:09.141115 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.337579 (* 1 = 0.337579 loss)
I0901 11:36:09.141125 916722 sgd_solver.cpp:106] Iteration 4454500, lr = 0.01
I0901 11:36:38.878324 916722 solver.cpp:218] Iteration 4455000 (16.814 iter/s, 29.7372s/500 iters), loss = 0.153055
I0901 11:36:38.878381 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.153058 (* 1 = 0.153058 loss)
I0901 11:36:38.878389 916722 sgd_solver.cpp:106] Iteration 4455000, lr = 0.01
I0901 11:37:08.615641 916722 solver.cpp:218] Iteration 4455500 (16.8139 iter/s, 29.7372s/500 iters), loss = 0.0413017
I0901 11:37:08.615693 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0413041 (* 1 = 0.0413041 loss)
I0901 11:37:08.615703 916722 sgd_solver.cpp:106] Iteration 4455500, lr = 0.01
I0901 11:37:38.353900 916722 solver.cpp:218] Iteration 4456000 (16.8134 iter/s, 29.7382s/500 iters), loss = 0.0769386
I0901 11:37:38.353956 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0769409 (* 1 = 0.0769409 loss)
I0901 11:37:38.353965 916722 sgd_solver.cpp:106] Iteration 4456000, lr = 0.01
I0901 11:38:08.093982 916722 solver.cpp:218] Iteration 4456500 (16.8124 iter/s, 29.74s/500 iters), loss = 0.0725929
I0901 11:38:08.094033 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0725952 (* 1 = 0.0725952 loss)
I0901 11:38:08.094043 916722 sgd_solver.cpp:106] Iteration 4456500, lr = 0.01
I0901 11:38:37.835116 916722 solver.cpp:218] Iteration 4457000 (16.8118 iter/s, 29.7411s/500 iters), loss = 0.130188
I0901 11:38:37.835177 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13019 (* 1 = 0.13019 loss)
I0901 11:38:37.835186 916722 sgd_solver.cpp:106] Iteration 4457000, lr = 0.01
I0901 11:39:07.572396 916722 solver.cpp:218] Iteration 4457500 (16.814 iter/s, 29.7372s/500 iters), loss = 0.0587351
I0901 11:39:07.572453 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0587375 (* 1 = 0.0587375 loss)
I0901 11:39:07.572464 916722 sgd_solver.cpp:106] Iteration 4457500, lr = 0.01
I0901 11:39:37.315718 916722 solver.cpp:218] Iteration 4458000 (16.8105 iter/s, 29.7432s/500 iters), loss = 0.117573
I0901 11:39:37.315781 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.117575 (* 1 = 0.117575 loss)
I0901 11:39:37.315789 916722 sgd_solver.cpp:106] Iteration 4458000, lr = 0.01
I0901 11:40:07.052906 916722 solver.cpp:218] Iteration 4458500 (16.814 iter/s, 29.737s/500 iters), loss = 0.20205
I0901 11:40:07.052958 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.202052 (* 1 = 0.202052 loss)
I0901 11:40:07.052966 916722 sgd_solver.cpp:106] Iteration 4458500, lr = 0.01
I0901 11:40:36.793085 916722 solver.cpp:218] Iteration 4459000 (16.8125 iter/s, 29.7398s/500 iters), loss = 0.178562
I0901 11:40:36.793146 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.178564 (* 1 = 0.178564 loss)
I0901 11:40:36.793154 916722 sgd_solver.cpp:106] Iteration 4459000, lr = 0.01
I0901 11:41:06.536057 916722 solver.cpp:218] Iteration 4459500 (16.8109 iter/s, 29.7426s/500 iters), loss = 0.0549374
I0901 11:41:06.536108 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0549397 (* 1 = 0.0549397 loss)
I0901 11:41:06.536118 916722 sgd_solver.cpp:106] Iteration 4459500, lr = 0.01
I0901 11:41:36.280870 916722 solver.cpp:218] Iteration 4460000 (16.8098 iter/s, 29.7445s/500 iters), loss = 0.141295
I0901 11:41:36.280930 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.141298 (* 1 = 0.141298 loss)
I0901 11:41:36.280938 916722 sgd_solver.cpp:106] Iteration 4460000, lr = 0.01
I0901 11:42:06.019577 916722 solver.cpp:218] Iteration 4460500 (16.8133 iter/s, 29.7384s/500 iters), loss = 0.238405
I0901 11:42:06.019625 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.238407 (* 1 = 0.238407 loss)
I0901 11:42:06.019650 916722 sgd_solver.cpp:106] Iteration 4460500, lr = 0.01
I0901 11:42:35.762240 916722 solver.cpp:218] Iteration 4461000 (16.811 iter/s, 29.7424s/500 iters), loss = 0.0664914
I0901 11:42:35.762308 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0664936 (* 1 = 0.0664936 loss)
I0901 11:42:35.762317 916722 sgd_solver.cpp:106] Iteration 4461000, lr = 0.01
I0901 11:43:05.502198 916722 solver.cpp:218] Iteration 4461500 (16.8126 iter/s, 29.7396s/500 iters), loss = 0.311895
I0901 11:43:05.502249 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.311897 (* 1 = 0.311897 loss)
I0901 11:43:05.502257 916722 sgd_solver.cpp:106] Iteration 4461500, lr = 0.01
I0901 11:43:35.243058 916722 solver.cpp:218] Iteration 4462000 (16.8121 iter/s, 29.7406s/500 iters), loss = 0.0184088
I0901 11:43:35.243117 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0184106 (* 1 = 0.0184106 loss)
I0901 11:43:35.243125 916722 sgd_solver.cpp:106] Iteration 4462000, lr = 0.01
I0901 11:44:04.984972 916722 solver.cpp:218] Iteration 4462500 (16.8115 iter/s, 29.7416s/500 iters), loss = 0.353613
I0901 11:44:04.985020 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.353615 (* 1 = 0.353615 loss)
I0901 11:44:04.985028 916722 sgd_solver.cpp:106] Iteration 4462500, lr = 0.01
I0901 11:44:34.724861 916722 solver.cpp:218] Iteration 4463000 (16.8126 iter/s, 29.7396s/500 iters), loss = 0.0995615
I0901 11:44:34.724923 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0995634 (* 1 = 0.0995634 loss)
I0901 11:44:34.724931 916722 sgd_solver.cpp:106] Iteration 4463000, lr = 0.01
I0901 11:45:04.466145 916722 solver.cpp:218] Iteration 4463500 (16.8118 iter/s, 29.741s/500 iters), loss = 0.152991
I0901 11:45:04.466194 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152992 (* 1 = 0.152992 loss)
I0901 11:45:04.466204 916722 sgd_solver.cpp:106] Iteration 4463500, lr = 0.01
I0901 11:45:34.205868 916722 solver.cpp:218] Iteration 4464000 (16.8127 iter/s, 29.7395s/500 iters), loss = 0.0399869
I0901 11:45:34.205922 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0399888 (* 1 = 0.0399888 loss)
I0901 11:45:34.205930 916722 sgd_solver.cpp:106] Iteration 4464000, lr = 0.01
I0901 11:46:03.943290 916722 solver.cpp:218] Iteration 4464500 (16.814 iter/s, 29.7372s/500 iters), loss = 0.239044
I0901 11:46:03.943339 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.239046 (* 1 = 0.239046 loss)
I0901 11:46:03.943348 916722 sgd_solver.cpp:106] Iteration 4464500, lr = 0.01
I0901 11:46:33.681071 916722 solver.cpp:218] Iteration 4465000 (16.8138 iter/s, 29.7375s/500 iters), loss = 0.0226045
I0901 11:46:33.681126 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0226064 (* 1 = 0.0226064 loss)
I0901 11:46:33.681134 916722 sgd_solver.cpp:106] Iteration 4465000, lr = 0.01
I0901 11:47:03.424293 916722 solver.cpp:218] Iteration 4465500 (16.8107 iter/s, 29.743s/500 iters), loss = 0.284326
I0901 11:47:03.424343 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.284328 (* 1 = 0.284328 loss)
I0901 11:47:03.424353 916722 sgd_solver.cpp:106] Iteration 4465500, lr = 0.01
I0901 11:47:33.162075 916722 solver.cpp:218] Iteration 4466000 (16.8138 iter/s, 29.7375s/500 iters), loss = 0.165774
I0901 11:47:33.162135 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.165775 (* 1 = 0.165775 loss)
I0901 11:47:33.162143 916722 sgd_solver.cpp:106] Iteration 4466000, lr = 0.01
I0901 11:48:02.902009 916722 solver.cpp:218] Iteration 4466500 (16.8125 iter/s, 29.7397s/500 iters), loss = 0.235738
I0901 11:48:02.902055 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.23574 (* 1 = 0.23574 loss)
I0901 11:48:02.902065 916722 sgd_solver.cpp:106] Iteration 4466500, lr = 0.01
I0901 11:48:32.642117 916722 solver.cpp:218] Iteration 4467000 (16.8124 iter/s, 29.7399s/500 iters), loss = 0.427388
I0901 11:48:32.642172 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.42739 (* 1 = 0.42739 loss)
I0901 11:48:32.642180 916722 sgd_solver.cpp:106] Iteration 4467000, lr = 0.01
I0901 11:49:02.382936 916722 solver.cpp:218] Iteration 4467500 (16.812 iter/s, 29.7406s/500 iters), loss = 0.0173502
I0901 11:49:02.382997 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.017352 (* 1 = 0.017352 loss)
I0901 11:49:02.383005 916722 sgd_solver.cpp:106] Iteration 4467500, lr = 0.01
I0901 11:49:32.123867 916722 solver.cpp:218] Iteration 4468000 (16.812 iter/s, 29.7407s/500 iters), loss = 0.145759
I0901 11:49:32.123935 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.145761 (* 1 = 0.145761 loss)
I0901 11:49:32.123944 916722 sgd_solver.cpp:106] Iteration 4468000, lr = 0.01
I0901 11:50:01.866732 916722 solver.cpp:218] Iteration 4468500 (16.8109 iter/s, 29.7427s/500 iters), loss = 0.15488
I0901 11:50:01.866780 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.154882 (* 1 = 0.154882 loss)
I0901 11:50:01.866788 916722 sgd_solver.cpp:106] Iteration 4468500, lr = 0.01
I0901 11:50:31.603920 916722 solver.cpp:218] Iteration 4469000 (16.8141 iter/s, 29.737s/500 iters), loss = 0.158757
I0901 11:50:31.603981 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.158759 (* 1 = 0.158759 loss)
I0901 11:50:31.603989 916722 sgd_solver.cpp:106] Iteration 4469000, lr = 0.01
I0901 11:51:01.344161 916722 solver.cpp:218] Iteration 4469500 (16.8124 iter/s, 29.74s/500 iters), loss = 0.0363422
I0901 11:51:01.344206 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0363444 (* 1 = 0.0363444 loss)
I0901 11:51:01.344215 916722 sgd_solver.cpp:106] Iteration 4469500, lr = 0.01
I0901 11:51:31.082182 916722 solver.cpp:218] Iteration 4470000 (16.8136 iter/s, 29.7378s/500 iters), loss = 0.0747066
I0901 11:51:31.082242 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0747087 (* 1 = 0.0747087 loss)
I0901 11:51:31.082250 916722 sgd_solver.cpp:106] Iteration 4470000, lr = 0.01
I0901 11:52:00.821919 916722 solver.cpp:218] Iteration 4470500 (16.8126 iter/s, 29.7395s/500 iters), loss = 0.236088
I0901 11:52:00.821966 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.23609 (* 1 = 0.23609 loss)
I0901 11:52:00.821974 916722 sgd_solver.cpp:106] Iteration 4470500, lr = 0.01
I0901 11:52:30.561285 916722 solver.cpp:218] Iteration 4471000 (16.8128 iter/s, 29.7392s/500 iters), loss = 0.0536026
I0901 11:52:30.561345 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0536049 (* 1 = 0.0536049 loss)
I0901 11:52:30.561353 916722 sgd_solver.cpp:106] Iteration 4471000, lr = 0.01
I0901 11:53:00.301410 916722 solver.cpp:218] Iteration 4471500 (16.8124 iter/s, 29.7399s/500 iters), loss = 0.0279872
I0901 11:53:00.301461 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0279896 (* 1 = 0.0279896 loss)
I0901 11:53:00.301470 916722 sgd_solver.cpp:106] Iteration 4471500, lr = 0.01
I0901 11:53:30.042049 916722 solver.cpp:218] Iteration 4472000 (16.8121 iter/s, 29.7405s/500 iters), loss = 0.0386114
I0901 11:53:30.042109 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0386138 (* 1 = 0.0386138 loss)
I0901 11:53:30.042119 916722 sgd_solver.cpp:106] Iteration 4472000, lr = 0.01
I0901 11:53:59.784220 916722 solver.cpp:218] Iteration 4472500 (16.8112 iter/s, 29.742s/500 iters), loss = 0.205722
I0901 11:53:59.784268 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.205724 (* 1 = 0.205724 loss)
I0901 11:53:59.784277 916722 sgd_solver.cpp:106] Iteration 4472500, lr = 0.01
I0901 11:54:29.523217 916722 solver.cpp:218] Iteration 4473000 (16.813 iter/s, 29.7388s/500 iters), loss = 0.147732
I0901 11:54:29.523275 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.147734 (* 1 = 0.147734 loss)
I0901 11:54:29.523284 916722 sgd_solver.cpp:106] Iteration 4473000, lr = 0.01
I0901 11:54:59.262974 916722 solver.cpp:218] Iteration 4473500 (16.8126 iter/s, 29.7396s/500 iters), loss = 0.189903
I0901 11:54:59.263020 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.189905 (* 1 = 0.189905 loss)
I0901 11:54:59.263028 916722 sgd_solver.cpp:106] Iteration 4473500, lr = 0.01
I0901 11:55:29.001894 916722 solver.cpp:218] Iteration 4474000 (16.8131 iter/s, 29.7388s/500 iters), loss = 0.0275684
I0901 11:55:29.001965 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0275707 (* 1 = 0.0275707 loss)
I0901 11:55:29.001974 916722 sgd_solver.cpp:106] Iteration 4474000, lr = 0.01
I0901 11:55:58.747354 916722 solver.cpp:218] Iteration 4474500 (16.8094 iter/s, 29.7453s/500 iters), loss = 0.0898815
I0901 11:55:58.747406 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.089884 (* 1 = 0.089884 loss)
I0901 11:55:58.747413 916722 sgd_solver.cpp:106] Iteration 4474500, lr = 0.01
I0901 11:56:28.485616 916722 solver.cpp:218] Iteration 4475000 (16.8134 iter/s, 29.7381s/500 iters), loss = 0.172387
I0901 11:56:28.485677 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.17239 (* 1 = 0.17239 loss)
I0901 11:56:28.485684 916722 sgd_solver.cpp:106] Iteration 4475000, lr = 0.01
I0901 11:56:58.230178 916722 solver.cpp:218] Iteration 4475500 (16.8099 iter/s, 29.7444s/500 iters), loss = 0.022136
I0901 11:56:58.230229 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0221385 (* 1 = 0.0221385 loss)
I0901 11:56:58.230238 916722 sgd_solver.cpp:106] Iteration 4475500, lr = 0.01
I0901 11:57:27.972388 916722 solver.cpp:218] Iteration 4476000 (16.8112 iter/s, 29.7421s/500 iters), loss = 0.0416485
I0901 11:57:27.972452 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0416509 (* 1 = 0.0416509 loss)
I0901 11:57:27.972461 916722 sgd_solver.cpp:106] Iteration 4476000, lr = 0.01
I0901 11:57:57.710812 916722 solver.cpp:218] Iteration 4476500 (16.8134 iter/s, 29.7383s/500 iters), loss = 0.0255745
I0901 11:57:57.710863 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.025577 (* 1 = 0.025577 loss)
I0901 11:57:57.710871 916722 sgd_solver.cpp:106] Iteration 4476500, lr = 0.01
I0901 11:58:27.454648 916722 solver.cpp:218] Iteration 4477000 (16.8103 iter/s, 29.7437s/500 iters), loss = 0.0367883
I0901 11:58:27.454706 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0367906 (* 1 = 0.0367906 loss)
I0901 11:58:27.454715 916722 sgd_solver.cpp:106] Iteration 4477000, lr = 0.01
I0901 11:58:57.194036 916722 solver.cpp:218] Iteration 4477500 (16.8128 iter/s, 29.7392s/500 iters), loss = 0.139826
I0901 11:58:57.194087 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139828 (* 1 = 0.139828 loss)
I0901 11:58:57.194095 916722 sgd_solver.cpp:106] Iteration 4477500, lr = 0.01
I0901 11:59:26.934985 916722 solver.cpp:218] Iteration 4478000 (16.8119 iter/s, 29.7408s/500 iters), loss = 0.0335575
I0901 11:59:26.935042 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0335596 (* 1 = 0.0335596 loss)
I0901 11:59:26.935050 916722 sgd_solver.cpp:106] Iteration 4478000, lr = 0.01
I0901 11:59:56.673965 916722 solver.cpp:218] Iteration 4478500 (16.813 iter/s, 29.7388s/500 iters), loss = 0.0987022
I0901 11:59:56.674015 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0987043 (* 1 = 0.0987043 loss)
I0901 11:59:56.674023 916722 sgd_solver.cpp:106] Iteration 4478500, lr = 0.01
I0901 12:00:26.416734 916722 solver.cpp:218] Iteration 4479000 (16.8109 iter/s, 29.7426s/500 iters), loss = 0.0490413
I0901 12:00:26.416805 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0490434 (* 1 = 0.0490434 loss)
I0901 12:00:26.416813 916722 sgd_solver.cpp:106] Iteration 4479000, lr = 0.01
I0901 12:00:56.158409 916722 solver.cpp:218] Iteration 4479500 (16.8115 iter/s, 29.7415s/500 iters), loss = 0.0480256
I0901 12:00:56.158460 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0480276 (* 1 = 0.0480276 loss)
I0901 12:00:56.158470 916722 sgd_solver.cpp:106] Iteration 4479500, lr = 0.01
I0901 12:01:25.898988 916722 solver.cpp:218] Iteration 4480000 (16.8121 iter/s, 29.7404s/500 iters), loss = 0.135373
I0901 12:01:25.899046 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.135375 (* 1 = 0.135375 loss)
I0901 12:01:25.899055 916722 sgd_solver.cpp:106] Iteration 4480000, lr = 0.01
I0901 12:01:55.644043 916722 solver.cpp:218] Iteration 4480500 (16.8096 iter/s, 29.7449s/500 iters), loss = 0.273609
I0901 12:01:55.644107 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.273611 (* 1 = 0.273611 loss)
I0901 12:01:55.644117 916722 sgd_solver.cpp:106] Iteration 4480500, lr = 0.01
I0901 12:02:25.387135 916722 solver.cpp:218] Iteration 4481000 (16.8107 iter/s, 29.7429s/500 iters), loss = 0.0395099
I0901 12:02:25.387204 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0395117 (* 1 = 0.0395117 loss)
I0901 12:02:25.387213 916722 sgd_solver.cpp:106] Iteration 4481000, lr = 0.01
I0901 12:02:55.127173 916722 solver.cpp:218] Iteration 4481500 (16.8124 iter/s, 29.7399s/500 iters), loss = 0.455426
I0901 12:02:55.127224 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.455428 (* 1 = 0.455428 loss)
I0901 12:02:55.127233 916722 sgd_solver.cpp:106] Iteration 4481500, lr = 0.01
I0901 12:03:24.873114 916722 solver.cpp:218] Iteration 4482000 (16.8091 iter/s, 29.7458s/500 iters), loss = 0.120818
I0901 12:03:24.873172 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.12082 (* 1 = 0.12082 loss)
I0901 12:03:24.873181 916722 sgd_solver.cpp:106] Iteration 4482000, lr = 0.01
I0901 12:03:54.627611 916722 solver.cpp:218] Iteration 4482500 (16.8043 iter/s, 29.7544s/500 iters), loss = 0.123598
I0901 12:03:54.627663 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.1236 (* 1 = 0.1236 loss)
I0901 12:03:54.627673 916722 sgd_solver.cpp:106] Iteration 4482500, lr = 0.01
I0901 12:04:24.383119 916722 solver.cpp:218] Iteration 4483000 (16.8037 iter/s, 29.7554s/500 iters), loss = 0.0635811
I0901 12:04:24.383177 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.063583 (* 1 = 0.063583 loss)
I0901 12:04:24.383185 916722 sgd_solver.cpp:106] Iteration 4483000, lr = 0.01
I0901 12:04:54.138058 916722 solver.cpp:218] Iteration 4483500 (16.804 iter/s, 29.7548s/500 iters), loss = 0.100951
I0901 12:04:54.138109 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.100953 (* 1 = 0.100953 loss)
I0901 12:04:54.138118 916722 sgd_solver.cpp:106] Iteration 4483500, lr = 0.01
I0901 12:05:23.892997 916722 solver.cpp:218] Iteration 4484000 (16.804 iter/s, 29.7548s/500 iters), loss = 0.124608
I0901 12:05:23.893059 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.12461 (* 1 = 0.12461 loss)
I0901 12:05:23.893069 916722 sgd_solver.cpp:106] Iteration 4484000, lr = 0.01
I0901 12:05:53.634443 916722 solver.cpp:218] Iteration 4484500 (16.8116 iter/s, 29.7413s/500 iters), loss = 0.0091324
I0901 12:05:53.634495 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.00913419 (* 1 = 0.00913419 loss)
I0901 12:05:53.634506 916722 sgd_solver.cpp:106] Iteration 4484500, lr = 0.01
I0901 12:06:23.378407 916722 solver.cpp:218] Iteration 4485000 (16.8102 iter/s, 29.7438s/500 iters), loss = 0.138249
I0901 12:06:23.378463 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.138251 (* 1 = 0.138251 loss)
I0901 12:06:23.378470 916722 sgd_solver.cpp:106] Iteration 4485000, lr = 0.01
I0901 12:06:53.129604 916722 solver.cpp:218] Iteration 4485500 (16.8061 iter/s, 29.7511s/500 iters), loss = 0.1439
I0901 12:06:53.129659 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.143902 (* 1 = 0.143902 loss)
I0901 12:06:53.129669 916722 sgd_solver.cpp:106] Iteration 4485500, lr = 0.01
I0901 12:07:22.870709 916722 solver.cpp:218] Iteration 4486000 (16.8118 iter/s, 29.741s/500 iters), loss = 0.10591
I0901 12:07:22.870770 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105912 (* 1 = 0.105912 loss)
I0901 12:07:22.870779 916722 sgd_solver.cpp:106] Iteration 4486000, lr = 0.01
I0901 12:07:52.614078 916722 solver.cpp:218] Iteration 4486500 (16.8105 iter/s, 29.7432s/500 iters), loss = 0.023643
I0901 12:07:52.614130 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0236449 (* 1 = 0.0236449 loss)
I0901 12:07:52.614137 916722 sgd_solver.cpp:106] Iteration 4486500, lr = 0.01
I0901 12:08:22.356814 916722 solver.cpp:218] Iteration 4487000 (16.8109 iter/s, 29.7426s/500 iters), loss = 0.0734881
I0901 12:08:22.356889 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.07349 (* 1 = 0.07349 loss)
I0901 12:08:22.356906 916722 sgd_solver.cpp:106] Iteration 4487000, lr = 0.01
I0901 12:08:52.097941 916722 solver.cpp:218] Iteration 4487500 (16.8118 iter/s, 29.741s/500 iters), loss = 0.160183
I0901 12:08:52.097988 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.160185 (* 1 = 0.160185 loss)
I0901 12:08:52.097997 916722 sgd_solver.cpp:106] Iteration 4487500, lr = 0.01
I0901 12:09:21.842267 916722 solver.cpp:218] Iteration 4488000 (16.81 iter/s, 29.7442s/500 iters), loss = 0.281878
I0901 12:09:21.842326 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.281879 (* 1 = 0.281879 loss)
I0901 12:09:21.842335 916722 sgd_solver.cpp:106] Iteration 4488000, lr = 0.01
I0901 12:09:51.582525 916722 solver.cpp:218] Iteration 4488500 (16.8123 iter/s, 29.7401s/500 iters), loss = 0.119855
I0901 12:09:51.582581 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.119856 (* 1 = 0.119856 loss)
I0901 12:09:51.582590 916722 sgd_solver.cpp:106] Iteration 4488500, lr = 0.01
I0901 12:10:21.323454 916722 solver.cpp:218] Iteration 4489000 (16.8119 iter/s, 29.7408s/500 iters), loss = 0.40231
I0901 12:10:21.323513 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.402312 (* 1 = 0.402312 loss)
I0901 12:10:21.323521 916722 sgd_solver.cpp:106] Iteration 4489000, lr = 0.01
I0901 12:10:51.065665 916722 solver.cpp:218] Iteration 4489500 (16.8112 iter/s, 29.7421s/500 iters), loss = 0.223047
I0901 12:10:51.065716 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.223048 (* 1 = 0.223048 loss)
I0901 12:10:51.065726 916722 sgd_solver.cpp:106] Iteration 4489500, lr = 0.01
I0901 12:11:20.806829 916722 solver.cpp:218] Iteration 4490000 (16.8118 iter/s, 29.741s/500 iters), loss = 0.264785
I0901 12:11:20.806890 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.264786 (* 1 = 0.264786 loss)
I0901 12:11:20.806897 916722 sgd_solver.cpp:106] Iteration 4490000, lr = 0.01
I0901 12:11:50.548895 916722 solver.cpp:218] Iteration 4490500 (16.8113 iter/s, 29.7419s/500 iters), loss = 0.22126
I0901 12:11:50.548947 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.221261 (* 1 = 0.221261 loss)
I0901 12:11:50.548956 916722 sgd_solver.cpp:106] Iteration 4490500, lr = 0.01
I0901 12:12:20.288872 916722 solver.cpp:218] Iteration 4491000 (16.8125 iter/s, 29.7399s/500 iters), loss = 0.393502
I0901 12:12:20.288931 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.393504 (* 1 = 0.393504 loss)
I0901 12:12:20.288940 916722 sgd_solver.cpp:106] Iteration 4491000, lr = 0.01
I0901 12:12:50.029983 916722 solver.cpp:218] Iteration 4491500 (16.8118 iter/s, 29.741s/500 iters), loss = 0.00920332
I0901 12:12:50.030033 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.00920456 (* 1 = 0.00920456 loss)
I0901 12:12:50.030042 916722 sgd_solver.cpp:106] Iteration 4491500, lr = 0.01
I0901 12:13:19.772094 916722 solver.cpp:218] Iteration 4492000 (16.8112 iter/s, 29.742s/500 iters), loss = 0.0508919
I0901 12:13:19.772152 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.050893 (* 1 = 0.050893 loss)
I0901 12:13:19.772161 916722 sgd_solver.cpp:106] Iteration 4492000, lr = 0.01
I0901 12:13:49.513947 916722 solver.cpp:218] Iteration 4492500 (16.8114 iter/s, 29.7417s/500 iters), loss = 0.0917161
I0901 12:13:49.513998 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0917172 (* 1 = 0.0917172 loss)
I0901 12:13:49.514008 916722 sgd_solver.cpp:106] Iteration 4492500, lr = 0.01
I0901 12:14:19.254837 916722 solver.cpp:218] Iteration 4493000 (16.812 iter/s, 29.7406s/500 iters), loss = 0.153466
I0901 12:14:19.254899 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.153467 (* 1 = 0.153467 loss)
I0901 12:14:19.254909 916722 sgd_solver.cpp:106] Iteration 4493000, lr = 0.01
I0901 12:14:48.997462 916722 solver.cpp:218] Iteration 4493500 (16.8112 iter/s, 29.7421s/500 iters), loss = 0.20265
I0901 12:14:48.997515 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.202651 (* 1 = 0.202651 loss)
I0901 12:14:48.997537 916722 sgd_solver.cpp:106] Iteration 4493500, lr = 0.01
I0901 12:15:18.743531 916722 solver.cpp:218] Iteration 4494000 (16.8092 iter/s, 29.7456s/500 iters), loss = 0.190268
I0901 12:15:18.743602 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.190269 (* 1 = 0.190269 loss)
I0901 12:15:18.743611 916722 sgd_solver.cpp:106] Iteration 4494000, lr = 0.01
I0901 12:15:48.496590 916722 solver.cpp:218] Iteration 4494500 (16.8053 iter/s, 29.7526s/500 iters), loss = 0.0430533
I0901 12:15:48.496642 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0430543 (* 1 = 0.0430543 loss)
I0901 12:15:48.496651 916722 sgd_solver.cpp:106] Iteration 4494500, lr = 0.01
I0901 12:16:18.247745 916722 solver.cpp:218] Iteration 4495000 (16.8063 iter/s, 29.7507s/500 iters), loss = 0.0338154
I0901 12:16:18.247803 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0338163 (* 1 = 0.0338163 loss)
I0901 12:16:18.247812 916722 sgd_solver.cpp:106] Iteration 4495000, lr = 0.01
I0901 12:16:47.990279 916722 solver.cpp:218] Iteration 4495500 (16.8112 iter/s, 29.7421s/500 iters), loss = 0.181701
I0901 12:16:47.990329 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.181702 (* 1 = 0.181702 loss)
I0901 12:16:47.990337 916722 sgd_solver.cpp:106] Iteration 4495500, lr = 0.01
I0901 12:17:17.734562 916722 solver.cpp:218] Iteration 4496000 (16.8102 iter/s, 29.7439s/500 iters), loss = 0.0425799
I0901 12:17:17.734620 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.042581 (* 1 = 0.042581 loss)
I0901 12:17:17.734628 916722 sgd_solver.cpp:106] Iteration 4496000, lr = 0.01
I0901 12:17:47.475478 916722 solver.cpp:218] Iteration 4496500 (16.8121 iter/s, 29.7405s/500 iters), loss = 0.0690117
I0901 12:17:47.475526 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0690127 (* 1 = 0.0690127 loss)
I0901 12:17:47.475534 916722 sgd_solver.cpp:106] Iteration 4496500, lr = 0.01
I0901 12:18:17.217624 916722 solver.cpp:218] Iteration 4497000 (16.8114 iter/s, 29.7418s/500 iters), loss = 0.0569325
I0901 12:18:17.217686 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0569336 (* 1 = 0.0569336 loss)
I0901 12:18:17.217695 916722 sgd_solver.cpp:106] Iteration 4497000, lr = 0.01
I0901 12:18:46.960840 916722 solver.cpp:218] Iteration 4497500 (16.8108 iter/s, 29.7428s/500 iters), loss = 0.147853
I0901 12:18:46.960891 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.147854 (* 1 = 0.147854 loss)
I0901 12:18:46.960901 916722 sgd_solver.cpp:106] Iteration 4497500, lr = 0.01
I0901 12:19:16.703568 916722 solver.cpp:218] Iteration 4498000 (16.811 iter/s, 29.7424s/500 iters), loss = 0.274795
I0901 12:19:16.703630 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.274796 (* 1 = 0.274796 loss)
I0901 12:19:16.703639 916722 sgd_solver.cpp:106] Iteration 4498000, lr = 0.01
I0901 12:19:46.445132 916722 solver.cpp:218] Iteration 4498500 (16.8117 iter/s, 29.7412s/500 iters), loss = 0.108438
I0901 12:19:46.445184 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.108439 (* 1 = 0.108439 loss)
I0901 12:19:46.445194 916722 sgd_solver.cpp:106] Iteration 4498500, lr = 0.01
I0901 12:20:16.185748 916722 solver.cpp:218] Iteration 4499000 (16.8122 iter/s, 29.7403s/500 iters), loss = 0.346526
I0901 12:20:16.185811 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.346527 (* 1 = 0.346527 loss)
I0901 12:20:16.185818 916722 sgd_solver.cpp:106] Iteration 4499000, lr = 0.01
I0901 12:20:45.930096 916722 solver.cpp:218] Iteration 4499500 (16.8101 iter/s, 29.744s/500 iters), loss = 0.0593351
I0901 12:20:45.930150 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0593361 (* 1 = 0.0593361 loss)
I0901 12:20:45.930159 916722 sgd_solver.cpp:106] Iteration 4499500, lr = 0.01
I0901 12:21:15.613147 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_4500000.caffemodel
I0901 12:21:15.632581 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_4500000.solverstate
I0901 12:21:15.638648 916722 solver.cpp:330] Iteration 4500000, Testing net (#0)
I0901 12:21:31.029448 916722 solver.cpp:397]     Test net output #0: accuracy = 0.875
I0901 12:21:31.029493 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.418128 (* 1 = 0.418128 loss)
I0901 12:21:31.087946 916722 solver.cpp:218] Iteration 4500000 (11.0724 iter/s, 45.1574s/500 iters), loss = 0.0577246
I0901 12:21:31.087973 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0577255 (* 1 = 0.0577255 loss)
I0901 12:21:31.087981 916722 sgd_solver.cpp:106] Iteration 4500000, lr = 0.01
I0901 12:22:00.813431 916722 solver.cpp:218] Iteration 4500500 (16.8208 iter/s, 29.7252s/500 iters), loss = 0.188789
I0901 12:22:00.813489 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.18879 (* 1 = 0.18879 loss)
I0901 12:22:00.813498 916722 sgd_solver.cpp:106] Iteration 4500500, lr = 0.01
I0901 12:22:30.544314 916722 solver.cpp:218] Iteration 4501000 (16.8177 iter/s, 29.7306s/500 iters), loss = 0.131371
I0901 12:22:30.544365 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131372 (* 1 = 0.131372 loss)
I0901 12:22:30.544374 916722 sgd_solver.cpp:106] Iteration 4501000, lr = 0.01
I0901 12:23:00.287765 916722 solver.cpp:218] Iteration 4501500 (16.8106 iter/s, 29.7432s/500 iters), loss = 0.182953
I0901 12:23:00.287828 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.182954 (* 1 = 0.182954 loss)
I0901 12:23:00.287837 916722 sgd_solver.cpp:106] Iteration 4501500, lr = 0.01
I0901 12:23:30.040678 916722 solver.cpp:218] Iteration 4502000 (16.8052 iter/s, 29.7526s/500 iters), loss = 0.145006
I0901 12:23:30.040728 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.145007 (* 1 = 0.145007 loss)
I0901 12:23:30.040738 916722 sgd_solver.cpp:106] Iteration 4502000, lr = 0.01
I0901 12:23:59.795589 916722 solver.cpp:218] Iteration 4502500 (16.8041 iter/s, 29.7546s/500 iters), loss = 0.121507
I0901 12:23:59.795648 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.121508 (* 1 = 0.121508 loss)
I0901 12:23:59.795657 916722 sgd_solver.cpp:106] Iteration 4502500, lr = 0.01
I0901 12:24:29.550453 916722 solver.cpp:218] Iteration 4503000 (16.8041 iter/s, 29.7546s/500 iters), loss = 0.0879739
I0901 12:24:29.550506 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0879749 (* 1 = 0.0879749 loss)
I0901 12:24:29.550515 916722 sgd_solver.cpp:106] Iteration 4503000, lr = 0.01
I0901 12:24:59.304937 916722 solver.cpp:218] Iteration 4503500 (16.8043 iter/s, 29.7542s/500 iters), loss = 0.250754
I0901 12:24:59.304996 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.250755 (* 1 = 0.250755 loss)
I0901 12:24:59.305003 916722 sgd_solver.cpp:106] Iteration 4503500, lr = 0.01
I0901 12:25:29.060170 916722 solver.cpp:218] Iteration 4504000 (16.8039 iter/s, 29.755s/500 iters), loss = 0.0619008
I0901 12:25:29.060220 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0619019 (* 1 = 0.0619019 loss)
I0901 12:25:29.060228 916722 sgd_solver.cpp:106] Iteration 4504000, lr = 0.01
I0901 12:25:58.816103 916722 solver.cpp:218] Iteration 4504500 (16.8035 iter/s, 29.7557s/500 iters), loss = 0.188234
I0901 12:25:58.816164 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.188235 (* 1 = 0.188235 loss)
I0901 12:25:58.816171 916722 sgd_solver.cpp:106] Iteration 4504500, lr = 0.01
I0901 12:26:28.561318 916722 solver.cpp:218] Iteration 4505000 (16.8096 iter/s, 29.745s/500 iters), loss = 0.0963644
I0901 12:26:28.561370 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0963655 (* 1 = 0.0963655 loss)
I0901 12:26:28.561380 916722 sgd_solver.cpp:106] Iteration 4505000, lr = 0.01
I0901 12:26:58.306469 916722 solver.cpp:218] Iteration 4505500 (16.8096 iter/s, 29.7449s/500 iters), loss = 0.00562226
I0901 12:26:58.306529 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.00562327 (* 1 = 0.00562327 loss)
I0901 12:26:58.306537 916722 sgd_solver.cpp:106] Iteration 4505500, lr = 0.01
I0901 12:27:28.052246 916722 solver.cpp:218] Iteration 4506000 (16.8092 iter/s, 29.7455s/500 iters), loss = 0.0482619
I0901 12:27:28.052309 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0482628 (* 1 = 0.0482628 loss)
I0901 12:27:28.052320 916722 sgd_solver.cpp:106] Iteration 4506000, lr = 0.01
I0901 12:27:57.799584 916722 solver.cpp:218] Iteration 4506500 (16.8084 iter/s, 29.7471s/500 iters), loss = 0.099764
I0901 12:27:57.799655 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0997649 (* 1 = 0.0997649 loss)
I0901 12:27:57.799664 916722 sgd_solver.cpp:106] Iteration 4506500, lr = 0.01
I0901 12:28:27.550144 916722 solver.cpp:218] Iteration 4507000 (16.8065 iter/s, 29.7503s/500 iters), loss = 0.112409
I0901 12:28:27.550196 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112409 (* 1 = 0.112409 loss)
I0901 12:28:27.550206 916722 sgd_solver.cpp:106] Iteration 4507000, lr = 0.01
I0901 12:28:57.296864 916722 solver.cpp:218] Iteration 4507500 (16.8087 iter/s, 29.7465s/500 iters), loss = 0.107281
I0901 12:28:57.296927 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.107282 (* 1 = 0.107282 loss)
I0901 12:28:57.296936 916722 sgd_solver.cpp:106] Iteration 4507500, lr = 0.01
I0901 12:29:27.041561 916722 solver.cpp:218] Iteration 4508000 (16.8098 iter/s, 29.7445s/500 iters), loss = 0.470336
I0901 12:29:27.041611 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.470337 (* 1 = 0.470337 loss)
I0901 12:29:27.041620 916722 sgd_solver.cpp:106] Iteration 4508000, lr = 0.01
I0901 12:29:56.783075 916722 solver.cpp:218] Iteration 4508500 (16.8116 iter/s, 29.7413s/500 iters), loss = 0.164316
I0901 12:29:56.783133 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.164317 (* 1 = 0.164317 loss)
I0901 12:29:56.783143 916722 sgd_solver.cpp:106] Iteration 4508500, lr = 0.01
I0901 12:30:26.528292 916722 solver.cpp:218] Iteration 4509000 (16.8095 iter/s, 29.745s/500 iters), loss = 0.109314
I0901 12:30:26.528342 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109315 (* 1 = 0.109315 loss)
I0901 12:30:26.528350 916722 sgd_solver.cpp:106] Iteration 4509000, lr = 0.01
I0901 12:30:56.274638 916722 solver.cpp:218] Iteration 4509500 (16.8089 iter/s, 29.7462s/500 iters), loss = 0.351226
I0901 12:30:56.274701 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.351227 (* 1 = 0.351227 loss)
I0901 12:30:56.274710 916722 sgd_solver.cpp:106] Iteration 4509500, lr = 0.01
I0901 12:31:26.019711 916722 solver.cpp:218] Iteration 4510000 (16.8096 iter/s, 29.7449s/500 iters), loss = 0.0107253
I0901 12:31:26.019762 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0107262 (* 1 = 0.0107262 loss)
I0901 12:31:26.019770 916722 sgd_solver.cpp:106] Iteration 4510000, lr = 0.01
I0901 12:31:55.764892 916722 solver.cpp:218] Iteration 4510500 (16.8096 iter/s, 29.745s/500 iters), loss = 0.0357816
I0901 12:31:55.764955 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0357824 (* 1 = 0.0357824 loss)
I0901 12:31:55.764964 916722 sgd_solver.cpp:106] Iteration 4510500, lr = 0.01
I0901 12:32:25.512076 916722 solver.cpp:218] Iteration 4511000 (16.8084 iter/s, 29.747s/500 iters), loss = 0.219543
I0901 12:32:25.512128 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.219544 (* 1 = 0.219544 loss)
I0901 12:32:25.512137 916722 sgd_solver.cpp:106] Iteration 4511000, lr = 0.01
I0901 12:32:55.261107 916722 solver.cpp:218] Iteration 4511500 (16.8074 iter/s, 29.7488s/500 iters), loss = 0.0848013
I0901 12:32:55.261168 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.084802 (* 1 = 0.084802 loss)
I0901 12:32:55.261178 916722 sgd_solver.cpp:106] Iteration 4511500, lr = 0.01
I0901 12:33:25.006321 916722 solver.cpp:218] Iteration 4512000 (16.8095 iter/s, 29.745s/500 iters), loss = 0.0398375
I0901 12:33:25.006371 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0398382 (* 1 = 0.0398382 loss)
I0901 12:33:25.006381 916722 sgd_solver.cpp:106] Iteration 4512000, lr = 0.01
I0901 12:33:54.754065 916722 solver.cpp:218] Iteration 4512500 (16.8081 iter/s, 29.7476s/500 iters), loss = 0.092447
I0901 12:33:54.754145 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0924477 (* 1 = 0.0924477 loss)
I0901 12:33:54.754153 916722 sgd_solver.cpp:106] Iteration 4512500, lr = 0.01
I0901 12:34:24.503420 916722 solver.cpp:218] Iteration 4513000 (16.8072 iter/s, 29.7491s/500 iters), loss = 0.0154169
I0901 12:34:24.503473 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0154175 (* 1 = 0.0154175 loss)
I0901 12:34:24.503482 916722 sgd_solver.cpp:106] Iteration 4513000, lr = 0.01
I0901 12:34:54.252270 916722 solver.cpp:218] Iteration 4513500 (16.8075 iter/s, 29.7487s/500 iters), loss = 0.293903
I0901 12:34:54.252331 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.293904 (* 1 = 0.293904 loss)
I0901 12:34:54.252339 916722 sgd_solver.cpp:106] Iteration 4513500, lr = 0.01
I0901 12:35:23.996851 916722 solver.cpp:218] Iteration 4514000 (16.8099 iter/s, 29.7444s/500 iters), loss = 0.0777095
I0901 12:35:23.996902 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0777103 (* 1 = 0.0777103 loss)
I0901 12:35:23.996912 916722 sgd_solver.cpp:106] Iteration 4514000, lr = 0.01
I0901 12:35:53.745314 916722 solver.cpp:218] Iteration 4514500 (16.8077 iter/s, 29.7483s/500 iters), loss = 0.0831937
I0901 12:35:53.745376 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0831944 (* 1 = 0.0831944 loss)
I0901 12:35:53.745384 916722 sgd_solver.cpp:106] Iteration 4514500, lr = 0.01
I0901 12:36:23.514288 916722 solver.cpp:218] Iteration 4515000 (16.7961 iter/s, 29.7688s/500 iters), loss = 0.419373
I0901 12:36:23.514339 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.419374 (* 1 = 0.419374 loss)
I0901 12:36:23.514349 916722 sgd_solver.cpp:106] Iteration 4515000, lr = 0.01
I0901 12:36:53.289264 916722 solver.cpp:218] Iteration 4515500 (16.7927 iter/s, 29.7748s/500 iters), loss = 0.0589597
I0901 12:36:53.289321 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0589604 (* 1 = 0.0589604 loss)
I0901 12:36:53.289330 916722 sgd_solver.cpp:106] Iteration 4515500, lr = 0.01
I0901 12:37:23.054998 916722 solver.cpp:218] Iteration 4516000 (16.7979 iter/s, 29.7656s/500 iters), loss = 0.111067
I0901 12:37:23.055047 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111068 (* 1 = 0.111068 loss)
I0901 12:37:23.055058 916722 sgd_solver.cpp:106] Iteration 4516000, lr = 0.01
I0901 12:37:52.821111 916722 solver.cpp:218] Iteration 4516500 (16.7977 iter/s, 29.7659s/500 iters), loss = 0.223899
I0901 12:37:52.821164 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.2239 (* 1 = 0.2239 loss)
I0901 12:37:52.821173 916722 sgd_solver.cpp:106] Iteration 4516500, lr = 0.01
I0901 12:38:22.581918 916722 solver.cpp:218] Iteration 4517000 (16.8007 iter/s, 29.7606s/500 iters), loss = 0.0696466
I0901 12:38:22.581965 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0696473 (* 1 = 0.0696473 loss)
I0901 12:38:22.581975 916722 sgd_solver.cpp:106] Iteration 4517000, lr = 0.01
I0901 12:38:52.342949 916722 solver.cpp:218] Iteration 4517500 (16.8006 iter/s, 29.7609s/500 iters), loss = 0.103463
I0901 12:38:52.343003 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.103464 (* 1 = 0.103464 loss)
I0901 12:38:52.343012 916722 sgd_solver.cpp:106] Iteration 4517500, lr = 0.01
I0901 12:39:22.103493 916722 solver.cpp:218] Iteration 4518000 (16.8009 iter/s, 29.7604s/500 iters), loss = 0.154496
I0901 12:39:22.103547 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.154497 (* 1 = 0.154497 loss)
I0901 12:39:22.103559 916722 sgd_solver.cpp:106] Iteration 4518000, lr = 0.01
I0901 12:39:51.857174 916722 solver.cpp:218] Iteration 4518500 (16.8047 iter/s, 29.7535s/500 iters), loss = 0.41296
I0901 12:39:51.857235 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.41296 (* 1 = 0.41296 loss)
I0901 12:39:51.857244 916722 sgd_solver.cpp:106] Iteration 4518500, lr = 0.01
I0901 12:40:21.609261 916722 solver.cpp:218] Iteration 4519000 (16.8056 iter/s, 29.7519s/500 iters), loss = 0.101348
I0901 12:40:21.609329 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101349 (* 1 = 0.101349 loss)
I0901 12:40:21.609340 916722 sgd_solver.cpp:106] Iteration 4519000, lr = 0.01
I0901 12:40:51.359424 916722 solver.cpp:218] Iteration 4519500 (16.8067 iter/s, 29.75s/500 iters), loss = 0.0732887
I0901 12:40:51.359495 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0732894 (* 1 = 0.0732894 loss)
I0901 12:40:51.359504 916722 sgd_solver.cpp:106] Iteration 4519500, lr = 0.01
I0901 12:41:21.114109 916722 solver.cpp:218] Iteration 4520000 (16.8042 iter/s, 29.7545s/500 iters), loss = 0.0836637
I0901 12:41:21.114166 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0836646 (* 1 = 0.0836646 loss)
I0901 12:41:21.114176 916722 sgd_solver.cpp:106] Iteration 4520000, lr = 0.01
I0901 12:41:50.862236 916722 solver.cpp:218] Iteration 4520500 (16.8079 iter/s, 29.748s/500 iters), loss = 0.115221
I0901 12:41:50.862298 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115222 (* 1 = 0.115222 loss)
I0901 12:41:50.862306 916722 sgd_solver.cpp:106] Iteration 4520500, lr = 0.01
I0901 12:42:20.613247 916722 solver.cpp:218] Iteration 4521000 (16.8062 iter/s, 29.7508s/500 iters), loss = 0.360651
I0901 12:42:20.613306 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.360651 (* 1 = 0.360651 loss)
I0901 12:42:20.613317 916722 sgd_solver.cpp:106] Iteration 4521000, lr = 0.01
I0901 12:42:50.365365 916722 solver.cpp:218] Iteration 4521500 (16.8056 iter/s, 29.7519s/500 iters), loss = 0.209157
I0901 12:42:50.365424 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.209157 (* 1 = 0.209157 loss)
I0901 12:42:50.365433 916722 sgd_solver.cpp:106] Iteration 4521500, lr = 0.01
I0901 12:43:20.118993 916722 solver.cpp:218] Iteration 4522000 (16.8048 iter/s, 29.7535s/500 iters), loss = 0.129673
I0901 12:43:20.119042 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.129674 (* 1 = 0.129674 loss)
I0901 12:43:20.119052 916722 sgd_solver.cpp:106] Iteration 4522000, lr = 0.01
I0901 12:43:49.873791 916722 solver.cpp:218] Iteration 4522500 (16.8041 iter/s, 29.7546s/500 iters), loss = 0.0179264
I0901 12:43:49.873857 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.017927 (* 1 = 0.017927 loss)
I0901 12:43:49.873867 916722 sgd_solver.cpp:106] Iteration 4522500, lr = 0.01
I0901 12:44:19.627202 916722 solver.cpp:218] Iteration 4523000 (16.8049 iter/s, 29.7532s/500 iters), loss = 0.152697
I0901 12:44:19.627254 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152697 (* 1 = 0.152697 loss)
I0901 12:44:19.627262 916722 sgd_solver.cpp:106] Iteration 4523000, lr = 0.01
I0901 12:44:49.377175 916722 solver.cpp:218] Iteration 4523500 (16.8068 iter/s, 29.7498s/500 iters), loss = 0.0497852
I0901 12:44:49.377236 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0497859 (* 1 = 0.0497859 loss)
I0901 12:44:49.377244 916722 sgd_solver.cpp:106] Iteration 4523500, lr = 0.01
I0901 12:45:19.129741 916722 solver.cpp:218] Iteration 4524000 (16.8054 iter/s, 29.7524s/500 iters), loss = 0.278944
I0901 12:45:19.129796 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.278945 (* 1 = 0.278945 loss)
I0901 12:45:19.129806 916722 sgd_solver.cpp:106] Iteration 4524000, lr = 0.01
I0901 12:45:48.884846 916722 solver.cpp:218] Iteration 4524500 (16.8039 iter/s, 29.7549s/500 iters), loss = 0.202203
I0901 12:45:48.884907 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.202203 (* 1 = 0.202203 loss)
I0901 12:45:48.884915 916722 sgd_solver.cpp:106] Iteration 4524500, lr = 0.01
I0901 12:46:18.639490 916722 solver.cpp:218] Iteration 4525000 (16.8042 iter/s, 29.7545s/500 iters), loss = 0.150026
I0901 12:46:18.639545 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.150026 (* 1 = 0.150026 loss)
I0901 12:46:18.639555 916722 sgd_solver.cpp:106] Iteration 4525000, lr = 0.01
I0901 12:46:48.394716 916722 solver.cpp:218] Iteration 4525500 (16.8039 iter/s, 29.7551s/500 iters), loss = 0.0999322
I0901 12:46:48.394788 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0999328 (* 1 = 0.0999328 loss)
I0901 12:46:48.394800 916722 sgd_solver.cpp:106] Iteration 4525500, lr = 0.01
I0901 12:47:18.150347 916722 solver.cpp:218] Iteration 4526000 (16.8036 iter/s, 29.7555s/500 iters), loss = 0.140945
I0901 12:47:18.150401 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.140945 (* 1 = 0.140945 loss)
I0901 12:47:18.150411 916722 sgd_solver.cpp:106] Iteration 4526000, lr = 0.01
I0901 12:47:47.901167 916722 solver.cpp:218] Iteration 4526500 (16.8064 iter/s, 29.7507s/500 iters), loss = 0.154945
I0901 12:47:47.901224 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.154946 (* 1 = 0.154946 loss)
I0901 12:47:47.901232 916722 sgd_solver.cpp:106] Iteration 4526500, lr = 0.01
I0901 12:48:17.655022 916722 solver.cpp:218] Iteration 4527000 (16.8046 iter/s, 29.7537s/500 iters), loss = 0.187767
I0901 12:48:17.655077 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.187767 (* 1 = 0.187767 loss)
I0901 12:48:17.655087 916722 sgd_solver.cpp:106] Iteration 4527000, lr = 0.01
I0901 12:48:47.407407 916722 solver.cpp:218] Iteration 4527500 (16.8055 iter/s, 29.7522s/500 iters), loss = 0.0339216
I0901 12:48:47.407470 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.033922 (* 1 = 0.033922 loss)
I0901 12:48:47.407480 916722 sgd_solver.cpp:106] Iteration 4527500, lr = 0.01
I0901 12:49:17.159519 916722 solver.cpp:218] Iteration 4528000 (16.8057 iter/s, 29.7518s/500 iters), loss = 0.11528
I0901 12:49:17.159574 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115281 (* 1 = 0.115281 loss)
I0901 12:49:17.159582 916722 sgd_solver.cpp:106] Iteration 4528000, lr = 0.01
I0901 12:49:46.914568 916722 solver.cpp:218] Iteration 4528500 (16.804 iter/s, 29.7548s/500 iters), loss = 0.330822
I0901 12:49:46.914630 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.330823 (* 1 = 0.330823 loss)
I0901 12:49:46.914638 916722 sgd_solver.cpp:106] Iteration 4528500, lr = 0.01
I0901 12:50:16.666982 916722 solver.cpp:218] Iteration 4529000 (16.8055 iter/s, 29.7521s/500 iters), loss = 0.105509
I0901 12:50:16.667037 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105509 (* 1 = 0.105509 loss)
I0901 12:50:16.667045 916722 sgd_solver.cpp:106] Iteration 4529000, lr = 0.01
I0901 12:50:46.422000 916722 solver.cpp:218] Iteration 4529500 (16.804 iter/s, 29.7548s/500 iters), loss = 0.126855
I0901 12:50:46.422061 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.126856 (* 1 = 0.126856 loss)
I0901 12:50:46.422070 916722 sgd_solver.cpp:106] Iteration 4529500, lr = 0.01
I0901 12:51:16.178544 916722 solver.cpp:218] Iteration 4530000 (16.8032 iter/s, 29.7563s/500 iters), loss = 0.0682822
I0901 12:51:16.178596 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0682826 (* 1 = 0.0682826 loss)
I0901 12:51:16.178606 916722 sgd_solver.cpp:106] Iteration 4530000, lr = 0.01
I0901 12:51:45.931773 916722 solver.cpp:218] Iteration 4530500 (16.805 iter/s, 29.753s/500 iters), loss = 0.10492
I0901 12:51:45.931833 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.10492 (* 1 = 0.10492 loss)
I0901 12:51:45.931843 916722 sgd_solver.cpp:106] Iteration 4530500, lr = 0.01
I0901 12:52:15.682291 916722 solver.cpp:218] Iteration 4531000 (16.8066 iter/s, 29.7503s/500 iters), loss = 0.370946
I0901 12:52:15.682341 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.370947 (* 1 = 0.370947 loss)
I0901 12:52:15.682350 916722 sgd_solver.cpp:106] Iteration 4531000, lr = 0.01
I0901 12:52:45.434950 916722 solver.cpp:218] Iteration 4531500 (16.8054 iter/s, 29.7524s/500 iters), loss = 0.201806
I0901 12:52:45.435012 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.201807 (* 1 = 0.201807 loss)
I0901 12:52:45.435020 916722 sgd_solver.cpp:106] Iteration 4531500, lr = 0.01
I0901 12:53:15.190593 916722 solver.cpp:218] Iteration 4532000 (16.8037 iter/s, 29.7554s/500 iters), loss = 0.159453
I0901 12:53:15.190647 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159453 (* 1 = 0.159453 loss)
I0901 12:53:15.190667 916722 sgd_solver.cpp:106] Iteration 4532000, lr = 0.01
I0901 12:53:44.944713 916722 solver.cpp:218] Iteration 4532500 (16.8045 iter/s, 29.7539s/500 iters), loss = 0.233849
I0901 12:53:44.944795 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.23385 (* 1 = 0.23385 loss)
I0901 12:53:44.944805 916722 sgd_solver.cpp:106] Iteration 4532500, lr = 0.01
I0901 12:54:14.698057 916722 solver.cpp:218] Iteration 4533000 (16.805 iter/s, 29.7531s/500 iters), loss = 0.207293
I0901 12:54:14.698115 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.207293 (* 1 = 0.207293 loss)
I0901 12:54:14.698125 916722 sgd_solver.cpp:106] Iteration 4533000, lr = 0.01
I0901 12:54:44.453811 916722 solver.cpp:218] Iteration 4533500 (16.8036 iter/s, 29.7555s/500 iters), loss = 0.163898
I0901 12:54:44.453873 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.163899 (* 1 = 0.163899 loss)
I0901 12:54:44.453882 916722 sgd_solver.cpp:106] Iteration 4533500, lr = 0.01
I0901 12:55:14.207126 916722 solver.cpp:218] Iteration 4534000 (16.805 iter/s, 29.7531s/500 iters), loss = 0.0938317
I0901 12:55:14.207181 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0938322 (* 1 = 0.0938322 loss)
I0901 12:55:14.207191 916722 sgd_solver.cpp:106] Iteration 4534000, lr = 0.01
I0901 12:55:43.962246 916722 solver.cpp:218] Iteration 4534500 (16.804 iter/s, 29.7549s/500 iters), loss = 0.0240883
I0901 12:55:43.962306 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0240888 (* 1 = 0.0240888 loss)
I0901 12:55:43.962314 916722 sgd_solver.cpp:106] Iteration 4534500, lr = 0.01
I0901 12:56:13.716768 916722 solver.cpp:218] Iteration 4535000 (16.8043 iter/s, 29.7543s/500 iters), loss = 0.133103
I0901 12:56:13.716821 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133103 (* 1 = 0.133103 loss)
I0901 12:56:13.716831 916722 sgd_solver.cpp:106] Iteration 4535000, lr = 0.01
I0901 12:56:43.469185 916722 solver.cpp:218] Iteration 4535500 (16.8055 iter/s, 29.7522s/500 iters), loss = 0.283365
I0901 12:56:43.469242 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.283366 (* 1 = 0.283366 loss)
I0901 12:56:43.469250 916722 sgd_solver.cpp:106] Iteration 4535500, lr = 0.01
I0901 12:57:13.220046 916722 solver.cpp:218] Iteration 4536000 (16.8064 iter/s, 29.7506s/500 iters), loss = 0.196861
I0901 12:57:13.220099 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.196861 (* 1 = 0.196861 loss)
I0901 12:57:13.220109 916722 sgd_solver.cpp:106] Iteration 4536000, lr = 0.01
I0901 12:57:42.976641 916722 solver.cpp:218] Iteration 4536500 (16.8031 iter/s, 29.7564s/500 iters), loss = 0.0975126
I0901 12:57:42.976704 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0975132 (* 1 = 0.0975132 loss)
I0901 12:57:42.976713 916722 sgd_solver.cpp:106] Iteration 4536500, lr = 0.01
I0901 12:58:12.736660 916722 solver.cpp:218] Iteration 4537000 (16.8012 iter/s, 29.7598s/500 iters), loss = 0.0623526
I0901 12:58:12.736716 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0623531 (* 1 = 0.0623531 loss)
I0901 12:58:12.736727 916722 sgd_solver.cpp:106] Iteration 4537000, lr = 0.01
I0901 12:58:42.495344 916722 solver.cpp:218] Iteration 4537500 (16.8019 iter/s, 29.7585s/500 iters), loss = 0.0416055
I0901 12:58:42.495409 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0416058 (* 1 = 0.0416058 loss)
I0901 12:58:42.495417 916722 sgd_solver.cpp:106] Iteration 4537500, lr = 0.01
I0901 12:59:12.256512 916722 solver.cpp:218] Iteration 4538000 (16.8005 iter/s, 29.761s/500 iters), loss = 0.298943
I0901 12:59:12.256569 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.298944 (* 1 = 0.298944 loss)
I0901 12:59:12.256578 916722 sgd_solver.cpp:106] Iteration 4538000, lr = 0.01
I0901 12:59:41.988994 916722 solver.cpp:218] Iteration 4538500 (16.8167 iter/s, 29.7323s/500 iters), loss = 0.184933
I0901 12:59:41.989056 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.184934 (* 1 = 0.184934 loss)
I0901 12:59:41.989065 916722 sgd_solver.cpp:106] Iteration 4538500, lr = 0.01
I0901 13:00:11.714143 916722 solver.cpp:218] Iteration 4539000 (16.8209 iter/s, 29.7249s/500 iters), loss = 0.0991021
I0901 13:00:11.714197 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0991027 (* 1 = 0.0991027 loss)
I0901 13:00:11.714206 916722 sgd_solver.cpp:106] Iteration 4539000, lr = 0.01
I0901 13:00:41.438378 916722 solver.cpp:218] Iteration 4539500 (16.8214 iter/s, 29.724s/500 iters), loss = 0.15406
I0901 13:00:41.438444 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.154061 (* 1 = 0.154061 loss)
I0901 13:00:41.438453 916722 sgd_solver.cpp:106] Iteration 4539500, lr = 0.01
I0901 13:01:11.161361 916722 solver.cpp:218] Iteration 4540000 (16.8221 iter/s, 29.7228s/500 iters), loss = 0.0167623
I0901 13:01:11.161413 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0167628 (* 1 = 0.0167628 loss)
I0901 13:01:11.161422 916722 sgd_solver.cpp:106] Iteration 4540000, lr = 0.01
I0901 13:01:40.886348 916722 solver.cpp:218] Iteration 4540500 (16.821 iter/s, 29.7248s/500 iters), loss = 0.114579
I0901 13:01:40.886409 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.11458 (* 1 = 0.11458 loss)
I0901 13:01:40.886417 916722 sgd_solver.cpp:106] Iteration 4540500, lr = 0.01
I0901 13:02:10.613968 916722 solver.cpp:218] Iteration 4541000 (16.8195 iter/s, 29.7274s/500 iters), loss = 0.317889
I0901 13:02:10.614019 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.31789 (* 1 = 0.31789 loss)
I0901 13:02:10.614028 916722 sgd_solver.cpp:106] Iteration 4541000, lr = 0.01
I0901 13:02:40.341898 916722 solver.cpp:218] Iteration 4541500 (16.8193 iter/s, 29.7277s/500 iters), loss = 0.0421813
I0901 13:02:40.341961 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0421817 (* 1 = 0.0421817 loss)
I0901 13:02:40.341970 916722 sgd_solver.cpp:106] Iteration 4541500, lr = 0.01
I0901 13:03:10.066478 916722 solver.cpp:218] Iteration 4542000 (16.8212 iter/s, 29.7244s/500 iters), loss = 0.463184
I0901 13:03:10.066532 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.463184 (* 1 = 0.463184 loss)
I0901 13:03:10.066542 916722 sgd_solver.cpp:106] Iteration 4542000, lr = 0.01
I0901 13:03:39.791550 916722 solver.cpp:218] Iteration 4542500 (16.8209 iter/s, 29.7249s/500 iters), loss = 0.14143
I0901 13:03:39.791610 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.14143 (* 1 = 0.14143 loss)
I0901 13:03:39.791620 916722 sgd_solver.cpp:106] Iteration 4542500, lr = 0.01
I0901 13:04:09.515552 916722 solver.cpp:218] Iteration 4543000 (16.8215 iter/s, 29.7238s/500 iters), loss = 0.161951
I0901 13:04:09.515604 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.161952 (* 1 = 0.161952 loss)
I0901 13:04:09.515614 916722 sgd_solver.cpp:106] Iteration 4543000, lr = 0.01
I0901 13:04:39.239293 916722 solver.cpp:218] Iteration 4543500 (16.8217 iter/s, 29.7236s/500 iters), loss = 0.0627133
I0901 13:04:39.239352 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0627137 (* 1 = 0.0627137 loss)
I0901 13:04:39.239360 916722 sgd_solver.cpp:106] Iteration 4543500, lr = 0.01
I0901 13:05:08.962227 916722 solver.cpp:218] Iteration 4544000 (16.8221 iter/s, 29.7227s/500 iters), loss = 0.0594054
I0901 13:05:08.962280 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0594058 (* 1 = 0.0594058 loss)
I0901 13:05:08.962289 916722 sgd_solver.cpp:106] Iteration 4544000, lr = 0.01
I0901 13:05:38.685571 916722 solver.cpp:218] Iteration 4544500 (16.8219 iter/s, 29.7232s/500 iters), loss = 0.217145
I0901 13:05:38.685626 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.217145 (* 1 = 0.217145 loss)
I0901 13:05:38.685634 916722 sgd_solver.cpp:106] Iteration 4544500, lr = 0.01
I0901 13:06:08.411398 916722 solver.cpp:218] Iteration 4545000 (16.8205 iter/s, 29.7256s/500 iters), loss = 0.0533921
I0901 13:06:08.411453 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0533927 (* 1 = 0.0533927 loss)
I0901 13:06:08.411463 916722 sgd_solver.cpp:106] Iteration 4545000, lr = 0.01
I0901 13:06:38.135010 916722 solver.cpp:218] Iteration 4545500 (16.8217 iter/s, 29.7234s/500 iters), loss = 0.0816906
I0901 13:06:38.135083 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0816913 (* 1 = 0.0816913 loss)
I0901 13:06:38.135092 916722 sgd_solver.cpp:106] Iteration 4545500, lr = 0.01
I0901 13:07:07.857978 916722 solver.cpp:218] Iteration 4546000 (16.8221 iter/s, 29.7228s/500 iters), loss = 0.156516
I0901 13:07:07.858031 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.156517 (* 1 = 0.156517 loss)
I0901 13:07:07.858042 916722 sgd_solver.cpp:106] Iteration 4546000, lr = 0.01
I0901 13:07:37.580924 916722 solver.cpp:218] Iteration 4546500 (16.8221 iter/s, 29.7228s/500 iters), loss = 0.127518
I0901 13:07:37.580987 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.127519 (* 1 = 0.127519 loss)
I0901 13:07:37.580996 916722 sgd_solver.cpp:106] Iteration 4546500, lr = 0.01
I0901 13:08:07.305191 916722 solver.cpp:218] Iteration 4547000 (16.8214 iter/s, 29.7241s/500 iters), loss = 0.0774725
I0901 13:08:07.305240 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0774729 (* 1 = 0.0774729 loss)
I0901 13:08:07.305248 916722 sgd_solver.cpp:106] Iteration 4547000, lr = 0.01
I0901 13:08:37.029475 916722 solver.cpp:218] Iteration 4547500 (16.8214 iter/s, 29.7241s/500 iters), loss = 0.0400502
I0901 13:08:37.029536 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0400506 (* 1 = 0.0400506 loss)
I0901 13:08:37.029546 916722 sgd_solver.cpp:106] Iteration 4547500, lr = 0.01
I0901 13:09:06.753975 916722 solver.cpp:218] Iteration 4548000 (16.8212 iter/s, 29.7243s/500 iters), loss = 0.234431
I0901 13:09:06.754026 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.234432 (* 1 = 0.234432 loss)
I0901 13:09:06.754036 916722 sgd_solver.cpp:106] Iteration 4548000, lr = 0.01
I0901 13:09:36.476279 916722 solver.cpp:218] Iteration 4548500 (16.8225 iter/s, 29.7221s/500 iters), loss = 0.0391383
I0901 13:09:36.476334 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0391386 (* 1 = 0.0391386 loss)
I0901 13:09:36.476343 916722 sgd_solver.cpp:106] Iteration 4548500, lr = 0.01
I0901 13:10:06.200150 916722 solver.cpp:218] Iteration 4549000 (16.8216 iter/s, 29.7237s/500 iters), loss = 0.0769495
I0901 13:10:06.200201 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0769499 (* 1 = 0.0769499 loss)
I0901 13:10:06.200212 916722 sgd_solver.cpp:106] Iteration 4549000, lr = 0.01
I0901 13:10:35.925877 916722 solver.cpp:218] Iteration 4549500 (16.8205 iter/s, 29.7256s/500 iters), loss = 0.377983
I0901 13:10:35.925938 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.377983 (* 1 = 0.377983 loss)
I0901 13:10:35.925947 916722 sgd_solver.cpp:106] Iteration 4549500, lr = 0.01
I0901 13:11:05.590943 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_4550000.caffemodel
I0901 13:11:05.610388 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_4550000.solverstate
I0901 13:11:05.616456 916722 solver.cpp:330] Iteration 4550000, Testing net (#0)
I0901 13:11:20.955626 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8709
I0901 13:11:20.955682 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.479923 (* 1 = 0.479923 loss)
I0901 13:11:21.014233 916722 solver.cpp:218] Iteration 4550000 (11.0894 iter/s, 45.0881s/500 iters), loss = 0.0659996
I0901 13:11:21.014261 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.066 (* 1 = 0.066 loss)
I0901 13:11:21.014271 916722 sgd_solver.cpp:106] Iteration 4550000, lr = 0.01
I0901 13:11:50.721169 916722 solver.cpp:218] Iteration 4550500 (16.8312 iter/s, 29.7068s/500 iters), loss = 0.113432
I0901 13:11:50.721220 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.113433 (* 1 = 0.113433 loss)
I0901 13:11:50.721230 916722 sgd_solver.cpp:106] Iteration 4550500, lr = 0.01
I0901 13:12:20.432761 916722 solver.cpp:218] Iteration 4551000 (16.8286 iter/s, 29.7114s/500 iters), loss = 0.102339
I0901 13:12:20.432835 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.102339 (* 1 = 0.102339 loss)
I0901 13:12:20.432844 916722 sgd_solver.cpp:106] Iteration 4551000, lr = 0.01
I0901 13:12:50.148512 916722 solver.cpp:218] Iteration 4551500 (16.8262 iter/s, 29.7156s/500 iters), loss = 0.0421729
I0901 13:12:50.148571 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0421733 (* 1 = 0.0421733 loss)
I0901 13:12:50.148581 916722 sgd_solver.cpp:106] Iteration 4551500, lr = 0.01
I0901 13:13:19.864126 916722 solver.cpp:218] Iteration 4552000 (16.8263 iter/s, 29.7154s/500 iters), loss = 0.242083
I0901 13:13:19.864187 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.242084 (* 1 = 0.242084 loss)
I0901 13:13:19.864195 916722 sgd_solver.cpp:106] Iteration 4552000, lr = 0.01
I0901 13:13:49.585320 916722 solver.cpp:218] Iteration 4552500 (16.8231 iter/s, 29.721s/500 iters), loss = 0.0640631
I0901 13:13:49.585376 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0640634 (* 1 = 0.0640634 loss)
I0901 13:13:49.585386 916722 sgd_solver.cpp:106] Iteration 4552500, lr = 0.01
I0901 13:14:19.302121 916722 solver.cpp:218] Iteration 4553000 (16.8256 iter/s, 29.7166s/500 iters), loss = 0.159835
I0901 13:14:19.302181 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159835 (* 1 = 0.159835 loss)
I0901 13:14:19.302191 916722 sgd_solver.cpp:106] Iteration 4553000, lr = 0.01
I0901 13:14:49.020925 916722 solver.cpp:218] Iteration 4553500 (16.8245 iter/s, 29.7186s/500 iters), loss = 0.0388432
I0901 13:14:49.020982 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0388435 (* 1 = 0.0388435 loss)
I0901 13:14:49.020992 916722 sgd_solver.cpp:106] Iteration 4553500, lr = 0.01
I0901 13:15:18.740717 916722 solver.cpp:218] Iteration 4554000 (16.8239 iter/s, 29.7196s/500 iters), loss = 0.0478283
I0901 13:15:18.740789 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0478285 (* 1 = 0.0478285 loss)
I0901 13:15:18.740797 916722 sgd_solver.cpp:106] Iteration 4554000, lr = 0.01
I0901 13:15:48.461079 916722 solver.cpp:218] Iteration 4554500 (16.8236 iter/s, 29.7202s/500 iters), loss = 0.211468
I0901 13:15:48.461131 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.211468 (* 1 = 0.211468 loss)
I0901 13:15:48.461141 916722 sgd_solver.cpp:106] Iteration 4554500, lr = 0.01
I0901 13:16:18.186419 916722 solver.cpp:218] Iteration 4555000 (16.8208 iter/s, 29.7252s/500 iters), loss = 0.22138
I0901 13:16:18.186477 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.22138 (* 1 = 0.22138 loss)
I0901 13:16:18.186486 916722 sgd_solver.cpp:106] Iteration 4555000, lr = 0.01
I0901 13:16:47.915477 916722 solver.cpp:218] Iteration 4555500 (16.8187 iter/s, 29.7289s/500 iters), loss = 0.301396
I0901 13:16:47.915524 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.301396 (* 1 = 0.301396 loss)
I0901 13:16:47.915534 916722 sgd_solver.cpp:106] Iteration 4555500, lr = 0.01
I0901 13:17:17.641778 916722 solver.cpp:218] Iteration 4556000 (16.8202 iter/s, 29.7261s/500 iters), loss = 0.340961
I0901 13:17:17.641839 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.340961 (* 1 = 0.340961 loss)
I0901 13:17:17.641847 916722 sgd_solver.cpp:106] Iteration 4556000, lr = 0.01
I0901 13:17:47.367625 916722 solver.cpp:218] Iteration 4556500 (16.8205 iter/s, 29.7257s/500 iters), loss = 0.0147821
I0901 13:17:47.367678 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0147826 (* 1 = 0.0147826 loss)
I0901 13:17:47.367687 916722 sgd_solver.cpp:106] Iteration 4556500, lr = 0.01
I0901 13:18:17.088280 916722 solver.cpp:218] Iteration 4557000 (16.8234 iter/s, 29.7205s/500 iters), loss = 0.117108
I0901 13:18:17.088341 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.117108 (* 1 = 0.117108 loss)
I0901 13:18:17.088351 916722 sgd_solver.cpp:106] Iteration 4557000, lr = 0.01
I0901 13:18:46.813376 916722 solver.cpp:218] Iteration 4557500 (16.8209 iter/s, 29.7249s/500 iters), loss = 0.291404
I0901 13:18:46.813431 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.291404 (* 1 = 0.291404 loss)
I0901 13:18:46.813452 916722 sgd_solver.cpp:106] Iteration 4557500, lr = 0.01
I0901 13:19:16.534639 916722 solver.cpp:218] Iteration 4558000 (16.8231 iter/s, 29.7211s/500 iters), loss = 0.086534
I0901 13:19:16.534710 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0865348 (* 1 = 0.0865348 loss)
I0901 13:19:16.534719 916722 sgd_solver.cpp:106] Iteration 4558000, lr = 0.01
I0901 13:19:46.255095 916722 solver.cpp:218] Iteration 4558500 (16.8235 iter/s, 29.7203s/500 iters), loss = 0.0174754
I0901 13:19:46.255148 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0174762 (* 1 = 0.0174762 loss)
I0901 13:19:46.255156 916722 sgd_solver.cpp:106] Iteration 4558500, lr = 0.01
I0901 13:20:15.976776 916722 solver.cpp:218] Iteration 4559000 (16.8228 iter/s, 29.7215s/500 iters), loss = 0.0617321
I0901 13:20:15.976835 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0617329 (* 1 = 0.0617329 loss)
I0901 13:20:15.976843 916722 sgd_solver.cpp:106] Iteration 4559000, lr = 0.01
I0901 13:20:45.697377 916722 solver.cpp:218] Iteration 4559500 (16.8234 iter/s, 29.7204s/500 iters), loss = 0.0782573
I0901 13:20:45.697427 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0782579 (* 1 = 0.0782579 loss)
I0901 13:20:45.697436 916722 sgd_solver.cpp:106] Iteration 4559500, lr = 0.01
I0901 13:21:15.418148 916722 solver.cpp:218] Iteration 4560000 (16.8233 iter/s, 29.7206s/500 iters), loss = 0.307746
I0901 13:21:15.418201 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.307747 (* 1 = 0.307747 loss)
I0901 13:21:15.418210 916722 sgd_solver.cpp:106] Iteration 4560000, lr = 0.01
I0901 13:21:45.135989 916722 solver.cpp:218] Iteration 4560500 (16.825 iter/s, 29.7177s/500 iters), loss = 0.198943
I0901 13:21:45.136044 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.198944 (* 1 = 0.198944 loss)
I0901 13:21:45.136052 916722 sgd_solver.cpp:106] Iteration 4560500, lr = 0.01
I0901 13:22:14.857219 916722 solver.cpp:218] Iteration 4561000 (16.8231 iter/s, 29.7211s/500 iters), loss = 0.168034
I0901 13:22:14.857280 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.168035 (* 1 = 0.168035 loss)
I0901 13:22:14.857288 916722 sgd_solver.cpp:106] Iteration 4561000, lr = 0.01
I0901 13:22:44.580256 916722 solver.cpp:218] Iteration 4561500 (16.8221 iter/s, 29.7229s/500 iters), loss = 0.273718
I0901 13:22:44.580310 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.273719 (* 1 = 0.273719 loss)
I0901 13:22:44.580319 916722 sgd_solver.cpp:106] Iteration 4561500, lr = 0.01
I0901 13:23:14.304265 916722 solver.cpp:218] Iteration 4562000 (16.8213 iter/s, 29.7243s/500 iters), loss = 0.343975
I0901 13:23:14.304327 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.343976 (* 1 = 0.343976 loss)
I0901 13:23:14.304334 916722 sgd_solver.cpp:106] Iteration 4562000, lr = 0.01
I0901 13:23:44.023715 916722 solver.cpp:218] Iteration 4562500 (16.8237 iter/s, 29.72s/500 iters), loss = 0.189336
I0901 13:23:44.023768 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.189337 (* 1 = 0.189337 loss)
I0901 13:23:44.023777 916722 sgd_solver.cpp:106] Iteration 4562500, lr = 0.01
I0901 13:24:13.744855 916722 solver.cpp:218] Iteration 4563000 (16.8227 iter/s, 29.7217s/500 iters), loss = 0.0399693
I0901 13:24:13.744916 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0399705 (* 1 = 0.0399705 loss)
I0901 13:24:13.744925 916722 sgd_solver.cpp:106] Iteration 4563000, lr = 0.01
I0901 13:24:43.465773 916722 solver.cpp:218] Iteration 4563500 (16.8229 iter/s, 29.7214s/500 iters), loss = 0.0922163
I0901 13:24:43.465827 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0922174 (* 1 = 0.0922174 loss)
I0901 13:24:43.465837 916722 sgd_solver.cpp:106] Iteration 4563500, lr = 0.01
I0901 13:25:13.184180 916722 solver.cpp:218] Iteration 4564000 (16.8243 iter/s, 29.7189s/500 iters), loss = 0.116127
I0901 13:25:13.184249 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.116128 (* 1 = 0.116128 loss)
I0901 13:25:13.184262 916722 sgd_solver.cpp:106] Iteration 4564000, lr = 0.01
I0901 13:25:42.902297 916722 solver.cpp:218] Iteration 4564500 (16.8245 iter/s, 29.7185s/500 iters), loss = 0.103802
I0901 13:25:42.902354 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.103804 (* 1 = 0.103804 loss)
I0901 13:25:42.902364 916722 sgd_solver.cpp:106] Iteration 4564500, lr = 0.01
I0901 13:26:12.623306 916722 solver.cpp:218] Iteration 4565000 (16.8229 iter/s, 29.7214s/500 iters), loss = 0.110945
I0901 13:26:12.623365 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110946 (* 1 = 0.110946 loss)
I0901 13:26:12.623373 916722 sgd_solver.cpp:106] Iteration 4565000, lr = 0.01
I0901 13:26:42.344513 916722 solver.cpp:218] Iteration 4565500 (16.8228 iter/s, 29.7216s/500 iters), loss = 0.141746
I0901 13:26:42.344568 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.141747 (* 1 = 0.141747 loss)
I0901 13:26:42.344578 916722 sgd_solver.cpp:106] Iteration 4565500, lr = 0.01
I0901 13:27:12.063912 916722 solver.cpp:218] Iteration 4566000 (16.8238 iter/s, 29.7198s/500 iters), loss = 0.285731
I0901 13:27:12.063971 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.285732 (* 1 = 0.285732 loss)
I0901 13:27:12.063978 916722 sgd_solver.cpp:106] Iteration 4566000, lr = 0.01
I0901 13:27:41.786393 916722 solver.cpp:218] Iteration 4566500 (16.8221 iter/s, 29.7228s/500 iters), loss = 0.16422
I0901 13:27:41.786443 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.164221 (* 1 = 0.164221 loss)
I0901 13:27:41.786453 916722 sgd_solver.cpp:106] Iteration 4566500, lr = 0.01
I0901 13:28:11.507876 916722 solver.cpp:218] Iteration 4567000 (16.8227 iter/s, 29.7218s/500 iters), loss = 0.0951448
I0901 13:28:11.507936 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0951463 (* 1 = 0.0951463 loss)
I0901 13:28:11.507944 916722 sgd_solver.cpp:106] Iteration 4567000, lr = 0.01
I0901 13:28:41.230618 916722 solver.cpp:218] Iteration 4567500 (16.822 iter/s, 29.723s/500 iters), loss = 0.0709663
I0901 13:28:41.230670 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0709677 (* 1 = 0.0709677 loss)
I0901 13:28:41.230680 916722 sgd_solver.cpp:106] Iteration 4567500, lr = 0.01
I0901 13:29:10.953588 916722 solver.cpp:218] Iteration 4568000 (16.8218 iter/s, 29.7232s/500 iters), loss = 0.150903
I0901 13:29:10.953645 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.150905 (* 1 = 0.150905 loss)
I0901 13:29:10.953655 916722 sgd_solver.cpp:106] Iteration 4568000, lr = 0.01
I0901 13:29:40.676646 916722 solver.cpp:218] Iteration 4568500 (16.8218 iter/s, 29.7233s/500 iters), loss = 0.0427128
I0901 13:29:40.676702 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0427143 (* 1 = 0.0427143 loss)
I0901 13:29:40.676712 916722 sgd_solver.cpp:106] Iteration 4568500, lr = 0.01
I0901 13:30:10.399771 916722 solver.cpp:218] Iteration 4569000 (16.8218 iter/s, 29.7234s/500 iters), loss = 0.370391
I0901 13:30:10.399828 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.370392 (* 1 = 0.370392 loss)
I0901 13:30:10.399837 916722 sgd_solver.cpp:106] Iteration 4569000, lr = 0.01
I0901 13:30:40.125720 916722 solver.cpp:218] Iteration 4569500 (16.8202 iter/s, 29.7262s/500 iters), loss = 0.195772
I0901 13:30:40.125773 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.195774 (* 1 = 0.195774 loss)
I0901 13:30:40.125783 916722 sgd_solver.cpp:106] Iteration 4569500, lr = 0.01
I0901 13:31:09.847959 916722 solver.cpp:218] Iteration 4570000 (16.8223 iter/s, 29.7224s/500 iters), loss = 0.166442
I0901 13:31:09.848019 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.166444 (* 1 = 0.166444 loss)
I0901 13:31:09.848027 916722 sgd_solver.cpp:106] Iteration 4570000, lr = 0.01
I0901 13:31:39.569124 916722 solver.cpp:218] Iteration 4570500 (16.8229 iter/s, 29.7213s/500 iters), loss = 0.19888
I0901 13:31:39.569175 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.198881 (* 1 = 0.198881 loss)
I0901 13:31:39.569193 916722 sgd_solver.cpp:106] Iteration 4570500, lr = 0.01
I0901 13:32:09.294126 916722 solver.cpp:218] Iteration 4571000 (16.8208 iter/s, 29.7252s/500 iters), loss = 0.115766
I0901 13:32:09.294193 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115768 (* 1 = 0.115768 loss)
I0901 13:32:09.294201 916722 sgd_solver.cpp:106] Iteration 4571000, lr = 0.01
I0901 13:32:39.018019 916722 solver.cpp:218] Iteration 4571500 (16.8214 iter/s, 29.724s/500 iters), loss = 0.0540939
I0901 13:32:39.018074 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0540954 (* 1 = 0.0540954 loss)
I0901 13:32:39.018083 916722 sgd_solver.cpp:106] Iteration 4571500, lr = 0.01
I0901 13:33:08.750337 916722 solver.cpp:218] Iteration 4572000 (16.8166 iter/s, 29.7325s/500 iters), loss = 0.22515
I0901 13:33:08.750402 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.225151 (* 1 = 0.225151 loss)
I0901 13:33:08.750411 916722 sgd_solver.cpp:106] Iteration 4572000, lr = 0.01
I0901 13:33:38.468037 916722 solver.cpp:218] Iteration 4572500 (16.8249 iter/s, 29.7178s/500 iters), loss = 0.0238515
I0901 13:33:38.468091 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0238528 (* 1 = 0.0238528 loss)
I0901 13:33:38.468101 916722 sgd_solver.cpp:106] Iteration 4572500, lr = 0.01
I0901 13:34:08.189798 916722 solver.cpp:218] Iteration 4573000 (16.8226 iter/s, 29.7219s/500 iters), loss = 0.188241
I0901 13:34:08.189857 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.188242 (* 1 = 0.188242 loss)
I0901 13:34:08.189865 916722 sgd_solver.cpp:106] Iteration 4573000, lr = 0.01
I0901 13:34:37.912227 916722 solver.cpp:218] Iteration 4573500 (16.8223 iter/s, 29.7225s/500 iters), loss = 0.169681
I0901 13:34:37.912281 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.169682 (* 1 = 0.169682 loss)
I0901 13:34:37.912289 916722 sgd_solver.cpp:106] Iteration 4573500, lr = 0.01
I0901 13:35:07.633685 916722 solver.cpp:218] Iteration 4574000 (16.8228 iter/s, 29.7216s/500 iters), loss = 0.309371
I0901 13:35:07.633744 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.309372 (* 1 = 0.309372 loss)
I0901 13:35:07.633752 916722 sgd_solver.cpp:106] Iteration 4574000, lr = 0.01
I0901 13:35:37.358398 916722 solver.cpp:218] Iteration 4574500 (16.821 iter/s, 29.7248s/500 iters), loss = 0.103507
I0901 13:35:37.358453 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.103509 (* 1 = 0.103509 loss)
I0901 13:35:37.358461 916722 sgd_solver.cpp:106] Iteration 4574500, lr = 0.01
I0901 13:36:07.081357 916722 solver.cpp:218] Iteration 4575000 (16.822 iter/s, 29.723s/500 iters), loss = 0.224481
I0901 13:36:07.081415 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.224483 (* 1 = 0.224483 loss)
I0901 13:36:07.081424 916722 sgd_solver.cpp:106] Iteration 4575000, lr = 0.01
I0901 13:36:36.803745 916722 solver.cpp:218] Iteration 4575500 (16.8223 iter/s, 29.7225s/500 iters), loss = 0.217313
I0901 13:36:36.803797 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.217314 (* 1 = 0.217314 loss)
I0901 13:36:36.803807 916722 sgd_solver.cpp:106] Iteration 4575500, lr = 0.01
I0901 13:37:06.529354 916722 solver.cpp:218] Iteration 4576000 (16.8205 iter/s, 29.7257s/500 iters), loss = 0.113381
I0901 13:37:06.529412 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.113382 (* 1 = 0.113382 loss)
I0901 13:37:06.529422 916722 sgd_solver.cpp:106] Iteration 4576000, lr = 0.01
I0901 13:37:36.248286 916722 solver.cpp:218] Iteration 4576500 (16.8243 iter/s, 29.719s/500 iters), loss = 0.0932634
I0901 13:37:36.248339 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.093265 (* 1 = 0.093265 loss)
I0901 13:37:36.248349 916722 sgd_solver.cpp:106] Iteration 4576500, lr = 0.01
I0901 13:38:05.970137 916722 solver.cpp:218] Iteration 4577000 (16.8226 iter/s, 29.7219s/500 iters), loss = 0.0617125
I0901 13:38:05.970194 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0617141 (* 1 = 0.0617141 loss)
I0901 13:38:05.970203 916722 sgd_solver.cpp:106] Iteration 4577000, lr = 0.01
I0901 13:38:35.691134 916722 solver.cpp:218] Iteration 4577500 (16.8231 iter/s, 29.721s/500 iters), loss = 0.149195
I0901 13:38:35.691188 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.149197 (* 1 = 0.149197 loss)
I0901 13:38:35.691198 916722 sgd_solver.cpp:106] Iteration 4577500, lr = 0.01
I0901 13:39:05.416126 916722 solver.cpp:218] Iteration 4578000 (16.8208 iter/s, 29.725s/500 iters), loss = 0.0700219
I0901 13:39:05.416193 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0700236 (* 1 = 0.0700236 loss)
I0901 13:39:05.416203 916722 sgd_solver.cpp:106] Iteration 4578000, lr = 0.01
I0901 13:39:35.139678 916722 solver.cpp:218] Iteration 4578500 (16.8217 iter/s, 29.7236s/500 iters), loss = 0.212412
I0901 13:39:35.139732 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.212413 (* 1 = 0.212413 loss)
I0901 13:39:35.139742 916722 sgd_solver.cpp:106] Iteration 4578500, lr = 0.01
I0901 13:40:04.860055 916722 solver.cpp:218] Iteration 4579000 (16.8235 iter/s, 29.7204s/500 iters), loss = 0.0502125
I0901 13:40:04.860111 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0502142 (* 1 = 0.0502142 loss)
I0901 13:40:04.860119 916722 sgd_solver.cpp:106] Iteration 4579000, lr = 0.01
I0901 13:40:34.581362 916722 solver.cpp:218] Iteration 4579500 (16.8229 iter/s, 29.7213s/500 iters), loss = 0.216681
I0901 13:40:34.581413 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.216683 (* 1 = 0.216683 loss)
I0901 13:40:34.581423 916722 sgd_solver.cpp:106] Iteration 4579500, lr = 0.01
I0901 13:41:04.305258 916722 solver.cpp:218] Iteration 4580000 (16.8215 iter/s, 29.7239s/500 iters), loss = 0.137785
I0901 13:41:04.305315 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.137787 (* 1 = 0.137787 loss)
I0901 13:41:04.305322 916722 sgd_solver.cpp:106] Iteration 4580000, lr = 0.01
I0901 13:41:34.038836 916722 solver.cpp:218] Iteration 4580500 (16.816 iter/s, 29.7336s/500 iters), loss = 0.0894444
I0901 13:41:34.038894 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.089446 (* 1 = 0.089446 loss)
I0901 13:41:34.038905 916722 sgd_solver.cpp:106] Iteration 4580500, lr = 0.01
I0901 13:42:03.769263 916722 solver.cpp:218] Iteration 4581000 (16.8178 iter/s, 29.7304s/500 iters), loss = 0.138526
I0901 13:42:03.769325 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.138528 (* 1 = 0.138528 loss)
I0901 13:42:03.769333 916722 sgd_solver.cpp:106] Iteration 4581000, lr = 0.01
I0901 13:42:33.493772 916722 solver.cpp:218] Iteration 4581500 (16.8211 iter/s, 29.7245s/500 iters), loss = 0.0811869
I0901 13:42:33.493829 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0811883 (* 1 = 0.0811883 loss)
I0901 13:42:33.493837 916722 sgd_solver.cpp:106] Iteration 4581500, lr = 0.01
I0901 13:43:03.219267 916722 solver.cpp:218] Iteration 4582000 (16.8206 iter/s, 29.7255s/500 iters), loss = 0.257588
I0901 13:43:03.219323 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.257589 (* 1 = 0.257589 loss)
I0901 13:43:03.219332 916722 sgd_solver.cpp:106] Iteration 4582000, lr = 0.01
I0901 13:43:32.945693 916722 solver.cpp:218] Iteration 4582500 (16.8201 iter/s, 29.7264s/500 iters), loss = 0.114848
I0901 13:43:32.945745 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.114849 (* 1 = 0.114849 loss)
I0901 13:43:32.945755 916722 sgd_solver.cpp:106] Iteration 4582500, lr = 0.01
I0901 13:44:02.668788 916722 solver.cpp:218] Iteration 4583000 (16.8219 iter/s, 29.7231s/500 iters), loss = 0.103836
I0901 13:44:02.668846 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.103837 (* 1 = 0.103837 loss)
I0901 13:44:02.668854 916722 sgd_solver.cpp:106] Iteration 4583000, lr = 0.01
I0901 13:44:32.395117 916722 solver.cpp:218] Iteration 4583500 (16.8201 iter/s, 29.7263s/500 iters), loss = 0.250462
I0901 13:44:32.395167 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.250464 (* 1 = 0.250464 loss)
I0901 13:44:32.395176 916722 sgd_solver.cpp:106] Iteration 4583500, lr = 0.01
I0901 13:45:02.117348 916722 solver.cpp:218] Iteration 4584000 (16.8224 iter/s, 29.7222s/500 iters), loss = 0.0801513
I0901 13:45:02.117420 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0801527 (* 1 = 0.0801527 loss)
I0901 13:45:02.117432 916722 sgd_solver.cpp:106] Iteration 4584000, lr = 0.01
I0901 13:45:31.840126 916722 solver.cpp:218] Iteration 4584500 (16.8221 iter/s, 29.7227s/500 iters), loss = 0.0654084
I0901 13:45:31.840174 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0654097 (* 1 = 0.0654097 loss)
I0901 13:45:31.840183 916722 sgd_solver.cpp:106] Iteration 4584500, lr = 0.01
I0901 13:46:01.562525 916722 solver.cpp:218] Iteration 4585000 (16.8223 iter/s, 29.7224s/500 iters), loss = 0.182369
I0901 13:46:01.562582 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.18237 (* 1 = 0.18237 loss)
I0901 13:46:01.562589 916722 sgd_solver.cpp:106] Iteration 4585000, lr = 0.01
I0901 13:46:31.285303 916722 solver.cpp:218] Iteration 4585500 (16.8221 iter/s, 29.7227s/500 iters), loss = 0.206407
I0901 13:46:31.285357 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.206408 (* 1 = 0.206408 loss)
I0901 13:46:31.285367 916722 sgd_solver.cpp:106] Iteration 4585500, lr = 0.01
I0901 13:47:01.008440 916722 solver.cpp:218] Iteration 4586000 (16.8219 iter/s, 29.7231s/500 iters), loss = 0.10428
I0901 13:47:01.008497 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104281 (* 1 = 0.104281 loss)
I0901 13:47:01.008505 916722 sgd_solver.cpp:106] Iteration 4586000, lr = 0.01
I0901 13:47:30.734829 916722 solver.cpp:218] Iteration 4586500 (16.8201 iter/s, 29.7264s/500 iters), loss = 0.0454461
I0901 13:47:30.734886 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0454475 (* 1 = 0.0454475 loss)
I0901 13:47:30.734896 916722 sgd_solver.cpp:106] Iteration 4586500, lr = 0.01
I0901 13:48:00.457412 916722 solver.cpp:218] Iteration 4587000 (16.8222 iter/s, 29.7225s/500 iters), loss = 0.167787
I0901 13:48:00.457471 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.167789 (* 1 = 0.167789 loss)
I0901 13:48:00.457479 916722 sgd_solver.cpp:106] Iteration 4587000, lr = 0.01
I0901 13:48:30.180917 916722 solver.cpp:218] Iteration 4587500 (16.8217 iter/s, 29.7235s/500 iters), loss = 0.220629
I0901 13:48:30.180971 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.220631 (* 1 = 0.220631 loss)
I0901 13:48:30.180981 916722 sgd_solver.cpp:106] Iteration 4587500, lr = 0.01
I0901 13:48:59.902901 916722 solver.cpp:218] Iteration 4588000 (16.8226 iter/s, 29.7219s/500 iters), loss = 0.033186
I0901 13:48:59.902958 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0331872 (* 1 = 0.0331872 loss)
I0901 13:48:59.902966 916722 sgd_solver.cpp:106] Iteration 4588000, lr = 0.01
I0901 13:49:29.623739 916722 solver.cpp:218] Iteration 4588500 (16.8232 iter/s, 29.7208s/500 iters), loss = 0.0392508
I0901 13:49:29.623790 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0392521 (* 1 = 0.0392521 loss)
I0901 13:49:29.623800 916722 sgd_solver.cpp:106] Iteration 4588500, lr = 0.01
I0901 13:49:59.346571 916722 solver.cpp:218] Iteration 4589000 (16.8221 iter/s, 29.7228s/500 iters), loss = 0.146507
I0901 13:49:59.346626 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.146508 (* 1 = 0.146508 loss)
I0901 13:49:59.346634 916722 sgd_solver.cpp:106] Iteration 4589000, lr = 0.01
I0901 13:50:29.067442 916722 solver.cpp:218] Iteration 4589500 (16.8232 iter/s, 29.7208s/500 iters), loss = 0.145526
I0901 13:50:29.067497 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.145527 (* 1 = 0.145527 loss)
I0901 13:50:29.067507 916722 sgd_solver.cpp:106] Iteration 4589500, lr = 0.01
I0901 13:50:58.790199 916722 solver.cpp:218] Iteration 4590000 (16.8222 iter/s, 29.7227s/500 iters), loss = 0.0714619
I0901 13:50:58.790259 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0714631 (* 1 = 0.0714631 loss)
I0901 13:50:58.790268 916722 sgd_solver.cpp:106] Iteration 4590000, lr = 0.01
I0901 13:51:28.511500 916722 solver.cpp:218] Iteration 4590500 (16.823 iter/s, 29.7213s/500 iters), loss = 0.137641
I0901 13:51:28.511566 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.137642 (* 1 = 0.137642 loss)
I0901 13:51:28.511576 916722 sgd_solver.cpp:106] Iteration 4590500, lr = 0.01
I0901 13:51:58.233233 916722 solver.cpp:218] Iteration 4591000 (16.8227 iter/s, 29.7217s/500 iters), loss = 0.335327
I0901 13:51:58.233307 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.335328 (* 1 = 0.335328 loss)
I0901 13:51:58.233316 916722 sgd_solver.cpp:106] Iteration 4591000, lr = 0.01
I0901 13:52:27.951799 916722 solver.cpp:218] Iteration 4591500 (16.8245 iter/s, 29.7185s/500 iters), loss = 0.114746
I0901 13:52:27.951849 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.114748 (* 1 = 0.114748 loss)
I0901 13:52:27.951858 916722 sgd_solver.cpp:106] Iteration 4591500, lr = 0.01
I0901 13:52:57.672169 916722 solver.cpp:218] Iteration 4592000 (16.8235 iter/s, 29.7203s/500 iters), loss = 0.0366873
I0901 13:52:57.672230 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0366887 (* 1 = 0.0366887 loss)
I0901 13:52:57.672237 916722 sgd_solver.cpp:106] Iteration 4592000, lr = 0.01
I0901 13:53:27.394155 916722 solver.cpp:218] Iteration 4592500 (16.8226 iter/s, 29.7219s/500 iters), loss = 0.10432
I0901 13:53:27.394207 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104322 (* 1 = 0.104322 loss)
I0901 13:53:27.394217 916722 sgd_solver.cpp:106] Iteration 4592500, lr = 0.01
I0901 13:53:57.115057 916722 solver.cpp:218] Iteration 4593000 (16.8232 iter/s, 29.7208s/500 iters), loss = 0.132233
I0901 13:53:57.115111 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.132235 (* 1 = 0.132235 loss)
I0901 13:53:57.115120 916722 sgd_solver.cpp:106] Iteration 4593000, lr = 0.01
I0901 13:54:26.839146 916722 solver.cpp:218] Iteration 4593500 (16.8214 iter/s, 29.724s/500 iters), loss = 0.0852478
I0901 13:54:26.839197 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0852494 (* 1 = 0.0852494 loss)
I0901 13:54:26.839207 916722 sgd_solver.cpp:106] Iteration 4593500, lr = 0.01
I0901 13:54:56.559119 916722 solver.cpp:218] Iteration 4594000 (16.8237 iter/s, 29.7199s/500 iters), loss = 0.187725
I0901 13:54:56.559181 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.187727 (* 1 = 0.187727 loss)
I0901 13:54:56.559190 916722 sgd_solver.cpp:106] Iteration 4594000, lr = 0.01
I0901 13:55:26.275777 916722 solver.cpp:218] Iteration 4594500 (16.8256 iter/s, 29.7166s/500 iters), loss = 0.0722245
I0901 13:55:26.275831 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0722259 (* 1 = 0.0722259 loss)
I0901 13:55:26.275841 916722 sgd_solver.cpp:106] Iteration 4594500, lr = 0.01
I0901 13:55:55.993723 916722 solver.cpp:218] Iteration 4595000 (16.8249 iter/s, 29.7179s/500 iters), loss = 0.171296
I0901 13:55:55.993783 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.171298 (* 1 = 0.171298 loss)
I0901 13:55:55.993793 916722 sgd_solver.cpp:106] Iteration 4595000, lr = 0.01
I0901 13:56:25.716142 916722 solver.cpp:218] Iteration 4595500 (16.8224 iter/s, 29.7224s/500 iters), loss = 0.211496
I0901 13:56:25.716194 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.211498 (* 1 = 0.211498 loss)
I0901 13:56:25.716204 916722 sgd_solver.cpp:106] Iteration 4595500, lr = 0.01
I0901 13:56:55.436089 916722 solver.cpp:218] Iteration 4596000 (16.8238 iter/s, 29.7199s/500 iters), loss = 0.0391552
I0901 13:56:55.436153 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0391569 (* 1 = 0.0391569 loss)
I0901 13:56:55.436161 916722 sgd_solver.cpp:106] Iteration 4596000, lr = 0.01
I0901 13:57:25.159818 916722 solver.cpp:218] Iteration 4596500 (16.8219 iter/s, 29.7231s/500 iters), loss = 0.23632
I0901 13:57:25.159871 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.236321 (* 1 = 0.236321 loss)
I0901 13:57:25.159880 916722 sgd_solver.cpp:106] Iteration 4596500, lr = 0.01
I0901 13:57:54.884611 916722 solver.cpp:218] Iteration 4597000 (16.8215 iter/s, 29.7239s/500 iters), loss = 0.15249
I0901 13:57:54.884685 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152492 (* 1 = 0.152492 loss)
I0901 13:57:54.884694 916722 sgd_solver.cpp:106] Iteration 4597000, lr = 0.01
I0901 13:58:24.608258 916722 solver.cpp:218] Iteration 4597500 (16.8221 iter/s, 29.7227s/500 iters), loss = 0.14024
I0901 13:58:24.608309 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.140242 (* 1 = 0.140242 loss)
I0901 13:58:24.608317 916722 sgd_solver.cpp:106] Iteration 4597500, lr = 0.01
I0901 13:58:54.331102 916722 solver.cpp:218] Iteration 4598000 (16.8225 iter/s, 29.722s/500 iters), loss = 0.262852
I0901 13:58:54.331156 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.262854 (* 1 = 0.262854 loss)
I0901 13:58:54.331164 916722 sgd_solver.cpp:106] Iteration 4598000, lr = 0.01
I0901 13:59:24.052206 916722 solver.cpp:218] Iteration 4598500 (16.8235 iter/s, 29.7203s/500 iters), loss = 0.148676
I0901 13:59:24.052260 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.148677 (* 1 = 0.148677 loss)
I0901 13:59:24.052268 916722 sgd_solver.cpp:106] Iteration 4598500, lr = 0.01
I0901 13:59:53.774384 916722 solver.cpp:218] Iteration 4599000 (16.8229 iter/s, 29.7214s/500 iters), loss = 0.0735636
I0901 13:59:53.774446 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0735651 (* 1 = 0.0735651 loss)
I0901 13:59:53.774454 916722 sgd_solver.cpp:106] Iteration 4599000, lr = 0.01
I0901 14:00:23.498646 916722 solver.cpp:218] Iteration 4599500 (16.8217 iter/s, 29.7235s/500 iters), loss = 0.355697
I0901 14:00:23.498697 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.355698 (* 1 = 0.355698 loss)
I0901 14:00:23.498706 916722 sgd_solver.cpp:106] Iteration 4599500, lr = 0.01
I0901 14:00:53.162853 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_4600000.caffemodel
I0901 14:00:53.181927 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_4600000.solverstate
I0901 14:00:53.187924 916722 solver.cpp:330] Iteration 4600000, Testing net (#0)
I0901 14:01:08.568338 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8453
I0901 14:01:08.568382 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.561539 (* 1 = 0.561539 loss)
I0901 14:01:08.627071 916722 solver.cpp:218] Iteration 4600000 (11.0797 iter/s, 45.1274s/500 iters), loss = 0.0474531
I0901 14:01:08.627101 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0474547 (* 1 = 0.0474547 loss)
I0901 14:01:08.627110 916722 sgd_solver.cpp:106] Iteration 4600000, lr = 0.01
I0901 14:01:38.380172 916722 solver.cpp:218] Iteration 4600500 (16.8053 iter/s, 29.7524s/500 iters), loss = 0.352403
I0901 14:01:38.380236 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.352405 (* 1 = 0.352405 loss)
I0901 14:01:38.380245 916722 sgd_solver.cpp:106] Iteration 4600500, lr = 0.01
I0901 14:02:08.132736 916722 solver.cpp:218] Iteration 4601000 (16.8056 iter/s, 29.7519s/500 iters), loss = 0.119355
I0901 14:02:08.132800 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.119357 (* 1 = 0.119357 loss)
I0901 14:02:08.132809 916722 sgd_solver.cpp:106] Iteration 4601000, lr = 0.01
I0901 14:02:37.888681 916722 solver.cpp:218] Iteration 4601500 (16.8037 iter/s, 29.7553s/500 iters), loss = 0.336809
I0901 14:02:37.888756 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.336811 (* 1 = 0.336811 loss)
I0901 14:02:37.888764 916722 sgd_solver.cpp:106] Iteration 4601500, lr = 0.01
I0901 14:03:07.644169 916722 solver.cpp:218] Iteration 4602000 (16.804 iter/s, 29.7549s/500 iters), loss = 0.226071
I0901 14:03:07.644222 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.226073 (* 1 = 0.226073 loss)
I0901 14:03:07.644230 916722 sgd_solver.cpp:106] Iteration 4602000, lr = 0.01
I0901 14:03:37.404563 916722 solver.cpp:218] Iteration 4602500 (16.8012 iter/s, 29.7598s/500 iters), loss = 0.0477283
I0901 14:03:37.404625 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0477298 (* 1 = 0.0477298 loss)
I0901 14:03:37.404637 916722 sgd_solver.cpp:106] Iteration 4602500, lr = 0.01
I0901 14:04:07.169055 916722 solver.cpp:218] Iteration 4603000 (16.7988 iter/s, 29.7639s/500 iters), loss = 0.0618189
I0901 14:04:07.169109 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0618203 (* 1 = 0.0618203 loss)
I0901 14:04:07.169118 916722 sgd_solver.cpp:106] Iteration 4603000, lr = 0.01
I0901 14:04:36.938305 916722 solver.cpp:218] Iteration 4603500 (16.7961 iter/s, 29.7687s/500 iters), loss = 0.348161
I0901 14:04:36.938364 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.348163 (* 1 = 0.348163 loss)
I0901 14:04:36.938372 916722 sgd_solver.cpp:106] Iteration 4603500, lr = 0.01
I0901 14:05:06.703872 916722 solver.cpp:218] Iteration 4604000 (16.7982 iter/s, 29.7651s/500 iters), loss = 0.137385
I0901 14:05:06.703925 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.137386 (* 1 = 0.137386 loss)
I0901 14:05:06.703934 916722 sgd_solver.cpp:106] Iteration 4604000, lr = 0.01
I0901 14:05:36.472641 916722 solver.cpp:218] Iteration 4604500 (16.7964 iter/s, 29.7683s/500 iters), loss = 0.138254
I0901 14:05:36.472699 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.138255 (* 1 = 0.138255 loss)
I0901 14:05:36.472708 916722 sgd_solver.cpp:106] Iteration 4604500, lr = 0.01
I0901 14:06:06.237169 916722 solver.cpp:218] Iteration 4605000 (16.7988 iter/s, 29.7641s/500 iters), loss = 0.211976
I0901 14:06:06.237222 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.211978 (* 1 = 0.211978 loss)
I0901 14:06:06.237233 916722 sgd_solver.cpp:106] Iteration 4605000, lr = 0.01
I0901 14:06:36.001109 916722 solver.cpp:218] Iteration 4605500 (16.7991 iter/s, 29.7635s/500 iters), loss = 0.159193
I0901 14:06:36.001171 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159195 (* 1 = 0.159195 loss)
I0901 14:06:36.001180 916722 sgd_solver.cpp:106] Iteration 4605500, lr = 0.01
I0901 14:07:05.764873 916722 solver.cpp:218] Iteration 4606000 (16.7992 iter/s, 29.7633s/500 iters), loss = 0.295459
I0901 14:07:05.764926 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.295461 (* 1 = 0.295461 loss)
I0901 14:07:05.764937 916722 sgd_solver.cpp:106] Iteration 4606000, lr = 0.01
I0901 14:07:35.524271 916722 solver.cpp:218] Iteration 4606500 (16.8016 iter/s, 29.759s/500 iters), loss = 0.089608
I0901 14:07:35.524333 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0896096 (* 1 = 0.0896096 loss)
I0901 14:07:35.524340 916722 sgd_solver.cpp:106] Iteration 4606500, lr = 0.01
I0901 14:08:05.290555 916722 solver.cpp:218] Iteration 4607000 (16.7978 iter/s, 29.7659s/500 iters), loss = 0.180619
I0901 14:08:05.290607 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.18062 (* 1 = 0.18062 loss)
I0901 14:08:05.290617 916722 sgd_solver.cpp:106] Iteration 4607000, lr = 0.01
I0901 14:08:35.053014 916722 solver.cpp:218] Iteration 4607500 (16.7999 iter/s, 29.7621s/500 iters), loss = 0.228439
I0901 14:08:35.053076 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.228441 (* 1 = 0.228441 loss)
I0901 14:08:35.053084 916722 sgd_solver.cpp:106] Iteration 4607500, lr = 0.01
I0901 14:09:04.812120 916722 solver.cpp:218] Iteration 4608000 (16.8018 iter/s, 29.7587s/500 iters), loss = 0.0272805
I0901 14:09:04.812172 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0272821 (* 1 = 0.0272821 loss)
I0901 14:09:04.812183 916722 sgd_solver.cpp:106] Iteration 4608000, lr = 0.01
I0901 14:09:34.575212 916722 solver.cpp:218] Iteration 4608500 (16.7995 iter/s, 29.7627s/500 iters), loss = 0.113751
I0901 14:09:34.575275 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.113752 (* 1 = 0.113752 loss)
I0901 14:09:34.575284 916722 sgd_solver.cpp:106] Iteration 4608500, lr = 0.01
I0901 14:10:04.339555 916722 solver.cpp:218] Iteration 4609000 (16.7988 iter/s, 29.764s/500 iters), loss = 0.190164
I0901 14:10:04.339605 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.190165 (* 1 = 0.190165 loss)
I0901 14:10:04.339615 916722 sgd_solver.cpp:106] Iteration 4609000, lr = 0.01
I0901 14:10:34.103636 916722 solver.cpp:218] Iteration 4609500 (16.799 iter/s, 29.7637s/500 iters), loss = 0.0866454
I0901 14:10:34.103709 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0866473 (* 1 = 0.0866473 loss)
I0901 14:10:34.103718 916722 sgd_solver.cpp:106] Iteration 4609500, lr = 0.01
I0901 14:11:03.868247 916722 solver.cpp:218] Iteration 4610000 (16.7987 iter/s, 29.7643s/500 iters), loss = 0.128412
I0901 14:11:03.868299 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128414 (* 1 = 0.128414 loss)
I0901 14:11:03.868309 916722 sgd_solver.cpp:106] Iteration 4610000, lr = 0.01
I0901 14:11:33.630395 916722 solver.cpp:218] Iteration 4610500 (16.8 iter/s, 29.7618s/500 iters), loss = 0.0968298
I0901 14:11:33.630462 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0968317 (* 1 = 0.0968317 loss)
I0901 14:11:33.630470 916722 sgd_solver.cpp:106] Iteration 4610500, lr = 0.01
I0901 14:12:03.394112 916722 solver.cpp:218] Iteration 4611000 (16.7992 iter/s, 29.7634s/500 iters), loss = 0.170579
I0901 14:12:03.394165 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.170581 (* 1 = 0.170581 loss)
I0901 14:12:03.394172 916722 sgd_solver.cpp:106] Iteration 4611000, lr = 0.01
I0901 14:12:33.170007 916722 solver.cpp:218] Iteration 4611500 (16.7923 iter/s, 29.7756s/500 iters), loss = 0.101416
I0901 14:12:33.170071 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101418 (* 1 = 0.101418 loss)
I0901 14:12:33.170079 916722 sgd_solver.cpp:106] Iteration 4611500, lr = 0.01
I0901 14:13:02.934407 916722 solver.cpp:218] Iteration 4612000 (16.7988 iter/s, 29.7641s/500 iters), loss = 0.295967
I0901 14:13:02.934459 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.295968 (* 1 = 0.295968 loss)
I0901 14:13:02.934468 916722 sgd_solver.cpp:106] Iteration 4612000, lr = 0.01
I0901 14:13:32.699596 916722 solver.cpp:218] Iteration 4612500 (16.7983 iter/s, 29.7649s/500 iters), loss = 0.268099
I0901 14:13:32.699656 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.268101 (* 1 = 0.268101 loss)
I0901 14:13:32.699664 916722 sgd_solver.cpp:106] Iteration 4612500, lr = 0.01
I0901 14:14:02.463644 916722 solver.cpp:218] Iteration 4613000 (16.799 iter/s, 29.7638s/500 iters), loss = 0.125606
I0901 14:14:02.463696 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.125608 (* 1 = 0.125608 loss)
I0901 14:14:02.463706 916722 sgd_solver.cpp:106] Iteration 4613000, lr = 0.01
I0901 14:14:32.227568 916722 solver.cpp:218] Iteration 4613500 (16.799 iter/s, 29.7637s/500 iters), loss = 0.0311034
I0901 14:14:32.227640 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0311052 (* 1 = 0.0311052 loss)
I0901 14:14:32.227649 916722 sgd_solver.cpp:106] Iteration 4613500, lr = 0.01
I0901 14:15:01.991050 916722 solver.cpp:218] Iteration 4614000 (16.7993 iter/s, 29.7632s/500 iters), loss = 0.225825
I0901 14:15:01.991102 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.225827 (* 1 = 0.225827 loss)
I0901 14:15:01.991111 916722 sgd_solver.cpp:106] Iteration 4614000, lr = 0.01
I0901 14:15:31.760231 916722 solver.cpp:218] Iteration 4614500 (16.796 iter/s, 29.7689s/500 iters), loss = 0.121284
I0901 14:15:31.760291 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.121285 (* 1 = 0.121285 loss)
I0901 14:15:31.760300 916722 sgd_solver.cpp:106] Iteration 4614500, lr = 0.01
I0901 14:16:01.526000 916722 solver.cpp:218] Iteration 4615000 (16.798 iter/s, 29.7655s/500 iters), loss = 0.0222459
I0901 14:16:01.526051 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0222475 (* 1 = 0.0222475 loss)
I0901 14:16:01.526059 916722 sgd_solver.cpp:106] Iteration 4615000, lr = 0.01
I0901 14:16:31.291033 916722 solver.cpp:218] Iteration 4615500 (16.7984 iter/s, 29.7648s/500 iters), loss = 0.282738
I0901 14:16:31.291095 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.282739 (* 1 = 0.282739 loss)
I0901 14:16:31.291102 916722 sgd_solver.cpp:106] Iteration 4615500, lr = 0.01
I0901 14:17:01.053354 916722 solver.cpp:218] Iteration 4616000 (16.7999 iter/s, 29.7621s/500 iters), loss = 0.10921
I0901 14:17:01.053406 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109212 (* 1 = 0.109212 loss)
I0901 14:17:01.053413 916722 sgd_solver.cpp:106] Iteration 4616000, lr = 0.01
I0901 14:17:30.819348 916722 solver.cpp:218] Iteration 4616500 (16.7978 iter/s, 29.7658s/500 iters), loss = 0.218294
I0901 14:17:30.819420 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.218296 (* 1 = 0.218296 loss)
I0901 14:17:30.819429 916722 sgd_solver.cpp:106] Iteration 4616500, lr = 0.01
I0901 14:18:00.584262 916722 solver.cpp:218] Iteration 4617000 (16.7984 iter/s, 29.7647s/500 iters), loss = 0.139444
I0901 14:18:00.584317 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139445 (* 1 = 0.139445 loss)
I0901 14:18:00.584327 916722 sgd_solver.cpp:106] Iteration 4617000, lr = 0.01
I0901 14:18:30.349901 916722 solver.cpp:218] Iteration 4617500 (16.798 iter/s, 29.7654s/500 iters), loss = 0.243272
I0901 14:18:30.349959 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.243274 (* 1 = 0.243274 loss)
I0901 14:18:30.349967 916722 sgd_solver.cpp:106] Iteration 4617500, lr = 0.01
I0901 14:19:00.114194 916722 solver.cpp:218] Iteration 4618000 (16.7988 iter/s, 29.7641s/500 iters), loss = 0.0608536
I0901 14:19:00.114251 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0608552 (* 1 = 0.0608552 loss)
I0901 14:19:00.114261 916722 sgd_solver.cpp:106] Iteration 4618000, lr = 0.01
I0901 14:19:29.883549 916722 solver.cpp:218] Iteration 4618500 (16.7959 iter/s, 29.7691s/500 iters), loss = 0.0983429
I0901 14:19:29.883610 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0983444 (* 1 = 0.0983444 loss)
I0901 14:19:29.883620 916722 sgd_solver.cpp:106] Iteration 4618500, lr = 0.01
I0901 14:19:59.645416 916722 solver.cpp:218] Iteration 4619000 (16.8002 iter/s, 29.7616s/500 iters), loss = 0.267513
I0901 14:19:59.645469 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.267515 (* 1 = 0.267515 loss)
I0901 14:19:59.645479 916722 sgd_solver.cpp:106] Iteration 4619000, lr = 0.01
I0901 14:20:29.411968 916722 solver.cpp:218] Iteration 4619500 (16.7975 iter/s, 29.7663s/500 iters), loss = 0.36289
I0901 14:20:29.412027 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.362892 (* 1 = 0.362892 loss)
I0901 14:20:29.412035 916722 sgd_solver.cpp:106] Iteration 4619500, lr = 0.01
I0901 14:20:59.171873 916722 solver.cpp:218] Iteration 4620000 (16.8013 iter/s, 29.7597s/500 iters), loss = 0.407724
I0901 14:20:59.171922 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.407725 (* 1 = 0.407725 loss)
I0901 14:20:59.171932 916722 sgd_solver.cpp:106] Iteration 4620000, lr = 0.01
I0901 14:21:28.932835 916722 solver.cpp:218] Iteration 4620500 (16.8007 iter/s, 29.7607s/500 iters), loss = 0.308759
I0901 14:21:28.932893 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.30876 (* 1 = 0.30876 loss)
I0901 14:21:28.932900 916722 sgd_solver.cpp:106] Iteration 4620500, lr = 0.01
I0901 14:21:58.694133 916722 solver.cpp:218] Iteration 4621000 (16.8005 iter/s, 29.7611s/500 iters), loss = 0.0668793
I0901 14:21:58.694190 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0668808 (* 1 = 0.0668808 loss)
I0901 14:21:58.694200 916722 sgd_solver.cpp:106] Iteration 4621000, lr = 0.01
I0901 14:22:28.458807 916722 solver.cpp:218] Iteration 4621500 (16.7986 iter/s, 29.7645s/500 iters), loss = 0.0258665
I0901 14:22:28.458873 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0258681 (* 1 = 0.0258681 loss)
I0901 14:22:28.458881 916722 sgd_solver.cpp:106] Iteration 4621500, lr = 0.01
I0901 14:22:58.221987 916722 solver.cpp:218] Iteration 4622000 (16.7994 iter/s, 29.763s/500 iters), loss = 0.108407
I0901 14:22:58.222041 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.108409 (* 1 = 0.108409 loss)
I0901 14:22:58.222051 916722 sgd_solver.cpp:106] Iteration 4622000, lr = 0.01
I0901 14:23:27.988056 916722 solver.cpp:218] Iteration 4622500 (16.7978 iter/s, 29.7659s/500 iters), loss = 0.0494003
I0901 14:23:27.988134 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.049402 (* 1 = 0.049402 loss)
I0901 14:23:27.988143 916722 sgd_solver.cpp:106] Iteration 4622500, lr = 0.01
I0901 14:23:57.752935 916722 solver.cpp:218] Iteration 4623000 (16.7985 iter/s, 29.7646s/500 iters), loss = 0.0163767
I0901 14:23:57.752990 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0163784 (* 1 = 0.0163784 loss)
I0901 14:23:57.753000 916722 sgd_solver.cpp:106] Iteration 4623000, lr = 0.01
I0901 14:24:27.518667 916722 solver.cpp:218] Iteration 4623500 (16.798 iter/s, 29.7655s/500 iters), loss = 0.0465821
I0901 14:24:27.518733 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0465836 (* 1 = 0.0465836 loss)
I0901 14:24:27.518741 916722 sgd_solver.cpp:106] Iteration 4623500, lr = 0.01
I0901 14:24:57.291404 916722 solver.cpp:218] Iteration 4624000 (16.794 iter/s, 29.7725s/500 iters), loss = 0.29317
I0901 14:24:57.291456 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.293171 (* 1 = 0.293171 loss)
I0901 14:24:57.291465 916722 sgd_solver.cpp:106] Iteration 4624000, lr = 0.01
I0901 14:25:27.065632 916722 solver.cpp:218] Iteration 4624500 (16.7932 iter/s, 29.774s/500 iters), loss = 0.131954
I0901 14:25:27.065690 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131955 (* 1 = 0.131955 loss)
I0901 14:25:27.065698 916722 sgd_solver.cpp:106] Iteration 4624500, lr = 0.01
I0901 14:25:56.844039 916722 solver.cpp:218] Iteration 4625000 (16.7908 iter/s, 29.7782s/500 iters), loss = 0.0609027
I0901 14:25:56.844089 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0609042 (* 1 = 0.0609042 loss)
I0901 14:25:56.844097 916722 sgd_solver.cpp:106] Iteration 4625000, lr = 0.01
I0901 14:26:26.621373 916722 solver.cpp:218] Iteration 4625500 (16.7914 iter/s, 29.7771s/500 iters), loss = 0.0620301
I0901 14:26:26.621435 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0620316 (* 1 = 0.0620316 loss)
I0901 14:26:26.621444 916722 sgd_solver.cpp:106] Iteration 4625500, lr = 0.01
I0901 14:26:56.397826 916722 solver.cpp:218] Iteration 4626000 (16.7919 iter/s, 29.7762s/500 iters), loss = 0.223102
I0901 14:26:56.397881 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.223104 (* 1 = 0.223104 loss)
I0901 14:26:56.397889 916722 sgd_solver.cpp:106] Iteration 4626000, lr = 0.01
I0901 14:27:26.176822 916722 solver.cpp:218] Iteration 4626500 (16.7905 iter/s, 29.7788s/500 iters), loss = 0.123503
I0901 14:27:26.176883 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.123505 (* 1 = 0.123505 loss)
I0901 14:27:26.176892 916722 sgd_solver.cpp:106] Iteration 4626500, lr = 0.01
I0901 14:27:55.951452 916722 solver.cpp:218] Iteration 4627000 (16.7929 iter/s, 29.7744s/500 iters), loss = 0.303007
I0901 14:27:55.951506 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.303009 (* 1 = 0.303009 loss)
I0901 14:27:55.951514 916722 sgd_solver.cpp:106] Iteration 4627000, lr = 0.01
I0901 14:28:25.729223 916722 solver.cpp:218] Iteration 4627500 (16.7912 iter/s, 29.7776s/500 iters), loss = 0.136627
I0901 14:28:25.729285 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.136628 (* 1 = 0.136628 loss)
I0901 14:28:25.729292 916722 sgd_solver.cpp:106] Iteration 4627500, lr = 0.01
I0901 14:28:55.505038 916722 solver.cpp:218] Iteration 4628000 (16.7923 iter/s, 29.7756s/500 iters), loss = 0.0462373
I0901 14:28:55.505095 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0462388 (* 1 = 0.0462388 loss)
I0901 14:28:55.505105 916722 sgd_solver.cpp:106] Iteration 4628000, lr = 0.01
I0901 14:29:25.281157 916722 solver.cpp:218] Iteration 4628500 (16.7921 iter/s, 29.7759s/500 iters), loss = 0.101034
I0901 14:29:25.281217 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101036 (* 1 = 0.101036 loss)
I0901 14:29:25.281225 916722 sgd_solver.cpp:106] Iteration 4628500, lr = 0.01
I0901 14:29:55.055274 916722 solver.cpp:218] Iteration 4629000 (16.7932 iter/s, 29.7739s/500 iters), loss = 0.293163
I0901 14:29:55.055335 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.293164 (* 1 = 0.293164 loss)
I0901 14:29:55.055346 916722 sgd_solver.cpp:106] Iteration 4629000, lr = 0.01
I0901 14:30:24.830124 916722 solver.cpp:218] Iteration 4629500 (16.7928 iter/s, 29.7747s/500 iters), loss = 0.0307293
I0901 14:30:24.830194 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0307308 (* 1 = 0.0307308 loss)
I0901 14:30:24.830204 916722 sgd_solver.cpp:106] Iteration 4629500, lr = 0.01
I0901 14:30:54.609107 916722 solver.cpp:218] Iteration 4630000 (16.7905 iter/s, 29.7788s/500 iters), loss = 0.139726
I0901 14:30:54.609160 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139727 (* 1 = 0.139727 loss)
I0901 14:30:54.609170 916722 sgd_solver.cpp:106] Iteration 4630000, lr = 0.01
I0901 14:31:24.381233 916722 solver.cpp:218] Iteration 4630500 (16.7943 iter/s, 29.772s/500 iters), loss = 0.113891
I0901 14:31:24.381292 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.113893 (* 1 = 0.113893 loss)
I0901 14:31:24.381301 916722 sgd_solver.cpp:106] Iteration 4630500, lr = 0.01
I0901 14:31:54.152576 916722 solver.cpp:218] Iteration 4631000 (16.7946 iter/s, 29.7714s/500 iters), loss = 0.0310752
I0901 14:31:54.152632 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0310766 (* 1 = 0.0310766 loss)
I0901 14:31:54.152642 916722 sgd_solver.cpp:106] Iteration 4631000, lr = 0.01
I0901 14:32:23.934099 916722 solver.cpp:218] Iteration 4631500 (16.7889 iter/s, 29.7816s/500 iters), loss = 0.103216
I0901 14:32:23.934162 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.103218 (* 1 = 0.103218 loss)
I0901 14:32:23.934170 916722 sgd_solver.cpp:106] Iteration 4631500, lr = 0.01
I0901 14:32:53.715121 916722 solver.cpp:218] Iteration 4632000 (16.7892 iter/s, 29.7811s/500 iters), loss = 0.133413
I0901 14:32:53.715175 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133414 (* 1 = 0.133414 loss)
I0901 14:32:53.715185 916722 sgd_solver.cpp:106] Iteration 4632000, lr = 0.01
I0901 14:33:23.489259 916722 solver.cpp:218] Iteration 4632500 (16.7931 iter/s, 29.7742s/500 iters), loss = 0.0622114
I0901 14:33:23.489318 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0622127 (* 1 = 0.0622127 loss)
I0901 14:33:23.489326 916722 sgd_solver.cpp:106] Iteration 4632500, lr = 0.01
I0901 14:33:53.267091 916722 solver.cpp:218] Iteration 4633000 (16.791 iter/s, 29.7779s/500 iters), loss = 0.130816
I0901 14:33:53.267144 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130818 (* 1 = 0.130818 loss)
I0901 14:33:53.267154 916722 sgd_solver.cpp:106] Iteration 4633000, lr = 0.01
I0901 14:34:23.049881 916722 solver.cpp:218] Iteration 4633500 (16.7882 iter/s, 29.7828s/500 iters), loss = 0.154731
I0901 14:34:23.049942 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.154733 (* 1 = 0.154733 loss)
I0901 14:34:23.049950 916722 sgd_solver.cpp:106] Iteration 4633500, lr = 0.01
I0901 14:34:52.820997 916722 solver.cpp:218] Iteration 4634000 (16.7948 iter/s, 29.7711s/500 iters), loss = 0.171507
I0901 14:34:52.821048 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.171509 (* 1 = 0.171509 loss)
I0901 14:34:52.821055 916722 sgd_solver.cpp:106] Iteration 4634000, lr = 0.01
I0901 14:35:22.599934 916722 solver.cpp:218] Iteration 4634500 (16.7904 iter/s, 29.7789s/500 iters), loss = 0.110089
I0901 14:35:22.599997 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110091 (* 1 = 0.110091 loss)
I0901 14:35:22.600005 916722 sgd_solver.cpp:106] Iteration 4634500, lr = 0.01
I0901 14:35:52.374609 916722 solver.cpp:218] Iteration 4635000 (16.7928 iter/s, 29.7747s/500 iters), loss = 0.198962
I0901 14:35:52.374662 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.198964 (* 1 = 0.198964 loss)
I0901 14:35:52.374671 916722 sgd_solver.cpp:106] Iteration 4635000, lr = 0.01
I0901 14:36:22.145460 916722 solver.cpp:218] Iteration 4635500 (16.795 iter/s, 29.7708s/500 iters), loss = 0.273486
I0901 14:36:22.145535 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.273487 (* 1 = 0.273487 loss)
I0901 14:36:22.145543 916722 sgd_solver.cpp:106] Iteration 4635500, lr = 0.01
I0901 14:36:51.923131 916722 solver.cpp:218] Iteration 4636000 (16.7911 iter/s, 29.7776s/500 iters), loss = 0.390938
I0901 14:36:51.923185 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.39094 (* 1 = 0.39094 loss)
I0901 14:36:51.923193 916722 sgd_solver.cpp:106] Iteration 4636000, lr = 0.01
I0901 14:37:21.700645 916722 solver.cpp:218] Iteration 4636500 (16.7912 iter/s, 29.7775s/500 iters), loss = 0.0823618
I0901 14:37:21.700709 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0823634 (* 1 = 0.0823634 loss)
I0901 14:37:21.700718 916722 sgd_solver.cpp:106] Iteration 4636500, lr = 0.01
I0901 14:37:51.479029 916722 solver.cpp:218] Iteration 4637000 (16.7907 iter/s, 29.7783s/500 iters), loss = 0.1251
I0901 14:37:51.479084 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.125102 (* 1 = 0.125102 loss)
I0901 14:37:51.479092 916722 sgd_solver.cpp:106] Iteration 4637000, lr = 0.01
I0901 14:38:21.252652 916722 solver.cpp:218] Iteration 4637500 (16.7934 iter/s, 29.7736s/500 iters), loss = 0.0618525
I0901 14:38:21.252714 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.061854 (* 1 = 0.061854 loss)
I0901 14:38:21.252724 916722 sgd_solver.cpp:106] Iteration 4637500, lr = 0.01
I0901 14:38:51.032630 916722 solver.cpp:218] Iteration 4638000 (16.7898 iter/s, 29.7799s/500 iters), loss = 0.0918675
I0901 14:38:51.032685 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0918689 (* 1 = 0.0918689 loss)
I0901 14:38:51.032694 916722 sgd_solver.cpp:106] Iteration 4638000, lr = 0.01
I0901 14:39:20.811292 916722 solver.cpp:218] Iteration 4638500 (16.7906 iter/s, 29.7786s/500 iters), loss = 0.142006
I0901 14:39:20.811349 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.142008 (* 1 = 0.142008 loss)
I0901 14:39:20.811357 916722 sgd_solver.cpp:106] Iteration 4638500, lr = 0.01
I0901 14:39:50.585490 916722 solver.cpp:218] Iteration 4639000 (16.7931 iter/s, 29.7741s/500 iters), loss = 0.167839
I0901 14:39:50.585544 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.16784 (* 1 = 0.16784 loss)
I0901 14:39:50.585553 916722 sgd_solver.cpp:106] Iteration 4639000, lr = 0.01
I0901 14:40:20.375504 916722 solver.cpp:218] Iteration 4639500 (16.7842 iter/s, 29.79s/500 iters), loss = 0.0985709
I0901 14:40:20.375564 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0985726 (* 1 = 0.0985726 loss)
I0901 14:40:20.375572 916722 sgd_solver.cpp:106] Iteration 4639500, lr = 0.01
I0901 14:40:50.151484 916722 solver.cpp:218] Iteration 4640000 (16.7921 iter/s, 29.7759s/500 iters), loss = 0.131716
I0901 14:40:50.151537 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131717 (* 1 = 0.131717 loss)
I0901 14:40:50.151546 916722 sgd_solver.cpp:106] Iteration 4640000, lr = 0.01
I0901 14:41:19.927386 916722 solver.cpp:218] Iteration 4640500 (16.7921 iter/s, 29.7758s/500 iters), loss = 0.0371991
I0901 14:41:19.927446 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0372008 (* 1 = 0.0372008 loss)
I0901 14:41:19.927455 916722 sgd_solver.cpp:106] Iteration 4640500, lr = 0.01
I0901 14:41:49.708768 916722 solver.cpp:218] Iteration 4641000 (16.7891 iter/s, 29.7813s/500 iters), loss = 0.0971246
I0901 14:41:49.708832 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0971263 (* 1 = 0.0971263 loss)
I0901 14:41:49.708842 916722 sgd_solver.cpp:106] Iteration 4641000, lr = 0.01
I0901 14:42:19.483301 916722 solver.cpp:218] Iteration 4641500 (16.7929 iter/s, 29.7744s/500 iters), loss = 0.107609
I0901 14:42:19.483362 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.10761 (* 1 = 0.10761 loss)
I0901 14:42:19.483371 916722 sgd_solver.cpp:106] Iteration 4641500, lr = 0.01
I0901 14:42:49.262737 916722 solver.cpp:218] Iteration 4642000 (16.7902 iter/s, 29.7793s/500 iters), loss = 0.0427908
I0901 14:42:49.262791 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0427924 (* 1 = 0.0427924 loss)
I0901 14:42:49.262811 916722 sgd_solver.cpp:106] Iteration 4642000, lr = 0.01
I0901 14:43:19.039680 916722 solver.cpp:218] Iteration 4642500 (16.7916 iter/s, 29.7769s/500 iters), loss = 0.125488
I0901 14:43:19.039750 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.125489 (* 1 = 0.125489 loss)
I0901 14:43:19.039759 916722 sgd_solver.cpp:106] Iteration 4642500, lr = 0.01
I0901 14:43:48.823165 916722 solver.cpp:218] Iteration 4643000 (16.7879 iter/s, 29.7834s/500 iters), loss = 0.270284
I0901 14:43:48.823215 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.270285 (* 1 = 0.270285 loss)
I0901 14:43:48.823225 916722 sgd_solver.cpp:106] Iteration 4643000, lr = 0.01
I0901 14:44:18.602440 916722 solver.cpp:218] Iteration 4643500 (16.7902 iter/s, 29.7792s/500 iters), loss = 0.190912
I0901 14:44:18.602502 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.190913 (* 1 = 0.190913 loss)
I0901 14:44:18.602510 916722 sgd_solver.cpp:106] Iteration 4643500, lr = 0.01
I0901 14:44:48.380861 916722 solver.cpp:218] Iteration 4644000 (16.7907 iter/s, 29.7783s/500 iters), loss = 0.173346
I0901 14:44:48.380914 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.173347 (* 1 = 0.173347 loss)
I0901 14:44:48.380923 916722 sgd_solver.cpp:106] Iteration 4644000, lr = 0.01
I0901 14:45:18.157552 916722 solver.cpp:218] Iteration 4644500 (16.7917 iter/s, 29.7766s/500 iters), loss = 0.250581
I0901 14:45:18.157614 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.250582 (* 1 = 0.250582 loss)
I0901 14:45:18.157624 916722 sgd_solver.cpp:106] Iteration 4644500, lr = 0.01
I0901 14:45:47.932739 916722 solver.cpp:218] Iteration 4645000 (16.7926 iter/s, 29.7751s/500 iters), loss = 0.11588
I0901 14:45:47.932792 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115881 (* 1 = 0.115881 loss)
I0901 14:45:47.932801 916722 sgd_solver.cpp:106] Iteration 4645000, lr = 0.01
I0901 14:46:17.715708 916722 solver.cpp:218] Iteration 4645500 (16.7882 iter/s, 29.7829s/500 iters), loss = 0.181192
I0901 14:46:17.715770 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.181193 (* 1 = 0.181193 loss)
I0901 14:46:17.715780 916722 sgd_solver.cpp:106] Iteration 4645500, lr = 0.01
I0901 14:46:47.492496 916722 solver.cpp:218] Iteration 4646000 (16.7917 iter/s, 29.7767s/500 iters), loss = 0.239971
I0901 14:46:47.492553 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.239972 (* 1 = 0.239972 loss)
I0901 14:46:47.492563 916722 sgd_solver.cpp:106] Iteration 4646000, lr = 0.01
I0901 14:47:17.269619 916722 solver.cpp:218] Iteration 4646500 (16.7915 iter/s, 29.777s/500 iters), loss = 0.0167697
I0901 14:47:17.269678 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.016771 (* 1 = 0.016771 loss)
I0901 14:47:17.269687 916722 sgd_solver.cpp:106] Iteration 4646500, lr = 0.01
I0901 14:47:47.049093 916722 solver.cpp:218] Iteration 4647000 (16.7901 iter/s, 29.7794s/500 iters), loss = 0.0469614
I0901 14:47:47.049144 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0469627 (* 1 = 0.0469627 loss)
I0901 14:47:47.049154 916722 sgd_solver.cpp:106] Iteration 4647000, lr = 0.01
I0901 14:48:16.839825 916722 solver.cpp:218] Iteration 4647500 (16.7838 iter/s, 29.7906s/500 iters), loss = 0.0279277
I0901 14:48:16.839881 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0279289 (* 1 = 0.0279289 loss)
I0901 14:48:16.839890 916722 sgd_solver.cpp:106] Iteration 4647500, lr = 0.01
I0901 14:48:46.615440 916722 solver.cpp:218] Iteration 4648000 (16.7923 iter/s, 29.7755s/500 iters), loss = 0.0448176
I0901 14:48:46.615496 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0448188 (* 1 = 0.0448188 loss)
I0901 14:48:46.615507 916722 sgd_solver.cpp:106] Iteration 4648000, lr = 0.01
I0901 14:49:16.393050 916722 solver.cpp:218] Iteration 4648500 (16.7912 iter/s, 29.7775s/500 iters), loss = 0.124338
I0901 14:49:16.393124 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.124339 (* 1 = 0.124339 loss)
I0901 14:49:16.393137 916722 sgd_solver.cpp:106] Iteration 4648500, lr = 0.01
I0901 14:49:46.168606 916722 solver.cpp:218] Iteration 4649000 (16.7924 iter/s, 29.7754s/500 iters), loss = 0.278776
I0901 14:49:46.168660 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.278777 (* 1 = 0.278777 loss)
I0901 14:49:46.168671 916722 sgd_solver.cpp:106] Iteration 4649000, lr = 0.01
I0901 14:50:15.947708 916722 solver.cpp:218] Iteration 4649500 (16.7904 iter/s, 29.779s/500 iters), loss = 0.326284
I0901 14:50:15.947768 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.326285 (* 1 = 0.326285 loss)
I0901 14:50:15.947777 916722 sgd_solver.cpp:106] Iteration 4649500, lr = 0.01
I0901 14:50:45.661478 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_4650000.caffemodel
I0901 14:50:45.680698 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_4650000.solverstate
I0901 14:50:45.686782 916722 solver.cpp:330] Iteration 4650000, Testing net (#0)
I0901 14:51:01.100842 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8939
I0901 14:51:01.100890 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.344186 (* 1 = 0.344186 loss)
I0901 14:51:01.159505 916722 solver.cpp:218] Iteration 4650000 (11.0591 iter/s, 45.2116s/500 iters), loss = 0.340505
I0901 14:51:01.159533 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.340505 (* 1 = 0.340505 loss)
I0901 14:51:01.159541 916722 sgd_solver.cpp:106] Iteration 4650000, lr = 0.01
I0901 14:51:30.912554 916722 solver.cpp:218] Iteration 4650500 (16.8051 iter/s, 29.7529s/500 iters), loss = 0.122659
I0901 14:51:30.912611 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.12266 (* 1 = 0.12266 loss)
I0901 14:51:30.912621 916722 sgd_solver.cpp:106] Iteration 4650500, lr = 0.01
I0901 14:52:00.671293 916722 solver.cpp:218] Iteration 4651000 (16.8019 iter/s, 29.7586s/500 iters), loss = 0.0325093
I0901 14:52:00.671351 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0325102 (* 1 = 0.0325102 loss)
I0901 14:52:00.671360 916722 sgd_solver.cpp:106] Iteration 4651000, lr = 0.01
I0901 14:52:30.433952 916722 solver.cpp:218] Iteration 4651500 (16.7996 iter/s, 29.7625s/500 iters), loss = 0.132411
I0901 14:52:30.434006 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.132412 (* 1 = 0.132412 loss)
I0901 14:52:30.434017 916722 sgd_solver.cpp:106] Iteration 4651500, lr = 0.01
I0901 14:53:00.201110 916722 solver.cpp:218] Iteration 4652000 (16.7971 iter/s, 29.767s/500 iters), loss = 0.233744
I0901 14:53:00.201172 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.233745 (* 1 = 0.233745 loss)
I0901 14:53:00.201180 916722 sgd_solver.cpp:106] Iteration 4652000, lr = 0.01
I0901 14:53:29.964906 916722 solver.cpp:218] Iteration 4652500 (16.799 iter/s, 29.7637s/500 iters), loss = 0.138644
I0901 14:53:29.964960 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.138645 (* 1 = 0.138645 loss)
I0901 14:53:29.964972 916722 sgd_solver.cpp:106] Iteration 4652500, lr = 0.01
I0901 14:53:59.732230 916722 solver.cpp:218] Iteration 4653000 (16.797 iter/s, 29.7672s/500 iters), loss = 0.404545
I0901 14:53:59.732291 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.404546 (* 1 = 0.404546 loss)
I0901 14:53:59.732300 916722 sgd_solver.cpp:106] Iteration 4653000, lr = 0.01
I0901 14:54:29.498265 916722 solver.cpp:218] Iteration 4653500 (16.7977 iter/s, 29.7659s/500 iters), loss = 0.0854614
I0901 14:54:29.498319 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0854624 (* 1 = 0.0854624 loss)
I0901 14:54:29.498329 916722 sgd_solver.cpp:106] Iteration 4653500, lr = 0.01
I0901 14:54:59.264376 916722 solver.cpp:218] Iteration 4654000 (16.7977 iter/s, 29.766s/500 iters), loss = 0.222675
I0901 14:54:59.264484 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.222676 (* 1 = 0.222676 loss)
I0901 14:54:59.264494 916722 sgd_solver.cpp:106] Iteration 4654000, lr = 0.01
I0901 14:55:29.029712 916722 solver.cpp:218] Iteration 4654500 (16.7982 iter/s, 29.7652s/500 iters), loss = 0.0368429
I0901 14:55:29.029762 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.036844 (* 1 = 0.036844 loss)
I0901 14:55:29.029772 916722 sgd_solver.cpp:106] Iteration 4654500, lr = 0.01
I0901 14:55:58.796422 916722 solver.cpp:218] Iteration 4655000 (16.7974 iter/s, 29.7666s/500 iters), loss = 0.270309
I0901 14:55:58.796510 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.27031 (* 1 = 0.27031 loss)
I0901 14:55:58.796519 916722 sgd_solver.cpp:106] Iteration 4655000, lr = 0.01
I0901 14:56:28.563305 916722 solver.cpp:218] Iteration 4655500 (16.7973 iter/s, 29.7667s/500 iters), loss = 0.160062
I0901 14:56:28.563360 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.160063 (* 1 = 0.160063 loss)
I0901 14:56:28.563369 916722 sgd_solver.cpp:106] Iteration 4655500, lr = 0.01
I0901 14:56:58.329226 916722 solver.cpp:218] Iteration 4656000 (16.7978 iter/s, 29.7658s/500 iters), loss = 0.282073
I0901 14:56:58.329288 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.282073 (* 1 = 0.282073 loss)
I0901 14:56:58.329298 916722 sgd_solver.cpp:106] Iteration 4656000, lr = 0.01
I0901 14:57:28.098183 916722 solver.cpp:218] Iteration 4656500 (16.7961 iter/s, 29.7688s/500 iters), loss = 0.217658
I0901 14:57:28.098237 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.217659 (* 1 = 0.217659 loss)
I0901 14:57:28.098245 916722 sgd_solver.cpp:106] Iteration 4656500, lr = 0.01
I0901 14:57:57.860636 916722 solver.cpp:218] Iteration 4657000 (16.7998 iter/s, 29.7623s/500 iters), loss = 0.102286
I0901 14:57:57.860698 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.102287 (* 1 = 0.102287 loss)
I0901 14:57:57.860708 916722 sgd_solver.cpp:106] Iteration 4657000, lr = 0.01
I0901 14:58:27.625072 916722 solver.cpp:218] Iteration 4657500 (16.7987 iter/s, 29.7643s/500 iters), loss = 0.170047
I0901 14:58:27.625126 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.170048 (* 1 = 0.170048 loss)
I0901 14:58:27.625134 916722 sgd_solver.cpp:106] Iteration 4657500, lr = 0.01
I0901 14:58:57.392882 916722 solver.cpp:218] Iteration 4658000 (16.7967 iter/s, 29.7677s/500 iters), loss = 0.299996
I0901 14:58:57.392943 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.299996 (* 1 = 0.299996 loss)
I0901 14:58:57.392952 916722 sgd_solver.cpp:106] Iteration 4658000, lr = 0.01
I0901 14:59:27.160394 916722 solver.cpp:218] Iteration 4658500 (16.7969 iter/s, 29.7674s/500 iters), loss = 0.176697
I0901 14:59:27.160455 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.176698 (* 1 = 0.176698 loss)
I0901 14:59:27.160465 916722 sgd_solver.cpp:106] Iteration 4658500, lr = 0.01
I0901 14:59:56.926654 916722 solver.cpp:218] Iteration 4659000 (16.7976 iter/s, 29.7661s/500 iters), loss = 0.185601
I0901 14:59:56.926712 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.185602 (* 1 = 0.185602 loss)
I0901 14:59:56.926720 916722 sgd_solver.cpp:106] Iteration 4659000, lr = 0.01
I0901 15:00:26.696182 916722 solver.cpp:218] Iteration 4659500 (16.7958 iter/s, 29.7694s/500 iters), loss = 0.14561
I0901 15:00:26.696236 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.145611 (* 1 = 0.145611 loss)
I0901 15:00:26.696245 916722 sgd_solver.cpp:106] Iteration 4659500, lr = 0.01
I0901 15:00:56.468897 916722 solver.cpp:218] Iteration 4660000 (16.794 iter/s, 29.7726s/500 iters), loss = 0.0374425
I0901 15:00:56.468961 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0374429 (* 1 = 0.0374429 loss)
I0901 15:00:56.468969 916722 sgd_solver.cpp:106] Iteration 4660000, lr = 0.01
I0901 15:01:26.236785 916722 solver.cpp:218] Iteration 4660500 (16.7967 iter/s, 29.7677s/500 iters), loss = 0.174401
I0901 15:01:26.236843 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.174401 (* 1 = 0.174401 loss)
I0901 15:01:26.236853 916722 sgd_solver.cpp:106] Iteration 4660500, lr = 0.01
I0901 15:01:56.004737 916722 solver.cpp:218] Iteration 4661000 (16.7967 iter/s, 29.7678s/500 iters), loss = 0.260996
I0901 15:01:56.004827 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.260997 (* 1 = 0.260997 loss)
I0901 15:01:56.004846 916722 sgd_solver.cpp:106] Iteration 4661000, lr = 0.01
I0901 15:02:25.776757 916722 solver.cpp:218] Iteration 4661500 (16.7944 iter/s, 29.7719s/500 iters), loss = 0.0611873
I0901 15:02:25.776834 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0611874 (* 1 = 0.0611874 loss)
I0901 15:02:25.776844 916722 sgd_solver.cpp:106] Iteration 4661500, lr = 0.01
I0901 15:02:55.544200 916722 solver.cpp:218] Iteration 4662000 (16.797 iter/s, 29.7673s/500 iters), loss = 0.0329882
I0901 15:02:55.544261 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0329881 (* 1 = 0.0329881 loss)
I0901 15:02:55.544270 916722 sgd_solver.cpp:106] Iteration 4662000, lr = 0.01
I0901 15:03:25.308755 916722 solver.cpp:218] Iteration 4662500 (16.7986 iter/s, 29.7644s/500 iters), loss = 0.116288
I0901 15:03:25.308809 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.116288 (* 1 = 0.116288 loss)
I0901 15:03:25.308818 916722 sgd_solver.cpp:106] Iteration 4662500, lr = 0.01
I0901 15:03:55.077927 916722 solver.cpp:218] Iteration 4663000 (16.796 iter/s, 29.769s/500 iters), loss = 0.0350396
I0901 15:03:55.077984 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0350396 (* 1 = 0.0350396 loss)
I0901 15:03:55.077992 916722 sgd_solver.cpp:106] Iteration 4663000, lr = 0.01
I0901 15:04:24.844849 916722 solver.cpp:218] Iteration 4663500 (16.7972 iter/s, 29.7668s/500 iters), loss = 0.0650376
I0901 15:04:24.844900 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0650376 (* 1 = 0.0650376 loss)
I0901 15:04:24.844910 916722 sgd_solver.cpp:106] Iteration 4663500, lr = 0.01
I0901 15:04:54.610030 916722 solver.cpp:218] Iteration 4664000 (16.7982 iter/s, 29.765s/500 iters), loss = 0.139286
I0901 15:04:54.610090 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139286 (* 1 = 0.139286 loss)
I0901 15:04:54.610098 916722 sgd_solver.cpp:106] Iteration 4664000, lr = 0.01
I0901 15:05:24.377442 916722 solver.cpp:218] Iteration 4664500 (16.797 iter/s, 29.7673s/500 iters), loss = 0.169277
I0901 15:05:24.377492 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.169277 (* 1 = 0.169277 loss)
I0901 15:05:24.377502 916722 sgd_solver.cpp:106] Iteration 4664500, lr = 0.01
I0901 15:05:54.142999 916722 solver.cpp:218] Iteration 4665000 (16.798 iter/s, 29.7654s/500 iters), loss = 0.14812
I0901 15:05:54.143062 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.14812 (* 1 = 0.14812 loss)
I0901 15:05:54.143071 916722 sgd_solver.cpp:106] Iteration 4665000, lr = 0.01
I0901 15:06:23.904841 916722 solver.cpp:218] Iteration 4665500 (16.8001 iter/s, 29.7617s/500 iters), loss = 0.0940742
I0901 15:06:23.904893 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0940742 (* 1 = 0.0940742 loss)
I0901 15:06:23.904901 916722 sgd_solver.cpp:106] Iteration 4665500, lr = 0.01
I0901 15:06:53.668911 916722 solver.cpp:218] Iteration 4666000 (16.7989 iter/s, 29.7639s/500 iters), loss = 0.0262133
I0901 15:06:53.668973 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0262132 (* 1 = 0.0262132 loss)
I0901 15:06:53.668982 916722 sgd_solver.cpp:106] Iteration 4666000, lr = 0.01
I0901 15:07:23.431957 916722 solver.cpp:218] Iteration 4666500 (16.7995 iter/s, 29.7629s/500 iters), loss = 0.127851
I0901 15:07:23.432013 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.127851 (* 1 = 0.127851 loss)
I0901 15:07:23.432021 916722 sgd_solver.cpp:106] Iteration 4666500, lr = 0.01
I0901 15:07:53.193264 916722 solver.cpp:218] Iteration 4667000 (16.8004 iter/s, 29.7611s/500 iters), loss = 0.12242
I0901 15:07:53.193325 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.12242 (* 1 = 0.12242 loss)
I0901 15:07:53.193332 916722 sgd_solver.cpp:106] Iteration 4667000, lr = 0.01
I0901 15:08:22.958482 916722 solver.cpp:218] Iteration 4667500 (16.7982 iter/s, 29.765s/500 iters), loss = 0.0827706
I0901 15:08:22.958544 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0827707 (* 1 = 0.0827707 loss)
I0901 15:08:22.958552 916722 sgd_solver.cpp:106] Iteration 4667500, lr = 0.01
I0901 15:08:52.725917 916722 solver.cpp:218] Iteration 4668000 (16.797 iter/s, 29.7673s/500 iters), loss = 0.274335
I0901 15:08:52.725981 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.274335 (* 1 = 0.274335 loss)
I0901 15:08:52.725991 916722 sgd_solver.cpp:106] Iteration 4668000, lr = 0.01
I0901 15:09:22.488807 916722 solver.cpp:218] Iteration 4668500 (16.7995 iter/s, 29.7627s/500 iters), loss = 0.314841
I0901 15:09:22.488858 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.314841 (* 1 = 0.314841 loss)
I0901 15:09:22.488867 916722 sgd_solver.cpp:106] Iteration 4668500, lr = 0.01
I0901 15:09:52.255683 916722 solver.cpp:218] Iteration 4669000 (16.7973 iter/s, 29.7667s/500 iters), loss = 0.0474187
I0901 15:09:52.255746 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0474188 (* 1 = 0.0474188 loss)
I0901 15:09:52.255755 916722 sgd_solver.cpp:106] Iteration 4669000, lr = 0.01
I0901 15:10:22.023921 916722 solver.cpp:218] Iteration 4669500 (16.7965 iter/s, 29.7681s/500 iters), loss = 0.0654041
I0901 15:10:22.023977 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0654041 (* 1 = 0.0654041 loss)
I0901 15:10:22.023986 916722 sgd_solver.cpp:106] Iteration 4669500, lr = 0.01
I0901 15:10:51.790642 916722 solver.cpp:218] Iteration 4670000 (16.7974 iter/s, 29.7666s/500 iters), loss = 0.208971
I0901 15:10:51.790706 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.208971 (* 1 = 0.208971 loss)
I0901 15:10:51.790715 916722 sgd_solver.cpp:106] Iteration 4670000, lr = 0.01
I0901 15:11:21.560895 916722 solver.cpp:218] Iteration 4670500 (16.7954 iter/s, 29.7701s/500 iters), loss = 0.213637
I0901 15:11:21.560950 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.213637 (* 1 = 0.213637 loss)
I0901 15:11:21.560958 916722 sgd_solver.cpp:106] Iteration 4670500, lr = 0.01
I0901 15:11:51.333693 916722 solver.cpp:218] Iteration 4671000 (16.7939 iter/s, 29.7726s/500 iters), loss = 0.104454
I0901 15:11:51.333755 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104454 (* 1 = 0.104454 loss)
I0901 15:11:51.333763 916722 sgd_solver.cpp:106] Iteration 4671000, lr = 0.01
I0901 15:12:21.103955 916722 solver.cpp:218] Iteration 4671500 (16.7954 iter/s, 29.7701s/500 iters), loss = 0.108516
I0901 15:12:21.104009 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.108515 (* 1 = 0.108515 loss)
I0901 15:12:21.104018 916722 sgd_solver.cpp:106] Iteration 4671500, lr = 0.01
I0901 15:12:50.869879 916722 solver.cpp:218] Iteration 4672000 (16.7978 iter/s, 29.7658s/500 iters), loss = 0.011033
I0901 15:12:50.869937 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0110328 (* 1 = 0.0110328 loss)
I0901 15:12:50.869946 916722 sgd_solver.cpp:106] Iteration 4672000, lr = 0.01
I0901 15:13:20.636147 916722 solver.cpp:218] Iteration 4672500 (16.7976 iter/s, 29.7661s/500 iters), loss = 0.0666876
I0901 15:13:20.636205 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0666873 (* 1 = 0.0666873 loss)
I0901 15:13:20.636215 916722 sgd_solver.cpp:106] Iteration 4672500, lr = 0.01
I0901 15:13:50.403766 916722 solver.cpp:218] Iteration 4673000 (16.7969 iter/s, 29.7675s/500 iters), loss = 0.0715597
I0901 15:13:50.403825 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0715595 (* 1 = 0.0715595 loss)
I0901 15:13:50.403832 916722 sgd_solver.cpp:106] Iteration 4673000, lr = 0.01
I0901 15:14:20.166977 916722 solver.cpp:218] Iteration 4673500 (16.7994 iter/s, 29.7631s/500 iters), loss = 0.109684
I0901 15:14:20.167033 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109683 (* 1 = 0.109683 loss)
I0901 15:14:20.167042 916722 sgd_solver.cpp:106] Iteration 4673500, lr = 0.01
I0901 15:14:49.929553 916722 solver.cpp:218] Iteration 4674000 (16.7997 iter/s, 29.7624s/500 iters), loss = 0.0710141
I0901 15:14:49.929627 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0710138 (* 1 = 0.0710138 loss)
I0901 15:14:49.929641 916722 sgd_solver.cpp:106] Iteration 4674000, lr = 0.01
I0901 15:15:19.690621 916722 solver.cpp:218] Iteration 4674500 (16.8006 iter/s, 29.7609s/500 iters), loss = 0.00673451
I0901 15:15:19.690675 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.00673414 (* 1 = 0.00673414 loss)
I0901 15:15:19.690685 916722 sgd_solver.cpp:106] Iteration 4674500, lr = 0.01
I0901 15:15:49.454195 916722 solver.cpp:218] Iteration 4675000 (16.7991 iter/s, 29.7634s/500 iters), loss = 0.249786
I0901 15:15:49.454257 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.249785 (* 1 = 0.249785 loss)
I0901 15:15:49.454267 916722 sgd_solver.cpp:106] Iteration 4675000, lr = 0.01
I0901 15:16:19.226506 916722 solver.cpp:218] Iteration 4675500 (16.7942 iter/s, 29.7721s/500 iters), loss = 0.160519
I0901 15:16:19.226563 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.160518 (* 1 = 0.160518 loss)
I0901 15:16:19.226574 916722 sgd_solver.cpp:106] Iteration 4675500, lr = 0.01
I0901 15:16:48.991258 916722 solver.cpp:218] Iteration 4676000 (16.7985 iter/s, 29.7646s/500 iters), loss = 0.130455
I0901 15:16:48.991320 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130455 (* 1 = 0.130455 loss)
I0901 15:16:48.991328 916722 sgd_solver.cpp:106] Iteration 4676000, lr = 0.01
I0901 15:17:18.756963 916722 solver.cpp:218] Iteration 4676500 (16.7979 iter/s, 29.7655s/500 iters), loss = 0.115584
I0901 15:17:18.757019 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115584 (* 1 = 0.115584 loss)
I0901 15:17:18.757030 916722 sgd_solver.cpp:106] Iteration 4676500, lr = 0.01
I0901 15:17:48.522655 916722 solver.cpp:218] Iteration 4677000 (16.798 iter/s, 29.7655s/500 iters), loss = 0.150885
I0901 15:17:48.522717 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.150885 (* 1 = 0.150885 loss)
I0901 15:17:48.522725 916722 sgd_solver.cpp:106] Iteration 4677000, lr = 0.01
I0901 15:18:18.291373 916722 solver.cpp:218] Iteration 4677500 (16.7962 iter/s, 29.7686s/500 iters), loss = 0.159879
I0901 15:18:18.291424 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159879 (* 1 = 0.159879 loss)
I0901 15:18:18.291435 916722 sgd_solver.cpp:106] Iteration 4677500, lr = 0.01
I0901 15:18:48.065636 916722 solver.cpp:218] Iteration 4678000 (16.7931 iter/s, 29.7741s/500 iters), loss = 0.124017
I0901 15:18:48.065690 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.124016 (* 1 = 0.124016 loss)
I0901 15:18:48.065698 916722 sgd_solver.cpp:106] Iteration 4678000, lr = 0.01
I0901 15:19:17.827838 916722 solver.cpp:218] Iteration 4678500 (16.7999 iter/s, 29.7621s/500 iters), loss = 0.078239
I0901 15:19:17.827890 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0782383 (* 1 = 0.0782383 loss)
I0901 15:19:17.827900 916722 sgd_solver.cpp:106] Iteration 4678500, lr = 0.01
I0901 15:19:47.595299 916722 solver.cpp:218] Iteration 4679000 (16.7969 iter/s, 29.7673s/500 iters), loss = 0.0479496
I0901 15:19:47.595356 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0479489 (* 1 = 0.0479489 loss)
I0901 15:19:47.595364 916722 sgd_solver.cpp:106] Iteration 4679000, lr = 0.01
I0901 15:20:17.361624 916722 solver.cpp:218] Iteration 4679500 (16.7976 iter/s, 29.7662s/500 iters), loss = 0.268631
I0901 15:20:17.361680 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.26863 (* 1 = 0.26863 loss)
I0901 15:20:17.361690 916722 sgd_solver.cpp:106] Iteration 4679500, lr = 0.01
I0901 15:20:47.132596 916722 solver.cpp:218] Iteration 4680000 (16.795 iter/s, 29.7708s/500 iters), loss = 0.333808
I0901 15:20:47.132656 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.333807 (* 1 = 0.333807 loss)
I0901 15:20:47.132665 916722 sgd_solver.cpp:106] Iteration 4680000, lr = 0.01
I0901 15:21:16.901044 916722 solver.cpp:218] Iteration 4680500 (16.7964 iter/s, 29.7683s/500 iters), loss = 0.210504
I0901 15:21:16.901100 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.210503 (* 1 = 0.210503 loss)
I0901 15:21:16.901122 916722 sgd_solver.cpp:106] Iteration 4680500, lr = 0.01
I0901 15:21:46.671044 916722 solver.cpp:218] Iteration 4681000 (16.7955 iter/s, 29.7698s/500 iters), loss = 0.420017
I0901 15:21:46.671118 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.420016 (* 1 = 0.420016 loss)
I0901 15:21:46.671137 916722 sgd_solver.cpp:106] Iteration 4681000, lr = 0.01
I0901 15:22:16.438055 916722 solver.cpp:218] Iteration 4681500 (16.7972 iter/s, 29.7668s/500 iters), loss = 0.0701452
I0901 15:22:16.438109 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0701442 (* 1 = 0.0701442 loss)
I0901 15:22:16.438118 916722 sgd_solver.cpp:106] Iteration 4681500, lr = 0.01
I0901 15:22:46.204860 916722 solver.cpp:218] Iteration 4682000 (16.7973 iter/s, 29.7667s/500 iters), loss = 0.0593484
I0901 15:22:46.204933 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0593474 (* 1 = 0.0593474 loss)
I0901 15:22:46.204942 916722 sgd_solver.cpp:106] Iteration 4682000, lr = 0.01
I0901 15:23:15.976979 916722 solver.cpp:218] Iteration 4682500 (16.7943 iter/s, 29.772s/500 iters), loss = 0.326219
I0901 15:23:15.977032 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.326218 (* 1 = 0.326218 loss)
I0901 15:23:15.977041 916722 sgd_solver.cpp:106] Iteration 4682500, lr = 0.01
I0901 15:23:45.746208 916722 solver.cpp:218] Iteration 4683000 (16.7959 iter/s, 29.7691s/500 iters), loss = 0.0716858
I0901 15:23:45.746270 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0716849 (* 1 = 0.0716849 loss)
I0901 15:23:45.746279 916722 sgd_solver.cpp:106] Iteration 4683000, lr = 0.01
I0901 15:24:15.517855 916722 solver.cpp:218] Iteration 4683500 (16.7946 iter/s, 29.7715s/500 iters), loss = 0.0912403
I0901 15:24:15.517908 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0912394 (* 1 = 0.0912394 loss)
I0901 15:24:15.517916 916722 sgd_solver.cpp:106] Iteration 4683500, lr = 0.01
I0901 15:24:45.287004 916722 solver.cpp:218] Iteration 4684000 (16.796 iter/s, 29.769s/500 iters), loss = 0.0544533
I0901 15:24:45.287066 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0544525 (* 1 = 0.0544525 loss)
I0901 15:24:45.287075 916722 sgd_solver.cpp:106] Iteration 4684000, lr = 0.01
I0901 15:25:15.057680 916722 solver.cpp:218] Iteration 4684500 (16.7951 iter/s, 29.7705s/500 iters), loss = 0.0842025
I0901 15:25:15.057735 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0842017 (* 1 = 0.0842017 loss)
I0901 15:25:15.057744 916722 sgd_solver.cpp:106] Iteration 4684500, lr = 0.01
I0901 15:25:44.825438 916722 solver.cpp:218] Iteration 4685000 (16.7968 iter/s, 29.7676s/500 iters), loss = 0.0761319
I0901 15:25:44.825500 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0761313 (* 1 = 0.0761313 loss)
I0901 15:25:44.825508 916722 sgd_solver.cpp:106] Iteration 4685000, lr = 0.01
I0901 15:26:14.592983 916722 solver.cpp:218] Iteration 4685500 (16.7969 iter/s, 29.7674s/500 iters), loss = 0.233896
I0901 15:26:14.593039 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.233895 (* 1 = 0.233895 loss)
I0901 15:26:14.593048 916722 sgd_solver.cpp:106] Iteration 4685500, lr = 0.01
I0901 15:26:44.361263 916722 solver.cpp:218] Iteration 4686000 (16.7965 iter/s, 29.7681s/500 iters), loss = 0.0775847
I0901 15:26:44.361323 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0775842 (* 1 = 0.0775842 loss)
I0901 15:26:44.361332 916722 sgd_solver.cpp:106] Iteration 4686000, lr = 0.01
I0901 15:27:14.129053 916722 solver.cpp:218] Iteration 4686500 (16.7968 iter/s, 29.7676s/500 iters), loss = 0.234939
I0901 15:27:14.129110 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.234939 (* 1 = 0.234939 loss)
I0901 15:27:14.129122 916722 sgd_solver.cpp:106] Iteration 4686500, lr = 0.01
I0901 15:27:43.900384 916722 solver.cpp:218] Iteration 4687000 (16.7948 iter/s, 29.7712s/500 iters), loss = 0.179018
I0901 15:27:43.900470 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.179017 (* 1 = 0.179017 loss)
I0901 15:27:43.900485 916722 sgd_solver.cpp:106] Iteration 4687000, lr = 0.01
I0901 15:28:13.671043 916722 solver.cpp:218] Iteration 4687500 (16.7952 iter/s, 29.7705s/500 iters), loss = 0.0309356
I0901 15:28:13.671094 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0309353 (* 1 = 0.0309353 loss)
I0901 15:28:13.671105 916722 sgd_solver.cpp:106] Iteration 4687500, lr = 0.01
I0901 15:28:43.445264 916722 solver.cpp:218] Iteration 4688000 (16.7931 iter/s, 29.7741s/500 iters), loss = 0.0906574
I0901 15:28:43.445325 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0906569 (* 1 = 0.0906569 loss)
I0901 15:28:43.445333 916722 sgd_solver.cpp:106] Iteration 4688000, lr = 0.01
I0901 15:29:13.208671 916722 solver.cpp:218] Iteration 4688500 (16.7992 iter/s, 29.7633s/500 iters), loss = 0.0903889
I0901 15:29:13.208726 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0903884 (* 1 = 0.0903884 loss)
I0901 15:29:13.208737 916722 sgd_solver.cpp:106] Iteration 4688500, lr = 0.01
I0901 15:29:42.973143 916722 solver.cpp:218] Iteration 4689000 (16.7986 iter/s, 29.7643s/500 iters), loss = 0.158896
I0901 15:29:42.973204 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.158896 (* 1 = 0.158896 loss)
I0901 15:29:42.973212 916722 sgd_solver.cpp:106] Iteration 4689000, lr = 0.01
I0901 15:30:12.741096 916722 solver.cpp:218] Iteration 4689500 (16.7967 iter/s, 29.7678s/500 iters), loss = 0.164722
I0901 15:30:12.741150 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.164721 (* 1 = 0.164721 loss)
I0901 15:30:12.741160 916722 sgd_solver.cpp:106] Iteration 4689500, lr = 0.01
I0901 15:30:42.506099 916722 solver.cpp:218] Iteration 4690000 (16.7983 iter/s, 29.7649s/500 iters), loss = 0.230613
I0901 15:30:42.506158 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.230613 (* 1 = 0.230613 loss)
I0901 15:30:42.506166 916722 sgd_solver.cpp:106] Iteration 4690000, lr = 0.01
I0901 15:31:12.269562 916722 solver.cpp:218] Iteration 4690500 (16.7992 iter/s, 29.7633s/500 iters), loss = 0.387443
I0901 15:31:12.269616 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.387443 (* 1 = 0.387443 loss)
I0901 15:31:12.269627 916722 sgd_solver.cpp:106] Iteration 4690500, lr = 0.01
I0901 15:31:42.034814 916722 solver.cpp:218] Iteration 4691000 (16.7982 iter/s, 29.7651s/500 iters), loss = 0.35607
I0901 15:31:42.034873 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.356069 (* 1 = 0.356069 loss)
I0901 15:31:42.034881 916722 sgd_solver.cpp:106] Iteration 4691000, lr = 0.01
I0901 15:32:11.804173 916722 solver.cpp:218] Iteration 4691500 (16.7959 iter/s, 29.7692s/500 iters), loss = 0.0807544
I0901 15:32:11.804229 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.080754 (* 1 = 0.080754 loss)
I0901 15:32:11.804239 916722 sgd_solver.cpp:106] Iteration 4691500, lr = 0.01
I0901 15:32:41.570403 916722 solver.cpp:218] Iteration 4692000 (16.7976 iter/s, 29.7661s/500 iters), loss = 0.454333
I0901 15:32:41.570464 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.454333 (* 1 = 0.454333 loss)
I0901 15:32:41.570472 916722 sgd_solver.cpp:106] Iteration 4692000, lr = 0.01
I0901 15:33:11.339395 916722 solver.cpp:218] Iteration 4692500 (16.7961 iter/s, 29.7688s/500 iters), loss = 0.040147
I0901 15:33:11.339449 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0401468 (* 1 = 0.0401468 loss)
I0901 15:33:11.339457 916722 sgd_solver.cpp:106] Iteration 4692500, lr = 0.01
I0901 15:33:41.105376 916722 solver.cpp:218] Iteration 4693000 (16.7978 iter/s, 29.7658s/500 iters), loss = 0.258569
I0901 15:33:41.105437 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.258568 (* 1 = 0.258568 loss)
I0901 15:33:41.105445 916722 sgd_solver.cpp:106] Iteration 4693000, lr = 0.01
I0901 15:34:10.873723 916722 solver.cpp:218] Iteration 4693500 (16.7964 iter/s, 29.7682s/500 iters), loss = 0.406281
I0901 15:34:10.873778 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.40628 (* 1 = 0.40628 loss)
I0901 15:34:10.873787 916722 sgd_solver.cpp:106] Iteration 4693500, lr = 0.01
I0901 15:34:40.640830 916722 solver.cpp:218] Iteration 4694000 (16.7971 iter/s, 29.767s/500 iters), loss = 0.0977412
I0901 15:34:40.640902 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0977409 (* 1 = 0.0977409 loss)
I0901 15:34:40.640911 916722 sgd_solver.cpp:106] Iteration 4694000, lr = 0.01
I0901 15:35:10.408675 916722 solver.cpp:218] Iteration 4694500 (16.7967 iter/s, 29.7677s/500 iters), loss = 0.146135
I0901 15:35:10.408727 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.146134 (* 1 = 0.146134 loss)
I0901 15:35:10.408736 916722 sgd_solver.cpp:106] Iteration 4694500, lr = 0.01
I0901 15:35:40.174849 916722 solver.cpp:218] Iteration 4695000 (16.7977 iter/s, 29.766s/500 iters), loss = 0.227339
I0901 15:35:40.174908 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.227339 (* 1 = 0.227339 loss)
I0901 15:35:40.174917 916722 sgd_solver.cpp:106] Iteration 4695000, lr = 0.01
I0901 15:36:09.949741 916722 solver.cpp:218] Iteration 4695500 (16.7928 iter/s, 29.7748s/500 iters), loss = 0.074463
I0901 15:36:09.949795 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0744628 (* 1 = 0.0744628 loss)
I0901 15:36:09.949805 916722 sgd_solver.cpp:106] Iteration 4695500, lr = 0.01
I0901 15:36:39.719614 916722 solver.cpp:218] Iteration 4696000 (16.7956 iter/s, 29.7697s/500 iters), loss = 0.253162
I0901 15:36:39.719672 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.253162 (* 1 = 0.253162 loss)
I0901 15:36:39.719681 916722 sgd_solver.cpp:106] Iteration 4696000, lr = 0.01
I0901 15:37:09.490841 916722 solver.cpp:218] Iteration 4696500 (16.7948 iter/s, 29.7711s/500 iters), loss = 0.12819
I0901 15:37:09.490892 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.12819 (* 1 = 0.12819 loss)
I0901 15:37:09.490902 916722 sgd_solver.cpp:106] Iteration 4696500, lr = 0.01
I0901 15:37:39.263778 916722 solver.cpp:218] Iteration 4697000 (16.7939 iter/s, 29.7728s/500 iters), loss = 0.165944
I0901 15:37:39.263844 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.165943 (* 1 = 0.165943 loss)
I0901 15:37:39.263851 916722 sgd_solver.cpp:106] Iteration 4697000, lr = 0.01
I0901 15:38:09.031165 916722 solver.cpp:218] Iteration 4697500 (16.797 iter/s, 29.7672s/500 iters), loss = 0.150376
I0901 15:38:09.031219 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.150376 (* 1 = 0.150376 loss)
I0901 15:38:09.031229 916722 sgd_solver.cpp:106] Iteration 4697500, lr = 0.01
I0901 15:38:38.802913 916722 solver.cpp:218] Iteration 4698000 (16.7945 iter/s, 29.7716s/500 iters), loss = 0.233441
I0901 15:38:38.802974 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.233441 (* 1 = 0.233441 loss)
I0901 15:38:38.802982 916722 sgd_solver.cpp:106] Iteration 4698000, lr = 0.01
I0901 15:39:08.571049 916722 solver.cpp:218] Iteration 4698500 (16.7966 iter/s, 29.768s/500 iters), loss = 0.104017
I0901 15:39:08.571105 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104016 (* 1 = 0.104016 loss)
I0901 15:39:08.571115 916722 sgd_solver.cpp:106] Iteration 4698500, lr = 0.01
I0901 15:39:38.343863 916722 solver.cpp:218] Iteration 4699000 (16.7939 iter/s, 29.7727s/500 iters), loss = 0.253635
I0901 15:39:38.343926 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.253635 (* 1 = 0.253635 loss)
I0901 15:39:38.343935 916722 sgd_solver.cpp:106] Iteration 4699000, lr = 0.01
I0901 15:40:08.109582 916722 solver.cpp:218] Iteration 4699500 (16.7979 iter/s, 29.7655s/500 iters), loss = 0.223337
I0901 15:40:08.109637 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.223336 (* 1 = 0.223336 loss)
I0901 15:40:08.109645 916722 sgd_solver.cpp:106] Iteration 4699500, lr = 0.01
I0901 15:40:37.822161 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_4700000.caffemodel
I0901 15:40:37.841548 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_4700000.solverstate
I0901 15:40:37.847558 916722 solver.cpp:330] Iteration 4700000, Testing net (#0)
I0901 15:40:53.241333 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8601
I0901 15:40:53.241380 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.457091 (* 1 = 0.457091 loss)
I0901 15:40:53.300035 916722 solver.cpp:218] Iteration 4700000 (11.0643 iter/s, 45.1902s/500 iters), loss = 0.116591
I0901 15:40:53.300065 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.116591 (* 1 = 0.116591 loss)
I0901 15:40:53.300073 916722 sgd_solver.cpp:106] Iteration 4700000, lr = 0.01
I0901 15:41:23.048720 916722 solver.cpp:218] Iteration 4700500 (16.8076 iter/s, 29.7485s/500 iters), loss = 0.0735345
I0901 15:41:23.048797 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0735341 (* 1 = 0.0735341 loss)
I0901 15:41:23.048806 916722 sgd_solver.cpp:106] Iteration 4700500, lr = 0.01
I0901 15:41:52.810806 916722 solver.cpp:218] Iteration 4701000 (16.8 iter/s, 29.7619s/500 iters), loss = 0.0518134
I0901 15:41:52.810863 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0518131 (* 1 = 0.0518131 loss)
I0901 15:41:52.810873 916722 sgd_solver.cpp:106] Iteration 4701000, lr = 0.01
I0901 15:42:22.582090 916722 solver.cpp:218] Iteration 4701500 (16.7948 iter/s, 29.7711s/500 iters), loss = 0.262132
I0901 15:42:22.582154 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.262132 (* 1 = 0.262132 loss)
I0901 15:42:22.582162 916722 sgd_solver.cpp:106] Iteration 4701500, lr = 0.01
I0901 15:42:52.348855 916722 solver.cpp:218] Iteration 4702000 (16.7974 iter/s, 29.7666s/500 iters), loss = 0.0277267
I0901 15:42:52.348912 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0277264 (* 1 = 0.0277264 loss)
I0901 15:42:52.348922 916722 sgd_solver.cpp:106] Iteration 4702000, lr = 0.01
I0901 15:43:22.118010 916722 solver.cpp:218] Iteration 4702500 (16.796 iter/s, 29.769s/500 iters), loss = 0.126452
I0901 15:43:22.118069 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.126451 (* 1 = 0.126451 loss)
I0901 15:43:22.118077 916722 sgd_solver.cpp:106] Iteration 4702500, lr = 0.01
I0901 15:43:51.875702 916722 solver.cpp:218] Iteration 4703000 (16.8025 iter/s, 29.7575s/500 iters), loss = 0.107128
I0901 15:43:51.875754 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.107127 (* 1 = 0.107127 loss)
I0901 15:43:51.875764 916722 sgd_solver.cpp:106] Iteration 4703000, lr = 0.01
I0901 15:44:21.619683 916722 solver.cpp:218] Iteration 4703500 (16.8102 iter/s, 29.7438s/500 iters), loss = 0.111
I0901 15:44:21.619743 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110999 (* 1 = 0.110999 loss)
I0901 15:44:21.619751 916722 sgd_solver.cpp:106] Iteration 4703500, lr = 0.01
I0901 15:44:51.359397 916722 solver.cpp:218] Iteration 4704000 (16.8126 iter/s, 29.7396s/500 iters), loss = 0.0573142
I0901 15:44:51.359452 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.057314 (* 1 = 0.057314 loss)
I0901 15:44:51.359462 916722 sgd_solver.cpp:106] Iteration 4704000, lr = 0.01
I0901 15:45:21.104879 916722 solver.cpp:218] Iteration 4704500 (16.8094 iter/s, 29.7453s/500 iters), loss = 0.00428149
I0901 15:45:21.104940 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.00428137 (* 1 = 0.00428137 loss)
I0901 15:45:21.104948 916722 sgd_solver.cpp:106] Iteration 4704500, lr = 0.01
I0901 15:45:50.849259 916722 solver.cpp:218] Iteration 4705000 (16.81 iter/s, 29.7442s/500 iters), loss = 0.0297251
I0901 15:45:50.849313 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0297249 (* 1 = 0.0297249 loss)
I0901 15:45:50.849324 916722 sgd_solver.cpp:106] Iteration 4705000, lr = 0.01
I0901 15:46:20.591524 916722 solver.cpp:218] Iteration 4705500 (16.8112 iter/s, 29.7421s/500 iters), loss = 0.139086
I0901 15:46:20.591583 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139085 (* 1 = 0.139085 loss)
I0901 15:46:20.591593 916722 sgd_solver.cpp:106] Iteration 4705500, lr = 0.01
I0901 15:46:50.335985 916722 solver.cpp:218] Iteration 4706000 (16.8099 iter/s, 29.7443s/500 iters), loss = 0.0357145
I0901 15:46:50.336051 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0357143 (* 1 = 0.0357143 loss)
I0901 15:46:50.336062 916722 sgd_solver.cpp:106] Iteration 4706000, lr = 0.01
I0901 15:47:20.075994 916722 solver.cpp:218] Iteration 4706500 (16.8125 iter/s, 29.7398s/500 iters), loss = 0.106586
I0901 15:47:20.076064 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.106586 (* 1 = 0.106586 loss)
I0901 15:47:20.076072 916722 sgd_solver.cpp:106] Iteration 4706500, lr = 0.01
I0901 15:47:49.815146 916722 solver.cpp:218] Iteration 4707000 (16.8129 iter/s, 29.739s/500 iters), loss = 0.0582875
I0901 15:47:49.815198 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0582872 (* 1 = 0.0582872 loss)
I0901 15:47:49.815208 916722 sgd_solver.cpp:106] Iteration 4707000, lr = 0.01
I0901 15:48:19.556895 916722 solver.cpp:218] Iteration 4707500 (16.8115 iter/s, 29.7416s/500 iters), loss = 0.210724
I0901 15:48:19.556950 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.210724 (* 1 = 0.210724 loss)
I0901 15:48:19.556958 916722 sgd_solver.cpp:106] Iteration 4707500, lr = 0.01
I0901 15:48:49.299090 916722 solver.cpp:218] Iteration 4708000 (16.8112 iter/s, 29.742s/500 iters), loss = 0.252867
I0901 15:48:49.299146 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.252867 (* 1 = 0.252867 loss)
I0901 15:48:49.299156 916722 sgd_solver.cpp:106] Iteration 4708000, lr = 0.01
I0901 15:49:19.040143 916722 solver.cpp:218] Iteration 4708500 (16.8119 iter/s, 29.7409s/500 iters), loss = 0.475276
I0901 15:49:19.040202 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.475275 (* 1 = 0.475275 loss)
I0901 15:49:19.040211 916722 sgd_solver.cpp:106] Iteration 4708500, lr = 0.01
I0901 15:49:48.783212 916722 solver.cpp:218] Iteration 4709000 (16.8107 iter/s, 29.7429s/500 iters), loss = 0.0259601
I0901 15:49:48.783267 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0259596 (* 1 = 0.0259596 loss)
I0901 15:49:48.783277 916722 sgd_solver.cpp:106] Iteration 4709000, lr = 0.01
I0901 15:50:18.522883 916722 solver.cpp:218] Iteration 4709500 (16.8126 iter/s, 29.7395s/500 iters), loss = 0.172379
I0901 15:50:18.522944 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.172379 (* 1 = 0.172379 loss)
I0901 15:50:18.522953 916722 sgd_solver.cpp:106] Iteration 4709500, lr = 0.01
I0901 15:50:48.259420 916722 solver.cpp:218] Iteration 4710000 (16.8144 iter/s, 29.7364s/500 iters), loss = 0.234281
I0901 15:50:48.259475 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.234281 (* 1 = 0.234281 loss)
I0901 15:50:48.259485 916722 sgd_solver.cpp:106] Iteration 4710000, lr = 0.01
I0901 15:51:18.001878 916722 solver.cpp:218] Iteration 4710500 (16.8111 iter/s, 29.7423s/500 iters), loss = 0.12943
I0901 15:51:18.001937 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.129429 (* 1 = 0.129429 loss)
I0901 15:51:18.001945 916722 sgd_solver.cpp:106] Iteration 4710500, lr = 0.01
I0901 15:51:47.741262 916722 solver.cpp:218] Iteration 4711000 (16.8128 iter/s, 29.7392s/500 iters), loss = 0.142561
I0901 15:51:47.741314 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.142561 (* 1 = 0.142561 loss)
I0901 15:51:47.741323 916722 sgd_solver.cpp:106] Iteration 4711000, lr = 0.01
I0901 15:52:17.482177 916722 solver.cpp:218] Iteration 4711500 (16.8119 iter/s, 29.7408s/500 iters), loss = 0.0666515
I0901 15:52:17.482235 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.066651 (* 1 = 0.066651 loss)
I0901 15:52:17.482244 916722 sgd_solver.cpp:106] Iteration 4711500, lr = 0.01
I0901 15:52:47.220953 916722 solver.cpp:218] Iteration 4712000 (16.8132 iter/s, 29.7386s/500 iters), loss = 0.0258262
I0901 15:52:47.221007 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0258256 (* 1 = 0.0258256 loss)
I0901 15:52:47.221016 916722 sgd_solver.cpp:106] Iteration 4712000, lr = 0.01
I0901 15:53:16.958882 916722 solver.cpp:218] Iteration 4712500 (16.8136 iter/s, 29.7378s/500 iters), loss = 0.0333426
I0901 15:53:16.958958 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0333421 (* 1 = 0.0333421 loss)
I0901 15:53:16.958972 916722 sgd_solver.cpp:106] Iteration 4712500, lr = 0.01
I0901 15:53:46.698055 916722 solver.cpp:218] Iteration 4713000 (16.8129 iter/s, 29.739s/500 iters), loss = 0.0327488
I0901 15:53:46.698108 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0327482 (* 1 = 0.0327482 loss)
I0901 15:53:46.698117 916722 sgd_solver.cpp:106] Iteration 4713000, lr = 0.01
I0901 15:54:16.436544 916722 solver.cpp:218] Iteration 4713500 (16.8133 iter/s, 29.7383s/500 iters), loss = 0.129107
I0901 15:54:16.436604 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.129106 (* 1 = 0.129106 loss)
I0901 15:54:16.436612 916722 sgd_solver.cpp:106] Iteration 4713500, lr = 0.01
I0901 15:54:46.172284 916722 solver.cpp:218] Iteration 4714000 (16.8149 iter/s, 29.7356s/500 iters), loss = 0.378692
I0901 15:54:46.172338 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.378692 (* 1 = 0.378692 loss)
I0901 15:54:46.172346 916722 sgd_solver.cpp:106] Iteration 4714000, lr = 0.01
I0901 15:55:15.912694 916722 solver.cpp:218] Iteration 4714500 (16.8122 iter/s, 29.7403s/500 iters), loss = 0.165778
I0901 15:55:15.912762 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.165777 (* 1 = 0.165777 loss)
I0901 15:55:15.912772 916722 sgd_solver.cpp:106] Iteration 4714500, lr = 0.01
I0901 15:55:45.649358 916722 solver.cpp:218] Iteration 4715000 (16.8144 iter/s, 29.7365s/500 iters), loss = 0.0581535
I0901 15:55:45.649410 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0581529 (* 1 = 0.0581529 loss)
I0901 15:55:45.649420 916722 sgd_solver.cpp:106] Iteration 4715000, lr = 0.01
I0901 15:56:15.387429 916722 solver.cpp:218] Iteration 4715500 (16.8135 iter/s, 29.7379s/500 iters), loss = 0.106426
I0901 15:56:15.387485 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.106425 (* 1 = 0.106425 loss)
I0901 15:56:15.387495 916722 sgd_solver.cpp:106] Iteration 4715500, lr = 0.01
I0901 15:56:45.127998 916722 solver.cpp:218] Iteration 4716000 (16.8121 iter/s, 29.7404s/500 iters), loss = 0.0480547
I0901 15:56:45.128052 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0480539 (* 1 = 0.0480539 loss)
I0901 15:56:45.128062 916722 sgd_solver.cpp:106] Iteration 4716000, lr = 0.01
I0901 15:57:14.866605 916722 solver.cpp:218] Iteration 4716500 (16.8132 iter/s, 29.7385s/500 iters), loss = 0.193905
I0901 15:57:14.866665 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.193904 (* 1 = 0.193904 loss)
I0901 15:57:14.866674 916722 sgd_solver.cpp:106] Iteration 4716500, lr = 0.01
I0901 15:57:44.604761 916722 solver.cpp:218] Iteration 4717000 (16.8135 iter/s, 29.738s/500 iters), loss = 0.183414
I0901 15:57:44.604815 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.183414 (* 1 = 0.183414 loss)
I0901 15:57:44.604825 916722 sgd_solver.cpp:106] Iteration 4717000, lr = 0.01
I0901 15:58:14.340502 916722 solver.cpp:218] Iteration 4717500 (16.8149 iter/s, 29.7356s/500 iters), loss = 0.106286
I0901 15:58:14.340565 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.106285 (* 1 = 0.106285 loss)
I0901 15:58:14.340574 916722 sgd_solver.cpp:106] Iteration 4717500, lr = 0.01
I0901 15:58:44.079782 916722 solver.cpp:218] Iteration 4718000 (16.8129 iter/s, 29.7391s/500 iters), loss = 0.0153493
I0901 15:58:44.079838 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0153485 (* 1 = 0.0153485 loss)
I0901 15:58:44.079847 916722 sgd_solver.cpp:106] Iteration 4718000, lr = 0.01
I0901 15:59:13.817564 916722 solver.cpp:218] Iteration 4718500 (16.8137 iter/s, 29.7376s/500 iters), loss = 0.18061
I0901 15:59:13.817623 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.18061 (* 1 = 0.18061 loss)
I0901 15:59:13.817632 916722 sgd_solver.cpp:106] Iteration 4718500, lr = 0.01
I0901 15:59:43.557355 916722 solver.cpp:218] Iteration 4719000 (16.8126 iter/s, 29.7396s/500 iters), loss = 0.341856
I0901 15:59:43.557410 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.341855 (* 1 = 0.341855 loss)
I0901 15:59:43.557431 916722 sgd_solver.cpp:106] Iteration 4719000, lr = 0.01
I0901 16:00:13.295121 916722 solver.cpp:218] Iteration 4719500 (16.8137 iter/s, 29.7376s/500 iters), loss = 0.0948908
I0901 16:00:13.295192 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.09489 (* 1 = 0.09489 loss)
I0901 16:00:13.295200 916722 sgd_solver.cpp:106] Iteration 4719500, lr = 0.01
I0901 16:00:43.031019 916722 solver.cpp:218] Iteration 4720000 (16.8148 iter/s, 29.7357s/500 iters), loss = 0.054397
I0901 16:00:43.031073 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0543962 (* 1 = 0.0543962 loss)
I0901 16:00:43.031083 916722 sgd_solver.cpp:106] Iteration 4720000, lr = 0.01
I0901 16:01:12.771436 916722 solver.cpp:218] Iteration 4720500 (16.8122 iter/s, 29.7403s/500 iters), loss = 0.11025
I0901 16:01:12.771492 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.11025 (* 1 = 0.11025 loss)
I0901 16:01:12.771502 916722 sgd_solver.cpp:106] Iteration 4720500, lr = 0.01
I0901 16:01:42.510900 916722 solver.cpp:218] Iteration 4721000 (16.8128 iter/s, 29.7393s/500 iters), loss = 0.175967
I0901 16:01:42.510954 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.175966 (* 1 = 0.175966 loss)
I0901 16:01:42.510965 916722 sgd_solver.cpp:106] Iteration 4721000, lr = 0.01
I0901 16:02:12.249461 916722 solver.cpp:218] Iteration 4721500 (16.8133 iter/s, 29.7384s/500 iters), loss = 0.145461
I0901 16:02:12.249526 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.14546 (* 1 = 0.14546 loss)
I0901 16:02:12.249534 916722 sgd_solver.cpp:106] Iteration 4721500, lr = 0.01
I0901 16:02:41.989382 916722 solver.cpp:218] Iteration 4722000 (16.8125 iter/s, 29.7398s/500 iters), loss = 0.126422
I0901 16:02:41.989436 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.126421 (* 1 = 0.126421 loss)
I0901 16:02:41.989445 916722 sgd_solver.cpp:106] Iteration 4722000, lr = 0.01
I0901 16:03:11.731074 916722 solver.cpp:218] Iteration 4722500 (16.8115 iter/s, 29.7415s/500 iters), loss = 0.0299203
I0901 16:03:11.731137 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0299195 (* 1 = 0.0299195 loss)
I0901 16:03:11.731144 916722 sgd_solver.cpp:106] Iteration 4722500, lr = 0.01
I0901 16:03:41.468467 916722 solver.cpp:218] Iteration 4723000 (16.8139 iter/s, 29.7372s/500 iters), loss = 0.0512176
I0901 16:03:41.468523 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0512168 (* 1 = 0.0512168 loss)
I0901 16:03:41.468530 916722 sgd_solver.cpp:106] Iteration 4723000, lr = 0.01
I0901 16:04:11.207863 916722 solver.cpp:218] Iteration 4723500 (16.8128 iter/s, 29.7393s/500 iters), loss = 0.0237336
I0901 16:04:11.207924 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0237327 (* 1 = 0.0237327 loss)
I0901 16:04:11.207932 916722 sgd_solver.cpp:106] Iteration 4723500, lr = 0.01
I0901 16:04:40.943905 916722 solver.cpp:218] Iteration 4724000 (16.8147 iter/s, 29.7359s/500 iters), loss = 0.0145872
I0901 16:04:40.943959 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0145865 (* 1 = 0.0145865 loss)
I0901 16:04:40.943969 916722 sgd_solver.cpp:106] Iteration 4724000, lr = 0.01
I0901 16:05:10.684309 916722 solver.cpp:218] Iteration 4724500 (16.8122 iter/s, 29.7403s/500 iters), loss = 0.0938047
I0901 16:05:10.684368 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0938039 (* 1 = 0.0938039 loss)
I0901 16:05:10.684377 916722 sgd_solver.cpp:106] Iteration 4724500, lr = 0.01
I0901 16:05:40.420146 916722 solver.cpp:218] Iteration 4725000 (16.8148 iter/s, 29.7357s/500 iters), loss = 0.377236
I0901 16:05:40.420202 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.377235 (* 1 = 0.377235 loss)
I0901 16:05:40.420209 916722 sgd_solver.cpp:106] Iteration 4725000, lr = 0.01
I0901 16:06:10.158674 916722 solver.cpp:218] Iteration 4725500 (16.8133 iter/s, 29.7384s/500 iters), loss = 0.130236
I0901 16:06:10.158751 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130235 (* 1 = 0.130235 loss)
I0901 16:06:10.158764 916722 sgd_solver.cpp:106] Iteration 4725500, lr = 0.01
I0901 16:06:39.897037 916722 solver.cpp:218] Iteration 4726000 (16.8134 iter/s, 29.7382s/500 iters), loss = 0.164794
I0901 16:06:39.897091 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.164793 (* 1 = 0.164793 loss)
I0901 16:06:39.897100 916722 sgd_solver.cpp:106] Iteration 4726000, lr = 0.01
I0901 16:07:09.639353 916722 solver.cpp:218] Iteration 4726500 (16.8111 iter/s, 29.7422s/500 iters), loss = 0.181886
I0901 16:07:09.639413 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.181886 (* 1 = 0.181886 loss)
I0901 16:07:09.639422 916722 sgd_solver.cpp:106] Iteration 4726500, lr = 0.01
I0901 16:07:39.376770 916722 solver.cpp:218] Iteration 4727000 (16.8139 iter/s, 29.7373s/500 iters), loss = 0.106014
I0901 16:07:39.376827 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.106014 (* 1 = 0.106014 loss)
I0901 16:07:39.376837 916722 sgd_solver.cpp:106] Iteration 4727000, lr = 0.01
I0901 16:08:09.116899 916722 solver.cpp:218] Iteration 4727500 (16.8124 iter/s, 29.74s/500 iters), loss = 0.0980985
I0901 16:08:09.116959 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0980978 (* 1 = 0.0980978 loss)
I0901 16:08:09.116967 916722 sgd_solver.cpp:106] Iteration 4727500, lr = 0.01
I0901 16:08:38.855490 916722 solver.cpp:218] Iteration 4728000 (16.8133 iter/s, 29.7384s/500 iters), loss = 0.0970589
I0901 16:08:38.855545 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0970582 (* 1 = 0.0970582 loss)
I0901 16:08:38.855554 916722 sgd_solver.cpp:106] Iteration 4728000, lr = 0.01
I0901 16:09:08.589865 916722 solver.cpp:218] Iteration 4728500 (16.8156 iter/s, 29.7342s/500 iters), loss = 0.259763
I0901 16:09:08.589923 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.259762 (* 1 = 0.259762 loss)
I0901 16:09:08.589931 916722 sgd_solver.cpp:106] Iteration 4728500, lr = 0.01
I0901 16:09:38.327077 916722 solver.cpp:218] Iteration 4729000 (16.814 iter/s, 29.7371s/500 iters), loss = 0.120455
I0901 16:09:38.327129 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.120454 (* 1 = 0.120454 loss)
I0901 16:09:38.327140 916722 sgd_solver.cpp:106] Iteration 4729000, lr = 0.01
I0901 16:10:08.061290 916722 solver.cpp:218] Iteration 4729500 (16.8157 iter/s, 29.7341s/500 iters), loss = 0.0801945
I0901 16:10:08.061348 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0801939 (* 1 = 0.0801939 loss)
I0901 16:10:08.061357 916722 sgd_solver.cpp:106] Iteration 4729500, lr = 0.01
I0901 16:10:37.797132 916722 solver.cpp:218] Iteration 4730000 (16.8148 iter/s, 29.7357s/500 iters), loss = 0.113699
I0901 16:10:37.797184 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.113699 (* 1 = 0.113699 loss)
I0901 16:10:37.797194 916722 sgd_solver.cpp:106] Iteration 4730000, lr = 0.01
I0901 16:11:07.533978 916722 solver.cpp:218] Iteration 4730500 (16.8142 iter/s, 29.7367s/500 iters), loss = 0.0948534
I0901 16:11:07.534036 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0948529 (* 1 = 0.0948529 loss)
I0901 16:11:07.534045 916722 sgd_solver.cpp:106] Iteration 4730500, lr = 0.01
I0901 16:11:37.272948 916722 solver.cpp:218] Iteration 4731000 (16.813 iter/s, 29.7388s/500 iters), loss = 0.241205
I0901 16:11:37.273001 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.241204 (* 1 = 0.241204 loss)
I0901 16:11:37.273012 916722 sgd_solver.cpp:106] Iteration 4731000, lr = 0.01
I0901 16:12:07.009490 916722 solver.cpp:218] Iteration 4731500 (16.8144 iter/s, 29.7364s/500 iters), loss = 0.0409268
I0901 16:12:07.009554 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0409264 (* 1 = 0.0409264 loss)
I0901 16:12:07.009563 916722 sgd_solver.cpp:106] Iteration 4731500, lr = 0.01
I0901 16:12:36.744875 916722 solver.cpp:218] Iteration 4732000 (16.8151 iter/s, 29.7352s/500 iters), loss = 0.0667358
I0901 16:12:36.744930 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0667355 (* 1 = 0.0667355 loss)
I0901 16:12:36.744938 916722 sgd_solver.cpp:106] Iteration 4732000, lr = 0.01
I0901 16:13:06.481091 916722 solver.cpp:218] Iteration 4732500 (16.8146 iter/s, 29.7361s/500 iters), loss = 0.059487
I0901 16:13:06.481163 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0594866 (* 1 = 0.0594866 loss)
I0901 16:13:06.481171 916722 sgd_solver.cpp:106] Iteration 4732500, lr = 0.01
I0901 16:13:36.213940 916722 solver.cpp:218] Iteration 4733000 (16.8165 iter/s, 29.7327s/500 iters), loss = 0.161057
I0901 16:13:36.213994 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.161056 (* 1 = 0.161056 loss)
I0901 16:13:36.214002 916722 sgd_solver.cpp:106] Iteration 4733000, lr = 0.01
I0901 16:14:05.944732 916722 solver.cpp:218] Iteration 4733500 (16.8175 iter/s, 29.731s/500 iters), loss = 0.140468
I0901 16:14:05.944795 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.140467 (* 1 = 0.140467 loss)
I0901 16:14:05.944804 916722 sgd_solver.cpp:106] Iteration 4733500, lr = 0.01
I0901 16:14:35.677757 916722 solver.cpp:218] Iteration 4734000 (16.8162 iter/s, 29.7332s/500 iters), loss = 0.182963
I0901 16:14:35.677809 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.182962 (* 1 = 0.182962 loss)
I0901 16:14:35.677817 916722 sgd_solver.cpp:106] Iteration 4734000, lr = 0.01
I0901 16:15:05.424526 916722 solver.cpp:218] Iteration 4734500 (16.8084 iter/s, 29.747s/500 iters), loss = 0.180225
I0901 16:15:05.424583 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.180224 (* 1 = 0.180224 loss)
I0901 16:15:05.424592 916722 sgd_solver.cpp:106] Iteration 4734500, lr = 0.01
I0901 16:15:35.175793 916722 solver.cpp:218] Iteration 4735000 (16.8059 iter/s, 29.7514s/500 iters), loss = 0.109477
I0901 16:15:35.175846 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109476 (* 1 = 0.109476 loss)
I0901 16:15:35.175855 916722 sgd_solver.cpp:106] Iteration 4735000, lr = 0.01
I0901 16:16:04.925073 916722 solver.cpp:218] Iteration 4735500 (16.807 iter/s, 29.7494s/500 iters), loss = 0.0809696
I0901 16:16:04.925133 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0809687 (* 1 = 0.0809687 loss)
I0901 16:16:04.925143 916722 sgd_solver.cpp:106] Iteration 4735500, lr = 0.01
I0901 16:16:34.678135 916722 solver.cpp:218] Iteration 4736000 (16.8049 iter/s, 29.7532s/500 iters), loss = 0.0737166
I0901 16:16:34.678189 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0737158 (* 1 = 0.0737158 loss)
I0901 16:16:34.678197 916722 sgd_solver.cpp:106] Iteration 4736000, lr = 0.01
I0901 16:17:04.436143 916722 solver.cpp:218] Iteration 4736500 (16.8021 iter/s, 29.7581s/500 iters), loss = 0.181297
I0901 16:17:04.436201 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.181296 (* 1 = 0.181296 loss)
I0901 16:17:04.436210 916722 sgd_solver.cpp:106] Iteration 4736500, lr = 0.01
I0901 16:17:34.190719 916722 solver.cpp:218] Iteration 4737000 (16.8041 iter/s, 29.7547s/500 iters), loss = 0.0961005
I0901 16:17:34.190775 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0960995 (* 1 = 0.0960995 loss)
I0901 16:17:34.190785 916722 sgd_solver.cpp:106] Iteration 4737000, lr = 0.01
I0901 16:18:03.942736 916722 solver.cpp:218] Iteration 4737500 (16.8055 iter/s, 29.7521s/500 iters), loss = 0.218479
I0901 16:18:03.942793 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.218478 (* 1 = 0.218478 loss)
I0901 16:18:03.942802 916722 sgd_solver.cpp:106] Iteration 4737500, lr = 0.01
I0901 16:18:33.696485 916722 solver.cpp:218] Iteration 4738000 (16.8046 iter/s, 29.7538s/500 iters), loss = 0.21272
I0901 16:18:33.696538 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.212719 (* 1 = 0.212719 loss)
I0901 16:18:33.696548 916722 sgd_solver.cpp:106] Iteration 4738000, lr = 0.01
I0901 16:19:03.452098 916722 solver.cpp:218] Iteration 4738500 (16.8035 iter/s, 29.7557s/500 iters), loss = 0.0374692
I0901 16:19:03.452157 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0374682 (* 1 = 0.0374682 loss)
I0901 16:19:03.452165 916722 sgd_solver.cpp:106] Iteration 4738500, lr = 0.01
I0901 16:19:33.205524 916722 solver.cpp:218] Iteration 4739000 (16.8048 iter/s, 29.7535s/500 iters), loss = 0.0679686
I0901 16:19:33.205579 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0679675 (* 1 = 0.0679675 loss)
I0901 16:19:33.205588 916722 sgd_solver.cpp:106] Iteration 4739000, lr = 0.01
I0901 16:20:02.961751 916722 solver.cpp:218] Iteration 4739500 (16.8032 iter/s, 29.7563s/500 iters), loss = 0.0506237
I0901 16:20:02.961820 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0506226 (* 1 = 0.0506226 loss)
I0901 16:20:02.961828 916722 sgd_solver.cpp:106] Iteration 4739500, lr = 0.01
I0901 16:20:32.706488 916722 solver.cpp:218] Iteration 4740000 (16.8097 iter/s, 29.7448s/500 iters), loss = 0.292296
I0901 16:20:32.706542 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.292295 (* 1 = 0.292295 loss)
I0901 16:20:32.706552 916722 sgd_solver.cpp:106] Iteration 4740000, lr = 0.01
I0901 16:21:02.465489 916722 solver.cpp:218] Iteration 4740500 (16.8016 iter/s, 29.759s/500 iters), loss = 0.321928
I0901 16:21:02.465546 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.321927 (* 1 = 0.321927 loss)
I0901 16:21:02.465555 916722 sgd_solver.cpp:106] Iteration 4740500, lr = 0.01
I0901 16:21:32.245802 916722 solver.cpp:218] Iteration 4741000 (16.7896 iter/s, 29.7803s/500 iters), loss = 0.0875547
I0901 16:21:32.245857 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0875534 (* 1 = 0.0875534 loss)
I0901 16:21:32.245867 916722 sgd_solver.cpp:106] Iteration 4741000, lr = 0.01
I0901 16:22:02.025779 916722 solver.cpp:218] Iteration 4741500 (16.7898 iter/s, 29.78s/500 iters), loss = 0.0661887
I0901 16:22:02.025841 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0661873 (* 1 = 0.0661873 loss)
I0901 16:22:02.025851 916722 sgd_solver.cpp:106] Iteration 4741500, lr = 0.01
I0901 16:22:31.807041 916722 solver.cpp:218] Iteration 4742000 (16.7891 iter/s, 29.7813s/500 iters), loss = 0.0455772
I0901 16:22:31.807092 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0455757 (* 1 = 0.0455757 loss)
I0901 16:22:31.807101 916722 sgd_solver.cpp:106] Iteration 4742000, lr = 0.01
I0901 16:23:01.582828 916722 solver.cpp:218] Iteration 4742500 (16.7922 iter/s, 29.7758s/500 iters), loss = 0.164428
I0901 16:23:01.582887 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.164427 (* 1 = 0.164427 loss)
I0901 16:23:01.582895 916722 sgd_solver.cpp:106] Iteration 4742500, lr = 0.01
I0901 16:23:31.365061 916722 solver.cpp:218] Iteration 4743000 (16.7885 iter/s, 29.7822s/500 iters), loss = 0.149934
I0901 16:23:31.365110 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.149933 (* 1 = 0.149933 loss)
I0901 16:23:31.365118 916722 sgd_solver.cpp:106] Iteration 4743000, lr = 0.01
I0901 16:24:01.148129 916722 solver.cpp:218] Iteration 4743500 (16.7881 iter/s, 29.7831s/500 iters), loss = 0.177582
I0901 16:24:01.148186 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.17758 (* 1 = 0.17758 loss)
I0901 16:24:01.148195 916722 sgd_solver.cpp:106] Iteration 4743500, lr = 0.01
I0901 16:24:30.930270 916722 solver.cpp:218] Iteration 4744000 (16.7886 iter/s, 29.7821s/500 iters), loss = 0.245595
I0901 16:24:30.930325 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.245594 (* 1 = 0.245594 loss)
I0901 16:24:30.930335 916722 sgd_solver.cpp:106] Iteration 4744000, lr = 0.01
I0901 16:25:00.714270 916722 solver.cpp:218] Iteration 4744500 (16.7875 iter/s, 29.784s/500 iters), loss = 0.208038
I0901 16:25:00.714327 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.208037 (* 1 = 0.208037 loss)
I0901 16:25:00.714335 916722 sgd_solver.cpp:106] Iteration 4744500, lr = 0.01
I0901 16:25:30.491164 916722 solver.cpp:218] Iteration 4745000 (16.7916 iter/s, 29.7769s/500 iters), loss = 0.0993298
I0901 16:25:30.491220 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0993286 (* 1 = 0.0993286 loss)
I0901 16:25:30.491230 916722 sgd_solver.cpp:106] Iteration 4745000, lr = 0.01
I0901 16:26:00.268664 916722 solver.cpp:218] Iteration 4745500 (16.7912 iter/s, 29.7775s/500 iters), loss = 0.189928
I0901 16:26:00.268750 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.189927 (* 1 = 0.189927 loss)
I0901 16:26:00.268759 916722 sgd_solver.cpp:106] Iteration 4745500, lr = 0.01
I0901 16:26:30.053092 916722 solver.cpp:218] Iteration 4746000 (16.7873 iter/s, 29.7844s/500 iters), loss = 0.133188
I0901 16:26:30.053148 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133187 (* 1 = 0.133187 loss)
I0901 16:26:30.053158 916722 sgd_solver.cpp:106] Iteration 4746000, lr = 0.01
I0901 16:26:59.833201 916722 solver.cpp:218] Iteration 4746500 (16.7898 iter/s, 29.7801s/500 iters), loss = 0.0160737
I0901 16:26:59.833267 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0160724 (* 1 = 0.0160724 loss)
I0901 16:26:59.833276 916722 sgd_solver.cpp:106] Iteration 4746500, lr = 0.01
I0901 16:27:29.619072 916722 solver.cpp:218] Iteration 4747000 (16.7865 iter/s, 29.7858s/500 iters), loss = 0.0772894
I0901 16:27:29.619128 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.077288 (* 1 = 0.077288 loss)
I0901 16:27:29.619136 916722 sgd_solver.cpp:106] Iteration 4747000, lr = 0.01
I0901 16:27:59.395455 916722 solver.cpp:218] Iteration 4747500 (16.7919 iter/s, 29.7763s/500 iters), loss = 0.179699
I0901 16:27:59.395515 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.179698 (* 1 = 0.179698 loss)
I0901 16:27:59.395524 916722 sgd_solver.cpp:106] Iteration 4747500, lr = 0.01
I0901 16:28:29.173029 916722 solver.cpp:218] Iteration 4748000 (16.7912 iter/s, 29.7775s/500 iters), loss = 0.238987
I0901 16:28:29.173084 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.238986 (* 1 = 0.238986 loss)
I0901 16:28:29.173094 916722 sgd_solver.cpp:106] Iteration 4748000, lr = 0.01
I0901 16:28:58.950601 916722 solver.cpp:218] Iteration 4748500 (16.7912 iter/s, 29.7775s/500 iters), loss = 0.30738
I0901 16:28:58.950661 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.307379 (* 1 = 0.307379 loss)
I0901 16:28:58.950670 916722 sgd_solver.cpp:106] Iteration 4748500, lr = 0.01
I0901 16:29:28.727389 916722 solver.cpp:218] Iteration 4749000 (16.7916 iter/s, 29.7767s/500 iters), loss = 0.0164205
I0901 16:29:28.727442 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0164193 (* 1 = 0.0164193 loss)
I0901 16:29:28.727450 916722 sgd_solver.cpp:106] Iteration 4749000, lr = 0.01
I0901 16:29:58.503794 916722 solver.cpp:218] Iteration 4749500 (16.7918 iter/s, 29.7764s/500 iters), loss = 0.281169
I0901 16:29:58.503856 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.281168 (* 1 = 0.281168 loss)
I0901 16:29:58.503865 916722 sgd_solver.cpp:106] Iteration 4749500, lr = 0.01
I0901 16:30:28.218699 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_4750000.caffemodel
I0901 16:30:28.238171 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_4750000.solverstate
I0901 16:30:28.244202 916722 solver.cpp:330] Iteration 4750000, Testing net (#0)
I0901 16:30:43.644497 916722 solver.cpp:397]     Test net output #0: accuracy = 0.88
I0901 16:30:43.644559 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.435826 (* 1 = 0.435826 loss)
I0901 16:30:43.703088 916722 solver.cpp:218] Iteration 4750000 (11.0621 iter/s, 45.1992s/500 iters), loss = 0.17925
I0901 16:30:43.703114 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.179248 (* 1 = 0.179248 loss)
I0901 16:30:43.703122 916722 sgd_solver.cpp:106] Iteration 4750000, lr = 0.01
I0901 16:31:13.465231 916722 solver.cpp:218] Iteration 4750500 (16.7999 iter/s, 29.7621s/500 iters), loss = 0.115431
I0901 16:31:13.465283 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.11543 (* 1 = 0.11543 loss)
I0901 16:31:13.465292 916722 sgd_solver.cpp:106] Iteration 4750500, lr = 0.01
I0901 16:31:43.243602 916722 solver.cpp:218] Iteration 4751000 (16.7908 iter/s, 29.7783s/500 iters), loss = 0.0869077
I0901 16:31:43.243674 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0869064 (* 1 = 0.0869064 loss)
I0901 16:31:43.243686 916722 sgd_solver.cpp:106] Iteration 4751000, lr = 0.01
I0901 16:32:13.012311 916722 solver.cpp:218] Iteration 4751500 (16.7962 iter/s, 29.7686s/500 iters), loss = 0.212817
I0901 16:32:13.012367 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.212815 (* 1 = 0.212815 loss)
I0901 16:32:13.012374 916722 sgd_solver.cpp:106] Iteration 4751500, lr = 0.01
I0901 16:32:42.788805 916722 solver.cpp:218] Iteration 4752000 (16.7918 iter/s, 29.7764s/500 iters), loss = 0.0493347
I0901 16:32:42.788867 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0493333 (* 1 = 0.0493333 loss)
I0901 16:32:42.788875 916722 sgd_solver.cpp:106] Iteration 4752000, lr = 0.01
I0901 16:33:12.560449 916722 solver.cpp:218] Iteration 4752500 (16.7946 iter/s, 29.7716s/500 iters), loss = 0.0282006
I0901 16:33:12.560503 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0281992 (* 1 = 0.0281992 loss)
I0901 16:33:12.560511 916722 sgd_solver.cpp:106] Iteration 4752500, lr = 0.01
I0901 16:33:42.340117 916722 solver.cpp:218] Iteration 4753000 (16.79 iter/s, 29.7796s/500 iters), loss = 0.221824
I0901 16:33:42.340179 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.221822 (* 1 = 0.221822 loss)
I0901 16:33:42.340188 916722 sgd_solver.cpp:106] Iteration 4753000, lr = 0.01
I0901 16:34:12.120239 916722 solver.cpp:218] Iteration 4753500 (16.7898 iter/s, 29.78s/500 iters), loss = 0.179513
I0901 16:34:12.120292 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.179511 (* 1 = 0.179511 loss)
I0901 16:34:12.120301 916722 sgd_solver.cpp:106] Iteration 4753500, lr = 0.01
I0901 16:34:41.899912 916722 solver.cpp:218] Iteration 4754000 (16.79 iter/s, 29.7796s/500 iters), loss = 0.178323
I0901 16:34:41.899973 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.178321 (* 1 = 0.178321 loss)
I0901 16:34:41.899981 916722 sgd_solver.cpp:106] Iteration 4754000, lr = 0.01
I0901 16:35:11.683144 916722 solver.cpp:218] Iteration 4754500 (16.788 iter/s, 29.7831s/500 iters), loss = 0.0810672
I0901 16:35:11.683199 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0810657 (* 1 = 0.0810657 loss)
I0901 16:35:11.683207 916722 sgd_solver.cpp:106] Iteration 4754500, lr = 0.01
I0901 16:35:41.453191 916722 solver.cpp:218] Iteration 4755000 (16.7955 iter/s, 29.77s/500 iters), loss = 0.244003
I0901 16:35:41.453250 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.244002 (* 1 = 0.244002 loss)
I0901 16:35:41.453258 916722 sgd_solver.cpp:106] Iteration 4755000, lr = 0.01
I0901 16:36:11.236302 916722 solver.cpp:218] Iteration 4755500 (16.7881 iter/s, 29.783s/500 iters), loss = 0.141012
I0901 16:36:11.236358 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.14101 (* 1 = 0.14101 loss)
I0901 16:36:11.236368 916722 sgd_solver.cpp:106] Iteration 4755500, lr = 0.01
I0901 16:36:41.017961 916722 solver.cpp:218] Iteration 4756000 (16.7889 iter/s, 29.7816s/500 iters), loss = 0.0331185
I0901 16:36:41.018021 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0331173 (* 1 = 0.0331173 loss)
I0901 16:36:41.018030 916722 sgd_solver.cpp:106] Iteration 4756000, lr = 0.01
I0901 16:37:10.795853 916722 solver.cpp:218] Iteration 4756500 (16.791 iter/s, 29.7778s/500 iters), loss = 0.162725
I0901 16:37:10.795907 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.162724 (* 1 = 0.162724 loss)
I0901 16:37:10.795917 916722 sgd_solver.cpp:106] Iteration 4756500, lr = 0.01
I0901 16:37:40.579443 916722 solver.cpp:218] Iteration 4757000 (16.7878 iter/s, 29.7835s/500 iters), loss = 0.100667
I0901 16:37:40.579504 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.100665 (* 1 = 0.100665 loss)
I0901 16:37:40.579514 916722 sgd_solver.cpp:106] Iteration 4757000, lr = 0.01
I0901 16:38:10.364156 916722 solver.cpp:218] Iteration 4757500 (16.7872 iter/s, 29.7846s/500 iters), loss = 0.190124
I0901 16:38:10.364210 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.190123 (* 1 = 0.190123 loss)
I0901 16:38:10.364231 916722 sgd_solver.cpp:106] Iteration 4757500, lr = 0.01
I0901 16:38:40.141824 916722 solver.cpp:218] Iteration 4758000 (16.7912 iter/s, 29.7776s/500 iters), loss = 0.188322
I0901 16:38:40.141896 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.18832 (* 1 = 0.18832 loss)
I0901 16:38:40.141903 916722 sgd_solver.cpp:106] Iteration 4758000, lr = 0.01
I0901 16:39:09.916908 916722 solver.cpp:218] Iteration 4758500 (16.7926 iter/s, 29.775s/500 iters), loss = 0.165565
I0901 16:39:09.916955 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.165564 (* 1 = 0.165564 loss)
I0901 16:39:09.916963 916722 sgd_solver.cpp:106] Iteration 4758500, lr = 0.01
I0901 16:39:39.691295 916722 solver.cpp:218] Iteration 4759000 (16.793 iter/s, 29.7743s/500 iters), loss = 0.179516
I0901 16:39:39.691354 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.179515 (* 1 = 0.179515 loss)
I0901 16:39:39.691363 916722 sgd_solver.cpp:106] Iteration 4759000, lr = 0.01
I0901 16:40:09.465948 916722 solver.cpp:218] Iteration 4759500 (16.7929 iter/s, 29.7746s/500 iters), loss = 0.183297
I0901 16:40:09.466002 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.183295 (* 1 = 0.183295 loss)
I0901 16:40:09.466013 916722 sgd_solver.cpp:106] Iteration 4759500, lr = 0.01
I0901 16:40:39.245330 916722 solver.cpp:218] Iteration 4760000 (16.7902 iter/s, 29.7793s/500 iters), loss = 0.15124
I0901 16:40:39.245391 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.151239 (* 1 = 0.151239 loss)
I0901 16:40:39.245399 916722 sgd_solver.cpp:106] Iteration 4760000, lr = 0.01
I0901 16:41:09.023398 916722 solver.cpp:218] Iteration 4760500 (16.7909 iter/s, 29.778s/500 iters), loss = 0.15847
I0901 16:41:09.023452 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.158468 (* 1 = 0.158468 loss)
I0901 16:41:09.023461 916722 sgd_solver.cpp:106] Iteration 4760500, lr = 0.01
I0901 16:41:38.799551 916722 solver.cpp:218] Iteration 4761000 (16.792 iter/s, 29.7761s/500 iters), loss = 0.0888375
I0901 16:41:38.799613 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0888358 (* 1 = 0.0888358 loss)
I0901 16:41:38.799623 916722 sgd_solver.cpp:106] Iteration 4761000, lr = 0.01
I0901 16:42:08.573699 916722 solver.cpp:218] Iteration 4761500 (16.7932 iter/s, 29.774s/500 iters), loss = 0.0176776
I0901 16:42:08.573755 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0176758 (* 1 = 0.0176758 loss)
I0901 16:42:08.573762 916722 sgd_solver.cpp:106] Iteration 4761500, lr = 0.01
I0901 16:42:38.347751 916722 solver.cpp:218] Iteration 4762000 (16.7932 iter/s, 29.774s/500 iters), loss = 0.0671234
I0901 16:42:38.347811 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0671218 (* 1 = 0.0671218 loss)
I0901 16:42:38.347820 916722 sgd_solver.cpp:106] Iteration 4762000, lr = 0.01
I0901 16:43:08.128743 916722 solver.cpp:218] Iteration 4762500 (16.7893 iter/s, 29.7809s/500 iters), loss = 0.0714697
I0901 16:43:08.128794 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0714681 (* 1 = 0.0714681 loss)
I0901 16:43:08.128803 916722 sgd_solver.cpp:106] Iteration 4762500, lr = 0.01
I0901 16:43:37.907939 916722 solver.cpp:218] Iteration 4763000 (16.7903 iter/s, 29.7791s/500 iters), loss = 0.0508067
I0901 16:43:37.908000 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0508052 (* 1 = 0.0508052 loss)
I0901 16:43:37.908008 916722 sgd_solver.cpp:106] Iteration 4763000, lr = 0.01
I0901 16:44:07.685756 916722 solver.cpp:218] Iteration 4763500 (16.7911 iter/s, 29.7777s/500 iters), loss = 0.0993777
I0901 16:44:07.685811 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.099376 (* 1 = 0.099376 loss)
I0901 16:44:07.685819 916722 sgd_solver.cpp:106] Iteration 4763500, lr = 0.01
I0901 16:44:37.453938 916722 solver.cpp:218] Iteration 4764000 (16.7965 iter/s, 29.7681s/500 iters), loss = 0.151275
I0901 16:44:37.454008 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.151274 (* 1 = 0.151274 loss)
I0901 16:44:37.454016 916722 sgd_solver.cpp:106] Iteration 4764000, lr = 0.01
I0901 16:45:07.232504 916722 solver.cpp:218] Iteration 4764500 (16.7907 iter/s, 29.7785s/500 iters), loss = 0.077186
I0901 16:45:07.232571 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0771843 (* 1 = 0.0771843 loss)
I0901 16:45:07.232580 916722 sgd_solver.cpp:106] Iteration 4764500, lr = 0.01
I0901 16:45:37.012953 916722 solver.cpp:218] Iteration 4765000 (16.7896 iter/s, 29.7803s/500 iters), loss = 0.137108
I0901 16:45:37.013012 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.137107 (* 1 = 0.137107 loss)
I0901 16:45:37.013021 916722 sgd_solver.cpp:106] Iteration 4765000, lr = 0.01
I0901 16:46:06.793928 916722 solver.cpp:218] Iteration 4765500 (16.7893 iter/s, 29.7809s/500 iters), loss = 0.0196104
I0901 16:46:06.793982 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0196085 (* 1 = 0.0196085 loss)
I0901 16:46:06.793992 916722 sgd_solver.cpp:106] Iteration 4765500, lr = 0.01
I0901 16:46:36.573815 916722 solver.cpp:218] Iteration 4766000 (16.7899 iter/s, 29.7798s/500 iters), loss = 0.152545
I0901 16:46:36.573892 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152543 (* 1 = 0.152543 loss)
I0901 16:46:36.573901 916722 sgd_solver.cpp:106] Iteration 4766000, lr = 0.01
I0901 16:47:06.353157 916722 solver.cpp:218] Iteration 4766500 (16.7902 iter/s, 29.7792s/500 iters), loss = 0.159345
I0901 16:47:06.353214 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159343 (* 1 = 0.159343 loss)
I0901 16:47:06.353224 916722 sgd_solver.cpp:106] Iteration 4766500, lr = 0.01
I0901 16:47:36.125452 916722 solver.cpp:218] Iteration 4767000 (16.7942 iter/s, 29.7722s/500 iters), loss = 0.229123
I0901 16:47:36.125512 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.229121 (* 1 = 0.229121 loss)
I0901 16:47:36.125520 916722 sgd_solver.cpp:106] Iteration 4767000, lr = 0.01
I0901 16:48:05.901702 916722 solver.cpp:218] Iteration 4767500 (16.792 iter/s, 29.7761s/500 iters), loss = 0.133695
I0901 16:48:05.901757 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133693 (* 1 = 0.133693 loss)
I0901 16:48:05.901768 916722 sgd_solver.cpp:106] Iteration 4767500, lr = 0.01
I0901 16:48:35.680850 916722 solver.cpp:218] Iteration 4768000 (16.7904 iter/s, 29.7789s/500 iters), loss = 0.197512
I0901 16:48:35.680909 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.19751 (* 1 = 0.19751 loss)
I0901 16:48:35.680917 916722 sgd_solver.cpp:106] Iteration 4768000, lr = 0.01
I0901 16:49:05.455932 916722 solver.cpp:218] Iteration 4768500 (16.7927 iter/s, 29.7749s/500 iters), loss = 0.254632
I0901 16:49:05.455982 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.25463 (* 1 = 0.25463 loss)
I0901 16:49:05.455992 916722 sgd_solver.cpp:106] Iteration 4768500, lr = 0.01
I0901 16:49:35.237015 916722 solver.cpp:218] Iteration 4769000 (16.7893 iter/s, 29.7809s/500 iters), loss = 0.251171
I0901 16:49:35.237072 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.251169 (* 1 = 0.251169 loss)
I0901 16:49:35.237080 916722 sgd_solver.cpp:106] Iteration 4769000, lr = 0.01
I0901 16:50:05.014648 916722 solver.cpp:218] Iteration 4769500 (16.7912 iter/s, 29.7774s/500 iters), loss = 0.151086
I0901 16:50:05.014695 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.151084 (* 1 = 0.151084 loss)
I0901 16:50:05.014704 916722 sgd_solver.cpp:106] Iteration 4769500, lr = 0.01
I0901 16:50:34.798776 916722 solver.cpp:218] Iteration 4770000 (16.7876 iter/s, 29.7839s/500 iters), loss = 0.143341
I0901 16:50:34.798835 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.143339 (* 1 = 0.143339 loss)
I0901 16:50:34.798842 916722 sgd_solver.cpp:106] Iteration 4770000, lr = 0.01
I0901 16:51:04.571696 916722 solver.cpp:218] Iteration 4770500 (16.7939 iter/s, 29.7727s/500 iters), loss = 0.115679
I0901 16:51:04.571748 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115677 (* 1 = 0.115677 loss)
I0901 16:51:04.571758 916722 sgd_solver.cpp:106] Iteration 4770500, lr = 0.01
I0901 16:51:34.340452 916722 solver.cpp:218] Iteration 4771000 (16.7962 iter/s, 29.7686s/500 iters), loss = 0.11375
I0901 16:51:34.340835 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.113748 (* 1 = 0.113748 loss)
I0901 16:51:34.340844 916722 sgd_solver.cpp:106] Iteration 4771000, lr = 0.01
I0901 16:52:04.119606 916722 solver.cpp:218] Iteration 4771500 (16.7906 iter/s, 29.7786s/500 iters), loss = 0.133414
I0901 16:52:04.119658 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133412 (* 1 = 0.133412 loss)
I0901 16:52:04.119668 916722 sgd_solver.cpp:106] Iteration 4771500, lr = 0.01
I0901 16:52:33.900249 916722 solver.cpp:218] Iteration 4772000 (16.7895 iter/s, 29.7805s/500 iters), loss = 0.197407
I0901 16:52:33.900308 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.197405 (* 1 = 0.197405 loss)
I0901 16:52:33.900316 916722 sgd_solver.cpp:106] Iteration 4772000, lr = 0.01
I0901 16:53:03.680316 916722 solver.cpp:218] Iteration 4772500 (16.7899 iter/s, 29.7799s/500 iters), loss = 0.0909369
I0901 16:53:03.680368 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.090935 (* 1 = 0.090935 loss)
I0901 16:53:03.680379 916722 sgd_solver.cpp:106] Iteration 4772500, lr = 0.01
I0901 16:53:33.462594 916722 solver.cpp:218] Iteration 4773000 (16.7886 iter/s, 29.7821s/500 iters), loss = 0.0727564
I0901 16:53:33.462654 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0727545 (* 1 = 0.0727545 loss)
I0901 16:53:33.462663 916722 sgd_solver.cpp:106] Iteration 4773000, lr = 0.01
I0901 16:54:03.242252 916722 solver.cpp:218] Iteration 4773500 (16.7901 iter/s, 29.7795s/500 iters), loss = 0.143442
I0901 16:54:03.242306 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.14344 (* 1 = 0.14344 loss)
I0901 16:54:03.242316 916722 sgd_solver.cpp:106] Iteration 4773500, lr = 0.01
I0901 16:54:33.022722 916722 solver.cpp:218] Iteration 4774000 (16.7896 iter/s, 29.7803s/500 iters), loss = 0.217411
I0901 16:54:33.022776 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.217409 (* 1 = 0.217409 loss)
I0901 16:54:33.022785 916722 sgd_solver.cpp:106] Iteration 4774000, lr = 0.01
I0901 16:55:02.797297 916722 solver.cpp:218] Iteration 4774500 (16.7929 iter/s, 29.7744s/500 iters), loss = 0.27626
I0901 16:55:02.797348 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.276258 (* 1 = 0.276258 loss)
I0901 16:55:02.797358 916722 sgd_solver.cpp:106] Iteration 4774500, lr = 0.01
I0901 16:55:32.572950 916722 solver.cpp:218] Iteration 4775000 (16.7923 iter/s, 29.7755s/500 iters), loss = 0.308982
I0901 16:55:32.573010 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.30898 (* 1 = 0.30898 loss)
I0901 16:55:32.573019 916722 sgd_solver.cpp:106] Iteration 4775000, lr = 0.01
I0901 16:56:02.351248 916722 solver.cpp:218] Iteration 4775500 (16.7908 iter/s, 29.7781s/500 iters), loss = 0.0305948
I0901 16:56:02.351300 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0305927 (* 1 = 0.0305927 loss)
I0901 16:56:02.351310 916722 sgd_solver.cpp:106] Iteration 4775500, lr = 0.01
I0901 16:56:32.134205 916722 solver.cpp:218] Iteration 4776000 (16.7882 iter/s, 29.7828s/500 iters), loss = 0.123814
I0901 16:56:32.134266 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.123812 (* 1 = 0.123812 loss)
I0901 16:56:32.134275 916722 sgd_solver.cpp:106] Iteration 4776000, lr = 0.01
I0901 16:57:01.917076 916722 solver.cpp:218] Iteration 4776500 (16.7883 iter/s, 29.7827s/500 iters), loss = 0.267742
I0901 16:57:01.917129 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.26774 (* 1 = 0.26774 loss)
I0901 16:57:01.917138 916722 sgd_solver.cpp:106] Iteration 4776500, lr = 0.01
I0901 16:57:31.701545 916722 solver.cpp:218] Iteration 4777000 (16.7874 iter/s, 29.7843s/500 iters), loss = 0.131877
I0901 16:57:31.701606 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.131875 (* 1 = 0.131875 loss)
I0901 16:57:31.701614 916722 sgd_solver.cpp:106] Iteration 4777000, lr = 0.01
I0901 16:58:01.473927 916722 solver.cpp:218] Iteration 4777500 (16.7942 iter/s, 29.7722s/500 iters), loss = 0.132807
I0901 16:58:01.473990 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.132805 (* 1 = 0.132805 loss)
I0901 16:58:01.473999 916722 sgd_solver.cpp:106] Iteration 4777500, lr = 0.01
I0901 16:58:31.249094 916722 solver.cpp:218] Iteration 4778000 (16.7926 iter/s, 29.775s/500 iters), loss = 0.163267
I0901 16:58:31.249166 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.163265 (* 1 = 0.163265 loss)
I0901 16:58:31.249173 916722 sgd_solver.cpp:106] Iteration 4778000, lr = 0.01
I0901 16:59:01.030982 916722 solver.cpp:218] Iteration 4778500 (16.7888 iter/s, 29.7817s/500 iters), loss = 0.159434
I0901 16:59:01.031033 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.159432 (* 1 = 0.159432 loss)
I0901 16:59:01.031041 916722 sgd_solver.cpp:106] Iteration 4778500, lr = 0.01
I0901 16:59:30.812755 916722 solver.cpp:218] Iteration 4779000 (16.7889 iter/s, 29.7816s/500 iters), loss = 0.174119
I0901 16:59:30.812817 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.174117 (* 1 = 0.174117 loss)
I0901 16:59:30.812826 916722 sgd_solver.cpp:106] Iteration 4779000, lr = 0.01
I0901 17:00:00.599251 916722 solver.cpp:218] Iteration 4779500 (16.7862 iter/s, 29.7863s/500 iters), loss = 0.0391756
I0901 17:00:00.599304 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0391735 (* 1 = 0.0391735 loss)
I0901 17:00:00.599313 916722 sgd_solver.cpp:106] Iteration 4779500, lr = 0.01
I0901 17:00:30.377359 916722 solver.cpp:218] Iteration 4780000 (16.7909 iter/s, 29.778s/500 iters), loss = 0.0946648
I0901 17:00:30.377418 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0946627 (* 1 = 0.0946627 loss)
I0901 17:00:30.377427 916722 sgd_solver.cpp:106] Iteration 4780000, lr = 0.01
I0901 17:01:00.163697 916722 solver.cpp:218] Iteration 4780500 (16.7863 iter/s, 29.7862s/500 iters), loss = 0.104589
I0901 17:01:00.163749 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.104587 (* 1 = 0.104587 loss)
I0901 17:01:00.163758 916722 sgd_solver.cpp:106] Iteration 4780500, lr = 0.01
I0901 17:01:29.950991 916722 solver.cpp:218] Iteration 4781000 (16.7858 iter/s, 29.7872s/500 iters), loss = 0.0384164
I0901 17:01:29.951051 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0384145 (* 1 = 0.0384145 loss)
I0901 17:01:29.951059 916722 sgd_solver.cpp:106] Iteration 4781000, lr = 0.01
I0901 17:01:59.741115 916722 solver.cpp:218] Iteration 4781500 (16.7842 iter/s, 29.79s/500 iters), loss = 0.295895
I0901 17:01:59.741168 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.295893 (* 1 = 0.295893 loss)
I0901 17:01:59.741178 916722 sgd_solver.cpp:106] Iteration 4781500, lr = 0.01
I0901 17:02:29.523746 916722 solver.cpp:218] Iteration 4782000 (16.7884 iter/s, 29.7825s/500 iters), loss = 0.192194
I0901 17:02:29.523802 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.192192 (* 1 = 0.192192 loss)
I0901 17:02:29.523810 916722 sgd_solver.cpp:106] Iteration 4782000, lr = 0.01
I0901 17:02:59.309355 916722 solver.cpp:218] Iteration 4782500 (16.7867 iter/s, 29.7855s/500 iters), loss = 0.1082
I0901 17:02:59.309412 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.108198 (* 1 = 0.108198 loss)
I0901 17:02:59.309422 916722 sgd_solver.cpp:106] Iteration 4782500, lr = 0.01
I0901 17:03:29.093109 916722 solver.cpp:218] Iteration 4783000 (16.7878 iter/s, 29.7836s/500 iters), loss = 0.0382841
I0901 17:03:29.093169 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0382821 (* 1 = 0.0382821 loss)
I0901 17:03:29.093178 916722 sgd_solver.cpp:106] Iteration 4783000, lr = 0.01
I0901 17:03:58.868726 916722 solver.cpp:218] Iteration 4783500 (16.7923 iter/s, 29.7755s/500 iters), loss = 0.404647
I0901 17:03:58.868791 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.404645 (* 1 = 0.404645 loss)
I0901 17:03:58.868803 916722 sgd_solver.cpp:106] Iteration 4783500, lr = 0.01
I0901 17:04:28.661453 916722 solver.cpp:218] Iteration 4784000 (16.7827 iter/s, 29.7926s/500 iters), loss = 0.110884
I0901 17:04:28.661527 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110882 (* 1 = 0.110882 loss)
I0901 17:04:28.661536 916722 sgd_solver.cpp:106] Iteration 4784000, lr = 0.01
I0901 17:04:58.451509 916722 solver.cpp:218] Iteration 4784500 (16.7842 iter/s, 29.7899s/500 iters), loss = 0.247646
I0901 17:04:58.451562 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.247644 (* 1 = 0.247644 loss)
I0901 17:04:58.451572 916722 sgd_solver.cpp:106] Iteration 4784500, lr = 0.01
I0901 17:05:28.242377 916722 solver.cpp:218] Iteration 4785000 (16.7837 iter/s, 29.7907s/500 iters), loss = 0.0363541
I0901 17:05:28.242436 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0363525 (* 1 = 0.0363525 loss)
I0901 17:05:28.242444 916722 sgd_solver.cpp:106] Iteration 4785000, lr = 0.01
I0901 17:05:58.032841 916722 solver.cpp:218] Iteration 4785500 (16.784 iter/s, 29.7903s/500 iters), loss = 0.307413
I0901 17:05:58.032893 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.307411 (* 1 = 0.307411 loss)
I0901 17:05:58.032903 916722 sgd_solver.cpp:106] Iteration 4785500, lr = 0.01
I0901 17:06:27.815591 916722 solver.cpp:218] Iteration 4786000 (16.7883 iter/s, 29.7826s/500 iters), loss = 0.203135
I0901 17:06:27.815649 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.203133 (* 1 = 0.203133 loss)
I0901 17:06:27.815658 916722 sgd_solver.cpp:106] Iteration 4786000, lr = 0.01
I0901 17:06:57.592818 916722 solver.cpp:218] Iteration 4786500 (16.7914 iter/s, 29.7771s/500 iters), loss = 0.131072
I0901 17:06:57.592869 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.13107 (* 1 = 0.13107 loss)
I0901 17:06:57.592878 916722 sgd_solver.cpp:106] Iteration 4786500, lr = 0.01
I0901 17:07:27.375140 916722 solver.cpp:218] Iteration 4787000 (16.7886 iter/s, 29.7822s/500 iters), loss = 0.189018
I0901 17:07:27.375200 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.189016 (* 1 = 0.189016 loss)
I0901 17:07:27.375208 916722 sgd_solver.cpp:106] Iteration 4787000, lr = 0.01
I0901 17:07:57.155197 916722 solver.cpp:218] Iteration 4787500 (16.7898 iter/s, 29.7799s/500 iters), loss = 0.101961
I0901 17:07:57.155251 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101959 (* 1 = 0.101959 loss)
I0901 17:07:57.155261 916722 sgd_solver.cpp:106] Iteration 4787500, lr = 0.01
I0901 17:08:26.924470 916722 solver.cpp:218] Iteration 4788000 (16.7959 iter/s, 29.7691s/500 iters), loss = 0.0399466
I0901 17:08:26.924530 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0399448 (* 1 = 0.0399448 loss)
I0901 17:08:26.924540 916722 sgd_solver.cpp:106] Iteration 4788000, lr = 0.01
I0901 17:08:56.704164 916722 solver.cpp:218] Iteration 4788500 (16.79 iter/s, 29.7796s/500 iters), loss = 0.00599488
I0901 17:08:56.704217 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.00599302 (* 1 = 0.00599302 loss)
I0901 17:08:56.704226 916722 sgd_solver.cpp:106] Iteration 4788500, lr = 0.01
I0901 17:09:26.479743 916722 solver.cpp:218] Iteration 4789000 (16.7924 iter/s, 29.7755s/500 iters), loss = 0.0180513
I0901 17:09:26.479804 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0180495 (* 1 = 0.0180495 loss)
I0901 17:09:26.479812 916722 sgd_solver.cpp:106] Iteration 4789000, lr = 0.01
I0901 17:09:56.262064 916722 solver.cpp:218] Iteration 4789500 (16.7886 iter/s, 29.7822s/500 iters), loss = 0.039189
I0901 17:09:56.262120 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0391872 (* 1 = 0.0391872 loss)
I0901 17:09:56.262130 916722 sgd_solver.cpp:106] Iteration 4789500, lr = 0.01
I0901 17:10:26.042210 916722 solver.cpp:218] Iteration 4790000 (16.7898 iter/s, 29.78s/500 iters), loss = 0.137613
I0901 17:10:26.042269 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.137611 (* 1 = 0.137611 loss)
I0901 17:10:26.042279 916722 sgd_solver.cpp:106] Iteration 4790000, lr = 0.01
I0901 17:10:55.823069 916722 solver.cpp:218] Iteration 4790500 (16.7894 iter/s, 29.7807s/500 iters), loss = 0.103399
I0901 17:10:55.823124 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.103398 (* 1 = 0.103398 loss)
I0901 17:10:55.823144 916722 sgd_solver.cpp:106] Iteration 4790500, lr = 0.01
I0901 17:11:25.600174 916722 solver.cpp:218] Iteration 4791000 (16.7915 iter/s, 29.777s/500 iters), loss = 0.0377913
I0901 17:11:25.600246 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0377897 (* 1 = 0.0377897 loss)
I0901 17:11:25.600255 916722 sgd_solver.cpp:106] Iteration 4791000, lr = 0.01
I0901 17:11:55.377375 916722 solver.cpp:218] Iteration 4791500 (16.7915 iter/s, 29.7771s/500 iters), loss = 0.0572659
I0901 17:11:55.377429 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0572641 (* 1 = 0.0572641 loss)
I0901 17:11:55.377439 916722 sgd_solver.cpp:106] Iteration 4791500, lr = 0.01
I0901 17:12:25.158718 916722 solver.cpp:218] Iteration 4792000 (16.7891 iter/s, 29.7812s/500 iters), loss = 0.149151
I0901 17:12:25.158778 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.149149 (* 1 = 0.149149 loss)
I0901 17:12:25.158787 916722 sgd_solver.cpp:106] Iteration 4792000, lr = 0.01
I0901 17:12:54.942526 916722 solver.cpp:218] Iteration 4792500 (16.7877 iter/s, 29.7837s/500 iters), loss = 0.133688
I0901 17:12:54.942579 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133687 (* 1 = 0.133687 loss)
I0901 17:12:54.942589 916722 sgd_solver.cpp:106] Iteration 4792500, lr = 0.01
I0901 17:13:24.736670 916722 solver.cpp:218] Iteration 4793000 (16.7819 iter/s, 29.794s/500 iters), loss = 0.0601711
I0901 17:13:24.736727 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0601695 (* 1 = 0.0601695 loss)
I0901 17:13:24.736737 916722 sgd_solver.cpp:106] Iteration 4793000, lr = 0.01
I0901 17:13:54.518261 916722 solver.cpp:218] Iteration 4793500 (16.789 iter/s, 29.7815s/500 iters), loss = 0.0883974
I0901 17:13:54.518311 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0883959 (* 1 = 0.0883959 loss)
I0901 17:13:54.518321 916722 sgd_solver.cpp:106] Iteration 4793500, lr = 0.01
I0901 17:14:24.300211 916722 solver.cpp:218] Iteration 4794000 (16.7888 iter/s, 29.7818s/500 iters), loss = 0.239834
I0901 17:14:24.300272 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.239833 (* 1 = 0.239833 loss)
I0901 17:14:24.300280 916722 sgd_solver.cpp:106] Iteration 4794000, lr = 0.01
I0901 17:14:54.078620 916722 solver.cpp:218] Iteration 4794500 (16.7908 iter/s, 29.7783s/500 iters), loss = 0.0367532
I0901 17:14:54.078673 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0367519 (* 1 = 0.0367519 loss)
I0901 17:14:54.078682 916722 sgd_solver.cpp:106] Iteration 4794500, lr = 0.01
I0901 17:15:23.855994 916722 solver.cpp:218] Iteration 4795000 (16.7913 iter/s, 29.7773s/500 iters), loss = 0.312939
I0901 17:15:23.856055 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.312938 (* 1 = 0.312938 loss)
I0901 17:15:23.856063 916722 sgd_solver.cpp:106] Iteration 4795000, lr = 0.01
I0901 17:15:53.635079 916722 solver.cpp:218] Iteration 4795500 (16.7904 iter/s, 29.779s/500 iters), loss = 0.094346
I0901 17:15:53.635133 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0943446 (* 1 = 0.0943446 loss)
I0901 17:15:53.635143 916722 sgd_solver.cpp:106] Iteration 4795500, lr = 0.01
I0901 17:16:23.405557 916722 solver.cpp:218] Iteration 4796000 (16.7952 iter/s, 29.7704s/500 iters), loss = 0.110661
I0901 17:16:23.405618 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.11066 (* 1 = 0.11066 loss)
I0901 17:16:23.405627 916722 sgd_solver.cpp:106] Iteration 4796000, lr = 0.01
I0901 17:16:53.192277 916722 solver.cpp:218] Iteration 4796500 (16.7861 iter/s, 29.7866s/500 iters), loss = 0.0937973
I0901 17:16:53.192334 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.093796 (* 1 = 0.093796 loss)
I0901 17:16:53.192344 916722 sgd_solver.cpp:106] Iteration 4796500, lr = 0.01
I0901 17:17:22.968281 916722 solver.cpp:218] Iteration 4797000 (16.7921 iter/s, 29.7759s/500 iters), loss = 0.119906
I0901 17:17:22.968343 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.119904 (* 1 = 0.119904 loss)
I0901 17:17:22.968358 916722 sgd_solver.cpp:106] Iteration 4797000, lr = 0.01
I0901 17:17:52.749240 916722 solver.cpp:218] Iteration 4797500 (16.7893 iter/s, 29.7808s/500 iters), loss = 0.164005
I0901 17:17:52.749294 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.164004 (* 1 = 0.164004 loss)
I0901 17:17:52.749305 916722 sgd_solver.cpp:106] Iteration 4797500, lr = 0.01
I0901 17:18:22.524210 916722 solver.cpp:218] Iteration 4798000 (16.7927 iter/s, 29.7748s/500 iters), loss = 0.0737577
I0901 17:18:22.524266 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0737565 (* 1 = 0.0737565 loss)
I0901 17:18:22.524273 916722 sgd_solver.cpp:106] Iteration 4798000, lr = 0.01
I0901 17:18:52.306177 916722 solver.cpp:218] Iteration 4798500 (16.7888 iter/s, 29.7818s/500 iters), loss = 0.0711506
I0901 17:18:52.306233 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0711496 (* 1 = 0.0711496 loss)
I0901 17:18:52.306243 916722 sgd_solver.cpp:106] Iteration 4798500, lr = 0.01
I0901 17:19:22.087826 916722 solver.cpp:218] Iteration 4799000 (16.7889 iter/s, 29.7815s/500 iters), loss = 0.211612
I0901 17:19:22.087884 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.211611 (* 1 = 0.211611 loss)
I0901 17:19:22.087893 916722 sgd_solver.cpp:106] Iteration 4799000, lr = 0.01
I0901 17:19:51.869957 916722 solver.cpp:218] Iteration 4799500 (16.7887 iter/s, 29.782s/500 iters), loss = 0.0701552
I0901 17:19:51.870012 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0701544 (* 1 = 0.0701544 loss)
I0901 17:19:51.870023 916722 sgd_solver.cpp:106] Iteration 4799500, lr = 0.01
I0901 17:20:21.587556 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_4800000.caffemodel
I0901 17:20:21.607096 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_4800000.solverstate
I0901 17:20:21.613194 916722 solver.cpp:330] Iteration 4800000, Testing net (#0)
I0901 17:20:37.082233 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8951
I0901 17:20:37.082276 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.359777 (* 1 = 0.359777 loss)
I0901 17:20:37.140789 916722 solver.cpp:218] Iteration 4800000 (11.0447 iter/s, 45.2707s/500 iters), loss = 0.0485451
I0901 17:20:37.140815 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0485443 (* 1 = 0.0485443 loss)
I0901 17:20:37.140823 916722 sgd_solver.cpp:106] Iteration 4800000, lr = 0.01
I0901 17:21:06.900063 916722 solver.cpp:218] Iteration 4800500 (16.8016 iter/s, 29.7591s/500 iters), loss = 0.163607
I0901 17:21:06.900122 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.163607 (* 1 = 0.163607 loss)
I0901 17:21:06.900130 916722 sgd_solver.cpp:106] Iteration 4800500, lr = 0.01
I0901 17:21:36.672134 916722 solver.cpp:218] Iteration 4801000 (16.7943 iter/s, 29.7719s/500 iters), loss = 0.136084
I0901 17:21:36.672186 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.136084 (* 1 = 0.136084 loss)
I0901 17:21:36.672196 916722 sgd_solver.cpp:106] Iteration 4801000, lr = 0.01
I0901 17:22:06.444100 916722 solver.cpp:218] Iteration 4801500 (16.7945 iter/s, 29.7717s/500 iters), loss = 0.0363168
I0901 17:22:06.444162 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0363165 (* 1 = 0.0363165 loss)
I0901 17:22:06.444171 916722 sgd_solver.cpp:106] Iteration 4801500, lr = 0.01
I0901 17:22:36.226531 916722 solver.cpp:218] Iteration 4802000 (16.7887 iter/s, 29.7819s/500 iters), loss = 0.167735
I0901 17:22:36.226583 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.167735 (* 1 = 0.167735 loss)
I0901 17:22:36.226590 916722 sgd_solver.cpp:106] Iteration 4802000, lr = 0.01
I0901 17:23:06.000792 916722 solver.cpp:218] Iteration 4802500 (16.7933 iter/s, 29.7737s/500 iters), loss = 0.0534293
I0901 17:23:06.000869 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0534289 (* 1 = 0.0534289 loss)
I0901 17:23:06.000887 916722 sgd_solver.cpp:106] Iteration 4802500, lr = 0.01
I0901 17:23:35.783501 916722 solver.cpp:218] Iteration 4803000 (16.7886 iter/s, 29.7822s/500 iters), loss = 0.0656964
I0901 17:23:35.783555 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.065696 (* 1 = 0.065696 loss)
I0901 17:23:35.783562 916722 sgd_solver.cpp:106] Iteration 4803000, lr = 0.01
I0901 17:24:05.566025 916722 solver.cpp:218] Iteration 4803500 (16.7886 iter/s, 29.782s/500 iters), loss = 0.0650511
I0901 17:24:05.566083 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0650507 (* 1 = 0.0650507 loss)
I0901 17:24:05.566092 916722 sgd_solver.cpp:106] Iteration 4803500, lr = 0.01
I0901 17:24:35.345008 916722 solver.cpp:218] Iteration 4804000 (16.7906 iter/s, 29.7785s/500 iters), loss = 0.129983
I0901 17:24:35.345058 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.129982 (* 1 = 0.129982 loss)
I0901 17:24:35.345067 916722 sgd_solver.cpp:106] Iteration 4804000, lr = 0.01
I0901 17:25:05.125236 916722 solver.cpp:218] Iteration 4804500 (16.7899 iter/s, 29.7798s/500 iters), loss = 0.117497
I0901 17:25:05.125293 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.117497 (* 1 = 0.117497 loss)
I0901 17:25:05.125300 916722 sgd_solver.cpp:106] Iteration 4804500, lr = 0.01
I0901 17:25:34.907951 916722 solver.cpp:218] Iteration 4805000 (16.7885 iter/s, 29.7823s/500 iters), loss = 0.333471
I0901 17:25:34.908002 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.33347 (* 1 = 0.33347 loss)
I0901 17:25:34.908011 916722 sgd_solver.cpp:106] Iteration 4805000, lr = 0.01
I0901 17:26:04.686508 916722 solver.cpp:218] Iteration 4805500 (16.7908 iter/s, 29.7781s/500 iters), loss = 0.121644
I0901 17:26:04.686569 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.121644 (* 1 = 0.121644 loss)
I0901 17:26:04.686578 916722 sgd_solver.cpp:106] Iteration 4805500, lr = 0.01
I0901 17:26:34.469926 916722 solver.cpp:218] Iteration 4806000 (16.7881 iter/s, 29.783s/500 iters), loss = 0.0114211
I0901 17:26:34.469982 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.011421 (* 1 = 0.011421 loss)
I0901 17:26:34.469992 916722 sgd_solver.cpp:106] Iteration 4806000, lr = 0.01
I0901 17:27:04.248054 916722 solver.cpp:218] Iteration 4806500 (16.7911 iter/s, 29.7777s/500 iters), loss = 0.0744129
I0901 17:27:04.248112 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0744128 (* 1 = 0.0744128 loss)
I0901 17:27:04.248121 916722 sgd_solver.cpp:106] Iteration 4806500, lr = 0.01
I0901 17:27:34.013425 916722 solver.cpp:218] Iteration 4807000 (16.7983 iter/s, 29.765s/500 iters), loss = 0.0772557
I0901 17:27:34.013476 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0772555 (* 1 = 0.0772555 loss)
I0901 17:27:34.013486 916722 sgd_solver.cpp:106] Iteration 4807000, lr = 0.01
I0901 17:28:03.794842 916722 solver.cpp:218] Iteration 4807500 (16.7892 iter/s, 29.781s/500 iters), loss = 0.0402922
I0901 17:28:03.794898 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0402922 (* 1 = 0.0402922 loss)
I0901 17:28:03.794905 916722 sgd_solver.cpp:106] Iteration 4807500, lr = 0.01
I0901 17:28:33.579682 916722 solver.cpp:218] Iteration 4808000 (16.7873 iter/s, 29.7845s/500 iters), loss = 0.115283
I0901 17:28:33.579735 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.115283 (* 1 = 0.115283 loss)
I0901 17:28:33.579746 916722 sgd_solver.cpp:106] Iteration 4808000, lr = 0.01
I0901 17:29:03.363330 916722 solver.cpp:218] Iteration 4808500 (16.7879 iter/s, 29.7833s/500 iters), loss = 0.00823487
I0901 17:29:03.363386 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.00823485 (* 1 = 0.00823485 loss)
I0901 17:29:03.363395 916722 sgd_solver.cpp:106] Iteration 4808500, lr = 0.01
I0901 17:29:33.143085 916722 solver.cpp:218] Iteration 4809000 (16.7901 iter/s, 29.7794s/500 iters), loss = 0.41788
I0901 17:29:33.143131 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.41788 (* 1 = 0.41788 loss)
I0901 17:29:33.143141 916722 sgd_solver.cpp:106] Iteration 4809000, lr = 0.01
I0901 17:30:02.913450 916722 solver.cpp:218] Iteration 4809500 (16.7954 iter/s, 29.77s/500 iters), loss = 0.0304189
I0901 17:30:02.913517 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0304189 (* 1 = 0.0304189 loss)
I0901 17:30:02.913525 916722 sgd_solver.cpp:106] Iteration 4809500, lr = 0.01
I0901 17:30:32.690497 916722 solver.cpp:218] Iteration 4810000 (16.7917 iter/s, 29.7767s/500 iters), loss = 0.32102
I0901 17:30:32.690552 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.32102 (* 1 = 0.32102 loss)
I0901 17:30:32.690562 916722 sgd_solver.cpp:106] Iteration 4810000, lr = 0.01
I0901 17:31:02.472813 916722 solver.cpp:218] Iteration 4810500 (16.7887 iter/s, 29.782s/500 iters), loss = 0.157985
I0901 17:31:02.472872 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.157985 (* 1 = 0.157985 loss)
I0901 17:31:02.472882 916722 sgd_solver.cpp:106] Iteration 4810500, lr = 0.01
I0901 17:31:32.248307 916722 solver.cpp:218] Iteration 4811000 (16.7925 iter/s, 29.7752s/500 iters), loss = 0.112375
I0901 17:31:32.248363 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112375 (* 1 = 0.112375 loss)
I0901 17:31:32.248370 916722 sgd_solver.cpp:106] Iteration 4811000, lr = 0.01
I0901 17:32:02.021080 916722 solver.cpp:218] Iteration 4811500 (16.794 iter/s, 29.7725s/500 iters), loss = 0.105818
I0901 17:32:02.021137 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105818 (* 1 = 0.105818 loss)
I0901 17:32:02.021147 916722 sgd_solver.cpp:106] Iteration 4811500, lr = 0.01
I0901 17:32:31.802759 916722 solver.cpp:218] Iteration 4812000 (16.789 iter/s, 29.7814s/500 iters), loss = 0.0781222
I0901 17:32:31.802814 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0781221 (* 1 = 0.0781221 loss)
I0901 17:32:31.802822 916722 sgd_solver.cpp:106] Iteration 4812000, lr = 0.01
I0901 17:33:01.579474 916722 solver.cpp:218] Iteration 4812500 (16.7918 iter/s, 29.7764s/500 iters), loss = 0.109194
I0901 17:33:01.579531 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109194 (* 1 = 0.109194 loss)
I0901 17:33:01.579540 916722 sgd_solver.cpp:106] Iteration 4812500, lr = 0.01
I0901 17:33:31.358400 916722 solver.cpp:218] Iteration 4813000 (16.7906 iter/s, 29.7786s/500 iters), loss = 0.1174
I0901 17:33:31.358450 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.1174 (* 1 = 0.1174 loss)
I0901 17:33:31.358458 916722 sgd_solver.cpp:106] Iteration 4813000, lr = 0.01
I0901 17:34:01.140384 916722 solver.cpp:218] Iteration 4813500 (16.7888 iter/s, 29.7817s/500 iters), loss = 0.119336
I0901 17:34:01.140447 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.119336 (* 1 = 0.119336 loss)
I0901 17:34:01.140456 916722 sgd_solver.cpp:106] Iteration 4813500, lr = 0.01
I0901 17:34:30.911170 916722 solver.cpp:218] Iteration 4814000 (16.7952 iter/s, 29.7705s/500 iters), loss = 0.20379
I0901 17:34:30.911224 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.20379 (* 1 = 0.20379 loss)
I0901 17:34:30.911233 916722 sgd_solver.cpp:106] Iteration 4814000, lr = 0.01
I0901 17:35:00.686484 916722 solver.cpp:218] Iteration 4814500 (16.7926 iter/s, 29.775s/500 iters), loss = 0.0674399
I0901 17:35:00.686542 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.06744 (* 1 = 0.06744 loss)
I0901 17:35:00.686549 916722 sgd_solver.cpp:106] Iteration 4814500, lr = 0.01
I0901 17:35:30.461097 916722 solver.cpp:218] Iteration 4815000 (16.793 iter/s, 29.7743s/500 iters), loss = 0.0596082
I0901 17:35:30.461149 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0596083 (* 1 = 0.0596083 loss)
I0901 17:35:30.461158 916722 sgd_solver.cpp:106] Iteration 4815000, lr = 0.01
I0901 17:36:00.241210 916722 solver.cpp:218] Iteration 4815500 (16.7899 iter/s, 29.7798s/500 iters), loss = 0.430824
I0901 17:36:00.241269 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.430825 (* 1 = 0.430825 loss)
I0901 17:36:00.241278 916722 sgd_solver.cpp:106] Iteration 4815500, lr = 0.01
I0901 17:36:30.022209 916722 solver.cpp:218] Iteration 4816000 (16.7894 iter/s, 29.7807s/500 iters), loss = 0.166936
I0901 17:36:30.022274 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.166936 (* 1 = 0.166936 loss)
I0901 17:36:30.022284 916722 sgd_solver.cpp:106] Iteration 4816000, lr = 0.01
I0901 17:36:59.797257 916722 solver.cpp:218] Iteration 4816500 (16.7927 iter/s, 29.7748s/500 iters), loss = 0.148198
I0901 17:36:59.797327 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.148199 (* 1 = 0.148199 loss)
I0901 17:36:59.797334 916722 sgd_solver.cpp:106] Iteration 4816500, lr = 0.01
I0901 17:37:29.571429 916722 solver.cpp:218] Iteration 4817000 (16.7932 iter/s, 29.7739s/500 iters), loss = 0.105353
I0901 17:37:29.571481 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105354 (* 1 = 0.105354 loss)
I0901 17:37:29.571491 916722 sgd_solver.cpp:106] Iteration 4817000, lr = 0.01
I0901 17:37:59.344039 916722 solver.cpp:218] Iteration 4817500 (16.7941 iter/s, 29.7724s/500 iters), loss = 0.164434
I0901 17:37:59.344096 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.164435 (* 1 = 0.164435 loss)
I0901 17:37:59.344105 916722 sgd_solver.cpp:106] Iteration 4817500, lr = 0.01
I0901 17:38:29.120968 916722 solver.cpp:218] Iteration 4818000 (16.7917 iter/s, 29.7767s/500 iters), loss = 0.292342
I0901 17:38:29.121019 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.292343 (* 1 = 0.292343 loss)
I0901 17:38:29.121028 916722 sgd_solver.cpp:106] Iteration 4818000, lr = 0.01
I0901 17:38:58.909210 916722 solver.cpp:218] Iteration 4818500 (16.7853 iter/s, 29.788s/500 iters), loss = 0.188272
I0901 17:38:58.909274 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.188273 (* 1 = 0.188273 loss)
I0901 17:38:58.909283 916722 sgd_solver.cpp:106] Iteration 4818500, lr = 0.01
I0901 17:39:28.683748 916722 solver.cpp:218] Iteration 4819000 (16.793 iter/s, 29.7743s/500 iters), loss = 0.124966
I0901 17:39:28.683804 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.124966 (* 1 = 0.124966 loss)
I0901 17:39:28.683812 916722 sgd_solver.cpp:106] Iteration 4819000, lr = 0.01
I0901 17:39:58.460733 916722 solver.cpp:218] Iteration 4819500 (16.7916 iter/s, 29.7767s/500 iters), loss = 0.0714757
I0901 17:39:58.460793 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0714762 (* 1 = 0.0714762 loss)
I0901 17:39:58.460803 916722 sgd_solver.cpp:106] Iteration 4819500, lr = 0.01
I0901 17:40:28.239151 916722 solver.cpp:218] Iteration 4820000 (16.7908 iter/s, 29.7782s/500 iters), loss = 0.0727764
I0901 17:40:28.239207 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0727767 (* 1 = 0.0727767 loss)
I0901 17:40:28.239217 916722 sgd_solver.cpp:106] Iteration 4820000, lr = 0.01
I0901 17:40:58.012239 916722 solver.cpp:218] Iteration 4820500 (16.7938 iter/s, 29.7728s/500 iters), loss = 0.0340171
I0901 17:40:58.012298 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0340174 (* 1 = 0.0340174 loss)
I0901 17:40:58.012307 916722 sgd_solver.cpp:106] Iteration 4820500, lr = 0.01
I0901 17:41:27.786773 916722 solver.cpp:218] Iteration 4821000 (16.793 iter/s, 29.7743s/500 iters), loss = 0.475895
I0901 17:41:27.786826 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.475895 (* 1 = 0.475895 loss)
I0901 17:41:27.786836 916722 sgd_solver.cpp:106] Iteration 4821000, lr = 0.01
I0901 17:41:57.561372 916722 solver.cpp:218] Iteration 4821500 (16.793 iter/s, 29.7744s/500 iters), loss = 0.0412747
I0901 17:41:57.561434 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0412752 (* 1 = 0.0412752 loss)
I0901 17:41:57.561442 916722 sgd_solver.cpp:106] Iteration 4821500, lr = 0.01
I0901 17:42:27.335287 916722 solver.cpp:218] Iteration 4822000 (16.7934 iter/s, 29.7737s/500 iters), loss = 0.0595729
I0901 17:42:27.335338 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0595733 (* 1 = 0.0595733 loss)
I0901 17:42:27.335348 916722 sgd_solver.cpp:106] Iteration 4822000, lr = 0.01
I0901 17:42:57.111622 916722 solver.cpp:218] Iteration 4822500 (16.792 iter/s, 29.7761s/500 iters), loss = 0.0446941
I0901 17:42:57.111697 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0446945 (* 1 = 0.0446945 loss)
I0901 17:42:57.111706 916722 sgd_solver.cpp:106] Iteration 4822500, lr = 0.01
I0901 17:43:26.886993 916722 solver.cpp:218] Iteration 4823000 (16.7925 iter/s, 29.7751s/500 iters), loss = 0.102851
I0901 17:43:26.887046 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.102851 (* 1 = 0.102851 loss)
I0901 17:43:26.887056 916722 sgd_solver.cpp:106] Iteration 4823000, lr = 0.01
I0901 17:43:56.655050 916722 solver.cpp:218] Iteration 4823500 (16.7967 iter/s, 29.7678s/500 iters), loss = 0.142004
I0901 17:43:56.655110 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.142004 (* 1 = 0.142004 loss)
I0901 17:43:56.655119 916722 sgd_solver.cpp:106] Iteration 4823500, lr = 0.01
I0901 17:44:26.462576 916722 solver.cpp:218] Iteration 4824000 (16.7744 iter/s, 29.8073s/500 iters), loss = 0.235648
I0901 17:44:26.462632 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.235648 (* 1 = 0.235648 loss)
I0901 17:44:26.462643 916722 sgd_solver.cpp:106] Iteration 4824000, lr = 0.01
I0901 17:44:56.254272 916722 solver.cpp:218] Iteration 4824500 (16.7833 iter/s, 29.7915s/500 iters), loss = 0.191202
I0901 17:44:56.254331 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.191202 (* 1 = 0.191202 loss)
I0901 17:44:56.254339 916722 sgd_solver.cpp:106] Iteration 4824500, lr = 0.01
I0901 17:45:26.041061 916722 solver.cpp:218] Iteration 4825000 (16.7861 iter/s, 29.7866s/500 iters), loss = 0.0920464
I0901 17:45:26.041116 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0920468 (* 1 = 0.0920468 loss)
I0901 17:45:26.041126 916722 sgd_solver.cpp:106] Iteration 4825000, lr = 0.01
I0901 17:45:55.828166 916722 solver.cpp:218] Iteration 4825500 (16.7859 iter/s, 29.7869s/500 iters), loss = 0.0168111
I0901 17:45:55.828227 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0168115 (* 1 = 0.0168115 loss)
I0901 17:45:55.828235 916722 sgd_solver.cpp:106] Iteration 4825500, lr = 0.01
I0901 17:46:25.621366 916722 solver.cpp:218] Iteration 4826000 (16.7825 iter/s, 29.793s/500 iters), loss = 0.0647343
I0901 17:46:25.621420 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0647347 (* 1 = 0.0647347 loss)
I0901 17:46:25.621431 916722 sgd_solver.cpp:106] Iteration 4826000, lr = 0.01
I0901 17:46:55.413681 916722 solver.cpp:218] Iteration 4826500 (16.783 iter/s, 29.7921s/500 iters), loss = 0.193407
I0901 17:46:55.413741 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.193408 (* 1 = 0.193408 loss)
I0901 17:46:55.413749 916722 sgd_solver.cpp:106] Iteration 4826500, lr = 0.01
I0901 17:47:25.209854 916722 solver.cpp:218] Iteration 4827000 (16.7808 iter/s, 29.796s/500 iters), loss = 0.0540281
I0901 17:47:25.209908 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0540286 (* 1 = 0.0540286 loss)
I0901 17:47:25.209918 916722 sgd_solver.cpp:106] Iteration 4827000, lr = 0.01
I0901 17:47:55.011479 916722 solver.cpp:218] Iteration 4827500 (16.7777 iter/s, 29.8014s/500 iters), loss = 0.0334996
I0901 17:47:55.011540 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0335 (* 1 = 0.0335 loss)
I0901 17:47:55.011549 916722 sgd_solver.cpp:106] Iteration 4827500, lr = 0.01
I0901 17:48:24.814894 916722 solver.cpp:218] Iteration 4828000 (16.7767 iter/s, 29.8032s/500 iters), loss = 0.227311
I0901 17:48:24.814949 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.227311 (* 1 = 0.227311 loss)
I0901 17:48:24.814957 916722 sgd_solver.cpp:106] Iteration 4828000, lr = 0.01
I0901 17:48:54.621755 916722 solver.cpp:218] Iteration 4828500 (16.7748 iter/s, 29.8067s/500 iters), loss = 0.111718
I0901 17:48:54.621816 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111718 (* 1 = 0.111718 loss)
I0901 17:48:54.621825 916722 sgd_solver.cpp:106] Iteration 4828500, lr = 0.01
I0901 17:49:24.426908 916722 solver.cpp:218] Iteration 4829000 (16.7757 iter/s, 29.805s/500 iters), loss = 0.14291
I0901 17:49:24.426959 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.14291 (* 1 = 0.14291 loss)
I0901 17:49:24.426982 916722 sgd_solver.cpp:106] Iteration 4829000, lr = 0.01
I0901 17:49:54.219437 916722 solver.cpp:218] Iteration 4829500 (16.7828 iter/s, 29.7924s/500 iters), loss = 0.0216049
I0901 17:49:54.219513 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0216051 (* 1 = 0.0216051 loss)
I0901 17:49:54.219522 916722 sgd_solver.cpp:106] Iteration 4829500, lr = 0.01
I0901 17:50:24.012641 916722 solver.cpp:218] Iteration 4830000 (16.7825 iter/s, 29.793s/500 iters), loss = 0.146002
I0901 17:50:24.012694 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.146002 (* 1 = 0.146002 loss)
I0901 17:50:24.012703 916722 sgd_solver.cpp:106] Iteration 4830000, lr = 0.01
I0901 17:50:53.816202 916722 solver.cpp:218] Iteration 4830500 (16.7766 iter/s, 29.8034s/500 iters), loss = 0.185131
I0901 17:50:53.816263 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.185132 (* 1 = 0.185132 loss)
I0901 17:50:53.816272 916722 sgd_solver.cpp:106] Iteration 4830500, lr = 0.01
I0901 17:51:23.629842 916722 solver.cpp:218] Iteration 4831000 (16.7709 iter/s, 29.8135s/500 iters), loss = 0.123421
I0901 17:51:23.629896 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.123421 (* 1 = 0.123421 loss)
I0901 17:51:23.629906 916722 sgd_solver.cpp:106] Iteration 4831000, lr = 0.01
I0901 17:51:53.438105 916722 solver.cpp:218] Iteration 4831500 (16.774 iter/s, 29.8081s/500 iters), loss = 0.174099
I0901 17:51:53.438164 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.1741 (* 1 = 0.1741 loss)
I0901 17:51:53.438174 916722 sgd_solver.cpp:106] Iteration 4831500, lr = 0.01
I0901 17:52:23.253170 916722 solver.cpp:218] Iteration 4832000 (16.7701 iter/s, 29.8149s/500 iters), loss = 0.124743
I0901 17:52:23.253224 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.124743 (* 1 = 0.124743 loss)
I0901 17:52:23.253234 916722 sgd_solver.cpp:106] Iteration 4832000, lr = 0.01
I0901 17:52:53.077390 916722 solver.cpp:218] Iteration 4832500 (16.765 iter/s, 29.8241s/500 iters), loss = 0.052039
I0901 17:52:53.077450 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0520393 (* 1 = 0.0520393 loss)
I0901 17:52:53.077458 916722 sgd_solver.cpp:106] Iteration 4832500, lr = 0.01
I0901 17:53:22.919793 916722 solver.cpp:218] Iteration 4833000 (16.7548 iter/s, 29.8422s/500 iters), loss = 0.187468
I0901 17:53:22.919847 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.187468 (* 1 = 0.187468 loss)
I0901 17:53:22.919857 916722 sgd_solver.cpp:106] Iteration 4833000, lr = 0.01
I0901 17:53:52.772830 916722 solver.cpp:218] Iteration 4833500 (16.7488 iter/s, 29.8529s/500 iters), loss = 0.0858756
I0901 17:53:52.772889 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0858759 (* 1 = 0.0858759 loss)
I0901 17:53:52.772898 916722 sgd_solver.cpp:106] Iteration 4833500, lr = 0.01
I0901 17:54:22.658805 916722 solver.cpp:218] Iteration 4834000 (16.7303 iter/s, 29.8858s/500 iters), loss = 0.0704618
I0901 17:54:22.658859 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.070462 (* 1 = 0.070462 loss)
I0901 17:54:22.658869 916722 sgd_solver.cpp:106] Iteration 4834000, lr = 0.01
I0901 17:54:52.610237 916722 solver.cpp:218] Iteration 4834500 (16.6938 iter/s, 29.9513s/500 iters), loss = 0.380255
I0901 17:54:52.610296 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.380255 (* 1 = 0.380255 loss)
I0901 17:54:52.610306 916722 sgd_solver.cpp:106] Iteration 4834500, lr = 0.01
I0901 17:55:22.564121 916722 solver.cpp:218] Iteration 4835000 (16.6924 iter/s, 29.9537s/500 iters), loss = 0.139507
I0901 17:55:22.564173 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139508 (* 1 = 0.139508 loss)
I0901 17:55:22.564183 916722 sgd_solver.cpp:106] Iteration 4835000, lr = 0.01
I0901 17:55:52.514889 916722 solver.cpp:218] Iteration 4835500 (16.6941 iter/s, 29.9506s/500 iters), loss = 0.0177447
I0901 17:55:52.514957 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0177448 (* 1 = 0.0177448 loss)
I0901 17:55:52.514971 916722 sgd_solver.cpp:106] Iteration 4835500, lr = 0.01
I0901 17:56:22.481215 916722 solver.cpp:218] Iteration 4836000 (16.6853 iter/s, 29.9664s/500 iters), loss = 0.23195
I0901 17:56:22.481268 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.23195 (* 1 = 0.23195 loss)
I0901 17:56:22.481278 916722 sgd_solver.cpp:106] Iteration 4836000, lr = 0.01
I0901 17:56:52.443042 916722 solver.cpp:218] Iteration 4836500 (16.6877 iter/s, 29.9621s/500 iters), loss = 0.0458438
I0901 17:56:52.443104 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0458439 (* 1 = 0.0458439 loss)
I0901 17:56:52.443112 916722 sgd_solver.cpp:106] Iteration 4836500, lr = 0.01
I0901 17:57:22.404417 916722 solver.cpp:218] Iteration 4837000 (16.688 iter/s, 29.9616s/500 iters), loss = 0.0661373
I0901 17:57:22.404485 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0661374 (* 1 = 0.0661374 loss)
I0901 17:57:22.404495 916722 sgd_solver.cpp:106] Iteration 4837000, lr = 0.01
I0901 17:57:52.373306 916722 solver.cpp:218] Iteration 4837500 (16.6838 iter/s, 29.9691s/500 iters), loss = 0.0338175
I0901 17:57:52.373368 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0338176 (* 1 = 0.0338176 loss)
I0901 17:57:52.373378 916722 sgd_solver.cpp:106] Iteration 4837500, lr = 0.01
I0901 17:58:22.358676 916722 solver.cpp:218] Iteration 4838000 (16.6747 iter/s, 29.9856s/500 iters), loss = 0.177578
I0901 17:58:22.358728 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.177578 (* 1 = 0.177578 loss)
I0901 17:58:22.358737 916722 sgd_solver.cpp:106] Iteration 4838000, lr = 0.01
I0901 17:58:52.329715 916722 solver.cpp:218] Iteration 4838500 (16.6827 iter/s, 29.9713s/500 iters), loss = 0.031336
I0901 17:58:52.329775 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0313361 (* 1 = 0.0313361 loss)
I0901 17:58:52.329784 916722 sgd_solver.cpp:106] Iteration 4838500, lr = 0.01
I0901 17:59:22.313267 916722 solver.cpp:218] Iteration 4839000 (16.6757 iter/s, 29.9837s/500 iters), loss = 0.190299
I0901 17:59:22.313321 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.190299 (* 1 = 0.190299 loss)
I0901 17:59:22.313330 916722 sgd_solver.cpp:106] Iteration 4839000, lr = 0.01
I0901 17:59:52.306113 916722 solver.cpp:218] Iteration 4839500 (16.6705 iter/s, 29.993s/500 iters), loss = 0.0720335
I0901 17:59:52.306171 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0720338 (* 1 = 0.0720338 loss)
I0901 17:59:52.306180 916722 sgd_solver.cpp:106] Iteration 4839500, lr = 0.01
I0901 18:00:22.289312 916722 solver.cpp:218] Iteration 4840000 (16.6759 iter/s, 29.9834s/500 iters), loss = 0.0685274
I0901 18:00:22.289366 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0685277 (* 1 = 0.0685277 loss)
I0901 18:00:22.289376 916722 sgd_solver.cpp:106] Iteration 4840000, lr = 0.01
I0901 18:00:52.287047 916722 solver.cpp:218] Iteration 4840500 (16.6678 iter/s, 29.9979s/500 iters), loss = 0.139356
I0901 18:00:52.287108 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139357 (* 1 = 0.139357 loss)
I0901 18:00:52.287117 916722 sgd_solver.cpp:106] Iteration 4840500, lr = 0.01
I0901 18:01:22.278618 916722 solver.cpp:218] Iteration 4841000 (16.6713 iter/s, 29.9917s/500 iters), loss = 0.156418
I0901 18:01:22.278671 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.156418 (* 1 = 0.156418 loss)
I0901 18:01:22.278681 916722 sgd_solver.cpp:106] Iteration 4841000, lr = 0.01
I0901 18:01:52.284991 916722 solver.cpp:218] Iteration 4841500 (16.6631 iter/s, 30.0065s/500 iters), loss = 0.172913
I0901 18:01:52.285053 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.172913 (* 1 = 0.172913 loss)
I0901 18:01:52.285061 916722 sgd_solver.cpp:106] Iteration 4841500, lr = 0.01
I0901 18:02:22.281738 916722 solver.cpp:218] Iteration 4842000 (16.6684 iter/s, 29.9969s/500 iters), loss = 0.0957094
I0901 18:02:22.281795 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0957096 (* 1 = 0.0957096 loss)
I0901 18:02:22.281817 916722 sgd_solver.cpp:106] Iteration 4842000, lr = 0.01
I0901 18:02:52.300880 916722 solver.cpp:218] Iteration 4842500 (16.656 iter/s, 30.0192s/500 iters), loss = 0.0735963
I0901 18:02:52.300951 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0735965 (* 1 = 0.0735965 loss)
I0901 18:02:52.300959 916722 sgd_solver.cpp:106] Iteration 4842500, lr = 0.01
I0901 18:03:22.305450 916722 solver.cpp:218] Iteration 4843000 (16.6641 iter/s, 30.0047s/500 iters), loss = 0.211907
I0901 18:03:22.305508 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.211907 (* 1 = 0.211907 loss)
I0901 18:03:22.305516 916722 sgd_solver.cpp:106] Iteration 4843000, lr = 0.01
I0901 18:03:52.324998 916722 solver.cpp:218] Iteration 4843500 (16.6558 iter/s, 30.0196s/500 iters), loss = 0.0674949
I0901 18:03:52.325057 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0674951 (* 1 = 0.0674951 loss)
I0901 18:03:52.325065 916722 sgd_solver.cpp:106] Iteration 4843500, lr = 0.01
I0901 18:04:22.332818 916722 solver.cpp:218] Iteration 4844000 (16.6623 iter/s, 30.0079s/500 iters), loss = 0.0917553
I0901 18:04:22.332876 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0917552 (* 1 = 0.0917552 loss)
I0901 18:04:22.332885 916722 sgd_solver.cpp:106] Iteration 4844000, lr = 0.01
I0901 18:04:52.347723 916722 solver.cpp:218] Iteration 4844500 (16.6584 iter/s, 30.015s/500 iters), loss = 0.0429914
I0901 18:04:52.347779 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0429912 (* 1 = 0.0429912 loss)
I0901 18:04:52.347787 916722 sgd_solver.cpp:106] Iteration 4844500, lr = 0.01
I0901 18:05:22.372648 916722 solver.cpp:218] Iteration 4845000 (16.6528 iter/s, 30.025s/500 iters), loss = 0.3581
I0901 18:05:22.372704 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.3581 (* 1 = 0.3581 loss)
I0901 18:05:22.372712 916722 sgd_solver.cpp:106] Iteration 4845000, lr = 0.01
I0901 18:05:52.394320 916722 solver.cpp:218] Iteration 4845500 (16.6546 iter/s, 30.0217s/500 iters), loss = 0.019212
I0901 18:05:52.394380 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.019212 (* 1 = 0.019212 loss)
I0901 18:05:52.394389 916722 sgd_solver.cpp:106] Iteration 4845500, lr = 0.01
I0901 18:06:22.401451 916722 solver.cpp:218] Iteration 4846000 (16.6627 iter/s, 30.0072s/500 iters), loss = 0.204332
I0901 18:06:22.401513 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.204332 (* 1 = 0.204332 loss)
I0901 18:06:22.401521 916722 sgd_solver.cpp:106] Iteration 4846000, lr = 0.01
I0901 18:06:52.426299 916722 solver.cpp:218] Iteration 4846500 (16.6529 iter/s, 30.0249s/500 iters), loss = 0.0234861
I0901 18:06:52.426358 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.023486 (* 1 = 0.023486 loss)
I0901 18:06:52.426367 916722 sgd_solver.cpp:106] Iteration 4846500, lr = 0.01
I0901 18:07:22.423118 916722 solver.cpp:218] Iteration 4847000 (16.6684 iter/s, 29.9968s/500 iters), loss = 0.0405577
I0901 18:07:22.423171 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0405577 (* 1 = 0.0405577 loss)
I0901 18:07:22.423182 916722 sgd_solver.cpp:106] Iteration 4847000, lr = 0.01
I0901 18:07:52.428514 916722 solver.cpp:218] Iteration 4847500 (16.6637 iter/s, 30.0054s/500 iters), loss = 0.163136
I0901 18:07:52.428573 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.163136 (* 1 = 0.163136 loss)
I0901 18:07:52.428581 916722 sgd_solver.cpp:106] Iteration 4847500, lr = 0.01
I0901 18:08:22.439178 916722 solver.cpp:218] Iteration 4848000 (16.6607 iter/s, 30.0107s/500 iters), loss = 0.122179
I0901 18:08:22.439241 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.122179 (* 1 = 0.122179 loss)
I0901 18:08:22.439249 916722 sgd_solver.cpp:106] Iteration 4848000, lr = 0.01
I0901 18:08:52.452076 916722 solver.cpp:218] Iteration 4848500 (16.6595 iter/s, 30.0129s/500 iters), loss = 0.11486
I0901 18:08:52.452137 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.11486 (* 1 = 0.11486 loss)
I0901 18:08:52.452145 916722 sgd_solver.cpp:106] Iteration 4848500, lr = 0.01
I0901 18:09:22.462432 916722 solver.cpp:218] Iteration 4849000 (16.6609 iter/s, 30.0104s/500 iters), loss = 0.110518
I0901 18:09:22.462504 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.110518 (* 1 = 0.110518 loss)
I0901 18:09:22.462513 916722 sgd_solver.cpp:106] Iteration 4849000, lr = 0.01
I0901 18:09:52.489434 916722 solver.cpp:218] Iteration 4849500 (16.6517 iter/s, 30.027s/500 iters), loss = 0.17819
I0901 18:09:52.489492 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.178189 (* 1 = 0.178189 loss)
I0901 18:09:52.489500 916722 sgd_solver.cpp:106] Iteration 4849500, lr = 0.01
I0901 18:10:22.460919 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_4850000.caffemodel
I0901 18:10:22.480315 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_4850000.solverstate
I0901 18:10:22.486375 916722 solver.cpp:330] Iteration 4850000, Testing net (#0)
I0901 18:10:37.925712 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8593
I0901 18:10:37.925765 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.446909 (* 1 = 0.446909 loss)
I0901 18:10:37.984575 916722 solver.cpp:218] Iteration 4850000 (10.9902 iter/s, 45.4952s/500 iters), loss = 0.266867
I0901 18:10:37.984603 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.266867 (* 1 = 0.266867 loss)
I0901 18:10:37.984611 916722 sgd_solver.cpp:106] Iteration 4850000, lr = 0.01
I0901 18:11:07.827376 916722 solver.cpp:218] Iteration 4850500 (16.7545 iter/s, 29.8428s/500 iters), loss = 0.124882
I0901 18:11:07.827430 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.124881 (* 1 = 0.124881 loss)
I0901 18:11:07.827438 916722 sgd_solver.cpp:106] Iteration 4850500, lr = 0.01
I0901 18:11:37.840811 916722 solver.cpp:218] Iteration 4851000 (16.6592 iter/s, 30.0134s/500 iters), loss = 0.111391
I0901 18:11:37.840874 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111391 (* 1 = 0.111391 loss)
I0901 18:11:37.840883 916722 sgd_solver.cpp:106] Iteration 4851000, lr = 0.01
I0901 18:12:07.900836 916722 solver.cpp:218] Iteration 4851500 (16.6334 iter/s, 30.06s/500 iters), loss = 0.187964
I0901 18:12:07.900895 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.187963 (* 1 = 0.187963 loss)
I0901 18:12:07.900904 916722 sgd_solver.cpp:106] Iteration 4851500, lr = 0.01
I0901 18:12:37.959918 916722 solver.cpp:218] Iteration 4852000 (16.6339 iter/s, 30.0591s/500 iters), loss = 0.0159384
I0901 18:12:37.959980 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0159378 (* 1 = 0.0159378 loss)
I0901 18:12:37.959987 916722 sgd_solver.cpp:106] Iteration 4852000, lr = 0.01
I0901 18:13:08.023490 916722 solver.cpp:218] Iteration 4852500 (16.6314 iter/s, 30.0635s/500 iters), loss = 0.362363
I0901 18:13:08.023550 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.362363 (* 1 = 0.362363 loss)
I0901 18:13:08.023559 916722 sgd_solver.cpp:106] Iteration 4852500, lr = 0.01
I0901 18:13:38.091876 916722 solver.cpp:218] Iteration 4853000 (16.6288 iter/s, 30.0684s/500 iters), loss = 0.175741
I0901 18:13:38.091933 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.17574 (* 1 = 0.17574 loss)
I0901 18:13:38.091943 916722 sgd_solver.cpp:106] Iteration 4853000, lr = 0.01
I0901 18:14:08.132961 916722 solver.cpp:218] Iteration 4853500 (16.6439 iter/s, 30.0411s/500 iters), loss = 0.194505
I0901 18:14:08.133020 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.194504 (* 1 = 0.194504 loss)
I0901 18:14:08.133028 916722 sgd_solver.cpp:106] Iteration 4853500, lr = 0.01
I0901 18:14:38.177276 916722 solver.cpp:218] Iteration 4854000 (16.6421 iter/s, 30.0443s/500 iters), loss = 0.0660564
I0901 18:14:38.177335 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.066056 (* 1 = 0.066056 loss)
I0901 18:14:38.177342 916722 sgd_solver.cpp:106] Iteration 4854000, lr = 0.01
I0901 18:15:08.221112 916722 solver.cpp:218] Iteration 4854500 (16.6424 iter/s, 30.0438s/500 iters), loss = 0.0729887
I0901 18:15:08.221184 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0729882 (* 1 = 0.0729882 loss)
I0901 18:15:08.221191 916722 sgd_solver.cpp:106] Iteration 4854500, lr = 0.01
I0901 18:15:38.268115 916722 solver.cpp:218] Iteration 4855000 (16.6406 iter/s, 30.047s/500 iters), loss = 0.0930415
I0901 18:15:38.268170 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.093041 (* 1 = 0.093041 loss)
I0901 18:15:38.268178 916722 sgd_solver.cpp:106] Iteration 4855000, lr = 0.01
I0901 18:16:08.315819 916722 solver.cpp:218] Iteration 4855500 (16.6402 iter/s, 30.0477s/500 iters), loss = 0.135142
I0901 18:16:08.315882 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.135142 (* 1 = 0.135142 loss)
I0901 18:16:08.315891 916722 sgd_solver.cpp:106] Iteration 4855500, lr = 0.01
I0901 18:16:38.364224 916722 solver.cpp:218] Iteration 4856000 (16.6398 iter/s, 30.0484s/500 iters), loss = 0.0773268
I0901 18:16:38.364284 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0773264 (* 1 = 0.0773264 loss)
I0901 18:16:38.364293 916722 sgd_solver.cpp:106] Iteration 4856000, lr = 0.01
I0901 18:17:08.422678 916722 solver.cpp:218] Iteration 4856500 (16.6343 iter/s, 30.0584s/500 iters), loss = 0.0227038
I0901 18:17:08.422737 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0227035 (* 1 = 0.0227035 loss)
I0901 18:17:08.422746 916722 sgd_solver.cpp:106] Iteration 4856500, lr = 0.01
I0901 18:17:38.457548 916722 solver.cpp:218] Iteration 4857000 (16.6473 iter/s, 30.0348s/500 iters), loss = 0.150993
I0901 18:17:38.457607 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.150993 (* 1 = 0.150993 loss)
I0901 18:17:38.457617 916722 sgd_solver.cpp:106] Iteration 4857000, lr = 0.01
I0901 18:18:08.503597 916722 solver.cpp:218] Iteration 4857500 (16.6411 iter/s, 30.046s/500 iters), loss = 0.0968138
I0901 18:18:08.503659 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0968133 (* 1 = 0.0968133 loss)
I0901 18:18:08.503667 916722 sgd_solver.cpp:106] Iteration 4857500, lr = 0.01
I0901 18:18:38.555574 916722 solver.cpp:218] Iteration 4858000 (16.6379 iter/s, 30.0519s/500 iters), loss = 0.167773
I0901 18:18:38.555632 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.167773 (* 1 = 0.167773 loss)
I0901 18:18:38.555640 916722 sgd_solver.cpp:106] Iteration 4858000, lr = 0.01
I0901 18:19:08.587677 916722 solver.cpp:218] Iteration 4858500 (16.6489 iter/s, 30.0321s/500 iters), loss = 0.297679
I0901 18:19:08.587735 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.297679 (* 1 = 0.297679 loss)
I0901 18:19:08.587744 916722 sgd_solver.cpp:106] Iteration 4858500, lr = 0.01
I0901 18:19:38.628939 916722 solver.cpp:218] Iteration 4859000 (16.6438 iter/s, 30.0412s/500 iters), loss = 0.17098
I0901 18:19:38.628994 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.17098 (* 1 = 0.17098 loss)
I0901 18:19:38.629004 916722 sgd_solver.cpp:106] Iteration 4859000, lr = 0.01
I0901 18:20:08.672343 916722 solver.cpp:218] Iteration 4859500 (16.6426 iter/s, 30.0434s/500 iters), loss = 0.0693473
I0901 18:20:08.672402 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0693469 (* 1 = 0.0693469 loss)
I0901 18:20:08.672410 916722 sgd_solver.cpp:106] Iteration 4859500, lr = 0.01
I0901 18:20:38.721014 916722 solver.cpp:218] Iteration 4860000 (16.6397 iter/s, 30.0486s/500 iters), loss = 0.0833335
I0901 18:20:38.721076 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0833332 (* 1 = 0.0833332 loss)
I0901 18:20:38.721083 916722 sgd_solver.cpp:106] Iteration 4860000, lr = 0.01
I0901 18:21:08.774369 916722 solver.cpp:218] Iteration 4860500 (16.6371 iter/s, 30.0533s/500 iters), loss = 0.153193
I0901 18:21:08.774426 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.153193 (* 1 = 0.153193 loss)
I0901 18:21:08.774435 916722 sgd_solver.cpp:106] Iteration 4860500, lr = 0.01
I0901 18:21:38.824007 916722 solver.cpp:218] Iteration 4861000 (16.6392 iter/s, 30.0496s/500 iters), loss = 0.0183715
I0901 18:21:38.824084 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0183713 (* 1 = 0.0183713 loss)
I0901 18:21:38.824092 916722 sgd_solver.cpp:106] Iteration 4861000, lr = 0.01
I0901 18:22:08.887840 916722 solver.cpp:218] Iteration 4861500 (16.6313 iter/s, 30.0638s/500 iters), loss = 0.0800267
I0901 18:22:08.887899 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0800266 (* 1 = 0.0800266 loss)
I0901 18:22:08.887908 916722 sgd_solver.cpp:106] Iteration 4861500, lr = 0.01
I0901 18:22:38.942634 916722 solver.cpp:218] Iteration 4862000 (16.6363 iter/s, 30.0547s/500 iters), loss = 0.0622087
I0901 18:22:38.942696 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0622087 (* 1 = 0.0622087 loss)
I0901 18:22:38.942705 916722 sgd_solver.cpp:106] Iteration 4862000, lr = 0.01
I0901 18:23:09.000836 916722 solver.cpp:218] Iteration 4862500 (16.6344 iter/s, 30.0581s/500 iters), loss = 0.0776811
I0901 18:23:09.000896 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0776812 (* 1 = 0.0776812 loss)
I0901 18:23:09.000905 916722 sgd_solver.cpp:106] Iteration 4862500, lr = 0.01
I0901 18:23:39.050868 916722 solver.cpp:218] Iteration 4863000 (16.6389 iter/s, 30.05s/500 iters), loss = 0.101588
I0901 18:23:39.050927 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.101589 (* 1 = 0.101589 loss)
I0901 18:23:39.050935 916722 sgd_solver.cpp:106] Iteration 4863000, lr = 0.01
I0901 18:24:09.106782 916722 solver.cpp:218] Iteration 4863500 (16.6357 iter/s, 30.0559s/500 iters), loss = 0.265917
I0901 18:24:09.106839 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.265917 (* 1 = 0.265917 loss)
I0901 18:24:09.106848 916722 sgd_solver.cpp:106] Iteration 4863500, lr = 0.01
I0901 18:24:39.157275 916722 solver.cpp:218] Iteration 4864000 (16.6387 iter/s, 30.0504s/500 iters), loss = 0.213735
I0901 18:24:39.157333 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.213735 (* 1 = 0.213735 loss)
I0901 18:24:39.157342 916722 sgd_solver.cpp:106] Iteration 4864000, lr = 0.01
I0901 18:25:09.225755 916722 solver.cpp:218] Iteration 4864500 (16.6287 iter/s, 30.0684s/500 iters), loss = 0.117902
I0901 18:25:09.225816 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.117903 (* 1 = 0.117903 loss)
I0901 18:25:09.225823 916722 sgd_solver.cpp:106] Iteration 4864500, lr = 0.01
I0901 18:25:39.269269 916722 solver.cpp:218] Iteration 4865000 (16.6426 iter/s, 30.0435s/500 iters), loss = 0.0304149
I0901 18:25:39.269331 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.030415 (* 1 = 0.030415 loss)
I0901 18:25:39.269340 916722 sgd_solver.cpp:106] Iteration 4865000, lr = 0.01
I0901 18:26:09.319149 916722 solver.cpp:218] Iteration 4865500 (16.639 iter/s, 30.0498s/500 iters), loss = 0.273071
I0901 18:26:09.319211 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.273071 (* 1 = 0.273071 loss)
I0901 18:26:09.319219 916722 sgd_solver.cpp:106] Iteration 4865500, lr = 0.01
I0901 18:26:39.370206 916722 solver.cpp:218] Iteration 4866000 (16.6384 iter/s, 30.051s/500 iters), loss = 0.0701397
I0901 18:26:39.370266 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.07014 (* 1 = 0.07014 loss)
I0901 18:26:39.370275 916722 sgd_solver.cpp:106] Iteration 4866000, lr = 0.01
I0901 18:27:09.428946 916722 solver.cpp:218] Iteration 4866500 (16.6341 iter/s, 30.0587s/500 iters), loss = 0.0725112
I0901 18:27:09.429008 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0725115 (* 1 = 0.0725115 loss)
I0901 18:27:09.429016 916722 sgd_solver.cpp:106] Iteration 4866500, lr = 0.01
I0901 18:27:39.491458 916722 solver.cpp:218] Iteration 4867000 (16.632 iter/s, 30.0624s/500 iters), loss = 0.0347819
I0901 18:27:39.491518 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0347821 (* 1 = 0.0347821 loss)
I0901 18:27:39.491528 916722 sgd_solver.cpp:106] Iteration 4867000, lr = 0.01
I0901 18:28:09.552619 916722 solver.cpp:218] Iteration 4867500 (16.6328 iter/s, 30.0611s/500 iters), loss = 0.067767
I0901 18:28:09.552690 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0677671 (* 1 = 0.0677671 loss)
I0901 18:28:09.552703 916722 sgd_solver.cpp:106] Iteration 4867500, lr = 0.01
I0901 18:28:39.607753 916722 solver.cpp:218] Iteration 4868000 (16.6361 iter/s, 30.0551s/500 iters), loss = 0.029348
I0901 18:28:39.607811 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.029348 (* 1 = 0.029348 loss)
I0901 18:28:39.607820 916722 sgd_solver.cpp:106] Iteration 4868000, lr = 0.01
I0901 18:29:09.671057 916722 solver.cpp:218] Iteration 4868500 (16.6316 iter/s, 30.0632s/500 iters), loss = 0.00757115
I0901 18:29:09.671113 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.00757125 (* 1 = 0.00757125 loss)
I0901 18:29:09.671121 916722 sgd_solver.cpp:106] Iteration 4868500, lr = 0.01
I0901 18:29:39.729568 916722 solver.cpp:218] Iteration 4869000 (16.6343 iter/s, 30.0585s/500 iters), loss = 0.0454259
I0901 18:29:39.729629 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0454259 (* 1 = 0.0454259 loss)
I0901 18:29:39.729637 916722 sgd_solver.cpp:106] Iteration 4869000, lr = 0.01
I0901 18:30:09.791638 916722 solver.cpp:218] Iteration 4869500 (16.6323 iter/s, 30.062s/500 iters), loss = 0.0780896
I0901 18:30:09.791699 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0780898 (* 1 = 0.0780898 loss)
I0901 18:30:09.791708 916722 sgd_solver.cpp:106] Iteration 4869500, lr = 0.01
I0901 18:30:39.847808 916722 solver.cpp:218] Iteration 4870000 (16.6355 iter/s, 30.0562s/500 iters), loss = 0.0398626
I0901 18:30:39.847868 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0398629 (* 1 = 0.0398629 loss)
I0901 18:30:39.847877 916722 sgd_solver.cpp:106] Iteration 4870000, lr = 0.01
I0901 18:31:09.917057 916722 solver.cpp:218] Iteration 4870500 (16.6283 iter/s, 30.0692s/500 iters), loss = 0.0648413
I0901 18:31:09.917115 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0648415 (* 1 = 0.0648415 loss)
I0901 18:31:09.917125 916722 sgd_solver.cpp:106] Iteration 4870500, lr = 0.01
I0901 18:31:39.999562 916722 solver.cpp:218] Iteration 4871000 (16.621 iter/s, 30.0825s/500 iters), loss = 0.0519671
I0901 18:31:39.999624 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0519673 (* 1 = 0.0519673 loss)
I0901 18:31:39.999634 916722 sgd_solver.cpp:106] Iteration 4871000, lr = 0.01
I0901 18:32:10.082414 916722 solver.cpp:218] Iteration 4871500 (16.6208 iter/s, 30.0828s/500 iters), loss = 0.224768
I0901 18:32:10.082474 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.224768 (* 1 = 0.224768 loss)
I0901 18:32:10.082482 916722 sgd_solver.cpp:106] Iteration 4871500, lr = 0.01
I0901 18:32:40.156167 916722 solver.cpp:218] Iteration 4872000 (16.6258 iter/s, 30.0737s/500 iters), loss = 0.166592
I0901 18:32:40.156225 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.166592 (* 1 = 0.166592 loss)
I0901 18:32:40.156234 916722 sgd_solver.cpp:106] Iteration 4872000, lr = 0.01
I0901 18:33:10.235792 916722 solver.cpp:218] Iteration 4872500 (16.6226 iter/s, 30.0796s/500 iters), loss = 0.0441331
I0901 18:33:10.235847 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0441332 (* 1 = 0.0441332 loss)
I0901 18:33:10.235855 916722 sgd_solver.cpp:106] Iteration 4872500, lr = 0.01
I0901 18:33:40.348049 916722 solver.cpp:218] Iteration 4873000 (16.6045 iter/s, 30.1122s/500 iters), loss = 0.0569545
I0901 18:33:40.348115 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0569546 (* 1 = 0.0569546 loss)
I0901 18:33:40.348124 916722 sgd_solver.cpp:106] Iteration 4873000, lr = 0.01
I0901 18:34:10.431499 916722 solver.cpp:218] Iteration 4873500 (16.6205 iter/s, 30.0834s/500 iters), loss = 0.0683957
I0901 18:34:10.431555 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0683959 (* 1 = 0.0683959 loss)
I0901 18:34:10.431564 916722 sgd_solver.cpp:106] Iteration 4873500, lr = 0.01
I0901 18:34:40.524065 916722 solver.cpp:218] Iteration 4874000 (16.6154 iter/s, 30.0925s/500 iters), loss = 0.112091
I0901 18:34:40.524137 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112091 (* 1 = 0.112091 loss)
I0901 18:34:40.524168 916722 sgd_solver.cpp:106] Iteration 4874000, lr = 0.01
I0901 18:35:10.613932 916722 solver.cpp:218] Iteration 4874500 (16.6169 iter/s, 30.0898s/500 iters), loss = 0.184911
I0901 18:35:10.613987 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.184912 (* 1 = 0.184912 loss)
I0901 18:35:10.613996 916722 sgd_solver.cpp:106] Iteration 4874500, lr = 0.01
I0901 18:35:40.695068 916722 solver.cpp:218] Iteration 4875000 (16.6217 iter/s, 30.0811s/500 iters), loss = 0.207647
I0901 18:35:40.695128 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.207647 (* 1 = 0.207647 loss)
I0901 18:35:40.695137 916722 sgd_solver.cpp:106] Iteration 4875000, lr = 0.01
I0901 18:36:10.793365 916722 solver.cpp:218] Iteration 4875500 (16.6123 iter/s, 30.0983s/500 iters), loss = 0.227331
I0901 18:36:10.793421 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.227331 (* 1 = 0.227331 loss)
I0901 18:36:10.793429 916722 sgd_solver.cpp:106] Iteration 4875500, lr = 0.01
I0901 18:36:40.913305 916722 solver.cpp:218] Iteration 4876000 (16.6003 iter/s, 30.1199s/500 iters), loss = 0.290494
I0901 18:36:40.913367 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.290494 (* 1 = 0.290494 loss)
I0901 18:36:40.913375 916722 sgd_solver.cpp:106] Iteration 4876000, lr = 0.01
I0901 18:37:11.028064 916722 solver.cpp:218] Iteration 4876500 (16.6032 iter/s, 30.1147s/500 iters), loss = 0.205405
I0901 18:37:11.028122 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.205405 (* 1 = 0.205405 loss)
I0901 18:37:11.028131 916722 sgd_solver.cpp:106] Iteration 4876500, lr = 0.01
I0901 18:37:41.138216 916722 solver.cpp:218] Iteration 4877000 (16.6057 iter/s, 30.1101s/500 iters), loss = 0.143506
I0901 18:37:41.138273 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.143506 (* 1 = 0.143506 loss)
I0901 18:37:41.138281 916722 sgd_solver.cpp:106] Iteration 4877000, lr = 0.01
I0901 18:38:11.243191 916722 solver.cpp:218] Iteration 4877500 (16.6086 iter/s, 30.1049s/500 iters), loss = 0.111128
I0901 18:38:11.243244 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.111128 (* 1 = 0.111128 loss)
I0901 18:38:11.243252 916722 sgd_solver.cpp:106] Iteration 4877500, lr = 0.01
I0901 18:38:41.342448 916722 solver.cpp:218] Iteration 4878000 (16.6117 iter/s, 30.0992s/500 iters), loss = 0.126158
I0901 18:38:41.342506 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.126159 (* 1 = 0.126159 loss)
I0901 18:38:41.342515 916722 sgd_solver.cpp:106] Iteration 4878000, lr = 0.01
I0901 18:39:11.470355 916722 solver.cpp:218] Iteration 4878500 (16.5959 iter/s, 30.1279s/500 iters), loss = 0.225432
I0901 18:39:11.470409 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.225432 (* 1 = 0.225432 loss)
I0901 18:39:11.470418 916722 sgd_solver.cpp:106] Iteration 4878500, lr = 0.01
I0901 18:39:41.586740 916722 solver.cpp:218] Iteration 4879000 (16.6023 iter/s, 30.1163s/500 iters), loss = 0.123351
I0901 18:39:41.586800 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.123351 (* 1 = 0.123351 loss)
I0901 18:39:41.586809 916722 sgd_solver.cpp:106] Iteration 4879000, lr = 0.01
I0901 18:40:11.690156 916722 solver.cpp:218] Iteration 4879500 (16.6094 iter/s, 30.1034s/500 iters), loss = 0.184005
I0901 18:40:11.690214 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.184005 (* 1 = 0.184005 loss)
I0901 18:40:11.690223 916722 sgd_solver.cpp:106] Iteration 4879500, lr = 0.01
I0901 18:40:41.801483 916722 solver.cpp:218] Iteration 4880000 (16.6051 iter/s, 30.1113s/500 iters), loss = 0.0718889
I0901 18:40:41.801543 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0718888 (* 1 = 0.0718888 loss)
I0901 18:40:41.801553 916722 sgd_solver.cpp:106] Iteration 4880000, lr = 0.01
I0901 18:41:11.927848 916722 solver.cpp:218] Iteration 4880500 (16.5968 iter/s, 30.1263s/500 iters), loss = 0.160346
I0901 18:41:11.927918 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.160346 (* 1 = 0.160346 loss)
I0901 18:41:11.927932 916722 sgd_solver.cpp:106] Iteration 4880500, lr = 0.01
I0901 18:41:42.038201 916722 solver.cpp:218] Iteration 4881000 (16.6056 iter/s, 30.1103s/500 iters), loss = 0.0492865
I0901 18:41:42.038262 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0492863 (* 1 = 0.0492863 loss)
I0901 18:41:42.038270 916722 sgd_solver.cpp:106] Iteration 4881000, lr = 0.01
I0901 18:42:12.238612 916722 solver.cpp:218] Iteration 4881500 (16.5561 iter/s, 30.2004s/500 iters), loss = 0.302462
I0901 18:42:12.238668 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.302461 (* 1 = 0.302461 loss)
I0901 18:42:12.238677 916722 sgd_solver.cpp:106] Iteration 4881500, lr = 0.01
I0901 18:42:42.428135 916722 solver.cpp:218] Iteration 4882000 (16.5621 iter/s, 30.1895s/500 iters), loss = 0.239678
I0901 18:42:42.428195 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.239677 (* 1 = 0.239677 loss)
I0901 18:42:42.428203 916722 sgd_solver.cpp:106] Iteration 4882000, lr = 0.01
I0901 18:43:12.624157 916722 solver.cpp:218] Iteration 4882500 (16.5585 iter/s, 30.196s/500 iters), loss = 0.188341
I0901 18:43:12.624208 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.188341 (* 1 = 0.188341 loss)
I0901 18:43:12.624217 916722 sgd_solver.cpp:106] Iteration 4882500, lr = 0.01
I0901 18:43:42.812287 916722 solver.cpp:218] Iteration 4883000 (16.5628 iter/s, 30.1881s/500 iters), loss = 0.318426
I0901 18:43:42.812346 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.318426 (* 1 = 0.318426 loss)
I0901 18:43:42.812355 916722 sgd_solver.cpp:106] Iteration 4883000, lr = 0.01
I0901 18:44:13.004140 916722 solver.cpp:218] Iteration 4883500 (16.5608 iter/s, 30.1918s/500 iters), loss = 0.173976
I0901 18:44:13.004196 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.173976 (* 1 = 0.173976 loss)
I0901 18:44:13.004205 916722 sgd_solver.cpp:106] Iteration 4883500, lr = 0.01
I0901 18:44:43.212206 916722 solver.cpp:218] Iteration 4884000 (16.5519 iter/s, 30.208s/500 iters), loss = 0.192377
I0901 18:44:43.212266 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.192377 (* 1 = 0.192377 loss)
I0901 18:44:43.212275 916722 sgd_solver.cpp:106] Iteration 4884000, lr = 0.01
I0901 18:45:13.398265 916722 solver.cpp:218] Iteration 4884500 (16.564 iter/s, 30.186s/500 iters), loss = 0.2419
I0901 18:45:13.398322 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.2419 (* 1 = 0.2419 loss)
I0901 18:45:13.398330 916722 sgd_solver.cpp:106] Iteration 4884500, lr = 0.01
I0901 18:45:43.599318 916722 solver.cpp:218] Iteration 4885000 (16.5557 iter/s, 30.201s/500 iters), loss = 0.0868335
I0901 18:45:43.599377 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0868335 (* 1 = 0.0868335 loss)
I0901 18:45:43.599386 916722 sgd_solver.cpp:106] Iteration 4885000, lr = 0.01
I0901 18:46:13.791586 916722 solver.cpp:218] Iteration 4885500 (16.5606 iter/s, 30.1922s/500 iters), loss = 0.360043
I0901 18:46:13.791644 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.360043 (* 1 = 0.360043 loss)
I0901 18:46:13.791652 916722 sgd_solver.cpp:106] Iteration 4885500, lr = 0.01
I0901 18:46:43.984778 916722 solver.cpp:218] Iteration 4886000 (16.56 iter/s, 30.1931s/500 iters), loss = 0.232953
I0901 18:46:43.984835 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.232953 (* 1 = 0.232953 loss)
I0901 18:46:43.984844 916722 sgd_solver.cpp:106] Iteration 4886000, lr = 0.01
I0901 18:47:14.176923 916722 solver.cpp:218] Iteration 4886500 (16.5606 iter/s, 30.1921s/500 iters), loss = 0.00643049
I0901 18:47:14.176985 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.00643064 (* 1 = 0.00643064 loss)
I0901 18:47:14.176995 916722 sgd_solver.cpp:106] Iteration 4886500, lr = 0.01
I0901 18:47:44.365253 916722 solver.cpp:218] Iteration 4887000 (16.5627 iter/s, 30.1883s/500 iters), loss = 0.0694595
I0901 18:47:44.365307 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0694596 (* 1 = 0.0694596 loss)
I0901 18:47:44.365315 916722 sgd_solver.cpp:106] Iteration 4887000, lr = 0.01
I0901 18:48:14.561805 916722 solver.cpp:218] Iteration 4887500 (16.5582 iter/s, 30.1965s/500 iters), loss = 0.036586
I0901 18:48:14.561877 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0365859 (* 1 = 0.0365859 loss)
I0901 18:48:14.561885 916722 sgd_solver.cpp:106] Iteration 4887500, lr = 0.01
I0901 18:48:44.750893 916722 solver.cpp:218] Iteration 4888000 (16.5623 iter/s, 30.189s/500 iters), loss = 0.124777
I0901 18:48:44.750949 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.124777 (* 1 = 0.124777 loss)
I0901 18:48:44.750958 916722 sgd_solver.cpp:106] Iteration 4888000, lr = 0.01
I0901 18:49:14.948930 916722 solver.cpp:218] Iteration 4888500 (16.5574 iter/s, 30.198s/500 iters), loss = 0.213362
I0901 18:49:14.948989 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.213362 (* 1 = 0.213362 loss)
I0901 18:49:14.948997 916722 sgd_solver.cpp:106] Iteration 4888500, lr = 0.01
I0901 18:49:45.152007 916722 solver.cpp:218] Iteration 4889000 (16.5546 iter/s, 30.203s/500 iters), loss = 0.307563
I0901 18:49:45.152065 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.307563 (* 1 = 0.307563 loss)
I0901 18:49:45.152073 916722 sgd_solver.cpp:106] Iteration 4889000, lr = 0.01
I0901 18:50:15.355530 916722 solver.cpp:218] Iteration 4889500 (16.5544 iter/s, 30.2035s/500 iters), loss = 0.238012
I0901 18:50:15.355589 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.238012 (* 1 = 0.238012 loss)
I0901 18:50:15.355598 916722 sgd_solver.cpp:106] Iteration 4889500, lr = 0.01
I0901 18:50:45.554323 916722 solver.cpp:218] Iteration 4890000 (16.557 iter/s, 30.1987s/500 iters), loss = 0.0517686
I0901 18:50:45.554380 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0517684 (* 1 = 0.0517684 loss)
I0901 18:50:45.554388 916722 sgd_solver.cpp:106] Iteration 4890000, lr = 0.01
I0901 18:51:15.746018 916722 solver.cpp:218] Iteration 4890500 (16.5609 iter/s, 30.1917s/500 iters), loss = 0.109437
I0901 18:51:15.746079 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109437 (* 1 = 0.109437 loss)
I0901 18:51:15.746088 916722 sgd_solver.cpp:106] Iteration 4890500, lr = 0.01
I0901 18:51:45.946457 916722 solver.cpp:218] Iteration 4891000 (16.5561 iter/s, 30.2004s/500 iters), loss = 0.130904
I0901 18:51:45.946514 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.130904 (* 1 = 0.130904 loss)
I0901 18:51:45.946522 916722 sgd_solver.cpp:106] Iteration 4891000, lr = 0.01
I0901 18:52:16.144554 916722 solver.cpp:218] Iteration 4891500 (16.5574 iter/s, 30.1981s/500 iters), loss = 0.524944
I0901 18:52:16.144613 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.524944 (* 1 = 0.524944 loss)
I0901 18:52:16.144623 916722 sgd_solver.cpp:106] Iteration 4891500, lr = 0.01
I0901 18:52:46.351136 916722 solver.cpp:218] Iteration 4892000 (16.5527 iter/s, 30.2065s/500 iters), loss = 0.20464
I0901 18:52:46.351192 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.20464 (* 1 = 0.20464 loss)
I0901 18:52:46.351200 916722 sgd_solver.cpp:106] Iteration 4892000, lr = 0.01
I0901 18:53:16.550163 916722 solver.cpp:218] Iteration 4892500 (16.5569 iter/s, 30.199s/500 iters), loss = 0.188265
I0901 18:53:16.550221 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.188265 (* 1 = 0.188265 loss)
I0901 18:53:16.550230 916722 sgd_solver.cpp:106] Iteration 4892500, lr = 0.01
I0901 18:53:46.756824 916722 solver.cpp:218] Iteration 4893000 (16.5527 iter/s, 30.2066s/500 iters), loss = 0.202059
I0901 18:53:46.756881 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.202058 (* 1 = 0.202058 loss)
I0901 18:53:46.756889 916722 sgd_solver.cpp:106] Iteration 4893000, lr = 0.01
I0901 18:54:16.965251 916722 solver.cpp:218] Iteration 4893500 (16.5517 iter/s, 30.2084s/500 iters), loss = 0.47504
I0901 18:54:16.965313 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.47504 (* 1 = 0.47504 loss)
I0901 18:54:16.965322 916722 sgd_solver.cpp:106] Iteration 4893500, lr = 0.01
I0901 18:54:47.165645 916722 solver.cpp:218] Iteration 4894000 (16.5561 iter/s, 30.2003s/500 iters), loss = 0.126799
I0901 18:54:47.165720 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.126798 (* 1 = 0.126798 loss)
I0901 18:54:47.165728 916722 sgd_solver.cpp:106] Iteration 4894000, lr = 0.01
I0901 18:55:17.363817 916722 solver.cpp:218] Iteration 4894500 (16.5573 iter/s, 30.1981s/500 iters), loss = 0.222276
I0901 18:55:17.363876 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.222275 (* 1 = 0.222275 loss)
I0901 18:55:17.363884 916722 sgd_solver.cpp:106] Iteration 4894500, lr = 0.01
I0901 18:55:47.569150 916722 solver.cpp:218] Iteration 4895000 (16.5534 iter/s, 30.2053s/500 iters), loss = 0.169973
I0901 18:55:47.569211 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.169972 (* 1 = 0.169972 loss)
I0901 18:55:47.569218 916722 sgd_solver.cpp:106] Iteration 4895000, lr = 0.01
I0901 18:56:17.773910 916722 solver.cpp:218] Iteration 4895500 (16.5537 iter/s, 30.2047s/500 iters), loss = 0.156655
I0901 18:56:17.773969 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.156655 (* 1 = 0.156655 loss)
I0901 18:56:17.773978 916722 sgd_solver.cpp:106] Iteration 4895500, lr = 0.01
I0901 18:56:47.952222 916722 solver.cpp:218] Iteration 4896000 (16.5682 iter/s, 30.1783s/500 iters), loss = 0.128316
I0901 18:56:47.952277 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128316 (* 1 = 0.128316 loss)
I0901 18:56:47.952286 916722 sgd_solver.cpp:106] Iteration 4896000, lr = 0.01
I0901 18:57:18.119683 916722 solver.cpp:218] Iteration 4896500 (16.5742 iter/s, 30.1674s/500 iters), loss = 0.297697
I0901 18:57:18.119740 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.297697 (* 1 = 0.297697 loss)
I0901 18:57:18.119748 916722 sgd_solver.cpp:106] Iteration 4896500, lr = 0.01
I0901 18:57:48.317525 916722 solver.cpp:218] Iteration 4897000 (16.5575 iter/s, 30.1978s/500 iters), loss = 0.150852
I0901 18:57:48.317577 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.150851 (* 1 = 0.150851 loss)
I0901 18:57:48.317586 916722 sgd_solver.cpp:106] Iteration 4897000, lr = 0.01
I0901 18:58:18.498934 916722 solver.cpp:218] Iteration 4897500 (16.5665 iter/s, 30.1814s/500 iters), loss = 0.414174
I0901 18:58:18.498996 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.414173 (* 1 = 0.414173 loss)
I0901 18:58:18.499004 916722 sgd_solver.cpp:106] Iteration 4897500, lr = 0.01
I0901 18:58:48.675619 916722 solver.cpp:218] Iteration 4898000 (16.5691 iter/s, 30.1766s/500 iters), loss = 0.0983869
I0901 18:58:48.675678 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0983864 (* 1 = 0.0983864 loss)
I0901 18:58:48.675686 916722 sgd_solver.cpp:106] Iteration 4898000, lr = 0.01
I0901 18:59:18.868973 916722 solver.cpp:218] Iteration 4898500 (16.56 iter/s, 30.1933s/500 iters), loss = 0.112263
I0901 18:59:18.869031 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.112262 (* 1 = 0.112262 loss)
I0901 18:59:18.869040 916722 sgd_solver.cpp:106] Iteration 4898500, lr = 0.01
I0901 18:59:49.085906 916722 solver.cpp:218] Iteration 4899000 (16.547 iter/s, 30.2169s/500 iters), loss = 0.295641
I0901 18:59:49.085961 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.295641 (* 1 = 0.295641 loss)
I0901 18:59:49.085969 916722 sgd_solver.cpp:106] Iteration 4899000, lr = 0.01
I0901 19:00:19.261961 916722 solver.cpp:218] Iteration 4899500 (16.5695 iter/s, 30.176s/500 iters), loss = 0.30545
I0901 19:00:19.262020 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.30545 (* 1 = 0.30545 loss)
I0901 19:00:19.262029 916722 sgd_solver.cpp:106] Iteration 4899500, lr = 0.01
I0901 19:00:49.370916 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_4900000.caffemodel
I0901 19:00:49.390381 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_4900000.solverstate
I0901 19:00:49.396447 916722 solver.cpp:330] Iteration 4900000, Testing net (#0)
I0901 19:01:04.848527 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8775
I0901 19:01:04.848588 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.413696 (* 1 = 0.413696 loss)
I0901 19:01:04.907317 916722 solver.cpp:218] Iteration 4900000 (10.954 iter/s, 45.6453s/500 iters), loss = 0.109264
I0901 19:01:04.907344 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109263 (* 1 = 0.109263 loss)
I0901 19:01:04.907351 916722 sgd_solver.cpp:106] Iteration 4900000, lr = 0.01
I0901 19:01:34.911352 916722 solver.cpp:218] Iteration 4900500 (16.6645 iter/s, 30.004s/500 iters), loss = 0.139497
I0901 19:01:34.911423 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139496 (* 1 = 0.139496 loss)
I0901 19:01:34.911432 916722 sgd_solver.cpp:106] Iteration 4900500, lr = 0.01
I0901 19:02:05.082062 916722 solver.cpp:218] Iteration 4901000 (16.5724 iter/s, 30.1706s/500 iters), loss = 0.142871
I0901 19:02:05.082120 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.142871 (* 1 = 0.142871 loss)
I0901 19:02:05.082129 916722 sgd_solver.cpp:106] Iteration 4901000, lr = 0.01
I0901 19:02:35.274132 916722 solver.cpp:218] Iteration 4901500 (16.5607 iter/s, 30.192s/500 iters), loss = 0.310531
I0901 19:02:35.274189 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.31053 (* 1 = 0.31053 loss)
I0901 19:02:35.274199 916722 sgd_solver.cpp:106] Iteration 4901500, lr = 0.01
I0901 19:03:05.430459 916722 solver.cpp:218] Iteration 4902000 (16.5803 iter/s, 30.1563s/500 iters), loss = 0.197411
I0901 19:03:05.430516 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.197411 (* 1 = 0.197411 loss)
I0901 19:03:05.430524 916722 sgd_solver.cpp:106] Iteration 4902000, lr = 0.01
I0901 19:03:35.581105 916722 solver.cpp:218] Iteration 4902500 (16.5834 iter/s, 30.1506s/500 iters), loss = 0.196927
I0901 19:03:35.581166 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.196927 (* 1 = 0.196927 loss)
I0901 19:03:35.581174 916722 sgd_solver.cpp:106] Iteration 4902500, lr = 0.01
I0901 19:04:05.754797 916722 solver.cpp:218] Iteration 4903000 (16.5708 iter/s, 30.1736s/500 iters), loss = 0.0275627
I0901 19:04:05.754859 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0275622 (* 1 = 0.0275622 loss)
I0901 19:04:05.754868 916722 sgd_solver.cpp:106] Iteration 4903000, lr = 0.01
I0901 19:04:35.930229 916722 solver.cpp:218] Iteration 4903500 (16.57 iter/s, 30.1751s/500 iters), loss = 0.448614
I0901 19:04:35.930290 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.448614 (* 1 = 0.448614 loss)
I0901 19:04:35.930299 916722 sgd_solver.cpp:106] Iteration 4903500, lr = 0.01
I0901 19:05:06.096786 916722 solver.cpp:218] Iteration 4904000 (16.575 iter/s, 30.1659s/500 iters), loss = 0.143518
I0901 19:05:06.096848 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.143517 (* 1 = 0.143517 loss)
I0901 19:05:06.096856 916722 sgd_solver.cpp:106] Iteration 4904000, lr = 0.01
I0901 19:05:36.306555 916722 solver.cpp:218] Iteration 4904500 (16.5513 iter/s, 30.2092s/500 iters), loss = 0.163864
I0901 19:05:36.306614 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.163864 (* 1 = 0.163864 loss)
I0901 19:05:36.306623 916722 sgd_solver.cpp:106] Iteration 4904500, lr = 0.01
I0901 19:06:06.528884 916722 solver.cpp:218] Iteration 4905000 (16.5444 iter/s, 30.2218s/500 iters), loss = 0.373109
I0901 19:06:06.528944 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.373108 (* 1 = 0.373108 loss)
I0901 19:06:06.528954 916722 sgd_solver.cpp:106] Iteration 4905000, lr = 0.01
I0901 19:06:36.739267 916722 solver.cpp:218] Iteration 4905500 (16.5509 iter/s, 30.2098s/500 iters), loss = 0.121513
I0901 19:06:36.739329 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.121513 (* 1 = 0.121513 loss)
I0901 19:06:36.739337 916722 sgd_solver.cpp:106] Iteration 4905500, lr = 0.01
I0901 19:07:06.947388 916722 solver.cpp:218] Iteration 4906000 (16.5521 iter/s, 30.2076s/500 iters), loss = 0.122657
I0901 19:07:06.947458 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.122657 (* 1 = 0.122657 loss)
I0901 19:07:06.947471 916722 sgd_solver.cpp:106] Iteration 4906000, lr = 0.01
I0901 19:07:37.140652 916722 solver.cpp:218] Iteration 4906500 (16.5603 iter/s, 30.1927s/500 iters), loss = 0.113522
I0901 19:07:37.140710 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.113522 (* 1 = 0.113522 loss)
I0901 19:07:37.140719 916722 sgd_solver.cpp:106] Iteration 4906500, lr = 0.01
I0901 19:08:07.342725 916722 solver.cpp:218] Iteration 4907000 (16.5554 iter/s, 30.2016s/500 iters), loss = 0.182599
I0901 19:08:07.342782 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.182598 (* 1 = 0.182598 loss)
I0901 19:08:07.342789 916722 sgd_solver.cpp:106] Iteration 4907000, lr = 0.01
I0901 19:08:37.551877 916722 solver.cpp:218] Iteration 4907500 (16.5515 iter/s, 30.2087s/500 iters), loss = 0.195286
I0901 19:08:37.551934 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.195286 (* 1 = 0.195286 loss)
I0901 19:08:37.551944 916722 sgd_solver.cpp:106] Iteration 4907500, lr = 0.01
I0901 19:09:07.747846 916722 solver.cpp:218] Iteration 4908000 (16.5587 iter/s, 30.1955s/500 iters), loss = 0.109918
I0901 19:09:07.747905 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.109918 (* 1 = 0.109918 loss)
I0901 19:09:07.747912 916722 sgd_solver.cpp:106] Iteration 4908000, lr = 0.01
I0901 19:09:37.954908 916722 solver.cpp:218] Iteration 4908500 (16.5527 iter/s, 30.2066s/500 iters), loss = 0.0939352
I0901 19:09:37.954968 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0939348 (* 1 = 0.0939348 loss)
I0901 19:09:37.954977 916722 sgd_solver.cpp:106] Iteration 4908500, lr = 0.01
I0901 19:10:08.163295 916722 solver.cpp:218] Iteration 4909000 (16.5519 iter/s, 30.208s/500 iters), loss = 0.144511
I0901 19:10:08.163354 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.14451 (* 1 = 0.14451 loss)
I0901 19:10:08.163362 916722 sgd_solver.cpp:106] Iteration 4909000, lr = 0.01
I0901 19:10:38.364975 916722 solver.cpp:218] Iteration 4909500 (16.5556 iter/s, 30.2013s/500 iters), loss = 0.395201
I0901 19:10:38.365036 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.395201 (* 1 = 0.395201 loss)
I0901 19:10:38.365046 916722 sgd_solver.cpp:106] Iteration 4909500, lr = 0.01
I0901 19:11:08.543208 916722 solver.cpp:218] Iteration 4910000 (16.5684 iter/s, 30.1779s/500 iters), loss = 0.0361696
I0901 19:11:08.543267 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.036169 (* 1 = 0.036169 loss)
I0901 19:11:08.543277 916722 sgd_solver.cpp:106] Iteration 4910000, lr = 0.01
I0901 19:11:38.728235 916722 solver.cpp:218] Iteration 4910500 (16.5647 iter/s, 30.1847s/500 iters), loss = 0.172545
I0901 19:11:38.728291 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.172544 (* 1 = 0.172544 loss)
I0901 19:11:38.728300 916722 sgd_solver.cpp:106] Iteration 4910500, lr = 0.01
I0901 19:12:08.922051 916722 solver.cpp:218] Iteration 4911000 (16.5599 iter/s, 30.1935s/500 iters), loss = 0.120353
I0901 19:12:08.922111 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.120352 (* 1 = 0.120352 loss)
I0901 19:12:08.922119 916722 sgd_solver.cpp:106] Iteration 4911000, lr = 0.01
I0901 19:12:39.144457 916722 solver.cpp:218] Iteration 4911500 (16.5442 iter/s, 30.2221s/500 iters), loss = 0.0877329
I0901 19:12:39.144513 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0877321 (* 1 = 0.0877321 loss)
I0901 19:12:39.144522 916722 sgd_solver.cpp:106] Iteration 4911500, lr = 0.01
I0901 19:13:09.355731 916722 solver.cpp:218] Iteration 4912000 (16.5503 iter/s, 30.211s/500 iters), loss = 0.154158
I0901 19:13:09.355787 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.154158 (* 1 = 0.154158 loss)
I0901 19:13:09.355796 916722 sgd_solver.cpp:106] Iteration 4912000, lr = 0.01
I0901 19:13:39.560135 916722 solver.cpp:218] Iteration 4912500 (16.554 iter/s, 30.2041s/500 iters), loss = 0.350062
I0901 19:13:39.560206 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.350061 (* 1 = 0.350061 loss)
I0901 19:13:39.560215 916722 sgd_solver.cpp:106] Iteration 4912500, lr = 0.01
I0901 19:14:09.793506 916722 solver.cpp:218] Iteration 4913000 (16.5382 iter/s, 30.2331s/500 iters), loss = 0.141645
I0901 19:14:09.793565 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.141644 (* 1 = 0.141644 loss)
I0901 19:14:09.793573 916722 sgd_solver.cpp:106] Iteration 4913000, lr = 0.01
I0901 19:14:40.008468 916722 solver.cpp:218] Iteration 4913500 (16.5483 iter/s, 30.2147s/500 iters), loss = 0.0908651
I0901 19:14:40.008528 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0908642 (* 1 = 0.0908642 loss)
I0901 19:14:40.008538 916722 sgd_solver.cpp:106] Iteration 4913500, lr = 0.01
I0901 19:15:10.238005 916722 solver.cpp:218] Iteration 4914000 (16.5403 iter/s, 30.2293s/500 iters), loss = 0.275872
I0901 19:15:10.238063 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.275871 (* 1 = 0.275871 loss)
I0901 19:15:10.238072 916722 sgd_solver.cpp:106] Iteration 4914000, lr = 0.01
I0901 19:15:40.456120 916722 solver.cpp:218] Iteration 4914500 (16.5465 iter/s, 30.2178s/500 iters), loss = 0.471022
I0901 19:15:40.456178 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.471021 (* 1 = 0.471021 loss)
I0901 19:15:40.456187 916722 sgd_solver.cpp:106] Iteration 4914500, lr = 0.01
I0901 19:16:10.657637 916722 solver.cpp:218] Iteration 4915000 (16.5556 iter/s, 30.2013s/500 iters), loss = 0.0277972
I0901 19:16:10.657696 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0277964 (* 1 = 0.0277964 loss)
I0901 19:16:10.657706 916722 sgd_solver.cpp:106] Iteration 4915000, lr = 0.01
I0901 19:16:40.862707 916722 solver.cpp:218] Iteration 4915500 (16.5537 iter/s, 30.2048s/500 iters), loss = 0.100886
I0901 19:16:40.862764 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.100885 (* 1 = 0.100885 loss)
I0901 19:16:40.862772 916722 sgd_solver.cpp:106] Iteration 4915500, lr = 0.01
I0901 19:17:11.088173 916722 solver.cpp:218] Iteration 4916000 (16.5425 iter/s, 30.2252s/500 iters), loss = 0.196715
I0901 19:17:11.088229 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.196714 (* 1 = 0.196714 loss)
I0901 19:17:11.088238 916722 sgd_solver.cpp:106] Iteration 4916000, lr = 0.01
I0901 19:17:41.298579 916722 solver.cpp:218] Iteration 4916500 (16.5507 iter/s, 30.2102s/500 iters), loss = 0.0752975
I0901 19:17:41.298641 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0752966 (* 1 = 0.0752966 loss)
I0901 19:17:41.298650 916722 sgd_solver.cpp:106] Iteration 4916500, lr = 0.01
I0901 19:18:11.529137 916722 solver.cpp:218] Iteration 4917000 (16.5397 iter/s, 30.2303s/500 iters), loss = 0.195613
I0901 19:18:11.529196 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.195612 (* 1 = 0.195612 loss)
I0901 19:18:11.529204 916722 sgd_solver.cpp:106] Iteration 4917000, lr = 0.01
I0901 19:18:41.764169 916722 solver.cpp:218] Iteration 4917500 (16.5372 iter/s, 30.2348s/500 iters), loss = 0.0928107
I0901 19:18:41.764231 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0928099 (* 1 = 0.0928099 loss)
I0901 19:18:41.764240 916722 sgd_solver.cpp:106] Iteration 4917500, lr = 0.01
I0901 19:19:12.016227 916722 solver.cpp:218] Iteration 4918000 (16.5279 iter/s, 30.2518s/500 iters), loss = 0.136258
I0901 19:19:12.016286 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.136257 (* 1 = 0.136257 loss)
I0901 19:19:12.016295 916722 sgd_solver.cpp:106] Iteration 4918000, lr = 0.01
I0901 19:19:42.261744 916722 solver.cpp:218] Iteration 4918500 (16.5315 iter/s, 30.2453s/500 iters), loss = 0.154699
I0901 19:19:42.261801 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.154698 (* 1 = 0.154698 loss)
I0901 19:19:42.261809 916722 sgd_solver.cpp:106] Iteration 4918500, lr = 0.01
I0901 19:20:12.495004 916722 solver.cpp:218] Iteration 4919000 (16.5382 iter/s, 30.2331s/500 iters), loss = 0.00731398
I0901 19:20:12.495064 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.00731315 (* 1 = 0.00731315 loss)
I0901 19:20:12.495072 916722 sgd_solver.cpp:106] Iteration 4919000, lr = 0.01
I0901 19:20:42.719822 916722 solver.cpp:218] Iteration 4919500 (16.5428 iter/s, 30.2246s/500 iters), loss = 0.128242
I0901 19:20:42.719894 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128241 (* 1 = 0.128241 loss)
I0901 19:20:42.719903 916722 sgd_solver.cpp:106] Iteration 4919500, lr = 0.01
I0901 19:21:12.953294 916722 solver.cpp:218] Iteration 4920000 (16.5381 iter/s, 30.2333s/500 iters), loss = 0.181602
I0901 19:21:12.953351 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.181601 (* 1 = 0.181601 loss)
I0901 19:21:12.953361 916722 sgd_solver.cpp:106] Iteration 4920000, lr = 0.01
I0901 19:21:43.193449 916722 solver.cpp:218] Iteration 4920500 (16.5344 iter/s, 30.24s/500 iters), loss = 0.17605
I0901 19:21:43.193516 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.176049 (* 1 = 0.176049 loss)
I0901 19:21:43.193524 916722 sgd_solver.cpp:106] Iteration 4920500, lr = 0.01
I0901 19:22:13.387933 916722 solver.cpp:218] Iteration 4921000 (16.5594 iter/s, 30.1943s/500 iters), loss = 0.142428
I0901 19:22:13.387987 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.142427 (* 1 = 0.142427 loss)
I0901 19:22:13.387996 916722 sgd_solver.cpp:106] Iteration 4921000, lr = 0.01
I0901 19:22:43.611196 916722 solver.cpp:218] Iteration 4921500 (16.5436 iter/s, 30.2231s/500 iters), loss = 0.079095
I0901 19:22:43.611255 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0790942 (* 1 = 0.0790942 loss)
I0901 19:22:43.611263 916722 sgd_solver.cpp:106] Iteration 4921500, lr = 0.01
I0901 19:23:13.852653 916722 solver.cpp:218] Iteration 4922000 (16.5337 iter/s, 30.2413s/500 iters), loss = 0.152958
I0901 19:23:13.852716 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152958 (* 1 = 0.152958 loss)
I0901 19:23:13.852725 916722 sgd_solver.cpp:106] Iteration 4922000, lr = 0.01
I0901 19:23:44.092339 916722 solver.cpp:218] Iteration 4922500 (16.5347 iter/s, 30.2395s/500 iters), loss = 0.259267
I0901 19:23:44.092396 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.259266 (* 1 = 0.259266 loss)
I0901 19:23:44.092404 916722 sgd_solver.cpp:106] Iteration 4922500, lr = 0.01
I0901 19:24:14.302163 916722 solver.cpp:218] Iteration 4923000 (16.551 iter/s, 30.2097s/500 iters), loss = 0.25399
I0901 19:24:14.302219 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.253989 (* 1 = 0.253989 loss)
I0901 19:24:14.302228 916722 sgd_solver.cpp:106] Iteration 4923000, lr = 0.01
I0901 19:24:44.530786 916722 solver.cpp:218] Iteration 4923500 (16.5407 iter/s, 30.2285s/500 iters), loss = 0.0228961
I0901 19:24:44.530844 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.022895 (* 1 = 0.022895 loss)
I0901 19:24:44.530853 916722 sgd_solver.cpp:106] Iteration 4923500, lr = 0.01
I0901 19:25:14.747684 916722 solver.cpp:218] Iteration 4924000 (16.5471 iter/s, 30.2167s/500 iters), loss = 0.228725
I0901 19:25:14.747738 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.228724 (* 1 = 0.228724 loss)
I0901 19:25:14.747746 916722 sgd_solver.cpp:106] Iteration 4924000, lr = 0.01
I0901 19:25:45.004338 916722 solver.cpp:218] Iteration 4924500 (16.5254 iter/s, 30.2565s/500 iters), loss = 0.0483776
I0901 19:25:45.004396 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0483764 (* 1 = 0.0483764 loss)
I0901 19:25:45.004405 916722 sgd_solver.cpp:106] Iteration 4924500, lr = 0.01
I0901 19:26:15.267843 916722 solver.cpp:218] Iteration 4925000 (16.5216 iter/s, 30.2633s/500 iters), loss = 0.0806279
I0901 19:26:15.267900 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0806268 (* 1 = 0.0806268 loss)
I0901 19:26:15.267908 916722 sgd_solver.cpp:106] Iteration 4925000, lr = 0.01
I0901 19:26:45.476519 916722 solver.cpp:218] Iteration 4925500 (16.5516 iter/s, 30.2085s/500 iters), loss = 0.18826
I0901 19:26:45.476577 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.188259 (* 1 = 0.188259 loss)
I0901 19:26:45.476585 916722 sgd_solver.cpp:106] Iteration 4925500, lr = 0.01
I0901 19:27:15.721499 916722 solver.cpp:218] Iteration 4926000 (16.5317 iter/s, 30.2448s/500 iters), loss = 0.0604268
I0901 19:27:15.721570 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0604258 (* 1 = 0.0604258 loss)
I0901 19:27:15.721578 916722 sgd_solver.cpp:106] Iteration 4926000, lr = 0.01
I0901 19:27:45.972440 916722 solver.cpp:218] Iteration 4926500 (16.5285 iter/s, 30.2508s/500 iters), loss = 0.187606
I0901 19:27:45.972502 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.187605 (* 1 = 0.187605 loss)
I0901 19:27:45.972512 916722 sgd_solver.cpp:106] Iteration 4926500, lr = 0.01
I0901 19:28:16.236410 916722 solver.cpp:218] Iteration 4927000 (16.5214 iter/s, 30.2638s/500 iters), loss = 0.113954
I0901 19:28:16.236469 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.113953 (* 1 = 0.113953 loss)
I0901 19:28:16.236479 916722 sgd_solver.cpp:106] Iteration 4927000, lr = 0.01
I0901 19:28:46.480600 916722 solver.cpp:218] Iteration 4927500 (16.5322 iter/s, 30.244s/500 iters), loss = 0.321683
I0901 19:28:46.480661 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.321682 (* 1 = 0.321682 loss)
I0901 19:28:46.480670 916722 sgd_solver.cpp:106] Iteration 4927500, lr = 0.01
I0901 19:29:16.698731 916722 solver.cpp:218] Iteration 4928000 (16.5464 iter/s, 30.218s/500 iters), loss = 0.0778458
I0901 19:29:16.698788 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0778449 (* 1 = 0.0778449 loss)
I0901 19:29:16.698796 916722 sgd_solver.cpp:106] Iteration 4928000, lr = 0.01
I0901 19:29:46.905321 916722 solver.cpp:218] Iteration 4928500 (16.5528 iter/s, 30.2065s/500 iters), loss = 0.145379
I0901 19:29:46.905380 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.145379 (* 1 = 0.145379 loss)
I0901 19:29:46.905388 916722 sgd_solver.cpp:106] Iteration 4928500, lr = 0.01
I0901 19:30:17.125108 916722 solver.cpp:218] Iteration 4929000 (16.5455 iter/s, 30.2196s/500 iters), loss = 0.10828
I0901 19:30:17.125164 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.108279 (* 1 = 0.108279 loss)
I0901 19:30:17.125171 916722 sgd_solver.cpp:106] Iteration 4929000, lr = 0.01
I0901 19:30:47.341372 916722 solver.cpp:218] Iteration 4929500 (16.5475 iter/s, 30.2161s/500 iters), loss = 0.0978926
I0901 19:30:47.341429 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0978918 (* 1 = 0.0978918 loss)
I0901 19:30:47.341439 916722 sgd_solver.cpp:106] Iteration 4929500, lr = 0.01
I0901 19:31:17.566612 916722 solver.cpp:218] Iteration 4930000 (16.5425 iter/s, 30.2251s/500 iters), loss = 0.1689
I0901 19:31:17.566664 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.168899 (* 1 = 0.168899 loss)
I0901 19:31:17.566673 916722 sgd_solver.cpp:106] Iteration 4930000, lr = 0.01
I0901 19:31:47.807940 916722 solver.cpp:218] Iteration 4930500 (16.5337 iter/s, 30.2412s/500 iters), loss = 0.33347
I0901 19:31:47.807993 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.33347 (* 1 = 0.33347 loss)
I0901 19:31:47.808001 916722 sgd_solver.cpp:106] Iteration 4930500, lr = 0.01
I0901 19:32:18.021108 916722 solver.cpp:218] Iteration 4931000 (16.5491 iter/s, 30.213s/500 iters), loss = 0.116166
I0901 19:32:18.021159 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.116166 (* 1 = 0.116166 loss)
I0901 19:32:18.021168 916722 sgd_solver.cpp:106] Iteration 4931000, lr = 0.01
I0901 19:32:48.250056 916722 solver.cpp:218] Iteration 4931500 (16.5405 iter/s, 30.2288s/500 iters), loss = 0.239526
I0901 19:32:48.250113 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.239525 (* 1 = 0.239525 loss)
I0901 19:32:48.250120 916722 sgd_solver.cpp:106] Iteration 4931500, lr = 0.01
I0901 19:33:18.475519 916722 solver.cpp:218] Iteration 4932000 (16.5424 iter/s, 30.2253s/500 iters), loss = 0.10893
I0901 19:33:18.475575 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.108929 (* 1 = 0.108929 loss)
I0901 19:33:18.475584 916722 sgd_solver.cpp:106] Iteration 4932000, lr = 0.01
I0901 19:33:48.725808 916722 solver.cpp:218] Iteration 4932500 (16.5288 iter/s, 30.2502s/500 iters), loss = 0.167884
I0901 19:33:48.725881 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.167883 (* 1 = 0.167883 loss)
I0901 19:33:48.725890 916722 sgd_solver.cpp:106] Iteration 4932500, lr = 0.01
I0901 19:34:18.930756 916722 solver.cpp:218] Iteration 4933000 (16.5537 iter/s, 30.2048s/500 iters), loss = 0.319651
I0901 19:34:18.930811 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.31965 (* 1 = 0.31965 loss)
I0901 19:34:18.930819 916722 sgd_solver.cpp:106] Iteration 4933000, lr = 0.01
I0901 19:34:49.201017 916722 solver.cpp:218] Iteration 4933500 (16.5179 iter/s, 30.2701s/500 iters), loss = 0.0361219
I0901 19:34:49.201078 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0361214 (* 1 = 0.0361214 loss)
I0901 19:34:49.201087 916722 sgd_solver.cpp:106] Iteration 4933500, lr = 0.01
I0901 19:35:19.442150 916722 solver.cpp:218] Iteration 4934000 (16.5338 iter/s, 30.241s/500 iters), loss = 0.0415904
I0901 19:35:19.442205 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.04159 (* 1 = 0.04159 loss)
I0901 19:35:19.442214 916722 sgd_solver.cpp:106] Iteration 4934000, lr = 0.01
I0901 19:35:49.711992 916722 solver.cpp:218] Iteration 4934500 (16.5182 iter/s, 30.2697s/500 iters), loss = 0.164142
I0901 19:35:49.712049 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.164142 (* 1 = 0.164142 loss)
I0901 19:35:49.712059 916722 sgd_solver.cpp:106] Iteration 4934500, lr = 0.01
I0901 19:36:19.961500 916722 solver.cpp:218] Iteration 4935000 (16.5293 iter/s, 30.2494s/500 iters), loss = 0.442171
I0901 19:36:19.961560 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.44217 (* 1 = 0.44217 loss)
I0901 19:36:19.961568 916722 sgd_solver.cpp:106] Iteration 4935000, lr = 0.01
I0901 19:36:50.196579 916722 solver.cpp:218] Iteration 4935500 (16.5372 iter/s, 30.235s/500 iters), loss = 0.194141
I0901 19:36:50.196631 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.194141 (* 1 = 0.194141 loss)
I0901 19:36:50.196640 916722 sgd_solver.cpp:106] Iteration 4935500, lr = 0.01
I0901 19:37:20.454831 916722 solver.cpp:218] Iteration 4936000 (16.5245 iter/s, 30.2581s/500 iters), loss = 0.0876392
I0901 19:37:20.454890 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0876391 (* 1 = 0.0876391 loss)
I0901 19:37:20.454900 916722 sgd_solver.cpp:106] Iteration 4936000, lr = 0.01
I0901 19:37:50.675971 916722 solver.cpp:218] Iteration 4936500 (16.5448 iter/s, 30.221s/500 iters), loss = 0.125265
I0901 19:37:50.676030 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.125264 (* 1 = 0.125264 loss)
I0901 19:37:50.676038 916722 sgd_solver.cpp:106] Iteration 4936500, lr = 0.01
I0901 19:38:20.891022 916722 solver.cpp:218] Iteration 4937000 (16.5481 iter/s, 30.2149s/500 iters), loss = 0.056342
I0901 19:38:20.891080 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0563419 (* 1 = 0.0563419 loss)
I0901 19:38:20.891089 916722 sgd_solver.cpp:106] Iteration 4937000, lr = 0.01
I0901 19:38:51.122517 916722 solver.cpp:218] Iteration 4937500 (16.539 iter/s, 30.2316s/500 iters), loss = 0.103611
I0901 19:38:51.122577 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.103611 (* 1 = 0.103611 loss)
I0901 19:38:51.122586 916722 sgd_solver.cpp:106] Iteration 4937500, lr = 0.01
I0901 19:39:21.358446 916722 solver.cpp:218] Iteration 4938000 (16.5365 iter/s, 30.2361s/500 iters), loss = 0.332163
I0901 19:39:21.358505 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.332163 (* 1 = 0.332163 loss)
I0901 19:39:21.358513 916722 sgd_solver.cpp:106] Iteration 4938000, lr = 0.01
I0901 19:39:51.592104 916722 solver.cpp:218] Iteration 4938500 (16.5378 iter/s, 30.2338s/500 iters), loss = 0.0376468
I0901 19:39:51.592164 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0376465 (* 1 = 0.0376465 loss)
I0901 19:39:51.592173 916722 sgd_solver.cpp:106] Iteration 4938500, lr = 0.01
I0901 19:40:21.808317 916722 solver.cpp:218] Iteration 4939000 (16.5473 iter/s, 30.2164s/500 iters), loss = 0.148975
I0901 19:40:21.808393 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.148974 (* 1 = 0.148974 loss)
I0901 19:40:21.808401 916722 sgd_solver.cpp:106] Iteration 4939000, lr = 0.01
I0901 19:40:52.042966 916722 solver.cpp:218] Iteration 4939500 (16.5373 iter/s, 30.2348s/500 iters), loss = 0.346963
I0901 19:40:52.043025 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.346963 (* 1 = 0.346963 loss)
I0901 19:40:52.043033 916722 sgd_solver.cpp:106] Iteration 4939500, lr = 0.01
I0901 19:41:22.293741 916722 solver.cpp:218] Iteration 4940000 (16.5284 iter/s, 30.2509s/500 iters), loss = 0.0699157
I0901 19:41:22.293798 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0699152 (* 1 = 0.0699152 loss)
I0901 19:41:22.293807 916722 sgd_solver.cpp:106] Iteration 4940000, lr = 0.01
I0901 19:41:52.508942 916722 solver.cpp:218] Iteration 4940500 (16.5479 iter/s, 30.2153s/500 iters), loss = 0.247628
I0901 19:41:52.508999 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.247627 (* 1 = 0.247627 loss)
I0901 19:41:52.509007 916722 sgd_solver.cpp:106] Iteration 4940500, lr = 0.01
I0901 19:42:22.739814 916722 solver.cpp:218] Iteration 4941000 (16.5393 iter/s, 30.231s/500 iters), loss = 0.0867698
I0901 19:42:22.739872 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0867696 (* 1 = 0.0867696 loss)
I0901 19:42:22.739881 916722 sgd_solver.cpp:106] Iteration 4941000, lr = 0.01
I0901 19:42:52.985816 916722 solver.cpp:218] Iteration 4941500 (16.5311 iter/s, 30.2461s/500 iters), loss = 0.447955
I0901 19:42:52.985880 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.447955 (* 1 = 0.447955 loss)
I0901 19:42:52.985889 916722 sgd_solver.cpp:106] Iteration 4941500, lr = 0.01
I0901 19:43:23.199251 916722 solver.cpp:218] Iteration 4942000 (16.5489 iter/s, 30.2135s/500 iters), loss = 0.0673055
I0901 19:43:23.199308 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0673055 (* 1 = 0.0673055 loss)
I0901 19:43:23.199316 916722 sgd_solver.cpp:106] Iteration 4942000, lr = 0.01
I0901 19:43:53.457093 916722 solver.cpp:218] Iteration 4942500 (16.5246 iter/s, 30.2579s/500 iters), loss = 0.0175693
I0901 19:43:53.457154 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0175692 (* 1 = 0.0175692 loss)
I0901 19:43:53.457162 916722 sgd_solver.cpp:106] Iteration 4942500, lr = 0.01
I0901 19:44:23.669129 916722 solver.cpp:218] Iteration 4943000 (16.5497 iter/s, 30.2121s/500 iters), loss = 0.013861
I0901 19:44:23.669186 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0138608 (* 1 = 0.0138608 loss)
I0901 19:44:23.669195 916722 sgd_solver.cpp:106] Iteration 4943000, lr = 0.01
I0901 19:44:53.898046 916722 solver.cpp:218] Iteration 4943500 (16.5404 iter/s, 30.229s/500 iters), loss = 0.0576689
I0901 19:44:53.898104 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0576686 (* 1 = 0.0576686 loss)
I0901 19:44:53.898113 916722 sgd_solver.cpp:106] Iteration 4943500, lr = 0.01
I0901 19:45:24.114131 916722 solver.cpp:218] Iteration 4944000 (16.5474 iter/s, 30.2161s/500 iters), loss = 0.135513
I0901 19:45:24.114187 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.135513 (* 1 = 0.135513 loss)
I0901 19:45:24.114197 916722 sgd_solver.cpp:106] Iteration 4944000, lr = 0.01
I0901 19:45:54.354629 916722 solver.cpp:218] Iteration 4944500 (16.5341 iter/s, 30.2406s/500 iters), loss = 0.0963885
I0901 19:45:54.354689 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0963883 (* 1 = 0.0963883 loss)
I0901 19:45:54.354697 916722 sgd_solver.cpp:106] Iteration 4944500, lr = 0.01
I0901 19:46:24.597426 916722 solver.cpp:218] Iteration 4945000 (16.5328 iter/s, 30.2428s/500 iters), loss = 0.161755
I0901 19:46:24.597483 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.161755 (* 1 = 0.161755 loss)
I0901 19:46:24.597492 916722 sgd_solver.cpp:106] Iteration 4945000, lr = 0.01
I0901 19:46:54.835445 916722 solver.cpp:218] Iteration 4945500 (16.5355 iter/s, 30.2381s/500 iters), loss = 0.0502368
I0901 19:46:54.835513 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0502364 (* 1 = 0.0502364 loss)
I0901 19:46:54.835531 916722 sgd_solver.cpp:106] Iteration 4945500, lr = 0.01
I0901 19:47:25.082394 916722 solver.cpp:218] Iteration 4946000 (16.5306 iter/s, 30.247s/500 iters), loss = 0.0660365
I0901 19:47:25.082453 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0660362 (* 1 = 0.0660362 loss)
I0901 19:47:25.082460 916722 sgd_solver.cpp:106] Iteration 4946000, lr = 0.01
I0901 19:47:55.315450 916722 solver.cpp:218] Iteration 4946500 (16.5382 iter/s, 30.2331s/500 iters), loss = 0.00589995
I0901 19:47:55.315512 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.00589988 (* 1 = 0.00589988 loss)
I0901 19:47:55.315521 916722 sgd_solver.cpp:106] Iteration 4946500, lr = 0.01
I0901 19:48:25.529240 916722 solver.cpp:218] Iteration 4947000 (16.5487 iter/s, 30.2138s/500 iters), loss = 0.265043
I0901 19:48:25.529299 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.265043 (* 1 = 0.265043 loss)
I0901 19:48:25.529306 916722 sgd_solver.cpp:106] Iteration 4947000, lr = 0.01
I0901 19:48:55.757843 916722 solver.cpp:218] Iteration 4947500 (16.5406 iter/s, 30.2286s/500 iters), loss = 0.235349
I0901 19:48:55.757905 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.235349 (* 1 = 0.235349 loss)
I0901 19:48:55.757913 916722 sgd_solver.cpp:106] Iteration 4947500, lr = 0.01
I0901 19:49:25.977464 916722 solver.cpp:218] Iteration 4948000 (16.5455 iter/s, 30.2196s/500 iters), loss = 0.081
I0901 19:49:25.977524 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0809998 (* 1 = 0.0809998 loss)
I0901 19:49:25.977531 916722 sgd_solver.cpp:106] Iteration 4948000, lr = 0.01
I0901 19:49:56.211902 916722 solver.cpp:218] Iteration 4948500 (16.5374 iter/s, 30.2344s/500 iters), loss = 0.0442672
I0901 19:49:56.211963 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0442669 (* 1 = 0.0442669 loss)
I0901 19:49:56.211971 916722 sgd_solver.cpp:106] Iteration 4948500, lr = 0.01
I0901 19:50:26.460094 916722 solver.cpp:218] Iteration 4949000 (16.5299 iter/s, 30.2482s/500 iters), loss = 0.0811547
I0901 19:50:26.460152 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0811543 (* 1 = 0.0811543 loss)
I0901 19:50:26.460161 916722 sgd_solver.cpp:106] Iteration 4949000, lr = 0.01
I0901 19:50:56.661496 916722 solver.cpp:218] Iteration 4949500 (16.5555 iter/s, 30.2014s/500 iters), loss = 0.216687
I0901 19:50:56.661558 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.216686 (* 1 = 0.216686 loss)
I0901 19:50:56.661567 916722 sgd_solver.cpp:106] Iteration 4949500, lr = 0.01
I0901 19:51:26.825695 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_4950000.caffemodel
I0901 19:51:26.845052 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_4950000.solverstate
I0901 19:51:26.851083 916722 solver.cpp:330] Iteration 4950000, Testing net (#0)
I0901 19:51:42.293366 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8841
I0901 19:51:42.293419 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.412294 (* 1 = 0.412294 loss)
I0901 19:51:42.352149 916722 solver.cpp:218] Iteration 4950000 (10.9432 iter/s, 45.6907s/500 iters), loss = 0.288579
I0901 19:51:42.352177 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.288579 (* 1 = 0.288579 loss)
I0901 19:51:42.352185 916722 sgd_solver.cpp:106] Iteration 4950000, lr = 0.01
I0901 19:52:12.419955 916722 solver.cpp:218] Iteration 4950500 (16.6291 iter/s, 30.0678s/500 iters), loss = 0.0505195
I0901 19:52:12.420015 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0505189 (* 1 = 0.0505189 loss)
I0901 19:52:12.420024 916722 sgd_solver.cpp:106] Iteration 4950500, lr = 0.01
I0901 19:52:42.615563 916722 solver.cpp:218] Iteration 4951000 (16.5587 iter/s, 30.1956s/500 iters), loss = 0.324788
I0901 19:52:42.615635 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.324787 (* 1 = 0.324787 loss)
I0901 19:52:42.615644 916722 sgd_solver.cpp:106] Iteration 4951000, lr = 0.01
I0901 19:53:12.857180 916722 solver.cpp:218] Iteration 4951500 (16.5335 iter/s, 30.2416s/500 iters), loss = 0.222245
I0901 19:53:12.857235 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.222245 (* 1 = 0.222245 loss)
I0901 19:53:12.857244 916722 sgd_solver.cpp:106] Iteration 4951500, lr = 0.01
I0901 19:53:43.084784 916722 solver.cpp:218] Iteration 4952000 (16.5412 iter/s, 30.2276s/500 iters), loss = 0.289861
I0901 19:53:43.084841 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.28986 (* 1 = 0.28986 loss)
I0901 19:53:43.084848 916722 sgd_solver.cpp:106] Iteration 4952000, lr = 0.01
I0901 19:54:13.346863 916722 solver.cpp:218] Iteration 4952500 (16.5223 iter/s, 30.2621s/500 iters), loss = 0.0752586
I0901 19:54:13.346922 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.075258 (* 1 = 0.075258 loss)
I0901 19:54:13.346931 916722 sgd_solver.cpp:106] Iteration 4952500, lr = 0.01
I0901 19:54:43.585552 916722 solver.cpp:218] Iteration 4953000 (16.5351 iter/s, 30.2387s/500 iters), loss = 0.466674
I0901 19:54:43.585610 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.466674 (* 1 = 0.466674 loss)
I0901 19:54:43.585619 916722 sgd_solver.cpp:106] Iteration 4953000, lr = 0.01
I0901 19:55:13.836537 916722 solver.cpp:218] Iteration 4953500 (16.5284 iter/s, 30.251s/500 iters), loss = 0.0958412
I0901 19:55:13.836596 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0958406 (* 1 = 0.0958406 loss)
I0901 19:55:13.836606 916722 sgd_solver.cpp:106] Iteration 4953500, lr = 0.01
I0901 19:55:44.082031 916722 solver.cpp:218] Iteration 4954000 (16.5314 iter/s, 30.2455s/500 iters), loss = 0.0898279
I0901 19:55:44.082089 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0898273 (* 1 = 0.0898273 loss)
I0901 19:55:44.082098 916722 sgd_solver.cpp:106] Iteration 4954000, lr = 0.01
I0901 19:56:14.337378 916722 solver.cpp:218] Iteration 4954500 (16.526 iter/s, 30.2553s/500 iters), loss = 0.0551255
I0901 19:56:14.337437 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.055125 (* 1 = 0.055125 loss)
I0901 19:56:14.337446 916722 sgd_solver.cpp:106] Iteration 4954500, lr = 0.01
I0901 19:56:44.567659 916722 solver.cpp:218] Iteration 4955000 (16.5397 iter/s, 30.2302s/500 iters), loss = 0.443839
I0901 19:56:44.567716 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.443839 (* 1 = 0.443839 loss)
I0901 19:56:44.567725 916722 sgd_solver.cpp:106] Iteration 4955000, lr = 0.01
I0901 19:57:14.822162 916722 solver.cpp:218] Iteration 4955500 (16.5265 iter/s, 30.2545s/500 iters), loss = 0.105495
I0901 19:57:14.822221 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105495 (* 1 = 0.105495 loss)
I0901 19:57:14.822230 916722 sgd_solver.cpp:106] Iteration 4955500, lr = 0.01
I0901 19:57:45.087216 916722 solver.cpp:218] Iteration 4956000 (16.5207 iter/s, 30.265s/500 iters), loss = 0.102549
I0901 19:57:45.087273 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.102548 (* 1 = 0.102548 loss)
I0901 19:57:45.087281 916722 sgd_solver.cpp:106] Iteration 4956000, lr = 0.01
I0901 19:58:15.381319 916722 solver.cpp:218] Iteration 4956500 (16.5049 iter/s, 30.2941s/500 iters), loss = 0.20676
I0901 19:58:15.381378 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.20676 (* 1 = 0.20676 loss)
I0901 19:58:15.381387 916722 sgd_solver.cpp:106] Iteration 4956500, lr = 0.01
I0901 19:58:45.652505 916722 solver.cpp:218] Iteration 4957000 (16.5174 iter/s, 30.2711s/500 iters), loss = 0.252174
I0901 19:58:45.652560 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.252173 (* 1 = 0.252173 loss)
I0901 19:58:45.652570 916722 sgd_solver.cpp:106] Iteration 4957000, lr = 0.01
I0901 19:59:15.886869 916722 solver.cpp:218] Iteration 4957500 (16.5375 iter/s, 30.2343s/500 iters), loss = 0.17952
I0901 19:59:15.886927 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.179519 (* 1 = 0.179519 loss)
I0901 19:59:15.886936 916722 sgd_solver.cpp:106] Iteration 4957500, lr = 0.01
I0901 19:59:46.108925 916722 solver.cpp:218] Iteration 4958000 (16.5442 iter/s, 30.222s/500 iters), loss = 0.0718237
I0901 19:59:46.109004 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0718227 (* 1 = 0.0718227 loss)
I0901 19:59:46.109012 916722 sgd_solver.cpp:106] Iteration 4958000, lr = 0.01
I0901 20:00:16.334810 916722 solver.cpp:218] Iteration 4958500 (16.5421 iter/s, 30.2258s/500 iters), loss = 0.297701
I0901 20:00:16.334868 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.2977 (* 1 = 0.2977 loss)
I0901 20:00:16.334877 916722 sgd_solver.cpp:106] Iteration 4958500, lr = 0.01
I0901 20:00:46.558790 916722 solver.cpp:218] Iteration 4959000 (16.5432 iter/s, 30.2239s/500 iters), loss = 0.328701
I0901 20:00:46.558846 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.3287 (* 1 = 0.3287 loss)
I0901 20:00:46.558856 916722 sgd_solver.cpp:106] Iteration 4959000, lr = 0.01
I0901 20:01:16.808020 916722 solver.cpp:218] Iteration 4959500 (16.5294 iter/s, 30.2492s/500 iters), loss = 0.186717
I0901 20:01:16.808077 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.186716 (* 1 = 0.186716 loss)
I0901 20:01:16.808086 916722 sgd_solver.cpp:106] Iteration 4959500, lr = 0.01
I0901 20:01:47.053905 916722 solver.cpp:218] Iteration 4960000 (16.5312 iter/s, 30.2458s/500 iters), loss = 0.0866634
I0901 20:01:47.053958 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0866623 (* 1 = 0.0866623 loss)
I0901 20:01:47.053967 916722 sgd_solver.cpp:106] Iteration 4960000, lr = 0.01
I0901 20:02:17.325017 916722 solver.cpp:218] Iteration 4960500 (16.5174 iter/s, 30.2711s/500 iters), loss = 0.466779
I0901 20:02:17.325076 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.466778 (* 1 = 0.466778 loss)
I0901 20:02:17.325084 916722 sgd_solver.cpp:106] Iteration 4960500, lr = 0.01
I0901 20:02:47.578778 916722 solver.cpp:218] Iteration 4961000 (16.5269 iter/s, 30.2537s/500 iters), loss = 0.198853
I0901 20:02:47.578833 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.198852 (* 1 = 0.198852 loss)
I0901 20:02:47.578841 916722 sgd_solver.cpp:106] Iteration 4961000, lr = 0.01
I0901 20:03:17.832442 916722 solver.cpp:218] Iteration 4961500 (16.5269 iter/s, 30.2536s/500 iters), loss = 0.321683
I0901 20:03:17.832500 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.321682 (* 1 = 0.321682 loss)
I0901 20:03:17.832509 916722 sgd_solver.cpp:106] Iteration 4961500, lr = 0.01
I0901 20:03:48.076370 916722 solver.cpp:218] Iteration 4962000 (16.5323 iter/s, 30.2439s/500 iters), loss = 0.132979
I0901 20:03:48.076429 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.132978 (* 1 = 0.132978 loss)
I0901 20:03:48.076439 916722 sgd_solver.cpp:106] Iteration 4962000, lr = 0.01
I0901 20:04:18.325677 916722 solver.cpp:218] Iteration 4962500 (16.5293 iter/s, 30.2493s/500 iters), loss = 0.219485
I0901 20:04:18.325735 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.219484 (* 1 = 0.219484 loss)
I0901 20:04:18.325743 916722 sgd_solver.cpp:106] Iteration 4962500, lr = 0.01
I0901 20:04:48.596061 916722 solver.cpp:218] Iteration 4963000 (16.5178 iter/s, 30.2703s/500 iters), loss = 0.0341446
I0901 20:04:48.596118 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0341436 (* 1 = 0.0341436 loss)
I0901 20:04:48.596127 916722 sgd_solver.cpp:106] Iteration 4963000, lr = 0.01
I0901 20:05:18.859012 916722 solver.cpp:218] Iteration 4963500 (16.5219 iter/s, 30.2629s/500 iters), loss = 0.30673
I0901 20:05:18.859074 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.306729 (* 1 = 0.306729 loss)
I0901 20:05:18.859082 916722 sgd_solver.cpp:106] Iteration 4963500, lr = 0.01
I0901 20:05:49.132856 916722 solver.cpp:218] Iteration 4964000 (16.5159 iter/s, 30.2738s/500 iters), loss = 0.399821
I0901 20:05:49.132911 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.39982 (* 1 = 0.39982 loss)
I0901 20:05:49.132920 916722 sgd_solver.cpp:106] Iteration 4964000, lr = 0.01
I0901 20:06:19.401576 916722 solver.cpp:218] Iteration 4964500 (16.5187 iter/s, 30.2687s/500 iters), loss = 0.26056
I0901 20:06:19.401646 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.260559 (* 1 = 0.260559 loss)
I0901 20:06:19.401654 916722 sgd_solver.cpp:106] Iteration 4964500, lr = 0.01
I0901 20:06:49.672149 916722 solver.cpp:218] Iteration 4965000 (16.5177 iter/s, 30.2705s/500 iters), loss = 0.465249
I0901 20:06:49.672201 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.465248 (* 1 = 0.465248 loss)
I0901 20:06:49.672209 916722 sgd_solver.cpp:106] Iteration 4965000, lr = 0.01
I0901 20:07:19.954551 916722 solver.cpp:218] Iteration 4965500 (16.5113 iter/s, 30.2824s/500 iters), loss = 0.163344
I0901 20:07:19.954613 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.163343 (* 1 = 0.163343 loss)
I0901 20:07:19.954622 916722 sgd_solver.cpp:106] Iteration 4965500, lr = 0.01
I0901 20:07:50.224071 916722 solver.cpp:218] Iteration 4966000 (16.5183 iter/s, 30.2695s/500 iters), loss = 0.249723
I0901 20:07:50.224128 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.249722 (* 1 = 0.249722 loss)
I0901 20:07:50.224135 916722 sgd_solver.cpp:106] Iteration 4966000, lr = 0.01
I0901 20:08:20.493320 916722 solver.cpp:218] Iteration 4966500 (16.5184 iter/s, 30.2692s/500 iters), loss = 0.158449
I0901 20:08:20.493379 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.158448 (* 1 = 0.158448 loss)
I0901 20:08:20.493388 916722 sgd_solver.cpp:106] Iteration 4966500, lr = 0.01
I0901 20:08:50.772189 916722 solver.cpp:218] Iteration 4967000 (16.5132 iter/s, 30.2788s/500 iters), loss = 0.0702045
I0901 20:08:50.772248 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0702035 (* 1 = 0.0702035 loss)
I0901 20:08:50.772256 916722 sgd_solver.cpp:106] Iteration 4967000, lr = 0.01
I0901 20:09:21.036410 916722 solver.cpp:218] Iteration 4967500 (16.5212 iter/s, 30.2642s/500 iters), loss = 0.250727
I0901 20:09:21.036474 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.250726 (* 1 = 0.250726 loss)
I0901 20:09:21.036484 916722 sgd_solver.cpp:106] Iteration 4967500, lr = 0.01
I0901 20:09:51.316143 916722 solver.cpp:218] Iteration 4968000 (16.5127 iter/s, 30.2797s/500 iters), loss = 0.121207
I0901 20:09:51.316197 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.121206 (* 1 = 0.121206 loss)
I0901 20:09:51.316206 916722 sgd_solver.cpp:106] Iteration 4968000, lr = 0.01
I0901 20:10:21.594027 916722 solver.cpp:218] Iteration 4968500 (16.5137 iter/s, 30.2778s/500 iters), loss = 0.100346
I0901 20:10:21.594089 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.100345 (* 1 = 0.100345 loss)
I0901 20:10:21.594097 916722 sgd_solver.cpp:106] Iteration 4968500, lr = 0.01
I0901 20:10:51.857250 916722 solver.cpp:218] Iteration 4969000 (16.5217 iter/s, 30.2632s/500 iters), loss = 0.216533
I0901 20:10:51.857306 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.216532 (* 1 = 0.216532 loss)
I0901 20:10:51.857316 916722 sgd_solver.cpp:106] Iteration 4969000, lr = 0.01
I0901 20:11:22.122095 916722 solver.cpp:218] Iteration 4969500 (16.5208 iter/s, 30.2648s/500 iters), loss = 0.100011
I0901 20:11:22.122153 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.10001 (* 1 = 0.10001 loss)
I0901 20:11:22.122161 916722 sgd_solver.cpp:106] Iteration 4969500, lr = 0.01
I0901 20:11:52.395900 916722 solver.cpp:218] Iteration 4970000 (16.516 iter/s, 30.2737s/500 iters), loss = 0.125573
I0901 20:11:52.395956 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.125572 (* 1 = 0.125572 loss)
I0901 20:11:52.395965 916722 sgd_solver.cpp:106] Iteration 4970000, lr = 0.01
I0901 20:12:22.656409 916722 solver.cpp:218] Iteration 4970500 (16.5232 iter/s, 30.2605s/500 iters), loss = 0.105389
I0901 20:12:22.656489 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.105388 (* 1 = 0.105388 loss)
I0901 20:12:22.656498 916722 sgd_solver.cpp:106] Iteration 4970500, lr = 0.01
I0901 20:12:52.912328 916722 solver.cpp:218] Iteration 4971000 (16.5258 iter/s, 30.2557s/500 iters), loss = 0.363472
I0901 20:12:52.912402 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.363471 (* 1 = 0.363471 loss)
I0901 20:12:52.912410 916722 sgd_solver.cpp:106] Iteration 4971000, lr = 0.01
I0901 20:13:23.184624 916722 solver.cpp:218] Iteration 4971500 (16.5169 iter/s, 30.272s/500 iters), loss = 0.407103
I0901 20:13:23.184684 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.407102 (* 1 = 0.407102 loss)
I0901 20:13:23.184691 916722 sgd_solver.cpp:106] Iteration 4971500, lr = 0.01
I0901 20:13:53.437968 916722 solver.cpp:218] Iteration 4972000 (16.5273 iter/s, 30.253s/500 iters), loss = 0.0785908
I0901 20:13:53.438026 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0785898 (* 1 = 0.0785898 loss)
I0901 20:13:53.438035 916722 sgd_solver.cpp:106] Iteration 4972000, lr = 0.01
I0901 20:14:23.689584 916722 solver.cpp:218] Iteration 4972500 (16.5282 iter/s, 30.2513s/500 iters), loss = 0.0602954
I0901 20:14:23.689642 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0602945 (* 1 = 0.0602945 loss)
I0901 20:14:23.689651 916722 sgd_solver.cpp:106] Iteration 4972500, lr = 0.01
I0901 20:14:53.937072 916722 solver.cpp:218] Iteration 4973000 (16.5305 iter/s, 30.2472s/500 iters), loss = 0.338248
I0901 20:14:53.937134 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.338248 (* 1 = 0.338248 loss)
I0901 20:14:53.937144 916722 sgd_solver.cpp:106] Iteration 4973000, lr = 0.01
I0901 20:15:24.194648 916722 solver.cpp:218] Iteration 4973500 (16.5249 iter/s, 30.2573s/500 iters), loss = 0.223172
I0901 20:15:24.194705 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.223172 (* 1 = 0.223172 loss)
I0901 20:15:24.194713 916722 sgd_solver.cpp:106] Iteration 4973500, lr = 0.01
I0901 20:15:54.436015 916722 solver.cpp:218] Iteration 4974000 (16.5338 iter/s, 30.2411s/500 iters), loss = 0.0754832
I0901 20:15:54.436074 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0754824 (* 1 = 0.0754824 loss)
I0901 20:15:54.436081 916722 sgd_solver.cpp:106] Iteration 4974000, lr = 0.01
I0901 20:16:24.684938 916722 solver.cpp:218] Iteration 4974500 (16.5297 iter/s, 30.2487s/500 iters), loss = 0.0375144
I0901 20:16:24.684993 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0375137 (* 1 = 0.0375137 loss)
I0901 20:16:24.685000 916722 sgd_solver.cpp:106] Iteration 4974500, lr = 0.01
I0901 20:16:54.941249 916722 solver.cpp:218] Iteration 4975000 (16.5256 iter/s, 30.2561s/500 iters), loss = 0.0755365
I0901 20:16:54.941310 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0755358 (* 1 = 0.0755358 loss)
I0901 20:16:54.941319 916722 sgd_solver.cpp:106] Iteration 4975000, lr = 0.01
I0901 20:17:25.219210 916722 solver.cpp:218] Iteration 4975500 (16.5138 iter/s, 30.2777s/500 iters), loss = 0.0126521
I0901 20:17:25.219269 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0126513 (* 1 = 0.0126513 loss)
I0901 20:17:25.219277 916722 sgd_solver.cpp:106] Iteration 4975500, lr = 0.01
I0901 20:17:55.477533 916722 solver.cpp:218] Iteration 4976000 (16.5245 iter/s, 30.2581s/500 iters), loss = 0.196209
I0901 20:17:55.477593 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.196208 (* 1 = 0.196208 loss)
I0901 20:17:55.477602 916722 sgd_solver.cpp:106] Iteration 4976000, lr = 0.01
I0901 20:18:25.741886 916722 solver.cpp:218] Iteration 4976500 (16.5212 iter/s, 30.2641s/500 iters), loss = 0.0989369
I0901 20:18:25.741945 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.098936 (* 1 = 0.098936 loss)
I0901 20:18:25.741952 916722 sgd_solver.cpp:106] Iteration 4976500, lr = 0.01
I0901 20:18:56.006412 916722 solver.cpp:218] Iteration 4977000 (16.5211 iter/s, 30.2643s/500 iters), loss = 0.0558187
I0901 20:18:56.006471 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.055818 (* 1 = 0.055818 loss)
I0901 20:18:56.006480 916722 sgd_solver.cpp:106] Iteration 4977000, lr = 0.01
I0901 20:19:26.267724 916722 solver.cpp:218] Iteration 4977500 (16.5229 iter/s, 30.2611s/500 iters), loss = 0.475485
I0901 20:19:26.267792 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.475484 (* 1 = 0.475484 loss)
I0901 20:19:26.267805 916722 sgd_solver.cpp:106] Iteration 4977500, lr = 0.01
I0901 20:19:56.543222 916722 solver.cpp:218] Iteration 4978000 (16.5151 iter/s, 30.2753s/500 iters), loss = 0.133649
I0901 20:19:56.543282 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.133648 (* 1 = 0.133648 loss)
I0901 20:19:56.543290 916722 sgd_solver.cpp:106] Iteration 4978000, lr = 0.01
I0901 20:20:26.805691 916722 solver.cpp:218] Iteration 4978500 (16.5222 iter/s, 30.2623s/500 iters), loss = 0.424596
I0901 20:20:26.805750 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.424595 (* 1 = 0.424595 loss)
I0901 20:20:26.805758 916722 sgd_solver.cpp:106] Iteration 4978500, lr = 0.01
I0901 20:20:57.063746 916722 solver.cpp:218] Iteration 4979000 (16.5246 iter/s, 30.2579s/500 iters), loss = 0.12179
I0901 20:20:57.063799 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.121789 (* 1 = 0.121789 loss)
I0901 20:20:57.063807 916722 sgd_solver.cpp:106] Iteration 4979000, lr = 0.01
I0901 20:21:27.339243 916722 solver.cpp:218] Iteration 4979500 (16.5151 iter/s, 30.2753s/500 iters), loss = 0.153891
I0901 20:21:27.339301 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.153891 (* 1 = 0.153891 loss)
I0901 20:21:27.339310 916722 sgd_solver.cpp:106] Iteration 4979500, lr = 0.01
I0901 20:21:57.631583 916722 solver.cpp:218] Iteration 4980000 (16.5059 iter/s, 30.2922s/500 iters), loss = 0.0455874
I0901 20:21:57.631640 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0455868 (* 1 = 0.0455868 loss)
I0901 20:21:57.631649 916722 sgd_solver.cpp:106] Iteration 4980000, lr = 0.01
I0901 20:22:27.900352 916722 solver.cpp:218] Iteration 4980500 (16.5188 iter/s, 30.2686s/500 iters), loss = 0.0286709
I0901 20:22:27.900413 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0286704 (* 1 = 0.0286704 loss)
I0901 20:22:27.900420 916722 sgd_solver.cpp:106] Iteration 4980500, lr = 0.01
I0901 20:22:58.175209 916722 solver.cpp:218] Iteration 4981000 (16.5154 iter/s, 30.2747s/500 iters), loss = 0.145779
I0901 20:22:58.175266 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.145779 (* 1 = 0.145779 loss)
I0901 20:22:58.175273 916722 sgd_solver.cpp:106] Iteration 4981000, lr = 0.01
I0901 20:23:28.464511 916722 solver.cpp:218] Iteration 4981500 (16.5076 iter/s, 30.2891s/500 iters), loss = 0.114419
I0901 20:23:28.464571 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.114418 (* 1 = 0.114418 loss)
I0901 20:23:28.464579 916722 sgd_solver.cpp:106] Iteration 4981500, lr = 0.01
I0901 20:23:58.743106 916722 solver.cpp:218] Iteration 4982000 (16.5134 iter/s, 30.2784s/500 iters), loss = 0.503027
I0901 20:23:58.743163 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.503026 (* 1 = 0.503026 loss)
I0901 20:23:58.743172 916722 sgd_solver.cpp:106] Iteration 4982000, lr = 0.01
I0901 20:24:29.019376 916722 solver.cpp:218] Iteration 4982500 (16.5147 iter/s, 30.2761s/500 iters), loss = 0.041405
I0901 20:24:29.019435 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0414046 (* 1 = 0.0414046 loss)
I0901 20:24:29.019443 916722 sgd_solver.cpp:106] Iteration 4982500, lr = 0.01
I0901 20:24:59.295194 916722 solver.cpp:218] Iteration 4983000 (16.5149 iter/s, 30.2757s/500 iters), loss = 0.271409
I0901 20:24:59.295249 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.271408 (* 1 = 0.271408 loss)
I0901 20:24:59.295258 916722 sgd_solver.cpp:106] Iteration 4983000, lr = 0.01
I0901 20:25:29.576972 916722 solver.cpp:218] Iteration 4983500 (16.5117 iter/s, 30.2816s/500 iters), loss = 0.28287
I0901 20:25:29.577031 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.28287 (* 1 = 0.28287 loss)
I0901 20:25:29.577039 916722 sgd_solver.cpp:106] Iteration 4983500, lr = 0.01
I0901 20:25:59.859773 916722 solver.cpp:218] Iteration 4984000 (16.5111 iter/s, 30.2827s/500 iters), loss = 0.0565998
I0901 20:25:59.859843 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0565997 (* 1 = 0.0565997 loss)
I0901 20:25:59.859856 916722 sgd_solver.cpp:106] Iteration 4984000, lr = 0.01
I0901 20:26:30.188520 916722 solver.cpp:218] Iteration 4984500 (16.4861 iter/s, 30.3286s/500 iters), loss = 0.0624542
I0901 20:26:30.188581 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.062454 (* 1 = 0.062454 loss)
I0901 20:26:30.188589 916722 sgd_solver.cpp:106] Iteration 4984500, lr = 0.01
I0901 20:27:00.488150 916722 solver.cpp:218] Iteration 4985000 (16.5019 iter/s, 30.2995s/500 iters), loss = 0.278477
I0901 20:27:00.488206 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.278477 (* 1 = 0.278477 loss)
I0901 20:27:00.488214 916722 sgd_solver.cpp:106] Iteration 4985000, lr = 0.01
I0901 20:27:30.793885 916722 solver.cpp:218] Iteration 4985500 (16.4986 iter/s, 30.3056s/500 iters), loss = 0.272663
I0901 20:27:30.793946 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.272662 (* 1 = 0.272662 loss)
I0901 20:27:30.793954 916722 sgd_solver.cpp:106] Iteration 4985500, lr = 0.01
I0901 20:28:01.091040 916722 solver.cpp:218] Iteration 4986000 (16.5033 iter/s, 30.297s/500 iters), loss = 0.331756
I0901 20:28:01.091094 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.331756 (* 1 = 0.331756 loss)
I0901 20:28:01.091102 916722 sgd_solver.cpp:106] Iteration 4986000, lr = 0.01
I0901 20:28:31.393143 916722 solver.cpp:218] Iteration 4986500 (16.5006 iter/s, 30.302s/500 iters), loss = 0.240533
I0901 20:28:31.393203 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.240532 (* 1 = 0.240532 loss)
I0901 20:28:31.393213 916722 sgd_solver.cpp:106] Iteration 4986500, lr = 0.01
I0901 20:29:01.689046 916722 solver.cpp:218] Iteration 4987000 (16.504 iter/s, 30.2958s/500 iters), loss = 0.106266
I0901 20:29:01.689100 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.106266 (* 1 = 0.106266 loss)
I0901 20:29:01.689108 916722 sgd_solver.cpp:106] Iteration 4987000, lr = 0.01
I0901 20:29:31.982223 916722 solver.cpp:218] Iteration 4987500 (16.5054 iter/s, 30.293s/500 iters), loss = 0.0393357
I0901 20:29:31.982282 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0393356 (* 1 = 0.0393356 loss)
I0901 20:29:31.982290 916722 sgd_solver.cpp:106] Iteration 4987500, lr = 0.01
I0901 20:30:02.291637 916722 solver.cpp:218] Iteration 4988000 (16.4966 iter/s, 30.3093s/500 iters), loss = 0.230342
I0901 20:30:02.291693 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.230342 (* 1 = 0.230342 loss)
I0901 20:30:02.291702 916722 sgd_solver.cpp:106] Iteration 4988000, lr = 0.01
I0901 20:30:32.577503 916722 solver.cpp:218] Iteration 4988500 (16.5094 iter/s, 30.2857s/500 iters), loss = 0.114672
I0901 20:30:32.577561 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.114672 (* 1 = 0.114672 loss)
I0901 20:30:32.577570 916722 sgd_solver.cpp:106] Iteration 4988500, lr = 0.01
I0901 20:31:02.873682 916722 solver.cpp:218] Iteration 4989000 (16.5038 iter/s, 30.2961s/500 iters), loss = 0.26665
I0901 20:31:02.873734 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.26665 (* 1 = 0.26665 loss)
I0901 20:31:02.873744 916722 sgd_solver.cpp:106] Iteration 4989000, lr = 0.01
I0901 20:31:33.184717 916722 solver.cpp:218] Iteration 4989500 (16.4957 iter/s, 30.3109s/500 iters), loss = 0.267139
I0901 20:31:33.184787 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.267139 (* 1 = 0.267139 loss)
I0901 20:31:33.184795 916722 sgd_solver.cpp:106] Iteration 4989500, lr = 0.01
I0901 20:32:03.459460 916722 solver.cpp:218] Iteration 4990000 (16.5155 iter/s, 30.2746s/500 iters), loss = 0.34254
I0901 20:32:03.459514 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.34254 (* 1 = 0.34254 loss)
I0901 20:32:03.459522 916722 sgd_solver.cpp:106] Iteration 4990000, lr = 0.01
I0901 20:32:33.765794 916722 solver.cpp:218] Iteration 4990500 (16.4983 iter/s, 30.3062s/500 iters), loss = 0.0407341
I0901 20:32:33.765864 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0407338 (* 1 = 0.0407338 loss)
I0901 20:32:33.765877 916722 sgd_solver.cpp:106] Iteration 4990500, lr = 0.01
I0901 20:33:04.047785 916722 solver.cpp:218] Iteration 4991000 (16.5115 iter/s, 30.2819s/500 iters), loss = 0.20528
I0901 20:33:04.047840 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.205279 (* 1 = 0.205279 loss)
I0901 20:33:04.047847 916722 sgd_solver.cpp:106] Iteration 4991000, lr = 0.01
I0901 20:33:34.349391 916722 solver.cpp:218] Iteration 4991500 (16.5008 iter/s, 30.3015s/500 iters), loss = 0.0578597
I0901 20:33:34.349452 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0578594 (* 1 = 0.0578594 loss)
I0901 20:33:34.349459 916722 sgd_solver.cpp:106] Iteration 4991500, lr = 0.01
I0901 20:34:04.630779 916722 solver.cpp:218] Iteration 4992000 (16.5119 iter/s, 30.2813s/500 iters), loss = 0.223462
I0901 20:34:04.630831 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.223462 (* 1 = 0.223462 loss)
I0901 20:34:04.630841 916722 sgd_solver.cpp:106] Iteration 4992000, lr = 0.01
I0901 20:34:34.922482 916722 solver.cpp:218] Iteration 4992500 (16.5062 iter/s, 30.2916s/500 iters), loss = 0.253984
I0901 20:34:34.922538 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.253983 (* 1 = 0.253983 loss)
I0901 20:34:34.922547 916722 sgd_solver.cpp:106] Iteration 4992500, lr = 0.01
I0901 20:35:05.213830 916722 solver.cpp:218] Iteration 4993000 (16.5064 iter/s, 30.2912s/500 iters), loss = 0.128825
I0901 20:35:05.213888 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.128824 (* 1 = 0.128824 loss)
I0901 20:35:05.213896 916722 sgd_solver.cpp:106] Iteration 4993000, lr = 0.01
I0901 20:35:35.498891 916722 solver.cpp:218] Iteration 4993500 (16.5098 iter/s, 30.285s/500 iters), loss = 0.155343
I0901 20:35:35.498948 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.155343 (* 1 = 0.155343 loss)
I0901 20:35:35.498956 916722 sgd_solver.cpp:106] Iteration 4993500, lr = 0.01
I0901 20:36:05.804600 916722 solver.cpp:218] Iteration 4994000 (16.4986 iter/s, 30.3056s/500 iters), loss = 0.06844
I0901 20:36:05.804661 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0684395 (* 1 = 0.0684395 loss)
I0901 20:36:05.804670 916722 sgd_solver.cpp:106] Iteration 4994000, lr = 0.01
I0901 20:36:36.097080 916722 solver.cpp:218] Iteration 4994500 (16.5058 iter/s, 30.2924s/500 iters), loss = 0.107143
I0901 20:36:36.097143 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.107142 (* 1 = 0.107142 loss)
I0901 20:36:36.097152 916722 sgd_solver.cpp:106] Iteration 4994500, lr = 0.01
I0901 20:37:06.386387 916722 solver.cpp:218] Iteration 4995000 (16.5075 iter/s, 30.2892s/500 iters), loss = 0.237649
I0901 20:37:06.386443 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.237649 (* 1 = 0.237649 loss)
I0901 20:37:06.386451 916722 sgd_solver.cpp:106] Iteration 4995000, lr = 0.01
I0901 20:37:36.670734 916722 solver.cpp:218] Iteration 4995500 (16.5102 iter/s, 30.2842s/500 iters), loss = 0.199502
I0901 20:37:36.670794 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.199502 (* 1 = 0.199502 loss)
I0901 20:37:36.670802 916722 sgd_solver.cpp:106] Iteration 4995500, lr = 0.01
I0901 20:38:06.967630 916722 solver.cpp:218] Iteration 4996000 (16.5034 iter/s, 30.2968s/500 iters), loss = 0.258674
I0901 20:38:06.967686 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.258674 (* 1 = 0.258674 loss)
I0901 20:38:06.967694 916722 sgd_solver.cpp:106] Iteration 4996000, lr = 0.01
I0901 20:38:37.275326 916722 solver.cpp:218] Iteration 4996500 (16.4975 iter/s, 30.3076s/500 iters), loss = 0.0780931
I0901 20:38:37.275393 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0780929 (* 1 = 0.0780929 loss)
I0901 20:38:37.275401 916722 sgd_solver.cpp:106] Iteration 4996500, lr = 0.01
I0901 20:39:07.586495 916722 solver.cpp:218] Iteration 4997000 (16.4956 iter/s, 30.3111s/500 iters), loss = 0.108128
I0901 20:39:07.586551 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.108128 (* 1 = 0.108128 loss)
I0901 20:39:07.586560 916722 sgd_solver.cpp:106] Iteration 4997000, lr = 0.01
I0901 20:39:37.897620 916722 solver.cpp:218] Iteration 4997500 (16.4956 iter/s, 30.311s/500 iters), loss = 0.139297
I0901 20:39:37.897691 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.139297 (* 1 = 0.139297 loss)
I0901 20:39:37.897701 916722 sgd_solver.cpp:106] Iteration 4997500, lr = 0.01
I0901 20:40:08.196799 916722 solver.cpp:218] Iteration 4998000 (16.5022 iter/s, 30.2991s/500 iters), loss = 0.0750027
I0901 20:40:08.196852 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.0750023 (* 1 = 0.0750023 loss)
I0901 20:40:08.196861 916722 sgd_solver.cpp:106] Iteration 4998000, lr = 0.01
I0901 20:40:38.498775 916722 solver.cpp:218] Iteration 4998500 (16.5006 iter/s, 30.3019s/500 iters), loss = 0.416767
I0901 20:40:38.498833 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.416767 (* 1 = 0.416767 loss)
I0901 20:40:38.498842 916722 sgd_solver.cpp:106] Iteration 4998500, lr = 0.01
I0901 20:41:08.809204 916722 solver.cpp:218] Iteration 4999000 (16.496 iter/s, 30.3103s/500 iters), loss = 0.255837
I0901 20:41:08.809255 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.255836 (* 1 = 0.255836 loss)
I0901 20:41:08.809264 916722 sgd_solver.cpp:106] Iteration 4999000, lr = 0.01
I0901 20:41:39.121631 916722 solver.cpp:218] Iteration 4999500 (16.4949 iter/s, 30.3123s/500 iters), loss = 0.152468
I0901 20:41:39.121690 916722 solver.cpp:237]     Train net output #0: softmax_loss = 0.152468 (* 1 = 0.152468 loss)
I0901 20:41:39.121699 916722 sgd_solver.cpp:106] Iteration 4999500, lr = 0.01
I0901 20:42:09.361757 916722 solver.cpp:447] Snapshotting to binary proto file weights_20210828200417/CIFAR10_iter_5000000.caffemodel
I0901 20:42:09.380798 916722 sgd_solver.cpp:274] Snapshotting solver state to binary proto file weights_20210828200417/CIFAR10_iter_5000000.solverstate
I0901 20:42:09.400533 916722 solver.cpp:310] Iteration 5000000, loss = 0.188963
I0901 20:42:09.400566 916722 solver.cpp:330] Iteration 5000000, Testing net (#0)
I0901 20:42:24.818953 916722 solver.cpp:397]     Test net output #0: accuracy = 0.8849
I0901 20:42:24.818998 916722 solver.cpp:397]     Test net output #1: softmax_loss = 0.400716 (* 1 = 0.400716 loss)
I0901 20:42:24.819005 916722 solver.cpp:315] Optimization Done.
I0901 20:42:24.819010 916722 caffe.cpp:259] Optimization Done.
